{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Contents Linux Python Cloud","title":"Home"},{"location":"#contents","text":"Linux Python Cloud","title":"Contents"},{"location":"about/","text":"Get busy living or get busy dying It is to summarize what I have been learning as reference and reminder. What's past is prologue. It\u2019s never too late to do. --James","title":"About"},{"location":"about/#get-busy-living-or-get-busy-dying","text":"It is to summarize what I have been learning as reference and reminder. What's past is prologue. It\u2019s never too late to do. --James","title":"Get busy living or get busy dying"},{"location":"cloud/","text":"Cloud Hands-On Microservices with Kubernetes Learning Memo Kubernetes Foundation Learning Memo Tutorials: local deployment Tutorials: Kyma@SAP BTP Tutorials: Ubuntu@Aliyun Tutorials: openSUSE@Aliyun","title":"Cloud"},{"location":"cloud/#cloud","text":"Hands-On Microservices with Kubernetes Learning Memo Kubernetes Foundation Learning Memo Tutorials: local deployment Tutorials: Kyma@SAP BTP Tutorials: Ubuntu@Aliyun Tutorials: openSUSE@Aliyun","title":"Cloud"},{"location":"linux/","text":"Linux SUSE Linux Administration Learning Memo SUSE Enterprise Storage Foundation and Basic Operation Learning Memo","title":"Linux"},{"location":"linux/#linux","text":"SUSE Linux Administration Learning Memo SUSE Enterprise Storage Foundation and Basic Operation Learning Memo","title":"Linux"},{"location":"python/","text":"Python Foundation Learning Memo (Chinese) Data Analysis Learning Memo (Chinese) Practice Demo","title":"Python"},{"location":"python/#python","text":"Foundation Learning Memo (Chinese) Data Analysis Learning Memo (Chinese) Practice Demo","title":"Python"},{"location":"cloud/KubernetesFoundationMemo/","text":"Kubernetes Foundation 1. Docker Fundamentals Demo environment Linux: openSUSE 15.3 james@lizard:/opt> cat /etc/os-release NAME=\"openSUSE Leap\" VERSION=\"15.3\" ID=\"opensuse-leap\" ID_LIKE=\"suse opensuse\" VERSION_ID=\"15.3\" PRETTY_NAME=\"openSUSE Leap 15.3\" ANSI_COLOR=\"0;32\" CPE_NAME=\"cpe:/o:opensuse:leap:15.3\" BUG_REPORT_URL=\"https://bugs.opensuse.org\" HOME_URL=\"https://www.opensuse.org/\" Linux Primitives chroot(using pivot_root) Changes the root directory for a process to any given directory namespaces Different processes see different environments even though they are on the same host/OS mnt (mount points) pid (process tree) net (network interfaces and connectivity) ipc (interprocess communication framework) uts (unix timesharing - domain name, hostname, etc.) uid (user IDs and mappings) cgroups(control groups) manage/limit resource allocation to individual processes Prioritization of processes Apparmor and SELinux profiles - Security profiles to govern access to resources Kernel capabilities without capabilities: root can do everything, everybody else may do nothing 38 granular facilities to control privileges seccomp policies Limitation of allowed kernel syscalls Unallowed syscalls lead to process termination Netlink - A Linux kernel interface used for inter-process communication (IPC) between both the kernel and userspace processes, and between different userspace processes. Netfilter A framework provided by the Linux kernel that allows various networking-related operations Packet filtering, network address translation, and port translation(iptables/nftables) used to direct network packages to individual containers More inforamtion could refer to LXC/LXD Let's download an image alpine to simulate an root file system under /opt/test folder. james@lizard:/opt> mkdir test james@lizard:/opt> cd test james@lizard:/opt/test> wget https://dl-cdn.alpinelinux.org/alpine/v3.13/releases/x86_64/alpine-minirootfs-3.13.4-x86_64.tar.gz james@lizard:/opt/test> tar zxvf alpine-minirootfs-3.13.4-x86_64.tar.gz -C alpine-minirootfs/ james@lizard:/opt> tree ./test -L 1 ./test \u251c\u2500\u2500 alpine-minirootfs-3.13.4-x86_64.tar.gz \u251c\u2500\u2500 bin \u251c\u2500\u2500 dev \u251c\u2500\u2500 etc \u251c\u2500\u2500 home \u251c\u2500\u2500 lib \u251c\u2500\u2500 media \u251c\u2500\u2500 mnt \u251c\u2500\u2500 opt \u251c\u2500\u2500 proc \u251c\u2500\u2500 root \u251c\u2500\u2500 run \u251c\u2500\u2500 sbin \u251c\u2500\u2500 srv \u251c\u2500\u2500 sys \u251c\u2500\u2500 tmp \u251c\u2500\u2500 usr \u2514\u2500\u2500 var Mount folder /opt/test/proc to a file and use command unshare to build a guest system. james@lizard:/opt> sudo mount -t tmpfs tmpfs /opt/test/proc james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # ps -ef PID USER TIME COMMAND 1 root 0:00 /bin/sh 2 root 0:00 ps -ef / # touch 123 / # ls 123 123 The file 123 created in guest system is accessable and writable from host system. james@lizard:/opt> su - lizard:/opt/test # ls 123 123 lizard:/opt/test # echo hello > 123 We will see above change in guest system. / # cat 123 hello Let's create two folders /opt/test-1 and /opt/test-2 . james@lizard:/opt> mkdir test-1 james@lizard:/opt> mkdir test-2 Create two guests system. Mount /opt/test/home/ to different folders for different guests. james@lizard:/opt> sudo mount --bind /opt/test-1 /opt/test/home/ james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # cd /home /home # echo \"test-1\" > 123.1 /home # cat 123.1 test-1 james@lizard:/opt> sudo mount --bind /opt/test-2 /opt/test/home/ james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # cd /home /home # echo \"test-2\" > 123.2 /home # cat 123.2 test-2 james@lizard:/opt> ll test/home -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 james@lizard:/opt> ll test-1/ -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 james@lizard:/opt> ll test-2/ -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 With above demo, the conclusion is that two guests share same home folder on host system and will impact each other. Installing Docker Install Docker engine by referring the guide , and Docker Desktop by referring the guide . Install engine via openSUSE repository automatically. james@lizard:/opt> sudo zypper in docker The docker group is automatically created at package installation time. The user can communicate with the local Docker daemon upon its next login. The Docker daemon listens on a local socket which is accessible only by the root user and by the members of the docker group. Add current user to docker group. james@lizard:/opt> sudo usermod -aG docker $USER Enable and start Docker engine. james@lizard:/opt> sudo systemctl enable docker.service Created symlink /etc/systemd/system/multi-user.target.wants/docker.service \u2192 /usr/lib/systemd/system/docker.service. james@lizard:/opt> sudo systemctl start docker.service james@lizard:/opt> sudo systemctl status docker.service \u25cf docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2022-05-28 14:36:45 CST; 6s ago Docs: http://docs.docker.com Main PID: 31565 (dockerd) Tasks: 20 CGroup: /system.slice/docker.service \u251c\u250031565 /usr/bin/dockerd --add-runtime oci=/usr/sbin/docker-runc \u2514\u250031574 containerd --config /var/run/docker/containerd/containerd.toml --log-level warn May 28 14:36:44 lizard systemd[1]: Starting Docker Application Container Engine... May 28 14:36:44 lizard dockerd[31565]: time=\"2022-05-28T14:36:44+08:00\" level=info msg=\"SUSE:secrets :: enabled\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44+08:00\" level=warning msg=\"deprecated version : `1`, please switch to version `2`\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.659346964+08:00\" level=warning msg=\"failed to load plugin io.containerd.snapshotter.v1.devmapper\" error=\"devmapper no> May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.660040930+08:00\" level=warning msg=\"could not use snapshotter devmapper in metadata plugin\" error=\"devmapper not conf> May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018458102+08:00\" level=warning msg=\"Your kernel does not support swap memory limit\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018495482+08:00\" level=warning msg=\"Your kernel does not support CPU realtime scheduler\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018502682+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018506223+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight_device\" May 28 14:36:45 lizard systemd[1]: Started Docker Application Container Engine. Container lifecycle Overview Pull down below images in advance. james@lizard:~> docker image pull busybox james@lizard:~> docker image pull nginx james@lizard:~> docker image pull alpine james@lizard:~> docker image pull jenkins/jenkins:lts james@lizard:~> docker image pull golang:1.12-alpine james@lizard:~> docker image pull golang Download some docker images. Create and run a new busybox container interactively and connect a pseudo terminal to it. Inside the container, use the top command to find out that /bin/sh is running as process with the PID 1 and top process is also running. After that, just exit. james@lizard:~> docker image ls (or docker images) REPOSITORY TAG IMAGE ID CREATED SIZE golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB james@lizard:~> docker run -d -it --name busybox_v1 -v /opt/test:/docker busybox:latest /bin/sh james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 185efe490507 busybox:latest \"/bin/sh\" 11 seconds ago Up 9 seconds busybox_v1 james@lizard:~> docker exec -it 185efe490507 /bin/sh / # top Mem: 3627396K used, 12731512K free, 10080K shrd, 2920K buff, 2999340K cached CPU: 0.0% usr 0.1% sys 0.0% nic 99.8% idle 0.0% io 0.0% irq 0.0% sirq Load average: 0.38 1.09 1.29 2/277 14 PID PPID USER STAT VSZ %VSZ CPU %CPU COMMAND 1 0 root S 1332 0.0 1 0.0 /bin/sh 8 0 root S 1332 0.0 2 0.0 /bin/sh 14 8 root R 1328 0.0 1 0.0 top / # exitbuild Start a new nginx container in detached mode. Use the docker exec command to start another shell ( /bin/sh ) in the nginx container. Use ps to find out that sh and ps commands are running in your container. james@lizard:~> docker run -d -it --name nginx_v1 -v /opt/test:/docker nginx:latest /bin/sh james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 seconds ago Up 2 seconds 80/tcp nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 2 minutes ago Up 2 minutes busybox_v1 james@lizard:~> docker exec -it edb640127a0d /bin/sh # ps /bin/sh: 2: ps: not found # apt-get update && apt-get install -y procps # ps PID TTY TIME CMD 8 pts/1 00:00:00 sh 351 pts/1 00:00:00 ps # exit Now we have two running containers below. james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 7 minutes ago Up 7 minutes 80/tcp nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 10 minutes Let's make use of this to create a new stage:ago Up 10 minutes busybox_v1 Let's use docker logs to display the logs of the container we just exited from. The option --since 35m means display log in last 35 minutes. james@lizard:~> docker logs nginx_v1 --details --since 35m james@lizard:~> docker logs busybox_v1 --details --since 35m Let's make use of this to create a new stage: Use the docker stop command to end your nginx container. james@lizard:~> docker stop busybox_v1 busybox_v1 james@lizard:~> docker stop nginx_v1 nginx_v1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 10 minutes ago Exited (137) 4 seconds ago nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 13 minutes ago Exited (137) 16 seconds ago busybox_v1 With above command docker container ps -a , we get a list of all running and exited containers. Remove them with docker rm. Use docker rm $(docker ps -aq) to clean up all containers on your host. Use it with caution! james@lizard:~> docker rm busybox_v1 busybox_v1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 11 minutes ago Exited (137) 53 seconds ago nginx_v1 Ports and volumes Now, let's run an nginx webserver in a container and serve a website to the outside world. Start a new nginx container and export the port of the nginx webserver to a random port that is chosen by Docker. Use command docker ps to find you which port the webserver is forwarded. Access the docker with the forwarded port number on host http://localhost:<port#> . james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 11 minutes ago Exited (137) 53 seconds ago nginx_v1 james@lizard:~> docker run -d -P --name nginx_v2 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 15 seconds ago Up 14 seconds 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 13 minutes ago Exited (137) 3 minutes ago nginx_v1 Start another nginx container and expose port to 1080 on host as an example via http://localhost:1080 . james@lizard:~> docker run -d -p 1080:80 --name nginx_v3 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up 28 seconds 0.0.0.0:1080->80/tcp, :::1080->80/tcp nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up About a minute 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up 3 seconds 80/tcp nginx_v1 Let's make use of this to create a new stage: Use command docker inspect to find out which port is exposed by the image. Network information (ip, gateway, ports, etc.) is part of the output JSON format. james@lizard:~> docker inspect nginx_v3 Create a file index.html in folder /opt/test with below sample content. <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> Start a new container that bind-mounts host directory /opt/test to container directory /usr/share/nginx/html as a volume, so that NGINX will publish the HTML file wee just created instead of its default message via http://localhost:49159/ below. james@lizard:~> docker run -d -P --mount type=bind,source=/opt/test/,target=/usr/share/nginx/html --name nginx_v3-1 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bd94e4df65cf nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up About a minute 0.0.0.0:49159->80/tcp, :::49154->80/tcp nginx_v3-1 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up 28 seconds 0.0.0.0:1080->80/tcp, :::1080->80/tcp nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up About a minute 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up 3 seconds 80/tcp nginx_v1 Check nginx config file on where is the html home page stored in container. james@lizard:~> docker exec -it nginx_v3-1 /bin/sh # cd /etc/nginx/conf.d # ls default.conf # cat default.conf server { listen 80; listen [::]:80; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; <-- index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } # cd /usr/share/nginx/html # cat index.html <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> # It's recommendable to add a persistence with volumes API, instead of storing data in a docker container. Docker supports 2 ways of mount: Bind mounts: mount a local host directory onto a certain path in the container. Everything that was present before in the target directory is hidden (nature of the bind mount). For example, if you have some configuration you want to inject, write your config file, store it on your docker host at /home/container/config and mount the content of this directory to /usr/application/config (assuming the application reads config from there). Command: docker run --mount type=bind,source=<source path>,target=<container path> \u2026 Named volumes: docker can create a separated storage volume. Its lifecycle is independent from the container but still managed by docker. Upon creation, the content of the mount target is merged into the volume. Command: docker run --mount source=<vol name>,target=<container path> \u2026 How to differentiate between bind mountbuild s and named volumes? When specifying an absolute path, docker assumes a bind mount. When you just give a name (like in a relative path \u201cconfig\u201d), it will assume a named volume and create a volume \u201cconfig\u201d. Note: Persistent storage is 'provided' by the host. It can be a part of the file system on the host directly but also an NFS mount. Dockerfile Let's build an image with a Dockerfile,build tag it and upload it to a registry. Get docker image build history. james@lizard:~> docker image history nginx:latest IMAGE CREATED CREATED BY SIZE COMMENT c316d5a335a5 6 days ago /bin/sh -c #(nop) CMD [\"nginx\" \"-g\" \"daemon\u2026 0B <missing> 6 days ago /bin/sh -c #(nop) STOPSIGNAL SIGQUIT 0B <missing> 6 days ago /bin/sh -c #(nop) EXPOSE 80 0B <missing> 6 days ago /bin/sh -c #(nop) ENTRYPOINT [\"/docker-entr\u2026 0B <missing> 6 days ago /bin/sh -c #(nop) COPY file:09a214a3e07c919a\u2026 4.61kB <missing> 6 days ago /bin/sh -c build #(nop) COPY file:0fd5fca330dcd6a7\u2026 1.04kB <missing> 6 days ago /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0\u2026 1.96kB <missing> 6 days ago /bin/sh -c #(nop) COPY file:65504f71f5855ca0\u2026 1.2kB <missing> 6 days ago /bin/sh -c set -x && addgroup --system -\u2026 61.1MB <missing> 6 days ago /bin/sh -c #(nop) ENV PKG_RELEASE=1~bullseye 0B <missing> 6 days ago /bin/sh -c #(nop) ENV NJS_VERSION=0.7.2 0B <missing> 6 days ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.21.6 0B <missing> 6 days ago /bin/sh -c #(nop) LABEL maintainer=NGINX Do\u2026 0B <missing> 7 days ago /bin/sh -c #(nop) CMD [\"bash\"] 0B <missing> 7 days ago /bin/sh -c #(nop) ADD file:90495c24c897ec479\u2026 80.4MB Create an empty directory /opt/tmp-1 , change to the directory and create an sample index.html file in /opt/tmp-1 . james@lizard:/opt/tmp-1> cat index.html <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> Use FROM to extend an existing image, specify the release number. Use COPY to copy a new default website into the image, e.g., /usr/share/nginx/html Create SSL configuration /opt/tmp-1/ssl.conf for nginx. server { listen 443 ssl; server_name localhost; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; location / { root /usr/share/nginx/html; index index.html index.htm; } } Use OpenSSL to create a self-signed certificate so SSL/TLS to work would work. Use the following command to create an encryption key and a certificate. james@lizard:/opt/tmp-1> openssl req -x509 -nodes -newkey rsa:4096 -keyout nginx.key -out nginx.crt -days 365 -subj \"/CN=$(hostname)\" Generating a RSA private key ........++++ ................................++++ writing new private key to 'nginx.key' ----- To enable encrypted HTTPS, we need to expose port 443 with the EXPOSE directive. The default nginx image only exposes port 80 for unencrypted HTTP. In summary, we create below Dockerfile in foder /opt/tmp-1 . james@lizard:/opt/tmp-1> cat Dockerfile FROM nginx:latest # copy the custom website into the image COPY index.html /usr/share/nginx/html # copy the SSL configuration file into the image COPY ssl.conf /etc/nginx/conf.d/ssl.conf # download the SSL key and certificate into the image COPY nginx.key /etc/nginx/ssl/ COPY nginx.crt /etc/nginx/ssl/ # expose the HTTPS port EXPOSE 443 We have five files in foder /opt/tmp-1 till now. james@lizard:/opt/tmp-1> ls Dockerfile index.html nginx.crt nginx.key ssl.conf Now let's use the docker build command to build the image, forward the containers ports 80 and 443. james@lizard:~> docker build -t nginx:my1 /opt/tmp-1/ Sending build context to Docker daemon 62.98kB Let's make use of this to create a new stage: Step 1/6 : FROM nginx:latest ---> c316d5a335a5 Step 2/6 : COPY index.html /usr/share/nginx/html ---> 4a71ac8a2624 Step 3/6 : COPY ssl.conf /etc/nginx/conf.d/ssl.conf ---> ad574bc8080c Step 4/6 : COPY nginx.key /etc/nginx/ssl/ ---> 90c41ec98809 Step 5/6 : COPY nginx.crt /etc/nginx/ssl/ ---> 5801c1e5e02f Step 6/6 : EXPOSE 443 ---> Running in 0db1bffe7eb3 Removing intermediate container 0db1bffe7eb3 ---> 748439b24876 Successfully built 748439b24876 Successfully tagged nginx:my1 james@lizard:~> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx my1 748439b24876 44 seconds ago 142MB golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB james@lizard:~> docker run -d -p 1086:80 -p 1088:443 --name nginx_v5 nginx:my1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND build CREATED STATUS PORTS NAMES 70126d22e48b nginx:my1 \"/docker-entrypoint.\u2026\" 7 seconds ago Up 6 seconds 0.0.0.0:1086->80/tcp, :::1086->80/tcp, 0.0.0.0:1088->443/tcp, :::1088->443/tcp nginx_v5 7714058076c0 nginx:latest \"/docker-entrypoint.\u2026\" About an hour ago Exited (0) 48 seconds ago nginx_v4 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 2 hours ago Exited (0) About an hour ago nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 5 hours ago Exited (0) About an hour ago nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 5 hours ago Exited (137) About an hour ago nginx_v1 Above changes can be validated via below links: http://localhost:1086/ https://localhost:1088/ Register an account in DockerHub and enable access token in Docker Hub for CLI client authentication. james@lizard:~> docker login Username: <your account id> Password: <token> Tag the image to give image a nice name and a release number as tag, e.g., name is secure_nginx_0001 , tag is v1 . james@lizard:~> docker tag nginx:my1 <your account id>secure_nginx_0001:v1 james@lizard:~> docker push <your account id>secure_nginx_0001:v1 james@lizard:~> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx my1 748439b24876 7 minutes ago 142MB <your account id>secure_nginx_0001 v1 748439b24876 7 minutes ago 142MB golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB Multi-stage Dockerfile Let's show an example of multi-stage build. The multi-stage in the context of Docker means, we can have more than one line with a FROM keyword. Create folder /opt/tmp-2 and /opt/tmp-2/tmpl . Create files edit.html , view.html , wiki.go and structure likes below. james@lizard:/opt/tmp-2> tree -l . \u251c\u2500\u2500 tmpl \u2502 \u251c\u2500\u2500 edit.html \u2502 \u2514\u2500\u2500 view.html \u2514\u2500\u2500 wiki.go Create an new Dockerfile that starts james@lizard:/opt/tmp-2> cat Dockerfile # app builder stage FROM golang:1.12-alpine as builder ## copy the go source code over and build the binary WORKDIR /go/src COPY wiki.go /go/src/wiki.go RUN go build wiki.go # app exec stage # separate & new image starts here!# FROM alpine:3.9 # prepare file system etc RUN mkdir -p /app/data /app/tmpl && adduser -S -D -H -h /app appuser COPY tmpl/* /app/tmpl/ # get the compiled binary from the previous stage COPY --from=builder /go/src/wiki /app/wiki # prepare runtime env RUN chown -R appuser /app USER appuser WORKDIR /app # expose app port & set default command EXPOSE 8080 CMD [\"/app/wiki\"] Build the images by Dockerfile we created above. james@lizard:~> docker build -t lizard/golang:my1 /opt/tmp-2/ Sending build context to Docker daemon 9.728kB Step 1/13 : FROM golang:1.12-alpine as builder ---> 76bddfb5e55e Step 2/13 : WORKDIR /go/src ---> Running in 279957765a67 Removing intermediate container 279957765a67 ---> d74f3297387b Step 3/13 : COPY wiki.go /go/src/wiki.go ---> f14f358f10c0 Step 4/13 : RUN go build wiki.go ---> Running in af4a9d2d1dcc Removing intermediate container af4a9d2d1dcc ---> 101e734099a3 Step 5/13 : FROM alpine:3.9 3.9: Pulling from library/alpine 31603596830f: Pull complete Digest: sha256:414e0518bb9228d35e4cd5165567fb91d26c6a214e9c95899e1e056fcd349011 Status: Downloaded newer image for alpine:3.9 ---> 78a2ce922f86 Step 6/13 : RUN mkdir -p /app/data /app/tmpl && adduser -S -D -H -h /app appuser ---> Running in c7a8793fc95d Removing intermediate container c7a8793fc95d ---> a6e83922a81f Step 7/13 : COPY tmpl/* /app/tmpl/ ---> e48d44caf735 Step 8/13 : COPY --from=builder /go/src/wiki /app/wiki ---> 26cc829fe32b Step 9/13 : RUN chown -R appuser /app ---> Running in 22f3af57f969 Removing intermediate container 22f3af57f969 ---> ea7d678adf67 Step 10/13 : USER appuser ---> Running in 03c5d8e9ad45 Removing intermediate container 03c5d8e9ad45 ---> 40a692198491 Step 11/13 : WORKDIR /app ---> Running in 7c1b04e38306 Removing intermediate container 7c1b04e38306 ---> 45eaaebb0c12 Step 12/13 : EXPOSE 8080 ---> Running in 84f06d2e5f90 Removing intermediate container 84f06d2e5f90 ---> 3750bfa8c032 Step 13/13 : CMD [\"/app/wiki\"] ---> Running in 9ce20ca3a834 Removing intermediate container 9ce20ca3a834 ---> 8621174bab0d Successfully built 8621174bab0d Successfully tagged lizard/golang:my1 Run the image in detached mode, create a port forwarding from port 8080 in the container to port 1090 on the host. james@lizard:~> docker run -d -p 1090:8080 --name golan_v1 lizard/golang:my1 Access the container via link http://localhost:1090 Tab the golang image we created and push it to DockerHub. james@lizard:~> docker tag lizard/golang:my1 <your acccount id>/golang_0001:v1 james@lizard:~> docker push <your acccount id>/golang_0001:v1 2.Basic Concepts of Kubernetes Kubernetes Components A Kubernetes cluster consists of the components that represent the control plane and a set of machines called nodes . Kubernetes Components : Control Plane Components kube-apiserver: query and manipulate the state of objects in Kubernetes. play as \"communication hub\" among all resources in cluster. provide cluster security authentication, authorization, and role assignment. the only one can connect to etcd . etcd: all Kubernetes objects are stored on etcd. Kubernetes objects are persistent entities in the Kubernetes system, which are used to represent the state of your cluster. kube-scheduler: watches for newly created Pods with no assigned node, and selects a node for them to run on. kube-controller-manager: runs controller processes. Node controller : Responsible for noticing and responding when nodes go down. Job controller : Watches for Job objects that represent one-off tasks, then creates Pods to run those tasks to completion. Endpoints controller : Populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : Create default accounts and API access tokens for new namespaces. cloud-controller-manager: embeds cloud-specific control logic and only runs controllers that are specific to your cloud provider, no need for own premises and learning environment. Node controller : For checking the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : For setting up routes in the underlying cloud infrastructure Service controller : For creating, updating and deleting cloud provider load balancers Node Components kubelet: An agent that runs on each node in the cluster. Manage node. It makes sure that containers are running in a Pod. kubelet registers and updates nodes information to APIServer, and APIServer stores them into etcd . Manage pod. Watch pod via APIServer, and action on pods or containers in pods. Health check at container level. kube-proxy: is a network proxy that runs on each node in cluster. iptables ipvs maintains network rules on nodes. Container runtime: is the software that is responsible for running containers. Addons DNS: is a DNS server and required by all Kubernetes clusters. Web UI (Dashboard): web-based UI for Kubernetes clusters. Container Resource Monitoring: records generic time-series metrics about containers in a central database Cluster-level Logging: is responsible for saving container logs to a central log store with search/browsing interface. Scalability: Scaling out (horizontal scaling) by adding more servers to your architecture to spread the workload across more machines. Scaling up (vertical scaling) by adding more hard drives and memory to increase the computing capacity of physical servers. Kubernetes API The core of Kubernetes' control plane is the API server. CRI: Container Runtime Interface CNI: Container Network Interface CSI: Container Storage Interface The API server exposes an HTTP API that lets end users, different parts of cluster, and external components communicate with one another. The Kubernetes API lets we query and manipulate the state of API objects in Kubernetes (for example: Pods, Namespaces, ConfigMaps, and Events). Kubernetes API: OpenAPI specification OpenAPI V2 OpenAPI V3 Persistence. Kubernetes stores the serialized state of objects by writing them into etcd. API groups and versioning. Versioning is done at the API level. API resources are distinguished by their API group, resource type, namespace (for namespaced resources), and name. API changes API Extension Kubernetes Objects Objects Overview: Object Spec: providing a description of the characteristics the resource created to have: its desired state . Object Status: describes the current state of the object. Example of Deployment as an object that can represent an application running on cluster. apiVersion: apps/v1 # Which version of the Kubernetes API you're using to create this object kind: Deployment # What kind of object you want to create metadata: # Data that helps uniquely identify the object, including a name string, UID, and optional namespace name: nginx-deployment spec: # What state you desire for the object selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 Object Management: The kubectl command-line tool supports several different ways to create and manage Kubernetes objects. Read the Kubectl book for details. A Kubernetes object should be managed using ONLY one technique. Mixing and matching techniques for the same object results in undefined behavior. Three management techniques: Imperative commands operates directly on live objects in a cluster. kubectl create deployment nginx --image nginx Imperative object configuration kubectl create -f nginx.yaml kubectl delete -f nginx.yaml -f redis.yaml kubectl replace -f nginx.yaml Declarative object configuration kubectl diff -f configs/ kubectl apply -f configs/ Object Names and IDs Each object in your cluster has a Name that is unique for that type of resource. DNS Subdomain Names Label Names Path Segment Names Every Kubernetes object also has a UID that is unique across the whole cluster. Namespaces In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces. Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc) Not All Objects are in a Namespace. Kubernetes starts with four initial namespaces: default The default namespace for objects with no other namespace kube-system The namespace for objects created by the Kubernetes system kube-public This namespace is created automatically and is readable by all users (including those not authenticated). This namespace is mostly reserved for cluster usage, in case that some resources should be visible and readable publicly throughout the whole cluster. The public aspect of this namespace is only a convention, not a requirement. kube-node-lease This namespace holds Lease objects associated with each node. Node leases allow the kubelet to send heartbeats so that the control plane can detect node failure. Viewing namespaces: kubectl get namespace Setting the namespace for a request kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here> kubectl get pods --namespace=<insert-namespace-name-here> Labels and Selectors Labels are key/value pairs that are attached to objects, such as pods. Valid label keys have two segments: an optional prefix and name, separated by a slash ( / ). Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object. Example of labels: \"metadata\": { \"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } Unlike names and UIDs, labels do not provide uniqueness. In general, we expect many objects to carry the same label(s). The API currently supports two types of selectors: equality-based, e.g., environment = production , tier != frontend set-based, e.g., environment in (production, qa) , tier notin (frontend, backend) Sample commands: kubectl get pods -l environment=production,tier=frontend kubectl get pods -l 'environment in (production),tier in (frontend)' kubectl get pods -l 'environment in (production, qa)' kubectl get pods -l 'environment,environment notin (frontend)' Annotations Use Kubernetes annotations to attach arbitrary non-identifying metadata to objects. Clients such as tools and libraries can retrieve this metadata. Use either labels or annotations to attach metadata to Kubernetes objects. Labels can be used to select objects and to find collections of objects that satisfy certain conditions. Annotations are not used to identify and select objects. Annotations, like labels, are key/value maps. The keys and the values in the map must be strings. \"metadata\": { \"annotations\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } Valid annotation keys have two segments: an optional prefix and name, separated by a slash ( / ). Field Selectors Field selectors let you select Kubernetes resources based on the value of one or more resource fields. Here are some examples of field selector queries: metadata.name=my-service metadata.namespace!=default status.phase=Pending This kubectl command selects all Pods for which the value of the status.phase field is Running: kubectl get pods --field-selector status.phase=Running Supported field selectors vary by Kubernetes resource type. All resource types support the metadata.name and metadata.namespace fields. Use the = , == , and != operators with field selectors ( = and == mean the same thing). For example: kubectl get ingress --field-selector foo.bar=baz With operators, kubectl get services --all-namespaces --field-selector metadata.namespace!=default Chained selectors, kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always Multiple resource types, kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default Finalizers Finalizers are namespaced keys that tell Kubernetes to wait until specific conditions are met before it fully deletes resources marked for deletion . Finalizers alert controllers to clean up resources the deleted object owned. Finalizers are usually added to resources for a reason, so forcefully removing them can lead to issues in the cluster. Like labels, owner references describe the relationships between objects in Kubernetes, but are used for a different purpose. Kubernetes uses the owner references (not labels) to determine which Pods in the cluster need cleanup. Kubernetes processes finalizers when it identifies owner references on a resource targeted for deletion. Owners and Dependents In Kubernetes, some objects are owners of other objects. For example, a ReplicaSet is the owner of a set of Pods. These owned objects are dependents of their owner. Dependent objects have a metadata.ownerReferences field that references their owner object. A valid owner reference consists of the object name and a UID within the same namespace as the dependent object. Dependent objects also have an ownerReferences.blockOwnerDeletion field that takes a boolean value and controls whether specific dependents can block garbage collection from deleting their owner object. 4.Tutorials Tutorials: local deployment Tutorials: Kyma@SAP BTP Tutorials: Ubuntu@Aliyun Tutorials: openSUSE@Aliyun","title":"Kubernetes Foundation"},{"location":"cloud/KubernetesFoundationMemo/#kubernetes-foundation","text":"","title":"Kubernetes Foundation"},{"location":"cloud/KubernetesFoundationMemo/#1-docker-fundamentals","text":"","title":"1. Docker Fundamentals"},{"location":"cloud/KubernetesFoundationMemo/#demo-environment","text":"Linux: openSUSE 15.3 james@lizard:/opt> cat /etc/os-release NAME=\"openSUSE Leap\" VERSION=\"15.3\" ID=\"opensuse-leap\" ID_LIKE=\"suse opensuse\" VERSION_ID=\"15.3\" PRETTY_NAME=\"openSUSE Leap 15.3\" ANSI_COLOR=\"0;32\" CPE_NAME=\"cpe:/o:opensuse:leap:15.3\" BUG_REPORT_URL=\"https://bugs.opensuse.org\" HOME_URL=\"https://www.opensuse.org/\"","title":"Demo environment"},{"location":"cloud/KubernetesFoundationMemo/#linux-primitives","text":"chroot(using pivot_root) Changes the root directory for a process to any given directory namespaces Different processes see different environments even though they are on the same host/OS mnt (mount points) pid (process tree) net (network interfaces and connectivity) ipc (interprocess communication framework) uts (unix timesharing - domain name, hostname, etc.) uid (user IDs and mappings) cgroups(control groups) manage/limit resource allocation to individual processes Prioritization of processes Apparmor and SELinux profiles - Security profiles to govern access to resources Kernel capabilities without capabilities: root can do everything, everybody else may do nothing 38 granular facilities to control privileges seccomp policies Limitation of allowed kernel syscalls Unallowed syscalls lead to process termination Netlink - A Linux kernel interface used for inter-process communication (IPC) between both the kernel and userspace processes, and between different userspace processes. Netfilter A framework provided by the Linux kernel that allows various networking-related operations Packet filtering, network address translation, and port translation(iptables/nftables) used to direct network packages to individual containers More inforamtion could refer to LXC/LXD Let's download an image alpine to simulate an root file system under /opt/test folder. james@lizard:/opt> mkdir test james@lizard:/opt> cd test james@lizard:/opt/test> wget https://dl-cdn.alpinelinux.org/alpine/v3.13/releases/x86_64/alpine-minirootfs-3.13.4-x86_64.tar.gz james@lizard:/opt/test> tar zxvf alpine-minirootfs-3.13.4-x86_64.tar.gz -C alpine-minirootfs/ james@lizard:/opt> tree ./test -L 1 ./test \u251c\u2500\u2500 alpine-minirootfs-3.13.4-x86_64.tar.gz \u251c\u2500\u2500 bin \u251c\u2500\u2500 dev \u251c\u2500\u2500 etc \u251c\u2500\u2500 home \u251c\u2500\u2500 lib \u251c\u2500\u2500 media \u251c\u2500\u2500 mnt \u251c\u2500\u2500 opt \u251c\u2500\u2500 proc \u251c\u2500\u2500 root \u251c\u2500\u2500 run \u251c\u2500\u2500 sbin \u251c\u2500\u2500 srv \u251c\u2500\u2500 sys \u251c\u2500\u2500 tmp \u251c\u2500\u2500 usr \u2514\u2500\u2500 var Mount folder /opt/test/proc to a file and use command unshare to build a guest system. james@lizard:/opt> sudo mount -t tmpfs tmpfs /opt/test/proc james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # ps -ef PID USER TIME COMMAND 1 root 0:00 /bin/sh 2 root 0:00 ps -ef / # touch 123 / # ls 123 123 The file 123 created in guest system is accessable and writable from host system. james@lizard:/opt> su - lizard:/opt/test # ls 123 123 lizard:/opt/test # echo hello > 123 We will see above change in guest system. / # cat 123 hello Let's create two folders /opt/test-1 and /opt/test-2 . james@lizard:/opt> mkdir test-1 james@lizard:/opt> mkdir test-2 Create two guests system. Mount /opt/test/home/ to different folders for different guests. james@lizard:/opt> sudo mount --bind /opt/test-1 /opt/test/home/ james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # cd /home /home # echo \"test-1\" > 123.1 /home # cat 123.1 test-1 james@lizard:/opt> sudo mount --bind /opt/test-2 /opt/test/home/ james@lizard:/opt> sudo unshare --pid --mount-proc=$PWD/test/proc --fork chroot ./test/ /bin/sh / # cd /home /home # echo \"test-2\" > 123.2 /home # cat 123.2 test-2 james@lizard:/opt> ll test/home -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 james@lizard:/opt> ll test-1/ -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 james@lizard:/opt> ll test-2/ -rw-r--r-- 1 root root 7 May 31 22:47 123.1 -rw-r--r-- 1 root root 7 May 31 22:47 123.2 With above demo, the conclusion is that two guests share same home folder on host system and will impact each other.","title":"Linux Primitives"},{"location":"cloud/KubernetesFoundationMemo/#installing-docker","text":"Install Docker engine by referring the guide , and Docker Desktop by referring the guide . Install engine via openSUSE repository automatically. james@lizard:/opt> sudo zypper in docker The docker group is automatically created at package installation time. The user can communicate with the local Docker daemon upon its next login. The Docker daemon listens on a local socket which is accessible only by the root user and by the members of the docker group. Add current user to docker group. james@lizard:/opt> sudo usermod -aG docker $USER Enable and start Docker engine. james@lizard:/opt> sudo systemctl enable docker.service Created symlink /etc/systemd/system/multi-user.target.wants/docker.service \u2192 /usr/lib/systemd/system/docker.service. james@lizard:/opt> sudo systemctl start docker.service james@lizard:/opt> sudo systemctl status docker.service \u25cf docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2022-05-28 14:36:45 CST; 6s ago Docs: http://docs.docker.com Main PID: 31565 (dockerd) Tasks: 20 CGroup: /system.slice/docker.service \u251c\u250031565 /usr/bin/dockerd --add-runtime oci=/usr/sbin/docker-runc \u2514\u250031574 containerd --config /var/run/docker/containerd/containerd.toml --log-level warn May 28 14:36:44 lizard systemd[1]: Starting Docker Application Container Engine... May 28 14:36:44 lizard dockerd[31565]: time=\"2022-05-28T14:36:44+08:00\" level=info msg=\"SUSE:secrets :: enabled\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44+08:00\" level=warning msg=\"deprecated version : `1`, please switch to version `2`\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.659346964+08:00\" level=warning msg=\"failed to load plugin io.containerd.snapshotter.v1.devmapper\" error=\"devmapper no> May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.660040930+08:00\" level=warning msg=\"could not use snapshotter devmapper in metadata plugin\" error=\"devmapper not conf> May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018458102+08:00\" level=warning msg=\"Your kernel does not support swap memory limit\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018495482+08:00\" level=warning msg=\"Your kernel does not support CPU realtime scheduler\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018502682+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018506223+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight_device\" May 28 14:36:45 lizard systemd[1]: Started Docker Application Container Engine.","title":"Installing Docker"},{"location":"cloud/KubernetesFoundationMemo/#container-lifecycle","text":"","title":"Container lifecycle"},{"location":"cloud/KubernetesFoundationMemo/#overview","text":"Pull down below images in advance. james@lizard:~> docker image pull busybox james@lizard:~> docker image pull nginx james@lizard:~> docker image pull alpine james@lizard:~> docker image pull jenkins/jenkins:lts james@lizard:~> docker image pull golang:1.12-alpine james@lizard:~> docker image pull golang Download some docker images. Create and run a new busybox container interactively and connect a pseudo terminal to it. Inside the container, use the top command to find out that /bin/sh is running as process with the PID 1 and top process is also running. After that, just exit. james@lizard:~> docker image ls (or docker images) REPOSITORY TAG IMAGE ID CREATED SIZE golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB james@lizard:~> docker run -d -it --name busybox_v1 -v /opt/test:/docker busybox:latest /bin/sh james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 185efe490507 busybox:latest \"/bin/sh\" 11 seconds ago Up 9 seconds busybox_v1 james@lizard:~> docker exec -it 185efe490507 /bin/sh / # top Mem: 3627396K used, 12731512K free, 10080K shrd, 2920K buff, 2999340K cached CPU: 0.0% usr 0.1% sys 0.0% nic 99.8% idle 0.0% io 0.0% irq 0.0% sirq Load average: 0.38 1.09 1.29 2/277 14 PID PPID USER STAT VSZ %VSZ CPU %CPU COMMAND 1 0 root S 1332 0.0 1 0.0 /bin/sh 8 0 root S 1332 0.0 2 0.0 /bin/sh 14 8 root R 1328 0.0 1 0.0 top / # exitbuild Start a new nginx container in detached mode. Use the docker exec command to start another shell ( /bin/sh ) in the nginx container. Use ps to find out that sh and ps commands are running in your container. james@lizard:~> docker run -d -it --name nginx_v1 -v /opt/test:/docker nginx:latest /bin/sh james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 seconds ago Up 2 seconds 80/tcp nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 2 minutes ago Up 2 minutes busybox_v1 james@lizard:~> docker exec -it edb640127a0d /bin/sh # ps /bin/sh: 2: ps: not found # apt-get update && apt-get install -y procps # ps PID TTY TIME CMD 8 pts/1 00:00:00 sh 351 pts/1 00:00:00 ps # exit Now we have two running containers below. james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 7 minutes ago Up 7 minutes 80/tcp nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 10 minutes Let's make use of this to create a new stage:ago Up 10 minutes busybox_v1 Let's use docker logs to display the logs of the container we just exited from. The option --since 35m means display log in last 35 minutes. james@lizard:~> docker logs nginx_v1 --details --since 35m james@lizard:~> docker logs busybox_v1 --details --since 35m Let's make use of this to create a new stage: Use the docker stop command to end your nginx container. james@lizard:~> docker stop busybox_v1 busybox_v1 james@lizard:~> docker stop nginx_v1 nginx_v1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 10 minutes ago Exited (137) 4 seconds ago nginx_v1 185efe490507 busybox:latest \"/bin/sh\" 13 minutes ago Exited (137) 16 seconds ago busybox_v1 With above command docker container ps -a , we get a list of all running and exited containers. Remove them with docker rm. Use docker rm $(docker ps -aq) to clean up all containers on your host. Use it with caution! james@lizard:~> docker rm busybox_v1 busybox_v1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 11 minutes ago Exited (137) 53 seconds ago nginx_v1","title":"Overview"},{"location":"cloud/KubernetesFoundationMemo/#ports-and-volumes","text":"Now, let's run an nginx webserver in a container and serve a website to the outside world. Start a new nginx container and export the port of the nginx webserver to a random port that is chosen by Docker. Use command docker ps to find you which port the webserver is forwarded. Access the docker with the forwarded port number on host http://localhost:<port#> . james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 11 minutes ago Exited (137) 53 seconds ago nginx_v1 james@lizard:~> docker run -d -P --name nginx_v2 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 15 seconds ago Up 14 seconds 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 13 minutes ago Exited (137) 3 minutes ago nginx_v1 Start another nginx container and expose port to 1080 on host as an example via http://localhost:1080 . james@lizard:~> docker run -d -p 1080:80 --name nginx_v3 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up 28 seconds 0.0.0.0:1080->80/tcp, :::1080->80/tcp nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up About a minute 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up 3 seconds 80/tcp nginx_v1 Let's make use of this to create a new stage: Use command docker inspect to find out which port is exposed by the image. Network information (ip, gateway, ports, etc.) is part of the output JSON format. james@lizard:~> docker inspect nginx_v3 Create a file index.html in folder /opt/test with below sample content. <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> Start a new container that bind-mounts host directory /opt/test to container directory /usr/share/nginx/html as a volume, so that NGINX will publish the HTML file wee just created instead of its default message via http://localhost:49159/ below. james@lizard:~> docker run -d -P --mount type=bind,source=/opt/test/,target=/usr/share/nginx/html --name nginx_v3-1 nginx:latest james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bd94e4df65cf nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up About a minute 0.0.0.0:49159->80/tcp, :::49154->80/tcp nginx_v3-1 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 30 seconds ago Up 28 seconds 0.0.0.0:1080->80/tcp, :::1080->80/tcp nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up About a minute 0.0.0.0:49153->80/tcp, :::49153->80/tcp nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 3 hours ago Up 3 seconds 80/tcp nginx_v1 Check nginx config file on where is the html home page stored in container. james@lizard:~> docker exec -it nginx_v3-1 /bin/sh # cd /etc/nginx/conf.d # ls default.conf # cat default.conf server { listen 80; listen [::]:80; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; <-- index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } # cd /usr/share/nginx/html # cat index.html <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> # It's recommendable to add a persistence with volumes API, instead of storing data in a docker container. Docker supports 2 ways of mount: Bind mounts: mount a local host directory onto a certain path in the container. Everything that was present before in the target directory is hidden (nature of the bind mount). For example, if you have some configuration you want to inject, write your config file, store it on your docker host at /home/container/config and mount the content of this directory to /usr/application/config (assuming the application reads config from there). Command: docker run --mount type=bind,source=<source path>,target=<container path> \u2026 Named volumes: docker can create a separated storage volume. Its lifecycle is independent from the container but still managed by docker. Upon creation, the content of the mount target is merged into the volume. Command: docker run --mount source=<vol name>,target=<container path> \u2026 How to differentiate between bind mountbuild s and named volumes? When specifying an absolute path, docker assumes a bind mount. When you just give a name (like in a relative path \u201cconfig\u201d), it will assume a named volume and create a volume \u201cconfig\u201d. Note: Persistent storage is 'provided' by the host. It can be a part of the file system on the host directly but also an NFS mount.","title":"Ports and volumes"},{"location":"cloud/KubernetesFoundationMemo/#dockerfile","text":"Let's build an image with a Dockerfile,build tag it and upload it to a registry. Get docker image build history. james@lizard:~> docker image history nginx:latest IMAGE CREATED CREATED BY SIZE COMMENT c316d5a335a5 6 days ago /bin/sh -c #(nop) CMD [\"nginx\" \"-g\" \"daemon\u2026 0B <missing> 6 days ago /bin/sh -c #(nop) STOPSIGNAL SIGQUIT 0B <missing> 6 days ago /bin/sh -c #(nop) EXPOSE 80 0B <missing> 6 days ago /bin/sh -c #(nop) ENTRYPOINT [\"/docker-entr\u2026 0B <missing> 6 days ago /bin/sh -c #(nop) COPY file:09a214a3e07c919a\u2026 4.61kB <missing> 6 days ago /bin/sh -c build #(nop) COPY file:0fd5fca330dcd6a7\u2026 1.04kB <missing> 6 days ago /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0\u2026 1.96kB <missing> 6 days ago /bin/sh -c #(nop) COPY file:65504f71f5855ca0\u2026 1.2kB <missing> 6 days ago /bin/sh -c set -x && addgroup --system -\u2026 61.1MB <missing> 6 days ago /bin/sh -c #(nop) ENV PKG_RELEASE=1~bullseye 0B <missing> 6 days ago /bin/sh -c #(nop) ENV NJS_VERSION=0.7.2 0B <missing> 6 days ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.21.6 0B <missing> 6 days ago /bin/sh -c #(nop) LABEL maintainer=NGINX Do\u2026 0B <missing> 7 days ago /bin/sh -c #(nop) CMD [\"bash\"] 0B <missing> 7 days ago /bin/sh -c #(nop) ADD file:90495c24c897ec479\u2026 80.4MB Create an empty directory /opt/tmp-1 , change to the directory and create an sample index.html file in /opt/tmp-1 . james@lizard:/opt/tmp-1> cat index.html <html> <head> <title>Sample Website from my container</title> </head> <body> <h1>This is a custom website.</h1> <p>This website is served from my <a href=\"http://www.docker.com\" target=\"_blank\">Docker</a> container.</p> </body> </html> Use FROM to extend an existing image, specify the release number. Use COPY to copy a new default website into the image, e.g., /usr/share/nginx/html Create SSL configuration /opt/tmp-1/ssl.conf for nginx. server { listen 443 ssl; server_name localhost; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; location / { root /usr/share/nginx/html; index index.html index.htm; } } Use OpenSSL to create a self-signed certificate so SSL/TLS to work would work. Use the following command to create an encryption key and a certificate. james@lizard:/opt/tmp-1> openssl req -x509 -nodes -newkey rsa:4096 -keyout nginx.key -out nginx.crt -days 365 -subj \"/CN=$(hostname)\" Generating a RSA private key ........++++ ................................++++ writing new private key to 'nginx.key' ----- To enable encrypted HTTPS, we need to expose port 443 with the EXPOSE directive. The default nginx image only exposes port 80 for unencrypted HTTP. In summary, we create below Dockerfile in foder /opt/tmp-1 . james@lizard:/opt/tmp-1> cat Dockerfile FROM nginx:latest # copy the custom website into the image COPY index.html /usr/share/nginx/html # copy the SSL configuration file into the image COPY ssl.conf /etc/nginx/conf.d/ssl.conf # download the SSL key and certificate into the image COPY nginx.key /etc/nginx/ssl/ COPY nginx.crt /etc/nginx/ssl/ # expose the HTTPS port EXPOSE 443 We have five files in foder /opt/tmp-1 till now. james@lizard:/opt/tmp-1> ls Dockerfile index.html nginx.crt nginx.key ssl.conf Now let's use the docker build command to build the image, forward the containers ports 80 and 443. james@lizard:~> docker build -t nginx:my1 /opt/tmp-1/ Sending build context to Docker daemon 62.98kB Let's make use of this to create a new stage: Step 1/6 : FROM nginx:latest ---> c316d5a335a5 Step 2/6 : COPY index.html /usr/share/nginx/html ---> 4a71ac8a2624 Step 3/6 : COPY ssl.conf /etc/nginx/conf.d/ssl.conf ---> ad574bc8080c Step 4/6 : COPY nginx.key /etc/nginx/ssl/ ---> 90c41ec98809 Step 5/6 : COPY nginx.crt /etc/nginx/ssl/ ---> 5801c1e5e02f Step 6/6 : EXPOSE 443 ---> Running in 0db1bffe7eb3 Removing intermediate container 0db1bffe7eb3 ---> 748439b24876 Successfully built 748439b24876 Successfully tagged nginx:my1 james@lizard:~> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx my1 748439b24876 44 seconds ago 142MB golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB james@lizard:~> docker run -d -p 1086:80 -p 1088:443 --name nginx_v5 nginx:my1 james@lizard:~> docker container ps -a CONTAINER ID IMAGE COMMAND build CREATED STATUS PORTS NAMES 70126d22e48b nginx:my1 \"/docker-entrypoint.\u2026\" 7 seconds ago Up 6 seconds 0.0.0.0:1086->80/tcp, :::1086->80/tcp, 0.0.0.0:1088->443/tcp, :::1088->443/tcp nginx_v5 7714058076c0 nginx:latest \"/docker-entrypoint.\u2026\" About an hour ago Exited (0) 48 seconds ago nginx_v4 214ded9b8645 nginx:latest \"/docker-entrypoint.\u2026\" 2 hours ago Exited (0) About an hour ago nginx_v3 3349a84e5024 nginx:latest \"/docker-entrypoint.\u2026\" 5 hours ago Exited (0) About an hour ago nginx_v2 edb640127a0d nginx:latest \"/docker-entrypoint.\u2026\" 5 hours ago Exited (137) About an hour ago nginx_v1 Above changes can be validated via below links: http://localhost:1086/ https://localhost:1088/ Register an account in DockerHub and enable access token in Docker Hub for CLI client authentication. james@lizard:~> docker login Username: <your account id> Password: <token> Tag the image to give image a nice name and a release number as tag, e.g., name is secure_nginx_0001 , tag is v1 . james@lizard:~> docker tag nginx:my1 <your account id>secure_nginx_0001:v1 james@lizard:~> docker push <your account id>secure_nginx_0001:v1 james@lizard:~> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE nginx my1 748439b24876 7 minutes ago 142MB <your account id>secure_nginx_0001 v1 748439b24876 7 minutes ago 142MB golang latest 80d9a75ccb38 5 days ago 941MB nginx latest c316d5a335a5 6 days ago 141MB jenkins/jenkins lts 9aee0d53624f 2 weeks ago 441MB busybox latest beae173ccac6 4 weeks ago 1.24MB alpine latest c059bfaa849c 2 months ago 5.58MB golang 1.12-alpine 76bddfb5e55e 23 months ago 346MB","title":"Dockerfile"},{"location":"cloud/KubernetesFoundationMemo/#multi-stage-dockerfile","text":"Let's show an example of multi-stage build. The multi-stage in the context of Docker means, we can have more than one line with a FROM keyword. Create folder /opt/tmp-2 and /opt/tmp-2/tmpl . Create files edit.html , view.html , wiki.go and structure likes below. james@lizard:/opt/tmp-2> tree -l . \u251c\u2500\u2500 tmpl \u2502 \u251c\u2500\u2500 edit.html \u2502 \u2514\u2500\u2500 view.html \u2514\u2500\u2500 wiki.go Create an new Dockerfile that starts james@lizard:/opt/tmp-2> cat Dockerfile # app builder stage FROM golang:1.12-alpine as builder ## copy the go source code over and build the binary WORKDIR /go/src COPY wiki.go /go/src/wiki.go RUN go build wiki.go # app exec stage # separate & new image starts here!# FROM alpine:3.9 # prepare file system etc RUN mkdir -p /app/data /app/tmpl && adduser -S -D -H -h /app appuser COPY tmpl/* /app/tmpl/ # get the compiled binary from the previous stage COPY --from=builder /go/src/wiki /app/wiki # prepare runtime env RUN chown -R appuser /app USER appuser WORKDIR /app # expose app port & set default command EXPOSE 8080 CMD [\"/app/wiki\"] Build the images by Dockerfile we created above. james@lizard:~> docker build -t lizard/golang:my1 /opt/tmp-2/ Sending build context to Docker daemon 9.728kB Step 1/13 : FROM golang:1.12-alpine as builder ---> 76bddfb5e55e Step 2/13 : WORKDIR /go/src ---> Running in 279957765a67 Removing intermediate container 279957765a67 ---> d74f3297387b Step 3/13 : COPY wiki.go /go/src/wiki.go ---> f14f358f10c0 Step 4/13 : RUN go build wiki.go ---> Running in af4a9d2d1dcc Removing intermediate container af4a9d2d1dcc ---> 101e734099a3 Step 5/13 : FROM alpine:3.9 3.9: Pulling from library/alpine 31603596830f: Pull complete Digest: sha256:414e0518bb9228d35e4cd5165567fb91d26c6a214e9c95899e1e056fcd349011 Status: Downloaded newer image for alpine:3.9 ---> 78a2ce922f86 Step 6/13 : RUN mkdir -p /app/data /app/tmpl && adduser -S -D -H -h /app appuser ---> Running in c7a8793fc95d Removing intermediate container c7a8793fc95d ---> a6e83922a81f Step 7/13 : COPY tmpl/* /app/tmpl/ ---> e48d44caf735 Step 8/13 : COPY --from=builder /go/src/wiki /app/wiki ---> 26cc829fe32b Step 9/13 : RUN chown -R appuser /app ---> Running in 22f3af57f969 Removing intermediate container 22f3af57f969 ---> ea7d678adf67 Step 10/13 : USER appuser ---> Running in 03c5d8e9ad45 Removing intermediate container 03c5d8e9ad45 ---> 40a692198491 Step 11/13 : WORKDIR /app ---> Running in 7c1b04e38306 Removing intermediate container 7c1b04e38306 ---> 45eaaebb0c12 Step 12/13 : EXPOSE 8080 ---> Running in 84f06d2e5f90 Removing intermediate container 84f06d2e5f90 ---> 3750bfa8c032 Step 13/13 : CMD [\"/app/wiki\"] ---> Running in 9ce20ca3a834 Removing intermediate container 9ce20ca3a834 ---> 8621174bab0d Successfully built 8621174bab0d Successfully tagged lizard/golang:my1 Run the image in detached mode, create a port forwarding from port 8080 in the container to port 1090 on the host. james@lizard:~> docker run -d -p 1090:8080 --name golan_v1 lizard/golang:my1 Access the container via link http://localhost:1090 Tab the golang image we created and push it to DockerHub. james@lizard:~> docker tag lizard/golang:my1 <your acccount id>/golang_0001:v1 james@lizard:~> docker push <your acccount id>/golang_0001:v1","title":"Multi-stage Dockerfile"},{"location":"cloud/KubernetesFoundationMemo/#2basic-concepts-of-kubernetes","text":"","title":"2.Basic Concepts of Kubernetes"},{"location":"cloud/KubernetesFoundationMemo/#kubernetes-components","text":"A Kubernetes cluster consists of the components that represent the control plane and a set of machines called nodes . Kubernetes Components : Control Plane Components kube-apiserver: query and manipulate the state of objects in Kubernetes. play as \"communication hub\" among all resources in cluster. provide cluster security authentication, authorization, and role assignment. the only one can connect to etcd . etcd: all Kubernetes objects are stored on etcd. Kubernetes objects are persistent entities in the Kubernetes system, which are used to represent the state of your cluster. kube-scheduler: watches for newly created Pods with no assigned node, and selects a node for them to run on. kube-controller-manager: runs controller processes. Node controller : Responsible for noticing and responding when nodes go down. Job controller : Watches for Job objects that represent one-off tasks, then creates Pods to run those tasks to completion. Endpoints controller : Populates the Endpoints object (that is, joins Services & Pods). Service Account & Token controllers : Create default accounts and API access tokens for new namespaces. cloud-controller-manager: embeds cloud-specific control logic and only runs controllers that are specific to your cloud provider, no need for own premises and learning environment. Node controller : For checking the cloud provider to determine if a node has been deleted in the cloud after it stops responding Route controller : For setting up routes in the underlying cloud infrastructure Service controller : For creating, updating and deleting cloud provider load balancers Node Components kubelet: An agent that runs on each node in the cluster. Manage node. It makes sure that containers are running in a Pod. kubelet registers and updates nodes information to APIServer, and APIServer stores them into etcd . Manage pod. Watch pod via APIServer, and action on pods or containers in pods. Health check at container level. kube-proxy: is a network proxy that runs on each node in cluster. iptables ipvs maintains network rules on nodes. Container runtime: is the software that is responsible for running containers. Addons DNS: is a DNS server and required by all Kubernetes clusters. Web UI (Dashboard): web-based UI for Kubernetes clusters. Container Resource Monitoring: records generic time-series metrics about containers in a central database Cluster-level Logging: is responsible for saving container logs to a central log store with search/browsing interface. Scalability: Scaling out (horizontal scaling) by adding more servers to your architecture to spread the workload across more machines. Scaling up (vertical scaling) by adding more hard drives and memory to increase the computing capacity of physical servers.","title":"Kubernetes Components"},{"location":"cloud/KubernetesFoundationMemo/#kubernetes-api","text":"The core of Kubernetes' control plane is the API server. CRI: Container Runtime Interface CNI: Container Network Interface CSI: Container Storage Interface The API server exposes an HTTP API that lets end users, different parts of cluster, and external components communicate with one another. The Kubernetes API lets we query and manipulate the state of API objects in Kubernetes (for example: Pods, Namespaces, ConfigMaps, and Events). Kubernetes API: OpenAPI specification OpenAPI V2 OpenAPI V3 Persistence. Kubernetes stores the serialized state of objects by writing them into etcd. API groups and versioning. Versioning is done at the API level. API resources are distinguished by their API group, resource type, namespace (for namespaced resources), and name. API changes API Extension","title":"Kubernetes API"},{"location":"cloud/KubernetesFoundationMemo/#kubernetes-objects","text":"","title":"Kubernetes Objects"},{"location":"cloud/KubernetesFoundationMemo/#objects-overview","text":"Object Spec: providing a description of the characteristics the resource created to have: its desired state . Object Status: describes the current state of the object. Example of Deployment as an object that can represent an application running on cluster. apiVersion: apps/v1 # Which version of the Kubernetes API you're using to create this object kind: Deployment # What kind of object you want to create metadata: # Data that helps uniquely identify the object, including a name string, UID, and optional namespace name: nginx-deployment spec: # What state you desire for the object selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80","title":"Objects Overview:"},{"location":"cloud/KubernetesFoundationMemo/#object-management","text":"The kubectl command-line tool supports several different ways to create and manage Kubernetes objects. Read the Kubectl book for details. A Kubernetes object should be managed using ONLY one technique. Mixing and matching techniques for the same object results in undefined behavior. Three management techniques: Imperative commands operates directly on live objects in a cluster. kubectl create deployment nginx --image nginx Imperative object configuration kubectl create -f nginx.yaml kubectl delete -f nginx.yaml -f redis.yaml kubectl replace -f nginx.yaml Declarative object configuration kubectl diff -f configs/ kubectl apply -f configs/","title":"Object Management:"},{"location":"cloud/KubernetesFoundationMemo/#object-names-and-ids","text":"Each object in your cluster has a Name that is unique for that type of resource. DNS Subdomain Names Label Names Path Segment Names Every Kubernetes object also has a UID that is unique across the whole cluster.","title":"Object Names and IDs"},{"location":"cloud/KubernetesFoundationMemo/#namespaces","text":"In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces. Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc) Not All Objects are in a Namespace. Kubernetes starts with four initial namespaces: default The default namespace for objects with no other namespace kube-system The namespace for objects created by the Kubernetes system kube-public This namespace is created automatically and is readable by all users (including those not authenticated). This namespace is mostly reserved for cluster usage, in case that some resources should be visible and readable publicly throughout the whole cluster. The public aspect of this namespace is only a convention, not a requirement. kube-node-lease This namespace holds Lease objects associated with each node. Node leases allow the kubelet to send heartbeats so that the control plane can detect node failure. Viewing namespaces: kubectl get namespace Setting the namespace for a request kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here> kubectl get pods --namespace=<insert-namespace-name-here>","title":"Namespaces"},{"location":"cloud/KubernetesFoundationMemo/#labels-and-selectors","text":"Labels are key/value pairs that are attached to objects, such as pods. Valid label keys have two segments: an optional prefix and name, separated by a slash ( / ). Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object. Example of labels: \"metadata\": { \"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } Unlike names and UIDs, labels do not provide uniqueness. In general, we expect many objects to carry the same label(s). The API currently supports two types of selectors: equality-based, e.g., environment = production , tier != frontend set-based, e.g., environment in (production, qa) , tier notin (frontend, backend) Sample commands: kubectl get pods -l environment=production,tier=frontend kubectl get pods -l 'environment in (production),tier in (frontend)' kubectl get pods -l 'environment in (production, qa)' kubectl get pods -l 'environment,environment notin (frontend)'","title":"Labels and Selectors"},{"location":"cloud/KubernetesFoundationMemo/#annotations","text":"Use Kubernetes annotations to attach arbitrary non-identifying metadata to objects. Clients such as tools and libraries can retrieve this metadata. Use either labels or annotations to attach metadata to Kubernetes objects. Labels can be used to select objects and to find collections of objects that satisfy certain conditions. Annotations are not used to identify and select objects. Annotations, like labels, are key/value maps. The keys and the values in the map must be strings. \"metadata\": { \"annotations\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } } Valid annotation keys have two segments: an optional prefix and name, separated by a slash ( / ).","title":"Annotations"},{"location":"cloud/KubernetesFoundationMemo/#field-selectors","text":"Field selectors let you select Kubernetes resources based on the value of one or more resource fields. Here are some examples of field selector queries: metadata.name=my-service metadata.namespace!=default status.phase=Pending This kubectl command selects all Pods for which the value of the status.phase field is Running: kubectl get pods --field-selector status.phase=Running Supported field selectors vary by Kubernetes resource type. All resource types support the metadata.name and metadata.namespace fields. Use the = , == , and != operators with field selectors ( = and == mean the same thing). For example: kubectl get ingress --field-selector foo.bar=baz With operators, kubectl get services --all-namespaces --field-selector metadata.namespace!=default Chained selectors, kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always Multiple resource types, kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default","title":"Field Selectors"},{"location":"cloud/KubernetesFoundationMemo/#finalizers","text":"Finalizers are namespaced keys that tell Kubernetes to wait until specific conditions are met before it fully deletes resources marked for deletion . Finalizers alert controllers to clean up resources the deleted object owned. Finalizers are usually added to resources for a reason, so forcefully removing them can lead to issues in the cluster. Like labels, owner references describe the relationships between objects in Kubernetes, but are used for a different purpose. Kubernetes uses the owner references (not labels) to determine which Pods in the cluster need cleanup. Kubernetes processes finalizers when it identifies owner references on a resource targeted for deletion.","title":"Finalizers"},{"location":"cloud/KubernetesFoundationMemo/#owners-and-dependents","text":"In Kubernetes, some objects are owners of other objects. For example, a ReplicaSet is the owner of a set of Pods. These owned objects are dependents of their owner. Dependent objects have a metadata.ownerReferences field that references their owner object. A valid owner reference consists of the object name and a UID within the same namespace as the dependent object. Dependent objects also have an ownerReferences.blockOwnerDeletion field that takes a boolean value and controls whether specific dependents can block garbage collection from deleting their owner object.","title":"Owners and Dependents"},{"location":"cloud/KubernetesFoundationMemo/#4tutorials","text":"Tutorials: local deployment Tutorials: Kyma@SAP BTP Tutorials: Ubuntu@Aliyun Tutorials: openSUSE@Aliyun","title":"4.Tutorials"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/","text":"Kubernetes Tutourials: Ubuntu@Aliyun Deployment Preparation Register Aliyun account via Alibaba Cloud home console . Request three Elastic Computer Service(ECS) instances with below sizing: System: 2vCPU+4GiB OS: Ubuntu 20.04 x86_64 Instance Type: ecs.sn1.medium Instance Name: cka001, cka002, cka003 Network: both public IPs and private IPs Maximum Bandwidth: 100Mbps (Peak Value) Cloud disk: 40GiB Billing Method: Preemptible instance (spot price) Generate SSH key pairs with name cka-key-pair in local directcory /opt . Change access control to 400 per security required by command sudo chmod 400 cka-key-pair.pem . cka003 Access remote cka servers via command ssh -i cka-key-pair.pem root@<your public ip address> Initialize VMs Configure /etc/hosts file Add private IPs in the /etc/hosts file in all VMs. Disable firewall Disable firewall by command ufw disable in all VMs. Turn off swap Turn off swap by command swapoff -a in all VMs. Set timezone and locale Set timezone and local for all VMs. For ECS with Ubuntu 20.04 version created by Aliyun, this step is not needed. # ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # sudo echo 'LANG=\"en_US.UTF-8\"' >> /etc/profile # source /etc/profile Something like this: root@cka001:~# ll /etc/localtime lrwxrwxrwx 1 root root 33 May 24 18:14 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai Kernel setting Perform below kernel setting in all VMs. Create file /etc/modules-load.d/containerd.conf to set up containerd configure file. It's to load two modules overlay and br_netfilter . Service containerd depends on overlay filesystem. Sometimes referred to as union-filesystems. An overlay-filesystem tries to present a filesystem which is the result over overlaying one filesystem on top of the other. The br_netfilter module is required to enable transparent masquerading and to facilitate Virtual Extensible LAN (VxLAN) traffic for communication between Kubernetes pods across the cluster. # cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF Load overlay and br_netfilter modules. # sudo modprobe overlay # sudo modprobe br_netfilter Create file 99-kubernetes-cri.conf to set up configure file for Kubernetes CRI. Set net/bridge/bridge-nf-call-iptables=1 to ensure simple configurations (like Docker with a bridge) work correctly with the iptables proxy. Why net/bridge/bridge-nf-call-iptables=1 need to be enable by Kubernetes . IP forwarding is also known as routing. When it comes to Linux, it may also be called Kernel IP forwarding because it uses the kernel variable net.ipv4.ip_forward to enable or disable the IP forwarding feature. The default preset value is ip_forward=0 . Hence, the Linux IP forwarding feature is disabled by default. # cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF The sysctl command reads the information from the /proc/sys directory. /proc/sys is a virtual directory that contains file objects that can be used to view and set the current kernel parameters. By commadn sysctl -w net.ipv4.ip_forward=1 , the change takes effect immediately, but it is not persistent. After a system reboot, the default value is loaded. Write the settings to /etc/sysctl.conf is to set a parameter permanently, you\u2019ll need to or another configuration file in the /etc/sysctl.d directory: sudo sysctl --system Install Containerd Install Containerd sevice fro all VMs. Backup source file. # sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak Add proper repo sources. For ECS with Ubuntu 20.04 version created by Aliyun, this step is not needed. cat > /etc/apt/sources.list << EOF deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal universe deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates universe deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal multiverse deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates multiverse deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-backports main restricted universe multivers deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security universe # deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security multiverse # deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security multiverse EOF Install Containered. # sudo apt-get update && sudo apt-get install -y containerd Configure Containerd. Modify file /etc/containerd/config.toml . # sudo mkdir -p /etc/containerd # containerd config default | sudo tee /etc/containerd/config.toml # vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd Install nerdctl Install nerdctl sevice fro all VMs. The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # cp nerdctl /usr/bin/ Verify nerdctl. # nerdctl --help To list local Kubernetes containers. # nerdctl -n k8s.io ps Install kubeadm Update apt-transport-https , ca-certificates , and curl . # apt-get update && sudo apt-get install -y apt-transport-https ca-certificates curl Install gpg certificate. # curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - Add Kubernetes repo. # cat <<EOF >/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF Update and install dependencied packages. # apt-get update # apt-get install ebtables # apt-get install libxtables12=1.8.4-3ubuntu2 # apt-get upgrade iptables Check available versions of kubeadm. # apt policy kubeadm Install 1.23.8-00 version of kubeadm and will upgrade to 1.24.2 later. # sudo apt-get -y install kubelet=1.23.8-00 kubeadm=1.23.8-00 kubectl=1.23.8-00 --allow-downgrades Setup Master Node Set up Control Plane on VM playing master node. Check kubeadm default parameters for initialization. # kubeadm config print init-defaults Dry rune and run. Save the output, which will be used later on work nodes. Be noted that 10.244.0.0/16 is default range of flannel. If it's changed here, please do change the same when deploy flannel. # kubeadm init --dry-run --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 # kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 Set kubeconfig file for current user (here it's root ). # mkdir -p $HOME/.kube # sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # sudo chown $(id -u):$(id -g) $HOME/.kube/config Set kubectl auto-completion. # apt install -y bash-completion # source /usr/share/bash-completion/bash_completion # source <(kubectl completion bash) # echo \"source <(kubectl completion bash)\" >> ~/.bashrc Setup Work Nodes Perform on all VMs playing work nodes. # kubeadm join <your master node ip>:6443 --token <token generated by kubeadm init> --discovery-token-ca-cert-hash <hash key generated by kubeadm init> Verify status on master node. root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION cka001 Ready control-plane,master 24m v1.23.8 cka002 Ready <none> 9m39s v1.23.8 cka003 Ready <none> 9m27s v1.23.8 Install Flannel Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes. Deploy Flannel on master node. In the kube-flannel.yml we can get the default network setting of Flannel, which is same with --pod-network-cidr=10.244.0.0/16 we defined before when we initiated kubeadm . net-conf.json: | { \"Network\": \"10.244.0.0/16\", \"Backend\": { \"Type\": \"vxlan\" } } root@cka001:~# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created Check Cluster Status Perform kubectl cluster-info command on master node we will get below information. Kubernetes control plane is running at https:// :6443 CoreDNS is running at https:// :6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy # kubectl cluster-info # kubectl get nodes -owide # kubectl get pod -A Reset cluster CAUTION: below steps will destroy current cluster. Delete all nodes in the cluster. # kubeadm reset Clean up rule of iptables . # iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X Clean up rule of IPVS if using IPVS . # ipvsadm --clear Snapshot of deployment Till now, the initial deployment is completed sucessfully. Container Layer We are using Containerd service to manage our images and containers via command nerdctl . Get current namespaces. root@cka001:~# nerdctl namespace ls NAME CONTAINERS IMAGES VOLUMES LABELS k8s.io 18 27 0 Get containers under the namespace k8s.io by command nerdctl -n k8s.io ps . root@cka001:~# nerdctl -n k8s.io container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1eb9a51e0406 registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.8 \"kube-apiserver --ad\u2026\" 28 hours ago Up k8s://kube-system/kube-apiserver-cka001/kube-apiserver 1ebee10176c4 registry.aliyuncs.com/google_containers/kube-proxy:v1.23.8 \"/usr/local/bin/kube\u2026\" 28 hours ago Up k8s://kube-system/kube-proxy-v7rsr/kube-proxy 2c5e1d183fc7 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-apiserver-cka001 2dd9743cecad registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/kube-flannel-ds-rf54c 39306eef76cd docker.io/rancher/mirrored-flannelcni-flannel:v0.18.1 \"/opt/bin/flanneld -\u2026\" 27 hours ago Up k8s://kube-system/kube-flannel-ds-rf54c/kube-flannel 3ca6fdda63a5 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-scheduler-cka001 49e07d9b2b98 registry.aliyuncs.com/google_containers/coredns:v1.8.6 \"/coredns -conf /etc\u2026\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-9khd8/coredns 555a3bf58832 registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.8 \"kube-scheduler --au\u2026\" 28 hours ago Up k8s://kube-system/kube-scheduler-cka001/kube-scheduler 5812c42bf572 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/etcd-cka001 8619e3c979a3 registry.aliyuncs.com/google_containers/coredns:v1.8.6 \"/coredns -conf /etc\u2026\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-qcp2l/coredns a9459900f462 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-9khd8 bb2b4624bfd5 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-qcp2l c9462709baff registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.8 \"kube-controller-man\u2026\" 28 hours ago Up k8s://kube-system/kube-controller-manager-cka001/kube-controller-manager e68c3fbc90f9 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-proxy-v7rsr eae550221813 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-controller-manager-cka001 ff6626664c43 registry.aliyuncs.com/google_containers/etcd:3.5.1-0 \"etcd --advertise-cl\u2026\" 28 hours ago Up k8s://kube-system/etcd-cka001/etcd Some management and commands options of nertctl . root@cka001:~# nertctl --help root@cka001:~# nerdctl image ls -a root@cka001:~# nerdctl volume ls root@cka001:~# nerdctl stats Get below network list with command nerdctl network ls in Containerd layer. root@cka001:~# nerdctl network ls NETWORK ID NAME FILE cbr0 /etc/cni/net.d/10-flannel.conflist 0 bridge /etc/cni/net.d/nerdctl-bridge.conflist host none Get network interface in host cka001 with command ip addr list . lo : inet 127.0.0.1/8 qlen 1000 eth0 : inet 172.16.18.161/24 brd 172.16.18.255 qlen 1000 flannel.1 : inet 10.244.0.0/32 cni0 : inet 10.244.0.1/24 brd 10.244.0.255 qlen 1000 vethb0a35696@if3 : noqueue master cni0 veth72791f64@if3 : noqueue master cni0 Kubernetes Layer Kubernetes is beyond container layer above. In Kubernetes layer, we have three nodes, cka001 , cka002 , and cka003 . root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION cka001 Ready control-plane,master 27h v1.23.8 cka002 Ready <none> 27h v1.23.8 cka003 Ready <none> 27h v1.23.8 We have four initial namespaces across three nodes. root@cka001:~# kubectl get namespace -A NAME STATUS AGE default Active 27h kube-node-lease Active 27h kube-public Active 27h kube-system Active 27h We have some initial pods. root@cka001:~# kubectl get pod -A -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-6d8c4cb4d-9khd8 1/1 Running 0 27h <cni0 IP> cka001 <none> <none> kube-system coredns-6d8c4cb4d-qcp2l 1/1 Running 0 27h <cni0 IP> cka001 <none> <none> kube-system etcd-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-apiserver-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-controller-manager-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-flannel-ds-hfvf7 1/1 Running 0 27h <eth0 IP> cka003 <none> <none> kube-system kube-flannel-ds-m5mdl 1/1 Running 0 27h <eth0 IP> cka002 <none> <none> kube-system kube-flannel-ds-rf54c 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-proxy-bj75j 1/1 Running 0 27h <eth0 IP> cka002 <none> <none> kube-system kube-proxy-gxjj4 1/1 Running 0 27h <eth0 IP> cka003 <none> <none> kube-system kube-proxy-v7rsr 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-scheduler-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> Summary below shows the relationship between containers and pods. Good references about container pause: article and artical . Master node: CoreDNS: 2 pods, 2 containers of each pod From image coredns:v1.8.6 : k8s://kube-system/coredns-6d8c4cb4d-9khd8/coredns k8s://kube-system/coredns-6d8c4cb4d-qcp2l/coredns By image pause:3.6 k8s://kube-system/coredns-6d8c4cb4d-9khd8 k8s://kube-system/coredns-6d8c4cb4d-qcp2l etcd: 1 pod, 2 containers By image etcd:3.5.1-0 k8s://kube-system/etcd-cka001/etcd By image pause:3.6 k8s://kube-system/etcd-cka001 apiserver: 1 pod, 2 containers By image kube-apiserver:v1.23.8 k8s://kube-system/kube-apiserver-cka001/kube-apiserver By image pause:3.6 k8s://kube-system/kube-apiserver-cka001 controller-manager: 1 pod, 2 containers By image kube-controller-manager:v1.23.8 k8s://kube-system/kube-controller-manager-cka001/kube-controller-manager By image pause:3.6 k8s://kube-system/kube-controller-manager-cka001 scheduler: 1 pod, 2 containers By image kube-scheduler:v1.23.8 k8s://kube-system/kube-scheduler-cka001/kube-scheduler By image pause:3.6 k8s://kube-system/kube-scheduler-cka001 All nodes: Flannel DS: 1 pod of each, 2 containers of each pod By image mirrored-flannelcni-flannel:v0.18.1 k8s://kube-system/kube-flannel-ds-rf54c/kube-flannel By image pause:3.6 k8s://kube-system/kube-flannel-ds-rf54c Proxy: 1 pod of each, 2 containers of each pod By image kube-proxy:v1.23.8 k8s://kube-system/kube-proxy-v7rsr/kube-proxy By image pause:3.6 k8s://kube-system/kube-proxy-v7rsr Let's check current configuration context of Kubernetes we just initialized. Contenxt name is kubernetes-admin@kubernetes . Cluster name is kubernetes . User is kubernetes-admin . No namespace explicitly defined. root@cka001:~# kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * kubernetes-admin@kubernetes kubernetes kubernetes-admin Create a new namespace jh-namespace . root@cka001:~# kubectl create namespace jh-namespace Update current context kubernetes-admin@kubernetes with new namespace jh-namespace as default namespace. root@cka001:~# kubectl config set-context kubernetes-admin@kubernetes --cluster=kubernetes --namespace=jh-namespace --user=kubernetes-admin Now default namespace is shown in current configuration context. root@cka001:~# kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * kubernetes-admin@kubernetes kubernetes kubernetes-admin jh-namespace Let's execute command kubectl apply -f 02-sample-pod.yaml to create a pod my-first-pod on namespace jh-namespace with below content of file 02-sample-pod.yaml . apiVersion: v1 kind: Pod metadata: name: my-first-pod spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 By command kubectl get pod -o wide we get the pod status. The pod's ip is allocated by cni0 . Node is assigned by Scheduler . We can also find related containers of pod my-first-pod via command nerdctl -n k8s.io container ls on cka003 . root@cka001:~# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-first-pod 1/1 Running 0 19s 10.244.2.2 cka003 <none> <none> Case Study Scenario: stop kubelet service on worker node cka003 . Question: What's the status of each node? What's containers changed via command nerdctl ? What's pods status via command kubectl get pod -owide -A ? Demo: Execute command systemctl stop kubelet.service on cka003 . Execute command kubectl get node on either cka001 or cka003 , the status of cka003 is NotReady . Execute command nerdctl -n k8s.io container ls on cka003 and we can observe all containers are still up and running, including the pod my-first-pod . Execute command systemctl start kubelet.service on cka003 . Conclusion: The node status is changed to NotReady from Ready . For those DaemonSet pods, like flannel \u3001 kube-proxy , are exclusively running on each node. They won't be terminated after kubelet is down. The status of pod my-first-pod keeps showing Terminating on each node because status can not be synced to other nodes via apiserver from cka003 because kubelet is down. The status of pod is marked by controller and recycled by kubelet . When we start kubelet service on cka003 , the pod my-first-pod will be termiated completely on cka003 . In addition, let's create a deployment with 3 replicas. Two are running on cka003 and one is running on cka002 . root@cka001:~# kubectl get pod -o wide -w NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deployment-9d745469b-2xdk4 1/1 Running 0 2m8s 10.244.2.3 cka003 <none> <none> nginx-deployment-9d745469b-4gvmr 1/1 Running 0 2m8s 10.244.2.4 cka003 <none> <none> nginx-deployment-9d745469b-5j927 1/1 Running 0 2m8s 10.244.1.3 cka002 <none> <none> After we stop kubelet service on cka003 , the two running on cka003 are terminated and another two are created and running on cka002 automatically. kubectl Three approach to operate Kubernetes cluster: via API via kubectl via Dashboard Example with kubectl : With Kubernetes 1.23 and lower version, when we create a new namespace, Kubernetes will automatically create a ServiceAccount default and a token default-token-xxxxx . We can say that the ServiceAccount default is an account under the namespace. Here is an example of new namespace jh-namespace I created. ServiceAcccount: default Token: default-token-8vrsc root@cka001:~# kubectl get sa -n jh-namespace NAME SECRETS AGE default 1 26h root@cka001:~# kubectl get secrets -n jh-namespace NAME TYPE DATA AGE default-token-8vrsc kubernetes.io/service-account-token 3 26h There is a cluster rule admin , and no related rolebinding. root@cka001:~# kubectl get clusterrole admin -n jh-namespace NAME CREATED AT admin 2022-06-25T06:24:44Z root@cka001:~# kubectl get role admin -n jh-namespace Error from server (NotFound): roles.rbac.authorization.k8s.io \"admin\" not found root@cka001:~# kubectl get role -n jh-namespace No resources found in jh-namespace namespace. root@cka001:~# kubectl get rolebinding -n jh-namespace No resources found in jh-namespace namespace. Let's create a rolebinding rolebinding-admin to bind cluster role admin to service account default in namespapce jh-namespace . Hence service account default is granted adminstrator authorization in namespace jh-namespace . kubectl create rolebinding <rule> --clusterrole=<clusterrule> --serviceaccount=<namespace>:<name> --namespace=<namespace> root@cka001:~# kubectl create rolebinding rolebinding-admin --clusterrole=admin --serviceaccount=jh-namespace:default --namespace=jh-namespace rolebinding.rbac.authorization.k8s.io/rolebinding-admin created root@cka001:~# kubectl get rolebinding -n jh-namespace NAME ROLE AGE rolebinding-admin ClusterRole/admin 39s Get token of the service account default . root@cka001:~# TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d ' ') root@cka001:~# echo $TOKEN Get API Service address. root@cka001:~# APISERVER=$(kubectl config view | grep https | cut -f 2- -d \":\" | tr -d \" \") root@cka001:~# echo $APISERVER Get pod resources in namespace jh-namespace via API server with JSON layout. root@cka001:~# curl $APISERVER/api/v1/namespaces/jh-namespace/pods --header \"Authorization: Bearer $TOKEN\" --insecure We can also access the link $APISERVER/api/v1/namespaces/jh-namespace/pods in browser for details. Config File Bash Autocomplete Common Usage Kubernetes API and Resource API Version API Group Resource Pods Basic InitContainer Static Pod","title":"Kubernetes Tutourials: Ubuntu@Aliyun"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#kubernetes-tutourials-ubuntualiyun","text":"","title":"Kubernetes Tutourials: Ubuntu@Aliyun"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#deployment","text":"","title":"Deployment"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#preparation","text":"Register Aliyun account via Alibaba Cloud home console . Request three Elastic Computer Service(ECS) instances with below sizing: System: 2vCPU+4GiB OS: Ubuntu 20.04 x86_64 Instance Type: ecs.sn1.medium Instance Name: cka001, cka002, cka003 Network: both public IPs and private IPs Maximum Bandwidth: 100Mbps (Peak Value) Cloud disk: 40GiB Billing Method: Preemptible instance (spot price) Generate SSH key pairs with name cka-key-pair in local directcory /opt . Change access control to 400 per security required by command sudo chmod 400 cka-key-pair.pem . cka003 Access remote cka servers via command ssh -i cka-key-pair.pem root@<your public ip address>","title":"Preparation"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#initialize-vms","text":"","title":"Initialize VMs"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#configure-etchosts-file","text":"Add private IPs in the /etc/hosts file in all VMs.","title":"Configure /etc/hosts file"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#disable-firewall","text":"Disable firewall by command ufw disable in all VMs.","title":"Disable firewall"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#turn-off-swap","text":"Turn off swap by command swapoff -a in all VMs.","title":"Turn off swap"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#set-timezone-and-locale","text":"Set timezone and local for all VMs. For ECS with Ubuntu 20.04 version created by Aliyun, this step is not needed. # ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # sudo echo 'LANG=\"en_US.UTF-8\"' >> /etc/profile # source /etc/profile Something like this: root@cka001:~# ll /etc/localtime lrwxrwxrwx 1 root root 33 May 24 18:14 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai","title":"Set timezone and locale"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#kernel-setting","text":"Perform below kernel setting in all VMs. Create file /etc/modules-load.d/containerd.conf to set up containerd configure file. It's to load two modules overlay and br_netfilter . Service containerd depends on overlay filesystem. Sometimes referred to as union-filesystems. An overlay-filesystem tries to present a filesystem which is the result over overlaying one filesystem on top of the other. The br_netfilter module is required to enable transparent masquerading and to facilitate Virtual Extensible LAN (VxLAN) traffic for communication between Kubernetes pods across the cluster. # cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF Load overlay and br_netfilter modules. # sudo modprobe overlay # sudo modprobe br_netfilter Create file 99-kubernetes-cri.conf to set up configure file for Kubernetes CRI. Set net/bridge/bridge-nf-call-iptables=1 to ensure simple configurations (like Docker with a bridge) work correctly with the iptables proxy. Why net/bridge/bridge-nf-call-iptables=1 need to be enable by Kubernetes . IP forwarding is also known as routing. When it comes to Linux, it may also be called Kernel IP forwarding because it uses the kernel variable net.ipv4.ip_forward to enable or disable the IP forwarding feature. The default preset value is ip_forward=0 . Hence, the Linux IP forwarding feature is disabled by default. # cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF The sysctl command reads the information from the /proc/sys directory. /proc/sys is a virtual directory that contains file objects that can be used to view and set the current kernel parameters. By commadn sysctl -w net.ipv4.ip_forward=1 , the change takes effect immediately, but it is not persistent. After a system reboot, the default value is loaded. Write the settings to /etc/sysctl.conf is to set a parameter permanently, you\u2019ll need to or another configuration file in the /etc/sysctl.d directory: sudo sysctl --system","title":"Kernel setting"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#install-containerd","text":"Install Containerd sevice fro all VMs. Backup source file. # sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak Add proper repo sources. For ECS with Ubuntu 20.04 version created by Aliyun, this step is not needed. cat > /etc/apt/sources.list << EOF deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal universe deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates universe deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal multiverse deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-updates multiverse deb http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.cloud.aliyuncs.com/ubuntu/ focal-backports main restricted universe multivers deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security main restricted deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security main restricted deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security universe deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security universe # deb http://mirrors.cloud.aliyuncs.com/ubuntu focal-security multiverse # deb-src http://mirrors.cloud.aliyuncs.com/ubuntu focal-security multiverse EOF Install Containered. # sudo apt-get update && sudo apt-get install -y containerd Configure Containerd. Modify file /etc/containerd/config.toml . # sudo mkdir -p /etc/containerd # containerd config default | sudo tee /etc/containerd/config.toml # vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd","title":"Install Containerd"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#install-nerdctl","text":"Install nerdctl sevice fro all VMs. The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # cp nerdctl /usr/bin/ Verify nerdctl. # nerdctl --help To list local Kubernetes containers. # nerdctl -n k8s.io ps","title":"Install nerdctl"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#install-kubeadm","text":"Update apt-transport-https , ca-certificates , and curl . # apt-get update && sudo apt-get install -y apt-transport-https ca-certificates curl Install gpg certificate. # curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - Add Kubernetes repo. # cat <<EOF >/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF Update and install dependencied packages. # apt-get update # apt-get install ebtables # apt-get install libxtables12=1.8.4-3ubuntu2 # apt-get upgrade iptables Check available versions of kubeadm. # apt policy kubeadm Install 1.23.8-00 version of kubeadm and will upgrade to 1.24.2 later. # sudo apt-get -y install kubelet=1.23.8-00 kubeadm=1.23.8-00 kubectl=1.23.8-00 --allow-downgrades","title":"Install kubeadm"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#setup-master-node","text":"Set up Control Plane on VM playing master node. Check kubeadm default parameters for initialization. # kubeadm config print init-defaults Dry rune and run. Save the output, which will be used later on work nodes. Be noted that 10.244.0.0/16 is default range of flannel. If it's changed here, please do change the same when deploy flannel. # kubeadm init --dry-run --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 # kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 Set kubeconfig file for current user (here it's root ). # mkdir -p $HOME/.kube # sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # sudo chown $(id -u):$(id -g) $HOME/.kube/config Set kubectl auto-completion. # apt install -y bash-completion # source /usr/share/bash-completion/bash_completion # source <(kubectl completion bash) # echo \"source <(kubectl completion bash)\" >> ~/.bashrc","title":"Setup Master Node"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#setup-work-nodes","text":"Perform on all VMs playing work nodes. # kubeadm join <your master node ip>:6443 --token <token generated by kubeadm init> --discovery-token-ca-cert-hash <hash key generated by kubeadm init> Verify status on master node. root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION cka001 Ready control-plane,master 24m v1.23.8 cka002 Ready <none> 9m39s v1.23.8 cka003 Ready <none> 9m27s v1.23.8","title":"Setup Work Nodes"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#install-flannel","text":"Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes. Deploy Flannel on master node. In the kube-flannel.yml we can get the default network setting of Flannel, which is same with --pod-network-cidr=10.244.0.0/16 we defined before when we initiated kubeadm . net-conf.json: | { \"Network\": \"10.244.0.0/16\", \"Backend\": { \"Type\": \"vxlan\" } } root@cka001:~# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created","title":"Install Flannel"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#check-cluster-status","text":"Perform kubectl cluster-info command on master node we will get below information. Kubernetes control plane is running at https:// :6443 CoreDNS is running at https:// :6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy # kubectl cluster-info # kubectl get nodes -owide # kubectl get pod -A","title":"Check Cluster Status"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#reset-cluster","text":"CAUTION: below steps will destroy current cluster. Delete all nodes in the cluster. # kubeadm reset Clean up rule of iptables . # iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X Clean up rule of IPVS if using IPVS . # ipvsadm --clear","title":"Reset cluster"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#snapshot-of-deployment","text":"Till now, the initial deployment is completed sucessfully.","title":"Snapshot of deployment"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#container-layer","text":"We are using Containerd service to manage our images and containers via command nerdctl . Get current namespaces. root@cka001:~# nerdctl namespace ls NAME CONTAINERS IMAGES VOLUMES LABELS k8s.io 18 27 0 Get containers under the namespace k8s.io by command nerdctl -n k8s.io ps . root@cka001:~# nerdctl -n k8s.io container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1eb9a51e0406 registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.8 \"kube-apiserver --ad\u2026\" 28 hours ago Up k8s://kube-system/kube-apiserver-cka001/kube-apiserver 1ebee10176c4 registry.aliyuncs.com/google_containers/kube-proxy:v1.23.8 \"/usr/local/bin/kube\u2026\" 28 hours ago Up k8s://kube-system/kube-proxy-v7rsr/kube-proxy 2c5e1d183fc7 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-apiserver-cka001 2dd9743cecad registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/kube-flannel-ds-rf54c 39306eef76cd docker.io/rancher/mirrored-flannelcni-flannel:v0.18.1 \"/opt/bin/flanneld -\u2026\" 27 hours ago Up k8s://kube-system/kube-flannel-ds-rf54c/kube-flannel 3ca6fdda63a5 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-scheduler-cka001 49e07d9b2b98 registry.aliyuncs.com/google_containers/coredns:v1.8.6 \"/coredns -conf /etc\u2026\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-9khd8/coredns 555a3bf58832 registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.8 \"kube-scheduler --au\u2026\" 28 hours ago Up k8s://kube-system/kube-scheduler-cka001/kube-scheduler 5812c42bf572 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/etcd-cka001 8619e3c979a3 registry.aliyuncs.com/google_containers/coredns:v1.8.6 \"/coredns -conf /etc\u2026\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-qcp2l/coredns a9459900f462 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-9khd8 bb2b4624bfd5 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 27 hours ago Up k8s://kube-system/coredns-6d8c4cb4d-qcp2l c9462709baff registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.8 \"kube-controller-man\u2026\" 28 hours ago Up k8s://kube-system/kube-controller-manager-cka001/kube-controller-manager e68c3fbc90f9 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-proxy-v7rsr eae550221813 registry.aliyuncs.com/google_containers/pause:3.6 \"/pause\" 28 hours ago Up k8s://kube-system/kube-controller-manager-cka001 ff6626664c43 registry.aliyuncs.com/google_containers/etcd:3.5.1-0 \"etcd --advertise-cl\u2026\" 28 hours ago Up k8s://kube-system/etcd-cka001/etcd Some management and commands options of nertctl . root@cka001:~# nertctl --help root@cka001:~# nerdctl image ls -a root@cka001:~# nerdctl volume ls root@cka001:~# nerdctl stats Get below network list with command nerdctl network ls in Containerd layer. root@cka001:~# nerdctl network ls NETWORK ID NAME FILE cbr0 /etc/cni/net.d/10-flannel.conflist 0 bridge /etc/cni/net.d/nerdctl-bridge.conflist host none Get network interface in host cka001 with command ip addr list . lo : inet 127.0.0.1/8 qlen 1000 eth0 : inet 172.16.18.161/24 brd 172.16.18.255 qlen 1000 flannel.1 : inet 10.244.0.0/32 cni0 : inet 10.244.0.1/24 brd 10.244.0.255 qlen 1000 vethb0a35696@if3 : noqueue master cni0 veth72791f64@if3 : noqueue master cni0","title":"Container Layer"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#kubernetes-layer","text":"Kubernetes is beyond container layer above. In Kubernetes layer, we have three nodes, cka001 , cka002 , and cka003 . root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION cka001 Ready control-plane,master 27h v1.23.8 cka002 Ready <none> 27h v1.23.8 cka003 Ready <none> 27h v1.23.8 We have four initial namespaces across three nodes. root@cka001:~# kubectl get namespace -A NAME STATUS AGE default Active 27h kube-node-lease Active 27h kube-public Active 27h kube-system Active 27h We have some initial pods. root@cka001:~# kubectl get pod -A -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-6d8c4cb4d-9khd8 1/1 Running 0 27h <cni0 IP> cka001 <none> <none> kube-system coredns-6d8c4cb4d-qcp2l 1/1 Running 0 27h <cni0 IP> cka001 <none> <none> kube-system etcd-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-apiserver-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-controller-manager-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-flannel-ds-hfvf7 1/1 Running 0 27h <eth0 IP> cka003 <none> <none> kube-system kube-flannel-ds-m5mdl 1/1 Running 0 27h <eth0 IP> cka002 <none> <none> kube-system kube-flannel-ds-rf54c 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-proxy-bj75j 1/1 Running 0 27h <eth0 IP> cka002 <none> <none> kube-system kube-proxy-gxjj4 1/1 Running 0 27h <eth0 IP> cka003 <none> <none> kube-system kube-proxy-v7rsr 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> kube-system kube-scheduler-cka001 1/1 Running 0 27h <eth0 IP> cka001 <none> <none> Summary below shows the relationship between containers and pods. Good references about container pause: article and artical . Master node: CoreDNS: 2 pods, 2 containers of each pod From image coredns:v1.8.6 : k8s://kube-system/coredns-6d8c4cb4d-9khd8/coredns k8s://kube-system/coredns-6d8c4cb4d-qcp2l/coredns By image pause:3.6 k8s://kube-system/coredns-6d8c4cb4d-9khd8 k8s://kube-system/coredns-6d8c4cb4d-qcp2l etcd: 1 pod, 2 containers By image etcd:3.5.1-0 k8s://kube-system/etcd-cka001/etcd By image pause:3.6 k8s://kube-system/etcd-cka001 apiserver: 1 pod, 2 containers By image kube-apiserver:v1.23.8 k8s://kube-system/kube-apiserver-cka001/kube-apiserver By image pause:3.6 k8s://kube-system/kube-apiserver-cka001 controller-manager: 1 pod, 2 containers By image kube-controller-manager:v1.23.8 k8s://kube-system/kube-controller-manager-cka001/kube-controller-manager By image pause:3.6 k8s://kube-system/kube-controller-manager-cka001 scheduler: 1 pod, 2 containers By image kube-scheduler:v1.23.8 k8s://kube-system/kube-scheduler-cka001/kube-scheduler By image pause:3.6 k8s://kube-system/kube-scheduler-cka001 All nodes: Flannel DS: 1 pod of each, 2 containers of each pod By image mirrored-flannelcni-flannel:v0.18.1 k8s://kube-system/kube-flannel-ds-rf54c/kube-flannel By image pause:3.6 k8s://kube-system/kube-flannel-ds-rf54c Proxy: 1 pod of each, 2 containers of each pod By image kube-proxy:v1.23.8 k8s://kube-system/kube-proxy-v7rsr/kube-proxy By image pause:3.6 k8s://kube-system/kube-proxy-v7rsr Let's check current configuration context of Kubernetes we just initialized. Contenxt name is kubernetes-admin@kubernetes . Cluster name is kubernetes . User is kubernetes-admin . No namespace explicitly defined. root@cka001:~# kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * kubernetes-admin@kubernetes kubernetes kubernetes-admin Create a new namespace jh-namespace . root@cka001:~# kubectl create namespace jh-namespace Update current context kubernetes-admin@kubernetes with new namespace jh-namespace as default namespace. root@cka001:~# kubectl config set-context kubernetes-admin@kubernetes --cluster=kubernetes --namespace=jh-namespace --user=kubernetes-admin Now default namespace is shown in current configuration context. root@cka001:~# kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * kubernetes-admin@kubernetes kubernetes kubernetes-admin jh-namespace Let's execute command kubectl apply -f 02-sample-pod.yaml to create a pod my-first-pod on namespace jh-namespace with below content of file 02-sample-pod.yaml . apiVersion: v1 kind: Pod metadata: name: my-first-pod spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 By command kubectl get pod -o wide we get the pod status. The pod's ip is allocated by cni0 . Node is assigned by Scheduler . We can also find related containers of pod my-first-pod via command nerdctl -n k8s.io container ls on cka003 . root@cka001:~# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-first-pod 1/1 Running 0 19s 10.244.2.2 cka003 <none> <none>","title":"Kubernetes Layer"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#case-study","text":"Scenario: stop kubelet service on worker node cka003 . Question: What's the status of each node? What's containers changed via command nerdctl ? What's pods status via command kubectl get pod -owide -A ? Demo: Execute command systemctl stop kubelet.service on cka003 . Execute command kubectl get node on either cka001 or cka003 , the status of cka003 is NotReady . Execute command nerdctl -n k8s.io container ls on cka003 and we can observe all containers are still up and running, including the pod my-first-pod . Execute command systemctl start kubelet.service on cka003 . Conclusion: The node status is changed to NotReady from Ready . For those DaemonSet pods, like flannel \u3001 kube-proxy , are exclusively running on each node. They won't be terminated after kubelet is down. The status of pod my-first-pod keeps showing Terminating on each node because status can not be synced to other nodes via apiserver from cka003 because kubelet is down. The status of pod is marked by controller and recycled by kubelet . When we start kubelet service on cka003 , the pod my-first-pod will be termiated completely on cka003 . In addition, let's create a deployment with 3 replicas. Two are running on cka003 and one is running on cka002 . root@cka001:~# kubectl get pod -o wide -w NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-deployment-9d745469b-2xdk4 1/1 Running 0 2m8s 10.244.2.3 cka003 <none> <none> nginx-deployment-9d745469b-4gvmr 1/1 Running 0 2m8s 10.244.2.4 cka003 <none> <none> nginx-deployment-9d745469b-5j927 1/1 Running 0 2m8s 10.244.1.3 cka002 <none> <none> After we stop kubelet service on cka003 , the two running on cka003 are terminated and another two are created and running on cka002 automatically.","title":"Case Study"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#kubectl","text":"Three approach to operate Kubernetes cluster: via API via kubectl via Dashboard Example with kubectl : With Kubernetes 1.23 and lower version, when we create a new namespace, Kubernetes will automatically create a ServiceAccount default and a token default-token-xxxxx . We can say that the ServiceAccount default is an account under the namespace. Here is an example of new namespace jh-namespace I created. ServiceAcccount: default Token: default-token-8vrsc root@cka001:~# kubectl get sa -n jh-namespace NAME SECRETS AGE default 1 26h root@cka001:~# kubectl get secrets -n jh-namespace NAME TYPE DATA AGE default-token-8vrsc kubernetes.io/service-account-token 3 26h There is a cluster rule admin , and no related rolebinding. root@cka001:~# kubectl get clusterrole admin -n jh-namespace NAME CREATED AT admin 2022-06-25T06:24:44Z root@cka001:~# kubectl get role admin -n jh-namespace Error from server (NotFound): roles.rbac.authorization.k8s.io \"admin\" not found root@cka001:~# kubectl get role -n jh-namespace No resources found in jh-namespace namespace. root@cka001:~# kubectl get rolebinding -n jh-namespace No resources found in jh-namespace namespace. Let's create a rolebinding rolebinding-admin to bind cluster role admin to service account default in namespapce jh-namespace . Hence service account default is granted adminstrator authorization in namespace jh-namespace . kubectl create rolebinding <rule> --clusterrole=<clusterrule> --serviceaccount=<namespace>:<name> --namespace=<namespace> root@cka001:~# kubectl create rolebinding rolebinding-admin --clusterrole=admin --serviceaccount=jh-namespace:default --namespace=jh-namespace rolebinding.rbac.authorization.k8s.io/rolebinding-admin created root@cka001:~# kubectl get rolebinding -n jh-namespace NAME ROLE AGE rolebinding-admin ClusterRole/admin 39s Get token of the service account default . root@cka001:~# TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d ' ') root@cka001:~# echo $TOKEN Get API Service address. root@cka001:~# APISERVER=$(kubectl config view | grep https | cut -f 2- -d \":\" | tr -d \" \") root@cka001:~# echo $APISERVER Get pod resources in namespace jh-namespace via API server with JSON layout. root@cka001:~# curl $APISERVER/api/v1/namespaces/jh-namespace/pods --header \"Authorization: Bearer $TOKEN\" --insecure We can also access the link $APISERVER/api/v1/namespaces/jh-namespace/pods in browser for details.","title":"kubectl"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#config-file","text":"","title":"Config File"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#bash-autocomplete","text":"","title":"Bash Autocomplete"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#common-usage","text":"","title":"Common Usage"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#kubernetes-api-and-resource","text":"","title":"Kubernetes API and Resource"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#api-version","text":"","title":"API Version"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#api-group","text":"","title":"API Group"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#resource","text":"","title":"Resource"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#pods","text":"","title":"Pods"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#basic","text":"","title":"Basic"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#initcontainer","text":"","title":"InitContainer"},{"location":"cloud/KubernetesTutorials-Aliyun-Ubuntu/#static-pod","text":"","title":"Static Pod"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/","text":"Kubernetes Tutourials: openSUSE@Aliyun Before, Kubic from openSUSE is focusing on kubeadm as open source project. CaaSP is comercial product for Kubenetes, compared with Kubic. After SUSE aand Rancher mergered, their fucus on Kubernetes turn to K3s / RKE / RKE2 and MicroOS , not Kubic nor CaaSP. Hence, for learning purpose, it's recommended to use K3s, for comercial perspective, may consider RKE or RKE2. Below demo only shows deployment of native Kubernetes on openSUSE 15sp3, which may just a refernce with native deployment on Ubuntu or RedHat. Deployment Preparation Register Aliyun account via Alibaba Cloud home console . Request three Elastic Computer Service(ECS) instances with below sizing: System: 2vCPU+4GiB OS: openSUSE 15sp3 x86_64 Instance Type: ecs.sn1.medium Instance Name: leap1, leap2, leap3 Network: both public IPs and private IPs Maximum Bandwidth: 100Mbps (Peak Value) Cloud disk: 40GiB Billing Method: Preemptible instance (spot price) Generate SSH key pairs with name cka-key-pair in local directory /opt . Change access control to 400 per security required by command sudo chmod 400 cka-key-pair.pem . Access remote cka servers via command ssh -i cka-key-pair.pem root@<your public ip address> Initialize VMs Configure /etc/hosts file Add private IPs in the /etc/hosts file in all VMs. Disable firewall SUSE introduces firewalld as the new default software firewall, replacing SuSEfirewall2. SuSEfirewall2 has not been removed and is still part of the main repository, though not installed by default. Firewalld and SuSEfirewall2 packages was not installed during initialization. Turn off swap Turn off swap by command swapoff -a in all VMs. Set timezone and locale Set timezone and local for all VMs. For ECS with SLES 15sp3 version created by Aliyun, this step is not needed. # ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # sudo echo 'LANG=\"en_US.UTF-8\"' >> /etc/profile # source /etc/profile Something like this: root@cka001:~# ll /etc/localtime lrwxrwxrwx 1 root root 33 May 24 18:14 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai Kernel setting Load overlay and br_netfilter modules. Check the active module loaded list. The removed module is not on the module loaded list. # lsmod | grep overlay # lsmod | grep br_netfilter # sudo modprobe overlay # sudo modprobe br_netfilter Set net/bridge/bridge-nf-call-iptables=1 to ensure simple configurations (like Docker with a bridge) work correctly with the iptables proxy. Why net/bridge/bridge-nf-call-iptables=1 need to be enable by Kubernetes . IP forwarding is also known as routing. When it comes to Linux, it may also be called Kernel IP forwarding because it uses the kernel variable net.ipv4.ip_forward to enable or disable the IP forwarding feature. The default preset value is ip_forward=0 . Hence, the Linux IP forwarding feature is disabled by default. # cat <<EOF >> /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.ipv4.conf.all.forwarding = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF The sysctl command reads the information from the /proc/sys directory. /proc/sys is a virtual directory that contains file objects that can be used to view and set the current kernel parameters. By commadn sysctl -w net.ipv4.ip_forward=1 , the change takes effect immediately, but it is not persistent. After a system reboot, the default value is loaded. Write the settings to /etc/sysctl.conf is to set a parameter permanently, you\u2019ll need to or another configuration file in the /etc/sysctl.d directory: # sudo sysctl --system Install Containerd Install docker in all VMs. # zypper install docker Start Containerd service # systemctl enable containerd.service # systemctl start containerd.service # systemctl status containerd.service Configure Containerd. Modify file /etc/containerd/config.toml . # sudo mkdir -p /etc/containerd # containerd config default | sudo tee /etc/containerd/config.toml # vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd Install nerdctl Install nerdctl sevice fro all VMs. The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # cp nerdctl /usr/bin/ Verify nerdctl. # nerdctl --help To list local Kubernetes containers. # nerdctl -n k8s.io ps Install kubeadm Install conntrackd, which is required by kubelet. # sudo zypper in conntrack-tools Add repository for installing Kubernetes packages. # cat <<EOF > /etc/zypp/repos.d/kubernetes.repo [kubernetes] name=Kubernetes enabled=1 autorefresh=1 baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ type=rpm-md gpgcheck=1 repo_gpgcheck=1 pkg_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF Refresh the repo # sudo zypper ref kubernetes List curren tavailable packages in repo Kubernetes. # sudo zypper packages --repo kubernetes Install 1.23.8-00 version of kubeadm and will upgrade to 1.24.2 later. Ignoring conntrack breakout, just pick. # sudo zypper in kubelet=1.23.8-00 kubeadm=1.23.8-00 kubectl=1.23.8-00 Enable kubelet service on boot: # sudo systemctl enable kubelet Setup Master Node Set up Control Plane on VM playing master node. Check kubeadm default parameters for initialization. # kubeadm config print init-defaults Dry rune and run. Save the output, which will be used later on work nodes. Be noted that 10.244.0.0/16 is default range of flannel. If it's changed here, please do change the same when deploy flannel. # kubeadm init --dry-run --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 # kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 Set kubeconfig file for current user (here it's root ). # mkdir -p $HOME/.kube # sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # sudo chown $(id -u):$(id -g) $HOME/.kube/config Set kubectl auto-completion. # sudo zypper in bash-completion # source /usr/share/bash-completion/bash_completion # source <(kubectl completion bash) # echo \"source <(kubectl completion bash)\" >> ~/.bashrc Setup Work Nodes Perform on all VMs playing work nodes. # kubeadm join <your master node ip>:6443 --token <token generated by kubeadm init> --discovery-token-ca-cert-hash <hash key generated by kubeadm init> Verify status on master node. root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION leap1 Ready control-plane,master 16m v1.23.8 leap2 Ready <none> 9m39s v1.23.8 leap3 Ready <none> 9m51s v1.23.8 Install Flannel Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes. Deploy Flannel on master node. In the kube-flannel.yml we can get the default network setting of Flannel, which is same with --pod-network-cidr=10.244.0.0/16 we defined before when we initiated kubeadm . net-conf.json: | { \"Network\": \"10.244.0.0/16\", \"Backend\": { \"Type\": \"vxlan\" } } root@cka001:~# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created Check Cluster Status Perform kubectl cluster-info command on master node we will get below information. Kubernetes control plane is running at https:// :6443 CoreDNS is running at https:// :6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy # kubectl cluster-info # kubectl get nodes -owide # kubectl get pod -A Reset cluster CAUTION: below steps will destroy current cluster. Delete all nodes in the cluster. # kubeadm reset Clean up rule of iptables . # iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X Clean up rule of IPVS if using IPVS . # ipvsadm --clear Two references I used. How to install kubernetes in Suse Linux enterprize server 15 virtual machines How to Install Kubernetes Cluster in openSUSE Leap 15.1","title":"Kubernetes Tutourials: openSUSE@Aliyun"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#kubernetes-tutourials-opensusealiyun","text":"Before, Kubic from openSUSE is focusing on kubeadm as open source project. CaaSP is comercial product for Kubenetes, compared with Kubic. After SUSE aand Rancher mergered, their fucus on Kubernetes turn to K3s / RKE / RKE2 and MicroOS , not Kubic nor CaaSP. Hence, for learning purpose, it's recommended to use K3s, for comercial perspective, may consider RKE or RKE2. Below demo only shows deployment of native Kubernetes on openSUSE 15sp3, which may just a refernce with native deployment on Ubuntu or RedHat.","title":"Kubernetes Tutourials: openSUSE@Aliyun"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#deployment","text":"","title":"Deployment"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#preparation","text":"Register Aliyun account via Alibaba Cloud home console . Request three Elastic Computer Service(ECS) instances with below sizing: System: 2vCPU+4GiB OS: openSUSE 15sp3 x86_64 Instance Type: ecs.sn1.medium Instance Name: leap1, leap2, leap3 Network: both public IPs and private IPs Maximum Bandwidth: 100Mbps (Peak Value) Cloud disk: 40GiB Billing Method: Preemptible instance (spot price) Generate SSH key pairs with name cka-key-pair in local directory /opt . Change access control to 400 per security required by command sudo chmod 400 cka-key-pair.pem . Access remote cka servers via command ssh -i cka-key-pair.pem root@<your public ip address>","title":"Preparation"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#initialize-vms","text":"","title":"Initialize VMs"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#configure-etchosts-file","text":"Add private IPs in the /etc/hosts file in all VMs.","title":"Configure /etc/hosts file"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#disable-firewall","text":"SUSE introduces firewalld as the new default software firewall, replacing SuSEfirewall2. SuSEfirewall2 has not been removed and is still part of the main repository, though not installed by default. Firewalld and SuSEfirewall2 packages was not installed during initialization.","title":"Disable firewall"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#turn-off-swap","text":"Turn off swap by command swapoff -a in all VMs.","title":"Turn off swap"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#set-timezone-and-locale","text":"Set timezone and local for all VMs. For ECS with SLES 15sp3 version created by Aliyun, this step is not needed. # ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # sudo echo 'LANG=\"en_US.UTF-8\"' >> /etc/profile # source /etc/profile Something like this: root@cka001:~# ll /etc/localtime lrwxrwxrwx 1 root root 33 May 24 18:14 /etc/localtime -> /usr/share/zoneinfo/Asia/Shanghai","title":"Set timezone and locale"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#kernel-setting","text":"Load overlay and br_netfilter modules. Check the active module loaded list. The removed module is not on the module loaded list. # lsmod | grep overlay # lsmod | grep br_netfilter # sudo modprobe overlay # sudo modprobe br_netfilter Set net/bridge/bridge-nf-call-iptables=1 to ensure simple configurations (like Docker with a bridge) work correctly with the iptables proxy. Why net/bridge/bridge-nf-call-iptables=1 need to be enable by Kubernetes . IP forwarding is also known as routing. When it comes to Linux, it may also be called Kernel IP forwarding because it uses the kernel variable net.ipv4.ip_forward to enable or disable the IP forwarding feature. The default preset value is ip_forward=0 . Hence, the Linux IP forwarding feature is disabled by default. # cat <<EOF >> /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.ipv4.conf.all.forwarding = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF The sysctl command reads the information from the /proc/sys directory. /proc/sys is a virtual directory that contains file objects that can be used to view and set the current kernel parameters. By commadn sysctl -w net.ipv4.ip_forward=1 , the change takes effect immediately, but it is not persistent. After a system reboot, the default value is loaded. Write the settings to /etc/sysctl.conf is to set a parameter permanently, you\u2019ll need to or another configuration file in the /etc/sysctl.d directory: # sudo sysctl --system","title":"Kernel setting"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#install-containerd","text":"Install docker in all VMs. # zypper install docker Start Containerd service # systemctl enable containerd.service # systemctl start containerd.service # systemctl status containerd.service Configure Containerd. Modify file /etc/containerd/config.toml . # sudo mkdir -p /etc/containerd # containerd config default | sudo tee /etc/containerd/config.toml # vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd","title":"Install Containerd"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#install-nerdctl","text":"Install nerdctl sevice fro all VMs. The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # cp nerdctl /usr/bin/ Verify nerdctl. # nerdctl --help To list local Kubernetes containers. # nerdctl -n k8s.io ps","title":"Install nerdctl"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#install-kubeadm","text":"Install conntrackd, which is required by kubelet. # sudo zypper in conntrack-tools Add repository for installing Kubernetes packages. # cat <<EOF > /etc/zypp/repos.d/kubernetes.repo [kubernetes] name=Kubernetes enabled=1 autorefresh=1 baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ type=rpm-md gpgcheck=1 repo_gpgcheck=1 pkg_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF Refresh the repo # sudo zypper ref kubernetes List curren tavailable packages in repo Kubernetes. # sudo zypper packages --repo kubernetes Install 1.23.8-00 version of kubeadm and will upgrade to 1.24.2 later. Ignoring conntrack breakout, just pick. # sudo zypper in kubelet=1.23.8-00 kubeadm=1.23.8-00 kubectl=1.23.8-00 Enable kubelet service on boot: # sudo systemctl enable kubelet","title":"Install kubeadm"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#setup-master-node","text":"Set up Control Plane on VM playing master node. Check kubeadm default parameters for initialization. # kubeadm config print init-defaults Dry rune and run. Save the output, which will be used later on work nodes. Be noted that 10.244.0.0/16 is default range of flannel. If it's changed here, please do change the same when deploy flannel. # kubeadm init --dry-run --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 # kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.23.8 Set kubeconfig file for current user (here it's root ). # mkdir -p $HOME/.kube # sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # sudo chown $(id -u):$(id -g) $HOME/.kube/config Set kubectl auto-completion. # sudo zypper in bash-completion # source /usr/share/bash-completion/bash_completion # source <(kubectl completion bash) # echo \"source <(kubectl completion bash)\" >> ~/.bashrc","title":"Setup Master Node"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#setup-work-nodes","text":"Perform on all VMs playing work nodes. # kubeadm join <your master node ip>:6443 --token <token generated by kubeadm init> --discovery-token-ca-cert-hash <hash key generated by kubeadm init> Verify status on master node. root@cka001:~# kubectl get node NAME STATUS ROLES AGE VERSION leap1 Ready control-plane,master 16m v1.23.8 leap2 Ready <none> 9m39s v1.23.8 leap3 Ready <none> 9m51s v1.23.8","title":"Setup Work Nodes"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#install-flannel","text":"Flannel is a simple and easy way to configure a layer 3 network fabric designed for Kubernetes. Deploy Flannel on master node. In the kube-flannel.yml we can get the default network setting of Flannel, which is same with --pod-network-cidr=10.244.0.0/16 we defined before when we initiated kubeadm . net-conf.json: | { \"Network\": \"10.244.0.0/16\", \"Backend\": { \"Type\": \"vxlan\" } } root@cka001:~# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created","title":"Install Flannel"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#check-cluster-status","text":"Perform kubectl cluster-info command on master node we will get below information. Kubernetes control plane is running at https:// :6443 CoreDNS is running at https:// :6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy # kubectl cluster-info # kubectl get nodes -owide # kubectl get pod -A","title":"Check Cluster Status"},{"location":"cloud/KubernetesTutorials-Aliyun-openSUSE/#reset-cluster","text":"CAUTION: below steps will destroy current cluster. Delete all nodes in the cluster. # kubeadm reset Clean up rule of iptables . # iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X Clean up rule of IPVS if using IPVS . # ipvsadm --clear Two references I used. How to install kubernetes in Suse Linux enterprize server 15 virtual machines How to Install Kubernetes Cluster in openSUSE Leap 15.1","title":"Reset cluster"},{"location":"cloud/KubernetesTutorials-BTP-trail/","text":"Tutorials: SAP BTP trail account kubectl basics Register account of SAP BTP trail system . I am using BTP Kyma runtime for the demo. Choose the entitlements for k8sdev subdomain: Alert Notification: Standard plan Continuous Integration & Delivery: default (Application) or the trial (Application) or free (Application) plans which are not charged Kyma runtime: any available plan in the list (trial and free are not charged) Launchpad Service: standard (Application) or free (Application) SAP HANA Cloud: hana SAP HANA Schemas & HDI Containers: hdi-shared Enable Kyma runtime in k8sdev subdomain, and download kubeconfig file to local directory ~/.kube/ and rename it to ~/.kube/config-btp-kyma.yaml . If the directory ~/.kube/ does not exist, create it. Add below line into file /etc/profile.local and make it effected by command source /etc/profile.local . export KUBECONFIG=$HOME/.kube/config-btp-kyma.yaml Check current kubeconfig file. Use the kubectl config command to get current context of configuration file. james@lizard:~> echo $KUBECONFIG /home/james/.kube/config-btp-kyma.yaml james@lizard:~> kubectl config view james@lizard:~> kubectl config get-contexts Using SAP BTP, brew and oidc-login need to be installed. Install krew (https://krew.sigs.k8s.io/docs/user-guide/setup/install/) james@lizard:~> ( set -x; cd \"$(mktemp -d)\" && OS=\"$(uname | tr '[:upper:]' '[:lower:]')\" && ARCH=\"$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\\(arm\\)\\(64\\)\\?.*/\\1\\2/' -e 's/aarch64$/arm64/')\" && KREW=\"krew-${OS}_${ARCH}\" && curl -fsSLO \"https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz\" && tar zxvf \"${KREW}.tar.gz\" && ./\"${KREW}\" install krew ) Append below two lines to file /etc/profile.local make it effected by command source /etc/profile.local export PATH=$HOME/.krew/bin:$PATH Install oidc-login (https://github.com/int128/kubelogin#setup) . james@lizard:~> kubectl krew install oidc-login Check the nodes Use the kubectl get nodes command to get the basic information about the clusters' nodes. There will be a pop-up web page for authentication with registered email address and password. More information can be found by appending --help to command. james@lizard:~> kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 47m v1.21.10 Get nodes information with different format output, e.g., yaml format. james@lizard:~> kubectl get nodes -o yaml Get detailed information about a node by running kubectl describe node <node-name> or kubectl get node <node-name>. . james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 53m v1.21.10 james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-10-250-0-53.ec2.internal Ready <none> 56m v1.21.10 10.250.0.53 <none> Garden Linux 576.8 5.10.109-garden-cloud-amd64 docker://20.10.11+dfsg1 james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o yaml james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o json james@lizard:~> kubectl describe nodes ip-10-250-0-53.ec2.internal Get namespaces information by running kubectl get namespaces . james@lizard:~> kubectl get namespaces NAME STATUS AGE compass-system Active 58m default Active 62m istio-system Active 55m kube-node-lease Active 62m kube-public Active 62m kube-system Active 62m kyma-integration Active 52m kyma-system Active 55m Get running pods under specific namespace by running kubectl get pods -n <namespace> . james@lizard:~> kubectl get pods james@lizard:~> kubectl get pods -n kube-system Check the proxy We can use kubectl proxy command to open a tunnel to the API server and make it available locally - usually on localhost:8001 / 127.0.0.1:8001. When I want to explore the API, this is an easy way to gain access. Run the command kubectl proxy & and open http://localhost:8001/api/v1 in browser. Just opening http://localhost:8001 will return an error because we are only allowed to access certain parts of the API. Hence the API path is important james@lizard:~> kubectl proxy & [1] 102358 james@lizard:~> Starting to serve on 127.0.0.1:8001 Example, get available API groups and so on via below link: http://127.0.0.1:8001/ http://127.0.0.1:8001/api/v1 http://127.0.0.1:8001/api/v1/namespaces http://127.0.0.1:8001/api/v1/namespaces/default http://127.0.0.1:8001/api/v1/namespaces/sock-shop/pods Check api-versions & api-resources Get an overview of existing APIs by running kubectl api-versions and kubectl api-resources . james@lizard:~> kubectl api-resources -o wide james@lizard:~> kubectl api-versions Namespace is a cluster, which includes services. Service may be on a node, may be not. Access as application If I access kubernetes as an application rather than an administrator, I cannot use the kubectl . Instead of kubectl I can use the program curl . I have to send HTTP requests to the cluster. asking for the available nodes. make sure kubectl proxy is running and serving on http://localhost:8001/ . Execute command below with a -v=9 flag, it shows all the information needed. james@lizard:~> kubectl get nodes Go through the command's output and find the correct curl request below. curl -v -XGET -H \"Accept: application/json;as=Table;v=v1;g=meta.k8s.io,application/json;as=Table;v=v1beta1;g=meta.k8s.io,application/json\" -H \"User-Agent: kubectl/v1.24.1 (linux/amd64) kubernetes/3ddd0f4\" 'https://api.eb68ebe.kyma.ondemand.com/api/v1/nodes?limit=500' Further information & references: There is a forum-like page hosted by K8s with lots of information around kubectl and how to use it best. Manage multiple clusters and multiple config files kubectl command documentation Shell autocompletion kubectl cheat sheet jsonpath in kubectl Work on pod Create pod Create new namespace jh-namespace for my demo. james@lizard:~> kubectl create namespace jh-namespace namespace/jh-namespace created james@lizard:~> kubectl get ns NAME STATUS AGE compass-system Active 2d1h default Active 2d1h istio-system Active 2d jh-namespace Active 7s kube-node-lease Active 2d1h kube-public Active 2d1h kube-system Active 2d1h kyma-integration Active 2d kyma-system Active 2d Get current config information, which will be referred by following commands. james@lizard:~> kubectl config view Get current contexts. james@lizard:~> kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * shoot--kyma--eb68ebe shoot--kyma--eb68ebe shoot--kyma--eb68ebe Update context with new namespace by command kubectl config set-context <context name> --cluster=<cluster name> --namespace=jh-namespace --user=<authinfo name> . Key information is from kubectl config view and kubectl config get-contexts . Verify if above change is effective by command kubectl config get-contexts . Create file 02-sample-pod.yaml . apiVersion: v1 kind: Pod metadata: name: my-first-pod spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 Create pod with file 02-sample-pod.yaml . james@lizard:~> kubectl create -n jh-namespace -f ./02-sample-pod.yaml pod/my-first-pod created Verify status of the pod just created. james@lizard:~> kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-first-pod 2/2 Running 0 6m43s 100.64.0.165 ip-10-250-0-53.ec2.internal <none> <none> Track pod Check logs of the pod just created. james@lizard:~> kubectl logs my-first-pod In case logs or describe or any other of the output generating commands don't help us to get to the root cause of an issue, we can use use kubectl exec -it <my-pod> -- bash command to look into it ourselves. james@lizard:~> kubectl exec -it my-first-pod -- bash root@my-first-pod:/# ls bin boot dev docker-entrypoint.d docker-entrypoint.sh etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@my-first-pod:/# cd bin root@my-first-pod:/bin# ls bash cp dir egrep gunzip login mktemp nisdomainname rm sleep tempfile uncompress zcmp zgrep cat dash dmesg false gzexe ls more pidof rmdir stty touch vdir zdiff zless chgrp date dnsdomainname fgrep gzip lsblk mount pwd run-parts su true wdctl zegrep zmore chmod dd domainname findmnt hostname mkdir mountpoint rbash sed sync umount ypdomainname zfgrep znew chown df echo grep ln mknod mv readlink sh tar uname zcat zforce root@my-first-pod:/bin# exit Execute command kubectl explain pod.spec will get details of Spec segment of Pod kind in yaml file. We can check the official API reference of the pod resource for help or use kubectl explain pod to get a command-line based description of the resource. By appending . to the resource type, the explain command will provide more details on the specified field. james@lizard:~> kubectl explain pod.kind james@lizard:~> kubectl explain pod.spec james@lizard:~> kubectl explain pod.spec.containers james@lizard:~> kubectl explain pod.spec.containers.name Label pod Get pod's label with option --show-labels . james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 5h47m james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 5h48m security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Add two labels to the pod pod my-first-pod . james@lizard:~> kubectl label pod my-first-pod nginx=mainline pod/my-first-pod labeled james@lizard:~> kubectl label pod my-first-pod env=demo pod/my-first-pod labeled james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 6h5m env=demo,nginx=mainline,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Search pod by labels. james@lizard:~> kubectl get pod -l env=demo NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 6h8m james@lizard:~> kubectl get pod -l env=demo,nginx=mainline NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 12h james@lizard:~> kubectl get pod -l env=training No resources found in jh-namespace namespace. Remove label james@lizard:~> kubectl label pods my-first-pod env- pod/my-first-pod unlabeled james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 24h nginx=mainline,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Describe pod. james@lizard:~> kubectl describe pod my-first-pod Delete pod. Run watch kubectl get pods to monitor the pod status. james@lizard:~> kubectl delete pod my-first-pod pod \"my-first-pod\" deleted james@lizard:~> watch kubectl get pods Label node Add label to node. james@lizard:~> kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 james@lizard:~> kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1f,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-250-0-53.ec2.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.xlarge,node.kubernetes.io/role=node,topology.ebs.csi.aws.com/zone=us-east-1f,topology.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1f,worker.garden.sapcloud.io/group=cpu-worker-0,worker.gardener.cloud/kubernetes-version=1.21.10,worker.gardener.cloud/pool=cpu-worker-0,worker.gardener.cloud/system-components=true james@lizard:~> kubectl label nodes ip-10-250-0-53.ec2.internal env=demo node/ip-10-250-0-53.ec2.internal labeled james@lizard:~> kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.xlarge,beta.kubernetes.io/os=linux,env=demo,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1f,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-250-0-53.ec2.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.xlarge,node.kubernetes.io/role=node,topology.ebs.csi.aws.com/zone=us-east-1f,topology.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1f,worker.garden.sapcloud.io/group=cpu-worker-0,worker.gardener.cloud/kubernetes-version=1.21.10,worker.gardener.cloud/pool=cpu-worker-0,worker.gardener.cloud/system-components=true Search node by label. james@lizard:~> kubectl get nodes -l env=demo NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 Describe node. james@lizard:~> kubectl describe node ip-10-250-0-53.ec2.internal Multi-Container Pods Create below yaml file to create multiple containers in one pod. In below yaml file, it describes some actions below: Define a volume named html and type is emptyDir . It means that the volume is created when a Pod is assigned to a node, and exists as long as that Pod is running on that node. Create container nginx and has the shared volume mounted to the directory /usr/share/nginx/html . Create container debian and has the shared volume mounted to the directory /html . Every second, the debian container adds the current datetime into the index.html file, which is located in the shared volume html , that is, /html/index.html and /usr/share/nginx/html/index.html are same, hence index.html can be read by nginx in directory /usr/share/nginx/html/ . apiVersion: v1 kind: Pod metadata: name: my-first-multi-pod spec: volumes: - name: html emptyDir: {} containers: - name: nginx image: nginx volumeMounts: - name: html mountPath: /usr/share/nginx/html - name: debian image: debian volumeMounts: - name: html mountPath: /html command: [\"/bin/sh\", \"-c\"] args: - while true; do date >> /html/index.html; sleep 1; done Create two containers nginx and debian in one pod my-first-multi-pod . james@lizard:~> kubectl apply -f 02-sample-pod-new.yaml pod/my-first-multi-pod created james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE my-first-multi-pod 3/3 Running 0 36s We now can verify content of file index.html either in container nginx or debian , which are same. james@lizard:~> kubectl exec my-first-multi-pod -c nginx -- /bin/cat /usr/share/nginx/html/index.html Fri Jun 17 13:04:16 UTC 2022 Fri Jun 17 13:04:17 UTC 2022 Fri Jun 17 13:04:18 UTC 2022 james@lizard:~> kubectl exec my-first-multi-pod -c debian -- /bin/cat /html/index.html Fri Jun 17 13:04:16 UTC 2022 Fri Jun 17 13:04:17 UTC 2022 Fri Jun 17 13:04:18 UTC 2022 Clean up the pod. james@lizard:~> kubectl delete pod my-first-multi-pod pod \"my-first-multi-pod\" deleted By default, all containers in a Pod are being started in parallel and there is no way to define that one container must be started after other container. We can use initContainers to run some containers (e.g., myservice-1 and mydb-1 ) before application containers (e.g., container-1 ). spec: containers: - name: container-1 image: busybox initContainers: - name: myservice-1 image: debain - name: mydb-1 image: mysql Further references: Pod basics Lifecycle & phases Kubernetes pod design pattern Deployment A Deployment provides declarative updates for Pods and ReplicaSets. The pod encapsulated the container and takes care of the desired state, that is, the deployment. The \"desired state\" means that a specified quorum of running instances is fulfilled. Create deployment from command Create a new resource of type deployment named \"nginx\". james@lizard:~> kubectl create deployment nginx --image=nginx:1.21 deployment.apps/nginx created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 21s james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-bnvgz 2/2 Running 0 5m54s Get nginx by labels. james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx 1/1 1 1 7m13s app=nginx james@lizard:~> kubectl get deployment -l app=nginx NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 8m57s james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-5c95dfd78d-bnvgz 2/2 Running 0 45s app=nginx,pod-template-hash=5c95dfd78d,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx,service.istio.io/canonical-revision=latest james@lizard:~> kubectl get pods -l app=nginx NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-bnvgz 2/2 Running 0 9m15s Use kubectl get deployment nginx -o yaml and kubectl describe deployment nginx to get more detailed information on the deployment just created. It's also good way to get reference yaml file for deployment creation. Scaling deployment Execute command kubectl scale deployment nginx --replicas=3 to scale the deployment nginx with 3 pods. james@lizard:~> kubectl scale deployment nginx --replicas=3 deployment.apps/nginx scaled james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx 3/3 3 3 14m app=nginx james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-5xfm7 2/2 Running 0 30s nginx-5c95dfd78d-bnvgz 2/2 Running 0 14m nginx-5c95dfd78d-m67ph 2/2 Running 0 30s james@lizard:~> kubectl get replicaset NAME DESIRED CURRENT READY AGE nginx-5c95dfd78d 3 3 3 33m Let's see the relationship and naming convention. Deployment: nginx | |--ReplicaSet: nginx-5c95dfd78d | |--Pods: |--nginx-5c95dfd78d-5xfm7 | |--Container: istio-proxy | |--Container: nginx | |--nginx-5c95dfd78d-bnvgz | |--Container: istio-proxy | |--Container: nginx | |--nginx-5c95dfd78d-m67ph |--Container: istio-proxy |--Container: nginx Verify scalling Delete a pod from the deployment and observe how the deployment's desired state (replicas=3) is kept. Use command kubectl delete pod <pod-name> to delete a pod and use command watch kubectl get pods to monitor the desired state. Delete one pod nginx-5c95dfd78d-m67ph and a replacement nginx-5c95dfd78d-5mwvr is created automtically. james@lizard:~> kubectl delete pod nginx-5c95dfd78d-m67ph pod \"nginx-5c95dfd78d-m67ph\" deleted james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-5mwvr 2/2 Running 0 95s nginx-5c95dfd78d-5xfm7 2/2 Running 0 34m nginx-5c95dfd78d-bnvgz 2/2 Running 0 48m Rolling update A deployment itself does not manage the number of replicas. It just creates a ReplicaSet and tells how many replicas it should have. Checkout the ReplicaSet created by your deployment: kubectl get replicaset , also -o yaml to see full configuration. james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 3 3 3 20h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d james@lizard:~> kubectl get replicaset -o yaml A deployment can also perform a rolling update. Run watch kubectl command to monitor the process of updating. james@lizard:~> watch kubectl rollout status deployment/nginx Get current deployment image version nginx:1.21 . james@lizard:~> kubectl get deployment nginx -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 20h nginx nginx:1.21 app=nginx Update deployment image to nginx:mainline with the below command. The --record option logs the kubectl command and stores it in the deployment's annotations. james@lizard:~> kubectl set image deployment/nginx nginx=nginx:mainline --record deployment.apps/nginx image updated We will receive message deployment \"nginx\" successfully rolled out from command watch kubectl rollout status deployment/nginx . Let's check the deployment, pods and ReplicaSets available in current namespace. By the command kubectl set image , all pods are running under new replicaset nginx-d64cb58b5 with new image version nginx:mainline . james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 20h nginx nginx:mainline app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 20h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-d64cb58b5 3 3 3 4m24s nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-d64cb58b5-55twx 2/2 Running 0 4m15s 100.64.0.238 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-679bk 2/2 Running 0 4m37s 100.64.0.236 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-k946n 2/2 Running 0 4m25s 100.64.0.237 ip-10-250-0-53.ec2.internal <none> <none> We can see the revision history at annotations in deploymant yaml file. james@lizard:~> kubectl get deployment -o yaml apiVersion: v1 items: - apiVersion: apps/v1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: \"2\" kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:mainline --record=true creationTimestamp: \"2022-06-17T14:37:56Z\" ... ... We can also get the revision hisotry by kubectl rollout history command. Get details by --revision=1 option. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 kubectl set image deployment/nginx nginx=nginx:mainline --record=true james@lizard:~> kubectl rollout history deployment/nginx --revision=1 deployment.apps/nginx with revision #1 Pod Template: Labels: app=nginx pod-template-hash=5c95dfd78d Containers: nginx: Image: nginx:1.21 Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=2 deployment.apps/nginx with revision #2Step 5: Pod Template: Labels: app=nginx pod-template-hash=d64cb58b5 Annotations: kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:mainline --record=true Containers: nginx: Image: nginx:mainline Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none> Update & Rollback Let's do a wrong update of deployment, e.g., set the image version to an not existing tag nginx=nginx:001 as typo. We will see new replicaset nginx-678b495695 is created and only one pod nginx-678b495695-rlgls under the new replicaset with an ImagePullBackOff error. The rollout is stuck with the update of 1 new replica. All pods are still running under replicaset nginx-d64cb58b5 of image nginx:mainline . james@lizard:~> kubectl set image deployment/nginx nginx=nginx:001 --record deployment.apps/nginx image updated james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 1 3 21h nginx nginx:001 app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 21h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-678b495695 1 1 0 66s nginx nginx:001 app=nginx,pod-template-hash=678b495695 nginx-d64cb58b5 3 3 3 77m nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-678b495695-rlgls 1/2 ImagePullBackOff 0 2m6s nginx-d64cb58b5-55twx 2/2 Running 0 77m nginx-d64cb58b5-679bk 2/2 Running 0 78m nginx-d64cb58b5-k946n 2/2 Running 0 77m The deployment specifies a maxUnavailable parameter as part of its update strategy ( kubectl explain deployment.spec.strategy.rollingUpdate ). It defaults to 25%, which means in the demo with 3 replicas, no more than one pod at a time is allowed to be unavailable. That's why the responsible controller does not attempt to patch all the other replicas in parallel. As the attempt to patch the deployment to a new image ailed, we need to roll back the image to nginx:mainline and bring up all pods. Now we can see the status of rollout with three revisions. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 kubectl set image deployment/nginx nginx=nginx:mainline --record=true 3 kubectl set image deployment/nginx nginx=nginx:001 --record=true james@lizard:~> kubectl rollout history deployment/nginx --revision=3 deployment.apps/nginx with revision #3 Pod Template: Labels: app=nginx pod-template-hash=678b495695 Annotations: kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:001 --record=true Containers: nginx: Image: nginx:001 Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none> To roll back from current version (3) to previous version (2), it promotes revision 2 to revision 4 as the latest available revision. There is no revision 2 after that. james@lizard:~> kubectl rollout undo deployment nginx deployment.apps/nginx rolled back james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 3 kubectl set image deployment/nginx nginx=nginx:001 --record=true 4 kubectl set image deployment/nginx nginx=nginx:mainline --record=true Let's verify current deployment, replicaset, and pods after rollback. james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 22h nginx nginx:mainline app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 22h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-678b495695 0 0 0 17m nginx nginx:001 app=nginx,pod-template-hash=678b495695 nginx-d64cb58b5 3 3 3 93m nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-d64cb58b5-55twx 2/2 Running 0 93m 100.64.0.238 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-679bk 2/2 Running 0 93m 100.64.0.236 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-k946n 2/2 Running 0 93m 100.64.0.237 ip-10-250-0-53.ec2.internal <none> <none> Delete deployment After deletion of deployment, all replica, pods of nginx were automatically deleted as well. james@lizard:~> kubectl delete deployment nginx deployment.apps \"nginx\" deleted james@lizard:~> kubectl get deployment No resources found in jh-namespace namespace. james@lizard:~> kubectl get replicaset No resources found in jh-namespace namespace. james@lizard:~> kubectl get pod No resources found in jh-namespace namespace. Create deployment from file The following demo shows an example how to create deployment from yaml file. Create the yaml file 03-deployment.yaml for a new deployment that creates 3 replicas of an nginx image, with version tag latest. james@lizard:~> cat 03-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 Create the deoployment via file 03-deployment.yaml . james@lizard:~> kubectl apply -f 03-deployment.yaml deployment.apps/nginx-deployment created Verify current deployment, replicaset, and pods. james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 38s nginx nginx run=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-658f4cf99f 3 3 3 48s nginx nginx pod-template-hash=658f4cf99f,run=nginx james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-658f4cf99f-74w6d 2/2 Running 0 64s 100.64.0.15 ip-10-250-0-53.ec2.internal <none> <none> nginx-658f4cf99f-7rbtn 2/2 Running 0 64s 100.64.0.12 ip-10-250-0-53.ec2.internal <none> <none> nginx-658f4cf99f-bvkp5 2/2 Running 0 64s 100.64.0.16 ip-10-250-0-53.ec2.internal <none> <none> james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> In above demo, we use image nginx with latest tag. In following demo, I will only change image to nginx:mainline and update the live deployment. Create new yaml file 03-deployment-new.yaml . james@lizard:~> cat 03-deployment-new.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 Show the difference. james@lizard:~> kubectl diff -f 03-deployment-new.yaml ... ... - generation: 1 + generation: 2 ... ... containers: - - image: nginx + - image: nginx:mainline ... ... Update the live version. james@lizard:~> kubectl apply -f 03-deployment-new.yaml deployment.apps/nginx configured Verify current deployment, replicaset, and pods. All pods are running under new replicaset nginx-74db5c7848 with image nginx:mainline . james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 24m nginx nginx:mainline run=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-658f4cf99f 0 0 0 25m nginx nginx pod-template-hash=658f4cf99f,run=nginx nginx-74db5c7848 3 3 3 77s nginx nginx:mainline pod-template-hash=74db5c7848,run=nginx james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-74db5c7848-4dxf2 2/2 Running 0 82s 100.64.0.22 ip-10-250-0-53.ec2.internal <none> <none> nginx-74db5c7848-9lmgx 2/2 Running 0 92s 100.64.0.21 ip-10-250-0-53.ec2.internal <none> <none> nginx-74db5c7848-wqfs9 2/2 Running 0 71s 100.64.0.24 ip-10-250-0-53.ec2.internal <none> <none> Check the rollout hisotry. The image is nginx in revision 1 and nginx:mainline in revision 2. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=1 deployment.apps/nginx with revision #1 Pod Template: Labels: pod-template-hash=658f4cf99f run=nginx Containers: nginx: Image: nginx Port: 80/TCP Host Port: 0/TCP Environment: <none> Mounts: <none> Volumes: <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=2 deployment.apps/nginx with revision #2 Pod Template: Labels: pod-template-hash=74db5c7848 run=nginx Containers: nginx: Image: nginx:mainline Port: 80/TCP Host Port: 0/TCP Environment: <none> Mounts: <none> Volumes: <none> Clean up what we created. james@lizard:~> kubectl delete deployment nginx deployment.apps \"nginx\" deleted Further references: Deployments in K8s concepts documentation Replication controller Labels in K8s Expose application Create deployment Create nginx deployment via below 04-deployment.yaml yaml file. james@lizard:~> cat 04-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 james@lizard:~> kubectl apply -f 04-deployment.yaml deployment.apps/nginx-deployment created We have below resource graph. Pods and replicaset have same label run=nginx . james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment 3/3 3 3 4m7s tier=application james@lizard:~> kubectl get replicaset --show-labels NAME DESIRED CURRENT READY AGE LABELS nginx-deployment-69745449db 3 3 3 4m18s pod-template-hash=69745449db,run=nginx james@lizard:~> kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-69745449db-9g69m 2/2 Running 0 104s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-glrcb 2/2 Running 0 105s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-qkkmw 2/2 Running 0 105s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest Expose deployment In Kubernetes, a Service is an abstraction which defines a logical set of Pods and a policy by which to access them (sometimes this pattern is called a micro-service). The set of Pods targeted by a Service is usually determined by a selector. We have two ways to create a service, commandline and yaml file. Run command kubectl expose deployment <deployment-name> --type=LoadBalancer --port=80 --target-port=80 to expose application. The BTP trail system is to provision a public IP address with option --type=LoadBalancer . It also automatically assigns a cluster-IP and a NodePort in the current setup of the cluster. To create a service that gets only a cluster-IP and does cluster interal load balancing, which can only be called within the cluster from other pods, not via a public IP from the outside, use --type=ClusterIP or leave it away since it is the default. The option --port is that the service should serve on. The option --target-port is the port on the container that the service should direct traffic to. Connect to service via external IP and port number. More detail information can be get via option -o=yaml . james@lizard:~> kubectl expose deployment nginx-deployment --type=LoadBalancer --port=80 --target-port=80 service/nginx-deployment exposed james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR nginx-deployment LoadBalancer 100.106.92.216 xxx.us-east-1.elb.amazonaws.com 80:31114/TCP 11s run=nginx james@lizard:~> kubectl get service --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-deployment LoadBalancer 100.106.92.216 xxx.us-east-1.elb.amazonaws.com 80:31114/TCP 34s tier=application Delete the service just created. james@lizard:~> kubectl delete service nginx-deployment service \"nginx-deployment\" deleted Create nginx service again via yaml file below. The label selector run: nginx matches the labels of deployment/pods run: nginx and create the service. The label tier is tier: application , which is same with deployment. james@lizard:~> cat 04-service.yaml apiVersion: v1 kind: Service metadata: name: nginx-service labels: tier: application spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx type: LoadBalancer james@lizard:~> kubectl apply -f 04-service.yaml service/nginx-service created james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR nginx-service LoadBalancer 100.104.35.35 xxx.elb.amazonaws.com 80:31803/TCP 4m7s run=nginx james@lizard:~> kubectl get service --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service LoadBalancer 100.104.35.35 xxx.us-east-1.elb.amazonaws.com 80:31803/TCP 3m6s tier=application james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment 3/3 3 3 24m tier=application james@lizard:~> kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-69745449db-5r999 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-lf6cc 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-rkrjs 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest Now the resource graph is like below. Expose pod In following, I will create the pod as we did before. james@lizard:~> kubectl apply -f 02-sample-pod.yaml pod/my-first-pod created james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 10s security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-9g69m 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-glrcb 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-qkkmw 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest Add the label run=nginx to the pod created above. james@lizard:~> kubectl label pod my-first-pod run=nginx pod/my-first-pod labeled james@lizard:~> kubectl get pod -l run=nginx NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 87s nginx-deployment-69745449db-9g69m 2/2 Running 0 20m nginx-deployment-69745449db-glrcb 2/2 Running 0 20m nginx-deployment-69745449db-qkkmw 2/2 Running 0 20m Expose it as LoadBalancer with kubectl expose pod . james@lizard:~> kubectl expose pod my-first-pod --type=LoadBalancer service/my-first-pod exposed We now have two services, one is for the pod my-first-pod , another is for the deployment nginx-deployment . They're exposed by different services. james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR my-first-pod LoadBalancer 100.108.11.185 xxx.us-east-1.elb.amazonaws.com 15090:30864/TCP,80:30133/TCP 20s run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest nginx-service LoadBalancer 100.104.35.35 xxx.us-east-1.elb.amazonaws.com 80:31803/TCP 10m run=nginx Check the correctness of the label - selector combination by running the query manually. Get the selector from the service by running kubectl get service <service-name> -o yaml . Use the <key>: <value> pairs stored in service.spec.selector to get all pods with the corresponding label set, kubectl get pods -l <key>=<value> . These pods are what the service is selecting. The selector often used within service matches the selector specified within the deployment. Verify the service from external IP and port number. There would be certificate issue to access xxx.us-east-1.elb.amazonaws.com, leave it at the moment and will be solve in ConfigMaps and Secrets . Clean up and remove the pod as well as the service created above. james@lizard:~> kubectl delete service my-first-pod service \"my-first-pod\" deleted james@lizard:~> kubectl delete pod my-first-pod pod \"my-first-pod\" deleted james@lizard:~> kubectl delete service nginx-service service \"nginx-service\" deleted james@lizard:~> kubectl delete deployment nginx-deployment deployment.apps \"nginx-deployment\" deleted Further references: Services in K8s Connecting a front end to a backend Cluster internal DNS Persistence Docker has a concept of volumes, though it is somewhat looser and less managed. A Docker volume is a directory on disk or in another container. Docker provides volume drivers, but the functionality is somewhat limited. Kubernetes supports many types of volumes . A Pod can use any number of volume types simultaneously. A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany). Check current persistent volume and corresponding claims. james@lizard:~> kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-shoot--kyma--eb68ebe-661d5e59-a895-4e02-916e-8621038a7ca3 20Gi RWO Delete Bound kyma-system/serverless-docker-registry default 7d pv-shoot--kyma--eb68ebe-92909d6a-b809-42f9-8f91-17f0c9a2ccbb 10Gi RWO Delete Bound kyma-system/prometheus-monitoring-prometheus-db-prometheus-monitoring-prometheus-0 default 7d pv-shoot--kyma--eb68ebe-d1f0cad5-60a6-41f7-b9ab-6a3f4524b3c4 1Gi RWO Delete Bound kyma-system/monitoring-grafana default 7d pv-shoot--kyma--eb68ebe-d48cc603-499b-40a6-896c-6e0a7d32cfde 10Gi RWO Delete Bound kyma-system/rafter-minio default 7d james@lizard:~> kubectl get pvc No resources found in jh-namespace namespace. Create PV and PVC In general, we create a PersistentVolume (PV) first and then bind it to a PersistentVolumeClaim (PVC). PVC are bound to a namespace, PV resource are not. When there is a fitting PV, it can be bound to any PVC in any namespace. There is some conflict potential, if your PV is claimed by the others. The storage classes overcomes this problem. Create the resource: kubectl create -f 05-pvc.yaml and verify if the claim has been created. james@lizard:~> cat 05-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc spec: storageClassName: default accessModes: - ReadWriteOnce resources: requests: storage: 1Gi james@lizard:~> kubectl get storageclass NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE default (default) ebs.csi.aws.com Delete WaitForFirstConsumer true 6d15h gp2 ebs.csi.aws.com Delete WaitForFirstConsumer true 6d15h james@lizard:~> kubectl apply -f 05-pvc.yaml persistentvolumeclaim/nginx-pvc created james@lizard:~> kubectl get pvc -o wide NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE nginx-pvc Pending default 67s Filesystem The status if PVC is Pending . Take a closer look with kubectl describe pvc <pvc-name> . james@lizard:~> kubectl describe pvc nginx-pvc Name: nginx-pvc Namespace: jh-namespace StorageClass: default Status: Pending Volume: Labels: <none> Annotations: <none> Finalizers: [kubernetes.io/pvc-protection] Capacity: Access Modes: VolumeMode: Filesystem Used By: <none> Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal WaitForFirstConsumer 11s (x10 over 2m19s) persistentvolume-controller waiting for first consumer to be created before binding Attach the PVC The PVC's access mode is ReadWriteOnce . we need reduce the number of replicas in the deployment to 1 . Modify file 05-deployment-with-pvc.yaml like below. apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: tier: application spec: replicas: 1 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: volumes: - name: content-storage persistentVolumeClaim: claimName: nginx-pvc # readOnly: true containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 volumeMounts: - mountPath: \"/usr/share/nginx/html\" name: content-storage # readOnly: true Create the deployment nginx-deployment with 1 replicaset and consume pvc nginx-pvc . james@lizard:~> kubectl apply -f 05-deployment-with-pvc.yaml deployment.apps/nginx-deployment created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 1/1 1 1 30s james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-84757d96f5-r2gqz 2/2 Running 0 105s The status of PVC is now Bound instead of Pending before. james@lizard:~> kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Bound pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b 1Gi RWO default 8m51s james@lizard:~> kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-shoot--kyma--eb68ebe-661d5e59-a895-4e02-916e-8621038a7ca3 20Gi RWO Delete Bound kyma-system/serverless-docker-registry default 7d1h pv-shoot--kyma--eb68ebe-92909d6a-b809-42f9-8f91-17f0c9a2ccbb 10Gi RWO Delete Bound kyma-system/prometheus-monitoring-prometheus-db-prometheus-monitoring-prometheus-0 default 7d1h pv-shoot--kyma--eb68ebe-d1f0cad5-60a6-41f7-b9ab-6a3f4524b3c4 1Gi RWO Delete Bound kyma-system/monitoring-grafana default 7d1h pv-shoot--kyma--eb68ebe-d48cc603-499b-40a6-896c-6e0a7d32cfde 10Gi RWO Delete Bound kyma-system/rafter-minio default 7d1h pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b 1Gi RWO Delete Bound jh-namespace/nginx-pvc default 6m51s By executing below commands, we can get more details on pvc and pv. james@lizard:~> kubectl describe pvc nginx-pvc james@lizard:~> kubectl describe pv pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b Tips: Use kubectl get pvc <pcv-name> to get the name of the bounded persistent volume. Use kubectl get pv <pv-name> -o json | jq \".spec.gcePersistentDisk\" to get the name of the physical disk used by the persistent volume. Use kubectl get nodes -o yaml | grep <physical-disk-name> to see if the physical disk is still conected to a node. Further references: descripton of the volumes API how to use PV & PVC storage classes volume snapshots ConfigMaps and Secrets ConfigMaps and secrets build generic images and run them with a specific configuration in an secured environment. Clean up the deployments, services, PVCs. Create PVC Create new file 06-pvc.yaml like below james@lizard:~> cat 06-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc spec: storageClassName: default accessModes: - ReadWriteOnce resources: requests: storage: 1Gi james@lizard:~> kubectl apply -f 06-pvc.yaml persistentvolumeclaim/nginx-pvc-07 created james@lizard:~> kubectl --kubeconfig=$KUBECONFIG get persistentvolumeclaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Pending default 15s Create certificate Create a new certificate. james@lizard:~> openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /opt/nginx.key -out /opt/nginx.crt -subj \"/CN=nginxsvc/O=nginxsvc\" Generating a RSA private key ................................+++++ ..........+++++ writing new private key to '/opt/nginx.key' ----- Store certificate In order to use the certificate with nginx, we need to add it to kubernetes and store it in a secret resource of type tls in the namespace. Kubernetes will change the names of the files to a standardized string, e.g., from nginx.crt to tls.crt . james@lizard:~> kubectl create secret tls nginx-sec --cert=/opt/nginx.crt --key=/opt/nginx.key secret/nginx-sec created james@lizard:~> kubectl get secret nginx-sec NAME TYPE DATA AGE nginx-sec kubernetes.io/tls 2 29m Get details of nginx-sec. james@lizard:~> kubectl describe secret nginx-sec Name: nginx-sec Namespace: jh-namespace Labels: <none> Annotations: <none> Type: kubernetes.io/tls Data ==== tls.crt: 1164 bytes tls.key: 1704 bytes Create configuration Create a configuration and store certificate secret to kubernetes, which is enable nginx to serve HTTPS traffic on port 443 using a certificate located at directory /etc/nginx/ssl/ . Download from gitHub or create the file default.conf with the following content. Ensure the file's name is default.conf . Ensure the values for ssl_certificate and ssl_certificate_key match the names of the files within the nginx-sec . Output the files are named tls.crt and tls.key in the secret as well as the configuration. The location /etc/nginx/ssl/ in the filesystem will be set via the volumeMount, when you create your deployment. Be noted, if called, /healthz will * return a status code 200 to satisfy a liveness probe. james@lizard:~> cat default.conf server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; listen 443 ssl; root /usr/share/nginx/html; index index.html; server_name localhost; ssl_certificate /etc/nginx/ssl/tls.crt; ssl_certificate_key /etc/nginx/ssl/tls.key; location / { try_files $uri $uri/ =404; } location /healthz { access_log off; return 200 'OK'; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html/; } } Upload the configuration Run kubectl create configmap nginxconf --from-file=<path>/default.conf to create a configMap resource with the corresponding content from default.conf . james@lizard:~> kubectl create configmap nginx-configmap --from-file=default.conf configmap/nginxconf-0013 created james@lizard:~> kubectl get configmap nginx-configmap NAME DATA AGE nginx-configmap 1 25s Combine into deployment Combine the PVC, secret and configMap in a new deployment. As a result, nginx should display the custom index.html page, serve HTTP traffic on port 80 and HTTPS on port 443. There are 3 volumes specified as part of deployment.spec.template.spec.volumes ( pvc , configMap and secret ). Each item of the volumes list defines local or pod-internal name and references the actual Kubernetes object. These 3 volumes should be used and mounted to a specific location within the container (defined in deployment.spec.template.spec.containers.volumeMount ). The local or pod-internal name is used for the name field. Use app: nginx-https as label/selector for the secured nginx. james@lizard:~> cat 06-deployment-https.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment-https labels: tier: application spec: replicas: 1 selector: matchLabels: app: nginx-https template: metadata: labels: app: nginx-https spec: volumes: - name: html-storage persistentVolumeClaim: claimName: nginx-pvc readOnly: true - name: tls-secret secret: secretName: nginx-sec - name: nginx-configmap configMap: name: nginx-configmap containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 name: http - containerPort: 443 name: https livenessProbe: httpGet: path: /healthz port: http initialDelaySeconds: 3 periodSeconds: 5 volumeMounts: - mountPath: \"/usr/share/nginx/html\" name: html-storage readOnly: true - mountPath: /etc/nginx/ssl name: tls-secret readOnly: true - mountPath: /etc/nginx/conf.d name: nginx-configmap Create the deployment. james@lizard:~> kubectl apply -f 06-deployment-https.yaml deployment.apps/nginx-deployment-https created james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment-https 1/1 1 1 5m45s tier=application james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 6m41s app=nginx-https,pod-template-hash=7cf8f66cb4,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-https,service.istio.io/canonical-revision=latest Get more details about pod. james@lizard:~> kubectl describe pods nginx-deployment-https-7cf8f66cb4-mv2sb Resource graph likes this. Create service Create a new service to expose the deployment nginx-deployment-https . Make sure the labels tier: application used in the deployment and the selector app: nginx-https specified by the service match. james@lizard:~> cat 06-service-https.yaml apiVersion: v1 kind: Service metadata: name: nginx-service-https labels: tier: application spec: ports: - port: 80 protocol: TCP name: http - port: 443 protocol: TCP name: https selector: app: nginx-https type: LoadBalancer james@lizard:~> kubectl apply -f 06-service-https.yaml service/nginx-service-https created james@lizard:~> kubectl get services --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 80s tier=application james@lizard:~> kubectl get services --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 46s tier=application Resource graph looks like it now. Validation: both http and https failed. james@lizard:~> curl -v -k https://xxx.us-east-1.elb.amazonaws.com:443 * Trying <external IP>:443... * TCP_NODELAY set * Connected to xxx.elb.amazonaws.com (<external IP>) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * TLSv1.3 (OUT), TLS handshake, Client hello (1): * TLSv1.3 (IN), TLS handshake, Server hello (2): * TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8): * TLSv1.3 (IN), TLS handshake, Request CERT (13): * TLSv1.3 (IN), TLS handshake, Certificate (11): * TLSv1.3 (IN), TLS handshake, CERT verify (15): * TLSv1.3 (IN), TLS handshake, Finished (20): * TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.3 (OUT), TLS handshake, Certificate (11): * TLSv1.3 (OUT), TLS handshake, Finished (20): * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 * ALPN, server accepted to use h2 * Server certificate: * subject: [NONE] * start date: Jun 20 08:09:07 2022 GMT * expire date: Jun 21 08:11:07 2022 GMT * issuer: O=cluster.local * SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway. * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Using Stream ID: 1 (easy handle 0x55663ef83850) > GET / HTTP/2 > Host: xxx.us-east-1.elb.amazonaws.com > User-Agent: curl/7.66.0 > Accept: */* > * TLSv1.3 (IN), TLS alert, unknown (628): * OpenSSL SSL_read: error:1409445C:SSL routines:ssl3_read_bytes:tlsv13 alert certificate required, errno 0 * Failed receiving HTTP2 data * OpenSSL SSL_write: SSL_ERROR_ZERO_RETURN, errno 0 * Failed sending HTTP2 data * Connection #0 to host axxx.us-east-1.elb.amazonaws.com left intact curl: (56) OpenSSL SSL_read: error:1409445C:SSL routines:ssl3_read_bytes:tlsv13 alert certificate required, errno 0 james@lizard:~> curl -v http://xxx.us-east-1.elb.amazonaws.com:80 * Trying <external IP>:80... * TCP_NODELAY set * Connected to xxx.us-east-1.elb.amazonaws.com (<external IP>) port 80 (#0) > GET / HTTP/1.1 > Host: xxx.us-east-1.elb.amazonaws.com > User-Agent: curl/7.66.0 > Accept: */* > * Empty reply from server * Connection #0 to host xxx.us-east-1.elb.amazonaws.com left intact curl: (52) Empty reply from server Further references: secrets in k8s options to use a configMap Ingress Ingress resources allow us to expose services through a URL. We can configure an Ingress so that traffic can be directed to different services, depending on the URL that is used for a request. Find out the cluster's and project's names: james@lizard:~> echo \"Clustername: $(kubectl config view -o json | jq \".clusters[0].cluster.server\" | cut -d. -f2)\"; echo \"Projectname: $(kubectl config view -o json | jq \".clusters[0].cluster.server\" | cut -d. -f3)\" Clustername: eb68ebe Projectname: kyma Create 07-ingress.yaml yaml file to create below resources: Deployment nginx-simple . The initContainers writes a string to and index.html on an emptyDir volume. Service nginx-simple-service . Ingress nginx-simple-ingress . james@lizard:~> cat 07-ingress.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-simple labels: tier: application spec: replicas: 1 selector: matchLabels: app: nginx-simple template: metadata: labels: app: nginx-simple spec: volumes: - name: index-html emptyDir: {} initContainers: - name: setup image: alpine:latest command: - /bin/sh - -c - echo This is a simple nginx! > /work-dir/index.html volumeMounts: - name: index-html mountPath: \"/work-dir\" containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 volumeMounts: - name: index-html mountPath: /usr/share/nginx/html --- apiVersion: v1 kind: Service metadata: name: nginx-simple-service labels: tier: networking spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: nginx-simple type: ClusterIP --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx-simple-ingress annotations: nginx.ingress.kubernetes.io/proxy-connect-timeout: \"61\" nginx.ingress.kubernetes.io/rewrite-target: /$1 spec: rules: - host: <namspace-number>-nginx-simple.ingress.<cluster-name>.<project-name>.shoot.canary.k8s-hana.ondemand.com http: paths: - path: /my-app(.*) pathType: Prefix backend: service: name: nginx-simple-service port: number: 80 Craete resources. james@lizard:~> kubectl apply -f 07-ingress.yaml deployment.apps/nginx-simple created service/nginx-simple-service created ingress.networking.k8s.io/nginx-simple-ingress created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment-https 1/1 1 1 5h50m nginx-simple 1/1 1 1 51s james@lizard:~> kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 5h25m nginx-simple-service ClusterIP 100.106.164.62 <none> 80/TCP 82s james@lizard:~> kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE nginx-simple-ingress <none> <your host> 80 2m6s james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 5h53m nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 3m58s http:// https:// Annotations Annotations are part of the metadata section and can be written directly to the yaml file as well as added via kubectl annotate . Annotations are also key-value pairs. Most commonly annotations are used to store additional information, describe a resource more detailed or tweak it's behavior. Further references: annotations init containers debugging of init containers ingress list of ingress controllers nginx ingress controller StatefulSet Like a Deployment, a StatefulSet manages Pods that are based on an identical container spec. Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling. Build StatefulSet Create yaml file 08-statefulset.yaml to create a service nginx-stateful and a statefulset web mapped to service nginx-stateful . james@lizard:~> cat 08-statefulset.yaml apiVersion: v1 kind: Service metadata: name: nginx-stateful labels: app: nginx-stateful spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx-stateful --- apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: serviceName: \"nginx-stateful\" replicas: 2 selector: matchLabels: app: nginx-stateful template: metadata: labels: app: nginx-stateful spec: initContainers: - name: setup image: alpine:latest command: - /bin/sh - -c - echo $(hostname) >> /work-dir/index.html volumeMounts: - name: www mountPath: /work-dir containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi Create statefulset resource. We can watch the upcoming new pods via watch kubectl get pods . james@lizard:~> kubectl apply -f 08-statefulset.yaml service/nginx-stateful created statefulset.apps/web created james@lizard:~> kubectl get service nginx-stateful NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-stateful ClusterIP None <none> 80/TCP 11h james@lizard:~> kubectl get statefulset web NAME READY AGE web 2/2 11h As we set replicas: 2 in the yaml file, be noted that the pod name consists of the statefulset's name + the index, not any randomly generated string (as with deployments). james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 41h nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 35h web-0 2/2 Running 0 11h web-1 2/2 Running 0 11h As we defined PVC Template volumeClaimTemplates with name www , we can find two new PVCs created as well. james@lizard:~> kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Bound pv-shoot--kyma--eb68ebe-b0f174a8-7800-43bb-86bd-751a5505363b 1Gi RWO default 2d www-web-0 Bound pv-shoot--kyma--eb68ebe-ce950e1d-0c5f-4ab2-9aa1-7bb3c834cb2b 1Gi RWO default 11h www-web-1 Bound pv-shoot--kyma--eb68ebe-dc954620-f4ec-48bd-89bd-737b59687794 1Gi RWO default 11h Quickly spin up a temporary pod and directly connect to it. james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash Within pod's shell context: run nslookup [pod-name].[service-name] to check if individual pods are accessible via the service. download the index.html page of each instance using wget -q -O - [pod-name].[service-name] . james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # ls bin dev etc home lib media mnt opt proc root run sbin srv sys tmp usr var / # nslookup web-0.nginx-stateful Server: 100.104.0.10 Address: 100.104.0.10:53 ** server can't find web-0.nginx-stateful: NXDOMAIN ** server can't find web-0.nginx-stateful: NXDOMAIN / # wget web-0.nginx-stateful Connecting to web-0.nginx-stateful (100.64.0.35:80) saving to 'index.html' index.html 100% |************************************************************************************************| 6 0:00:00 ETA 'index.html' saved / # ls bin etc index.html media opt root sbin sys usr dev home lib mnt proc run srv tmp var / # cat index.html web-0 / # exit pod \"dns-test\" deleted StatefulSets guarantee stable/reliable names, and it won't change over time - even when the pod gets killed and re-created. Delete the pods web-0 of the StatefulSet web and the same will be created automatically per replicaset. james@lizard:~> kubectl delete pods web-0 pod \"web-0\" deleted james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 2d4h nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 47h web-0 2/2 Running 0 50s web-1 2/2 Running 0 22h Rerun kubectl run dns-test again, and we can see there are two pod web-0 now because the initContainer wrote the \"new\" hostname to the index.html page, james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # nslookup web-0.nginx-stateful Server: 100.104.0.10 Address: 100.104.0.10:53 ** server can't find web-0.nginx-stateful: NXDOMAIN ** server can't find web-0.nginx-stateful: NXDOMAIN / # wget web-0.nginx-stateful Connecting to web-0.nginx-stateful (100.64.0.198:80) saving to 'index.html' index.html 100% |************************************************************************************************| 12 0:00:00 ETA 'index.html' saved / # ls bin etc index.html media opt root sbin sys usr dev home lib mnt proc run srv tmp var / # cat index.html web-0 web-0 / # exit pod \"dns-test\" deleted Increase the number of replicas to 3. james@lizard:~> kubectl edit sts web statefulset.apps/web edited If we set partition parameter with value \"2\", we will have 3 replicas with index [0,1,2], and will limit the effect of an update to replica #2 only. The partition parameter controls the replicas that are patched based on an \"equals or greater\" evaluation of the ordinal index of the replica. james@lizard:~> kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"type\":\"RollingUpdate\",\"rollingUpdate\":{\"partition\":2}}}}' statefulset.apps/web patched Use the json path with the patch command to change the image version in your podSpec template: james@lizard:~> kubectl patch statefulset web --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/image\", \"value\":\"nginx:1.13.12\"}]' statefulset.apps/web patched The pod web-2 will be terminated and re-created. The image version of the updated pod: james@lizard:~> kubectl get po web-2 --template '{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}' eu.gcr.io/kyma-project/external/istio/proxyv2:1.13.2-distrolessnginx:mainline Set \"partition\" to \"0\" to move all replicas to the new version. james@lizard:~> kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"type\":\"RollingUpdate\",\"rollingUpdate\":{\"partition\":0}}}}' statefulset.apps/web patched Further references statefulset documentation cassandara deployed as a statefulset init containers debugging of init containers Network Policy Network policies namespace based to help us restrict access to the nginx deployment. From within any pod that is not labeled correctly we will not be able to access our nginx instances. The network policy features two selector sections: networkpolicy.spec.podSelector.matchLabels determines the target pods -> traffic to all matching pods will be filtered (allow or drop) networkpolicy.spec.ingress.from lists the sources, from which traffic is accepted. There are different ways to identify trusted sources by podSelector.matchLabels - to filter for labels of pods in the same namespace by namespaceSelector.matchLabels - to filter for traffic from a specific namespace (can be combined with podSelector) by ipBlock.cidr - an IP address range defined as trustworthy Let's check the connection from a random pod tester and run wget --timeout=1 -q -O - <your-service-name> within the pod to send an HTTP request to the nginx service nginx-simple-service . james@lizard:~> kubectl get pod -l app=nginx-simple NAME READY STATUS RESTARTS AGE nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 2d james@lizard:~> kubectl run tester -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # wget --timeout=1 -q -O - nginx-simple-service This is a simple nginx! / # exit pod \"tester\" deleted Now deploy the networkpolicy nginx-access which applys to pod label app=nginx-simple . james@lizard:~> kubectl get networkpolicy No resources found in jh-namespace namespace. james@lizard:~> kubectl apply -f 09-network-policy.yaml networkpolicy.networking.k8s.io/nginx-access created james@lizard:~> kubectl get networkpolicy NAME POD-SELECTOR AGE nginx-access app=nginx-simple 71s Let's send HTTP request from a random pod tester to the nginx service nginx-simple-service again. As I did not maintain correct IPs in ingress, hence the connection to pod with label app=nginx-simple fails now after the networkpolicy nginx-access deployed. james@lizard:~> kubectl run tester -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # wget --timeout=1 -q -O - nginx-simple-service wget: download timed out / # exit pod \"tester\" deleted Further references network policy basics example / tutorial on network policies Helming Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Refer to installation guide and binary release and source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed. Step 2: looking for charts? Helm organizes applications in so called charts, which contain parameters you can set during installation. By default, helm (v3) is not configured to search any remote repository for charts. So as a first step, add the stable repository, which hosts charts maintained on github.com. Add repo charts . Note: The charts repo is officially deprecated. The helm organization is now using Artifact Hub. james@lizard:~> helm repo add stable https://charts.helm.sh/stable \"stable\" has been added to your repositories james@lizard:~> helm repo list NAME URL stable https://charts.helm.sh/stable Check out the available charts and search for the chaoskube : james@lizard:~> helm search repo chaoskube NAME CHART VERSION APP VERSION DESCRIPTION stable/chaoskube 3.3.2 0.21.0 DEPRECATED Chaoskube periodically kills random ... Run the following command to install the chaoskube chart with new name chaoskube-jh . The --set flags specifies parameters of the chart. The parameter namespaces defines in which namespaces the chaoskube will delete pods. rbac.serviceAccountName specifies which serviceAccount the scheduled chaoskube pod will use. james@lizard:~> helm install chaoskube-jh stable/chaoskube --set namespaces=jh-namespace --set rbac.serviceAccountName=chaoskube --debug We can get the deployment chaoskube-jh now. james@lizard:~> kubectl get deployment chaoskube-jh NAME READY UP-TO-DATE AVAILABLE AGE chaoskube-jh 0/1 0 0 3m36s Inspect the chaoskube we deployed. james@lizard:~> helm status chaoskube-jh NAME: chaoskube-jh LAST DEPLOYED: Wed Jun 22 23:25:05 2022 NAMESPACE: jh-namespace STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: chaoskube is running and will kill arbitrary pods every 10m. You can follow the logs to see what chaoskube does: POD=$(kubectl -n jh-namespace get pods -l='app.kubernetes.io/instance=chaoskube-jh' --output=jsonpath='{.items[0].metadata.name}') kubectl -n jh-namespace logs -f $POD You are running in dry-run mode. No pod is actually terminated. Clean up chaoskube-jh . james@lizard:~> helm delete chaoskube-jh release \"chaoskube-jh\" uninstalled james@lizard:~> helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION Clean up all resources created in this demo. # kubectl detele deployment nginx-simple nginx-deployment-https # kubectl delete deployment nginx-simple nginx-deployment-https # kubectl delete sts web # kubectl delete ingress nginx-simple-ingress # kubectl delete service nginx-service-https nginx-simple-service nginx-stateful # kubectl delete networkpolicy nginx-access # kubectl delete pvc nginx-pvc www-web-0 www-web-1 www-web-2 # kubectl delete configmap nginx-configmap # kubectl delete secret nginx-sec","title":"Tutorials: SAP BTP trail account"},{"location":"cloud/KubernetesTutorials-BTP-trail/#tutorials-sap-btp-trail-account","text":"","title":"Tutorials: SAP BTP trail account"},{"location":"cloud/KubernetesTutorials-BTP-trail/#kubectl-basics","text":"Register account of SAP BTP trail system . I am using BTP Kyma runtime for the demo. Choose the entitlements for k8sdev subdomain: Alert Notification: Standard plan Continuous Integration & Delivery: default (Application) or the trial (Application) or free (Application) plans which are not charged Kyma runtime: any available plan in the list (trial and free are not charged) Launchpad Service: standard (Application) or free (Application) SAP HANA Cloud: hana SAP HANA Schemas & HDI Containers: hdi-shared Enable Kyma runtime in k8sdev subdomain, and download kubeconfig file to local directory ~/.kube/ and rename it to ~/.kube/config-btp-kyma.yaml . If the directory ~/.kube/ does not exist, create it. Add below line into file /etc/profile.local and make it effected by command source /etc/profile.local . export KUBECONFIG=$HOME/.kube/config-btp-kyma.yaml","title":"kubectl basics"},{"location":"cloud/KubernetesTutorials-BTP-trail/#check-current-kubeconfig-file","text":"Use the kubectl config command to get current context of configuration file. james@lizard:~> echo $KUBECONFIG /home/james/.kube/config-btp-kyma.yaml james@lizard:~> kubectl config view james@lizard:~> kubectl config get-contexts Using SAP BTP, brew and oidc-login need to be installed. Install krew (https://krew.sigs.k8s.io/docs/user-guide/setup/install/) james@lizard:~> ( set -x; cd \"$(mktemp -d)\" && OS=\"$(uname | tr '[:upper:]' '[:lower:]')\" && ARCH=\"$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\\(arm\\)\\(64\\)\\?.*/\\1\\2/' -e 's/aarch64$/arm64/')\" && KREW=\"krew-${OS}_${ARCH}\" && curl -fsSLO \"https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz\" && tar zxvf \"${KREW}.tar.gz\" && ./\"${KREW}\" install krew ) Append below two lines to file /etc/profile.local make it effected by command source /etc/profile.local export PATH=$HOME/.krew/bin:$PATH Install oidc-login (https://github.com/int128/kubelogin#setup) . james@lizard:~> kubectl krew install oidc-login","title":"Check current kubeconfig file."},{"location":"cloud/KubernetesTutorials-BTP-trail/#check-the-nodes","text":"Use the kubectl get nodes command to get the basic information about the clusters' nodes. There will be a pop-up web page for authentication with registered email address and password. More information can be found by appending --help to command. james@lizard:~> kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 47m v1.21.10 Get nodes information with different format output, e.g., yaml format. james@lizard:~> kubectl get nodes -o yaml Get detailed information about a node by running kubectl describe node <node-name> or kubectl get node <node-name>. . james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 53m v1.21.10 james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-10-250-0-53.ec2.internal Ready <none> 56m v1.21.10 10.250.0.53 <none> Garden Linux 576.8 5.10.109-garden-cloud-amd64 docker://20.10.11+dfsg1 james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o yaml james@lizard:~> kubectl get nodes ip-10-250-0-53.ec2.internal -o json james@lizard:~> kubectl describe nodes ip-10-250-0-53.ec2.internal Get namespaces information by running kubectl get namespaces . james@lizard:~> kubectl get namespaces NAME STATUS AGE compass-system Active 58m default Active 62m istio-system Active 55m kube-node-lease Active 62m kube-public Active 62m kube-system Active 62m kyma-integration Active 52m kyma-system Active 55m Get running pods under specific namespace by running kubectl get pods -n <namespace> . james@lizard:~> kubectl get pods james@lizard:~> kubectl get pods -n kube-system","title":"Check the nodes"},{"location":"cloud/KubernetesTutorials-BTP-trail/#check-the-proxy","text":"We can use kubectl proxy command to open a tunnel to the API server and make it available locally - usually on localhost:8001 / 127.0.0.1:8001. When I want to explore the API, this is an easy way to gain access. Run the command kubectl proxy & and open http://localhost:8001/api/v1 in browser. Just opening http://localhost:8001 will return an error because we are only allowed to access certain parts of the API. Hence the API path is important james@lizard:~> kubectl proxy & [1] 102358 james@lizard:~> Starting to serve on 127.0.0.1:8001 Example, get available API groups and so on via below link: http://127.0.0.1:8001/ http://127.0.0.1:8001/api/v1 http://127.0.0.1:8001/api/v1/namespaces http://127.0.0.1:8001/api/v1/namespaces/default http://127.0.0.1:8001/api/v1/namespaces/sock-shop/pods","title":"Check the proxy"},{"location":"cloud/KubernetesTutorials-BTP-trail/#check-api-versions-api-resources","text":"Get an overview of existing APIs by running kubectl api-versions and kubectl api-resources . james@lizard:~> kubectl api-resources -o wide james@lizard:~> kubectl api-versions Namespace is a cluster, which includes services. Service may be on a node, may be not.","title":"Check api-versions &amp; api-resources"},{"location":"cloud/KubernetesTutorials-BTP-trail/#access-as-application","text":"If I access kubernetes as an application rather than an administrator, I cannot use the kubectl . Instead of kubectl I can use the program curl . I have to send HTTP requests to the cluster. asking for the available nodes. make sure kubectl proxy is running and serving on http://localhost:8001/ . Execute command below with a -v=9 flag, it shows all the information needed. james@lizard:~> kubectl get nodes Go through the command's output and find the correct curl request below. curl -v -XGET -H \"Accept: application/json;as=Table;v=v1;g=meta.k8s.io,application/json;as=Table;v=v1beta1;g=meta.k8s.io,application/json\" -H \"User-Agent: kubectl/v1.24.1 (linux/amd64) kubernetes/3ddd0f4\" 'https://api.eb68ebe.kyma.ondemand.com/api/v1/nodes?limit=500' Further information & references: There is a forum-like page hosted by K8s with lots of information around kubectl and how to use it best. Manage multiple clusters and multiple config files kubectl command documentation Shell autocompletion kubectl cheat sheet jsonpath in kubectl","title":"Access as application"},{"location":"cloud/KubernetesTutorials-BTP-trail/#work-on-pod","text":"","title":"Work on pod"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-pod","text":"Create new namespace jh-namespace for my demo. james@lizard:~> kubectl create namespace jh-namespace namespace/jh-namespace created james@lizard:~> kubectl get ns NAME STATUS AGE compass-system Active 2d1h default Active 2d1h istio-system Active 2d jh-namespace Active 7s kube-node-lease Active 2d1h kube-public Active 2d1h kube-system Active 2d1h kyma-integration Active 2d kyma-system Active 2d Get current config information, which will be referred by following commands. james@lizard:~> kubectl config view Get current contexts. james@lizard:~> kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * shoot--kyma--eb68ebe shoot--kyma--eb68ebe shoot--kyma--eb68ebe Update context with new namespace by command kubectl config set-context <context name> --cluster=<cluster name> --namespace=jh-namespace --user=<authinfo name> . Key information is from kubectl config view and kubectl config get-contexts . Verify if above change is effective by command kubectl config get-contexts . Create file 02-sample-pod.yaml . apiVersion: v1 kind: Pod metadata: name: my-first-pod spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 Create pod with file 02-sample-pod.yaml . james@lizard:~> kubectl create -n jh-namespace -f ./02-sample-pod.yaml pod/my-first-pod created Verify status of the pod just created. james@lizard:~> kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-first-pod 2/2 Running 0 6m43s 100.64.0.165 ip-10-250-0-53.ec2.internal <none> <none>","title":"Create pod"},{"location":"cloud/KubernetesTutorials-BTP-trail/#track-pod","text":"Check logs of the pod just created. james@lizard:~> kubectl logs my-first-pod In case logs or describe or any other of the output generating commands don't help us to get to the root cause of an issue, we can use use kubectl exec -it <my-pod> -- bash command to look into it ourselves. james@lizard:~> kubectl exec -it my-first-pod -- bash root@my-first-pod:/# ls bin boot dev docker-entrypoint.d docker-entrypoint.sh etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@my-first-pod:/# cd bin root@my-first-pod:/bin# ls bash cp dir egrep gunzip login mktemp nisdomainname rm sleep tempfile uncompress zcmp zgrep cat dash dmesg false gzexe ls more pidof rmdir stty touch vdir zdiff zless chgrp date dnsdomainname fgrep gzip lsblk mount pwd run-parts su true wdctl zegrep zmore chmod dd domainname findmnt hostname mkdir mountpoint rbash sed sync umount ypdomainname zfgrep znew chown df echo grep ln mknod mv readlink sh tar uname zcat zforce root@my-first-pod:/bin# exit Execute command kubectl explain pod.spec will get details of Spec segment of Pod kind in yaml file. We can check the official API reference of the pod resource for help or use kubectl explain pod to get a command-line based description of the resource. By appending . to the resource type, the explain command will provide more details on the specified field. james@lizard:~> kubectl explain pod.kind james@lizard:~> kubectl explain pod.spec james@lizard:~> kubectl explain pod.spec.containers james@lizard:~> kubectl explain pod.spec.containers.name","title":"Track pod"},{"location":"cloud/KubernetesTutorials-BTP-trail/#label-pod","text":"Get pod's label with option --show-labels . james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 5h47m james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 5h48m security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Add two labels to the pod pod my-first-pod . james@lizard:~> kubectl label pod my-first-pod nginx=mainline pod/my-first-pod labeled james@lizard:~> kubectl label pod my-first-pod env=demo pod/my-first-pod labeled james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 6h5m env=demo,nginx=mainline,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Search pod by labels. james@lizard:~> kubectl get pod -l env=demo NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 6h8m james@lizard:~> kubectl get pod -l env=demo,nginx=mainline NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 12h james@lizard:~> kubectl get pod -l env=training No resources found in jh-namespace namespace. Remove label james@lizard:~> kubectl label pods my-first-pod env- pod/my-first-pod unlabeled james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 24h nginx=mainline,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest Describe pod. james@lizard:~> kubectl describe pod my-first-pod Delete pod. Run watch kubectl get pods to monitor the pod status. james@lizard:~> kubectl delete pod my-first-pod pod \"my-first-pod\" deleted james@lizard:~> watch kubectl get pods","title":"Label pod"},{"location":"cloud/KubernetesTutorials-BTP-trail/#label-node","text":"Add label to node. james@lizard:~> kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 james@lizard:~> kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1f,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-250-0-53.ec2.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.xlarge,node.kubernetes.io/role=node,topology.ebs.csi.aws.com/zone=us-east-1f,topology.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1f,worker.garden.sapcloud.io/group=cpu-worker-0,worker.gardener.cloud/kubernetes-version=1.21.10,worker.gardener.cloud/pool=cpu-worker-0,worker.gardener.cloud/system-components=true james@lizard:~> kubectl label nodes ip-10-250-0-53.ec2.internal env=demo node/ip-10-250-0-53.ec2.internal labeled james@lizard:~> kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5.xlarge,beta.kubernetes.io/os=linux,env=demo,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1f,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-250-0-53.ec2.internal,kubernetes.io/os=linux,node.kubernetes.io/instance-type=m5.xlarge,node.kubernetes.io/role=node,topology.ebs.csi.aws.com/zone=us-east-1f,topology.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1f,worker.garden.sapcloud.io/group=cpu-worker-0,worker.gardener.cloud/kubernetes-version=1.21.10,worker.gardener.cloud/pool=cpu-worker-0,worker.gardener.cloud/system-components=true Search node by label. james@lizard:~> kubectl get nodes -l env=demo NAME STATUS ROLES AGE VERSION ip-10-250-0-53.ec2.internal Ready <none> 3d11h v1.21.10 Describe node. james@lizard:~> kubectl describe node ip-10-250-0-53.ec2.internal","title":"Label node"},{"location":"cloud/KubernetesTutorials-BTP-trail/#multi-container-pods","text":"Create below yaml file to create multiple containers in one pod. In below yaml file, it describes some actions below: Define a volume named html and type is emptyDir . It means that the volume is created when a Pod is assigned to a node, and exists as long as that Pod is running on that node. Create container nginx and has the shared volume mounted to the directory /usr/share/nginx/html . Create container debian and has the shared volume mounted to the directory /html . Every second, the debian container adds the current datetime into the index.html file, which is located in the shared volume html , that is, /html/index.html and /usr/share/nginx/html/index.html are same, hence index.html can be read by nginx in directory /usr/share/nginx/html/ . apiVersion: v1 kind: Pod metadata: name: my-first-multi-pod spec: volumes: - name: html emptyDir: {} containers: - name: nginx image: nginx volumeMounts: - name: html mountPath: /usr/share/nginx/html - name: debian image: debian volumeMounts: - name: html mountPath: /html command: [\"/bin/sh\", \"-c\"] args: - while true; do date >> /html/index.html; sleep 1; done Create two containers nginx and debian in one pod my-first-multi-pod . james@lizard:~> kubectl apply -f 02-sample-pod-new.yaml pod/my-first-multi-pod created james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE my-first-multi-pod 3/3 Running 0 36s We now can verify content of file index.html either in container nginx or debian , which are same. james@lizard:~> kubectl exec my-first-multi-pod -c nginx -- /bin/cat /usr/share/nginx/html/index.html Fri Jun 17 13:04:16 UTC 2022 Fri Jun 17 13:04:17 UTC 2022 Fri Jun 17 13:04:18 UTC 2022 james@lizard:~> kubectl exec my-first-multi-pod -c debian -- /bin/cat /html/index.html Fri Jun 17 13:04:16 UTC 2022 Fri Jun 17 13:04:17 UTC 2022 Fri Jun 17 13:04:18 UTC 2022 Clean up the pod. james@lizard:~> kubectl delete pod my-first-multi-pod pod \"my-first-multi-pod\" deleted By default, all containers in a Pod are being started in parallel and there is no way to define that one container must be started after other container. We can use initContainers to run some containers (e.g., myservice-1 and mydb-1 ) before application containers (e.g., container-1 ). spec: containers: - name: container-1 image: busybox initContainers: - name: myservice-1 image: debain - name: mydb-1 image: mysql Further references: Pod basics Lifecycle & phases Kubernetes pod design pattern","title":"Multi-Container Pods"},{"location":"cloud/KubernetesTutorials-BTP-trail/#deployment","text":"A Deployment provides declarative updates for Pods and ReplicaSets. The pod encapsulated the container and takes care of the desired state, that is, the deployment. The \"desired state\" means that a specified quorum of running instances is fulfilled.","title":"Deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-deployment-from-command","text":"Create a new resource of type deployment named \"nginx\". james@lizard:~> kubectl create deployment nginx --image=nginx:1.21 deployment.apps/nginx created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 21s james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-bnvgz 2/2 Running 0 5m54s Get nginx by labels. james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx 1/1 1 1 7m13s app=nginx james@lizard:~> kubectl get deployment -l app=nginx NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 8m57s james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-5c95dfd78d-bnvgz 2/2 Running 0 45s app=nginx,pod-template-hash=5c95dfd78d,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx,service.istio.io/canonical-revision=latest james@lizard:~> kubectl get pods -l app=nginx NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-bnvgz 2/2 Running 0 9m15s Use kubectl get deployment nginx -o yaml and kubectl describe deployment nginx to get more detailed information on the deployment just created. It's also good way to get reference yaml file for deployment creation.","title":"Create deployment from command"},{"location":"cloud/KubernetesTutorials-BTP-trail/#scaling-deployment","text":"Execute command kubectl scale deployment nginx --replicas=3 to scale the deployment nginx with 3 pods. james@lizard:~> kubectl scale deployment nginx --replicas=3 deployment.apps/nginx scaled james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx 3/3 3 3 14m app=nginx james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-5xfm7 2/2 Running 0 30s nginx-5c95dfd78d-bnvgz 2/2 Running 0 14m nginx-5c95dfd78d-m67ph 2/2 Running 0 30s james@lizard:~> kubectl get replicaset NAME DESIRED CURRENT READY AGE nginx-5c95dfd78d 3 3 3 33m Let's see the relationship and naming convention. Deployment: nginx | |--ReplicaSet: nginx-5c95dfd78d | |--Pods: |--nginx-5c95dfd78d-5xfm7 | |--Container: istio-proxy | |--Container: nginx | |--nginx-5c95dfd78d-bnvgz | |--Container: istio-proxy | |--Container: nginx | |--nginx-5c95dfd78d-m67ph |--Container: istio-proxy |--Container: nginx","title":"Scaling deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#verify-scalling","text":"Delete a pod from the deployment and observe how the deployment's desired state (replicas=3) is kept. Use command kubectl delete pod <pod-name> to delete a pod and use command watch kubectl get pods to monitor the desired state. Delete one pod nginx-5c95dfd78d-m67ph and a replacement nginx-5c95dfd78d-5mwvr is created automtically. james@lizard:~> kubectl delete pod nginx-5c95dfd78d-m67ph pod \"nginx-5c95dfd78d-m67ph\" deleted james@lizard:~> kubectl get pods NAME READY STATUS RESTARTS AGE nginx-5c95dfd78d-5mwvr 2/2 Running 0 95s nginx-5c95dfd78d-5xfm7 2/2 Running 0 34m nginx-5c95dfd78d-bnvgz 2/2 Running 0 48m","title":"Verify scalling"},{"location":"cloud/KubernetesTutorials-BTP-trail/#rolling-update","text":"A deployment itself does not manage the number of replicas. It just creates a ReplicaSet and tells how many replicas it should have. Checkout the ReplicaSet created by your deployment: kubectl get replicaset , also -o yaml to see full configuration. james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 3 3 3 20h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d james@lizard:~> kubectl get replicaset -o yaml A deployment can also perform a rolling update. Run watch kubectl command to monitor the process of updating. james@lizard:~> watch kubectl rollout status deployment/nginx Get current deployment image version nginx:1.21 . james@lizard:~> kubectl get deployment nginx -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 20h nginx nginx:1.21 app=nginx Update deployment image to nginx:mainline with the below command. The --record option logs the kubectl command and stores it in the deployment's annotations. james@lizard:~> kubectl set image deployment/nginx nginx=nginx:mainline --record deployment.apps/nginx image updated We will receive message deployment \"nginx\" successfully rolled out from command watch kubectl rollout status deployment/nginx . Let's check the deployment, pods and ReplicaSets available in current namespace. By the command kubectl set image , all pods are running under new replicaset nginx-d64cb58b5 with new image version nginx:mainline . james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 20h nginx nginx:mainline app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 20h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-d64cb58b5 3 3 3 4m24s nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-d64cb58b5-55twx 2/2 Running 0 4m15s 100.64.0.238 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-679bk 2/2 Running 0 4m37s 100.64.0.236 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-k946n 2/2 Running 0 4m25s 100.64.0.237 ip-10-250-0-53.ec2.internal <none> <none> We can see the revision history at annotations in deploymant yaml file. james@lizard:~> kubectl get deployment -o yaml apiVersion: v1 items: - apiVersion: apps/v1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: \"2\" kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:mainline --record=true creationTimestamp: \"2022-06-17T14:37:56Z\" ... ... We can also get the revision hisotry by kubectl rollout history command. Get details by --revision=1 option. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 kubectl set image deployment/nginx nginx=nginx:mainline --record=true james@lizard:~> kubectl rollout history deployment/nginx --revision=1 deployment.apps/nginx with revision #1 Pod Template: Labels: app=nginx pod-template-hash=5c95dfd78d Containers: nginx: Image: nginx:1.21 Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=2 deployment.apps/nginx with revision #2Step 5: Pod Template: Labels: app=nginx pod-template-hash=d64cb58b5 Annotations: kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:mainline --record=true Containers: nginx: Image: nginx:mainline Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none>","title":"Rolling update"},{"location":"cloud/KubernetesTutorials-BTP-trail/#update-rollback","text":"Let's do a wrong update of deployment, e.g., set the image version to an not existing tag nginx=nginx:001 as typo. We will see new replicaset nginx-678b495695 is created and only one pod nginx-678b495695-rlgls under the new replicaset with an ImagePullBackOff error. The rollout is stuck with the update of 1 new replica. All pods are still running under replicaset nginx-d64cb58b5 of image nginx:mainline . james@lizard:~> kubectl set image deployment/nginx nginx=nginx:001 --record deployment.apps/nginx image updated james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 1 3 21h nginx nginx:001 app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 21h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-678b495695 1 1 0 66s nginx nginx:001 app=nginx,pod-template-hash=678b495695 nginx-d64cb58b5 3 3 3 77m nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-678b495695-rlgls 1/2 ImagePullBackOff 0 2m6s nginx-d64cb58b5-55twx 2/2 Running 0 77m nginx-d64cb58b5-679bk 2/2 Running 0 78m nginx-d64cb58b5-k946n 2/2 Running 0 77m The deployment specifies a maxUnavailable parameter as part of its update strategy ( kubectl explain deployment.spec.strategy.rollingUpdate ). It defaults to 25%, which means in the demo with 3 replicas, no more than one pod at a time is allowed to be unavailable. That's why the responsible controller does not attempt to patch all the other replicas in parallel. As the attempt to patch the deployment to a new image ailed, we need to roll back the image to nginx:mainline and bring up all pods. Now we can see the status of rollout with three revisions. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 kubectl set image deployment/nginx nginx=nginx:mainline --record=true 3 kubectl set image deployment/nginx nginx=nginx:001 --record=true james@lizard:~> kubectl rollout history deployment/nginx --revision=3 deployment.apps/nginx with revision #3 Pod Template: Labels: app=nginx pod-template-hash=678b495695 Annotations: kubernetes.io/change-cause: kubectl set image deployment/nginx nginx=nginx:001 --record=true Containers: nginx: Image: nginx:001 Port: <none> Host Port: <none> Environment: <none> Mounts: <none> Volumes: <none> To roll back from current version (3) to previous version (2), it promotes revision 2 to revision 4 as the latest available revision. There is no revision 2 after that. james@lizard:~> kubectl rollout undo deployment nginx deployment.apps/nginx rolled back james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 3 kubectl set image deployment/nginx nginx=nginx:001 --record=true 4 kubectl set image deployment/nginx nginx=nginx:mainline --record=true Let's verify current deployment, replicaset, and pods after rollback. james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 22h nginx nginx:mainline app=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-5c95dfd78d 0 0 0 22h nginx nginx:1.21 app=nginx,pod-template-hash=5c95dfd78d nginx-678b495695 0 0 0 17m nginx nginx:001 app=nginx,pod-template-hash=678b495695 nginx-d64cb58b5 3 3 3 93m nginx nginx:mainline app=nginx,pod-template-hash=d64cb58b5 james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-d64cb58b5-55twx 2/2 Running 0 93m 100.64.0.238 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-679bk 2/2 Running 0 93m 100.64.0.236 ip-10-250-0-53.ec2.internal <none> <none> nginx-d64cb58b5-k946n 2/2 Running 0 93m 100.64.0.237 ip-10-250-0-53.ec2.internal <none> <none>","title":"Update &amp; Rollback"},{"location":"cloud/KubernetesTutorials-BTP-trail/#delete-deployment","text":"After deletion of deployment, all replica, pods of nginx were automatically deleted as well. james@lizard:~> kubectl delete deployment nginx deployment.apps \"nginx\" deleted james@lizard:~> kubectl get deployment No resources found in jh-namespace namespace. james@lizard:~> kubectl get replicaset No resources found in jh-namespace namespace. james@lizard:~> kubectl get pod No resources found in jh-namespace namespace.","title":"Delete deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-deployment-from-file","text":"The following demo shows an example how to create deployment from yaml file. Create the yaml file 03-deployment.yaml for a new deployment that creates 3 replicas of an nginx image, with version tag latest. james@lizard:~> cat 03-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 Create the deoployment via file 03-deployment.yaml . james@lizard:~> kubectl apply -f 03-deployment.yaml deployment.apps/nginx-deployment created Verify current deployment, replicaset, and pods. james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 38s nginx nginx run=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-658f4cf99f 3 3 3 48s nginx nginx pod-template-hash=658f4cf99f,run=nginx james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-658f4cf99f-74w6d 2/2 Running 0 64s 100.64.0.15 ip-10-250-0-53.ec2.internal <none> <none> nginx-658f4cf99f-7rbtn 2/2 Running 0 64s 100.64.0.12 ip-10-250-0-53.ec2.internal <none> <none> nginx-658f4cf99f-bvkp5 2/2 Running 0 64s 100.64.0.16 ip-10-250-0-53.ec2.internal <none> <none> james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> In above demo, we use image nginx with latest tag. In following demo, I will only change image to nginx:mainline and update the live deployment. Create new yaml file 03-deployment-new.yaml . james@lizard:~> cat 03-deployment-new.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 Show the difference. james@lizard:~> kubectl diff -f 03-deployment-new.yaml ... ... - generation: 1 + generation: 2 ... ... containers: - - image: nginx + - image: nginx:mainline ... ... Update the live version. james@lizard:~> kubectl apply -f 03-deployment-new.yaml deployment.apps/nginx configured Verify current deployment, replicaset, and pods. All pods are running under new replicaset nginx-74db5c7848 with image nginx:mainline . james@lizard:~> kubectl get deployment -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 24m nginx nginx:mainline run=nginx james@lizard:~> kubectl get replicaset -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR nginx-658f4cf99f 0 0 0 25m nginx nginx pod-template-hash=658f4cf99f,run=nginx nginx-74db5c7848 3 3 3 77s nginx nginx:mainline pod-template-hash=74db5c7848,run=nginx james@lizard:~> kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-74db5c7848-4dxf2 2/2 Running 0 82s 100.64.0.22 ip-10-250-0-53.ec2.internal <none> <none> nginx-74db5c7848-9lmgx 2/2 Running 0 92s 100.64.0.21 ip-10-250-0-53.ec2.internal <none> <none> nginx-74db5c7848-wqfs9 2/2 Running 0 71s 100.64.0.24 ip-10-250-0-53.ec2.internal <none> <none> Check the rollout hisotry. The image is nginx in revision 1 and nginx:mainline in revision 2. james@lizard:~> kubectl rollout history deployment/nginx deployment.apps/nginx REVISION CHANGE-CAUSE 1 <none> 2 <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=1 deployment.apps/nginx with revision #1 Pod Template: Labels: pod-template-hash=658f4cf99f run=nginx Containers: nginx: Image: nginx Port: 80/TCP Host Port: 0/TCP Environment: <none> Mounts: <none> Volumes: <none> james@lizard:~> kubectl rollout history deployment/nginx --revision=2 deployment.apps/nginx with revision #2 Pod Template: Labels: pod-template-hash=74db5c7848 run=nginx Containers: nginx: Image: nginx:mainline Port: 80/TCP Host Port: 0/TCP Environment: <none> Mounts: <none> Volumes: <none> Clean up what we created. james@lizard:~> kubectl delete deployment nginx deployment.apps \"nginx\" deleted Further references: Deployments in K8s concepts documentation Replication controller Labels in K8s","title":"Create deployment from file"},{"location":"cloud/KubernetesTutorials-BTP-trail/#expose-application","text":"","title":"Expose application"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-deployment","text":"Create nginx deployment via below 04-deployment.yaml yaml file. james@lizard:~> cat 04-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: tier: application spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 james@lizard:~> kubectl apply -f 04-deployment.yaml deployment.apps/nginx-deployment created We have below resource graph. Pods and replicaset have same label run=nginx . james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment 3/3 3 3 4m7s tier=application james@lizard:~> kubectl get replicaset --show-labels NAME DESIRED CURRENT READY AGE LABELS nginx-deployment-69745449db 3 3 3 4m18s pod-template-hash=69745449db,run=nginx james@lizard:~> kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-69745449db-9g69m 2/2 Running 0 104s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-glrcb 2/2 Running 0 105s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-qkkmw 2/2 Running 0 105s pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest","title":"Create deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#expose-deployment","text":"In Kubernetes, a Service is an abstraction which defines a logical set of Pods and a policy by which to access them (sometimes this pattern is called a micro-service). The set of Pods targeted by a Service is usually determined by a selector. We have two ways to create a service, commandline and yaml file. Run command kubectl expose deployment <deployment-name> --type=LoadBalancer --port=80 --target-port=80 to expose application. The BTP trail system is to provision a public IP address with option --type=LoadBalancer . It also automatically assigns a cluster-IP and a NodePort in the current setup of the cluster. To create a service that gets only a cluster-IP and does cluster interal load balancing, which can only be called within the cluster from other pods, not via a public IP from the outside, use --type=ClusterIP or leave it away since it is the default. The option --port is that the service should serve on. The option --target-port is the port on the container that the service should direct traffic to. Connect to service via external IP and port number. More detail information can be get via option -o=yaml . james@lizard:~> kubectl expose deployment nginx-deployment --type=LoadBalancer --port=80 --target-port=80 service/nginx-deployment exposed james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR nginx-deployment LoadBalancer 100.106.92.216 xxx.us-east-1.elb.amazonaws.com 80:31114/TCP 11s run=nginx james@lizard:~> kubectl get service --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-deployment LoadBalancer 100.106.92.216 xxx.us-east-1.elb.amazonaws.com 80:31114/TCP 34s tier=application Delete the service just created. james@lizard:~> kubectl delete service nginx-deployment service \"nginx-deployment\" deleted Create nginx service again via yaml file below. The label selector run: nginx matches the labels of deployment/pods run: nginx and create the service. The label tier is tier: application , which is same with deployment. james@lizard:~> cat 04-service.yaml apiVersion: v1 kind: Service metadata: name: nginx-service labels: tier: application spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx type: LoadBalancer james@lizard:~> kubectl apply -f 04-service.yaml service/nginx-service created james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR nginx-service LoadBalancer 100.104.35.35 xxx.elb.amazonaws.com 80:31803/TCP 4m7s run=nginx james@lizard:~> kubectl get service --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service LoadBalancer 100.104.35.35 xxx.us-east-1.elb.amazonaws.com 80:31803/TCP 3m6s tier=application james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment 3/3 3 3 24m tier=application james@lizard:~> kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-69745449db-5r999 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-lf6cc 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-rkrjs 2/2 Running 0 25m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest Now the resource graph is like below.","title":"Expose deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#expose-pod","text":"In following, I will create the pod as we did before. james@lizard:~> kubectl apply -f 02-sample-pod.yaml pod/my-first-pod created james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS my-first-pod 2/2 Running 0 10s security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-9g69m 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-glrcb 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest nginx-deployment-69745449db-qkkmw 2/2 Running 0 19m pod-template-hash=69745449db,run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-deployment,service.istio.io/canonical-revision=latest Add the label run=nginx to the pod created above. james@lizard:~> kubectl label pod my-first-pod run=nginx pod/my-first-pod labeled james@lizard:~> kubectl get pod -l run=nginx NAME READY STATUS RESTARTS AGE my-first-pod 2/2 Running 0 87s nginx-deployment-69745449db-9g69m 2/2 Running 0 20m nginx-deployment-69745449db-glrcb 2/2 Running 0 20m nginx-deployment-69745449db-qkkmw 2/2 Running 0 20m Expose it as LoadBalancer with kubectl expose pod . james@lizard:~> kubectl expose pod my-first-pod --type=LoadBalancer service/my-first-pod exposed We now have two services, one is for the pod my-first-pod , another is for the deployment nginx-deployment . They're exposed by different services. james@lizard:~> kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR my-first-pod LoadBalancer 100.108.11.185 xxx.us-east-1.elb.amazonaws.com 15090:30864/TCP,80:30133/TCP 20s run=nginx,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=my-first-pod,service.istio.io/canonical-revision=latest nginx-service LoadBalancer 100.104.35.35 xxx.us-east-1.elb.amazonaws.com 80:31803/TCP 10m run=nginx Check the correctness of the label - selector combination by running the query manually. Get the selector from the service by running kubectl get service <service-name> -o yaml . Use the <key>: <value> pairs stored in service.spec.selector to get all pods with the corresponding label set, kubectl get pods -l <key>=<value> . These pods are what the service is selecting. The selector often used within service matches the selector specified within the deployment. Verify the service from external IP and port number. There would be certificate issue to access xxx.us-east-1.elb.amazonaws.com, leave it at the moment and will be solve in ConfigMaps and Secrets . Clean up and remove the pod as well as the service created above. james@lizard:~> kubectl delete service my-first-pod service \"my-first-pod\" deleted james@lizard:~> kubectl delete pod my-first-pod pod \"my-first-pod\" deleted james@lizard:~> kubectl delete service nginx-service service \"nginx-service\" deleted james@lizard:~> kubectl delete deployment nginx-deployment deployment.apps \"nginx-deployment\" deleted Further references: Services in K8s Connecting a front end to a backend Cluster internal DNS","title":"Expose pod"},{"location":"cloud/KubernetesTutorials-BTP-trail/#persistence","text":"Docker has a concept of volumes, though it is somewhat looser and less managed. A Docker volume is a directory on disk or in another container. Docker provides volume drivers, but the functionality is somewhat limited. Kubernetes supports many types of volumes . A Pod can use any number of volume types simultaneously. A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. A PersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany). Check current persistent volume and corresponding claims. james@lizard:~> kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-shoot--kyma--eb68ebe-661d5e59-a895-4e02-916e-8621038a7ca3 20Gi RWO Delete Bound kyma-system/serverless-docker-registry default 7d pv-shoot--kyma--eb68ebe-92909d6a-b809-42f9-8f91-17f0c9a2ccbb 10Gi RWO Delete Bound kyma-system/prometheus-monitoring-prometheus-db-prometheus-monitoring-prometheus-0 default 7d pv-shoot--kyma--eb68ebe-d1f0cad5-60a6-41f7-b9ab-6a3f4524b3c4 1Gi RWO Delete Bound kyma-system/monitoring-grafana default 7d pv-shoot--kyma--eb68ebe-d48cc603-499b-40a6-896c-6e0a7d32cfde 10Gi RWO Delete Bound kyma-system/rafter-minio default 7d james@lizard:~> kubectl get pvc No resources found in jh-namespace namespace.","title":"Persistence"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-pv-and-pvc","text":"In general, we create a PersistentVolume (PV) first and then bind it to a PersistentVolumeClaim (PVC). PVC are bound to a namespace, PV resource are not. When there is a fitting PV, it can be bound to any PVC in any namespace. There is some conflict potential, if your PV is claimed by the others. The storage classes overcomes this problem. Create the resource: kubectl create -f 05-pvc.yaml and verify if the claim has been created. james@lizard:~> cat 05-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc spec: storageClassName: default accessModes: - ReadWriteOnce resources: requests: storage: 1Gi james@lizard:~> kubectl get storageclass NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE default (default) ebs.csi.aws.com Delete WaitForFirstConsumer true 6d15h gp2 ebs.csi.aws.com Delete WaitForFirstConsumer true 6d15h james@lizard:~> kubectl apply -f 05-pvc.yaml persistentvolumeclaim/nginx-pvc created james@lizard:~> kubectl get pvc -o wide NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE nginx-pvc Pending default 67s Filesystem The status if PVC is Pending . Take a closer look with kubectl describe pvc <pvc-name> . james@lizard:~> kubectl describe pvc nginx-pvc Name: nginx-pvc Namespace: jh-namespace StorageClass: default Status: Pending Volume: Labels: <none> Annotations: <none> Finalizers: [kubernetes.io/pvc-protection] Capacity: Access Modes: VolumeMode: Filesystem Used By: <none> Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal WaitForFirstConsumer 11s (x10 over 2m19s) persistentvolume-controller waiting for first consumer to be created before binding","title":"Create PV and PVC"},{"location":"cloud/KubernetesTutorials-BTP-trail/#attach-the-pvc","text":"The PVC's access mode is ReadWriteOnce . we need reduce the number of replicas in the deployment to 1 . Modify file 05-deployment-with-pvc.yaml like below. apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: tier: application spec: replicas: 1 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: volumes: - name: content-storage persistentVolumeClaim: claimName: nginx-pvc # readOnly: true containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 volumeMounts: - mountPath: \"/usr/share/nginx/html\" name: content-storage # readOnly: true Create the deployment nginx-deployment with 1 replicaset and consume pvc nginx-pvc . james@lizard:~> kubectl apply -f 05-deployment-with-pvc.yaml deployment.apps/nginx-deployment created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 1/1 1 1 30s james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-84757d96f5-r2gqz 2/2 Running 0 105s The status of PVC is now Bound instead of Pending before. james@lizard:~> kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Bound pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b 1Gi RWO default 8m51s james@lizard:~> kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-shoot--kyma--eb68ebe-661d5e59-a895-4e02-916e-8621038a7ca3 20Gi RWO Delete Bound kyma-system/serverless-docker-registry default 7d1h pv-shoot--kyma--eb68ebe-92909d6a-b809-42f9-8f91-17f0c9a2ccbb 10Gi RWO Delete Bound kyma-system/prometheus-monitoring-prometheus-db-prometheus-monitoring-prometheus-0 default 7d1h pv-shoot--kyma--eb68ebe-d1f0cad5-60a6-41f7-b9ab-6a3f4524b3c4 1Gi RWO Delete Bound kyma-system/monitoring-grafana default 7d1h pv-shoot--kyma--eb68ebe-d48cc603-499b-40a6-896c-6e0a7d32cfde 10Gi RWO Delete Bound kyma-system/rafter-minio default 7d1h pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b 1Gi RWO Delete Bound jh-namespace/nginx-pvc default 6m51s By executing below commands, we can get more details on pvc and pv. james@lizard:~> kubectl describe pvc nginx-pvc james@lizard:~> kubectl describe pv pv-shoot--kyma--eb68ebe-e3c25178-13ec-4b27-a68c-7db296fc7e5b Tips: Use kubectl get pvc <pcv-name> to get the name of the bounded persistent volume. Use kubectl get pv <pv-name> -o json | jq \".spec.gcePersistentDisk\" to get the name of the physical disk used by the persistent volume. Use kubectl get nodes -o yaml | grep <physical-disk-name> to see if the physical disk is still conected to a node. Further references: descripton of the volumes API how to use PV & PVC storage classes volume snapshots","title":"Attach the PVC"},{"location":"cloud/KubernetesTutorials-BTP-trail/#configmaps-and-secrets","text":"ConfigMaps and secrets build generic images and run them with a specific configuration in an secured environment. Clean up the deployments, services, PVCs.","title":"ConfigMaps and Secrets"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-pvc","text":"Create new file 06-pvc.yaml like below james@lizard:~> cat 06-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nginx-pvc spec: storageClassName: default accessModes: - ReadWriteOnce resources: requests: storage: 1Gi james@lizard:~> kubectl apply -f 06-pvc.yaml persistentvolumeclaim/nginx-pvc-07 created james@lizard:~> kubectl --kubeconfig=$KUBECONFIG get persistentvolumeclaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Pending default 15s","title":"Create PVC"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-certificate","text":"Create a new certificate. james@lizard:~> openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /opt/nginx.key -out /opt/nginx.crt -subj \"/CN=nginxsvc/O=nginxsvc\" Generating a RSA private key ................................+++++ ..........+++++ writing new private key to '/opt/nginx.key' -----","title":"Create certificate"},{"location":"cloud/KubernetesTutorials-BTP-trail/#store-certificate","text":"In order to use the certificate with nginx, we need to add it to kubernetes and store it in a secret resource of type tls in the namespace. Kubernetes will change the names of the files to a standardized string, e.g., from nginx.crt to tls.crt . james@lizard:~> kubectl create secret tls nginx-sec --cert=/opt/nginx.crt --key=/opt/nginx.key secret/nginx-sec created james@lizard:~> kubectl get secret nginx-sec NAME TYPE DATA AGE nginx-sec kubernetes.io/tls 2 29m Get details of nginx-sec. james@lizard:~> kubectl describe secret nginx-sec Name: nginx-sec Namespace: jh-namespace Labels: <none> Annotations: <none> Type: kubernetes.io/tls Data ==== tls.crt: 1164 bytes tls.key: 1704 bytes","title":"Store certificate"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-configuration","text":"Create a configuration and store certificate secret to kubernetes, which is enable nginx to serve HTTPS traffic on port 443 using a certificate located at directory /etc/nginx/ssl/ . Download from gitHub or create the file default.conf with the following content. Ensure the file's name is default.conf . Ensure the values for ssl_certificate and ssl_certificate_key match the names of the files within the nginx-sec . Output the files are named tls.crt and tls.key in the secret as well as the configuration. The location /etc/nginx/ssl/ in the filesystem will be set via the volumeMount, when you create your deployment. Be noted, if called, /healthz will * return a status code 200 to satisfy a liveness probe. james@lizard:~> cat default.conf server { listen 80 default_server; listen [::]:80 default_server ipv6only=on; listen 443 ssl; root /usr/share/nginx/html; index index.html; server_name localhost; ssl_certificate /etc/nginx/ssl/tls.crt; ssl_certificate_key /etc/nginx/ssl/tls.key; location / { try_files $uri $uri/ =404; } location /healthz { access_log off; return 200 'OK'; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html/; } }","title":"Create configuration"},{"location":"cloud/KubernetesTutorials-BTP-trail/#upload-the-configuration","text":"Run kubectl create configmap nginxconf --from-file=<path>/default.conf to create a configMap resource with the corresponding content from default.conf . james@lizard:~> kubectl create configmap nginx-configmap --from-file=default.conf configmap/nginxconf-0013 created james@lizard:~> kubectl get configmap nginx-configmap NAME DATA AGE nginx-configmap 1 25s","title":"Upload the configuration"},{"location":"cloud/KubernetesTutorials-BTP-trail/#combine-into-deployment","text":"Combine the PVC, secret and configMap in a new deployment. As a result, nginx should display the custom index.html page, serve HTTP traffic on port 80 and HTTPS on port 443. There are 3 volumes specified as part of deployment.spec.template.spec.volumes ( pvc , configMap and secret ). Each item of the volumes list defines local or pod-internal name and references the actual Kubernetes object. These 3 volumes should be used and mounted to a specific location within the container (defined in deployment.spec.template.spec.containers.volumeMount ). The local or pod-internal name is used for the name field. Use app: nginx-https as label/selector for the secured nginx. james@lizard:~> cat 06-deployment-https.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment-https labels: tier: application spec: replicas: 1 selector: matchLabels: app: nginx-https template: metadata: labels: app: nginx-https spec: volumes: - name: html-storage persistentVolumeClaim: claimName: nginx-pvc readOnly: true - name: tls-secret secret: secretName: nginx-sec - name: nginx-configmap configMap: name: nginx-configmap containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 name: http - containerPort: 443 name: https livenessProbe: httpGet: path: /healthz port: http initialDelaySeconds: 3 periodSeconds: 5 volumeMounts: - mountPath: \"/usr/share/nginx/html\" name: html-storage readOnly: true - mountPath: /etc/nginx/ssl name: tls-secret readOnly: true - mountPath: /etc/nginx/conf.d name: nginx-configmap Create the deployment. james@lizard:~> kubectl apply -f 06-deployment-https.yaml deployment.apps/nginx-deployment-https created james@lizard:~> kubectl get deployment --show-labels NAME READY UP-TO-DATE AVAILABLE AGE LABELS nginx-deployment-https 1/1 1 1 5m45s tier=application james@lizard:~> kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 6m41s app=nginx-https,pod-template-hash=7cf8f66cb4,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=nginx-https,service.istio.io/canonical-revision=latest Get more details about pod. james@lizard:~> kubectl describe pods nginx-deployment-https-7cf8f66cb4-mv2sb Resource graph likes this.","title":"Combine into deployment"},{"location":"cloud/KubernetesTutorials-BTP-trail/#create-service","text":"Create a new service to expose the deployment nginx-deployment-https . Make sure the labels tier: application used in the deployment and the selector app: nginx-https specified by the service match. james@lizard:~> cat 06-service-https.yaml apiVersion: v1 kind: Service metadata: name: nginx-service-https labels: tier: application spec: ports: - port: 80 protocol: TCP name: http - port: 443 protocol: TCP name: https selector: app: nginx-https type: LoadBalancer james@lizard:~> kubectl apply -f 06-service-https.yaml service/nginx-service-https created james@lizard:~> kubectl get services --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 80s tier=application james@lizard:~> kubectl get services --show-labels NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE LABELS nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 46s tier=application Resource graph looks like it now. Validation: both http and https failed. james@lizard:~> curl -v -k https://xxx.us-east-1.elb.amazonaws.com:443 * Trying <external IP>:443... * TCP_NODELAY set * Connected to xxx.elb.amazonaws.com (<external IP>) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * TLSv1.3 (OUT), TLS handshake, Client hello (1): * TLSv1.3 (IN), TLS handshake, Server hello (2): * TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8): * TLSv1.3 (IN), TLS handshake, Request CERT (13): * TLSv1.3 (IN), TLS handshake, Certificate (11): * TLSv1.3 (IN), TLS handshake, CERT verify (15): * TLSv1.3 (IN), TLS handshake, Finished (20): * TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.3 (OUT), TLS handshake, Certificate (11): * TLSv1.3 (OUT), TLS handshake, Finished (20): * SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384 * ALPN, server accepted to use h2 * Server certificate: * subject: [NONE] * start date: Jun 20 08:09:07 2022 GMT * expire date: Jun 21 08:11:07 2022 GMT * issuer: O=cluster.local * SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway. * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Using Stream ID: 1 (easy handle 0x55663ef83850) > GET / HTTP/2 > Host: xxx.us-east-1.elb.amazonaws.com > User-Agent: curl/7.66.0 > Accept: */* > * TLSv1.3 (IN), TLS alert, unknown (628): * OpenSSL SSL_read: error:1409445C:SSL routines:ssl3_read_bytes:tlsv13 alert certificate required, errno 0 * Failed receiving HTTP2 data * OpenSSL SSL_write: SSL_ERROR_ZERO_RETURN, errno 0 * Failed sending HTTP2 data * Connection #0 to host axxx.us-east-1.elb.amazonaws.com left intact curl: (56) OpenSSL SSL_read: error:1409445C:SSL routines:ssl3_read_bytes:tlsv13 alert certificate required, errno 0 james@lizard:~> curl -v http://xxx.us-east-1.elb.amazonaws.com:80 * Trying <external IP>:80... * TCP_NODELAY set * Connected to xxx.us-east-1.elb.amazonaws.com (<external IP>) port 80 (#0) > GET / HTTP/1.1 > Host: xxx.us-east-1.elb.amazonaws.com > User-Agent: curl/7.66.0 > Accept: */* > * Empty reply from server * Connection #0 to host xxx.us-east-1.elb.amazonaws.com left intact curl: (52) Empty reply from server Further references: secrets in k8s options to use a configMap","title":"Create service"},{"location":"cloud/KubernetesTutorials-BTP-trail/#ingress","text":"Ingress resources allow us to expose services through a URL. We can configure an Ingress so that traffic can be directed to different services, depending on the URL that is used for a request. Find out the cluster's and project's names: james@lizard:~> echo \"Clustername: $(kubectl config view -o json | jq \".clusters[0].cluster.server\" | cut -d. -f2)\"; echo \"Projectname: $(kubectl config view -o json | jq \".clusters[0].cluster.server\" | cut -d. -f3)\" Clustername: eb68ebe Projectname: kyma Create 07-ingress.yaml yaml file to create below resources: Deployment nginx-simple . The initContainers writes a string to and index.html on an emptyDir volume. Service nginx-simple-service . Ingress nginx-simple-ingress . james@lizard:~> cat 07-ingress.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-simple labels: tier: application spec: replicas: 1 selector: matchLabels: app: nginx-simple template: metadata: labels: app: nginx-simple spec: volumes: - name: index-html emptyDir: {} initContainers: - name: setup image: alpine:latest command: - /bin/sh - -c - echo This is a simple nginx! > /work-dir/index.html volumeMounts: - name: index-html mountPath: \"/work-dir\" containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 volumeMounts: - name: index-html mountPath: /usr/share/nginx/html --- apiVersion: v1 kind: Service metadata: name: nginx-simple-service labels: tier: networking spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: nginx-simple type: ClusterIP --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx-simple-ingress annotations: nginx.ingress.kubernetes.io/proxy-connect-timeout: \"61\" nginx.ingress.kubernetes.io/rewrite-target: /$1 spec: rules: - host: <namspace-number>-nginx-simple.ingress.<cluster-name>.<project-name>.shoot.canary.k8s-hana.ondemand.com http: paths: - path: /my-app(.*) pathType: Prefix backend: service: name: nginx-simple-service port: number: 80 Craete resources. james@lizard:~> kubectl apply -f 07-ingress.yaml deployment.apps/nginx-simple created service/nginx-simple-service created ingress.networking.k8s.io/nginx-simple-ingress created james@lizard:~> kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment-https 1/1 1 1 5h50m nginx-simple 1/1 1 1 51s james@lizard:~> kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service-https LoadBalancer 100.104.128.56 xxx.us-east-1.elb.amazonaws.com 80:30406/TCP,443:31538/TCP 5h25m nginx-simple-service ClusterIP 100.106.164.62 <none> 80/TCP 82s james@lizard:~> kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE nginx-simple-ingress <none> <your host> 80 2m6s james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 5h53m nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 3m58s http:// https://","title":"Ingress"},{"location":"cloud/KubernetesTutorials-BTP-trail/#annotations","text":"Annotations are part of the metadata section and can be written directly to the yaml file as well as added via kubectl annotate . Annotations are also key-value pairs. Most commonly annotations are used to store additional information, describe a resource more detailed or tweak it's behavior. Further references: annotations init containers debugging of init containers ingress list of ingress controllers nginx ingress controller","title":"Annotations"},{"location":"cloud/KubernetesTutorials-BTP-trail/#statefulset","text":"Like a Deployment, a StatefulSet manages Pods that are based on an identical container spec. Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.","title":"StatefulSet"},{"location":"cloud/KubernetesTutorials-BTP-trail/#build-statefulset","text":"Create yaml file 08-statefulset.yaml to create a service nginx-stateful and a statefulset web mapped to service nginx-stateful . james@lizard:~> cat 08-statefulset.yaml apiVersion: v1 kind: Service metadata: name: nginx-stateful labels: app: nginx-stateful spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx-stateful --- apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: serviceName: \"nginx-stateful\" replicas: 2 selector: matchLabels: app: nginx-stateful template: metadata: labels: app: nginx-stateful spec: initContainers: - name: setup image: alpine:latest command: - /bin/sh - -c - echo $(hostname) >> /work-dir/index.html volumeMounts: - name: www mountPath: /work-dir containers: - name: nginx image: nginx:mainline ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi Create statefulset resource. We can watch the upcoming new pods via watch kubectl get pods . james@lizard:~> kubectl apply -f 08-statefulset.yaml service/nginx-stateful created statefulset.apps/web created james@lizard:~> kubectl get service nginx-stateful NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-stateful ClusterIP None <none> 80/TCP 11h james@lizard:~> kubectl get statefulset web NAME READY AGE web 2/2 11h As we set replicas: 2 in the yaml file, be noted that the pod name consists of the statefulset's name + the index, not any randomly generated string (as with deployments). james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 41h nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 35h web-0 2/2 Running 0 11h web-1 2/2 Running 0 11h As we defined PVC Template volumeClaimTemplates with name www , we can find two new PVCs created as well. james@lizard:~> kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nginx-pvc Bound pv-shoot--kyma--eb68ebe-b0f174a8-7800-43bb-86bd-751a5505363b 1Gi RWO default 2d www-web-0 Bound pv-shoot--kyma--eb68ebe-ce950e1d-0c5f-4ab2-9aa1-7bb3c834cb2b 1Gi RWO default 11h www-web-1 Bound pv-shoot--kyma--eb68ebe-dc954620-f4ec-48bd-89bd-737b59687794 1Gi RWO default 11h Quickly spin up a temporary pod and directly connect to it. james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash Within pod's shell context: run nslookup [pod-name].[service-name] to check if individual pods are accessible via the service. download the index.html page of each instance using wget -q -O - [pod-name].[service-name] . james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # ls bin dev etc home lib media mnt opt proc root run sbin srv sys tmp usr var / # nslookup web-0.nginx-stateful Server: 100.104.0.10 Address: 100.104.0.10:53 ** server can't find web-0.nginx-stateful: NXDOMAIN ** server can't find web-0.nginx-stateful: NXDOMAIN / # wget web-0.nginx-stateful Connecting to web-0.nginx-stateful (100.64.0.35:80) saving to 'index.html' index.html 100% |************************************************************************************************| 6 0:00:00 ETA 'index.html' saved / # ls bin etc index.html media opt root sbin sys usr dev home lib mnt proc run srv tmp var / # cat index.html web-0 / # exit pod \"dns-test\" deleted StatefulSets guarantee stable/reliable names, and it won't change over time - even when the pod gets killed and re-created. Delete the pods web-0 of the StatefulSet web and the same will be created automatically per replicaset. james@lizard:~> kubectl delete pods web-0 pod \"web-0\" deleted james@lizard:~> kubectl get pod NAME READY STATUS RESTARTS AGE nginx-deployment-https-7cf8f66cb4-mv2sb 2/2 Running 0 2d4h nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 47h web-0 2/2 Running 0 50s web-1 2/2 Running 0 22h Rerun kubectl run dns-test again, and we can see there are two pod web-0 now because the initContainer wrote the \"new\" hostname to the index.html page, james@lizard:~> kubectl run dns-test -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # nslookup web-0.nginx-stateful Server: 100.104.0.10 Address: 100.104.0.10:53 ** server can't find web-0.nginx-stateful: NXDOMAIN ** server can't find web-0.nginx-stateful: NXDOMAIN / # wget web-0.nginx-stateful Connecting to web-0.nginx-stateful (100.64.0.198:80) saving to 'index.html' index.html 100% |************************************************************************************************| 12 0:00:00 ETA 'index.html' saved / # ls bin etc index.html media opt root sbin sys usr dev home lib mnt proc run srv tmp var / # cat index.html web-0 web-0 / # exit pod \"dns-test\" deleted Increase the number of replicas to 3. james@lizard:~> kubectl edit sts web statefulset.apps/web edited If we set partition parameter with value \"2\", we will have 3 replicas with index [0,1,2], and will limit the effect of an update to replica #2 only. The partition parameter controls the replicas that are patched based on an \"equals or greater\" evaluation of the ordinal index of the replica. james@lizard:~> kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"type\":\"RollingUpdate\",\"rollingUpdate\":{\"partition\":2}}}}' statefulset.apps/web patched Use the json path with the patch command to change the image version in your podSpec template: james@lizard:~> kubectl patch statefulset web --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/image\", \"value\":\"nginx:1.13.12\"}]' statefulset.apps/web patched The pod web-2 will be terminated and re-created. The image version of the updated pod: james@lizard:~> kubectl get po web-2 --template '{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}' eu.gcr.io/kyma-project/external/istio/proxyv2:1.13.2-distrolessnginx:mainline Set \"partition\" to \"0\" to move all replicas to the new version. james@lizard:~> kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"type\":\"RollingUpdate\",\"rollingUpdate\":{\"partition\":0}}}}' statefulset.apps/web patched Further references statefulset documentation cassandara deployed as a statefulset init containers debugging of init containers","title":"Build StatefulSet"},{"location":"cloud/KubernetesTutorials-BTP-trail/#network-policy","text":"Network policies namespace based to help us restrict access to the nginx deployment. From within any pod that is not labeled correctly we will not be able to access our nginx instances. The network policy features two selector sections: networkpolicy.spec.podSelector.matchLabels determines the target pods -> traffic to all matching pods will be filtered (allow or drop) networkpolicy.spec.ingress.from lists the sources, from which traffic is accepted. There are different ways to identify trusted sources by podSelector.matchLabels - to filter for labels of pods in the same namespace by namespaceSelector.matchLabels - to filter for traffic from a specific namespace (can be combined with podSelector) by ipBlock.cidr - an IP address range defined as trustworthy Let's check the connection from a random pod tester and run wget --timeout=1 -q -O - <your-service-name> within the pod to send an HTTP request to the nginx service nginx-simple-service . james@lizard:~> kubectl get pod -l app=nginx-simple NAME READY STATUS RESTARTS AGE nginx-simple-7d77885fc5-dzqj9 2/2 Running 0 2d james@lizard:~> kubectl run tester -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # wget --timeout=1 -q -O - nginx-simple-service This is a simple nginx! / # exit pod \"tester\" deleted Now deploy the networkpolicy nginx-access which applys to pod label app=nginx-simple . james@lizard:~> kubectl get networkpolicy No resources found in jh-namespace namespace. james@lizard:~> kubectl apply -f 09-network-policy.yaml networkpolicy.networking.k8s.io/nginx-access created james@lizard:~> kubectl get networkpolicy NAME POD-SELECTOR AGE nginx-access app=nginx-simple 71s Let's send HTTP request from a random pod tester to the nginx service nginx-simple-service again. As I did not maintain correct IPs in ingress, hence the connection to pod with label app=nginx-simple fails now after the networkpolicy nginx-access deployed. james@lizard:~> kubectl run tester -i --tty --restart=Never --rm --image=alpine:3.12 -- ash If you don't see a command prompt, try pressing enter. / # wget --timeout=1 -q -O - nginx-simple-service wget: download timed out / # exit pod \"tester\" deleted Further references network policy basics example / tutorial on network policies","title":"Network Policy"},{"location":"cloud/KubernetesTutorials-BTP-trail/#helming","text":"Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Refer to installation guide and binary release and source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed. Step 2: looking for charts? Helm organizes applications in so called charts, which contain parameters you can set during installation. By default, helm (v3) is not configured to search any remote repository for charts. So as a first step, add the stable repository, which hosts charts maintained on github.com. Add repo charts . Note: The charts repo is officially deprecated. The helm organization is now using Artifact Hub. james@lizard:~> helm repo add stable https://charts.helm.sh/stable \"stable\" has been added to your repositories james@lizard:~> helm repo list NAME URL stable https://charts.helm.sh/stable Check out the available charts and search for the chaoskube : james@lizard:~> helm search repo chaoskube NAME CHART VERSION APP VERSION DESCRIPTION stable/chaoskube 3.3.2 0.21.0 DEPRECATED Chaoskube periodically kills random ... Run the following command to install the chaoskube chart with new name chaoskube-jh . The --set flags specifies parameters of the chart. The parameter namespaces defines in which namespaces the chaoskube will delete pods. rbac.serviceAccountName specifies which serviceAccount the scheduled chaoskube pod will use. james@lizard:~> helm install chaoskube-jh stable/chaoskube --set namespaces=jh-namespace --set rbac.serviceAccountName=chaoskube --debug We can get the deployment chaoskube-jh now. james@lizard:~> kubectl get deployment chaoskube-jh NAME READY UP-TO-DATE AVAILABLE AGE chaoskube-jh 0/1 0 0 3m36s Inspect the chaoskube we deployed. james@lizard:~> helm status chaoskube-jh NAME: chaoskube-jh LAST DEPLOYED: Wed Jun 22 23:25:05 2022 NAMESPACE: jh-namespace STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: chaoskube is running and will kill arbitrary pods every 10m. You can follow the logs to see what chaoskube does: POD=$(kubectl -n jh-namespace get pods -l='app.kubernetes.io/instance=chaoskube-jh' --output=jsonpath='{.items[0].metadata.name}') kubectl -n jh-namespace logs -f $POD You are running in dry-run mode. No pod is actually terminated. Clean up chaoskube-jh . james@lizard:~> helm delete chaoskube-jh release \"chaoskube-jh\" uninstalled james@lizard:~> helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION Clean up all resources created in this demo. # kubectl detele deployment nginx-simple nginx-deployment-https # kubectl delete deployment nginx-simple nginx-deployment-https # kubectl delete sts web # kubectl delete ingress nginx-simple-ingress # kubectl delete service nginx-service-https nginx-simple-service nginx-stateful # kubectl delete networkpolicy nginx-access # kubectl delete pvc nginx-pvc www-web-0 www-web-1 www-web-2 # kubectl delete configmap nginx-configmap # kubectl delete secret nginx-sec","title":"Helming"},{"location":"cloud/KubernetesTutorials-Local-Deploy/","text":"Tutorials: Local Deployment 1.Installation Installing kubeadm, kubelet and kubectl Prerequisite: 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. These required ports need to be open in order for Kubernetes components to communicate with each other. Use command nc 127.0.0.1 6443 to check if a port is open. Swap disabled. You MUST disable swap in order for the kubelet to work properly. Turn off swap Turn off swap by command swapoff -a in all VMs. # sudo swapoff -a Kernel setting Load overlay and br_netfilter modules. Check the active module loaded list. The removed module is not on the module loaded list. # lsmod | grep overlay # lsmod | grep br_netfilter # sudo modprobe overlay # sudo modprobe br_netfilter Enable IP forwarding, known as routing or Kernel IP forwarding. The Linux IP forwarding feature is disabled by default. # sudo cat <<EOF >> /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.ipv4.conf.all.forwarding = 1 EOF Enable the change. # sudo sysctl --system Install Containerd Install and enable Containerd service. # sudo zypper in containerd containerd-ctr # sudo systemctl enable containerd.service # sudo systemctl start containerd.service # sudo systemctl status containerd.service Configure Containerd. Modify file /etc/containerd/config.toml . If file does not exist, execute the command sudo mkdir -p /etc/containerd to create it first. # sudo containerd config default | sudo tee /etc/containerd/config.toml # sudo vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd Install nerdctl The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. Refer to installation guide . # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # sudo cp nerdctl /usr/bin/ Verify nerdctl, e.g, list local Kubernetes containers. # nerdctl --help # nerdctl -n k8s.io ps Install Kubernetes Tools Install kubeadm , kubelet , kubectl . kubeadm : the command to bootstrap the cluster. kubelet : the component that runs on all of the machines in your cluster and does things like starting pods and containers. kubectl : the command line util to talk to your cluster. Install CNI plugins (required for most pod network): # CNI_VERSION=\"v0.8.2\" # ARCH=\"amd64\" # sudo mkdir -p /opt/cni/bin # curl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C /opt/cni/bin -xz Install crictl (required for kubeadm / Kubelet Container Runtime Interface (CRI)) # DOWNLOAD_DIR=/usr/local/bin # CRICTL_VERSION=\"v1.22.0\" # ARCH=\"amd64\" # curl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $DOWNLOAD_DIR -xz Install kubeadm , kubelet , kubectl . # DOWNLOAD_DIR=/usr/local/bin # RELEASE=\"$(curl -sSL https://dl.k8s.io/release/stable.txt)\" # ARCH=\"amd64\" # cd $DOWNLOAD_DIR # sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl} # sudo chmod +x {kubeadm,kubelet,kubectl} Add a kubelet systemd service, enable and start kubelet # RELEASE_VERSION=\"v0.4.0\" # curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service # sudo mkdir -p /etc/systemd/system/kubelet.service.d # curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf # systemctl enable --now kubelet # sudo systemctl status kubelet.service The content of file /etc/systemd/system/kubelet.service is below. [Unit] Description=kubelet: The Kubernetes Node Agent Documentation=https://kubernetes.io/docs/home/ Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/local/bin/kubelet Restart=always StartLimitInterval=0 RestartSec=10 [Install] WantedBy=multi-user.target The content of file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf is below. # Note: This dropin only works with kubeadm and kubelet v1.11+ [Service] Environment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf\" Environment=\"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml\" # This is a file that \"kubeadm init\" and \"kubeadm join\" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file. EnvironmentFile=-/etc/default/kubelet ExecStart= ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS Enable kubelet service on boot: # sudo systemctl enable kubelet At the moment, kubelet.service failed to start. kubelet was just installed without proper configuration. Configuring each kubelet in your cluster using kubeadm Helm Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Reference: installation guide binary release source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed. kind (optional) Installing From Release Binaries, which are available on releases page . Refer to Quich Start . NOTE: kind does not require kubectl, but we will not be able to perform some of tasks without it. kind requires that you have Docker installed and configured. Download the binary and copy to /usr/local/bin directory. james@lizard:/opt> curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-linux-amd64 james@lizard:/opt> chmod +x ./kind james@lizard:/opt> sudo cp ./kind /usr/local/bin To see all the clusters we have created. james@lizard:/opt> kind get clusters No kind clusters found. Minikube (optional) Install Minikube by referring to the guide . Installation. james@lizard:/opt> curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 69.2M 100 69.2M 0 0 5720k 0 0:00:12 0:00:12 --:--:-- 6328k james@lizard:/opt> sudo install minikube-linux-amd64 /usr/local/bin/minikube james@lizard:/opt> ll /usr/local/bin/minikube -rwxr-xr-x 1 root root 72651748 May 28 14:56 /usr/local/bin/minikube Start start cluster. james@lizard:/opt> minikube start minikube v1.25.2 on Opensuse-Leap 15.3 Using the docker driver based on existing profile docker is currently using the btrfs storage driver, consider switching to overlay2 for better performance Starting control plane node minikube in cluster minikube Pulling base image ... Updating the running docker \"minikube\" container ... Preparing Kubernetes v1.23.3 on Docker 20.10.12 ... \u25aa kubelet.housekeeping-interval=5ms \u25aa Generating certificates and keys ... \u25aa Booting up control plane ... \u25aa Configuring RBAC rules ... Verifying Kubernetes components... \u25aa Using image gcr.io/k8s-minikube/storage-provisioner:v5 Enabled addons: default-storageclass, storage-provisioner Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default Two folders were created after minikube start . ~/.kube : default config file was created here. ~/.minikube : configure files of Minikube. Check what Docker images has been pulled down and what containers are up after Minikube start. james@lizard:/opt> docker images --all REPOSITORY TAG IMAGE ID CREATED SIZE kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker container ls -all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 39 minutes ago Up 39 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube Get all nodes and namespaces deployed by default after Minikube installed. james@lizard:/opt> kubectl get nodes NAME STATUS ROLES AGE VERSION james@lizard:/opt> kubectl get ns NAME STATUS AGE default Active 4h51m kube-node-lease Active 4h51m kube-public Active 4h51m kube-system Active 4h51m Enbale Minikube addon - Dashboard. james@lizard:/opt> minikube addons list james@lizard:/opt> minikube addons enable dashboard Get all the services in all the namespaces. james@lizard:/opt> kubectl get service --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s james@lizard:/opt> kubectl get svc --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s Get details of deployment kubernetes-dashboard. james@lizard:/opt> kubectl get deployment -n kubernetes-dashboard NAME READY UP-TO-DATE AVAILABLE AGE dashboard-metrics-scraper 1/1 1 1 5m54s kubernetes-dashboard 1/1 1 1 5m54s Explore the dashboard, and verify it via http://localhost:9090 james@lizard:/opt> kubectl -n kubernetes-dashboard port-forward deployment/kubernetes-dashboard 9090 The dashboard looks like below.","title":"Tutorials: Local Deployment"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#tutorials-local-deployment","text":"","title":"Tutorials: Local Deployment"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#1installation","text":"","title":"1.Installation"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#installing-kubeadm-kubelet-and-kubectl","text":"Prerequisite: 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. These required ports need to be open in order for Kubernetes components to communicate with each other. Use command nc 127.0.0.1 6443 to check if a port is open. Swap disabled. You MUST disable swap in order for the kubelet to work properly.","title":"Installing kubeadm, kubelet and kubectl"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#turn-off-swap","text":"Turn off swap by command swapoff -a in all VMs. # sudo swapoff -a","title":"Turn off swap"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#kernel-setting","text":"Load overlay and br_netfilter modules. Check the active module loaded list. The removed module is not on the module loaded list. # lsmod | grep overlay # lsmod | grep br_netfilter # sudo modprobe overlay # sudo modprobe br_netfilter Enable IP forwarding, known as routing or Kernel IP forwarding. The Linux IP forwarding feature is disabled by default. # sudo cat <<EOF >> /etc/sysctl.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.ipv4.conf.all.forwarding = 1 EOF Enable the change. # sudo sysctl --system","title":"Kernel setting"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#install-containerd","text":"Install and enable Containerd service. # sudo zypper in containerd containerd-ctr # sudo systemctl enable containerd.service # sudo systemctl start containerd.service # sudo systemctl status containerd.service Configure Containerd. Modify file /etc/containerd/config.toml . If file does not exist, execute the command sudo mkdir -p /etc/containerd to create it first. # sudo containerd config default | sudo tee /etc/containerd/config.toml # sudo vi /etc/containerd/config.toml Update sandbox_image with new value \"registry.aliyuncs.com/google_containers/pause:3.6\" . Update SystemdCgroup with new value true . [plugins] [plugins.\"io.containerd.gc.v1.scheduler\"] [plugins.\"io.containerd.grpc.v1.cri\"] sandbox_image = \"registry.aliyuncs.com/google_containers/pause:3.6\" [plugins.\"io.containerd.grpc.v1.cri\".cni] [plugins.\"io.containerd.grpc.v1.cri\".containerd] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime.options] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] SystemdCgroup = true Restart Containerd service. # sudo systemctl restart containerd # sudo systemctl status containerd","title":"Install Containerd"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#install-nerdctl","text":"The goal of nerdctl is to facilitate experimenting the cutting-edge features of containerd that are not present in Docker. Refer to installation guide . # wget https://github.com/containerd/nerdctl/releases/download/v0.21.0/nerdctl-0.21.0-linux-amd64.tar.gz # tar -zxvf nerdctl-0.21.0-linux-amd64.tar.gz # sudo cp nerdctl /usr/bin/ Verify nerdctl, e.g, list local Kubernetes containers. # nerdctl --help # nerdctl -n k8s.io ps","title":"Install nerdctl"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#install-kubernetes-tools","text":"Install kubeadm , kubelet , kubectl . kubeadm : the command to bootstrap the cluster. kubelet : the component that runs on all of the machines in your cluster and does things like starting pods and containers. kubectl : the command line util to talk to your cluster. Install CNI plugins (required for most pod network): # CNI_VERSION=\"v0.8.2\" # ARCH=\"amd64\" # sudo mkdir -p /opt/cni/bin # curl -L \"https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz\" | sudo tar -C /opt/cni/bin -xz Install crictl (required for kubeadm / Kubelet Container Runtime Interface (CRI)) # DOWNLOAD_DIR=/usr/local/bin # CRICTL_VERSION=\"v1.22.0\" # ARCH=\"amd64\" # curl -L \"https://github.com/kubernetes-sigs/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-${ARCH}.tar.gz\" | sudo tar -C $DOWNLOAD_DIR -xz Install kubeadm , kubelet , kubectl . # DOWNLOAD_DIR=/usr/local/bin # RELEASE=\"$(curl -sSL https://dl.k8s.io/release/stable.txt)\" # ARCH=\"amd64\" # cd $DOWNLOAD_DIR # sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/${ARCH}/{kubeadm,kubelet,kubectl} # sudo chmod +x {kubeadm,kubelet,kubectl} Add a kubelet systemd service, enable and start kubelet # RELEASE_VERSION=\"v0.4.0\" # curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service # sudo mkdir -p /etc/systemd/system/kubelet.service.d # curl -sSL \"https://raw.githubusercontent.com/kubernetes/release/${RELEASE_VERSION}/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | sed \"s:/usr/bin:${DOWNLOAD_DIR}:g\" | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf # systemctl enable --now kubelet # sudo systemctl status kubelet.service The content of file /etc/systemd/system/kubelet.service is below. [Unit] Description=kubelet: The Kubernetes Node Agent Documentation=https://kubernetes.io/docs/home/ Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/local/bin/kubelet Restart=always StartLimitInterval=0 RestartSec=10 [Install] WantedBy=multi-user.target The content of file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf is below. # Note: This dropin only works with kubeadm and kubelet v1.11+ [Service] Environment=\"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf\" Environment=\"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml\" # This is a file that \"kubeadm init\" and \"kubeadm join\" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file. EnvironmentFile=-/etc/default/kubelet ExecStart= ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS Enable kubelet service on boot: # sudo systemctl enable kubelet At the moment, kubelet.service failed to start. kubelet was just installed without proper configuration. Configuring each kubelet in your cluster using kubeadm","title":"Install Kubernetes Tools"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#helm","text":"Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Reference: installation guide binary release source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed.","title":"Helm"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#kind-optional","text":"Installing From Release Binaries, which are available on releases page . Refer to Quich Start . NOTE: kind does not require kubectl, but we will not be able to perform some of tasks without it. kind requires that you have Docker installed and configured. Download the binary and copy to /usr/local/bin directory. james@lizard:/opt> curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.14.0/kind-linux-amd64 james@lizard:/opt> chmod +x ./kind james@lizard:/opt> sudo cp ./kind /usr/local/bin To see all the clusters we have created. james@lizard:/opt> kind get clusters No kind clusters found.","title":"kind (optional)"},{"location":"cloud/KubernetesTutorials-Local-Deploy/#minikube-optional","text":"Install Minikube by referring to the guide . Installation. james@lizard:/opt> curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 69.2M 100 69.2M 0 0 5720k 0 0:00:12 0:00:12 --:--:-- 6328k james@lizard:/opt> sudo install minikube-linux-amd64 /usr/local/bin/minikube james@lizard:/opt> ll /usr/local/bin/minikube -rwxr-xr-x 1 root root 72651748 May 28 14:56 /usr/local/bin/minikube Start start cluster. james@lizard:/opt> minikube start minikube v1.25.2 on Opensuse-Leap 15.3 Using the docker driver based on existing profile docker is currently using the btrfs storage driver, consider switching to overlay2 for better performance Starting control plane node minikube in cluster minikube Pulling base image ... Updating the running docker \"minikube\" container ... Preparing Kubernetes v1.23.3 on Docker 20.10.12 ... \u25aa kubelet.housekeeping-interval=5ms \u25aa Generating certificates and keys ... \u25aa Booting up control plane ... \u25aa Configuring RBAC rules ... Verifying Kubernetes components... \u25aa Using image gcr.io/k8s-minikube/storage-provisioner:v5 Enabled addons: default-storageclass, storage-provisioner Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default Two folders were created after minikube start . ~/.kube : default config file was created here. ~/.minikube : configure files of Minikube. Check what Docker images has been pulled down and what containers are up after Minikube start. james@lizard:/opt> docker images --all REPOSITORY TAG IMAGE ID CREATED SIZE kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker container ls -all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 39 minutes ago Up 39 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube Get all nodes and namespaces deployed by default after Minikube installed. james@lizard:/opt> kubectl get nodes NAME STATUS ROLES AGE VERSION james@lizard:/opt> kubectl get ns NAME STATUS AGE default Active 4h51m kube-node-lease Active 4h51m kube-public Active 4h51m kube-system Active 4h51m Enbale Minikube addon - Dashboard. james@lizard:/opt> minikube addons list james@lizard:/opt> minikube addons enable dashboard Get all the services in all the namespaces. james@lizard:/opt> kubectl get service --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s james@lizard:/opt> kubectl get svc --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s Get details of deployment kubernetes-dashboard. james@lizard:/opt> kubectl get deployment -n kubernetes-dashboard NAME READY UP-TO-DATE AVAILABLE AGE dashboard-metrics-scraper 1/1 1 1 5m54s kubernetes-dashboard 1/1 1 1 5m54s Explore the dashboard, and verify it via http://localhost:9090 james@lizard:/opt> kubectl -n kubernetes-dashboard port-forward deployment/kubernetes-dashboard 9090 The dashboard looks like below.","title":"Minikube (optional)"},{"location":"cloud/MicroservicesKubernetes/","text":"Hands-On Microservices with Kubernetes Sample code in GitHub Chapter 1 - Kubernetes Introduction to Kubernetes for Developers, introduces you to Kubernetes. You will receive a whirlwind tour of Kubernetes and get an ideaof how well it aligns with microservices. Technical requirements System environment for the demo Linux: openSUSE 15.3 Installing Docker Install Docker Desktop by referring the guide . Install Docker engine by referring the guide . Install engine via openSUSE repository automatically. james@lizard:/opt> sudo zypper in docker Add current user to docker group. The docker group is automatically created at package installation time. The user can communicate with the local Docker daemon upon its next login. The Docker daemon listens on a local socket which is accessible only by the root user and by the members of the docker group. james@lizard:/opt> sudo usermod -aG docker $USER Enable and start Docker engine. james@lizard:/opt> sudo systemctl enable docker.service Created symlink /etc/systemd/system/multi-user.target.wants/docker.service \u2192 /usr/lib/systemd/system/docker.service. james@lizard:/opt> sudo systemctl start docker.service james@lizard:/opt> sudo systemctl status docker.service \u25cf docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2022-05-28 14:36:45 CST; 6s ago Docs: http://docs.docker.com Main PID: 31565 (dockerd) Tasks: 20 CGroup: /system.slice/docker.service \u251c\u250031565 /usr/bin/dockerd --add-runtime oci=/usr/sbin/docker-runc \u2514\u250031574 containerd --config /var/run/docker/containerd/containerd.toml --log-level warn May 28 14:36:44 lizard systemd[1]: Starting Docker Application Container Engine... May 28 14:36:44 lizard dockerd[31565]: time=\"2022-05-28T14:36:44+08:00\" level=info msg=\"SUSE:secrets :: enabled\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44+08:00\" level=warning msg=\"deprecated version : `1`, please switch to version `2`\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.659346964+08:00\" level=warning msg=\"failed to load plugin io.containerd.snapshotter.v1.devmapper\" error=\"devmapper no> May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.660040930+08:00\" level=warning msg=\"could not use snapshotter devmapper in metadata plugin\" error=\"devmapper not conf> May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018458102+08:00\" level=warning msg=\"Your kernel does not support swap memory limit\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018495482+08:00\" level=warning msg=\"Your kernel does not support CPU realtime scheduler\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018502682+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018506223+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight_device\" May 28 14:36:45 lizard systemd[1]: Started Docker Application Container Engine. Installing kubectl Install kubectl by referring the guidd . Download kubectl. james@lizard:/opt> curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" Install kubectl. james@lizard:/opt> sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl james@lizard:/opt> l /usr/local/bin/kubectl -rwxr-xr-x 1 root root 45711360 May 28 14:49 /usr/local/bin/kubectl* Test to ensure the version you installed is up-to-date: james@lizard:/opt> kubectl version --client WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short. Use --output=yaml|json to get the full version. Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.1\", GitCommit:\"3ddd0f45aa91e2f30c70734b175631bec5b5825a\", GitTreeState:\"clean\", BuildDate:\"2022-05-24T12:26:19Z\", GoVersion:\"go1.18.2\", Compiler:\"gc\", Platform:\"linux/amd64\"} Kustomize Version: v4.5.4 Installing Minikube Install Minikube by referring to the guide . Installation. james@lizard:/opt> curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 69.2M 100 69.2M 0 0 5720k 0 0:00:12 0:00:12 --:--:-- 6328k james@lizard:/opt> sudo install minikube-linux-amd64 /usr/local/bin/minikube james@lizard:/opt> ll /usr/local/bin/minikube -rwxr-xr-x 1 root root 72651748 May 28 14:56 /usr/local/bin/minikube Start start cluster. james@lizard:/opt> minikube start minikube v1.25.2 on Opensuse-Leap 15.3 Using the docker driver based on existing profile docker is currently using the btrfs storage driver, consider switching to overlay2 for better performance Starting control plane node minikube in cluster minikube Pulling base image ... Updating the running docker \"minikube\" container ... Preparing Kubernetes v1.23.3 on Docker 20.10.12 ... \u25aa kubelet.housekeeping-interval=5m \u25aa Generating certificates and keys ... \u25aa Booting up control plane ... \u25aa Configuring RBAC rules ... Verifying Kubernetes components... \u25aa Using image gcr.io/k8s-minikube/storage-provisioner:v5 Enabled addons: default-storageclass, storage-provisioner Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default Two folders were created after minikube start . ~/.kube : default config file was created here. ~/.minikube : configure files of Minikube. Check what Docker images has been pulled down and what containers are up after Minikube start. james@lizard:/opt> docker images --all REPOSITORY TAG IMAGE ID CREATED SIZE kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker container ls -all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 39 minutes ago Up 39 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube The Kubernetes architecture Diagram that illustrates the overall architecture of Kubernetes. The control plane in production will be distributed across multiple machines for high availability and robustness. The control plane will deploy and run your pods (groups of containers) on these nodes, and then watch for changes and respond. The control plane: API server. Exposes the Kubernetes APIto the world. Keeps the cluster state in etcd . The etcd metadata store. a consistent and reliable, distributed key-value store to keep complete cluster. The etcd store is an open source project. It is common to have three or five instances of etcd for redundancy. If you losethe data in your etcd store, you lose your cluster. Scheduler. Responsible for scheduling pods to worker nodes. Controller manager. It is a single process that contains multiplecontrollers for simplicity. Node controller : Responsible for noticing and responding when nodes go down. Replication controller : This makes sure that there is the correct number of pods for each replica set or replication controller object. Endpoints controller : This assigns for each service an endpoints object that lists the service's pods. Service account and token controllers : These initialize new namespaces with default service accounts and corresponding API access tokens. The data plane: The data plane is the collection of the nodes in the cluster that run your containerized workloads as pods. The kubelet: It is a Kubernetes agent. It's responsible for talking to the API serverand for running and managing the pods on the node. Downloading pod secrets from the API server Mounting volumes Running the pod container via the Container Runtime Interface (CRI) Reporting the status of the node and each pod Probe container liveness (restart the pod's container if it crashes) The kube proxy: The kube proxy is responsible for the networking aspects of the node. The container runtime Kubernetes supports different container runtimes. Kubernetes runs containers through an interface called CRI ,which is based on gRPC . Each container runtime that implements CRI can be used on a node controlled by the kubelet. The kubectl: Cluster management Deployment Troubleshooting and debugging Resource management (Kubernetes objects) Configuration and metadata Kubernetes and microservices Packaging and deploying microservices The packaging mechanism is simply containers. Every microservice you develop will have a Dockerfile. The resulting image represents the deployment unit for that microservice. In Kubernetes, your microservice image will run inside a pod (possibly alongside other containers). The kubelet on the node will restart the pod's container if it crashes, but if something happens to the node itself, the pod is gone. Kubernetes has abstractions and resources that build on the pod. ReplicaSets are sets of pods with a certain number of replicas. When you create a ReplicaSet, Kubernetes will make sure that the correct number of pods you specify always run in the cluster. We use a deployment YAML file to deploy our microservice. Exposing and discovering microservices We use a service YAML file to expose our microservice so that it can be used by other services in/out the cluster. Kubernetes services are backed up by pods, identified by labels. Services discover each other inside the cluster, using DNS or environment variables. Securing microservices. Namespaces. Let you isolate different parts of your cluster from each other. Pods running in anamespace can only access directly their own namespace. To access othernamespaces, they must go through public APIs. Service accounts. Service accounts provide identity to your microservices. You can associate service accounts with a pod. Each service account is associated with a secret used to authenticate it. Secrets. Secrets are managed per namespace. Secrets are mounted in pods as either files (secret volumes) or environment variables. The secrets can be encrypted at rest on etcd, and are always encrypted on the wire (over HTTPS). Secrets communication. All communication to the Kubernetes API from outside should be over HTTP, which by default is not authenticated. Internal cluster communication between the API server and the kubelet on the node is over HTTPS too (the kubelet endpoint). Network policies. In a distributed system, beyond securing each container, pod, and node, it iscritical to also control communication over the network. Authenticating and authorizing microservices. Role-based access control (RBAC) is is based on two concepts: role and binding. A role is a set of permissions on resources defined as rules. There are two types of roles: Role, which applies to a single namespace, and ClusterRole, which applies to all namespaces in a cluster. Each role has three components: API groups, resources, and verbs. Cluster roles are very similar, except there is no namespace field because they apply to all namespaces. A binding is associating a list of subjects (users, user groups, or service accounts) with a role. There are two types of binding, RoleBinding and ClusterRoleBinding, which correspond to Role and ClusterRole. You can bind a ClusterRole to a subject in a single namespace. Upgrading microservices Scaling microservices. Two aspects: The first aspect is scaling the number of pods backing up a particular microservice. scaling out (horizontal scaling) by adding more servers to your architecture to spread the workload across more machines. The second aspect is the total capacity of the cluster. Scaling up (vertical scaling) by adding more hard drives and memory to increase the computing capacity of physical servers. Monitoring microservices. Third-party logs Application logs Application errors Kubernetes events Metrics, which are useful for detecting performance and system health problems or trends over time. Logging. Several ways: Have a logging agent that runs on every node Inject a logging sidecar container to every application pod Have your application send its logs directly to a central logging service Metrics. Kubernetes provide metrics server: heapster Prometheus Creating a local cluster Playing with your cluster Get all nodes deployed. james@lizard:/opt> kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready control-plane,master 4h49m v1.23.3 Get all namespaces. james@lizard:/opt> kubectl get ns NAME STATUS AGE default Active 4h51m kube-node-lease Active 4h51m kube-public Active 4h51m kube-system Active 4h51m Enbale Minikube addon - Dashboard. james@lizard:/opt> minikube addons list james@lizard:/opt> minikube addons enable dashboard Get all the services in all the namespaces. james@lizard:/opt> kubectl get service --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s james@lizard:/opt> kubectl get svc --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s Get details of deployment kubernetes-dashboard. james@lizard:/opt> kubectl get deployment -n kubernetes-dashboard NAME READY UP-TO-DATE AVAILABLE AGE dashboard-metrics-scraper 1/1 1 1 5m54s kubernetes-dashboard 1/1 1 1 5m54s Explore the dashboard, and verify it via http://localhost:9090 james@lizard:/opt> kubectl -n kubernetes-dashboard port-forward deployment/kubernetes-dashboard 9090 The dashboard looks like below. Installing Helm Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Refer to installation guide and binary release and source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed. Chapter 2 - Microservices Getting Started with Microservices, discusses various aspects,patterns, and approaches to common problems in microservice-basedsystems and how they compare to other common architectures, such asmonoliths and large services. Installing Go Refer to installation guide to download and install Go locally. Installation james@lizard:/opt> sudo zypper in go james@lizard:/opt> go version go version go1.18.2 linux/amd64 Choosing source control strategy. There are two main approaches: monorepo Your entire code base is in a single source controlrepository. multiple repos Each project, and often each library, has a separate source control repository. Hybrid Each repository contains multiple services and projects. Each repository is isolated from the other repositories, but within each repo, multiple services and projectscan be developed in lockstep. This approach balances the pros and cons ofmonorepo and multiple repos. Choosing data strategy One data store per microservice, which is a crucial element of the microservicearchitecture. Running distributed queries. It recommends to start with API composition andtransition to CQRS only if the proper conditions exist. Employing Command Query Responsibility Segregation (CQRS). The CQRS service (responsible forqueries) receives a change notification from the three microservices (responsible for updates) and aggregates them into its own data store. When a query comes, the CQRS service responds by accessing its own aggregated view without hitting the microservices. It duplicates the data and adds complexity to the system. An illustration of CQRS in action. Employing API composition. It exposes an API that can answer well-known queries across multiple microservices. A query to an API composer service is translated under the covers to queries to three microservices. The failure of any service will fail the query. An illustration of API composition in action Maintaining distributed dataintegrity is a complex problem. If you store all your data in a single relationaldatabase and specify proper constraints in your schema, then you can rely on the database engine to take care of data integrity. If multiple microservices maintain your data in isolated data stores (relational ornon-relational). Data integrity is essential, but it must be maintained by your code. The saga pattern addresses this concern. A common measure of data integrity is that all transactions that modify data havethe ACID properties. Atomic: All operations in the transaction succeed or they all fail. Consistent: The state of the data complies with all constraints before and after the transaction. Isolated: Concurrent transactions behave as if serialized. Durable: When a transaction completes successfully, the results are persisted. There are different levels of persistence: Persistence to disk: Can survive restart of the node, but no disk failure Redundant memory on multiple nodes: Can survive restart of a node and disk failure, but not temporary failure of all the nodes Redundant disks: Can survive the failure of a disk Geo-distributed replicas: Can survive a whole data center being down Backups: Cheaper to store a lot of information, but slower to restore and often lags behind real time The CAP theorem states that a distributed system can't have all three propertiesat the same time: Consistency Availability Partition resiliency The basic idea of the saga pattern is that there is centralized management of the operations across all the microservices and that, for each operation, there is a compensating operation that will be executed if, for some reason, the entire transaction can't be completed. This achieves the atomicity property of ACID. A saga is a set of operations and corresponding compensating operations on microservices. When an operation fails, its compensating operation and the compensating operations of all the previous operations are called in reverse order to roll back the entire state of the system. Chapter 3 - Sample Application Delinkcious \u2013 the Sample Application, explores why we should choose Go as the programming language of Delinkcious; then we will lookat Go kit. Delinkcious source code Go kit , which is a toolkit for microservice. Download Delinkcious source code release v0.1 and unpack it under folder /opt . The whole structure looks like below. The pkg directory contains packages that are used by services and commands.We should run the unit tests of these packages. The svc directory contains ourmicroservices. We should build those services, package each one in a properly versioned Docker image, and push those images to DockerHub (the imageregistry). The cmd directory currently contains end-to-end tests. Those are designed to run locally and don't need to be built by the CI pipeline. james@lizard:/opt> tree delinkcious-0.1 delinkcious-0.1 \u251c\u2500\u2500 cmd \u2502 \u2514\u2500\u2500 social_graph_service_e2e \u2502 \u251c\u2500\u2500 README.md \u2502 \u2514\u2500\u2500 social_graph_service_e2e.go \u251c\u2500\u2500 go.mod \u251c\u2500\u2500 go.sum \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 pkg \u2502 \u251c\u2500\u2500 link_manager \u2502 \u2502 \u251c\u2500\u2500 abstract_link_store.go \u2502 \u2502 \u251c\u2500\u2500 db_link_store.go \u2502 \u2502 \u251c\u2500\u2500 db_link_store_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_link_store.go \u2502 \u2502 \u251c\u2500\u2500 link_manager.go \u2502 \u2502 \u2514\u2500\u2500 link_manager_suite_test.go \u2502 \u251c\u2500\u2500 link_manager_client \u2502 \u2502 \u2514\u2500\u2500 client.go \u2502 \u251c\u2500\u2500 object_model \u2502 \u2502 \u251c\u2500\u2500 interfaces.go \u2502 \u2502 \u251c\u2500\u2500 README.md \u2502 \u2502 \u2514\u2500\u2500 types.go \u2502 \u251c\u2500\u2500 social_graph_client \u2502 \u2502 \u251c\u2500\u2500 client.go \u2502 \u2502 \u2514\u2500\u2500 endpoints.go \u2502 \u251c\u2500\u2500 social_graph_manager \u2502 \u2502 \u251c\u2500\u2500 db_scoial_graph_store.go \u2502 \u2502 \u251c\u2500\u2500 db_social_graph_manager_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_social_graph_manager_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_social_graph_store.go \u2502 \u2502 \u251c\u2500\u2500 social_graph_manager.go \u2502 \u2502 \u2514\u2500\u2500 social_graph_manager_suite_test.go \u2502 \u2514\u2500\u2500 user_manager \u2502 \u251c\u2500\u2500 db_user_manager_test.go \u2502 \u251c\u2500\u2500 db_user_store.go \u2502 \u251c\u2500\u2500 in_memory_user_manager.go \u2502 \u251c\u2500\u2500 in_memory_user_manager_test.go \u2502 \u251c\u2500\u2500 in_memory_user_store.go \u2502 \u2514\u2500\u2500 user_manager_suite_test.go \u251c\u2500\u2500 README.md \u2514\u2500\u2500 svc \u251c\u2500\u2500 delinkcious_service \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 link_service \u2502 \u251c\u2500\u2500 link_service.go \u2502 \u2514\u2500\u2500 transport.go \u251c\u2500\u2500 social_graph_service \u2502 \u251c\u2500\u2500 main.go \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 social_graph_service.go \u2502 \u2514\u2500\u2500 transport.go \u2514\u2500\u2500 user_service \u251c\u2500\u2500 transport.go \u2514\u2500\u2500 user_service.go 15 directories, 38 files Download and launch the Postgres DB. james@lizard:/opt> docker pull postgres:alpine james@lizard:/opt> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE postgres latest 5b21e2e86aab 14 hours ago 376MB kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker run --name postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 -d postgres:alpine james@lizard:/opt> docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 223e0f44e107 postgres \"docker-entrypoint.s\u2026\" 26 seconds ago Up 24 seconds 5432/tcp postgres-delinkcious 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 18 hours ago Up 19 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube james@lizard:/opt> cd delinkcious-0.1/svc/social_graph_service james@lizard:/opt/delinkcious-0.1/svc/social_graph_service> go run main.go 2022/05/29 12:50:55 pq: unknown authentication response: 10 exit status 1 Chapter 4 - CI/CD Pipeline Setting Up the CI/CD Pipeline, teaches you about the problem the CI/CD pipeline solves, covers the different options for CI/CD pipelinesfor Kubernetes, and finally looks at building a CI/CD pipeline forDelinkcious. Download Delinkcious source code release v0.2 and unpack it under folder /opt . Here we use CircleCI and Argo CD. Prefer to separate the CI solution from the CD solution. Conceptually, the role of the CI process is to generate a container image and push it to a registry. It doesn'tneed to be aware of Kubernetes at all. The CD solution, on the other hand, must be Kubernetes-aware, and it ideally runs inside the cluster. Tekton is a very interesting project. It is Kubernetes-native and has great abstractions of steps, tasks, runs, and pipelines. It is relatively young, but seemsvery promising. It was also selected as one of the inaugural projects of the CD Foundation: https://cd.foundation/projects/. Jenkins X provides automated CI+CD for Kubernetes with Preview Environments on Pull Requests using Cloud Native pipelines from Tekton Argo CD is very specific CD solution to Kubernetes. CircleCI: https://circleci.com/docs/ Argo: https://argoproj.github.io/docs/argo-cd/docs/ Free mini ebook about CI/CD with Kubernetes:https://thenewstack.io/ebooks/kubernetes/ci-cd-with-kubernetes/ Jenkins X: https://jenkins-x.io/ Spinnaker: https://www.spinnaker.io/ Chapter 5 - Configuring Microservices Configuring Microservices with Kubernetes, moves you into the practical and real-world area of microservices configuration. Also, we will discuss Kubernetes-specific options and, in particular, ConfigMaps. The code samples at https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter05 The updated Delinkcious application at https://github.com/the-gigi/delinkcious/releases/tag/v0.3 Configuration is a very overloaded term. Configuration mostly refers to operational data that's needed forcomputation. The configuration may be different between environments. Here are some typical configuration items: Service discovery Support testing Environment-specific metadata Secrets Third-party configuration Feature flags Timeouts Rate limits Various defaults Twelve factor app configuration Dynamic configuration means that the service keeps running with the same codeand the same in-memory state, but it can detect that the configuration has changed, and will dynamically adjust its behavior according to the new configuration. Dynamic configuration is useful in the following cases: If you just have a single instance of your service, then restarting means a mini-outage If you have feature flags that you want to switch back and forth quickly If you have services where initialization or dropping in-flight requests is expansive If your service doesn't support advanced deployment strategies, such as rolling updates, or blue-green or canary deployments When redeploying a new configuration file may pull in unrelated code changes from source control that are not ready for deployment yet. When should you avoid dynamic configuration? Regulated services where configuration change must go through a vetting and approval process Critical services where the low risk of static configuration trumps any benefit of dynamic configuration A dynamic configuration mechanism doesn't exist and the benefits don't justify the development of such a mechanism Existing system with a large number of services where the benefits of migration to a dynamic configuration doesn't justify the cost Advanced deployment strategies provide the benefits of dynamic configuration with static configuration and restarts/redeployments The added complexity of keeping track of and auditing configuration changes is too high One of the options for dynamic configuration is a remote configuration store. All service instances can periodically query the configuration store, check whetherthe configuration has changed, and read the new configuration when it does. Possible options include the following: * Relational databases (Postgres, MySQL) * Key\u2013value stores (Etcd, Redis) * Shared filesystems (NFS, EFS) Chapter 6 - Securing Microservices Securing Microservices on Kubernetes, examines how to secure your microservices on Kubernetes in depth. We will also discuss the pillars that act as the foundation of microservice security on Kubernetes. Chapter 7 - APIs and Load Balancers Talking to the World \u2013 APIs and Load Balancers, sees us open Delinkcious to the world and let users interact with it from outside the cluster. Also, we will add a gRPC-based news service that users can hitup to get news about other users they follow. Finally, we will add a message queue that lets services communicate in a loosely coupled manner. Chapter 8 - Stateful Services Working with Stateful Services, delves into the Kubernetesstorage model. We will also extend the Delinkcious news service to store itsdata in Redis, instead of in memory. Chapter 9 Serverless Tasks Running Serverless Tasks on Kubernetes, dives into one of thehottest trends in cloud-native systems: serverless computing (also knownas Function as a Service, or FaaS). Also, we'll cover other ways to doserverless computing in Kubernetes. Chapter 10 - Testing Microservices Testing Microservices, covers the topic of testing and its variousflavors: unit testing, integration testing, and all kinds of end-to-end testing.We also delve into how Delinkcious tests are structured. Chapter 11 - Deploying Microservices Deploying Microservices, deals with two related, yet separate,themes: production deployments and development deployments. Chapter 12 - Operationing Microservices Monitoring, Logging, and Metrics, focuses on the operational side of running a large-scale distributed system on Kubernetes, as well ason how to design the system and what to take into account to ensure atop-notch operational posture. Chapter 13 - Service Mesh Service Mesh \u2013 Working with Istio, reviews the hot topic ofservice meshes and, in particular, Istio. This is exciting because service meshes are a real game changer. Chapter 14 - The Future The Future of Microservices and Kubernetes, covers the topicsof Kubernetes and microservices, and will help us learn how to decide whenit's the right time to adopt and invest in newer technologies. Reference: The code of the book Kubernetes document Minikube documents Helm document and source code and artifact hub Go language document","title":"Hands-On Microservices with Kubernetes"},{"location":"cloud/MicroservicesKubernetes/#hands-on-microservices-with-kubernetes","text":"Sample code in GitHub","title":"Hands-On Microservices with Kubernetes"},{"location":"cloud/MicroservicesKubernetes/#chapter-1-kubernetes","text":"Introduction to Kubernetes for Developers, introduces you to Kubernetes. You will receive a whirlwind tour of Kubernetes and get an ideaof how well it aligns with microservices.","title":"Chapter 1 - Kubernetes"},{"location":"cloud/MicroservicesKubernetes/#technical-requirements","text":"","title":"Technical requirements"},{"location":"cloud/MicroservicesKubernetes/#system-environment-for-the-demo","text":"Linux: openSUSE 15.3","title":"System environment for the demo"},{"location":"cloud/MicroservicesKubernetes/#installing-docker","text":"Install Docker Desktop by referring the guide . Install Docker engine by referring the guide . Install engine via openSUSE repository automatically. james@lizard:/opt> sudo zypper in docker Add current user to docker group. The docker group is automatically created at package installation time. The user can communicate with the local Docker daemon upon its next login. The Docker daemon listens on a local socket which is accessible only by the root user and by the members of the docker group. james@lizard:/opt> sudo usermod -aG docker $USER Enable and start Docker engine. james@lizard:/opt> sudo systemctl enable docker.service Created symlink /etc/systemd/system/multi-user.target.wants/docker.service \u2192 /usr/lib/systemd/system/docker.service. james@lizard:/opt> sudo systemctl start docker.service james@lizard:/opt> sudo systemctl status docker.service \u25cf docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2022-05-28 14:36:45 CST; 6s ago Docs: http://docs.docker.com Main PID: 31565 (dockerd) Tasks: 20 CGroup: /system.slice/docker.service \u251c\u250031565 /usr/bin/dockerd --add-runtime oci=/usr/sbin/docker-runc \u2514\u250031574 containerd --config /var/run/docker/containerd/containerd.toml --log-level warn May 28 14:36:44 lizard systemd[1]: Starting Docker Application Container Engine... May 28 14:36:44 lizard dockerd[31565]: time=\"2022-05-28T14:36:44+08:00\" level=info msg=\"SUSE:secrets :: enabled\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44+08:00\" level=warning msg=\"deprecated version : `1`, please switch to version `2`\" May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.659346964+08:00\" level=warning msg=\"failed to load plugin io.containerd.snapshotter.v1.devmapper\" error=\"devmapper no> May 28 14:36:44 lizard dockerd[31574]: time=\"2022-05-28T14:36:44.660040930+08:00\" level=warning msg=\"could not use snapshotter devmapper in metadata plugin\" error=\"devmapper not conf> May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018458102+08:00\" level=warning msg=\"Your kernel does not support swap memory limit\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018495482+08:00\" level=warning msg=\"Your kernel does not support CPU realtime scheduler\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018502682+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight\" May 28 14:36:45 lizard dockerd[31565]: time=\"2022-05-28T14:36:45.018506223+08:00\" level=warning msg=\"Your kernel does not support cgroup blkio weight_device\" May 28 14:36:45 lizard systemd[1]: Started Docker Application Container Engine.","title":"Installing Docker"},{"location":"cloud/MicroservicesKubernetes/#installing-kubectl","text":"Install kubectl by referring the guidd . Download kubectl. james@lizard:/opt> curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" Install kubectl. james@lizard:/opt> sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl james@lizard:/opt> l /usr/local/bin/kubectl -rwxr-xr-x 1 root root 45711360 May 28 14:49 /usr/local/bin/kubectl* Test to ensure the version you installed is up-to-date: james@lizard:/opt> kubectl version --client WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short. Use --output=yaml|json to get the full version. Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.1\", GitCommit:\"3ddd0f45aa91e2f30c70734b175631bec5b5825a\", GitTreeState:\"clean\", BuildDate:\"2022-05-24T12:26:19Z\", GoVersion:\"go1.18.2\", Compiler:\"gc\", Platform:\"linux/amd64\"} Kustomize Version: v4.5.4","title":"Installing kubectl"},{"location":"cloud/MicroservicesKubernetes/#installing-minikube","text":"Install Minikube by referring to the guide . Installation. james@lizard:/opt> curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 69.2M 100 69.2M 0 0 5720k 0 0:00:12 0:00:12 --:--:-- 6328k james@lizard:/opt> sudo install minikube-linux-amd64 /usr/local/bin/minikube james@lizard:/opt> ll /usr/local/bin/minikube -rwxr-xr-x 1 root root 72651748 May 28 14:56 /usr/local/bin/minikube Start start cluster. james@lizard:/opt> minikube start minikube v1.25.2 on Opensuse-Leap 15.3 Using the docker driver based on existing profile docker is currently using the btrfs storage driver, consider switching to overlay2 for better performance Starting control plane node minikube in cluster minikube Pulling base image ... Updating the running docker \"minikube\" container ... Preparing Kubernetes v1.23.3 on Docker 20.10.12 ... \u25aa kubelet.housekeeping-interval=5m \u25aa Generating certificates and keys ... \u25aa Booting up control plane ... \u25aa Configuring RBAC rules ... Verifying Kubernetes components... \u25aa Using image gcr.io/k8s-minikube/storage-provisioner:v5 Enabled addons: default-storageclass, storage-provisioner Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default Two folders were created after minikube start . ~/.kube : default config file was created here. ~/.minikube : configure files of Minikube. Check what Docker images has been pulled down and what containers are up after Minikube start. james@lizard:/opt> docker images --all REPOSITORY TAG IMAGE ID CREATED SIZE kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker container ls -all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 39 minutes ago Up 39 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube","title":"Installing Minikube"},{"location":"cloud/MicroservicesKubernetes/#the-kubernetes-architecture","text":"Diagram that illustrates the overall architecture of Kubernetes. The control plane in production will be distributed across multiple machines for high availability and robustness. The control plane will deploy and run your pods (groups of containers) on these nodes, and then watch for changes and respond. The control plane: API server. Exposes the Kubernetes APIto the world. Keeps the cluster state in etcd . The etcd metadata store. a consistent and reliable, distributed key-value store to keep complete cluster. The etcd store is an open source project. It is common to have three or five instances of etcd for redundancy. If you losethe data in your etcd store, you lose your cluster. Scheduler. Responsible for scheduling pods to worker nodes. Controller manager. It is a single process that contains multiplecontrollers for simplicity. Node controller : Responsible for noticing and responding when nodes go down. Replication controller : This makes sure that there is the correct number of pods for each replica set or replication controller object. Endpoints controller : This assigns for each service an endpoints object that lists the service's pods. Service account and token controllers : These initialize new namespaces with default service accounts and corresponding API access tokens. The data plane: The data plane is the collection of the nodes in the cluster that run your containerized workloads as pods. The kubelet: It is a Kubernetes agent. It's responsible for talking to the API serverand for running and managing the pods on the node. Downloading pod secrets from the API server Mounting volumes Running the pod container via the Container Runtime Interface (CRI) Reporting the status of the node and each pod Probe container liveness (restart the pod's container if it crashes) The kube proxy: The kube proxy is responsible for the networking aspects of the node. The container runtime Kubernetes supports different container runtimes. Kubernetes runs containers through an interface called CRI ,which is based on gRPC . Each container runtime that implements CRI can be used on a node controlled by the kubelet. The kubectl: Cluster management Deployment Troubleshooting and debugging Resource management (Kubernetes objects) Configuration and metadata","title":"The Kubernetes architecture"},{"location":"cloud/MicroservicesKubernetes/#kubernetes-and-microservices","text":"","title":"Kubernetes and microservices"},{"location":"cloud/MicroservicesKubernetes/#packaging-and-deploying-microservices","text":"The packaging mechanism is simply containers. Every microservice you develop will have a Dockerfile. The resulting image represents the deployment unit for that microservice. In Kubernetes, your microservice image will run inside a pod (possibly alongside other containers). The kubelet on the node will restart the pod's container if it crashes, but if something happens to the node itself, the pod is gone. Kubernetes has abstractions and resources that build on the pod. ReplicaSets are sets of pods with a certain number of replicas. When you create a ReplicaSet, Kubernetes will make sure that the correct number of pods you specify always run in the cluster. We use a deployment YAML file to deploy our microservice.","title":"Packaging and deploying microservices"},{"location":"cloud/MicroservicesKubernetes/#exposing-and-discovering-microservices","text":"We use a service YAML file to expose our microservice so that it can be used by other services in/out the cluster. Kubernetes services are backed up by pods, identified by labels. Services discover each other inside the cluster, using DNS or environment variables.","title":"Exposing and discovering microservices"},{"location":"cloud/MicroservicesKubernetes/#securing-microservices","text":"Namespaces. Let you isolate different parts of your cluster from each other. Pods running in anamespace can only access directly their own namespace. To access othernamespaces, they must go through public APIs. Service accounts. Service accounts provide identity to your microservices. You can associate service accounts with a pod. Each service account is associated with a secret used to authenticate it. Secrets. Secrets are managed per namespace. Secrets are mounted in pods as either files (secret volumes) or environment variables. The secrets can be encrypted at rest on etcd, and are always encrypted on the wire (over HTTPS). Secrets communication. All communication to the Kubernetes API from outside should be over HTTP, which by default is not authenticated. Internal cluster communication between the API server and the kubelet on the node is over HTTPS too (the kubelet endpoint). Network policies. In a distributed system, beyond securing each container, pod, and node, it iscritical to also control communication over the network.","title":"Securing microservices."},{"location":"cloud/MicroservicesKubernetes/#authenticating-and-authorizing-microservices","text":"Role-based access control (RBAC) is is based on two concepts: role and binding. A role is a set of permissions on resources defined as rules. There are two types of roles: Role, which applies to a single namespace, and ClusterRole, which applies to all namespaces in a cluster. Each role has three components: API groups, resources, and verbs. Cluster roles are very similar, except there is no namespace field because they apply to all namespaces. A binding is associating a list of subjects (users, user groups, or service accounts) with a role. There are two types of binding, RoleBinding and ClusterRoleBinding, which correspond to Role and ClusterRole. You can bind a ClusterRole to a subject in a single namespace.","title":"Authenticating and authorizing microservices."},{"location":"cloud/MicroservicesKubernetes/#upgrading-microservices","text":"Scaling microservices. Two aspects: The first aspect is scaling the number of pods backing up a particular microservice. scaling out (horizontal scaling) by adding more servers to your architecture to spread the workload across more machines. The second aspect is the total capacity of the cluster. Scaling up (vertical scaling) by adding more hard drives and memory to increase the computing capacity of physical servers. Monitoring microservices. Third-party logs Application logs Application errors Kubernetes events Metrics, which are useful for detecting performance and system health problems or trends over time. Logging. Several ways: Have a logging agent that runs on every node Inject a logging sidecar container to every application pod Have your application send its logs directly to a central logging service Metrics. Kubernetes provide metrics server: heapster Prometheus","title":"Upgrading microservices"},{"location":"cloud/MicroservicesKubernetes/#creating-a-local-cluster","text":"","title":"Creating a local cluster"},{"location":"cloud/MicroservicesKubernetes/#playing-with-your-cluster","text":"Get all nodes deployed. james@lizard:/opt> kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready control-plane,master 4h49m v1.23.3 Get all namespaces. james@lizard:/opt> kubectl get ns NAME STATUS AGE default Active 4h51m kube-node-lease Active 4h51m kube-public Active 4h51m kube-system Active 4h51m Enbale Minikube addon - Dashboard. james@lizard:/opt> minikube addons list james@lizard:/opt> minikube addons enable dashboard Get all the services in all the namespaces. james@lizard:/opt> kubectl get service --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s james@lizard:/opt> kubectl get svc --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 5h2m kube-system kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 5h2m kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.110.44.98 <none> 8000/TCP 49s kubernetes-dashboard kubernetes-dashboard ClusterIP 10.108.121.183 <none> 80/TCP 49s Get details of deployment kubernetes-dashboard. james@lizard:/opt> kubectl get deployment -n kubernetes-dashboard NAME READY UP-TO-DATE AVAILABLE AGE dashboard-metrics-scraper 1/1 1 1 5m54s kubernetes-dashboard 1/1 1 1 5m54s Explore the dashboard, and verify it via http://localhost:9090 james@lizard:/opt> kubectl -n kubernetes-dashboard port-forward deployment/kubernetes-dashboard 9090 The dashboard looks like below.","title":"Playing with your cluster"},{"location":"cloud/MicroservicesKubernetes/#installing-helm","text":"Helm is the Kubernetes package manager. It doesn't come with Kubernetes. Three concepts of helm: A Chart is a Helm package. It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. Think of it like the Kubernetes equivalent of a Homebrew formula, an Apt dpkg, or a Yum RPM file. A Repository is the place where charts can be collected and shared. It's like Perl's CPAN archive or the Fedora Package Database, but for Kubernetes packages. A Release is an instance of a chart running in a Kubernetes cluster. One chart can often be installed many times into the same cluster. And each time it is installed, a new release is created. Consider a MySQL chart. If you want two databases running in your cluster, you can install that chart twice. Each one will have its own release, which will in turn have its own release name. Refer to installation guide and binary release and source code . Helm Client Installation: james@lizard:/opt> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 james@lizard:/opt> chmod 700 get_helm.sh james@lizard:/opt> ./get_helm.sh Downloading https://get.helm.sh/helm-v3.9.0-linux-amd64.tar.gz Verifying checksum... Done. Preparing to install helm into /usr/local/bin helm installed into /usr/local/bin/helm Note: helm init does not exist in Helm 3, following the removal of Tiller. You no longer need to install Tiller in your cluster in order to use Helm. helm search can be used to search two different types of source: helm search hub searches the Artifact Hub , which lists helm charts from dozens of different repositories. helm search repo searches the repositories that you have added to your local helm client (with helm repo add). This search is done over local data, and no public network connection is needed.","title":"Installing Helm"},{"location":"cloud/MicroservicesKubernetes/#chapter-2-microservices","text":"Getting Started with Microservices, discusses various aspects,patterns, and approaches to common problems in microservice-basedsystems and how they compare to other common architectures, such asmonoliths and large services.","title":"Chapter 2 - Microservices"},{"location":"cloud/MicroservicesKubernetes/#installing-go","text":"Refer to installation guide to download and install Go locally. Installation james@lizard:/opt> sudo zypper in go james@lizard:/opt> go version go version go1.18.2 linux/amd64 Choosing source control strategy. There are two main approaches: monorepo Your entire code base is in a single source controlrepository. multiple repos Each project, and often each library, has a separate source control repository. Hybrid Each repository contains multiple services and projects. Each repository is isolated from the other repositories, but within each repo, multiple services and projectscan be developed in lockstep. This approach balances the pros and cons ofmonorepo and multiple repos. Choosing data strategy One data store per microservice, which is a crucial element of the microservicearchitecture. Running distributed queries. It recommends to start with API composition andtransition to CQRS only if the proper conditions exist. Employing Command Query Responsibility Segregation (CQRS). The CQRS service (responsible forqueries) receives a change notification from the three microservices (responsible for updates) and aggregates them into its own data store. When a query comes, the CQRS service responds by accessing its own aggregated view without hitting the microservices. It duplicates the data and adds complexity to the system. An illustration of CQRS in action. Employing API composition. It exposes an API that can answer well-known queries across multiple microservices. A query to an API composer service is translated under the covers to queries to three microservices. The failure of any service will fail the query. An illustration of API composition in action Maintaining distributed dataintegrity is a complex problem. If you store all your data in a single relationaldatabase and specify proper constraints in your schema, then you can rely on the database engine to take care of data integrity. If multiple microservices maintain your data in isolated data stores (relational ornon-relational). Data integrity is essential, but it must be maintained by your code. The saga pattern addresses this concern. A common measure of data integrity is that all transactions that modify data havethe ACID properties. Atomic: All operations in the transaction succeed or they all fail. Consistent: The state of the data complies with all constraints before and after the transaction. Isolated: Concurrent transactions behave as if serialized. Durable: When a transaction completes successfully, the results are persisted. There are different levels of persistence: Persistence to disk: Can survive restart of the node, but no disk failure Redundant memory on multiple nodes: Can survive restart of a node and disk failure, but not temporary failure of all the nodes Redundant disks: Can survive the failure of a disk Geo-distributed replicas: Can survive a whole data center being down Backups: Cheaper to store a lot of information, but slower to restore and often lags behind real time The CAP theorem states that a distributed system can't have all three propertiesat the same time: Consistency Availability Partition resiliency The basic idea of the saga pattern is that there is centralized management of the operations across all the microservices and that, for each operation, there is a compensating operation that will be executed if, for some reason, the entire transaction can't be completed. This achieves the atomicity property of ACID. A saga is a set of operations and corresponding compensating operations on microservices. When an operation fails, its compensating operation and the compensating operations of all the previous operations are called in reverse order to roll back the entire state of the system.","title":"Installing Go"},{"location":"cloud/MicroservicesKubernetes/#chapter-3-sample-application","text":"Delinkcious \u2013 the Sample Application, explores why we should choose Go as the programming language of Delinkcious; then we will lookat Go kit. Delinkcious source code Go kit , which is a toolkit for microservice. Download Delinkcious source code release v0.1 and unpack it under folder /opt . The whole structure looks like below. The pkg directory contains packages that are used by services and commands.We should run the unit tests of these packages. The svc directory contains ourmicroservices. We should build those services, package each one in a properly versioned Docker image, and push those images to DockerHub (the imageregistry). The cmd directory currently contains end-to-end tests. Those are designed to run locally and don't need to be built by the CI pipeline. james@lizard:/opt> tree delinkcious-0.1 delinkcious-0.1 \u251c\u2500\u2500 cmd \u2502 \u2514\u2500\u2500 social_graph_service_e2e \u2502 \u251c\u2500\u2500 README.md \u2502 \u2514\u2500\u2500 social_graph_service_e2e.go \u251c\u2500\u2500 go.mod \u251c\u2500\u2500 go.sum \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 pkg \u2502 \u251c\u2500\u2500 link_manager \u2502 \u2502 \u251c\u2500\u2500 abstract_link_store.go \u2502 \u2502 \u251c\u2500\u2500 db_link_store.go \u2502 \u2502 \u251c\u2500\u2500 db_link_store_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_link_store.go \u2502 \u2502 \u251c\u2500\u2500 link_manager.go \u2502 \u2502 \u2514\u2500\u2500 link_manager_suite_test.go \u2502 \u251c\u2500\u2500 link_manager_client \u2502 \u2502 \u2514\u2500\u2500 client.go \u2502 \u251c\u2500\u2500 object_model \u2502 \u2502 \u251c\u2500\u2500 interfaces.go \u2502 \u2502 \u251c\u2500\u2500 README.md \u2502 \u2502 \u2514\u2500\u2500 types.go \u2502 \u251c\u2500\u2500 social_graph_client \u2502 \u2502 \u251c\u2500\u2500 client.go \u2502 \u2502 \u2514\u2500\u2500 endpoints.go \u2502 \u251c\u2500\u2500 social_graph_manager \u2502 \u2502 \u251c\u2500\u2500 db_scoial_graph_store.go \u2502 \u2502 \u251c\u2500\u2500 db_social_graph_manager_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_social_graph_manager_test.go \u2502 \u2502 \u251c\u2500\u2500 in_memory_social_graph_store.go \u2502 \u2502 \u251c\u2500\u2500 social_graph_manager.go \u2502 \u2502 \u2514\u2500\u2500 social_graph_manager_suite_test.go \u2502 \u2514\u2500\u2500 user_manager \u2502 \u251c\u2500\u2500 db_user_manager_test.go \u2502 \u251c\u2500\u2500 db_user_store.go \u2502 \u251c\u2500\u2500 in_memory_user_manager.go \u2502 \u251c\u2500\u2500 in_memory_user_manager_test.go \u2502 \u251c\u2500\u2500 in_memory_user_store.go \u2502 \u2514\u2500\u2500 user_manager_suite_test.go \u251c\u2500\u2500 README.md \u2514\u2500\u2500 svc \u251c\u2500\u2500 delinkcious_service \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 link_service \u2502 \u251c\u2500\u2500 link_service.go \u2502 \u2514\u2500\u2500 transport.go \u251c\u2500\u2500 social_graph_service \u2502 \u251c\u2500\u2500 main.go \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 social_graph_service.go \u2502 \u2514\u2500\u2500 transport.go \u2514\u2500\u2500 user_service \u251c\u2500\u2500 transport.go \u2514\u2500\u2500 user_service.go 15 directories, 38 files Download and launch the Postgres DB. james@lizard:/opt> docker pull postgres:alpine james@lizard:/opt> docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE postgres latest 5b21e2e86aab 14 hours ago 376MB kicbase/stable v0.0.30 1312ccd2422d 3 months ago 1.14GB james@lizard:/opt> docker run --name postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 -d postgres:alpine james@lizard:/opt> docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 223e0f44e107 postgres \"docker-entrypoint.s\u2026\" 26 seconds ago Up 24 seconds 5432/tcp postgres-delinkcious 5ec9c519d1e1 kicbase/stable:v0.0.30 \"/usr/local/bin/entr\u2026\" 18 hours ago Up 19 minutes 127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp minikube james@lizard:/opt> cd delinkcious-0.1/svc/social_graph_service james@lizard:/opt/delinkcious-0.1/svc/social_graph_service> go run main.go 2022/05/29 12:50:55 pq: unknown authentication response: 10 exit status 1","title":"Chapter 3 - Sample Application"},{"location":"cloud/MicroservicesKubernetes/#chapter-4-cicd-pipeline","text":"Setting Up the CI/CD Pipeline, teaches you about the problem the CI/CD pipeline solves, covers the different options for CI/CD pipelinesfor Kubernetes, and finally looks at building a CI/CD pipeline forDelinkcious. Download Delinkcious source code release v0.2 and unpack it under folder /opt . Here we use CircleCI and Argo CD. Prefer to separate the CI solution from the CD solution. Conceptually, the role of the CI process is to generate a container image and push it to a registry. It doesn'tneed to be aware of Kubernetes at all. The CD solution, on the other hand, must be Kubernetes-aware, and it ideally runs inside the cluster. Tekton is a very interesting project. It is Kubernetes-native and has great abstractions of steps, tasks, runs, and pipelines. It is relatively young, but seemsvery promising. It was also selected as one of the inaugural projects of the CD Foundation: https://cd.foundation/projects/. Jenkins X provides automated CI+CD for Kubernetes with Preview Environments on Pull Requests using Cloud Native pipelines from Tekton Argo CD is very specific CD solution to Kubernetes. CircleCI: https://circleci.com/docs/ Argo: https://argoproj.github.io/docs/argo-cd/docs/ Free mini ebook about CI/CD with Kubernetes:https://thenewstack.io/ebooks/kubernetes/ci-cd-with-kubernetes/ Jenkins X: https://jenkins-x.io/ Spinnaker: https://www.spinnaker.io/","title":"Chapter 4 - CI/CD Pipeline"},{"location":"cloud/MicroservicesKubernetes/#chapter-5-configuring-microservices","text":"Configuring Microservices with Kubernetes, moves you into the practical and real-world area of microservices configuration. Also, we will discuss Kubernetes-specific options and, in particular, ConfigMaps. The code samples at https://github.com/PacktPublishing/Hands-On-Microservices-with-Kubernetes/tree/master/Chapter05 The updated Delinkcious application at https://github.com/the-gigi/delinkcious/releases/tag/v0.3 Configuration is a very overloaded term. Configuration mostly refers to operational data that's needed forcomputation. The configuration may be different between environments. Here are some typical configuration items: Service discovery Support testing Environment-specific metadata Secrets Third-party configuration Feature flags Timeouts Rate limits Various defaults Twelve factor app configuration Dynamic configuration means that the service keeps running with the same codeand the same in-memory state, but it can detect that the configuration has changed, and will dynamically adjust its behavior according to the new configuration. Dynamic configuration is useful in the following cases: If you just have a single instance of your service, then restarting means a mini-outage If you have feature flags that you want to switch back and forth quickly If you have services where initialization or dropping in-flight requests is expansive If your service doesn't support advanced deployment strategies, such as rolling updates, or blue-green or canary deployments When redeploying a new configuration file may pull in unrelated code changes from source control that are not ready for deployment yet. When should you avoid dynamic configuration? Regulated services where configuration change must go through a vetting and approval process Critical services where the low risk of static configuration trumps any benefit of dynamic configuration A dynamic configuration mechanism doesn't exist and the benefits don't justify the development of such a mechanism Existing system with a large number of services where the benefits of migration to a dynamic configuration doesn't justify the cost Advanced deployment strategies provide the benefits of dynamic configuration with static configuration and restarts/redeployments The added complexity of keeping track of and auditing configuration changes is too high One of the options for dynamic configuration is a remote configuration store. All service instances can periodically query the configuration store, check whetherthe configuration has changed, and read the new configuration when it does. Possible options include the following: * Relational databases (Postgres, MySQL) * Key\u2013value stores (Etcd, Redis) * Shared filesystems (NFS, EFS)","title":"Chapter 5 - Configuring Microservices"},{"location":"cloud/MicroservicesKubernetes/#chapter-6-securing-microservices","text":"Securing Microservices on Kubernetes, examines how to secure your microservices on Kubernetes in depth. We will also discuss the pillars that act as the foundation of microservice security on Kubernetes.","title":"Chapter 6 - Securing Microservices"},{"location":"cloud/MicroservicesKubernetes/#chapter-7-apis-and-load-balancers","text":"Talking to the World \u2013 APIs and Load Balancers, sees us open Delinkcious to the world and let users interact with it from outside the cluster. Also, we will add a gRPC-based news service that users can hitup to get news about other users they follow. Finally, we will add a message queue that lets services communicate in a loosely coupled manner.","title":"Chapter 7 - APIs and Load Balancers"},{"location":"cloud/MicroservicesKubernetes/#chapter-8-stateful-services","text":"Working with Stateful Services, delves into the Kubernetesstorage model. We will also extend the Delinkcious news service to store itsdata in Redis, instead of in memory.","title":"Chapter 8 - Stateful Services"},{"location":"cloud/MicroservicesKubernetes/#chapter-9-serverless-tasks","text":"Running Serverless Tasks on Kubernetes, dives into one of thehottest trends in cloud-native systems: serverless computing (also knownas Function as a Service, or FaaS). Also, we'll cover other ways to doserverless computing in Kubernetes.","title":"Chapter 9 Serverless Tasks"},{"location":"cloud/MicroservicesKubernetes/#chapter-10-testing-microservices","text":"Testing Microservices, covers the topic of testing and its variousflavors: unit testing, integration testing, and all kinds of end-to-end testing.We also delve into how Delinkcious tests are structured.","title":"Chapter 10 - Testing Microservices"},{"location":"cloud/MicroservicesKubernetes/#chapter-11-deploying-microservices","text":"Deploying Microservices, deals with two related, yet separate,themes: production deployments and development deployments.","title":"Chapter 11 - Deploying Microservices"},{"location":"cloud/MicroservicesKubernetes/#chapter-12-operationing-microservices","text":"Monitoring, Logging, and Metrics, focuses on the operational side of running a large-scale distributed system on Kubernetes, as well ason how to design the system and what to take into account to ensure atop-notch operational posture.","title":"Chapter 12 - Operationing Microservices"},{"location":"cloud/MicroservicesKubernetes/#chapter-13-service-mesh","text":"Service Mesh \u2013 Working with Istio, reviews the hot topic ofservice meshes and, in particular, Istio. This is exciting because service meshes are a real game changer.","title":"Chapter 13 - Service Mesh"},{"location":"cloud/MicroservicesKubernetes/#chapter-14-the-future","text":"The Future of Microservices and Kubernetes, covers the topicsof Kubernetes and microservices, and will help us learn how to decide whenit's the right time to adopt and invest in newer technologies.","title":"Chapter 14 - The Future"},{"location":"cloud/MicroservicesKubernetes/#reference","text":"The code of the book Kubernetes document Minikube documents Helm document and source code and artifact hub Go language document","title":"Reference:"},{"location":"linux/Administration/01/","text":"Linux File System Overview Linux File System Overview Filesystem Hierarchy Standard (FHS), which is part of the LSB (Linux Standards Base) specifications. The Root directory \"/\". Refers to the highest layer of the file system tree. This root partition is mounted first at system boot. All programs that are run at system startup must be in this partition. The following directories must be in the root partition: /bin - User binaries. \u57fa\u672c\u7a0b\u5e8f Contains executables required when no other file systems are mounted. For example, programs required for system booting, working with files and configuration. /bin/bash - The bash shell /bin/cat - Display file contents /bin/cp - Copy files /bin/dd - Copy files byte-wise /bin/gzip - Compress files /bin/mount - Mount file systems /bin/rm - Delete files /bin/vi - Edit files /sbin - System binaries. \u7cfb\u7edf\u7a0b\u5e8f Contains programs important for system administration. \u5b58\u653e\u7cfb\u7edf\u7ba1\u7406\u7684\u7a0b\u5e8f Typically are intended to be run by the root user and therefore it is not in the regular users path. \u9ed8\u8ba4\u662froot\u7528\u6237\u6709\u6743\u9650\u6267\u884c Some important files: /sbin/yast - Administration tool /sbin/fdisk* - Modifies partitions /sbin/fsck* - File system check \u4e0d\u80fd\u5728\u8fd0\u884c\u7684\u7cfb\u7edf\u4e0a\u9762\u76f4\u63a5\u6267\u884cfsck\uff0c\u635f\u574f\u6839\u6587\u4ef6\u7cfb\u7edf\uff0c\u9700\u8981umount /sbin/mkfs - Creates file systems /sbin/shutdown - Shuts down the system /dev - Device files Each system hardware component is represented (except network cards, which are kernel modules). \u4ee5\u592a\u7f51\u5361\u662f\u5185\u6838\u6a21\u5757\uff0c\u5176\u4ed6\u786c\u4ef6\u90fd\u4ee5\u8bbe\u5907dev\u7684\u65b9\u5f0f\u5c55\u73b0 Applications read from and write to these files to address hardware components. Two kinds of device files: Character-oriented \u2013 Sequential devices (printer, tape and mouse) \u5b57\u7b26\u8bbe\u5907 Block-oriented \u2013 Hard disks and DVDs \u5757\u8bbe\u5907 Connections to device drivers are implemented in the kernel using channels called major device numbers. \u4e0e\u8bbe\u5907\u9a71\u52a8\u7a0b\u5e8f\u7684\u8fde\u63a5\u901a\u8fc7\u5185\u6838\u4e2d\u79f0\u4e3a\u4e3b\u8bbe\u5907\u53f7\u7684\u901a\u9053\u5b9e\u73b0\u3002 When using ls -l the file size is replaced with the device numbers, such as 8, 0. In the past these files were created manually using the mknod command. Today they are created automatically (by udev) when the devices are discovered by the kernel. Some important device files: Null device: - /dev/null Zero device: - /dev/zero System Console: - /dev/console Virtual Terminal: - /dev/tty1 Serial ports - /dev/ttyS0 Parallel port: - /dev/lp0 Floppy disk drive: - /dev/fd0 Hard drive: - /dev/sda Hard disk partition: - /dev/sda1 CD-ROM drive: - /dev/scd0 /etc - Configuration files Contains system and services configuration files. \u5b58\u653e\u7cfb\u7edf\u548c\u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6 Most of these files are ASCII files. \u5927\u90e8\u5206\u90fd\u662fASCII\u6587\u4ef6 Normal users can read most of these by default. This can be a security issue since some of these files contain passwords so it important that these files are only readable by the rootuser. \u666e\u901a\u7528\u6237\u53ef\u4ee5\u9ed8\u8ba4\u8bfb\u53d6\u5176\u4e2d\u7684\u5927\u90e8\u5206\u5185\u5bb9\u3002 \u8fd9\u53ef\u80fd\u662f\u4e00\u4e2a\u5b89\u5168\u95ee\u9898\uff0c\u56e0\u4e3a\u5176\u4e2d\u4e00\u4e9b\u6587\u4ef6\u5305\u542b\u5bc6\u7801\uff0c\u56e0\u6b64\u91cd\u8981\u7684\u662f\u8fd9\u4e9b\u6587\u4ef6\u53ea\u80fd\u7531root\u7528\u6237\u8bfb\u53d6 No executables can be put here according to the FHS, however subdirectories may contain shell scripts. \u6839\u636eFHS\uff0c\u6b64\u5904\u4e0d\u80fd\u653e\u7f6e\u4efb\u4f55\u53ef\u6267\u884c\u6587\u4ef6\uff0c\u4f46\u5b50\u76ee\u5f55\u53ef\u80fd\u5305\u542bshell\u811a\u672c\u3002 Almost every installed service has at least one configuration file in /etc or a subdirectory. \u51e0\u4e4e\u6bcf\u4e2a\u5df2\u5b89\u88c5\u7684\u670d\u52a1\u5728/ etc\u6216\u5b50\u76ee\u5f55\u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6\u3002 Some important configuration files: /etc/SuSE-release - Version of installed system /etc/DIR_COLORS - Colors for the ls command /etc/fstab - For file systems to be mounted /etc/profile - Shell login script /etc/passwd - User database, except passwords /etc/shadow - Password and password info /etc/group - Database of user groups /etc/cups/* - For the CUPS printing system (CUPS=Common UNIX Printing System) /etc/hosts - Host names to IP addresses /etc/motd - Message after login /etc/issue - Message before login /etc/sysconfig/* - System configuration files /lib - Libraries. Many programs have common functions they need. The functions can be kept in a shared library. Libraries are called shared objects and end with the .so extension. \u5171\u4eab\u5e93 Libraries in /lib are used by programs in /bin and /sbin . There are additional libraries in subdirectories. Kernel modules are located in /lib/modules . /lib64 - 64-Bit Libraries. Similar to the /lib directory. This is an architecture dependent directory. Some systems support different binary formats and keep different versions of the same shared library. /usr - Contains application programs, graphical interface files, libraries, local programs, documentation and more. /usr means Unix System Resources. Examples: /usr/X11R6/ - X Window System Files /usr/bin/ - Almost all executables /usr/lib/ - Libraries and application directories /usr/local/ - Locally installed programs (i.e. on local system if /usr is mounted from the network). The content is not overwritten by system updates. \u4e0b\u97623\u4e2a\u76ee\u5f55\u5728\u521d\u59cb\u5b89\u88c5\u540e\u662f\u7a7a\u7684 /usr/local/bin - /usr/local/sbin - /usr/local/lib - /usr/sbin/ - System administration programs /usr/share/doc/ - Documentation /usr/src/ - Source code of kernel and programs /usr/src/linux - /usr/share/man/ - Manual pages /opt - Optional Application Directory Where optional or third party applications that are not considered to be \u201cpart of the distribution\u201d store their static files. Applications considered to be \u201cpart of the distribution\u201d are usually installed under /usr/lib/ rather than /opt . At installation a directory is created for each application's files with the name of the application. Example: /opt/novell - /boot - The Boot Directory /boot/grub2 - Contains static boot loader files for GRUB2. (GRUB = Grand Unified Boot Loader) Contains the kernel and initrd file identified with the links vmlinuz and initrd. /root - Administrator's Home Directory The root user's home directory. Not under /home with regular users' home directories. Needs to be in the root partition so that root can always log in with his configured environment. /home - User Directories Every system user has an assigned file area which becomes the current working directory after log in. By default they exist in /home . The files and directories in /home could be in a separate partition or on another computer on the network. The user profile and configuration files are found here: .profile - Private user login script .bashrc - Configuration file for bash .bash_history - Previous commands run in bash /run/media/<user>/* - Mount Point for Removable Media SLE 12 creates directories here for mounting removable media. The name depends on the device that is mounted/discovered. Examples: /run/media/media_name/ (Created if labeled media is inserted) /run/media/cdrom/ - /run/media/dvd/ - /run/media/usbdisk/ - /mnt - Temporarily Mounted File Systems \u6587\u4ef6\u7cfb\u7edf\u4e34\u65f6\u6302\u8f7d\u70b9 Standard directory for integrating file systems that are used temporarily. File systems are mounted using the mount command and removed using the umount command. Subdirectories do not exist by default and are not automatically created. /srv - Service Data Directories Contains subdirectories for various services. Examples: \u5b58\u653e\u5404\u79cd\u670d\u52a1\u7684\u6570\u636e /srv/www - for the Apache Web Server /srv/ftp - for an FTP server /var - Variable Files Contains files that can be modified while the system is running. \u5728\u7cfb\u7edf\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u88ab\u4fee\u6539\u7684\u6587\u4ef6 Important subdirectories: /var/lib/ - Variable libraries, like databases \u53ef\u53d8\u5e93\u6587\u4ef6 /var/log/ - Services log files \u65e5\u5fd7\u6587\u4ef6 /var/run/ - Information on running processes \u8fd0\u884c\u4e2d\u7684\u7ebf\u7a0b\u7684\u4fe1\u606f /var/spool/ - Queues (printers, email) /var/spool/mail - /var/spool/cron - /var/lock/ - Lock files for multiuser access /var/cache - /var/mail - /tmp - Temporary Area Where programs create temporary files while they are running /proc - Process Files A virtual file system that exists only in memory and is used to display the current state of processes running on the system. (Takes no space - file size always 0) \u865a\u62df\u6587\u4ef6\u7cfb\u7edf\uff0c\u4e0d\u5360\u95f4\uff0c\u5927\u5c0f* \u59cb\u7ec8\u96f6\uff0c\u663e\u793a\u5f53\u524d\u8fdb\u7a0b\u7684\u72b6\u6001\u4fe1\u606f Directories containing information about individual processes are named according to the PID number of the process. Some values can be modified to change how things are running in real time. Any changes made are lost at reboot. Examples: \u6709\u4e9b\u503c\u53ef\u4ee5\u4e34\u65f6\u5728\u7ebf\u66f4\u6539\u751f\u6548\uff0c\u4f46\u91cd\u542f\u540e\u4e22\u5931 /proc/cpuinfo/ - Processor information /proc/dma/ - Use of DMA ports /proc/interrupts/ - Use of interrupts /proc/ioports/ - Use of I/O ports /proc/filesystems/ - File system formats the kernel knows /proc/modules/ - Active modules /proc/mounts/ - Mounted file systems /proc/net/* - Network information and statistics /proc/partitions/ - Existing partitions /proc/bus/pci/ - Connected PCI devices /proc/bus/scsi/ - Connected SCSI devices /proc/sys/* - System and kernel information /proc/version - Kernel version /sys - System Information Directory A virtual file system that exists only in memory. Takes no space so file size always 0 \u865a\u62df\u6587\u4ef6\u7cfb\u7edf Provides information on: hardware buses hardware devices active devices drivers Lab: Explore Filesystem Hierarchy Show the directory structure of the /data folder hierarchy of current logon user: mySUSE:~ # tree /data /data \u2514\u2500\u2500 linktype \u251c\u2500\u2500 file \u251c\u2500\u2500 hardlinkfile1 \u251c\u2500\u2500 hardlinkfile2 \u251c\u2500\u2500 symlinkfile1 -> file \u251c\u2500\u2500 symlinkfile1-1 -> symlinkfile1 \u2514\u2500\u2500 symlinkfile2 -> file Show only directories in the /data hierarchhy, not the files in them: mySUSE:~ # tree -d /data /data \u2514\u2500\u2500 linktype Show the files and directories in the /data hierarchy, including the full path and filename of each object. mySUSE:~ # tree -f /data /data \u2514\u2500\u2500 /data/linktype \u251c\u2500\u2500 /data/linktype/file \u251c\u2500\u2500 /data/linktype/hardlinkfile1 \u251c\u2500\u2500 /data/linktype/hardlinkfile2 \u251c\u2500\u2500 /data/linktype/symlinkfile1 -> file \u251c\u2500\u2500 /data/linktype/symlinkfile1-1 -> symlinkfile1 \u2514\u2500\u2500 /data/linktype/symlinkfile2 -> file Seven Different types of files Normal files , examples: ASCII text files Executable files Graphics files Directories Organize files on the disk Contain files and subdirectories Implement the hierarchical file system Links Hard links Secondary file names for files on the disk Multiple file names referencing a single inode Referenced file must reside in the same file system Symbolic links: References to other files on the disk The inode contains a reference to another file name .Referenced files can exist in the same file system or in other file systems A symbolic link can reference a non-existent file (broken link) Sockets - Used for two-way communication between processes. \u5957\u63a5\u5b57 Pipes (FIFOs) - Used for one-way communication from one process to another. \u7ba1\u9053 Block Devices \u5757\u8bbe\u5907 Character Devices \u5b57\u7b26\u8bbe\u5907 Linux Link Type Hard links : A hard link is a directory reference, or pointer, to a file on a storage volume. The name associated with the file is a label stored in a directory structure that refers the operating system to the file data. As such, more than one name can be associated with the same file. When accessed through different names, any changes made will affect the same file data. \u786c\u94fe\u63a5\u662f\u5b58\u50a8\u5377\u4e0a\u6587\u4ef6\u7684\u76ee\u5f55\u5f15\u7528\u6216\u6307\u9488\u3002 \u6587\u4ef6\u540d\u662f\u5b58\u50a8\u5728\u76ee\u5f55\u7ed3\u6784\u4e2d\u7684\u6807\u7b7e\uff0c\u76ee\u5f55\u7ed3\u6784\u6307\u5411\u6587\u4ef6\u6570\u636e\u3002 \u56e0\u6b64\uff0c\u53ef\u4ee5\u5c06\u591a\u4e2a\u6587\u4ef6\u540d\u4e0e\u540c\u4e00\u6587\u4ef6\u5173\u8054\u3002 \u901a\u8fc7\u4e0d\u540c\u7684\u6587\u4ef6\u540d\u8bbf\u95ee\u65f6\uff0c\u6240\u505a\u7684\u4efb\u4f55\u66f4\u6539\u90fd\u662f\u9488\u5bf9\u6e90\u6587\u4ef6\u6570\u636e\u3002 Symbolic links : A symbolic link contains a text string that is interpreted and followed by the operating system as a path to another file or directory. It is a file on its own and can exist independently of its target. If a symbolic link is deleted, its target remains unaffected. If the target is moved, renamed or deleted, any symbolic link that used to point to it continues to exist but now points to a non-existing file. \u7b26\u53f7\u94fe\u63a5\u5305\u542b\u4e00\u4e2a\u6587\u672c\u5b57\u7b26\u4e32\uff0c\u64cd\u4f5c\u7cfb\u7edf\u5c06\u5176\u89e3\u91ca\u5e76\u4f5c\u4e3a\u53e6\u4e00\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\u3002 \u5b83\u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u6587\u4ef6\uff0c\u53ef\u4ee5\u72ec\u7acb\u4e8e\u76ee\u6807\u800c\u5b58\u5728\u3002 \u5982\u679c\u5220\u9664\u4e86\u7b26\u53f7\u94fe\u63a5\uff0c\u5219\u5176\u76ee\u6807\u4e0d\u53d7\u5f71\u54cd\u3002 \u5982\u679c\u79fb\u52a8\uff0c\u91cd\u547d\u540d\u6216\u5220\u9664\u76ee\u6807\uff0c\u5219\u7528\u4e8e\u6307\u5411\u5b83\u7684\u4efb\u4f55\u7b26\u53f7\u94fe\u63a5\u5c06\u7ee7\u7eed\u5b58\u5728\uff0c\u4f46\u73b0\u5728\u6307\u5411\u4e0d\u5b58\u5728\u7684\u6587\u4ef6\u3002 Hard links can only be used when both the file and the link are in the same file system (on the same partition), because inode numbers are only unique within the same file system. You create a hard link by using the ln command, which points to the inode of an already existing file. Thereafter, the file can be accessed under both names\u2013that of the file and that of the link, and you can no longer discern which name existed first or how the original file and the link differ. \u4ec5\u5f53\u6587\u4ef6\u548c\u94fe\u63a5\u6587\u4ef6\u4f4d\u4e8e\u540c\u4e00\u6587\u4ef6\u7cfb\u7edf\uff08\u5728\u540c\u4e00\u5206\u533a\u4e0a\uff09\u65f6\uff0c\u624d\u80fd\u4f7f\u7528\u786c\u94fe\u63a5\uff0c\u56e0\u4e3ainode\u7f16\u53f7\u5728\u540c\u4e00\u6587\u4ef6\u7cfb\u7edf\u4e2d\u4ec5\u662f\u552f\u4e00\u7684\u3002 \u60a8\u53ef\u4ee5\u4f7f\u7528ln\u547d\u4ee4\u521b\u5efa\u786c\u94fe\u63a5\uff0c\u8be5\u547d\u4ee4\u6307\u5411\u5df2\u5b58\u5728\u6587\u4ef6\u7684inode\u3002 \u6b64\u540e\uff0c\u53ef\u4ee5\u5728\u6587\u4ef6\u7684\u540d\u79f0\u548c\u94fe\u63a5\u7684\u540d\u79f0\u4e0b\u8bbf\u95ee\u6587\u4ef6\uff0c\u5e76\u4e14\u65e0\u6cd5\u518d\u8bc6\u522b\u9996\u5148\u5b58\u5728\u7684\u540d\u79f0\u6216\u539f\u59cb\u6587\u4ef6\u548c\u94fe\u63a5\u7684\u4e0d\u540c\u4e4b\u5904\u3002 You can create a symbolic link with the ln command and the -s option. A symbolic link is assigned its own inode\u2014the link refers to a file, so a distinction can always be made between the link and the actual file. \u8f6f\u8fde\u63a5\u53ef\u4ee5\u9488\u5bf9\u76ee\u5f55\uff0c\u786c\u8fde\u63a5\u53ea\u80fd\u9488\u5bf9\u6587\u4ef6\u3002 A file system is essentially a database that is used to keep track of files in a volume. For normal files, data blocks are allocated to store the file's data, an inode is allocated to point to the data blocks as well as store the metadata about the file and then a file name is assigned to the inode. A hard link is a secondary file name associated with an existing inode. For symbolic links, a new inode is allocated with a new file name associated with it but the inode references another file name rather than referencing datablocks. \u6587\u4ef6\u7cfb\u7edf\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u5377\u4e2d\u6587\u4ef6\u7684\u6570\u636e\u5e93\u3002 \u5bf9\u4e8e\u666e\u901a\u6587\u4ef6\uff0c\u5206\u914d\u6570\u636e\u5757\u4ee5\u5b58\u50a8\u6587\u4ef6\u7684\u6570\u636e\uff0c\u5206\u914dinode\u4ee5\u6307\u5411\u6570\u636e\u5757\u4ee5\u53ca\u5b58\u50a8\u5173\u4e8e\u6587\u4ef6\u7684\u5143\u6570\u636e\uff0c\u7136\u540e\u5c06\u6587\u4ef6\u540d\u5206\u914d\u7ed9inode\u3002 \u786c\u94fe\u63a5\u662f\u4e0e\u73b0\u6709inode\u5173\u8054\u7684\u8f85\u52a9\u6587\u4ef6\u540d\u3002 \u5bf9\u4e8e\u7b26\u53f7\u94fe\u63a5\uff0c\u5c06\u4e3a\u65b0\u7684inode\u5206\u914d\u4e00\u4e2a\u4e0e\u4e4b\u5173\u8054\u7684\u65b0\u6587\u4ef6\u540d\uff0c\u4f46inode\u5f15\u7528\u53e6\u4e00\u4e2a\u6587\u4ef6\u540d\u800c\u4e0d\u662f\u5f15\u7528\u6570\u636e\u5757\u3002 A good way to see the relationship between file names and inodes is to use the ls -il command. The typical size of an inode is 128 Bit and data blocks can range in size from 1k, 2k, 4k or larger depending on the file system type. \u67e5\u770b\u6587\u4ef6\u540d\u548cinode\u4e4b\u95f4\u5173\u7cfb\u7684\u597d\u65b9\u6cd5\u662f\u4f7f\u7528ls -il\u547d\u4ee4\u3002inode\u7684\u5178\u578b\u5927\u5c0f\u4e3a128\u4f4d\uff0c\u6570\u636e\u5757\u7684\u5927\u5c0f\u8303\u56f4\u53ef\u4ee5\u662f1k\uff0c2k\uff0c4k\u6216\u66f4\u5927\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\u3002 \u786c\u94fe\u63a5\u76f8\u5f53\u4e8e\u589e\u52a0\u4e86\u4e00\u4e2a\u767b\u8bb0\u9879\uff0c\u4f7f\u5f97\u539f\u6765\u7684\u6587\u4ef6\u591a\u4e86\u4e00\u4e2a\u540d\u5b57\uff0c\u81f3\u4e8einode\u90fd\u6ca1\u53d8\u3002\u6240\u8c13\u7684\u767b\u8bb0\u9879\u5176\u5b9e\u662f\u76ee\u5f55\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2a\u6761\u76ee(\u76ee\u5f55\u9879)\uff0c\u4f7f\u7528hard link \u662f\u8ba9\u591a\u4e2a\u4e0d\u540c\u7684\u76ee\u5f55\u9879\u6307\u5411\u540c\u4e00\u4e2a\u6587\u4ef6\u7684inode\uff0c\u6ca1\u6709\u591a\u4f59\u7684\u5185\u5bb9\u9700\u8981\u5b58\u50a8\u5728\u78c1\u76d8\u6247\u533a\u4e2d\uff0c\u6240\u4ee5hardlink\u4e0d\u5360\u7528\u989d\u5916\u7684\u7a7a\u95f4\u3002 \u7b26\u53f7\u94fe\u63a5\u6709\u5355\u72ec\u7684inode\uff0c\u5728inode\u4e2d\u5b58\u653e\u53e6\u4e00\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u800c\u4e0d\u662f\u6587\u4ef6\u6570\u636e\uff0c\u6240\u4ee5\u7b26\u53f7\u94fe\u63a5\u4f1a\u5360\u7528\u989d\u5916\u7684\u7a7a\u95f4\u3002 Lab: File Link Type Create original file mySUSE:/data/linktype # echo \"it's original file\" > file mySUSE:/data/linktype # l -rw-r--r-- 1 root root 19 Mar 28 15:20 file Create hardlink file (\u6ce8\u610ffile\u3001hardlinkfile1\u3001hardlinkfile2\u7684link\u4f4d\u7f6e\u7684\u6570\u503c\u7684\u53d8\u5316[\u7ea2\u8272]) mySUSE:/data/linktype # ln file hardlinkfile1 mySUSE:/data/linktype # ln -s file symlinkfile1 mySUSE:/data/linktype # ln -s file symlinkfile2 mySUSE:/data/linktype # l -rw-r--r-- 2 root root 19 Mar 28 15:20 file -rw-r--r-- 2 root root 19 Mar 28 15:20 hardlinkfile1 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file mySUSE:/data/linktype # ln file hardlinkfile2 mySUSE:/data/linktype # l -rw-r--r-- 3 root root 19 Mar 28 15:20 file (\u5305\u62ec\u81ea\u5df1\uff0c\u4e00\u5171\u67093\u4e2a\u786c\u94fe\u63a5) -rw-r--r-- 3 root root 19 Mar 28 15:20 hardlinkfile1 (\u7ee7\u627f\u4e86\u539f\u6587\u4ef6\u7684\u786c\u94fe\u63a5\u6570\u91cf) -rw-r--r-- 3 root root 19 Mar 28 15:20 hardlinkfile2 (\u7ee7\u627f\u4e86\u539f\u6587\u4ef6\u7684\u786c\u94fe\u63a5\u6570\u91cf) lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file Modify content of file (original file). Content change were shown in all hard/soft link files mySUSE:/data/linktype # echo \"add oneline\" >> file mySUSE:/data/linktype # cat file it's original file add oneline mySUSE:/data/linktype # cat hardlinkfile1 it's original file add oneline mySUSE:/data/linktype # cat hardlinkfile2 it's original file add oneline mySUSE:/data/linktype # cat symlinkfile1 it's original file add oneline mySUSE:/data/linktype # cat symlinkfile2 it's original file add oneline To view the value stored in a symbolic link use the command readlink. mySUSE:/data/linktype # ln -s symlinkfile1 symlinkfile1-1 mySUSE:/data/linktype # ls -il 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 file 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 hardlinkfile1 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 hardlinkfile2 259 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file 265 lrwxrwxrwx 1 root root 12 Mar 28 15:49 symlinkfile1-1 -> symlinkfile1 260 lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file mySUSE:/data/linktype # readlink symlinkfile1 file mySUSE:/data/linktype # readlink symlinkfile2 file mySUSE:/data/linktype # readlink symlinkfile1-1 symlinkfile1 (\u6ce8\u610f\uff1a\u8fd9\u4ecd\u7136\u662f\u4e00\u4e2a\u7b26\u53f7\u94fe\u63a5\u6587\u4ef6) mySUSE:/data/linktype # readlink -f symlinkfile1-1(\u53c2\u6570-f\u53ef\u4ee5\u76f4\u63a5\u5b9a\u4f4d\u771f\u6b63\u7684\u6e90\u6587\u4ef6) /data/linktype/file (\u6ce8\u610f\uff1a\u8fd9\u624d\u662f\u771f\u6b63\u7684\u539f\u6587\u4ef6) Linux Device File Represent hardware (except network cards). Each piece of hardware is represented by a device file. Network cards are interfaces. (\u533a\u522b) Link between hardware devices and the kernel drivers \u8bbe\u5907\u6587\u4ef6\u628a\u5185\u6838\u9a71\u52a8\u548c\u7269\u7406\u786c\u4ef6\u8bbe\u5907\u8fde\u63a5\u8d77\u6765 Kernel drivers read from and write to the device file \u5185\u6838\u9a71\u52a8\u7a0b\u5e8f\u5bf9\u8bbe\u5907\u6587\u4ef6\u8fdb\u884c\u8bfb\u5199\u6765\u5b9e\u73b0\u5bf9\u786c\u4ef6\u7684\u8bfb\u5199 The kernel gets the data to the actual hardware in the correct format \u5185\u6838\u4ee5\u6b63\u786e\u7684\u683c\u5f0f\u5bf9\u7269\u7406\u8bbe\u5907\u8fdb\u884c\u8bfb\u5199 Types: Block Devices. A block device reads/writes information in (normally) 512 byte large blocks. Character Devices. A character device reads/writes information character wise. Character devices provide unbuffered access directly to a hardware device. \u76f4\u63a5\u8bfb\u5199\uff0c\u4e0d\u901a\u8fc7\u7f13\u5b58 Sometimes referred to as raw devices. \u88f8\u8bbe\u5907\uff08\u6ce8\u610f\uff1a\u88f8\u8bbe\u5907\u88ab\u89c6\u4e3a\u5b57\u7b26\u8bbe\u5907\uff0c\u4e0d\u662f\u5757\u8bbe\u5907\uff09 any different options for character devices, making their use and application wide and varied. Created automatically by the OS (udev) when the device is discovered by the kernel. \u5185\u6838\u76f4\u63a5\u521b\u5efa\u5bf9\u5e94\u786c\u4ef6\u7684\u8bbe\u5907\u6587\u4ef6","title":"Linux File System Overview"},{"location":"linux/Administration/01/#linux-file-system-overview","text":"","title":"Linux File System Overview"},{"location":"linux/Administration/01/#linux-file-system-overview_1","text":"Filesystem Hierarchy Standard (FHS), which is part of the LSB (Linux Standards Base) specifications. The Root directory \"/\". Refers to the highest layer of the file system tree. This root partition is mounted first at system boot. All programs that are run at system startup must be in this partition. The following directories must be in the root partition: /bin - User binaries. \u57fa\u672c\u7a0b\u5e8f Contains executables required when no other file systems are mounted. For example, programs required for system booting, working with files and configuration. /bin/bash - The bash shell /bin/cat - Display file contents /bin/cp - Copy files /bin/dd - Copy files byte-wise /bin/gzip - Compress files /bin/mount - Mount file systems /bin/rm - Delete files /bin/vi - Edit files /sbin - System binaries. \u7cfb\u7edf\u7a0b\u5e8f Contains programs important for system administration. \u5b58\u653e\u7cfb\u7edf\u7ba1\u7406\u7684\u7a0b\u5e8f Typically are intended to be run by the root user and therefore it is not in the regular users path. \u9ed8\u8ba4\u662froot\u7528\u6237\u6709\u6743\u9650\u6267\u884c Some important files: /sbin/yast - Administration tool /sbin/fdisk* - Modifies partitions /sbin/fsck* - File system check \u4e0d\u80fd\u5728\u8fd0\u884c\u7684\u7cfb\u7edf\u4e0a\u9762\u76f4\u63a5\u6267\u884cfsck\uff0c\u635f\u574f\u6839\u6587\u4ef6\u7cfb\u7edf\uff0c\u9700\u8981umount /sbin/mkfs - Creates file systems /sbin/shutdown - Shuts down the system /dev - Device files Each system hardware component is represented (except network cards, which are kernel modules). \u4ee5\u592a\u7f51\u5361\u662f\u5185\u6838\u6a21\u5757\uff0c\u5176\u4ed6\u786c\u4ef6\u90fd\u4ee5\u8bbe\u5907dev\u7684\u65b9\u5f0f\u5c55\u73b0 Applications read from and write to these files to address hardware components. Two kinds of device files: Character-oriented \u2013 Sequential devices (printer, tape and mouse) \u5b57\u7b26\u8bbe\u5907 Block-oriented \u2013 Hard disks and DVDs \u5757\u8bbe\u5907 Connections to device drivers are implemented in the kernel using channels called major device numbers. \u4e0e\u8bbe\u5907\u9a71\u52a8\u7a0b\u5e8f\u7684\u8fde\u63a5\u901a\u8fc7\u5185\u6838\u4e2d\u79f0\u4e3a\u4e3b\u8bbe\u5907\u53f7\u7684\u901a\u9053\u5b9e\u73b0\u3002 When using ls -l the file size is replaced with the device numbers, such as 8, 0. In the past these files were created manually using the mknod command. Today they are created automatically (by udev) when the devices are discovered by the kernel. Some important device files: Null device: - /dev/null Zero device: - /dev/zero System Console: - /dev/console Virtual Terminal: - /dev/tty1 Serial ports - /dev/ttyS0 Parallel port: - /dev/lp0 Floppy disk drive: - /dev/fd0 Hard drive: - /dev/sda Hard disk partition: - /dev/sda1 CD-ROM drive: - /dev/scd0 /etc - Configuration files Contains system and services configuration files. \u5b58\u653e\u7cfb\u7edf\u548c\u670d\u52a1\u7684\u914d\u7f6e\u6587\u4ef6 Most of these files are ASCII files. \u5927\u90e8\u5206\u90fd\u662fASCII\u6587\u4ef6 Normal users can read most of these by default. This can be a security issue since some of these files contain passwords so it important that these files are only readable by the rootuser. \u666e\u901a\u7528\u6237\u53ef\u4ee5\u9ed8\u8ba4\u8bfb\u53d6\u5176\u4e2d\u7684\u5927\u90e8\u5206\u5185\u5bb9\u3002 \u8fd9\u53ef\u80fd\u662f\u4e00\u4e2a\u5b89\u5168\u95ee\u9898\uff0c\u56e0\u4e3a\u5176\u4e2d\u4e00\u4e9b\u6587\u4ef6\u5305\u542b\u5bc6\u7801\uff0c\u56e0\u6b64\u91cd\u8981\u7684\u662f\u8fd9\u4e9b\u6587\u4ef6\u53ea\u80fd\u7531root\u7528\u6237\u8bfb\u53d6 No executables can be put here according to the FHS, however subdirectories may contain shell scripts. \u6839\u636eFHS\uff0c\u6b64\u5904\u4e0d\u80fd\u653e\u7f6e\u4efb\u4f55\u53ef\u6267\u884c\u6587\u4ef6\uff0c\u4f46\u5b50\u76ee\u5f55\u53ef\u80fd\u5305\u542bshell\u811a\u672c\u3002 Almost every installed service has at least one configuration file in /etc or a subdirectory. \u51e0\u4e4e\u6bcf\u4e2a\u5df2\u5b89\u88c5\u7684\u670d\u52a1\u5728/ etc\u6216\u5b50\u76ee\u5f55\u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6\u3002 Some important configuration files: /etc/SuSE-release - Version of installed system /etc/DIR_COLORS - Colors for the ls command /etc/fstab - For file systems to be mounted /etc/profile - Shell login script /etc/passwd - User database, except passwords /etc/shadow - Password and password info /etc/group - Database of user groups /etc/cups/* - For the CUPS printing system (CUPS=Common UNIX Printing System) /etc/hosts - Host names to IP addresses /etc/motd - Message after login /etc/issue - Message before login /etc/sysconfig/* - System configuration files /lib - Libraries. Many programs have common functions they need. The functions can be kept in a shared library. Libraries are called shared objects and end with the .so extension. \u5171\u4eab\u5e93 Libraries in /lib are used by programs in /bin and /sbin . There are additional libraries in subdirectories. Kernel modules are located in /lib/modules . /lib64 - 64-Bit Libraries. Similar to the /lib directory. This is an architecture dependent directory. Some systems support different binary formats and keep different versions of the same shared library. /usr - Contains application programs, graphical interface files, libraries, local programs, documentation and more. /usr means Unix System Resources. Examples: /usr/X11R6/ - X Window System Files /usr/bin/ - Almost all executables /usr/lib/ - Libraries and application directories /usr/local/ - Locally installed programs (i.e. on local system if /usr is mounted from the network). The content is not overwritten by system updates. \u4e0b\u97623\u4e2a\u76ee\u5f55\u5728\u521d\u59cb\u5b89\u88c5\u540e\u662f\u7a7a\u7684 /usr/local/bin - /usr/local/sbin - /usr/local/lib - /usr/sbin/ - System administration programs /usr/share/doc/ - Documentation /usr/src/ - Source code of kernel and programs /usr/src/linux - /usr/share/man/ - Manual pages /opt - Optional Application Directory Where optional or third party applications that are not considered to be \u201cpart of the distribution\u201d store their static files. Applications considered to be \u201cpart of the distribution\u201d are usually installed under /usr/lib/ rather than /opt . At installation a directory is created for each application's files with the name of the application. Example: /opt/novell - /boot - The Boot Directory /boot/grub2 - Contains static boot loader files for GRUB2. (GRUB = Grand Unified Boot Loader) Contains the kernel and initrd file identified with the links vmlinuz and initrd. /root - Administrator's Home Directory The root user's home directory. Not under /home with regular users' home directories. Needs to be in the root partition so that root can always log in with his configured environment. /home - User Directories Every system user has an assigned file area which becomes the current working directory after log in. By default they exist in /home . The files and directories in /home could be in a separate partition or on another computer on the network. The user profile and configuration files are found here: .profile - Private user login script .bashrc - Configuration file for bash .bash_history - Previous commands run in bash /run/media/<user>/* - Mount Point for Removable Media SLE 12 creates directories here for mounting removable media. The name depends on the device that is mounted/discovered. Examples: /run/media/media_name/ (Created if labeled media is inserted) /run/media/cdrom/ - /run/media/dvd/ - /run/media/usbdisk/ - /mnt - Temporarily Mounted File Systems \u6587\u4ef6\u7cfb\u7edf\u4e34\u65f6\u6302\u8f7d\u70b9 Standard directory for integrating file systems that are used temporarily. File systems are mounted using the mount command and removed using the umount command. Subdirectories do not exist by default and are not automatically created. /srv - Service Data Directories Contains subdirectories for various services. Examples: \u5b58\u653e\u5404\u79cd\u670d\u52a1\u7684\u6570\u636e /srv/www - for the Apache Web Server /srv/ftp - for an FTP server /var - Variable Files Contains files that can be modified while the system is running. \u5728\u7cfb\u7edf\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u88ab\u4fee\u6539\u7684\u6587\u4ef6 Important subdirectories: /var/lib/ - Variable libraries, like databases \u53ef\u53d8\u5e93\u6587\u4ef6 /var/log/ - Services log files \u65e5\u5fd7\u6587\u4ef6 /var/run/ - Information on running processes \u8fd0\u884c\u4e2d\u7684\u7ebf\u7a0b\u7684\u4fe1\u606f /var/spool/ - Queues (printers, email) /var/spool/mail - /var/spool/cron - /var/lock/ - Lock files for multiuser access /var/cache - /var/mail - /tmp - Temporary Area Where programs create temporary files while they are running /proc - Process Files A virtual file system that exists only in memory and is used to display the current state of processes running on the system. (Takes no space - file size always 0) \u865a\u62df\u6587\u4ef6\u7cfb\u7edf\uff0c\u4e0d\u5360\u95f4\uff0c\u5927\u5c0f* \u59cb\u7ec8\u96f6\uff0c\u663e\u793a\u5f53\u524d\u8fdb\u7a0b\u7684\u72b6\u6001\u4fe1\u606f Directories containing information about individual processes are named according to the PID number of the process. Some values can be modified to change how things are running in real time. Any changes made are lost at reboot. Examples: \u6709\u4e9b\u503c\u53ef\u4ee5\u4e34\u65f6\u5728\u7ebf\u66f4\u6539\u751f\u6548\uff0c\u4f46\u91cd\u542f\u540e\u4e22\u5931 /proc/cpuinfo/ - Processor information /proc/dma/ - Use of DMA ports /proc/interrupts/ - Use of interrupts /proc/ioports/ - Use of I/O ports /proc/filesystems/ - File system formats the kernel knows /proc/modules/ - Active modules /proc/mounts/ - Mounted file systems /proc/net/* - Network information and statistics /proc/partitions/ - Existing partitions /proc/bus/pci/ - Connected PCI devices /proc/bus/scsi/ - Connected SCSI devices /proc/sys/* - System and kernel information /proc/version - Kernel version /sys - System Information Directory A virtual file system that exists only in memory. Takes no space so file size always 0 \u865a\u62df\u6587\u4ef6\u7cfb\u7edf Provides information on: hardware buses hardware devices active devices drivers","title":"Linux File System Overview"},{"location":"linux/Administration/01/#lab-explore-filesystem-hierarchy","text":"Show the directory structure of the /data folder hierarchy of current logon user: mySUSE:~ # tree /data /data \u2514\u2500\u2500 linktype \u251c\u2500\u2500 file \u251c\u2500\u2500 hardlinkfile1 \u251c\u2500\u2500 hardlinkfile2 \u251c\u2500\u2500 symlinkfile1 -> file \u251c\u2500\u2500 symlinkfile1-1 -> symlinkfile1 \u2514\u2500\u2500 symlinkfile2 -> file Show only directories in the /data hierarchhy, not the files in them: mySUSE:~ # tree -d /data /data \u2514\u2500\u2500 linktype Show the files and directories in the /data hierarchy, including the full path and filename of each object. mySUSE:~ # tree -f /data /data \u2514\u2500\u2500 /data/linktype \u251c\u2500\u2500 /data/linktype/file \u251c\u2500\u2500 /data/linktype/hardlinkfile1 \u251c\u2500\u2500 /data/linktype/hardlinkfile2 \u251c\u2500\u2500 /data/linktype/symlinkfile1 -> file \u251c\u2500\u2500 /data/linktype/symlinkfile1-1 -> symlinkfile1 \u2514\u2500\u2500 /data/linktype/symlinkfile2 -> file","title":"Lab: Explore Filesystem Hierarchy"},{"location":"linux/Administration/01/#seven-different-types-of-files","text":"Normal files , examples: ASCII text files Executable files Graphics files Directories Organize files on the disk Contain files and subdirectories Implement the hierarchical file system Links Hard links Secondary file names for files on the disk Multiple file names referencing a single inode Referenced file must reside in the same file system Symbolic links: References to other files on the disk The inode contains a reference to another file name .Referenced files can exist in the same file system or in other file systems A symbolic link can reference a non-existent file (broken link) Sockets - Used for two-way communication between processes. \u5957\u63a5\u5b57 Pipes (FIFOs) - Used for one-way communication from one process to another. \u7ba1\u9053 Block Devices \u5757\u8bbe\u5907 Character Devices \u5b57\u7b26\u8bbe\u5907","title":"Seven Different types of files"},{"location":"linux/Administration/01/#linux-link-type","text":"Hard links : A hard link is a directory reference, or pointer, to a file on a storage volume. The name associated with the file is a label stored in a directory structure that refers the operating system to the file data. As such, more than one name can be associated with the same file. When accessed through different names, any changes made will affect the same file data. \u786c\u94fe\u63a5\u662f\u5b58\u50a8\u5377\u4e0a\u6587\u4ef6\u7684\u76ee\u5f55\u5f15\u7528\u6216\u6307\u9488\u3002 \u6587\u4ef6\u540d\u662f\u5b58\u50a8\u5728\u76ee\u5f55\u7ed3\u6784\u4e2d\u7684\u6807\u7b7e\uff0c\u76ee\u5f55\u7ed3\u6784\u6307\u5411\u6587\u4ef6\u6570\u636e\u3002 \u56e0\u6b64\uff0c\u53ef\u4ee5\u5c06\u591a\u4e2a\u6587\u4ef6\u540d\u4e0e\u540c\u4e00\u6587\u4ef6\u5173\u8054\u3002 \u901a\u8fc7\u4e0d\u540c\u7684\u6587\u4ef6\u540d\u8bbf\u95ee\u65f6\uff0c\u6240\u505a\u7684\u4efb\u4f55\u66f4\u6539\u90fd\u662f\u9488\u5bf9\u6e90\u6587\u4ef6\u6570\u636e\u3002 Symbolic links : A symbolic link contains a text string that is interpreted and followed by the operating system as a path to another file or directory. It is a file on its own and can exist independently of its target. If a symbolic link is deleted, its target remains unaffected. If the target is moved, renamed or deleted, any symbolic link that used to point to it continues to exist but now points to a non-existing file. \u7b26\u53f7\u94fe\u63a5\u5305\u542b\u4e00\u4e2a\u6587\u672c\u5b57\u7b26\u4e32\uff0c\u64cd\u4f5c\u7cfb\u7edf\u5c06\u5176\u89e3\u91ca\u5e76\u4f5c\u4e3a\u53e6\u4e00\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\u7684\u8def\u5f84\u3002 \u5b83\u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u6587\u4ef6\uff0c\u53ef\u4ee5\u72ec\u7acb\u4e8e\u76ee\u6807\u800c\u5b58\u5728\u3002 \u5982\u679c\u5220\u9664\u4e86\u7b26\u53f7\u94fe\u63a5\uff0c\u5219\u5176\u76ee\u6807\u4e0d\u53d7\u5f71\u54cd\u3002 \u5982\u679c\u79fb\u52a8\uff0c\u91cd\u547d\u540d\u6216\u5220\u9664\u76ee\u6807\uff0c\u5219\u7528\u4e8e\u6307\u5411\u5b83\u7684\u4efb\u4f55\u7b26\u53f7\u94fe\u63a5\u5c06\u7ee7\u7eed\u5b58\u5728\uff0c\u4f46\u73b0\u5728\u6307\u5411\u4e0d\u5b58\u5728\u7684\u6587\u4ef6\u3002 Hard links can only be used when both the file and the link are in the same file system (on the same partition), because inode numbers are only unique within the same file system. You create a hard link by using the ln command, which points to the inode of an already existing file. Thereafter, the file can be accessed under both names\u2013that of the file and that of the link, and you can no longer discern which name existed first or how the original file and the link differ. \u4ec5\u5f53\u6587\u4ef6\u548c\u94fe\u63a5\u6587\u4ef6\u4f4d\u4e8e\u540c\u4e00\u6587\u4ef6\u7cfb\u7edf\uff08\u5728\u540c\u4e00\u5206\u533a\u4e0a\uff09\u65f6\uff0c\u624d\u80fd\u4f7f\u7528\u786c\u94fe\u63a5\uff0c\u56e0\u4e3ainode\u7f16\u53f7\u5728\u540c\u4e00\u6587\u4ef6\u7cfb\u7edf\u4e2d\u4ec5\u662f\u552f\u4e00\u7684\u3002 \u60a8\u53ef\u4ee5\u4f7f\u7528ln\u547d\u4ee4\u521b\u5efa\u786c\u94fe\u63a5\uff0c\u8be5\u547d\u4ee4\u6307\u5411\u5df2\u5b58\u5728\u6587\u4ef6\u7684inode\u3002 \u6b64\u540e\uff0c\u53ef\u4ee5\u5728\u6587\u4ef6\u7684\u540d\u79f0\u548c\u94fe\u63a5\u7684\u540d\u79f0\u4e0b\u8bbf\u95ee\u6587\u4ef6\uff0c\u5e76\u4e14\u65e0\u6cd5\u518d\u8bc6\u522b\u9996\u5148\u5b58\u5728\u7684\u540d\u79f0\u6216\u539f\u59cb\u6587\u4ef6\u548c\u94fe\u63a5\u7684\u4e0d\u540c\u4e4b\u5904\u3002 You can create a symbolic link with the ln command and the -s option. A symbolic link is assigned its own inode\u2014the link refers to a file, so a distinction can always be made between the link and the actual file. \u8f6f\u8fde\u63a5\u53ef\u4ee5\u9488\u5bf9\u76ee\u5f55\uff0c\u786c\u8fde\u63a5\u53ea\u80fd\u9488\u5bf9\u6587\u4ef6\u3002 A file system is essentially a database that is used to keep track of files in a volume. For normal files, data blocks are allocated to store the file's data, an inode is allocated to point to the data blocks as well as store the metadata about the file and then a file name is assigned to the inode. A hard link is a secondary file name associated with an existing inode. For symbolic links, a new inode is allocated with a new file name associated with it but the inode references another file name rather than referencing datablocks. \u6587\u4ef6\u7cfb\u7edf\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u5377\u4e2d\u6587\u4ef6\u7684\u6570\u636e\u5e93\u3002 \u5bf9\u4e8e\u666e\u901a\u6587\u4ef6\uff0c\u5206\u914d\u6570\u636e\u5757\u4ee5\u5b58\u50a8\u6587\u4ef6\u7684\u6570\u636e\uff0c\u5206\u914dinode\u4ee5\u6307\u5411\u6570\u636e\u5757\u4ee5\u53ca\u5b58\u50a8\u5173\u4e8e\u6587\u4ef6\u7684\u5143\u6570\u636e\uff0c\u7136\u540e\u5c06\u6587\u4ef6\u540d\u5206\u914d\u7ed9inode\u3002 \u786c\u94fe\u63a5\u662f\u4e0e\u73b0\u6709inode\u5173\u8054\u7684\u8f85\u52a9\u6587\u4ef6\u540d\u3002 \u5bf9\u4e8e\u7b26\u53f7\u94fe\u63a5\uff0c\u5c06\u4e3a\u65b0\u7684inode\u5206\u914d\u4e00\u4e2a\u4e0e\u4e4b\u5173\u8054\u7684\u65b0\u6587\u4ef6\u540d\uff0c\u4f46inode\u5f15\u7528\u53e6\u4e00\u4e2a\u6587\u4ef6\u540d\u800c\u4e0d\u662f\u5f15\u7528\u6570\u636e\u5757\u3002 A good way to see the relationship between file names and inodes is to use the ls -il command. The typical size of an inode is 128 Bit and data blocks can range in size from 1k, 2k, 4k or larger depending on the file system type. \u67e5\u770b\u6587\u4ef6\u540d\u548cinode\u4e4b\u95f4\u5173\u7cfb\u7684\u597d\u65b9\u6cd5\u662f\u4f7f\u7528ls -il\u547d\u4ee4\u3002inode\u7684\u5178\u578b\u5927\u5c0f\u4e3a128\u4f4d\uff0c\u6570\u636e\u5757\u7684\u5927\u5c0f\u8303\u56f4\u53ef\u4ee5\u662f1k\uff0c2k\uff0c4k\u6216\u66f4\u5927\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\u3002 \u786c\u94fe\u63a5\u76f8\u5f53\u4e8e\u589e\u52a0\u4e86\u4e00\u4e2a\u767b\u8bb0\u9879\uff0c\u4f7f\u5f97\u539f\u6765\u7684\u6587\u4ef6\u591a\u4e86\u4e00\u4e2a\u540d\u5b57\uff0c\u81f3\u4e8einode\u90fd\u6ca1\u53d8\u3002\u6240\u8c13\u7684\u767b\u8bb0\u9879\u5176\u5b9e\u662f\u76ee\u5f55\u6587\u4ef6\u4e2d\u7684\u4e00\u4e2a\u6761\u76ee(\u76ee\u5f55\u9879)\uff0c\u4f7f\u7528hard link \u662f\u8ba9\u591a\u4e2a\u4e0d\u540c\u7684\u76ee\u5f55\u9879\u6307\u5411\u540c\u4e00\u4e2a\u6587\u4ef6\u7684inode\uff0c\u6ca1\u6709\u591a\u4f59\u7684\u5185\u5bb9\u9700\u8981\u5b58\u50a8\u5728\u78c1\u76d8\u6247\u533a\u4e2d\uff0c\u6240\u4ee5hardlink\u4e0d\u5360\u7528\u989d\u5916\u7684\u7a7a\u95f4\u3002 \u7b26\u53f7\u94fe\u63a5\u6709\u5355\u72ec\u7684inode\uff0c\u5728inode\u4e2d\u5b58\u653e\u53e6\u4e00\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u800c\u4e0d\u662f\u6587\u4ef6\u6570\u636e\uff0c\u6240\u4ee5\u7b26\u53f7\u94fe\u63a5\u4f1a\u5360\u7528\u989d\u5916\u7684\u7a7a\u95f4\u3002","title":"Linux Link Type"},{"location":"linux/Administration/01/#lab-file-link-type","text":"Create original file mySUSE:/data/linktype # echo \"it's original file\" > file mySUSE:/data/linktype # l -rw-r--r-- 1 root root 19 Mar 28 15:20 file Create hardlink file (\u6ce8\u610ffile\u3001hardlinkfile1\u3001hardlinkfile2\u7684link\u4f4d\u7f6e\u7684\u6570\u503c\u7684\u53d8\u5316[\u7ea2\u8272]) mySUSE:/data/linktype # ln file hardlinkfile1 mySUSE:/data/linktype # ln -s file symlinkfile1 mySUSE:/data/linktype # ln -s file symlinkfile2 mySUSE:/data/linktype # l -rw-r--r-- 2 root root 19 Mar 28 15:20 file -rw-r--r-- 2 root root 19 Mar 28 15:20 hardlinkfile1 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file mySUSE:/data/linktype # ln file hardlinkfile2 mySUSE:/data/linktype # l -rw-r--r-- 3 root root 19 Mar 28 15:20 file (\u5305\u62ec\u81ea\u5df1\uff0c\u4e00\u5171\u67093\u4e2a\u786c\u94fe\u63a5) -rw-r--r-- 3 root root 19 Mar 28 15:20 hardlinkfile1 (\u7ee7\u627f\u4e86\u539f\u6587\u4ef6\u7684\u786c\u94fe\u63a5\u6570\u91cf) -rw-r--r-- 3 root root 19 Mar 28 15:20 hardlinkfile2 (\u7ee7\u627f\u4e86\u539f\u6587\u4ef6\u7684\u786c\u94fe\u63a5\u6570\u91cf) lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file Modify content of file (original file). Content change were shown in all hard/soft link files mySUSE:/data/linktype # echo \"add oneline\" >> file mySUSE:/data/linktype # cat file it's original file add oneline mySUSE:/data/linktype # cat hardlinkfile1 it's original file add oneline mySUSE:/data/linktype # cat hardlinkfile2 it's original file add oneline mySUSE:/data/linktype # cat symlinkfile1 it's original file add oneline mySUSE:/data/linktype # cat symlinkfile2 it's original file add oneline To view the value stored in a symbolic link use the command readlink. mySUSE:/data/linktype # ln -s symlinkfile1 symlinkfile1-1 mySUSE:/data/linktype # ls -il 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 file 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 hardlinkfile1 258 -rw-r--r-- 3 root root 31 Mar 28 15:42 hardlinkfile2 259 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file 265 lrwxrwxrwx 1 root root 12 Mar 28 15:49 symlinkfile1-1 -> symlinkfile1 260 lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file mySUSE:/data/linktype # readlink symlinkfile1 file mySUSE:/data/linktype # readlink symlinkfile2 file mySUSE:/data/linktype # readlink symlinkfile1-1 symlinkfile1 (\u6ce8\u610f\uff1a\u8fd9\u4ecd\u7136\u662f\u4e00\u4e2a\u7b26\u53f7\u94fe\u63a5\u6587\u4ef6) mySUSE:/data/linktype # readlink -f symlinkfile1-1(\u53c2\u6570-f\u53ef\u4ee5\u76f4\u63a5\u5b9a\u4f4d\u771f\u6b63\u7684\u6e90\u6587\u4ef6) /data/linktype/file (\u6ce8\u610f\uff1a\u8fd9\u624d\u662f\u771f\u6b63\u7684\u539f\u6587\u4ef6)","title":"Lab: File Link Type"},{"location":"linux/Administration/01/#linux-device-file","text":"Represent hardware (except network cards). Each piece of hardware is represented by a device file. Network cards are interfaces. (\u533a\u522b) Link between hardware devices and the kernel drivers \u8bbe\u5907\u6587\u4ef6\u628a\u5185\u6838\u9a71\u52a8\u548c\u7269\u7406\u786c\u4ef6\u8bbe\u5907\u8fde\u63a5\u8d77\u6765 Kernel drivers read from and write to the device file \u5185\u6838\u9a71\u52a8\u7a0b\u5e8f\u5bf9\u8bbe\u5907\u6587\u4ef6\u8fdb\u884c\u8bfb\u5199\u6765\u5b9e\u73b0\u5bf9\u786c\u4ef6\u7684\u8bfb\u5199 The kernel gets the data to the actual hardware in the correct format \u5185\u6838\u4ee5\u6b63\u786e\u7684\u683c\u5f0f\u5bf9\u7269\u7406\u8bbe\u5907\u8fdb\u884c\u8bfb\u5199 Types: Block Devices. A block device reads/writes information in (normally) 512 byte large blocks. Character Devices. A character device reads/writes information character wise. Character devices provide unbuffered access directly to a hardware device. \u76f4\u63a5\u8bfb\u5199\uff0c\u4e0d\u901a\u8fc7\u7f13\u5b58 Sometimes referred to as raw devices. \u88f8\u8bbe\u5907\uff08\u6ce8\u610f\uff1a\u88f8\u8bbe\u5907\u88ab\u89c6\u4e3a\u5b57\u7b26\u8bbe\u5907\uff0c\u4e0d\u662f\u5757\u8bbe\u5907\uff09 any different options for character devices, making their use and application wide and varied. Created automatically by the OS (udev) when the device is discovered by the kernel. \u5185\u6838\u76f4\u63a5\u521b\u5efa\u5bf9\u5e94\u786c\u4ef6\u7684\u8bbe\u5907\u6587\u4ef6","title":"Linux Device File"},{"location":"linux/Administration/02/","text":"Useful Commands Some common abbreviations Abbreviations Description . represents the current directory .. represents the parent directory ~ represents the home directory ~username represents the home directory of user username Software package documentation /usr/share/doc/packages/ Release Notes /usr/share/doc/release-notes/ Command help <command> -h or <command> --help # tree --help Manual pages man [section] command # man 5 crontab # man /sestion options Show tree command manual: # man tree List for keywords: # man -k keyword Force mandb to update. Normally this is done daily via a cron job. # mandb Search for all instances of a command or a file named crontab # man -f crontab # whatis crontab (same output with above command) # man -k crontab # apropos crontab (same output with above command) To go directly to a given man page: # man 5 crontab 1G : go to the 1st line 10G : go to the 10th line G : go to the end of the page /^SELinux : search the word SELinux /section OPTIONS : go to the section OPTIONS man\u5171\u6709\u4ee5\u4e0b\u51e0\u4e2a\u7ae0\u8282\uff0c\u6bd4\u5982\uff0cman 5 crontab\u5c31\u662f\u8fdb\u5165crontab\u7684\u7b2c5\u7ae0\u8282\uff1a Executable programs or shell commands \uff08\u6807\u51c6\u547d\u4ee4\uff09 System calls (functions provided by the kernel)\uff08\u7cfb\u7edf\u8c03\u7528\uff09 Library calls (functions within program libraries)\uff08\u5e93\u51fd\u6570\uff09 Special files (usually found in /dev)\uff08\u8bbe\u5907\u8bf4\u660e\uff09 File formats and conventions eg /etc/passwd \uff08\u6587\u4ef6\u683c\u5f0f\uff09 Games \uff08\u6e38\u620f\u548c\u5a31\u4e50\uff09 Miscellaneous (including macro packages and conventions)\uff08\u6742\u9879\uff0c\u60ef\u4f8b\u4e0e\u534f\u5b9a\u7b49\u7f51\u7edc\u534f\u5b9a\u3001ASCII code\u7b49\u7b49\u7684\u8aaa\u660e\uff09 System administration commands (usually only for root) \uff08\u7ba1\u7406\u5458\u547d\u4ee4\uff09 Kernel routines [Non standard] \uff08\u5176\u4ed6Linux\u7279\u5b9a\u7684\uff0c\u7528\u6765\u5b58\u653e\u5185\u6838\u4f8b\u884c\u7a0b\u5e8f\u7684\u6587\u6863\u3002\uff09 man\u5e38\u7528\u5feb\u6377\u952e \u7ffb\u5c4f \u5411\u540e\u7ffb\u4e00\u5c4f\uff1aspace(\u7a7a\u683c\u952e) \u5411\u524d\u7ffb\u4e00\u5c4f\uff1ab \u5411\u540e\u7ffb\u4e00\u884c\uff1aEnter(\u56de\u8f66\u952e) \u5411\u524d\u7ffb\u4e00\u884c\uff1ak \u67e5\u627e /\u5173\u952e\u8bcd ?\u5173\u952e\u8bcd n (\u4e0b\u4e00\u4e2a) N (\u524d\u4e00\u4e2a) man \u4e2d\u6587\u5316\u3002\u5728 /etc/profile \u52a0\u5165\u4e0b\u9762alias\uff0c\u53ef\u4ee5\u5728man\u4e2d\u8f93\u51fa\u4e2d\u6587 # For man in zh_CH alias cman='man -M /usr/share/man/zh_CN' Display descriptions: whatis command Info pages: info command # info # info top From the terminal window display the info pages for the info command by entering: # info info Move the cursor to the line referring to (Invoking Info) by pressing Tab Tab Follow the link by pressing Enter Move the cursor to the link Note Custom Key Bindings: by pressing Tab (6 times) Follow the link by pressing Enter Return to the page Note Custom Key Bindings: by typing (lowercase L): l Exit the info file by typing: q pwd command Display the current working directory cd command Change directory ls command Display directory contents * Display hidden files with -a option * Detailed listing with -l option * Output is recursive, including all subdirectories with -R option * With option -F After each name, a character indicates the file type (\u201c/\u201d for directories, \u201c*\u201d for executable files, \u201c|\u201d for FIFO files, \u201c@\u201d symbolic link). cp command Copy a file or directory Syntax: cp [option] <source> <destination> Option -a : Copies a directory and subdirectories (compare -R ); symbolic links, file permissions, owners, and time stamps are not changed. \u5b83\u4fdd\u7559\u7b26\u53f7\u94fe\u63a5\u3001\u6587\u4ef6\u5c5e\u6027\uff0c\u5e76\u590d\u5236\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u5185\u5bb9\u3002\u5176\u4f5c\u7528\u7b49\u4e8e-dpR\u53c2\u6570\u7ec4\u5408\u3002 Option -I : Asks before overwriting. Option -R , -r : Copies directories recursively (the directory and any subdirectories). \u9012\u5f52\u62f7\u8d1d\uff0c\u5305\u542b\u5b50\u76ee\u5f55\u53ca\uff08\u9690\u542b\uff09\u6587\u4ef6\uff0c\u7ee7\u627f\u76ee\u6807\u76ee\u5f55\u7684\u6743\u9650\u548c\u5c5e\u6027\u7b49 Option -l : Makes hardlinks instead of copying (\u521b\u5efa\u786c\u94fe\u63a5\u7684\u53e6\u5916\u4e00\u4e2a\u65b9\u6cd5) Option -s : Makes symbolic instead of copying (\u521b\u5efa\u7b26\u53f7\u94fe\u63a5\u7684\u53e6\u5916\u4e00\u4e2a\u65b9\u6cd5) Option -u : Copies a file only when the source file is newer than the destination file or when the destination file is missing. Option -p : \u8fde\u540c\u6863\u6848\u7684\u5c5e\u6027\u4e00\u8d77\u590d\u5236\u8fc7\u53bb\uff0c\u5305\u62ec\u4fee\u6539\u65f6\u95f4\u3001\u8bbf\u95ee\u6743\u9650\u3001\u6240\u6709\u8005\u7ec4\u7b49\uff0c\u800c\u975e\u4f7f\u7528\u9884\u8bbe\u5c5e\u6027\uff1b Labs: Initiate directories and files mySUSE:~ # su - pmgr pmgr@mySUSE:~> mkdir /data/program pmgr@mySUSE:~> mkdir /data/program/general pmgr@mySUSE:~> mkdir /data/program/general/staffing pmgr@mySUSE:~> touch /data/program/general/program_scope pmgr@mySUSE:~> touch /data/program/general/staffing/assignment mySUSE:~ # su - pm1 pm1@mySUSE:~> mkdir /data/project1 pm1@mySUSE:~> mkdir /data/project1/iot pm1@mySUSE:~> mkdir /data/project1/iot/bigdata pm1@mySUSE:~> touch /data/project1/iot/devicelist pm1@mySUSE:~> touch /data/project1/iot/bigdata/math_lib mySUSE:~ # su - pm2 pm2@mySUSE:~> mkdir /data/project2 pm2@mySUSE:~> mkdir /data/project2/erp pm2@mySUSE:~> mkdir /data/project2/erp/fin pm2@mySUSE:~> touch /data/project2/erp/erp_vision pm2@mySUSE:~> touch /data/project2/erp/fin/fin_ar pm2@mySUSE:~> chmod g+w /data/project2/erp/erp_vision pmgr@mySUSE:~> ln /data/project2/erp/erp_vision /data/program/general/p2_erp_version (\u521b\u5efa\u786c\u94fe\u63a5\uff0c\u5f53\u524d\u7528\u6237\u9700\u8981\u5bf9\u6e90\u6587\u4ef6erp_vision\u6709w\u6743\u9650) pmgr@mySUSE:~> ln -s /data/project1/iot/devicelist /data/program/general/p1_devicelist (\u521b\u5efa\u7b26\u53f7\u94fe\u63a5\uff0c\u4e0d\u9a8c\u8bc1\u5f53\u524d\u7528\u6237\u662f\u5426\u5bf9\u6e90\u6587\u4ef6devicelist\u6709\u6743\u9650) mySUSE:~ # tree /data /data \u251c\u2500\u2500 program \u2502 \u2514\u2500\u2500 general \u2502 \u251c\u2500\u2500 p1_devicelist -> /data/project1/iot/devicelist \u2502 \u251c\u2500\u2500 p2_erp_version \u2502 \u251c\u2500\u2500 program_scope \u2502 \u2514\u2500\u2500 staffing \u2502 \u2514\u2500\u2500 assignment \u251c\u2500\u2500 project1 \u2502 \u2514\u2500\u2500 iot \u2502 \u251c\u2500\u2500 bigdata \u2502 \u2502 \u2514\u2500\u2500 math_lib \u2502 \u2514\u2500\u2500 devicelist \u2514\u2500\u2500 project2 \u2514\u2500\u2500 erp \u251c\u2500\u2500 erp_vision \u2514\u2500\u2500 fin \u2514\u2500\u2500 fin_ar pmgr@mySUSE:~> cp -R /data/project1 /data/program/ (/data/program/project1\u7684\u7528\u6237\u548c\u7ec4\u90fd\u7ee7\u627f\u4e86/data/program/) pmgr@mySUSE:~> cp -a /data/project2 /data/program/ (/data/program/project2\u7684\u7528\u6237\u7ee7\u627f\u4e86/data/program/\uff0c\u4f46\u7ec4\u8fd8\u662f\u4fdd\u7559\u539f\u6765\u7684) mv command Move or rename a file or directory Option -i : Asks for confirmation before moving or renaming a file. This prevents existing files with the same name from being overwritten. Option -u : Only moves files that are newer than the target files of the same name. pmgr@mySUSE:/data/program/general> cp program_scope ./staffing/ pmgr@mySUSE:/data/program/general> mv -i program_scope ./staffing/ mv: overwrite './staffing/program_scope'? n rm command Delete a file or directory Option -i : Asks for confirmation before deleting. Option -r : (recursively) Allows full directories to be deleted. Option -f : (force) By default, rm asks for confirmation if the file that should be deleted is read-only. Using this option, the files are deleted without asking for confirmation. mkdir command Create a new directory Option -p lets you create a complete path (\u5c42\u7ea7\u8def\u5f84\u4e00\u6b21\u521b\u5efa) pmgr@mySUSE:/data> mkdir -p industry/utilities pmgr@mySUSE:/data> tree ./industry/ ./industry/ \u2514\u2500\u2500 utilities rmdir command Remove an empty directory. The directory or directories must be empty before you can delete them. ln command Create a link Default: Hard link Symbolic link with -s option Syntax: ln [-s] <original> <link> touch command Change the access and modification times Create an empty file if the given file does not exist. Change the time stamp of a file. Option -a : Changes only the time of the last read access (access time). Option -m : Changes only the time of the last modification (modification time). Option -r file : Sets the time stamp of file instead of the current time. Option -t time : Instead of the current time, sets time (structure: [[CC]YY]MMDDhhmm.[ss] ([Century]Year] Month Day Hour Minute [Seconds], two digits in each)) pmgr@mySUSE:/data/industry> touch readme pmgr@mySUSE:/data/industry> touch -a readme pmgr@mySUSE:/data/industry> touch -m readme pmgr@mySUSE:/data/industry> stat readme File: readme Size: 0 Blocks: 0 IO Block: 4096 regular empty file Device: 3dh/61d Inode: 338 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1003/ pmgr) Gid: ( 1000/ admins) Access: 2019-03-31 10:07:47.489055973 +0800 Modify: 2019-03-31 10:07:58.805109884 +0800 Change: 2019-03-31 10:07:58.805109884 +0800 Birth: - cat command Concatenates files tac command Same as cat, but displays the file(s) in reverse pmgr@mySUSE:/data/industry> cat readme line 1 line 2 line 3 pmgr@mySUSE:/data/industry> tac readme line 3 line 2 line 1 more command Display file contents one page at a time less command Displays file contents for better navigation head command Displays the first 10 lines of a file. To set the number of lines use the -n option pmgr@mySUSE:/data/industry> head readme line 1 line 2 line 3 line 4 line 5 line 6 line 7 line 8 line 9 line 10 pmgr@mySUSE:/data/industry> head -n 5 readme line 1 line 2 line 3 line 4 line 5 tail command Display the last lines of a file To set the number of lines use the -n option To output appended data use -f option, displays a continuously updated view of the last lines of a file. To exit tail -f, press Ctrl+C. pmgr@mySUSE:/data/industry> tail -n 6 readme line 10 line 11 line 12 line 13 line 14 line 15 tar command Create, expand or list archive files Use option c to create an archive Use option f to specify the archive file name Use option v for verbose mode Use option x to extract an archive Use option t to list the content of an archive Use option z to (un-)compress the archive with gzip Use option j to (un-)compress the archive with bzip The /etc directory (include sub-directories) is backed up to the /backup/etc.tar file pmgr@mySUSE:~> tar -cvf /data/backup/project1.tar /data/project1/ pmgr@mySUSE:~> tar -cvf /data/backup/project2.tar /data/project2/ pmgr@mySUSE:~> tar -cv --exclude='*.conf' -f /data/backup/project2a.tar /data/project2/ View the contents of an archive. Some .conf files are excluded in project2a.tar file. pmgr@mySUSE:~> tar -tvf /data/backup/project2.tar drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/ -rw-r--r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/fin/fin_ar -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/fin.conf -rw-rw-r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/erp_vision -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/erp/erp.conf -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/project2.conf pmgr@mySUSE:~> tar -tvf /data/backup/project2a.tar drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/ -rw-r--r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/fin/fin_ar -rw-rw-r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/erp_vision Unpack and write all files in the archive to the current directory. Extract to another directory by using the -C option pmgr@mySUSE:~> mkdir project1.backup pmgr@mySUSE:~> tar -xvf /data/backup/project1.tar -C /data/backup/project1.backup/ Incremental backup with tar command pmgr@mySUSE:~> tar -g snapshot_program -cvf /data/backup/bkp_program_full.tar /data/program/ pmgr@mySUSE:~> tar -tvf /data/backup/bkp_program_full.tar pmgr@mySUSE:~> touch /data/program/general/general.conf pmgr@mySUSE:~> tar -g snapshot_program -cvf /data/backup/bkp_program_inc.tar /data/program/ pmgr@mySUSE:~> rm -rf program/ pmgr@mySUSE:~> tar -xvf /data/backup/bkp_program_inc.tar -C /data/ cpio command Another archiving command gzip command Compress files using the gzip algorithm Option -c : Compresses the file without modifying the original file. The result is written to the standard output (usually the screen). From there, it can be redirected to a file with \u201c>\u201d. Option -d : Decompresses the specified file (gunzip) Option -r : Compresses and decompresses files in all subdirectories. Option -1 to -9, --fast, --best : Controls the compression speed: -1 means --fast and causes a quick compression but produces larger files, -9 corresponds to --best and requires more computing time but produces smaller files. The default setting is -6. gunzip command Expand files compressed with gzip bzip2 command Compress files using the bzip2 algorithm Option -c : Option -d : Decompresses the specified file (bunzip2). Option -1 to -9 : Controls the compression speed: -1 causes a quick compression but produces larger files, -9 requires more computing time but produces smaller files. The default setting is -9 . bunzip2 command Expand files compressed with bzip rsync command Copy only deltas between two directories. A key benefit of using rsync is that when copying data, rsync compares the source and the target directory and transfers only data that has changed or has been created. \u4ec5\u590d\u5236\u4e24\u4e2a\u76ee\u5f55\u4e4b\u95f4\u7684\u589e\u91cf\u3002 \u4f7f\u7528rsync\u7684\u4e00\u4e2a\u4e3b\u8981\u597d\u5904\u662f\uff0c\u5728\u590d\u5236\u6570\u636e\u65f6\uff0crsync\u4f1a\u6bd4\u8f83\u6e90\u76ee\u5f55\u548c\u76ee\u6807\u76ee\u5f55\uff0c\u5e76\u4ec5\u4f20\u8f93\u5df2\u66f4\u6539\u6216\u5df2\u521b\u5efa\u7684\u6570\u636e\u3002 Local or via network \u672c\u5730\u6216\u901a\u8fc7\u7f51\u7edc Uses ssh as default transport \u4f7f\u7528ssh\u4f5c\u4e3a\u9ed8\u8ba4\u4f20\u8f93 Can talk to rsync daemon on the remote machine \u53ef\u4ee5\u4e0e\u8fdc\u7a0b\u8ba1\u7b97\u673a\u4e0a\u7684rsync\u5b88\u62a4\u7a0b\u5e8f\u901a\u4fe1 Note: rsync must be installed on both the source and the target computer for this to work. \u5fc5\u987b\u5728\u6e90\u8ba1\u7b97\u673a\u548c\u76ee\u6807\u8ba1\u7b97\u673a\u4e0a\u5b89\u88c5rsync\u624d\u80fd\u4f7f\u5176\u6b63\u5e38\u5de5\u4f5c\u3002 As the default shell used by rsync is ssh, the -e option only needs to be used when you want to use something else than ssh. \u7531\u4e8ersync\u4f7f\u7528\u7684\u9ed8\u8ba4shell\u662fssh\uff0c\u56e0\u6b64\u53ea\u6709\u5728\u60f3\u8981\u4f7f\u7528\u9664ssh\u4ee5\u5916\u7684\u5176\u4ed6\u5de5\u5177\u65f6\u624d\u9700\u8981\u4f7f\u7528-e\u9009\u9879\u3002 Options Option -a : Puts rsync into the archive mode. The -a option ensures the following are preserved \u4fdd\u7559 in the mirrored copy of the directory: Symbolic links (l option) Access permissions (p option) Owners (o option) Group membership (g option) Time stamp (t option) Option -x : Saves files on one file system only, which means that rsync does not follow symbolic links to other file systems. \u4e0d\u8de8\u6587\u4ef6\u7cfb\u7edf\uff0c\u53ea\u5728\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u5185(don't cross filesyste* undaries) Option -v : Enables the verbose mode. Use this mode to output information about the transferred files and the progress of the copying process. \u8f93\u51fa\u4f20\u8f93\u8fc7\u7a0b\u7684\u7ec6\u8282\u4fe1\u606f Option -z : Compresses the data during the transfer. This is especially useful for remote synchronization. \u538b\u7f29\u65b9\u5f0f\u4f20\u8f93 Option --delete : Deletes files from the mirrored directory that no longer exist in the original directory. Option --exclude-from : Does not back up files listed in an exclude file. Local backup via rsync command pmgr@mySUSE:/data> rsync -av /data/industry/* /data/backup/industry/ sending incremental file list created directory /data/backup/industry readme utilities/ sent 264 bytes received 87 bytes 702.00 bytes/sec total size is 111 speedup is 0.32 pmgr@mySUSE:/data/industry/utilities> touch roadmap.txt pmgr@mySUSE:/data> rsync -av /data/industry/* /data/backup/industry/ sending incremental file list utilities/ utilities/roadmap.txt sent 171 bytes received 39 bytes 420.00 bytes/sec total size is 111 speedup is 0.53 pmgr@mySUSE:/data> rm roadmap.txt pmgr@mySUSE:/data> rsync -av /data/industry/* --delete /data/backup/industry/ sending incremental file list deleting utilities/roadmap.txt utilities/ sent 102 bytes received 41 bytes 286.00 bytes/sec total size is 111 speedup is 0.78 dd command Copies files block by block Used to create disk or partition images Most important options: if =input_file `of``=output_file bs =block_size You can use the dd command to convert and copy files byte-wise. Normally dd reads from the standard input and writes the result to the standard output. But with the appropriate parameters, regular files can be addressed as well. You can copy all kinds of Linux data with this command, including entire hard disk partitions. You can even copy an entire installed system (or just parts of it). Copy file /etc/protocols to protocols.old. The default size for a record is 512 bytes. Below 45+1 means, 45 complete record of standard size and 1 incomplete record (less than 512 bytes pmgr@mySUSE:/data/program> dd if=/etc/protocols of=protocols.old bs=512 45+1 records in 45+1 records out 23259 bytes (23 kB, 23 KiB) copied, 0.000595392 s, 39.1 MB/s \u521b\u5efa\u4e00\u4e2a100M\u7684\u7a7a\u6587\u4ef6 pmgr@mySUSE:/data/program> dd if=/dev/zero of=datafile bs=100M count=2 2+0 records in 2+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 2.79311 s, 75.1 MB/s \u5907\u4efd\u6574\u4e2a\u5206\u533a #dd if=/dev/sda1 of=boot.partition \u5236\u4f5cU\u76d8\u542f\u52a8\u76d8\uff08U\u76d8\u6302\u8f7d\u5230/dev/sdb\uff09 #dd if=/root/diskboot.img of=/dev/sdb bs=125682176 \u5907\u4efd\u786c\u76d8\u4e3b\u5f15\u5bfc\u8bb0\u5f55 #dd if=/dev/sda of=/tmp/mbr_copy bs=512 count=1 \u8fd8\u539f\u786c\u76d8\u4e3b\u5f15\u5bfc\u8bb0\u5f55 #dd if=/disk.mbr of=/dev/hda bs=512 count=1 \u5c06\u5185\u5b58\u91cc\u7684\u6570\u636e\u62f7\u8d1d\u5230root\u76ee\u5f55\u4e0b\u7684mem.bin\u6587\u4ef6 # dd if=/dev/mem of=/root/mem.bin bs=1024 \u62f7\u8d1d\u5149\u76d8\u6570\u636e\u5230root\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u4fdd\u5b58\u4e3acd.iso\u6587\u4ef6 # dd if=/dev/cdrom of=/root/cd.iso \u5229\u7528\u968f\u673a\u7684\u6570\u636e\u586b\u5145\u786c\u76d8(\u9500\u6bc1\u786c\u76d8\u6570\u636e) # dd if=/dev/urandom of=/dev/hda1 \u6d4b\u8bd5\u786c\u76d8\u8bfb\u5199\u901f\u5ea6\u3002\u901a\u8fc7\u4e24\u4e2a\u547d\u4ee4\u8f93\u51fa\u7684\u6267\u884c\u65f6\u95f4\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6d4b\u8bd5\u786c\u76d8\u7684\u8bfb\uff0f\u5199\u901f\u5ea6\uff1a mySUSE:/data # dd if=/data/program/datafile bs=64k | dd of=/dev/null 3200+0 records in 3200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 0.67138 s, 312 MB/s 409600+0 records in 409600+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 0.675912 s, 310 MB/s # dd if=/dev/zero of=/data/program/datafile bs=1024 count=100 \u5207\u5272\u5927\u6587\u4ef6bigfile\uff0c\u517198336321\u5b57\u8282\uff0c\u5219\uff1a # dd if=bigfile of=smallfile1 bs=1 count=20000000 # dd if=bigfile of=smallfile2 bs=1 count=20000000 skip=20000000 # dd if=bigfile of=smallfile3 bs=1 count=20000000 skip=40000000 # dd if=bigfile of=smallfile4 bs=1 count=20000000 skip=60000000 # dd if=bigfile of=smallfile5 bs=1 count=18336321 skip=80000000 \u5c06\u5207\u5272\u6587\u4ef6\u7ec4\u88c5 # dd if=smallfile1 of=bigfile bs=1 count=20000000 # dd if=smallfile2 of=bigfile bs=1 count=20000000 seek=20000000 # dd if=smallfile3 of=bigfile bs=1 count=20000000 seek=40000000 # dd if=smallfile4 of=bigfile bs=1 count=20000000 seek=60000000 # dd if=smallfile5 of=bigfile bs=1 count=18336321 seek=80000000 if: \u8981\u5207\u5272\u7684\u5927\u6587\u4ef6\u540d of: \u5207\u5272\u540e\u7684\u5b50\u6587\u4ef6\u540d bs: \u4ee5\u591a\u5c11\u5b57\u8282\u4f5c\u4e3a\u4e00\u4e2a\u5207\u5272\u8bb0\u5f55\u5355\u4f4d count: \u662f\u8981\u5207\u5272\u7684\u5355\u4f4d\u8bb0\u5f55\u6570 skip: \u8bf4\u660e\u5207\u5272\u65f6\u7684\u8d77\u70b9 seek: \u660e\u786e\u6307\u51fa\u5f00\u59cb\u4f4d\u7f6e find command Search for files or directories Syntax: find path criterion [action] The find command has a multitude of options, a few of which are explained here. You can use the following arguments with the command: path: The section of the file system to search (the specified directory and all its subdirectories). If nothing is specified, the file system below the current directory is used. criterion: The properties the file should have (see below) action: Options that influence the following conditions or control the search as a whole The most important actions are: -print (default) -exec command With the -exec option, you can call up another command. This option is frequently used to link find and grep, as in the following: \u627e\u51fagen\u5f00\u5934\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -name gen\\* ./program/general ./program/general/general.conf \u627e\u51fagen\u5f00\u5934\u7684\u6587\u4ef6\uff0c\u5e76\u5728\u6587\u4ef6\u5185\u5bb9\u4e2d\u67e5\u627exen\uff0c\u627e\u5230\u540e\u7ed3\u679c\u8f93\u51faxen pmgr@dcmaster:/data> find . -name gen\\* -type f -exec grep xen {} \\; xen xening The two brackets \u201c{}\u201d stand as placeholders for the file names which are found and passed to the grep command. The semicolon closes the -exec instruction. Because this is a special character, it is masked by placing a backslash in front of it. -ctime [+/-]days Searches for files whose last change took place no later than (no earlier than) a specified number of days ago. \u5728\u8fc7\u53bbn\u5929\u5185\u88ab\u4fee\u6539\u8fc7\u7684\u6587\u4ef6 mgr@dcmaster:/data> find . -ctime 1 . ./program/datafile -gid number Searches for files with the numeric GID (Group ID) number. (gid \u662f n) -group name Searches for files that are owned by the group name. Instead of a name, the numeric GID is allowed. (group \u540d\u79f0\u662f name) -name pattern Searches for files whose names contain the given pattern. If the pattern contains meta characters or wild cards, the name must be enclosed by quotation marks. Otherwise thename will be interpreted by the shell and not by find. -newer file Searches for files that were modified more recently than file. \u6bd4\u6587\u4ef6 file \u66f4\u65b0\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -cnewer ./program/datafile . -size [+/-]size Matches files that are above or below a certain size. The size (in blocks of 512 bytes) is given as an argument. The suffix \u201cc\u201cswitches to byte and \u201ck\u201d to blocks of 1024bytes. A preceding \u201c+\u201d stands for all larger files and a \u201c-\u201d for all smaller files. (\u6587\u4ef6\u5927\u5c0f \u662f n \u2022 b \u4ee3\u8868 512 \u4f4d\u5143\u7ec4\u7684\u533a\u5757 \u2022 c \u8868\u793a\u5b57\u5143\u6570 \u2022 k \u8868\u793a kilo bytes \u2022 w \u662f\u4e8c\u4e2a\u4f4d\u5143\u7ec4 pmgr@dcmaster:/data> find . -size 20k ./backup/project2.tar -type file_type Searches for a file type. A file type can be one of the following: * c : \u6587\u4ef6\u7c7b\u578b\u662f c \u7684\u6587\u4ef6\u3002 * d: \u76ee\u5f55 * c: \u5b57\u578b\u88c5\u7f6e\u6587\u4ef6 * b: \u533a\u5757\u88c5\u7f6e\u6587\u4ef6 * p: \u5177\u540d\u8d2e\u5217 * f: \u4e00\u822c\u6587\u4ef6 * l: \u7b26\u53f7\u8fde\u7ed3 * s: socket -uid number Searches for files with the numeric UID (User ID) number. -user name Searches for files, which are owned by user name. Instead of a name, the numeric UID is allowed. \u5e38\u7528\u53c2\u6570 mount, -xdev : \u53ea\u68c0\u67e5\u548c\u6307\u5b9a\u76ee\u5f55\u5728\u540c\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u4e0b\u7684\u6587\u4ef6\uff0c\u907f\u514d\u5217\u51fa\u5176\u5b83\u6587\u4ef6\u7cfb\u7edf\u4e2d\u7684\u6587\u4ef6 amin n : \u5728\u8fc7\u53bb n \u5206\u949f\u5185\u88ab\u8bfb\u53d6\u8fc7 anewer file : \u6bd4\u6587\u4ef6 file \u66f4\u665a\u88ab\u8bfb\u53d6\u8fc7\u7684\u6587\u4ef6 atime n : \u5728\u8fc7\u53bbn\u5929\u5185\u88ab\u8bfb\u53d6\u8fc7\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -atime 1 ./program/datafile cmin n : \u5728\u8fc7\u53bb n \u5206\u949f\u5185\u88ab\u4fee\u6539\u8fc7 pmgr@dcmaster:/data> find . -cmin 20 empty : \u7a7a\u7684\u6587\u4ef6 ipath p, -path p : \u8def\u5f84\u540d\u79f0\u7b26\u5408 p \u7684\u6587\u4ef6\uff0cipath \u4f1a\u5ffd\u7565\u5927\u5c0f\u5199 name name, -iname name : \u6587\u4ef6\u540d\u79f0\u7b26\u5408 name \u7684\u6587\u4ef6\u3002iname \u4f1a\u5ffd\u7565\u5927\u5c0f\u5199 pid n : process id \u662f n \u7684\u6587\u4ef6 \u67e5\u627e\u5f53\u524d\u76ee\u5f55\u53ca\u5b50\u76ee\u5f55\u4e2d\u6240\u6709\u6587\u4ef6\u957f\u5ea6\u4e3a0\u7684\u666e\u901a\u6587\u4ef6\uff0c\u5e76\u5217\u51fa\u5b83\u4eec\u7684\u5b8c\u6574\u8def\u5f84 pmgr@dcmaster:/data> find . -type f -size 0 -exec ls -l {} \\; \u67e5\u627e\u524d\u76ee\u5f55\u4e2d\u6587\u4ef6\u5c5e\u4e3b\u5177\u6709\u8bfb\u3001\u5199\u6743\u9650\uff0c\u5e76\u4e14\u6587\u4ef6\u6240\u5c5e\u7ec4\u7684\u7528\u6237\u548c\u5176\u4ed6\u7528\u6237\u5177\u6709\u8bfb\u6743\u9650\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -type f -perm 644 -exec ls -l {} \\; \u67e5\u627e/var/log\u76ee\u5f55\u4e2d\u66f4\u6539\u65f6\u95f4\u572817\u65e5\u4ee5\u524d\u7684\u666e\u901a\u6587\u4ef6\uff0c\u5e76\u5728\u5220\u9664\u4e4b\u524d\u8be2\u95ee\u5b83\u4eec pmgr@dcmaster:/data> find /var/log -type f -mtime +17 -ok rm {} \\; \u5c06\u76ee\u524d\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e0b\u6240\u6709\u6700\u8fd1 1 \u5929\u5185\u66f4\u65b0\u8fc7\u7684\u6587\u4ef6\u5217\u51fa mgr@dcmaster:/data> find . -ctime 1 \u5c06\u76ee\u524d\u76ee\u5f55\u5176\u5176\u4e0b\u5b50\u76ee\u5f55\u4e2d\u6240\u6709\u4e00\u822c\u6587\u4ef6\u5217\u51fa pmgr@dcmaster:/data> find . -type f \u5c06\u76ee\u524d\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e0b\u6240\u6709\u5ef6\u4f38\u6863\u540d\u662fconf \u7684\u6587\u4ef6\u5217\u51fa\u6765 pmgr@dcmaster:/data> find . -name \"*.conf\" which command Searches all paths listed in the variable $PATH and returns the full path of the command The which command searches all paths listed in the variable $PATH for the specified command and returns the full path of the command. In the variable $PATH, the most important directoriesare listed where the shell looks for executable files. which\u547d\u4ee4\u641c\u7d22\u53d8\u91cf$PATH\u4e2d\u5217\u51fa\u7684\u6240\u6709\u8def\u5f84\u4ee5\u83b7\u53d6\u6307\u5b9a\u547d\u4ee4\uff0c\u5e76\u8fd4\u56de\u547d\u4ee4\u7684\u5b8c\u6574\u8def\u5f84\u3002 The which command is especially useful if several versions of a command exist in different directories and you want to know which version is executed when entered without specifying apath. \u5982\u679c\u547d\u4ee4\u7684\u591a\u4e2a\u7248\u672c\u5b58\u5728\u4e8e\u4e0d\u540c\u7684\u76ee\u5f55\u4e2d\uff0c\u5e76\u4e14\u60a8\u60f3\u77e5\u9053\u5728\u8f93\u5165\u65f6\u6267\u884c\u4e86\u54ea\u4e2a\u7248\u672c\u800c\u672a\u6307\u5b9a\u8def\u5f84\uff0c\u90a3\u4e48which\u547d\u4ee4\u7279\u522b\u6709\u7528\u3002 NOTE: To see the content of a variable, use the echo command Options Description -n<\u6587\u4ef6\u540d\u957f\u5ea6> \u6307\u5b9a\u6587\u4ef6\u540d\u957f\u5ea6\uff0c\u6307\u5b9a\u7684\u957f\u5ea6\u5fc5\u987b\u5927\u4e8e\u6216\u7b49\u4e8e\u6240\u6709\u6587\u4ef6\u4e2d\u6700\u957f\u7684\u6587\u4ef6\u540d\u3002 -p<\u6587\u4ef6\u540d\u957f\u5ea6> \u4e0e-n\u53c2\u6570\u76f8\u540c\uff0c\u4f46\u6b64\u5904\u7684<\u6587\u4ef6\u540d\u957f\u5ea6>\u5305\u62ec\u4e86\u6587\u4ef6\u7684\u8def\u5f84\u3002 -w \u6307\u5b9a\u8f93\u51fa\u65f6\u680f\u4f4d\u7684\u5bbd\u5ea6\u3002 -V \u663e\u793a\u7248\u672c\u4fe1\u606f # which grep /usr/bin/grep # which -V grep GNU which v2.21, Copyright (C) 1999 - 2015 Carlo Wood. GNU which comes with ABSOLUTELY NO WARRANTY; This program is free software; your freedom to use, change and distribute this program is protected by the GPL. whereis command The whereis command returns the binaries (option -b), manual pages (option -m), and the source code (option -s) of the specified command. If no option is used, all this information is returned, provided the information is available. This command is faster than find, but it is less thorough. Attempts to locate the desired program in the standard Linux places, and in the places specified by $PATH and $MANPATH . \u5c1d\u8bd5\u5728\u6807\u51c6Linux\u4f4d\u7f6e\u548c\u6307\u5b9a\u4f4d\u7f6e($PATH\u548c$MANPATH)\u627e\u5230\u6240\u9700\u7684\u7a0b\u5e8f Options Description -b \u53ea\u67e5\u627e\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002 -B<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002 -f \u4e0d\u663e\u793a\u6587\u4ef6\u540d\u524d\u7684\u8def\u5f84\u540d\u79f0\u3002 -m \u53ea\u67e5\u627e\u8bf4\u660e\u6587\u4ef6\u3002 -M<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u8bf4\u660e\u6587\u4ef6\u3002 -s \u53ea\u67e5\u627e\u539f\u59cb\u4ee3\u7801\u6587\u4ef6\u3002 -S<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u539f\u59cb\u4ee3\u7801\u6587\u4ef6\u3002 -u \u67e5\u627e\u4e0d\u5305\u542b\u6307\u5b9a\u7c7b\u578b\u7684\u6587\u4ef6\u3002 \u4ee5\u4e0b\u8f93\u51fa\u4fe1\u606f\u4ece\u5de6\u81f3\u53f3\u5206\u522b\u4e3a\u67e5\u8be2\u7684\u7a0b\u5e8f\u540d\u3001bash\u8def\u5f84\u3001bash\u7684man\u624b\u518c\u9875\u8def\u5f84\u3002 # whereis grep grep: /usr/bin/grep /bin/grep /usr/share/man/man1/grep.1.gz /usr/share/info/grep.info.gz \u663e\u793abash \u547d\u4ee4\u7684\u4e8c\u8fdb\u5236\u7a0b\u5e8f # whereis -b grep grep: /usr/bin/grep /bin/grep \u663e\u793abash \u547d\u4ee4\u7684\u5e2e\u52a9\u6587\u4ef6 # whereis -m grep grep: /usr/share/man/man1/grep.1.gz /usr/share/info/grep.info.gz type command The type command shows what kind of command is executed when you enter it: \u547d\u4ee4\u7684\u7c7b\u578b a shell built-in command (an essential command that is hard coded in the shell), for example type or cd an external command (called by the shell) an alias, for example ls. An alias defines shortcuts and synonyms for commonly used shell commands. a function The -a option delivers all instances of a command bearing this name in the file system. NOTE: If you want to have more information about a file format, you can use the file command. \u4e0d\u9002\u7528\u4e8e\u666e\u901a\u6587\u4ef6 dcmaster:/data/shell # type pwd.txt -bash: type: pwd.txt: not found \u4e0d\u9002\u7528\u4e8e\u81ea\u5b9a\u4e49\u53ef\u6267\u884c\u811a\u672c dcmaster:/data/shell # type math.sh -bash: type: math.sh: not found \u7cfb\u7edf\u547d\u4ee4 dcmaster:/data/shell # type rsync rsync is /usr/bin/rsync \u522b\u540d dcmaster:/data/shell # type l l is aliased to `ls -alF' file command file\u547d\u4ee4\u7528\u4e8e\u8fa8\u8bc6\u6587\u4ef6\u7c7b\u578b -b \u5217\u51fa\u8fa8\u8bc6\u7ed3\u679c\u65f6\uff0c\u4e0d\u663e\u793a\u6587\u4ef6\u540d\u79f0\u3002 -c \u8be6\u7ec6\u663e\u793a\u6307\u4ee4\u6267\u884c\u8fc7\u7a0b\uff0c\u4fbf\u4e8e\u6392\u9519\u6216\u5206\u6790\u7a0b\u5e8f\u6267\u884c\u7684\u60c5\u5f62\u3002 -f <\u540d\u79f0\u6587\u4ef6> \u6307\u5b9a\u540d\u79f0\u6587\u4ef6\uff0c\u5176\u5185\u5bb9\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6587\u4ef6\u540d\u79f0\u65f6\uff0c\u8ba9file\u4f9d\u5e8f\u8fa8\u8bc6\u8fd9\u4e9b\u6587\u4ef6\uff0c\u683c\u5f0f\u4e3a\u6bcf\u5217\u4e00\u4e2a\u6587\u4ef6\u540d\u79f0\u3002 -L \u76f4\u63a5\u663e\u793a\u7b26\u53f7\u8fde\u63a5\u6240\u6307\u5411\u7684\u6587\u4ef6\u7684\u7c7b\u522b\u3002 -m<\u9b54\u6cd5\u6570\u5b57\u6587\u4ef6> \u6307\u5b9a\u9b54\u6cd5\u6570\u5b57\u6587\u4ef6\u3002 -v \u663e\u793a\u7248\u672c\u4fe1\u606f\u3002 -z \u5c1d\u8bd5\u53bb\u89e3\u8bfb\u538b\u7f29\u6587\u4ef6\u7684\u5185\u5bb9\u3002 dcmaster:/data/linktype # l -rw-r--r-- 3 root root 44 May 3 09:50 file -rw-r--r-- 3 root root 44 May 3 09:50 hardlinkfile1 -rw-r--r-- 3 root root 44 May 3 09:50 hardlinkfile2 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 12 Mar 28 15:49 symlinkfile1-1 -> symlinkfile1 lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file dcmaster:/data/linktype # file hardlinkfile1 hardlinkfile1: ASCII text dcmaster:/data/linktype # file -i hardlinkfile1 hardlinkfile1: text/plain; charset=us-ascii dcmaster:/data/linktype # file /data/linktype/ /data/linktype/: directory dcmaster:/data/linktype # file -L /data/linktype/ /data/linktype/: directory dcmaster:/data/linktype # file -i /data/linktype/ /data/linktype/: inode/directory; charset=binary dcmaster:/data/linktype # file symlinkfile1 symlinkfile1: symbolic link to file dcmaster:/data/linktype # file -i symlinkfile1 symlinkfile1: inode/symlink; charset=binary grep command You can specify search patterns in the form of regular expressions, although the basic grep command is limited in this regard. To search for more complex patterns, use the egrep command (or grep -E ) instead, which accepts extended regular expressions. To avoid having special characters in search patterns interpreted by the shell, enclose the pattern in quotation marks. Syntax: grep [options] search_pattern filename * egrep = grep -E * rgrep \u53c2\u6570 -a \u6216 --text : \u4e0d\u8981\u5ffd\u7565\u4e8c\u8fdb\u5236\u7684\u6570\u636e\u3002 -A<\u663e\u793a\u884c\u6570> \u6216 --after-context=<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u8303\u672c\u6837\u5f0f\u7684\u90a3\u4e00\u5217\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u540e\u7684\u5185\u5bb9\u3002 -b \u6216 --byte-offset : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u6807\u793a\u51fa\u8be5\u884c\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u7f16\u53f7\u3002 -B<\u663e\u793a\u884c\u6570> \u6216 --before-context=<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u524d\u7684\u5185\u5bb9\u3002 -c \u6216 --count : \u8ba1\u7b97\u7b26\u5408\u6837\u5f0f\u7684\u5217\u6570\u3002 -C<\u663e\u793a\u884c\u6570> \u6216 --context=<\u663e\u793a\u884c\u6570> \u6216 -<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u524d\u540e\u7684\u5185\u5bb9\u3002 -d <\u52a8\u4f5c> \u6216 --directories=<\u52a8\u4f5c> : \u5f53\u6307\u5b9a\u8981\u67e5\u627e\u7684\u662f\u76ee\u5f55\u800c\u975e\u6587\u4ef6\u65f6\uff0c\u5fc5\u987b\u4f7f\u7528\u8fd9\u9879\u53c2\u6570\uff0c\u5426\u5219grep\u6307\u4ee4\u5c06\u56de\u62a5\u4fe1\u606f\u5e76\u505c\u6b62\u52a8\u4f5c\u3002 -e<\u8303\u672c\u6837\u5f0f> \u6216 --regexp=<\u8303\u672c\u6837\u5f0f> : \u6307\u5b9a\u5b57\u7b26\u4e32\u505a\u4e3a\u67e5\u627e\u6587\u4ef6\u5185\u5bb9\u7684\u6837\u5f0f\u3002 -E \u6216 --extended-regexp : \u5c06\u6837\u5f0f\u4e3a\u5ef6\u4f38\u7684\u666e\u901a\u8868\u793a\u6cd5\u6765\u4f7f\u7528\u3002 -f<\u89c4\u5219\u6587\u4ef6> \u6216 --file=<\u89c4\u5219\u6587\u4ef6> : \u6307\u5b9a\u89c4\u5219\u6587\u4ef6\uff0c\u5176\u5185\u5bb9\u542b\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u89c4\u5219\u6837\u5f0f\uff0c\u8ba9grep\u67e5\u627e\u7b26\u5408\u89c4\u5219\u6761\u4ef6\u7684\u6587\u4ef6\u5185\u5bb9\uff0c\u683c\u5f0f\u4e3a\u6bcf\u884c\u4e00\u4e2a\u89c4\u5219\u6837\u5f0f\u3002 -F \u6216 --fixed-regexp : \u5c06\u6837\u5f0f\u89c6\u4e3a\u56fa\u5b9a\u5b57\u7b26\u4e32\u7684\u5217\u8868\u3002 -G \u6216 --basic-regexp : \u5c06\u6837\u5f0f\u89c6\u4e3a\u666e\u901a\u7684\u8868\u793a\u6cd5\u6765\u4f7f\u7528\u3002 -h \u6216 --no-filename : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u4e0d\u6807\u793a\u8be5\u884c\u6240\u5c5e\u7684\u6587\u4ef6\u540d\u79f0\u3002 -H \u6216 --with-filename : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u8868\u793a\u8be5\u884c\u6240\u5c5e\u7684\u6587\u4ef6\u540d\u79f0\u3002 -i \u6216 --ignore-case : \u5ffd\u7565\u5b57\u7b26\u5927\u5c0f\u5199\u7684\u5dee\u522b\u3002 -l \u6216 --file-with-matches : \u5217\u51fa\u6587\u4ef6\u5185\u5bb9\u7b26\u5408\u6307\u5b9a\u7684\u6837\u5f0f\u7684\u6587\u4ef6\u540d\u79f0\u3002 -L \u6216 --files-without-match : \u5217\u51fa\u6587\u4ef6\u5185\u5bb9\u4e0d\u7b26\u5408\u6307\u5b9a\u7684\u6837\u5f0f\u7684\u6587\u4ef6\u540d\u79f0\u3002 -n \u6216 --line-number : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u6807\u793a\u51fa\u8be5\u884c\u7684\u5217\u6570\u7f16\u53f7\u3002 -o \u6216 --only-matching : \u53ea\u663e\u793a\u5339\u914dPATTERN \u90e8\u5206\u3002 -q \u6216 --quiet\u6216--silent : \u4e0d\u663e\u793a\u4efb\u4f55\u4fe1\u606f\u3002 -r \u6216 --recursive : \u6b64\u53c2\u6570\u7684\u6548\u679c\u548c\u6307\u5b9a\"-d recurse\"\u53c2\u6570\u76f8\u540c\u3002 -s \u6216 --no-messages : \u4e0d\u663e\u793a\u9519\u8bef\u4fe1\u606f\u3002 -v \u6216 --revert-match : \u663e\u793a\u4e0d\u5305\u542b\u5339\u914d\u6587\u672c\u7684\u6240\u6709\u884c\u3002 -V \u6216 --version : \u663e\u793a\u7248\u672c\u4fe1\u606f\u3002 -w \u6216 --word-regexp : \u53ea\u663e\u793a\u5168\u5b57\u7b26\u5408\u7684\u5217\u3002 -x --line-regexp : \u53ea\u663e\u793a\u5168\u5217\u7b26\u5408\u7684\u5217\u3002 -y : \u6b64\u53c2\u6570\u7684\u6548\u679c\u548c\u6307\u5b9a\"-i\"\u53c2\u6570\u76f8\u540c\u3002 \u5728\u5f53\u524d\u76ee\u5f55\u4e2d\uff0c\u67e5\u627e\u540e\u7f00\u6709conf\u5b57\u6837\u7684\u6587\u4ef6\u4e2d\u5305\u542bxen\u5b57\u7b26\u4e32\u7684\u6587\u4ef6\uff0c\u5e76\u6253\u5370\u51fa\u8be5\u5b57\u7b26\u4e32\u7684\u884c\u3002 pmgr@dcmaster:/data/program/general> grep xen *.conf xen xening \u67e5\u627e\u524d\u7f00\u6709gen\u7684\u6587\u4ef6\u5305\u542bxen\u5b57\u7b26\u4e32\u7684\u6587\u4ef6 pmgr@dcmaster:/data/program/general> grep xen gen* xen xening \u4ee5\u9012\u5f52\u7684\u65b9\u5f0f\u67e5\u627e\u7b26\u5408\u6761\u4ef6\u7684\u6587\u4ef6\u3002\u67e5\u627e\u6307\u5b9a\u76ee\u5f55/data/program/\u53ca\u5176\u5b50\u76ee\u5f55\uff08\u5982\u679c\u5b58\u5728\u5b50\u76ee\u5f55\u7684\u8bdd\uff09\u4e0b\u6240\u6709\u6587\u4ef6\u4e2d\u5305\u542b\u5b57\u7b26\u4e32xen\u7684\u6587\u4ef6\uff0c\u5e76\u6253\u5370\u51fa\u8be5\u5b57\u7b26\u4e32\u6240\u5728\u884c\u7684\u5185\u5bb9 pmgr@dcmaster:/data> grep -r xen /data/program/ ./program/general/general.conf:xen ./program/general/general.conf:xening \u53cd\u5411\u67e5\u627e\u3002\u524d\u9762\u5404\u4e2a\u4f8b\u5b50\u662f\u67e5\u627e\u5e76\u6253\u5370\u51fa\u7b26\u5408\u6761\u4ef6\u7684\u884c\uff0c\u901a\u8fc7 -v \u53c2\u6570\u53ef\u4ee5\u6253\u5370\u51fa\u4e0d\u7b26\u5408\u6761\u4ef6\u884c\u7684\u5185\u5bb9\u3002\u67e5\u627e\u6587\u4ef6\u540d\u4e2d\u5305\u542bxen\u7684\u6587\u4ef6\u4e2d\u4e0d\u5305\u542bxen\u7684\u884c pmgr@dcmaster:/data/program/general> grep -v xen gen* Linux Test test \u67e5\u627e\u5f53\u524d\u76ee\u5f55\u4e0b\u5305\u542b\u5b57\u7b26\u4e32\u201cLinux\u201d\u7684\u6587\u4ef6 pmgr@dcmaster:/data/program/general> grep Linux * general.conf:Linux grep: staffing: Is a directory pmgr@dcmaster:/data/program/general> egrep Linux * general.conf:Linux grep: staffing: Is a directory","title":"Useful Commands"},{"location":"linux/Administration/02/#useful-commands","text":"","title":"Useful Commands"},{"location":"linux/Administration/02/#some-common-abbreviations","text":"Abbreviations Description . represents the current directory .. represents the parent directory ~ represents the home directory ~username represents the home directory of user username","title":"Some common abbreviations"},{"location":"linux/Administration/02/#software-package-documentation","text":"/usr/share/doc/packages/","title":"Software package documentation"},{"location":"linux/Administration/02/#release-notes","text":"/usr/share/doc/release-notes/","title":"Release Notes"},{"location":"linux/Administration/02/#command-help","text":"<command> -h or <command> --help # tree --help","title":"Command help"},{"location":"linux/Administration/02/#manual-pages","text":"man [section] command # man 5 crontab # man /sestion options Show tree command manual: # man tree List for keywords: # man -k keyword Force mandb to update. Normally this is done daily via a cron job. # mandb Search for all instances of a command or a file named crontab # man -f crontab # whatis crontab (same output with above command) # man -k crontab # apropos crontab (same output with above command) To go directly to a given man page: # man 5 crontab 1G : go to the 1st line 10G : go to the 10th line G : go to the end of the page /^SELinux : search the word SELinux /section OPTIONS : go to the section OPTIONS man\u5171\u6709\u4ee5\u4e0b\u51e0\u4e2a\u7ae0\u8282\uff0c\u6bd4\u5982\uff0cman 5 crontab\u5c31\u662f\u8fdb\u5165crontab\u7684\u7b2c5\u7ae0\u8282\uff1a Executable programs or shell commands \uff08\u6807\u51c6\u547d\u4ee4\uff09 System calls (functions provided by the kernel)\uff08\u7cfb\u7edf\u8c03\u7528\uff09 Library calls (functions within program libraries)\uff08\u5e93\u51fd\u6570\uff09 Special files (usually found in /dev)\uff08\u8bbe\u5907\u8bf4\u660e\uff09 File formats and conventions eg /etc/passwd \uff08\u6587\u4ef6\u683c\u5f0f\uff09 Games \uff08\u6e38\u620f\u548c\u5a31\u4e50\uff09 Miscellaneous (including macro packages and conventions)\uff08\u6742\u9879\uff0c\u60ef\u4f8b\u4e0e\u534f\u5b9a\u7b49\u7f51\u7edc\u534f\u5b9a\u3001ASCII code\u7b49\u7b49\u7684\u8aaa\u660e\uff09 System administration commands (usually only for root) \uff08\u7ba1\u7406\u5458\u547d\u4ee4\uff09 Kernel routines [Non standard] \uff08\u5176\u4ed6Linux\u7279\u5b9a\u7684\uff0c\u7528\u6765\u5b58\u653e\u5185\u6838\u4f8b\u884c\u7a0b\u5e8f\u7684\u6587\u6863\u3002\uff09 man\u5e38\u7528\u5feb\u6377\u952e \u7ffb\u5c4f \u5411\u540e\u7ffb\u4e00\u5c4f\uff1aspace(\u7a7a\u683c\u952e) \u5411\u524d\u7ffb\u4e00\u5c4f\uff1ab \u5411\u540e\u7ffb\u4e00\u884c\uff1aEnter(\u56de\u8f66\u952e) \u5411\u524d\u7ffb\u4e00\u884c\uff1ak \u67e5\u627e /\u5173\u952e\u8bcd ?\u5173\u952e\u8bcd n (\u4e0b\u4e00\u4e2a) N (\u524d\u4e00\u4e2a) man \u4e2d\u6587\u5316\u3002\u5728 /etc/profile \u52a0\u5165\u4e0b\u9762alias\uff0c\u53ef\u4ee5\u5728man\u4e2d\u8f93\u51fa\u4e2d\u6587 # For man in zh_CH alias cman='man -M /usr/share/man/zh_CN'","title":"Manual pages"},{"location":"linux/Administration/02/#display-descriptions","text":"whatis command","title":"Display descriptions:"},{"location":"linux/Administration/02/#info-pages","text":"info command # info # info top From the terminal window display the info pages for the info command by entering: # info info Move the cursor to the line referring to (Invoking Info) by pressing Tab Tab Follow the link by pressing Enter Move the cursor to the link Note Custom Key Bindings: by pressing Tab (6 times) Follow the link by pressing Enter Return to the page Note Custom Key Bindings: by typing (lowercase L): l Exit the info file by typing: q","title":"Info pages:"},{"location":"linux/Administration/02/#pwd-command","text":"Display the current working directory","title":"pwd command"},{"location":"linux/Administration/02/#cd-command","text":"Change directory","title":"cd command"},{"location":"linux/Administration/02/#ls-command","text":"Display directory contents * Display hidden files with -a option * Detailed listing with -l option * Output is recursive, including all subdirectories with -R option * With option -F After each name, a character indicates the file type (\u201c/\u201d for directories, \u201c*\u201d for executable files, \u201c|\u201d for FIFO files, \u201c@\u201d symbolic link).","title":"ls command"},{"location":"linux/Administration/02/#cp-command","text":"Copy a file or directory Syntax: cp [option] <source> <destination> Option -a : Copies a directory and subdirectories (compare -R ); symbolic links, file permissions, owners, and time stamps are not changed. \u5b83\u4fdd\u7559\u7b26\u53f7\u94fe\u63a5\u3001\u6587\u4ef6\u5c5e\u6027\uff0c\u5e76\u590d\u5236\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u5185\u5bb9\u3002\u5176\u4f5c\u7528\u7b49\u4e8e-dpR\u53c2\u6570\u7ec4\u5408\u3002 Option -I : Asks before overwriting. Option -R , -r : Copies directories recursively (the directory and any subdirectories). \u9012\u5f52\u62f7\u8d1d\uff0c\u5305\u542b\u5b50\u76ee\u5f55\u53ca\uff08\u9690\u542b\uff09\u6587\u4ef6\uff0c\u7ee7\u627f\u76ee\u6807\u76ee\u5f55\u7684\u6743\u9650\u548c\u5c5e\u6027\u7b49 Option -l : Makes hardlinks instead of copying (\u521b\u5efa\u786c\u94fe\u63a5\u7684\u53e6\u5916\u4e00\u4e2a\u65b9\u6cd5) Option -s : Makes symbolic instead of copying (\u521b\u5efa\u7b26\u53f7\u94fe\u63a5\u7684\u53e6\u5916\u4e00\u4e2a\u65b9\u6cd5) Option -u : Copies a file only when the source file is newer than the destination file or when the destination file is missing. Option -p : \u8fde\u540c\u6863\u6848\u7684\u5c5e\u6027\u4e00\u8d77\u590d\u5236\u8fc7\u53bb\uff0c\u5305\u62ec\u4fee\u6539\u65f6\u95f4\u3001\u8bbf\u95ee\u6743\u9650\u3001\u6240\u6709\u8005\u7ec4\u7b49\uff0c\u800c\u975e\u4f7f\u7528\u9884\u8bbe\u5c5e\u6027\uff1b Labs: Initiate directories and files mySUSE:~ # su - pmgr pmgr@mySUSE:~> mkdir /data/program pmgr@mySUSE:~> mkdir /data/program/general pmgr@mySUSE:~> mkdir /data/program/general/staffing pmgr@mySUSE:~> touch /data/program/general/program_scope pmgr@mySUSE:~> touch /data/program/general/staffing/assignment mySUSE:~ # su - pm1 pm1@mySUSE:~> mkdir /data/project1 pm1@mySUSE:~> mkdir /data/project1/iot pm1@mySUSE:~> mkdir /data/project1/iot/bigdata pm1@mySUSE:~> touch /data/project1/iot/devicelist pm1@mySUSE:~> touch /data/project1/iot/bigdata/math_lib mySUSE:~ # su - pm2 pm2@mySUSE:~> mkdir /data/project2 pm2@mySUSE:~> mkdir /data/project2/erp pm2@mySUSE:~> mkdir /data/project2/erp/fin pm2@mySUSE:~> touch /data/project2/erp/erp_vision pm2@mySUSE:~> touch /data/project2/erp/fin/fin_ar pm2@mySUSE:~> chmod g+w /data/project2/erp/erp_vision pmgr@mySUSE:~> ln /data/project2/erp/erp_vision /data/program/general/p2_erp_version (\u521b\u5efa\u786c\u94fe\u63a5\uff0c\u5f53\u524d\u7528\u6237\u9700\u8981\u5bf9\u6e90\u6587\u4ef6erp_vision\u6709w\u6743\u9650) pmgr@mySUSE:~> ln -s /data/project1/iot/devicelist /data/program/general/p1_devicelist (\u521b\u5efa\u7b26\u53f7\u94fe\u63a5\uff0c\u4e0d\u9a8c\u8bc1\u5f53\u524d\u7528\u6237\u662f\u5426\u5bf9\u6e90\u6587\u4ef6devicelist\u6709\u6743\u9650) mySUSE:~ # tree /data /data \u251c\u2500\u2500 program \u2502 \u2514\u2500\u2500 general \u2502 \u251c\u2500\u2500 p1_devicelist -> /data/project1/iot/devicelist \u2502 \u251c\u2500\u2500 p2_erp_version \u2502 \u251c\u2500\u2500 program_scope \u2502 \u2514\u2500\u2500 staffing \u2502 \u2514\u2500\u2500 assignment \u251c\u2500\u2500 project1 \u2502 \u2514\u2500\u2500 iot \u2502 \u251c\u2500\u2500 bigdata \u2502 \u2502 \u2514\u2500\u2500 math_lib \u2502 \u2514\u2500\u2500 devicelist \u2514\u2500\u2500 project2 \u2514\u2500\u2500 erp \u251c\u2500\u2500 erp_vision \u2514\u2500\u2500 fin \u2514\u2500\u2500 fin_ar pmgr@mySUSE:~> cp -R /data/project1 /data/program/ (/data/program/project1\u7684\u7528\u6237\u548c\u7ec4\u90fd\u7ee7\u627f\u4e86/data/program/) pmgr@mySUSE:~> cp -a /data/project2 /data/program/ (/data/program/project2\u7684\u7528\u6237\u7ee7\u627f\u4e86/data/program/\uff0c\u4f46\u7ec4\u8fd8\u662f\u4fdd\u7559\u539f\u6765\u7684)","title":"cp command"},{"location":"linux/Administration/02/#mv-command","text":"Move or rename a file or directory Option -i : Asks for confirmation before moving or renaming a file. This prevents existing files with the same name from being overwritten. Option -u : Only moves files that are newer than the target files of the same name. pmgr@mySUSE:/data/program/general> cp program_scope ./staffing/ pmgr@mySUSE:/data/program/general> mv -i program_scope ./staffing/ mv: overwrite './staffing/program_scope'? n","title":"mv command"},{"location":"linux/Administration/02/#rm-command","text":"Delete a file or directory Option -i : Asks for confirmation before deleting. Option -r : (recursively) Allows full directories to be deleted. Option -f : (force) By default, rm asks for confirmation if the file that should be deleted is read-only. Using this option, the files are deleted without asking for confirmation.","title":"rm command"},{"location":"linux/Administration/02/#mkdir-command","text":"Create a new directory Option -p lets you create a complete path (\u5c42\u7ea7\u8def\u5f84\u4e00\u6b21\u521b\u5efa) pmgr@mySUSE:/data> mkdir -p industry/utilities pmgr@mySUSE:/data> tree ./industry/ ./industry/ \u2514\u2500\u2500 utilities","title":"mkdir command"},{"location":"linux/Administration/02/#rmdir-command","text":"Remove an empty directory. The directory or directories must be empty before you can delete them.","title":"rmdir command"},{"location":"linux/Administration/02/#ln-command","text":"Create a link Default: Hard link Symbolic link with -s option Syntax: ln [-s] <original> <link>","title":"ln command"},{"location":"linux/Administration/02/#touch-command","text":"Change the access and modification times Create an empty file if the given file does not exist. Change the time stamp of a file. Option -a : Changes only the time of the last read access (access time). Option -m : Changes only the time of the last modification (modification time). Option -r file : Sets the time stamp of file instead of the current time. Option -t time : Instead of the current time, sets time (structure: [[CC]YY]MMDDhhmm.[ss] ([Century]Year] Month Day Hour Minute [Seconds], two digits in each)) pmgr@mySUSE:/data/industry> touch readme pmgr@mySUSE:/data/industry> touch -a readme pmgr@mySUSE:/data/industry> touch -m readme pmgr@mySUSE:/data/industry> stat readme File: readme Size: 0 Blocks: 0 IO Block: 4096 regular empty file Device: 3dh/61d Inode: 338 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1003/ pmgr) Gid: ( 1000/ admins) Access: 2019-03-31 10:07:47.489055973 +0800 Modify: 2019-03-31 10:07:58.805109884 +0800 Change: 2019-03-31 10:07:58.805109884 +0800 Birth: -","title":"touch command"},{"location":"linux/Administration/02/#cat-command","text":"Concatenates files","title":"cat command"},{"location":"linux/Administration/02/#tac-command","text":"Same as cat, but displays the file(s) in reverse pmgr@mySUSE:/data/industry> cat readme line 1 line 2 line 3 pmgr@mySUSE:/data/industry> tac readme line 3 line 2 line 1","title":"tac command"},{"location":"linux/Administration/02/#more-command","text":"Display file contents one page at a time","title":"more command"},{"location":"linux/Administration/02/#less-command","text":"Displays file contents for better navigation","title":"less command"},{"location":"linux/Administration/02/#head-command","text":"Displays the first 10 lines of a file. To set the number of lines use the -n option pmgr@mySUSE:/data/industry> head readme line 1 line 2 line 3 line 4 line 5 line 6 line 7 line 8 line 9 line 10 pmgr@mySUSE:/data/industry> head -n 5 readme line 1 line 2 line 3 line 4 line 5","title":"head command"},{"location":"linux/Administration/02/#tail-command","text":"Display the last lines of a file To set the number of lines use the -n option To output appended data use -f option, displays a continuously updated view of the last lines of a file. To exit tail -f, press Ctrl+C. pmgr@mySUSE:/data/industry> tail -n 6 readme line 10 line 11 line 12 line 13 line 14 line 15","title":"tail command"},{"location":"linux/Administration/02/#tar-command","text":"Create, expand or list archive files Use option c to create an archive Use option f to specify the archive file name Use option v for verbose mode Use option x to extract an archive Use option t to list the content of an archive Use option z to (un-)compress the archive with gzip Use option j to (un-)compress the archive with bzip The /etc directory (include sub-directories) is backed up to the /backup/etc.tar file pmgr@mySUSE:~> tar -cvf /data/backup/project1.tar /data/project1/ pmgr@mySUSE:~> tar -cvf /data/backup/project2.tar /data/project2/ pmgr@mySUSE:~> tar -cv --exclude='*.conf' -f /data/backup/project2a.tar /data/project2/ View the contents of an archive. Some .conf files are excluded in project2a.tar file. pmgr@mySUSE:~> tar -tvf /data/backup/project2.tar drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/ -rw-r--r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/fin/fin_ar -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/fin.conf -rw-rw-r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/erp_vision -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/erp/erp.conf -rw-r--r-- pm2/project2 0 2019-03-31 16:47 data/project2/project2.conf pmgr@mySUSE:~> tar -tvf /data/backup/project2a.tar drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/ drwxr-xr-x pm2/project2 0 2019-03-31 16:47 data/project2/erp/fin/ -rw-r--r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/fin/fin_ar -rw-rw-r-- pm2/project2 0 2019-03-29 16:06 data/project2/erp/erp_vision Unpack and write all files in the archive to the current directory. Extract to another directory by using the -C option pmgr@mySUSE:~> mkdir project1.backup pmgr@mySUSE:~> tar -xvf /data/backup/project1.tar -C /data/backup/project1.backup/ Incremental backup with tar command pmgr@mySUSE:~> tar -g snapshot_program -cvf /data/backup/bkp_program_full.tar /data/program/ pmgr@mySUSE:~> tar -tvf /data/backup/bkp_program_full.tar pmgr@mySUSE:~> touch /data/program/general/general.conf pmgr@mySUSE:~> tar -g snapshot_program -cvf /data/backup/bkp_program_inc.tar /data/program/ pmgr@mySUSE:~> rm -rf program/ pmgr@mySUSE:~> tar -xvf /data/backup/bkp_program_inc.tar -C /data/","title":"tar command"},{"location":"linux/Administration/02/#cpio-command","text":"Another archiving command","title":"cpio command"},{"location":"linux/Administration/02/#gzip-command","text":"Compress files using the gzip algorithm Option -c : Compresses the file without modifying the original file. The result is written to the standard output (usually the screen). From there, it can be redirected to a file with \u201c>\u201d. Option -d : Decompresses the specified file (gunzip) Option -r : Compresses and decompresses files in all subdirectories. Option -1 to -9, --fast, --best : Controls the compression speed: -1 means --fast and causes a quick compression but produces larger files, -9 corresponds to --best and requires more computing time but produces smaller files. The default setting is -6.","title":"gzip command"},{"location":"linux/Administration/02/#gunzip-command","text":"Expand files compressed with gzip","title":"gunzip command"},{"location":"linux/Administration/02/#bzip2-command","text":"Compress files using the bzip2 algorithm Option -c : Option -d : Decompresses the specified file (bunzip2). Option -1 to -9 : Controls the compression speed: -1 causes a quick compression but produces larger files, -9 requires more computing time but produces smaller files. The default setting is -9 .","title":"bzip2 command"},{"location":"linux/Administration/02/#bunzip2-command","text":"Expand files compressed with bzip","title":"bunzip2 command"},{"location":"linux/Administration/02/#rsync-command","text":"Copy only deltas between two directories. A key benefit of using rsync is that when copying data, rsync compares the source and the target directory and transfers only data that has changed or has been created. \u4ec5\u590d\u5236\u4e24\u4e2a\u76ee\u5f55\u4e4b\u95f4\u7684\u589e\u91cf\u3002 \u4f7f\u7528rsync\u7684\u4e00\u4e2a\u4e3b\u8981\u597d\u5904\u662f\uff0c\u5728\u590d\u5236\u6570\u636e\u65f6\uff0crsync\u4f1a\u6bd4\u8f83\u6e90\u76ee\u5f55\u548c\u76ee\u6807\u76ee\u5f55\uff0c\u5e76\u4ec5\u4f20\u8f93\u5df2\u66f4\u6539\u6216\u5df2\u521b\u5efa\u7684\u6570\u636e\u3002 Local or via network \u672c\u5730\u6216\u901a\u8fc7\u7f51\u7edc Uses ssh as default transport \u4f7f\u7528ssh\u4f5c\u4e3a\u9ed8\u8ba4\u4f20\u8f93 Can talk to rsync daemon on the remote machine \u53ef\u4ee5\u4e0e\u8fdc\u7a0b\u8ba1\u7b97\u673a\u4e0a\u7684rsync\u5b88\u62a4\u7a0b\u5e8f\u901a\u4fe1 Note: rsync must be installed on both the source and the target computer for this to work. \u5fc5\u987b\u5728\u6e90\u8ba1\u7b97\u673a\u548c\u76ee\u6807\u8ba1\u7b97\u673a\u4e0a\u5b89\u88c5rsync\u624d\u80fd\u4f7f\u5176\u6b63\u5e38\u5de5\u4f5c\u3002 As the default shell used by rsync is ssh, the -e option only needs to be used when you want to use something else than ssh. \u7531\u4e8ersync\u4f7f\u7528\u7684\u9ed8\u8ba4shell\u662fssh\uff0c\u56e0\u6b64\u53ea\u6709\u5728\u60f3\u8981\u4f7f\u7528\u9664ssh\u4ee5\u5916\u7684\u5176\u4ed6\u5de5\u5177\u65f6\u624d\u9700\u8981\u4f7f\u7528-e\u9009\u9879\u3002 Options Option -a : Puts rsync into the archive mode. The -a option ensures the following are preserved \u4fdd\u7559 in the mirrored copy of the directory: Symbolic links (l option) Access permissions (p option) Owners (o option) Group membership (g option) Time stamp (t option) Option -x : Saves files on one file system only, which means that rsync does not follow symbolic links to other file systems. \u4e0d\u8de8\u6587\u4ef6\u7cfb\u7edf\uff0c\u53ea\u5728\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u5185(don't cross filesyste* undaries) Option -v : Enables the verbose mode. Use this mode to output information about the transferred files and the progress of the copying process. \u8f93\u51fa\u4f20\u8f93\u8fc7\u7a0b\u7684\u7ec6\u8282\u4fe1\u606f Option -z : Compresses the data during the transfer. This is especially useful for remote synchronization. \u538b\u7f29\u65b9\u5f0f\u4f20\u8f93 Option --delete : Deletes files from the mirrored directory that no longer exist in the original directory. Option --exclude-from : Does not back up files listed in an exclude file. Local backup via rsync command pmgr@mySUSE:/data> rsync -av /data/industry/* /data/backup/industry/ sending incremental file list created directory /data/backup/industry readme utilities/ sent 264 bytes received 87 bytes 702.00 bytes/sec total size is 111 speedup is 0.32 pmgr@mySUSE:/data/industry/utilities> touch roadmap.txt pmgr@mySUSE:/data> rsync -av /data/industry/* /data/backup/industry/ sending incremental file list utilities/ utilities/roadmap.txt sent 171 bytes received 39 bytes 420.00 bytes/sec total size is 111 speedup is 0.53 pmgr@mySUSE:/data> rm roadmap.txt pmgr@mySUSE:/data> rsync -av /data/industry/* --delete /data/backup/industry/ sending incremental file list deleting utilities/roadmap.txt utilities/ sent 102 bytes received 41 bytes 286.00 bytes/sec total size is 111 speedup is 0.78","title":"rsync command"},{"location":"linux/Administration/02/#dd-command","text":"Copies files block by block Used to create disk or partition images Most important options: if =input_file `of``=output_file bs =block_size You can use the dd command to convert and copy files byte-wise. Normally dd reads from the standard input and writes the result to the standard output. But with the appropriate parameters, regular files can be addressed as well. You can copy all kinds of Linux data with this command, including entire hard disk partitions. You can even copy an entire installed system (or just parts of it). Copy file /etc/protocols to protocols.old. The default size for a record is 512 bytes. Below 45+1 means, 45 complete record of standard size and 1 incomplete record (less than 512 bytes pmgr@mySUSE:/data/program> dd if=/etc/protocols of=protocols.old bs=512 45+1 records in 45+1 records out 23259 bytes (23 kB, 23 KiB) copied, 0.000595392 s, 39.1 MB/s \u521b\u5efa\u4e00\u4e2a100M\u7684\u7a7a\u6587\u4ef6 pmgr@mySUSE:/data/program> dd if=/dev/zero of=datafile bs=100M count=2 2+0 records in 2+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 2.79311 s, 75.1 MB/s \u5907\u4efd\u6574\u4e2a\u5206\u533a #dd if=/dev/sda1 of=boot.partition \u5236\u4f5cU\u76d8\u542f\u52a8\u76d8\uff08U\u76d8\u6302\u8f7d\u5230/dev/sdb\uff09 #dd if=/root/diskboot.img of=/dev/sdb bs=125682176 \u5907\u4efd\u786c\u76d8\u4e3b\u5f15\u5bfc\u8bb0\u5f55 #dd if=/dev/sda of=/tmp/mbr_copy bs=512 count=1 \u8fd8\u539f\u786c\u76d8\u4e3b\u5f15\u5bfc\u8bb0\u5f55 #dd if=/disk.mbr of=/dev/hda bs=512 count=1 \u5c06\u5185\u5b58\u91cc\u7684\u6570\u636e\u62f7\u8d1d\u5230root\u76ee\u5f55\u4e0b\u7684mem.bin\u6587\u4ef6 # dd if=/dev/mem of=/root/mem.bin bs=1024 \u62f7\u8d1d\u5149\u76d8\u6570\u636e\u5230root\u6587\u4ef6\u5939\u4e0b\uff0c\u5e76\u4fdd\u5b58\u4e3acd.iso\u6587\u4ef6 # dd if=/dev/cdrom of=/root/cd.iso \u5229\u7528\u968f\u673a\u7684\u6570\u636e\u586b\u5145\u786c\u76d8(\u9500\u6bc1\u786c\u76d8\u6570\u636e) # dd if=/dev/urandom of=/dev/hda1 \u6d4b\u8bd5\u786c\u76d8\u8bfb\u5199\u901f\u5ea6\u3002\u901a\u8fc7\u4e24\u4e2a\u547d\u4ee4\u8f93\u51fa\u7684\u6267\u884c\u65f6\u95f4\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6d4b\u8bd5\u786c\u76d8\u7684\u8bfb\uff0f\u5199\u901f\u5ea6\uff1a mySUSE:/data # dd if=/data/program/datafile bs=64k | dd of=/dev/null 3200+0 records in 3200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 0.67138 s, 312 MB/s 409600+0 records in 409600+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 0.675912 s, 310 MB/s # dd if=/dev/zero of=/data/program/datafile bs=1024 count=100 \u5207\u5272\u5927\u6587\u4ef6bigfile\uff0c\u517198336321\u5b57\u8282\uff0c\u5219\uff1a # dd if=bigfile of=smallfile1 bs=1 count=20000000 # dd if=bigfile of=smallfile2 bs=1 count=20000000 skip=20000000 # dd if=bigfile of=smallfile3 bs=1 count=20000000 skip=40000000 # dd if=bigfile of=smallfile4 bs=1 count=20000000 skip=60000000 # dd if=bigfile of=smallfile5 bs=1 count=18336321 skip=80000000 \u5c06\u5207\u5272\u6587\u4ef6\u7ec4\u88c5 # dd if=smallfile1 of=bigfile bs=1 count=20000000 # dd if=smallfile2 of=bigfile bs=1 count=20000000 seek=20000000 # dd if=smallfile3 of=bigfile bs=1 count=20000000 seek=40000000 # dd if=smallfile4 of=bigfile bs=1 count=20000000 seek=60000000 # dd if=smallfile5 of=bigfile bs=1 count=18336321 seek=80000000 if: \u8981\u5207\u5272\u7684\u5927\u6587\u4ef6\u540d of: \u5207\u5272\u540e\u7684\u5b50\u6587\u4ef6\u540d bs: \u4ee5\u591a\u5c11\u5b57\u8282\u4f5c\u4e3a\u4e00\u4e2a\u5207\u5272\u8bb0\u5f55\u5355\u4f4d count: \u662f\u8981\u5207\u5272\u7684\u5355\u4f4d\u8bb0\u5f55\u6570 skip: \u8bf4\u660e\u5207\u5272\u65f6\u7684\u8d77\u70b9 seek: \u660e\u786e\u6307\u51fa\u5f00\u59cb\u4f4d\u7f6e","title":"dd command"},{"location":"linux/Administration/02/#find-command","text":"Search for files or directories Syntax: find path criterion [action] The find command has a multitude of options, a few of which are explained here. You can use the following arguments with the command: path: The section of the file system to search (the specified directory and all its subdirectories). If nothing is specified, the file system below the current directory is used. criterion: The properties the file should have (see below) action: Options that influence the following conditions or control the search as a whole The most important actions are: -print (default) -exec command With the -exec option, you can call up another command. This option is frequently used to link find and grep, as in the following: \u627e\u51fagen\u5f00\u5934\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -name gen\\* ./program/general ./program/general/general.conf \u627e\u51fagen\u5f00\u5934\u7684\u6587\u4ef6\uff0c\u5e76\u5728\u6587\u4ef6\u5185\u5bb9\u4e2d\u67e5\u627exen\uff0c\u627e\u5230\u540e\u7ed3\u679c\u8f93\u51faxen pmgr@dcmaster:/data> find . -name gen\\* -type f -exec grep xen {} \\; xen xening The two brackets \u201c{}\u201d stand as placeholders for the file names which are found and passed to the grep command. The semicolon closes the -exec instruction. Because this is a special character, it is masked by placing a backslash in front of it. -ctime [+/-]days Searches for files whose last change took place no later than (no earlier than) a specified number of days ago. \u5728\u8fc7\u53bbn\u5929\u5185\u88ab\u4fee\u6539\u8fc7\u7684\u6587\u4ef6 mgr@dcmaster:/data> find . -ctime 1 . ./program/datafile -gid number Searches for files with the numeric GID (Group ID) number. (gid \u662f n) -group name Searches for files that are owned by the group name. Instead of a name, the numeric GID is allowed. (group \u540d\u79f0\u662f name) -name pattern Searches for files whose names contain the given pattern. If the pattern contains meta characters or wild cards, the name must be enclosed by quotation marks. Otherwise thename will be interpreted by the shell and not by find. -newer file Searches for files that were modified more recently than file. \u6bd4\u6587\u4ef6 file \u66f4\u65b0\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -cnewer ./program/datafile . -size [+/-]size Matches files that are above or below a certain size. The size (in blocks of 512 bytes) is given as an argument. The suffix \u201cc\u201cswitches to byte and \u201ck\u201d to blocks of 1024bytes. A preceding \u201c+\u201d stands for all larger files and a \u201c-\u201d for all smaller files. (\u6587\u4ef6\u5927\u5c0f \u662f n \u2022 b \u4ee3\u8868 512 \u4f4d\u5143\u7ec4\u7684\u533a\u5757 \u2022 c \u8868\u793a\u5b57\u5143\u6570 \u2022 k \u8868\u793a kilo bytes \u2022 w \u662f\u4e8c\u4e2a\u4f4d\u5143\u7ec4 pmgr@dcmaster:/data> find . -size 20k ./backup/project2.tar -type file_type Searches for a file type. A file type can be one of the following: * c : \u6587\u4ef6\u7c7b\u578b\u662f c \u7684\u6587\u4ef6\u3002 * d: \u76ee\u5f55 * c: \u5b57\u578b\u88c5\u7f6e\u6587\u4ef6 * b: \u533a\u5757\u88c5\u7f6e\u6587\u4ef6 * p: \u5177\u540d\u8d2e\u5217 * f: \u4e00\u822c\u6587\u4ef6 * l: \u7b26\u53f7\u8fde\u7ed3 * s: socket -uid number Searches for files with the numeric UID (User ID) number. -user name Searches for files, which are owned by user name. Instead of a name, the numeric UID is allowed. \u5e38\u7528\u53c2\u6570 mount, -xdev : \u53ea\u68c0\u67e5\u548c\u6307\u5b9a\u76ee\u5f55\u5728\u540c\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u4e0b\u7684\u6587\u4ef6\uff0c\u907f\u514d\u5217\u51fa\u5176\u5b83\u6587\u4ef6\u7cfb\u7edf\u4e2d\u7684\u6587\u4ef6 amin n : \u5728\u8fc7\u53bb n \u5206\u949f\u5185\u88ab\u8bfb\u53d6\u8fc7 anewer file : \u6bd4\u6587\u4ef6 file \u66f4\u665a\u88ab\u8bfb\u53d6\u8fc7\u7684\u6587\u4ef6 atime n : \u5728\u8fc7\u53bbn\u5929\u5185\u88ab\u8bfb\u53d6\u8fc7\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -atime 1 ./program/datafile cmin n : \u5728\u8fc7\u53bb n \u5206\u949f\u5185\u88ab\u4fee\u6539\u8fc7 pmgr@dcmaster:/data> find . -cmin 20 empty : \u7a7a\u7684\u6587\u4ef6 ipath p, -path p : \u8def\u5f84\u540d\u79f0\u7b26\u5408 p \u7684\u6587\u4ef6\uff0cipath \u4f1a\u5ffd\u7565\u5927\u5c0f\u5199 name name, -iname name : \u6587\u4ef6\u540d\u79f0\u7b26\u5408 name \u7684\u6587\u4ef6\u3002iname \u4f1a\u5ffd\u7565\u5927\u5c0f\u5199 pid n : process id \u662f n \u7684\u6587\u4ef6 \u67e5\u627e\u5f53\u524d\u76ee\u5f55\u53ca\u5b50\u76ee\u5f55\u4e2d\u6240\u6709\u6587\u4ef6\u957f\u5ea6\u4e3a0\u7684\u666e\u901a\u6587\u4ef6\uff0c\u5e76\u5217\u51fa\u5b83\u4eec\u7684\u5b8c\u6574\u8def\u5f84 pmgr@dcmaster:/data> find . -type f -size 0 -exec ls -l {} \\; \u67e5\u627e\u524d\u76ee\u5f55\u4e2d\u6587\u4ef6\u5c5e\u4e3b\u5177\u6709\u8bfb\u3001\u5199\u6743\u9650\uff0c\u5e76\u4e14\u6587\u4ef6\u6240\u5c5e\u7ec4\u7684\u7528\u6237\u548c\u5176\u4ed6\u7528\u6237\u5177\u6709\u8bfb\u6743\u9650\u7684\u6587\u4ef6 pmgr@dcmaster:/data> find . -type f -perm 644 -exec ls -l {} \\; \u67e5\u627e/var/log\u76ee\u5f55\u4e2d\u66f4\u6539\u65f6\u95f4\u572817\u65e5\u4ee5\u524d\u7684\u666e\u901a\u6587\u4ef6\uff0c\u5e76\u5728\u5220\u9664\u4e4b\u524d\u8be2\u95ee\u5b83\u4eec pmgr@dcmaster:/data> find /var/log -type f -mtime +17 -ok rm {} \\; \u5c06\u76ee\u524d\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e0b\u6240\u6709\u6700\u8fd1 1 \u5929\u5185\u66f4\u65b0\u8fc7\u7684\u6587\u4ef6\u5217\u51fa mgr@dcmaster:/data> find . -ctime 1 \u5c06\u76ee\u524d\u76ee\u5f55\u5176\u5176\u4e0b\u5b50\u76ee\u5f55\u4e2d\u6240\u6709\u4e00\u822c\u6587\u4ef6\u5217\u51fa pmgr@dcmaster:/data> find . -type f \u5c06\u76ee\u524d\u76ee\u5f55\u53ca\u5176\u5b50\u76ee\u5f55\u4e0b\u6240\u6709\u5ef6\u4f38\u6863\u540d\u662fconf \u7684\u6587\u4ef6\u5217\u51fa\u6765 pmgr@dcmaster:/data> find . -name \"*.conf\"","title":"find command"},{"location":"linux/Administration/02/#which-command","text":"Searches all paths listed in the variable $PATH and returns the full path of the command The which command searches all paths listed in the variable $PATH for the specified command and returns the full path of the command. In the variable $PATH, the most important directoriesare listed where the shell looks for executable files. which\u547d\u4ee4\u641c\u7d22\u53d8\u91cf$PATH\u4e2d\u5217\u51fa\u7684\u6240\u6709\u8def\u5f84\u4ee5\u83b7\u53d6\u6307\u5b9a\u547d\u4ee4\uff0c\u5e76\u8fd4\u56de\u547d\u4ee4\u7684\u5b8c\u6574\u8def\u5f84\u3002 The which command is especially useful if several versions of a command exist in different directories and you want to know which version is executed when entered without specifying apath. \u5982\u679c\u547d\u4ee4\u7684\u591a\u4e2a\u7248\u672c\u5b58\u5728\u4e8e\u4e0d\u540c\u7684\u76ee\u5f55\u4e2d\uff0c\u5e76\u4e14\u60a8\u60f3\u77e5\u9053\u5728\u8f93\u5165\u65f6\u6267\u884c\u4e86\u54ea\u4e2a\u7248\u672c\u800c\u672a\u6307\u5b9a\u8def\u5f84\uff0c\u90a3\u4e48which\u547d\u4ee4\u7279\u522b\u6709\u7528\u3002 NOTE: To see the content of a variable, use the echo command Options Description -n<\u6587\u4ef6\u540d\u957f\u5ea6> \u6307\u5b9a\u6587\u4ef6\u540d\u957f\u5ea6\uff0c\u6307\u5b9a\u7684\u957f\u5ea6\u5fc5\u987b\u5927\u4e8e\u6216\u7b49\u4e8e\u6240\u6709\u6587\u4ef6\u4e2d\u6700\u957f\u7684\u6587\u4ef6\u540d\u3002 -p<\u6587\u4ef6\u540d\u957f\u5ea6> \u4e0e-n\u53c2\u6570\u76f8\u540c\uff0c\u4f46\u6b64\u5904\u7684<\u6587\u4ef6\u540d\u957f\u5ea6>\u5305\u62ec\u4e86\u6587\u4ef6\u7684\u8def\u5f84\u3002 -w \u6307\u5b9a\u8f93\u51fa\u65f6\u680f\u4f4d\u7684\u5bbd\u5ea6\u3002 -V \u663e\u793a\u7248\u672c\u4fe1\u606f # which grep /usr/bin/grep # which -V grep GNU which v2.21, Copyright (C) 1999 - 2015 Carlo Wood. GNU which comes with ABSOLUTELY NO WARRANTY; This program is free software; your freedom to use, change and distribute this program is protected by the GPL.","title":"which command"},{"location":"linux/Administration/02/#whereis-command","text":"The whereis command returns the binaries (option -b), manual pages (option -m), and the source code (option -s) of the specified command. If no option is used, all this information is returned, provided the information is available. This command is faster than find, but it is less thorough. Attempts to locate the desired program in the standard Linux places, and in the places specified by $PATH and $MANPATH . \u5c1d\u8bd5\u5728\u6807\u51c6Linux\u4f4d\u7f6e\u548c\u6307\u5b9a\u4f4d\u7f6e($PATH\u548c$MANPATH)\u627e\u5230\u6240\u9700\u7684\u7a0b\u5e8f Options Description -b \u53ea\u67e5\u627e\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002 -B<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002 -f \u4e0d\u663e\u793a\u6587\u4ef6\u540d\u524d\u7684\u8def\u5f84\u540d\u79f0\u3002 -m \u53ea\u67e5\u627e\u8bf4\u660e\u6587\u4ef6\u3002 -M<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u8bf4\u660e\u6587\u4ef6\u3002 -s \u53ea\u67e5\u627e\u539f\u59cb\u4ee3\u7801\u6587\u4ef6\u3002 -S<\u76ee\u5f55> \u53ea\u5728\u8bbe\u7f6e\u7684\u76ee\u5f55\u4e0b\u67e5\u627e\u539f\u59cb\u4ee3\u7801\u6587\u4ef6\u3002 -u \u67e5\u627e\u4e0d\u5305\u542b\u6307\u5b9a\u7c7b\u578b\u7684\u6587\u4ef6\u3002 \u4ee5\u4e0b\u8f93\u51fa\u4fe1\u606f\u4ece\u5de6\u81f3\u53f3\u5206\u522b\u4e3a\u67e5\u8be2\u7684\u7a0b\u5e8f\u540d\u3001bash\u8def\u5f84\u3001bash\u7684man\u624b\u518c\u9875\u8def\u5f84\u3002 # whereis grep grep: /usr/bin/grep /bin/grep /usr/share/man/man1/grep.1.gz /usr/share/info/grep.info.gz \u663e\u793abash \u547d\u4ee4\u7684\u4e8c\u8fdb\u5236\u7a0b\u5e8f # whereis -b grep grep: /usr/bin/grep /bin/grep \u663e\u793abash \u547d\u4ee4\u7684\u5e2e\u52a9\u6587\u4ef6 # whereis -m grep grep: /usr/share/man/man1/grep.1.gz /usr/share/info/grep.info.gz","title":"whereis command"},{"location":"linux/Administration/02/#type-command","text":"The type command shows what kind of command is executed when you enter it: \u547d\u4ee4\u7684\u7c7b\u578b a shell built-in command (an essential command that is hard coded in the shell), for example type or cd an external command (called by the shell) an alias, for example ls. An alias defines shortcuts and synonyms for commonly used shell commands. a function The -a option delivers all instances of a command bearing this name in the file system. NOTE: If you want to have more information about a file format, you can use the file command. \u4e0d\u9002\u7528\u4e8e\u666e\u901a\u6587\u4ef6 dcmaster:/data/shell # type pwd.txt -bash: type: pwd.txt: not found \u4e0d\u9002\u7528\u4e8e\u81ea\u5b9a\u4e49\u53ef\u6267\u884c\u811a\u672c dcmaster:/data/shell # type math.sh -bash: type: math.sh: not found \u7cfb\u7edf\u547d\u4ee4 dcmaster:/data/shell # type rsync rsync is /usr/bin/rsync \u522b\u540d dcmaster:/data/shell # type l l is aliased to `ls -alF'","title":"type command"},{"location":"linux/Administration/02/#file-command","text":"file\u547d\u4ee4\u7528\u4e8e\u8fa8\u8bc6\u6587\u4ef6\u7c7b\u578b -b \u5217\u51fa\u8fa8\u8bc6\u7ed3\u679c\u65f6\uff0c\u4e0d\u663e\u793a\u6587\u4ef6\u540d\u79f0\u3002 -c \u8be6\u7ec6\u663e\u793a\u6307\u4ee4\u6267\u884c\u8fc7\u7a0b\uff0c\u4fbf\u4e8e\u6392\u9519\u6216\u5206\u6790\u7a0b\u5e8f\u6267\u884c\u7684\u60c5\u5f62\u3002 -f <\u540d\u79f0\u6587\u4ef6> \u6307\u5b9a\u540d\u79f0\u6587\u4ef6\uff0c\u5176\u5185\u5bb9\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u6587\u4ef6\u540d\u79f0\u65f6\uff0c\u8ba9file\u4f9d\u5e8f\u8fa8\u8bc6\u8fd9\u4e9b\u6587\u4ef6\uff0c\u683c\u5f0f\u4e3a\u6bcf\u5217\u4e00\u4e2a\u6587\u4ef6\u540d\u79f0\u3002 -L \u76f4\u63a5\u663e\u793a\u7b26\u53f7\u8fde\u63a5\u6240\u6307\u5411\u7684\u6587\u4ef6\u7684\u7c7b\u522b\u3002 -m<\u9b54\u6cd5\u6570\u5b57\u6587\u4ef6> \u6307\u5b9a\u9b54\u6cd5\u6570\u5b57\u6587\u4ef6\u3002 -v \u663e\u793a\u7248\u672c\u4fe1\u606f\u3002 -z \u5c1d\u8bd5\u53bb\u89e3\u8bfb\u538b\u7f29\u6587\u4ef6\u7684\u5185\u5bb9\u3002 dcmaster:/data/linktype # l -rw-r--r-- 3 root root 44 May 3 09:50 file -rw-r--r-- 3 root root 44 May 3 09:50 hardlinkfile1 -rw-r--r-- 3 root root 44 May 3 09:50 hardlinkfile2 lrwxrwxrwx 1 root root 4 Mar 28 15:21 symlinkfile1 -> file lrwxrwxrwx 1 root root 12 Mar 28 15:49 symlinkfile1-1 -> symlinkfile1 lrwxrwxrwx 1 root root 4 Mar 28 15:23 symlinkfile2 -> file dcmaster:/data/linktype # file hardlinkfile1 hardlinkfile1: ASCII text dcmaster:/data/linktype # file -i hardlinkfile1 hardlinkfile1: text/plain; charset=us-ascii dcmaster:/data/linktype # file /data/linktype/ /data/linktype/: directory dcmaster:/data/linktype # file -L /data/linktype/ /data/linktype/: directory dcmaster:/data/linktype # file -i /data/linktype/ /data/linktype/: inode/directory; charset=binary dcmaster:/data/linktype # file symlinkfile1 symlinkfile1: symbolic link to file dcmaster:/data/linktype # file -i symlinkfile1 symlinkfile1: inode/symlink; charset=binary","title":"file command"},{"location":"linux/Administration/02/#grep-command","text":"You can specify search patterns in the form of regular expressions, although the basic grep command is limited in this regard. To search for more complex patterns, use the egrep command (or grep -E ) instead, which accepts extended regular expressions. To avoid having special characters in search patterns interpreted by the shell, enclose the pattern in quotation marks. Syntax: grep [options] search_pattern filename * egrep = grep -E * rgrep \u53c2\u6570 -a \u6216 --text : \u4e0d\u8981\u5ffd\u7565\u4e8c\u8fdb\u5236\u7684\u6570\u636e\u3002 -A<\u663e\u793a\u884c\u6570> \u6216 --after-context=<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u8303\u672c\u6837\u5f0f\u7684\u90a3\u4e00\u5217\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u540e\u7684\u5185\u5bb9\u3002 -b \u6216 --byte-offset : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u6807\u793a\u51fa\u8be5\u884c\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u7f16\u53f7\u3002 -B<\u663e\u793a\u884c\u6570> \u6216 --before-context=<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u524d\u7684\u5185\u5bb9\u3002 -c \u6216 --count : \u8ba1\u7b97\u7b26\u5408\u6837\u5f0f\u7684\u5217\u6570\u3002 -C<\u663e\u793a\u884c\u6570> \u6216 --context=<\u663e\u793a\u884c\u6570> \u6216 -<\u663e\u793a\u884c\u6570> : \u9664\u4e86\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u5916\uff0c\u5e76\u663e\u793a\u8be5\u884c\u4e4b\u524d\u540e\u7684\u5185\u5bb9\u3002 -d <\u52a8\u4f5c> \u6216 --directories=<\u52a8\u4f5c> : \u5f53\u6307\u5b9a\u8981\u67e5\u627e\u7684\u662f\u76ee\u5f55\u800c\u975e\u6587\u4ef6\u65f6\uff0c\u5fc5\u987b\u4f7f\u7528\u8fd9\u9879\u53c2\u6570\uff0c\u5426\u5219grep\u6307\u4ee4\u5c06\u56de\u62a5\u4fe1\u606f\u5e76\u505c\u6b62\u52a8\u4f5c\u3002 -e<\u8303\u672c\u6837\u5f0f> \u6216 --regexp=<\u8303\u672c\u6837\u5f0f> : \u6307\u5b9a\u5b57\u7b26\u4e32\u505a\u4e3a\u67e5\u627e\u6587\u4ef6\u5185\u5bb9\u7684\u6837\u5f0f\u3002 -E \u6216 --extended-regexp : \u5c06\u6837\u5f0f\u4e3a\u5ef6\u4f38\u7684\u666e\u901a\u8868\u793a\u6cd5\u6765\u4f7f\u7528\u3002 -f<\u89c4\u5219\u6587\u4ef6> \u6216 --file=<\u89c4\u5219\u6587\u4ef6> : \u6307\u5b9a\u89c4\u5219\u6587\u4ef6\uff0c\u5176\u5185\u5bb9\u542b\u6709\u4e00\u4e2a\u6216\u591a\u4e2a\u89c4\u5219\u6837\u5f0f\uff0c\u8ba9grep\u67e5\u627e\u7b26\u5408\u89c4\u5219\u6761\u4ef6\u7684\u6587\u4ef6\u5185\u5bb9\uff0c\u683c\u5f0f\u4e3a\u6bcf\u884c\u4e00\u4e2a\u89c4\u5219\u6837\u5f0f\u3002 -F \u6216 --fixed-regexp : \u5c06\u6837\u5f0f\u89c6\u4e3a\u56fa\u5b9a\u5b57\u7b26\u4e32\u7684\u5217\u8868\u3002 -G \u6216 --basic-regexp : \u5c06\u6837\u5f0f\u89c6\u4e3a\u666e\u901a\u7684\u8868\u793a\u6cd5\u6765\u4f7f\u7528\u3002 -h \u6216 --no-filename : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u4e0d\u6807\u793a\u8be5\u884c\u6240\u5c5e\u7684\u6587\u4ef6\u540d\u79f0\u3002 -H \u6216 --with-filename : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u8868\u793a\u8be5\u884c\u6240\u5c5e\u7684\u6587\u4ef6\u540d\u79f0\u3002 -i \u6216 --ignore-case : \u5ffd\u7565\u5b57\u7b26\u5927\u5c0f\u5199\u7684\u5dee\u522b\u3002 -l \u6216 --file-with-matches : \u5217\u51fa\u6587\u4ef6\u5185\u5bb9\u7b26\u5408\u6307\u5b9a\u7684\u6837\u5f0f\u7684\u6587\u4ef6\u540d\u79f0\u3002 -L \u6216 --files-without-match : \u5217\u51fa\u6587\u4ef6\u5185\u5bb9\u4e0d\u7b26\u5408\u6307\u5b9a\u7684\u6837\u5f0f\u7684\u6587\u4ef6\u540d\u79f0\u3002 -n \u6216 --line-number : \u5728\u663e\u793a\u7b26\u5408\u6837\u5f0f\u7684\u90a3\u4e00\u884c\u4e4b\u524d\uff0c\u6807\u793a\u51fa\u8be5\u884c\u7684\u5217\u6570\u7f16\u53f7\u3002 -o \u6216 --only-matching : \u53ea\u663e\u793a\u5339\u914dPATTERN \u90e8\u5206\u3002 -q \u6216 --quiet\u6216--silent : \u4e0d\u663e\u793a\u4efb\u4f55\u4fe1\u606f\u3002 -r \u6216 --recursive : \u6b64\u53c2\u6570\u7684\u6548\u679c\u548c\u6307\u5b9a\"-d recurse\"\u53c2\u6570\u76f8\u540c\u3002 -s \u6216 --no-messages : \u4e0d\u663e\u793a\u9519\u8bef\u4fe1\u606f\u3002 -v \u6216 --revert-match : \u663e\u793a\u4e0d\u5305\u542b\u5339\u914d\u6587\u672c\u7684\u6240\u6709\u884c\u3002 -V \u6216 --version : \u663e\u793a\u7248\u672c\u4fe1\u606f\u3002 -w \u6216 --word-regexp : \u53ea\u663e\u793a\u5168\u5b57\u7b26\u5408\u7684\u5217\u3002 -x --line-regexp : \u53ea\u663e\u793a\u5168\u5217\u7b26\u5408\u7684\u5217\u3002 -y : \u6b64\u53c2\u6570\u7684\u6548\u679c\u548c\u6307\u5b9a\"-i\"\u53c2\u6570\u76f8\u540c\u3002 \u5728\u5f53\u524d\u76ee\u5f55\u4e2d\uff0c\u67e5\u627e\u540e\u7f00\u6709conf\u5b57\u6837\u7684\u6587\u4ef6\u4e2d\u5305\u542bxen\u5b57\u7b26\u4e32\u7684\u6587\u4ef6\uff0c\u5e76\u6253\u5370\u51fa\u8be5\u5b57\u7b26\u4e32\u7684\u884c\u3002 pmgr@dcmaster:/data/program/general> grep xen *.conf xen xening \u67e5\u627e\u524d\u7f00\u6709gen\u7684\u6587\u4ef6\u5305\u542bxen\u5b57\u7b26\u4e32\u7684\u6587\u4ef6 pmgr@dcmaster:/data/program/general> grep xen gen* xen xening \u4ee5\u9012\u5f52\u7684\u65b9\u5f0f\u67e5\u627e\u7b26\u5408\u6761\u4ef6\u7684\u6587\u4ef6\u3002\u67e5\u627e\u6307\u5b9a\u76ee\u5f55/data/program/\u53ca\u5176\u5b50\u76ee\u5f55\uff08\u5982\u679c\u5b58\u5728\u5b50\u76ee\u5f55\u7684\u8bdd\uff09\u4e0b\u6240\u6709\u6587\u4ef6\u4e2d\u5305\u542b\u5b57\u7b26\u4e32xen\u7684\u6587\u4ef6\uff0c\u5e76\u6253\u5370\u51fa\u8be5\u5b57\u7b26\u4e32\u6240\u5728\u884c\u7684\u5185\u5bb9 pmgr@dcmaster:/data> grep -r xen /data/program/ ./program/general/general.conf:xen ./program/general/general.conf:xening \u53cd\u5411\u67e5\u627e\u3002\u524d\u9762\u5404\u4e2a\u4f8b\u5b50\u662f\u67e5\u627e\u5e76\u6253\u5370\u51fa\u7b26\u5408\u6761\u4ef6\u7684\u884c\uff0c\u901a\u8fc7 -v \u53c2\u6570\u53ef\u4ee5\u6253\u5370\u51fa\u4e0d\u7b26\u5408\u6761\u4ef6\u884c\u7684\u5185\u5bb9\u3002\u67e5\u627e\u6587\u4ef6\u540d\u4e2d\u5305\u542bxen\u7684\u6587\u4ef6\u4e2d\u4e0d\u5305\u542bxen\u7684\u884c pmgr@dcmaster:/data/program/general> grep -v xen gen* Linux Test test \u67e5\u627e\u5f53\u524d\u76ee\u5f55\u4e0b\u5305\u542b\u5b57\u7b26\u4e32\u201cLinux\u201d\u7684\u6587\u4ef6 pmgr@dcmaster:/data/program/general> grep Linux * general.conf:Linux grep: staffing: Is a directory pmgr@dcmaster:/data/program/general> egrep Linux * general.conf:Linux grep: staffing: Is a directory","title":"grep command"},{"location":"linux/Administration/03/","text":"Shell","title":"Shell"},{"location":"linux/Administration/03/#shell","text":"","title":"Shell"},{"location":"linux/Administration/linux_admin/","text":"Linux File System Overview Useful Commands Shell VIM Editor Remote Administration System Initialization Process Management Identity and Security Software Management Network Administration Storage Administration Administration and Monitoring","title":"Linux admin"},{"location":"linux/SES/linux_ses/","text":"SUSE Enterprise Storage Foundation and Basic Operation SUSE Enterprise Storage Foundation Ceph\u2019s RADOS Ceph architecture Enhanced SES Architecture Diagram Object Storage Ceph OSDs (Object Storage Daemon) Ceph Mons (Monitor Servers) Ceph MGRs (Manager Daemon) Ceph MDS (Metadata) Ceph Admin Node Ceph Dashboard Client Access Objects in Ceph CRUSH (Controllable Replication Under Scalable Hashing) CRUSH Algorithm CRUSH Maps and Rulesets CRUSH Weight The Monitor\u2019s Cluster Map contains CRUSH Hierarchy CRUSH Map Sections (Six main sections) Erasure Coding Erasure Coding in SES Replication vs Erasure Code EC Overwrites EC Profiles Creating Erasure Code Profiles and Pools BlueStore BlueStore Cache Parameters BlueStore Device Types BlueStore Configuration Recommendations Architecture Overview of Object, Block, Filesystem Access Object Storage Block Storage RADOS Block Device (RBD) File Storage Ceph Users and Authentication Ceph Configuration Health Scrub and Deep-Scrub Repair Ceph Manager Modules Ceph Tell Ceph Dashboard Basic Troubleshooting SUSE Enterprise Storage Basic Operation 1. Installation 1.1. Environment Setup 1.2. Install Packages 1.3. Stage 0 \u2014 the preparation 1.4. Stage 2 \u2014 the configuration 1.5. Stage 3 \u2014 the deployment 1.6. Stage 4 \u2014 the services 1.7. Stage 5 \u2014 the removal stage 1.8. Installation Guide 1.9. Issues during installation 1.10. Shutting Down the Whole Ceph Cluster 1.11. Starting, Stopping, and Restarting Services Using Targets 1.12. Restarting All Services 1.13. Restarting Specific Services 2. Basic Operation 2.1. Pools and Data Placement 2.1.1. Enable the PG Autoscaler and Balancer Modules 2.1.2. Manipulate Erasure Code Profiles 2.1.3. Manipulate CRUSH Map Rulesets 2.1.4. Investigate BlueStore 2.2. Common Day 1 Tasks Using the CLI 2.2.1. Ceph Users and Configuration 2.2.2. Run the Ceph Health Commands 2.2.3. Manipulate Pools 2.2.4. Maintain consistency of data with Scrub and Repair 2.2.5. Manipulate Manager Modules 2.2.6. Introduction to the Tell command 2.3. Ceph Dashboard 2.3.1. Access Dashboard 2.3.2. Explore the Dashboard Health, Performance, Status 2.4. Storage Data Access 2.4.1. Ensure the SES Cluster is Healthy 2.4.2. Use the S3 API to Interact with the RADOS Gateway 2.4.3. Use the swift API to Interact with the RADOS Gateway 2.4.4. Create Snapshots on SES using RBD 2.4.5. Create and manage COW Clones with rbd 2.4.6. Configure iSCSI on SES 2.4.7. Mount CephFS Provided by SUSE Enterprise Storage 2.4.8. Export an NFS Share from SES with NFS Ganesha 2.4.9. Configure and Mount CIFS","title":"SUSE Enterprise Storage Foundation and Basic Operation"},{"location":"linux/SES/linux_ses/#suse-enterprise-storage-foundation-and-basic-operation","text":"","title":"SUSE Enterprise Storage Foundation and Basic Operation"},{"location":"linux/SES/linux_ses/#suse-enterprise-storage-foundation","text":"Ceph\u2019s RADOS Ceph architecture Enhanced SES Architecture Diagram Object Storage Ceph OSDs (Object Storage Daemon) Ceph Mons (Monitor Servers) Ceph MGRs (Manager Daemon) Ceph MDS (Metadata) Ceph Admin Node Ceph Dashboard Client Access Objects in Ceph CRUSH (Controllable Replication Under Scalable Hashing) CRUSH Algorithm CRUSH Maps and Rulesets CRUSH Weight The Monitor\u2019s Cluster Map contains CRUSH Hierarchy CRUSH Map Sections (Six main sections) Erasure Coding Erasure Coding in SES Replication vs Erasure Code EC Overwrites EC Profiles Creating Erasure Code Profiles and Pools BlueStore BlueStore Cache Parameters BlueStore Device Types BlueStore Configuration Recommendations Architecture Overview of Object, Block, Filesystem Access Object Storage Block Storage RADOS Block Device (RBD) File Storage Ceph Users and Authentication Ceph Configuration Health Scrub and Deep-Scrub Repair Ceph Manager Modules Ceph Tell Ceph Dashboard Basic Troubleshooting","title":"SUSE Enterprise Storage Foundation"},{"location":"linux/SES/linux_ses/#suse-enterprise-storage-basic-operation","text":"","title":"SUSE Enterprise Storage Basic Operation"},{"location":"linux/SES/linux_ses/#1-installation","text":"","title":"1. Installation"},{"location":"linux/SES/linux_ses/#11-environment-setup","text":"","title":"1.1. Environment Setup"},{"location":"linux/SES/linux_ses/#12-install-packages","text":"","title":"1.2. Install Packages"},{"location":"linux/SES/linux_ses/#13-stage-0-the-preparation","text":"","title":"1.3. Stage 0 \u2014 the preparation"},{"location":"linux/SES/linux_ses/#14-stage-2-the-configuration","text":"","title":"1.4. Stage 2 \u2014 the configuration"},{"location":"linux/SES/linux_ses/#15-stage-3-the-deployment","text":"","title":"1.5. Stage 3 \u2014 the deployment"},{"location":"linux/SES/linux_ses/#16-stage-4-the-services","text":"","title":"1.6. Stage 4 \u2014 the services"},{"location":"linux/SES/linux_ses/#17-stage-5-the-removal-stage","text":"","title":"1.7. Stage 5 \u2014 the removal stage"},{"location":"linux/SES/linux_ses/#18-installation-guide","text":"","title":"1.8. Installation Guide"},{"location":"linux/SES/linux_ses/#19-issues-during-installation","text":"","title":"1.9. Issues during installation"},{"location":"linux/SES/linux_ses/#110-shutting-down-the-whole-ceph-cluster","text":"","title":"1.10. Shutting Down the Whole Ceph Cluster"},{"location":"linux/SES/linux_ses/#111-starting-stopping-and-restarting-services-using-targets","text":"","title":"1.11. Starting, Stopping, and Restarting Services Using Targets"},{"location":"linux/SES/linux_ses/#112-restarting-all-services","text":"","title":"1.12. Restarting All Services"},{"location":"linux/SES/linux_ses/#113-restarting-specific-services","text":"","title":"1.13. Restarting Specific Services"},{"location":"linux/SES/linux_ses/#2-basic-operation","text":"","title":"2. Basic Operation"},{"location":"linux/SES/linux_ses/#21-pools-and-data-placement","text":"","title":"2.1. Pools and Data Placement"},{"location":"linux/SES/linux_ses/#211-enable-the-pg-autoscaler-and-balancer-modules","text":"","title":"2.1.1. Enable the PG Autoscaler and Balancer Modules"},{"location":"linux/SES/linux_ses/#212-manipulate-erasure-code-profiles","text":"","title":"2.1.2. Manipulate Erasure Code Profiles"},{"location":"linux/SES/linux_ses/#213-manipulate-crush-map-rulesets","text":"","title":"2.1.3. Manipulate CRUSH Map Rulesets"},{"location":"linux/SES/linux_ses/#214-investigate-bluestore","text":"","title":"2.1.4. Investigate BlueStore"},{"location":"linux/SES/linux_ses/#22-common-day-1-tasks-using-the-cli","text":"","title":"2.2. Common Day 1 Tasks Using the CLI"},{"location":"linux/SES/linux_ses/#221-ceph-users-and-configuration","text":"","title":"2.2.1. Ceph Users and Configuration"},{"location":"linux/SES/linux_ses/#222-run-the-ceph-health-commands","text":"","title":"2.2.2. Run the Ceph Health Commands"},{"location":"linux/SES/linux_ses/#223-manipulate-pools","text":"","title":"2.2.3. Manipulate Pools"},{"location":"linux/SES/linux_ses/#224-maintain-consistency-of-data-with-scrub-and-repair","text":"","title":"2.2.4. Maintain consistency of data with Scrub and Repair"},{"location":"linux/SES/linux_ses/#225-manipulate-manager-modules","text":"","title":"2.2.5. Manipulate Manager Modules"},{"location":"linux/SES/linux_ses/#226-introduction-to-the-tell-command","text":"","title":"2.2.6. Introduction to the Tell command"},{"location":"linux/SES/linux_ses/#23-ceph-dashboard","text":"","title":"2.3. Ceph Dashboard"},{"location":"linux/SES/linux_ses/#231-access-dashboard","text":"","title":"2.3.1. Access Dashboard"},{"location":"linux/SES/linux_ses/#232-explore-the-dashboard-health-performance-status","text":"","title":"2.3.2. Explore the Dashboard Health, Performance, Status"},{"location":"linux/SES/linux_ses/#24-storage-data-access","text":"","title":"2.4. Storage Data Access"},{"location":"linux/SES/linux_ses/#241-ensure-the-ses-cluster-is-healthy","text":"","title":"2.4.1. Ensure the SES Cluster is Healthy"},{"location":"linux/SES/linux_ses/#242-use-the-s3-api-to-interact-with-the-rados-gateway","text":"","title":"2.4.2. Use the S3 API to Interact with the RADOS Gateway"},{"location":"linux/SES/linux_ses/#243-use-the-swift-api-to-interact-with-the-rados-gateway","text":"","title":"2.4.3. Use the swift API to Interact with the RADOS Gateway"},{"location":"linux/SES/linux_ses/#244-create-snapshots-on-ses-using-rbd","text":"","title":"2.4.4. Create Snapshots on SES using RBD"},{"location":"linux/SES/linux_ses/#245-create-and-manage-cow-clones-with-rbd","text":"","title":"2.4.5. Create and manage COW Clones with rbd"},{"location":"linux/SES/linux_ses/#246-configure-iscsi-on-ses","text":"","title":"2.4.6. Configure iSCSI on SES"},{"location":"linux/SES/linux_ses/#247-mount-cephfs-provided-by-suse-enterprise-storage","text":"","title":"2.4.7. Mount CephFS Provided by SUSE Enterprise Storage"},{"location":"linux/SES/linux_ses/#248-export-an-nfs-share-from-ses-with-nfs-ganesha","text":"","title":"2.4.8. Export an NFS Share from SES with NFS Ganesha"},{"location":"linux/SES/linux_ses/#249-configure-and-mount-cifs","text":"","title":"2.4.9. Configure and Mount CIFS"},{"location":"linux/SES/linux_ses_demo/","text":"SUSE Enterprise Storage 6 Installation and Basic Operation 1. Installation 1.1. Environment Setup In this demo, I use below environment, including VM setting and software installed. All VMs installed here was built on a physical host 10.58.121.68 . Host Server: 10.58.121.68 root / rootroot Account root / root123 Gateway: 10.58.120.1 Network Mask: 255.255.254.0 Nameserver: 10.58.32.32 10.33.50.20 Domain Search sha.me.corp dhcp.sha.me.corp me.corp ind.me.corp bgr.me.corp SUSE Server 15 SP1 Extensions and Modules were installed as below. [x] SUSE Enterprise Storage 6 [x] Basesystem Module 15 SP1 x86_64 [x] Server Applications Module 15 SP1 x86_64 Disable Services is as below: AppArmor Firewall Enable Services is as below. SSH Register SLES15.1 to local SMT. # SUSEConnect --url https://smtproxy.ind.me.corp Demo Environment summary is below. Alias Host Name Memory Disk eth0 eth0 mac address sles01 admin (salt-master) 16GB Disk1: 20G 10.58.121.181/23 52:54:00:23:7d:cd sles02 data1 16GB Disk1: 20G 10.58.121.182/23 52:54:00:5f:ce:6f Disk2: 8G Disk3: 8G Disk4: 8G sles03 data2 16GB Disk1: 20G 10.58.121.183/23 52:54:00:6f:f2:23 Disk2: 8G Disk3: 8G Disk4: 8G sles04 data3 16GB Disk1: 20G 10.58.121.184/23 52:54:00:93:4c:67 Disk2: 8G Disk3: 8G Disk4: 8G sles05 data4 16GB Disk1: 20G 10.58.121.185/23 52:54:00:90:b0:b0 Disk2: 8G Disk3: 8G Disk4: 8G sles06 mon1 16GB Disk1: 20G 10.58.121.186/23 52:54:00:46:43:7a sles07 mon2 16GB Disk1: 20G 10.58.121.187/23 52:54:00:00:fe:6b sles08 mon3 16GB Disk1: 20G 10.58.121.188/23 52:54:00:60:a3:92 Add hostname to file /etc/hosts (all nodes) If you do not specify a cluster network during Ceph deployment, it assumes a single public network environment. Make sure that the fully qualified domain name (FQDN) of each node can be resolved to the public network IP address by all other nodes. # vi /etc/hosts 10.58.121.181 admin.sha.me.corp admin salt 10.58.121.182 data1.sha.me.corp data1 10.58.121.183 data2.sha.me.corp data2 10.58.121.184 data3.sha.me.corp data3 10.58.121.185 data4.sha.me.corp data4 10.58.121.186 mon1.sha.me.corp mon1 10.58.121.187 mon2.sha.me.corp mon2 10.58.121.188 mon3.sha.me.corp mon3 Add all nodes as trust ssh access (root account) # cd ~ # ssh-keygen -t rsa # ssh-copy-id -i ~/.ssh/id_rsa.pub root@admin # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data1 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data2 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data3 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data4 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon1 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon2 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon3 # ssh admin.sha.me.corp # ssh data1.sha.me.corp # ssh data2.sha.me.corp # ssh data3.sha.me.corp # ssh data4.sha.me.corp # ssh mon1.sha.me.corp # ssh mon2.sha.me.corp # ssh mon3.sha.me.corp # ssh salt # ssh admin # ssh data1 # ssh data2 # ssh data3 # ssh data4 # ssh mon1 # ssh mon2 # ssh mon3 Disable firewall (all nodes) # sudo /sbin/SuSEfirewall2 off # firewall-cmd --state not running # systemctl stop firewalld.service # systemctl status firewalld.service firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: man:firewalld(1) Disable IPv6 (all nodes) and Set kernel pid to max value (all nodes) # vi /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 kernel.pid_max = 4194303 # sysctl -p Set DEV_ENV=true in /etc/profile.local in all nodes Install basic software (all nodes) # zypper in -y -t pattern yast2_basis base # zypper in -y net-tools vim man sudo tuned irqbalance # zypper in -y ethtool rsyslog iputils less supportutils-plugin-ses # zypper in -y net-tools-deprecated tree wget Configure NTP service (all nodes), Setting via YaST2 and add server cn.pool.ntp.,org . And /etc/chrony.conf file looks like below. admin:~ # cat /etc/chrony.conf # Use public servers from the pool.ntp.org project. pool cn.pool.ntp.org iburst ! pool pool.ntp.org iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second. makestep 1.0 3 # Enable kernel synchronization of the real-time clock (RTC). rtcsync # Enable hardware timestamping on all interfaces that support it. #hwtimestamp * # Increase the minimum numbgr of selectable sources required to adjust # the system clock. #minsources 2 # Allow NTP client access from local network. #allow 192.168.0.0/16 # Serve time even if not synchronized to a time source. #local stratum 10 # Specify file containing keys for NTP authentication. #keyfile /etc/chrony.keys # Get TAI-UTC offset and leap seconds from the system tz database. #leapsectz right/UTC # Specify directory for log files. logdir /var/log/chrony # Select which information is logged. #log measurements statistics tracking # Also include any directives found in configuration files in /etc/chrony.d include /etc/chrony.d/*.conf Make /etc/chrony.conf effective. # systemctl enable chronyd.service # systemctl restart chronyd.service # systemctl status chronyd.service # chronyc sources 1.2. Install Packages Install salt-minion on all nodes. And start the service. Hostname is in file `/etc/salt/minion_id` # zypper in -y salt-minion Uncomment below to let all nodes know who is master # vi /etc/salt/minion master: salt # systemctl enable salt-minion.service # systemctl start salt-minion.service # systemctl status salt-minion.service Install Ceph in admin node. Check log in /var/log/salt admin:~ # zypper in -y salt-master admin:~ # systemctl enable salt-master.service admin:~ # systemctl start salt-master.service admin:~ # systemctl status salt-master.service Note: ganesha will be installed on mon1, not admin node. admin:~ # zypper se ganesha admin:~ # zypper in nfs-ganesha admin:~ # systemctl enable nfs-ganesha admin:~ # systemctl start nfs-ganesha admin:~ # systemctl status nfs-ganesha admin:~ # cd /var/log/salt List fingerprints of all unaccepted minion keys on the Salt master. admin:~ # salt-key -F Local Keys: master.pem: c0:e5:***:04:c7 master.pub: 43:73:***:6a:34 Unaccepted Keys: admin.sha.me.corp: fe:51:***:b9:48 mon1.sha.me.corp: 94:13:***:91:63 mon2.sha.me.corp: c0:fd:***:39:3f mon3.sha.me.corp: 38:fc:***:2e:05 data1.sha.me.corp: b6:6c:***:63:4f data2.sha.me.corp: ab:14:***:c8:ac data3.sha.me.corp: 90:3f:***:76:3b data4.sha.me.corp: d8:12:***:f1:20 If the minions' fingerprints match, accept them admin:~ # salt-key --accept-all The following keys are going to be accepted: Unaccepted Keys: admin.sha.me.corp mon1.sha.me.corp mon2.sha.me.corp mon3.sha.me.corp data1.sha.me.corp data2.sha.me.corp data3.sha.me.corp data4.sha.me.corp Proceed? [n/Y] Y Key for minion admin.sha.me.corp accepted. Key for minion mon1.sha.me.corp accepted. Key for minion mon2.sha.me.corp accepted. Key for minion mon3.sha.me.corp accepted. Key for minion data1.sha.me.corp accepted. Key for minion data2.sha.me.corp accepted. Key for minion data3.sha.me.corp accepted. Key for minion data4.sha.me.corp accepted. Verify that the keys have been accepted admin:~ # salt-key -F admin:~ # salt-key --list-all Accepted Keys: admin.sha.me.corp data1.sha.me.corp data2.sha.me.corp data3.sha.me.corp data4.sha.me.corp mon1.sha.me.corp mon2.sha.me.corp mon3.sha.me.corp Denied Keys: Unaccepted Keys: Rejected Keys: Zero out all drivers which will be used as OSDs (optional) data1:~ lsblk data1:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done data2:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done data3:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done Install DeepSea admin:~ # zypper in -y deepsea Edit the /srv/pillar/ceph/deepsea_minions.sls file on the Salt master (admin node) and add or replace the following line: admin:~ # vi /srv/pillar/ceph/deepsea_minions.sls # Choose minions with a deepsea grain deepsea_minions: 'G@deepsea:*' #Match all Salt minions in the cluster # Choose all minions # deepsea_minions: '*' #Match all minions with the 'deepsea' grain # Choose custom Salt targeting # deepsea_minions: 'ses*' # deepsea_minions: 'ceph* or salt' Target the Minions Affirm salt-master (admin node) can communicate with the minions. And deploy the grains from admin node to all minions. admin:~ # salt '*' test.ping mon1.sha.me.corp: True data4.sha.me.corp: True data3.sha.me.corp: True data2.sha.me.corp: True data1.sha.me.corp: True mon3.sha.me.corp: True admin.sha.me.corp: True mon2.sha.me.corp: True Apply the 'deepsea' grain to a group of minions, and target with a DeepSea Grain admin:~ # salt '*' grains.append deepsea default data3.sha.me.corp: The val default was already in the list deepsea mon2.sha.me.corp: The val default was already in the list deepsea data1.sha.me.corp: The val default was already in the list deepsea data4.sha.me.corp: The val default was already in the list deepsea data2.sha.me.corp: The val default was already in the list deepsea mon3.sha.me.corp: The val default was already in the list deepsea admin.sha.me.corp: The val default was already in the list deepsea mon1.sha.me.corp: The val default was already in the list deepsea admin:~ # salt -G 'deepsea:*' test.ping (The following command is an equivalent) admin:~ # salt -C 'G@deepsea:*' test.ping admin.sha.me.corp: True data3.sha.me.corp: True mon1.sha.me.corp: True mon2.sha.me.corp: True data2.sha.me.corp: True data4.sha.me.corp: True mon3.sha.me.corp: True data1.sha.me.corp: True 1.3. Stage 0 \u2014 the preparation Run Stage 0\u2014the preparation During this stage, all required updates are applied and your system may be rebooted. If there are errors, re-run the stage. admin:~ # deepsea stage run ceph.stage.0 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.0 admin:~ # salt-run state.orch ceph.stage.prep Run Stage 1\u2014the discovery Here all hardware in your cluster is being detected and necessary information for the Ceph configuration is being collected. The discovery stage collects data from all minions and creates configuration fragments that are stored in the directory /srv/pillar/ceph/proposals . The data are stored in the YAML format in *.sls or *.yml files admin:~ # deepsea stage run ceph.stage.1 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.1 admin:~ # salt-run state.orch ceph.stage.discovery 1.4. Stage 2 \u2014 the configuration Run Stage 2 \u2014 the configuration \u2014 you need to prepare configuration data in a particular format. The assignment follows this pattern: role-ROLE_NAME/PATH/FILES_TO_INCLUDE (NOTE, the parent directory of PATH is /srv/pillar/ceph/ ) To avoid trouble with performance and the upgrade procedure, do not deploy the Ceph OSD, Metadata Server, or Ceph Monitor role to the Admin Node. Monitors, Metadata Server, and gateways can be co-located on the OSD nodes. If you are using CephFS, S3/Swift, iSCSI, at least two instances of the respective roles (Metadata Server, Object Gateway, iSCSI) are required for redundancy and availability. admin:~ # cp /usr/share/doc/packages/deepsea/examples/policy.cfg-rolebased /srv/pillar/ceph/proposals/policy.cfg admin:~ # vi /srv/pillar/ceph/proposals/policy.cfg ## Cluster Assignment # Add all nodes into Ceph cluster cluster-ceph/cluster/*.sls ## Roles # The Admin node fills the \u201cmaster\u201d and \u201cadmin\u201d roles for DeepSea # The master role is mandatory, always add a similar line to the following role-master/cluster/admin*.sls role-admin/cluster/admin*.sls # Monitoring # Cluster monitoring and data graphs, most commonly they run on Admin node # NFS Ganesha is configured via the file /etc/ganesha/ganesha.conf # As additional configuration is required to install NFS Ganesha, you can install NFS Ganesha later. # The following requirements need to be met before DeepSea stages 2 and 4 can be executed to install NFS Ganesha: # a)At least one node needs to be assigned the role-ganesha. # b)You can define only one role-ganesha per minion. # c)NFS Ganesha needs either an Object Gateway or CephFS to work, otherwise the validation will fail in Stage 3. # d)The kernel based NFS needs to be disabled on minions with the role-ganesha role. role-prometheus/cluster/admin*.sls role-grafana/cluster/mon1*.sls # MON # The minion will provide the monitor service to the Ceph cluster role-mon/cluster/mon*.sls # MGR # The Ceph manager daemon which collects all the state information from the whole cluster # Deploy it on all minions where you plan to deploy the Ceph monitor role role-mgr/cluster/mon1*.sls # MDS # The minion will provide the metadata service to support CephFS role-mds/cluster/mon*.sls # IGW # The minion will act as an iSCSI Gateway role-igw/cluster/mon2*.sls # RGW # The minion will act as an Object Gateway role-rgw/cluster/mon3*.sls # Storage # Use this role to specify storage nodes # It points to data1~4 nodes with a wildcard. role-storage/cluster/data*.sls # COMMON # It includes configuration files generated during the discovery (Stage 1) # Accept the default values for common configuration parameters such as fsid and public_network config/stack/default/global.yml config/stack/default/ceph/cluster.yml admin:~ # deepsea stage run ceph.stage.2 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.2 admin:~ # salt-run state.orch ceph.stage.configure After the command succeeds, run below command to view the pillar data for the specified minions admin:~ # salt 'mon*' pillar.items admin:~ # salt '*' saltutil.pillar_refresh Check time server (admin node) (the directory /srv/pillar/ceph/stack was initialized after deepsea installed, but global.yml file was not created yet until stage 2) By default, DeepSea uses the Admin Node as the time server for other cluster nodes. admin:~ # cat /srv/pillar/ceph/stack/default/global.yml (this file will be generated after stage 2) monitoring: prometheus: metric_relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] rule_files: [] scrape_interval: ceph: 10s grafana: 10s node_exporter: 10s prometheus: 10s target_partition: ceph: 1/1 grafana: 1/1 node_exporter: 1/1 prometheus: 1/1 time_server: admin.sha.me.corp Verify network (the directory /srv/pillar/ceph/stack was initialized after deepsea installed, but cluster.yml file was not created until stage 2 ) admin:~ # cat /srv/pillar/ceph/stack/ceph/cluster.yml --nothing admin:~ # cat /srv/pillar/ceph/stack/default/ceph/cluster.yml available_roles: - storage - admin - mon - mds - mgr - igw - grafana - prometheus - storage - rgw - ganesha - client-cephfs - client-radosgw - client-iscsi - client-nfs - benchmark-rbd - benchmark-blockdev - benchmark-fs - master cluster_network: 10.58.120.0/23 fsid: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 public_network: 10.58.120.0/23 Note: customized file will overwrite default one. Default file: /srv/pillar/ceph/stack/default/ceph/cluster.yml Customized file: /srv/pillar/ceph/stack/ceph/cluster.yml Check DriveGroup DriveGroups specify the layouts of OSDs in the Ceph cluster. They are defined in a single file /srv/salt/ceph/configuration/files/drive_groups.yml admin:~ # cat /srv/salt/ceph/configuration/files/drive_groups.yml default_drive_group_name: target: 'data*' <--original: 'I@role:storage' data_devices: all: true admin:~ # salt 'data*' pillar.items | grep -B5 stroage 1.5. Stage 3 \u2014 the deployment Run Stage 3 \u2014 the deployment \u2014 creates a basic Ceph cluster with mandatory Ceph services. This Deployment stage has more than 60 automated steps. Be patient and make sure the stage completes successfully before proceeding. Set dev environment and disable subvolume: admin:~ # vi /srv/pillar/ceph/stack/global.yml admin:~ # vi /srv/pillar/ceph/stack/default/global.yml monitoring: prometheus: metric_relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] rule_files: [] scrape_interval: ceph: 10s grafana: 10s node_exporter: 10s prometheus: 10s target_partition: ceph: 1/1 grafana: 1/1 node_exporter: 1/1 prometheus: 1/1 time_server: admin.sha.me.corp DEV_ENV: True subvolume_init: disabled admin:~ # salt '*' saltutil.pillar_refresh Note: customized file will overwrite default one. Default file: /srv/pillar/ceph/stack/default/global.yml Customized file: /srv/pillar/ceph/stack/global.yml admin:~ # deepsea stage run ceph.stage.3 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.3 admin:~ # salt-run state.orch ceph.stage.deploy After the command succeeds, run the following to check the status: admin:~ # ceph -s Below comands return you a structure of matching disks based on your DriveGroups. (will show available information after stage 3) admin:~ # salt-run disks.Report admin:~ # salt-run disks.list admin:~ # salt-run disks.details 1.6. Stage 4 \u2014 the services Run Stage 4 \u2014 the services \u2014 additional features of Ceph like iSCSI, Object Gateway and CephFS can be installed in this stage. Each is optional. admin:~ # deepsea stage run ceph.stage.4 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.4 admin:~ # salt-run state.orch ceph.stage.services admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log Before logon to dashboard via url, need get credentials first admin:~ # salt-call grains.get dashboard_creds local: ---------- admin: <your password> --> the password was changed to mypassword to log on to dashboard admin:~ # ceph mgr services { \"dashboard\": \"https://mon1.sha.me.corp:8443/\", \"prometheus\": \"http://mon1.sha.me.corp:9283/\" } https://10.58.121.186:8443 http://10.58.121.186:9283 admin:~ # watch ceph -s Every 2.0s: ceph -s admin: Mon Oct 5 14:41:51 2020 cluster: id: <id> health: HEALTH_OK services:s: ceph -s mon: 3 daemons, quorum mon1,mon2,mon3 (age 87m) mgr: mon1(active, since 82m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 85m), 12 in (since 85m) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 576 pgs objects: 213 objects, 4.2 KiB usage: 12 GiB used, 84 GiB / 96 GiB avail pgs: 576 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr 1.7. Stage 5 \u2014 the removal stage Run Stage 5 \u2014 the removal stage. This stage is not mandatory and during the initial setup it is usually not needed. In this stage the roles of minions and also the cluster configuration are removed. You need to run this stage when you need to remove a storage node from your cluster. admin:~ # deepsea stage run ceph.stage. 1.8. Installation Guide Deployment Guide (EN) Deployment Guide (ZH) 1.9. Issues during installation [ERROR]: The Salt Master has cached the public key for this node SOLUTION : Restart minions service [ERROR]: This server_id is computed nor by Adler32 neither by CRC32 [QUESTION]: How to change new salt key Stop salt-minion service # systemctl stop salt-minion Delete salt-minion pulic key # rm /etc/salt/pki/minion/minion.pub # rm /etc/salt/pki/minion/minion.pem Change new minion_id admin:~ # echo admin.sha.me.corp > /etc/salt/minion_id data1:~ # echo data1.sha.me.corp > /etc/salt/minion_id data2:~ # echo data2.sha.me.corp > /etc/salt/minion_id data3:~ # echo data3.sha.me.corp > /etc/salt/minion_id data4:~ # echo data4.sha.me.corp > /etc/salt/minion_id mon1:~ # echo mon1.sha.me.corp > /etc/salt/minion_id mon2:~ # echo mon2.sha.me.corp > /etc/salt/minion_id mon3:~ # echo mon3.sha.me.corp > /etc/salt/minion_id Delete old ID on admin node # salt-key -D Restart salt-minion service # systemctl restart salt-minion Accept all new key on admin node admin:~ # salt-key -L admin:~ # salt-key -A or admin:~ # salt-key -a admin.sha.me.corp data1:~ # salt-key -a data1.sha.me.corp data2:~ # salt-key -a data2.sha.me.corp data3:~ # salt-key -a data3.sha.me.corp data4:~ # salt-key -a data4.sha.me.corp mon1:~ # salt-key -a mon1.sha.me.corp mon2:~ # salt-key -a mon2.sha.me.corp mon3:~ # salt-key -a mon3.sha.me.corp [ERROR] ['/var/lib/ceph subvolume missing on mon3.sha.me.corp', '/var/lib/ceph subvolume missing on mon1.sha.me.corp', '/var/lib/ceph subvolume missing on mon2.sha.me.corp', 'See /srv/salt/ceph/subvolume/README.md'] SOLUTION Edit /srv/pillar/ceph/stack/global.yml and add the following line: subvolume_init: disabled Then refresh the Salt pillar and re-run DeepSea stage.3: admin:~ # salt '*' saltutil.refresh_pillar admin:~ # salt-run state.orch ceph.stage.3 After DeepSea successfully finished stage.3, the Ceph Dashboard will be running. Refer to Book \u201cAdministration Guide\u201d, Chapter 20 \u201cCeph Dashboard\u201d for a detailed overview of Ceph Dashboard features. To list nodes running dashboard, run: admin:~ # ceph mgr services | grep dashboard To list admin credentials, run: admin:~ # salt-call grains.get dashboard_creds [ERROR] module function cephprocesses.wait executed on nodes mon1~3 and data1~4 in Stage 0 SOLUTION Check below on all nodes # salt-call cephprocesses.check ERROR: process ceph-mds for role mds is not running ERROR: process radosgw for role rgw is not running admin:~ # ceph -s Clock skew detected on mon ceph (mon.mon2, mon.mon3) Set time server to public server (China) # chronyc sources 1.10. Shutting Down the Whole Ceph Cluster Shut down or disconnect any clients accessing the cluster. To prevent CRUSH from automatically rebalancing the cluster, set the cluster to noout: # ceph osd set noout Other flags you can set per osd: nodown noup noin noout Disable safety measures and run the ceph.shutdown runner: admin:~ # salt-run disengage.safety safety is now disabled for cluster ceph admin:~ # salt-run state.orch ceph.shutdown admin.sha.me.corp_master: Name: set noout - Function: salt.state - Result: Changed Started: - 14:32:14.398022 Duration: 2266.75 ms Name: Shutting down radosgw for rgw - Function: salt.state - Result: Changed Started: - 14:32:16.665452 Duration: 1461.23 ms Name: Shutting down cephfs - Function: salt.state - Result: Changed Started: - 14:32:18.127353 Duration: 30326.193 ms Name: Shutting down iscsi - Function: salt.state - Result: Clean Started: - 14:32:48.454187 Duration: 30142.468 ms Name: Shutting down storage - Function: salt.state - Result: Changed Started: - 14:33:18.597321 Duration: 10841.45 ms Name: Shutting down mgr - Function: salt.state - Result: Changed Started: - 14:33:29.439442 Duration: 29209.141 ms Name: Shutting down mon - Function: salt.state - Result: Changed Started: - 14:33:58.649221 Duration: 30519.97 ms Summary for admin.sha.me.corp_master ------------ Succeeded: 7 (changed=6) Failed: 0 ------------ Total states run: 7 Total run time: 134.767 s Power off all cluster nodes: admin:~ # salt -C 'G@deepsea:*' cmd.run \"shutdown -h\" Broadcast message from root@admin (Sat 2021-03-06 14:40:37 CST): The system is going down for poweroff at Sat 2021-03-06 14:41:37 CST! admin.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon2.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data2.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon3.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data3.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data4.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon1.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data1.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. 1.11. Starting, Stopping, and Restarting Services Using Targets # ls /usr/lib/systemd/system/ceph*.target ceph.target ceph-osd.target ceph-mon.target ceph-mgr.target ceph-mds.target ceph-radosgw.target ceph-rbd-mirror.target To start/stop/restart all Ceph services on the node, run: # systemctl start ceph.target # systemctl stop ceph.target # systemctl restart ceph.target To start/stop/restart all OSDs on the node, run: # systemctl start ceph-osd.target # systemctl stop ceph-osd.target # systemctl restart ceph-osd.target Starting, Stopping, and Restarting Individual Services # systemctl list-unit-files --all --type=service ceph* ceph-osd@.service ceph-mon@.service ceph-mds@.service ceph-mgr@.service ceph-radosgw@.service ceph-rbd-mirror@.service Example : # systemctl status ceph-mon@HOSTNAME.service (e.g., ceph-mon@mon1.service) # systemctl start ceph-osd@1.service # systemctl stop ceph-osd@1.service # systemctl restart ceph-osd@1.service # systemctl status ceph-osd@1.service 1.12. Restarting All Services # salt-run state.orch ceph.restart 1.13. Restarting Specific Services Example: salt-run state.orch ceph.restart.service_name # salt-run state.orch ceph.restart.mon # salt-run state.orch ceph.restart.mgr # salt-run state.orch ceph.restart.osd # salt-run state.orch ceph.restart.mds # salt-run state.orch ceph.restart.rgw # salt-run state.orch ceph.restart.igw # salt-run state.orch ceph.restart.ganesha Default log file path of salt-run: /var/log/salt/master 2. Basic Operation 2.1. Pools and Data Placement 2.1.1. Enable the PG Autoscaler and Balancer Modules Task 1: View the state of all the Manager Modules List all the existing Manager Modules admin:~ # ceph mgr module ls | less Task 2: List the Existing Pools List the pools that already exist in the cluster admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log List the pools again, but this time using the rados command: admin:~ # rados lspools iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log View the output of placement group autoscale-status command for the pools admin:~ # ceph osd pool autoscale-status Error ENOTSUP: Module 'pg_autoscaler' is not enabled (required by command 'osd pool autoscale-status'): use `ceph mgr module enable pg_autoscaler` to enable it Task 3: Enable the pg_autoscaler module Enable the pg_autoscaler module admin:~ # ceph mgr module enable pg_autoscaler admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 128 32 warn cephfs_data 0 3.0 98256M 0.0000 1.0 256 32 warn cephfs_metadata 7285 3.0 98256M 0.0000 4.0 64 16 warn .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 18078 3.0 98256M 0.0000 1.0 32 warn Note that for the iscsi-images pool the PG_NUM value is 128. And note that the NEW PG_NUM value is 32. The PGs won\u2019t be adjusted automatically because the default setting for the autoscaler is \u201cwarn\u201d. Note the last column (mode) that shows status \u201cwarn\u201d for all the pools. Check current status. \u201chave too many placement groups\u201d. That\u2019s exactly what we want the pg_autoscaler to tell us. admin:~ # ceph health HEALTH_WARN 3 pools have too many placement groups Turn off the pg_autoscaler feature for CephFS pools admin:~ # ceph osd pool set cephfs_data pg_autoscale_mode off set pool 2 pg_autoscale_mode to off admin:~ # ceph osd pool set cephfs_metadata pg_autoscale_mode off set pool 3 pg_autoscale_mode to off admin:~ # ceph health HEALTH_WARN 1 pools have too many placement groups Set the pg_autoscaler mode to \u201con\u201d for the iscs-images pool: admin:~ # ceph osd pool set iscsi-images pg_autoscale_mode on set pool 1 pg_autoscale_mode to on admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 128 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 256 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 64 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 18078 3.0 98256M 0.0000 1.0 32 warn Turn on the pg_autoscaler feature for CephFS pools admin:~ # ceph osd pool set cephfs_data pg_autoscale_mode on set pool 2 pg_autoscale_mode to on admin:~ # ceph osd pool set cephfs_metadata pg_autoscale_mode on set pool 3 pg_autoscale_mode to on PG numbgrs must always be a power of 2 admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 35900 3.0 98256M 0.0000 1.0 32 warn Show the cluster health admin:~ # ceph -s cluster: id: <id> health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 4w) mgr: mon1(active, since 46h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 8w), 12 in (since 8w) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 433 pgs objects: 246 objects, 4.7 KiB usage: 13 GiB used, 83 GiB / 96 GiB avail pgs: 0.462% pgs not active 431 active+clean 2 peering io: client: 45 KiB/s rd, 0 B/s wr, 44 op/s rd, 28 op/s wr Task 4: Turn on the Placement Group balancer feature 1). Show the \u201cstatus\u201d of the balancer: admin:~ # ceph balancer status { \"plans\": [], \"active\": false, \"last_optimize_started\": \"\", \"last_optimize_duration\": \"\", \"optimize_result\": \"\", \"mode\": \"none\" } admin:~ # ceph balancer on admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:22:57 2021\", \"last_optimize_duration\": \"0:00:00.001379\", \"optimize_result\": \"Please do \\\"ceph balancer mode\\\" to choose a valid mode first\", \"mode\": \"none\" } 2). Set the mode for the balancer to \u201cupmap\u201d: admin:~ # ceph balancer mode upmap Error EPERM: min_compat_client \"jewel\" < \"luminous\", which is required for pg-upmap. Try \"ceph osd set-require-min-compat-client luminous\" before enabling this mode admin:~ # ceph osd set-require-min-compat-client luminous --yes-i-really-mean-it set require_min_compat_client to luminous admin:~ # ceph balancer mode upmap admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:23:57 2021\", \"last_optimize_duration\": \"0:00:00.001807\", \"optimize_result\": \"Please do \\\"ceph balancer mode\\\" to choose a valid mode first\", \"mode\": \"upmap\" } 3). Create a balancer optimization plan called basic-plan. Ceph won\u2019t let you do this yet. Because you just recently enabled the pg_autoscaler, Ceph is moving objects around, and the PGs are quite busy with re-peering. admin:~ # ceph balancer optimize basic-plan Error EINVAL: Balancer enabled, disable to optimize manually 4). Show the details of the plan: This shows what \u201cexecute\u201d-ing the plan will do, itemizing which PGs will be affected. admin:~ # ceph balancer show basic-plan Error ENOENT: plan basic-plan not found <--- failed here 5). Show the effectiveness of the plan by comparing the current score for the pre-planned balancing and the score for the planned balancing: admin:~ # ceph balancer eval current cluster score 0.118731 (lower is better) admin:~ # ceph balancer eval basic-plan Error EINVAL: option \"basic-plan\" not a plan or a pool 6). Show the status of the balancer, now with all of these settings having been set, but before putting them into effect: The pg_autoscaler has already optimized the balance of PGs sufficiently. That\u2019s because this cluster is very small and has no significant content stored in it yet. If that\u2019s the case, you would see a message like \u201cError EALREADY: Unable to find further optimization, or pool(s)' pg_num is decreasing, or distribution is already perfect.\u201d If you receive this message, then you will not be able to complete this task. At some later time in the course you may choose to revisit this task to complete it. admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:32:59 2021\", \"last_optimize_duration\": \"0:00:00.004170\", \"optimize_result\": \"Unable to find further optimization, or pool(s) pg_num is decreasing, or distribution is already perfect\", \"mode\": \"upmap\" } 7). Set the basic-plan into effect: admin:~ # ceph balancer execute basic-plan Error EINVAL: Balancer enabled, disable to execute a plan 8). Now re-show the current score for the balanced cluster: admin:~ # ceph balancer eval current cluster score 0.118731 (lower is better) 2.1.2. Manipulate Erasure Code Profiles Task 1: Display a list of the current Erasure Code profiles admin:~ # ceph osd erasure-code-profile no valid command found; 4 closest matches: osd erasure-code-profile set <name> {<profile> [<profile>...]} {--force} osd erasure-code-profile get <name> osd erasure-code-profile rm <name> osd erasure-code-profile ls Error EINVAL: invalid command admin:~ # ceph osd erasure-code-profile ls default Task 2: Examine the details of the default EC profile admin:~ # ceph osd erasure-code-profile get default k=2 m=1 plugin=jerasure technique=reed_sol_van Task 3: Create and remove a new EC profile 1. Create a new EC profile from the command line. This is going to be a \u201cbad\u201d profile that will be removed in a moment: admin:~ # ceph osd erasure-code-profile set bad_profile k=2 m=4 plugin=jerasure admin:~ # ceph osd erasure-code-profile ls bad_profile default admin:~ # ceph osd erasure-code-profile get bad_profile crush-device-class= crush-failure-domain=host crush-root=default jerasure-per-chunk-alignment=false k=2 m=4 plugin=jerasure technique=reed_sol_van w=8 admin:~ # ceph osd erasure-code-profile rm bad_profile admin:~ # ceph osd erasure-code-profile ls default Task 4: Create a better EC profile admin:~ # ceph osd erasure-code-profile set usable_profile k=2 m=1 plugin=jerasure technique=reed_sol_van stripe_unit=4K crush-failure-domain=host admin:~ # ceph osd erasure-code-profile get usable_profile crush-device-class= crush-failure-domain=host crush-root=default jerasure-per-chunk-alignment=false k=2 m=1 plugin=jerasure stripe_unit=4K technique=reed_sol_van w=8 2.1.3. Manipulate CRUSH Map Rulesets Task 1: Display a list of the current CRUSH Map rules admin:~ # ceph osd crush rule ls replicated_rule admin:~ # ceph osd crush osd crush rule ls osd crush rule ls-by-class <class> osd crush rule dump {<name>} osd crush dump osd crush set {<int>} osd crush add-bucket <name> <type> {<args> [<args>...]} osd crush rename-bucket <srcname> <dstname> osd crush set <osdname (id|osd.id)> <float[0.0-]> <args> [<args>...] osd crush add <osdname (id|osd.id)> <float[0.0-]> <args> [<args>...] osd crush set-all-straw-buckets-to-straw2 admin:~ # ceph osd crush rule osd crush rule ls osd crush rule ls-by-class <class> osd crush rule dump {<name>} osd crush rule create-simple <name> <root> <type> {firstn|indep} osd crush rule create-replicated <name> <root> <type> {<class>} osd crush rule create-erasure <name> {<profile>} osd crush rule rm <name> osd crush rule rename <srcname> <dstname> List the existing CRUSH Map rulesets that have been defined according to a particular device class: admin:~ # ceph osd crush rule ls-by-class hdd admin:~ # ceph osd crush rule ls-by-class ssd Error ENOENT: failed to get rules by class 'ssd' admin:~ # ceph osd crush rule ls-by-class nvme Error ENOENT: failed to get rules by class 'nvme' Task 2: Examine the details of the default CRUSH Map rule Show the details of the default CRUSH Map rule with the dump sub-command: The \u201crule_id\u201d and \u201cruleset\u201d values just numbgrs to keep track of rules similar to a DB key id. \u201cmin_size\u201d and \u201cmax_size\u201d are related to how CRUSH behaves when a certain numbgr of replicas are created. The \u201csteps\u201d section is the most functional portion of the rule, providing an ordered set of rules for how CRUSH should behave. Note that there are three \u201cop\u201d parts, one each for \u201ctake\u201d, \u201cchooseleaf_firstn\u201d, and \u201cemit\u201d. \u201ctake\u201d in a replicated rule is always the first step, and \u201cemit\u201d is always the last step. The \u201citem_type\u201d in the \u201ctake\u201d step is the crush_root value, and the \u201chost\u201d in the \u201cchooseleaf_firstn\u201d step is the failure_domain. admin:~ # ceph osd crush rule dump replicated_rule { \"rule_id\": 0, \"rule_name\": \"replicated_rule\", \"ruleset\": 0, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } Task 3: Create and remove a new CRUSH Map rule 1). Create a new CRUSH ruleset from the command line.We made two mistakes here: First, we named it \u201cbud\u201d instead of \u201cbad\u201d. admin:~ # ceph osd crush rule create-replicated bud_ruleset default host admin:~ # ceph osd crush rule ls replicated_rule bud_ruleset 2). Rename the ruleset: admin:~ # ceph osd crush rule rename bud_ruleset bad_ruleset admin:~ # ceph osd crush rule ls replicated_rule bad_ruleset 3). The second mistake was that we specified the failure-domain at the host-bucket level. This is technically not a bad thing to do, in fact it would be a common use case. But for this demo we want to set the failure domain at the rack-bucket level. We can\u2019t change a defined CRUSH Map ruleset, so delete the bad one: admin:~ # ceph osd crush rule rm bad_ruleset admin:~ # ceph osd crush rule ls replicated_rule Task 4: Create a better CRUSH Map rule Create a more appropriate CRUSH Map rule from the CLI, that will survive the failure of a rack: admin:~ # ceph osd crush rule create-replicated better_ruleset default rack admin:~ # ceph osd crush rule dump better_ruleset { \"rule_id\": 1, \"rule_name\": \"better_ruleset\", \"ruleset\": 1, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"rack\" }, { \"op\": \"emit\" } ] } Task 5: Create CRUSH Map rules for different classes of devices 1). Create two different CRUSH Map rules from the CLI, that will accommodate a slow set of devices (HDDs) and a fast set of devices (SDDs): The error of 2nd is because the cluster does not have any SSD devices. admin:~ # ceph osd crush rule create-replicated slow_devices default host hdd admin:~ # ceph osd crush rule create-replicated fast_devices default host sdd Error EINVAL: device class sdd does not exist 2). Display the details of the new \u201cslow\u201d rule: admin:~ # ceph osd crush rule dump slow_devices { \"rule_id\": 2, \"rule_name\": \"slow_devices\", \"ruleset\": 2, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -2, \"item_name\": \"default~hdd\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } Task 6: Change the ruleset used by a pool 1). Show which CRUSH Map Ruleset is being used by the cephfs_data pool: The rule should be listed as replicated_rule. admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: replicated_rule 2). Change the cephfs_data pool to use the new CRUSH Map ruleset that you created in the previous task. admin:~ # ceph osd pool set cephfs_data crush_rule better_ruleset set pool 2 crush_rule to better_ruleset 3). Verify that the rule has been changed by re-running the earlier command: admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: better_ruleset 4). In this demo cluster, making the cephfs_data pool use the \u201cbetter_ruleset\u201d will result in problems. (There\u2019s no rack for the CRUSH Map, and not enough nodes to accommodate the requirement for a large numbgr of PGs.) So change the setting back to the replicated_rule. admin:~ # ceph osd pool set cephfs_data crush_rule replicated_rule set pool 2 crush_rule to replicated_rule admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: replicated_rule Task 7: Create a CRUSH Map rule enhanced with an EC profile 1). Combine the benefits of Erasure Coding with a CRUSH Map rule: This will only work if you have already created an appropriate EC profile called usable_profile. In this demo you would have done in an earlier exercise. And in this demo you need to tie this ec_rule to the usable_profile, not the better_profile.Or else any pool that you create using the ec_rule will fail due to insufficient resources. admin:~ # ceph osd crush rule create-erasure ec_rule usable_profile Link the CRUSH map rule (ec_rule) to EC profile (usable_profile) created rule ec_rule at 3 P.S., The useable_profile was created by : admin:~ # ceph osd erasure-code-profile set usable_profile k=2 m=1 plugin=jerasure technique=reed_sol_van stripe_unit=4K crush-failure-domain=host 2). Display the details of the EC-enhanced CRUSH Map rule: See the added, extra \u201cop\u201d steps. You might also notice the different values for \u201ctype,\u201d \u201cmin_size,\u201d and \u201cmax_size\u201d than what you saw in the standard replicated rules. admin:~ # ceph osd crush rule dump ec_rule { \"rule_id\": 3, \"rule_name\": \"ec_rule\", \"ruleset\": 3, \"type\": 3, \"min_size\": 3, \"max_size\": 3, \"steps\": [ { \"op\": \"set_chooseleaf_tries\", \"num\": 5 }, { \"op\": \"set_choose_tries\", \"num\": 100 }, { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_indep\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule ls replicated_rule better_ruleset slow_devices ec_rule admin:~ # ceph osd crush rule create-replicated better_ruleset default rack admin:~ # ceph osd crush rule create-replicated slow_devices default host hdd admin:~ # ceph osd crush rule create-erasure ec_rule usable_profile admin:~ # ceph osd crush rule dump replicated_rule { \"rule_id\": 0, \"rule_name\": \"replicated_rule\", \"ruleset\": 0, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule dump better_ruleset { \"rule_id\": 1, \"rule_name\": \"better_ruleset\", \"ruleset\": 1, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"rack\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule dump slow_devices { \"rule_id\": 2, \"rule_name\": \"slow_devices\", \"ruleset\": 2, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -2, \"item_name\": \"default~hdd\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd pool osd pool stats {<poolname>} osd pool scrub <poolname> [<poolname>...] osd pool deep-scrub <poolname> [<poolname>...] osd pool repair <poolname> [<poolname>...] osd pool force-recovery <poolname> [<poolname>...] osd pool force-backfill <poolname> [<poolname>...] osd pool cancel-force-recovery <poolname> [<poolname>...] osd pool cancel-force-backfill <poolname> [<poolname>...] osd pool autoscale-status osd pool mksnap <poolname> <snap> admin:~ # ceph osd pool get <poolname> size min_size pg_num pgp_num crush_rule Hashpspool Nodelete Nopgchange Nosizechange write_fadvise_dontneed Noscrub nodeep-scrub hit_set_type hit_set_period hit_set_count hit_set_fpp use_gmt_hitset target_max_objects target_max_bytes cache_target_dirty_ratio cache_target_dirty_high_ratio cache_target_full_ratio cache_min_flush_age cache_min_evict_age erasure_code_profile min_read_recency_for_promote All min_write_recency_for_promote fast_read hit_set_grade_decay_rate hit_set_search_last_n scrub_min_interval scrub_max_interval deep_scrub_interval recovery_priority recovery_op_priority scrub_priority compression_mode compression_algorithm compression_required_ratio compression_max_blob_size compression_min_blob_size csum_type csum_min_block csum_max_block allow_ec_overwrites fingerprint_algorithm pg_autoscale_mode pg_autoscale_bias pg_num_min target_size_bytes target_size_ratio 2.1.4. Investigate BlueStore Task 1: Explore the drive_groups.yml configuration After deployment, the drive_groups.yml file is where the storage administrator defines the configuration of the cluster\u2019s storage devices. Note the \u201cdata_devices\u201d parameter. In this demo, \u201call\u201d storage devices are data devices for BlueStore. Note that there are no definitions for \u201cwal_devices\u201d or \u201cdb_devices.\u201d That\u2019s because in this demo environment we don\u2019t have any other \u201cfast\u201d devices that would be appropriate for these roles. Since BlueStore is the default, there is no definition of a \u201cformat\u201d for the devices. Otherwise, a \u201cFormat: bluestore\u201d key-value pair might exist to ensure that BlueStore is used. admin:~ # cd /srv/salt/ceph/configuration/files admin:/srv/salt/ceph/configuration/files # cat drive_groups.yml # default: <- just a name - can be anything # target: 'data*' <- must be resolvable by salt's targeting processor # data_devices: # size: 20G # db_devices: # size: 10G # rotational: 1 # allflash: # target: 'fast_nodes*' # data_devices: # size: 100G # db_devices: # size: 50G # rotational: 0 # This is the default configuration and # will create an OSD on all available drives default: target: 'data*' data_devices: all: true Task 2: Examine a storage host\u2019s storage devices admin:~ # ssh data1 Last login: Tue Jan 5 18:06:40 2021 from 10.58.121.181 Should see 3 devices, which are named ceph LVM-type devices data1:~ # lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 8G 0 disk \u2514\u2500ceph--14c886af--269d--475f--8ee3--f5e4abbb222d-osd--data--38911b2d--f30a--4b09--9010--8dd6fad2fcc6 254:0 0 8G 0 lvm sdb 8:16 0 8G 0 disk \u2514\u2500ceph--9ec4a77a--5d67--4b21--be53--d7e9221082de-osd--data--00cb3dc6--c28b--41ae--95de--efb86da254da 254:1 0 8G 0 lvm sdc 8:32 0 8G 0 disk \u2514\u2500ceph--5eaea8a8--bb68--49dd--a1e3--b82c5464ab1f-osd--data--a4a05f70--53d9--41d4--a273--4f47a088968a 254:2 0 8G 0 lvm sr0 11:0 1 672M 0 rom vda 253:0 0 20G 0 disk \u251c\u2500vda1 253:1 0 8M 0 part \u251c\u2500vda2 253:2 0 18.4G 0 part / \u2514\u2500vda3 253:3 0 1.7G 0 part [SWAP] See the raw ceph devices data1:~ # ls -lad /dev/ceph* drwxr-xr-x 2 root root 60 Oct 5 13:15 /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d drwxr-xr-x 2 root root 60 Oct 5 13:16 /dev/ceph-5eaea8a8-bb68-49dd-a1e3-b82c5464ab1f drwxr-xr-x 2 root root 60 Oct 5 13:15 /dev/ceph-9ec4a77a-5d67-4b21-be53-d7e9221082de Dig down even farther by examining the content of one of the directories, see a symlink to an LVM device-mapper device. All the devices are tied together with LVM. Note that the name of the symlink is named osd-data- . data1:~ # ls -l /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d lrwxrwxrwx 1 ceph ceph 7 Oct 5 13:15 osd-data-38911b2d-f30a-4b09-9010-8dd6fad2fcc6 -> ../dm-0 data1:~ # l /dev/dm* brw-rw---- 1 ceph ceph 254, 0 Jan 5 18:10 /dev/dm-0 brw-rw---- 1 ceph ceph 254, 1 Jan 5 18:10 /dev/dm-1 brw-rw---- 1 ceph ceph 254, 2 Jan 5 18:10 /dev/dm-2 Task 3: Examine a storage host\u2019s OSD details data1:~ # cd /var/lib/ceph/ data1:/var/lib/ceph # ls -l drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-mds drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-mgr drwxr-x--- 1 ceph ceph 24 Oct 5 13:15 bootstrap-osd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rbd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rbd-mirror drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rgw drwxr-x--- 1 ceph ceph 12 Oct 5 09:04 crash drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mds drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mgr drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mon drwxr-x--- 1 ceph ceph 38 Oct 5 13:16 osd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 tmp See 3 different sub-directories, each representing the 3 different OSDs (ceph-2, ceph-6, ceph-10) that are running on this storage server data1:/var/lib/ceph # cd osd/ data1:/var/lib/ceph/osd # ls -l drwxrwxrwt 2 ceph ceph 320 Oct 5 13:16 ceph-10 drwxrwxrwt 2 ceph ceph 320 Oct 5 13:15 ceph-2 drwxrwxrwt 2 ceph ceph 320 Oct 5 13:16 ceph-6 See some functional files associated with the OSD and BlueStore. See a block file, which is a symlink to one of the ceph devices, which stores the raw objects for the OSD. data1:/var/lib/ceph/osd # cd ceph-2 data1:/var/lib/ceph/osd/ceph-2 # ls -l -rw-r--r-- 1 ceph ceph 400 Oct 5 13:15 activate.monmap lrwxrwxrwx 1 ceph ceph 92 Oct 5 13:15 block -> /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d/osd-data-38911b2d-f30a-4b09-9010-8dd6fad2fcc6 -rw------- 1 ceph ceph 2 Oct 5 13:15 bluefs -rw------- 1 ceph ceph 37 Oct 5 13:15 ceph_fsid -rw-r--r-- 1 ceph ceph 37 Oct 5 13:15 fsid -rw------- 1 ceph ceph 55 Oct 5 13:15 keyring -rw------- 1 ceph ceph 8 Oct 5 13:15 kv_backend -rw------- 1 ceph ceph 21 Oct 5 13:15 magic -rw------- 1 ceph ceph 4 Oct 5 13:15 mkfs_done -rw------- 1 ceph ceph 41 Oct 5 13:15 osd_key -rw------- 1 ceph ceph 6 Oct 5 13:15 ready -rw------- 1 ceph ceph 3 Oct 5 13:15 require_osd_release -rw------- 1 ceph ceph 10 Oct 5 13:15 type -rw------- 1 ceph ceph 2 Oct 5 13:15 whoami data1:/var/lib/ceph/osd/ceph-2 # cat ceph_fsid # The unique ID of this Ceph cluster 343ee7d3-232f-4c71-8216-1edbc55ac6e0 data1:/var/lib/ceph/osd/ceph-2 # cat fsid # The unique ID of this OSD 6df58ebc-dbfe-4822-9714-90212c06ea05 data1:/var/lib/ceph/osd/ceph-2 # cat keyring # The Ceph key for this OSD [osd.2] key = <your key> data1:/var/lib/ceph/osd/ceph-2 # cat ready # Indication of the readiness of this OSD ready data1:/var/lib/ceph/osd/ceph-2 # cat type # filestore or bluestore (in this case: bluestore) bluestore data1:/var/lib/ceph/osd/ceph-2 # cat whoami # The integer id of this OSD (in this case: 2) 2 Task 4: Display BlueStore information using ceph-bluestore-tool Show BlueStore metadata for osd.2: data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool show-label --path /var/lib/ceph/osd/ceph-2 inferring bluefs devices from bluestore path { \"/var/lib/ceph/osd/ceph-2/block\": { \"osd_uuid\": \"6df58ebc-dbfe-4822-9714-90212c06ea05\", \"size\": 8585740288, \"btime\": \"2020-10-05 13:15:51.227799\", \"description\": \"main\", \"bluefs\": \"1\", \"ceph_fsid\": \"343ee7d3-232f-4c71-8216-1edbc55ac6e0\", \"kv_backend\": \"rocksdb\", \"magic\": \"ceph osd volume v026\", \"mkfs_done\": \"yes\", \"osd_key\": <your key>, \"ready\": \"ready\", \"require_osd_release\": \"14\", \"whoami\": \"2\" } Run a manual \u201cscrub\u201d on osd.7 using ceph-blestore-tool. (Received error, the tool won\u2019t allow you to do this while the OSD is running.) data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool fsck --path /var/lib/ceph/osd/ceph-2 error from fsck: (11) Resource temporarily unavailable 2021-01-05 18:32:25.528 7f4abad6e180 -1 bluestore(/var/lib/ceph/osd/ceph-2) _lock_fsid failed to lock /var/lib/ceph/osd/ceph-2/fsid (is another ceph-osd still running?)(11) Resource temporarily unavailable Simulate that the OSD is down, shutdown the OSD: data1:/var/lib/ceph/osd/ceph-2 # systemctl stop ceph-osd@2.service Now run the \u201cfsck\u201d command again. This time the \u201cfsck\u201d has worked, with the output showing: \u201cfsck success\u201d data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool fsck --path /var/lib/ceph/osd/ceph-2 fsck success Restart the OSD: data1:/var/lib/ceph/osd/ceph-2 # systemctl start ceph-osd@2.service data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool show-label --path /var/lib/ceph/osd/ceph-2 inferring bluefs devices from bluestore path { \"/var/lib/ceph/osd/ceph-2/block\": { \"osd_uuid\": \"6df58ebc-dbfe-4822-9714-90212c06ea05\", \"size\": 8585740288, \"btime\": \"2020-10-05 13:15:51.227799\", \"description\": \"main\", \"bluefs\": \"1\", \"ceph_fsid\": \"343ee7d3-232f-4c71-8216-1edbc55ac6e0\", \"kv_backend\": \"rocksdb\", \"magic\": \"ceph osd volume v026\", \"mkfs_done\": \"yes\", \"osd_key\": <your key>, \"ready\": \"ready\", \"require_osd_release\": \"14\", \"whoami\": \"2\" } } 2.2. Common Day 1 Tasks Using the CLI Including ollowing topics in relation to the commandline: Users and Ceph Configuration Health commands Erasure Code Profiles CRUSH Map rules Pools Scrubbing OSDs and Placement Groups Manager modules The tell commands 2.2.1. Ceph Users and Configuration Task 1: View the current user keyrings Ceph keyrings are stored in below directory admin:~ # cd /etc/ceph/ admin:/etc/ceph # ls -l -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap The value of 'key' is the key that\u2019s on the keyring. The admin keyring is \u201callow\u201ded all capabilities (permissions) to all services in the cluster, as expected. there are more than just client keys. admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" Display the existing users with the \u201cauth\u201d command: Below two commands are equivalent admin:/etc/ceph # ceph -n client.admin -keyring=/etc/ceph/ceph.client.admin.keyring auth ls -- failed??? no valid command found admin:/etc/ceph # ceph auth ls installed auth entries: mds.mon1 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx mds.mon2 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx mds.mon3 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx osd.0 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.1 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.10 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.11 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.2 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.3 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.4 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.5 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.6 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.7 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.8 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.9 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * client.admin key: <your key> caps: [mds] allow * caps: [mgr] allow * caps: [mon] allow * caps: [osd] allow * client.bootstrap-mds key: <your key> caps: [mon] allow profile bootstrap-mds client.bootstrap-mgr key: <your key> caps: [mon] allow profile bootstrap-mgr client.bootstrap-osd key: <your key> caps: [mgr] allow r caps: [mon] allow profile bootstrap-osd client.bootstrap-rbd key: <your key> caps: [mon] allow profile bootstrap-rbd client.bootstrap-rbd-mirror key: <your key> caps: [mon] allow profile bootstrap-rbd-mirror client.bootstrap-rgw key: <your key> caps: [mon] allow profile bootstrap-rgw client.igw.mon2 key: <your key> caps: [mgr] allow r caps: [mon] allow * caps: [osd] allow * client.rgw.mon3 key: <your key> caps: [mgr] allow r caps: [mon] allow rwx caps: [osd] allow rwx client.storage key: <your key> caps: [mon] allow rw mgr.mon1 key: <your key> caps: [mds] allow * caps: [mon] allow profile mgr caps: [osd] allow * Task 2: Create a new keyring and associated user 1). There are several different ways to create a new keyring and user. This is just one way. Create a new keyring and associated user named James . Remembgr that typically all new users will need read rights for the mon capability, and will need read/write rights for the osd capability, including a specification of rights to a pool. admin:/etc/ceph # ceph-authtool -g -n client.james --cap mon 'allow r' --cap osd 'allow rw pool=iscsi-images' -C /etc/ceph/ceph.client.james.keyring creating /etc/ceph/ceph.client.james.keyring admin:/etc/ceph # l total 16 drwxr-xr-x 1 root root 130 Jan 5 19:31 ./ drwxr-xr-x 1 root root 4392 Oct 5 13:03 ../ -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap 2). Show the content of the newly created keyring: admin:/etc/ceph # cat ceph.client.james.keyring [client.james] key = <your key> caps mon = \"allow r\" caps osd = \"allow rw pool=iscsi-images\" 3). Officially add the new keyring to Ceph: admin:/etc/ceph # ceph auth add client.james -i /etc/ceph/ceph.client.james.keyring added key for client.james 4). Show the key information using the \u201cauth\u201d function: admin:/etc/ceph # ceph auth get client.james exported keyring for client.james [client.james] key = <your key> caps mon = \"allow r\" caps osd = \"allow rw pool=iscsi-images\" Task 3: Create a client key for RBD 1). Change to the directory that contains the ceph keyrings. admin:~ # cd /etc/ceph/ 2). List the content of the directory: Although you see the admin users\u2019s keyring, ceph.client.admin.keyring, there is not yet a file that is appropriate for a specific application to use. Also note that the permissions on the keyring file are quite restrictive: 0600 admin:/etc/ceph # ls -l -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap 3). Show the content of the admin user\u2019s keyring: You will use the value associated with the \u201ckey\u201d key to create a new file. Copy the \u201ckey\u201d value using your favorite method. admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" 4). Open a new file for editing called admin.secret using your favorite editor (such as vi): The name of the file isn\u2019t very important, but naming it this way will help to identify its purpose: it\u2019s a secret key for the admin user. Note that there are many ways to do this. An alternative way is mentioned in the tip below that will do this in one step using grep and awk. admin:/etc/ceph # vi admin.secret 5). Paste the \u201ckey\u201d value into the new file. It will be the only content of the file. It will look like this (in fact it\u2019s probably exactly the same as this, if you\u2019re using the demo environment provided to you): admin:/etc/ceph # cat admin.secret <your key> 6). Save the file and exist out of the editor. 7). Change the permissions of the file so that no other user on the host can see the content of the file: admin:/etc/ceph # chmod 0600 admin.secret admin:/etc/ceph # l drwxr-xr-x 1 root root 154 Jan 5 20:03 ./ drwxr-xr-x 1 root root 4392 Oct 5 13:03 ../ -rw------- 1 root root 41 Jan 5 20:03 admin.secret -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap Tip: An alternative way to create this key file is to simply use grep/awk together in one bash command, like this: admin:/etc/ceph # grep \"key =\" ceph.client.admin.keyring | awk -F\" = \" '{ print $2 }' <your key> admin:/etc/ceph # grep \"key =\" ceph.client.admin.keyring | awk -F\" = \" '{ print $2 }' > admin.secret admin:/etc/ceph # cat admin.secret <your key> Task 4: View the Ceph master configuration file View the content of the file. The file is managed and controlled by DeepSea. The comment makes reference to the control files in the /srv/salt/ceph/configuration/ directory hierarchy. This is a very simple storage cluster. In a more diverse and sophisticated ceph cluster there may be more configuration settings defined. Although this exercise doesn\u2019t call out any more specific information about this configuration file, you may take a moment to consider the content of the file before finishing the task. admin:/etc/ceph # cat ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.186, 10.58.121.187, 10.58.121.188 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] admin:/etc/ceph # ls -l /srv/salt/ceph/configuration/ drwxr-xr-x 1 salt salt 18 Oct 5 13:13 cache drwxr-xr-x 1 root root 38 Oct 5 09:04 check drwxr-xr-x 1 root root 74 Oct 5 09:04 create -rw-r--r-- 1 root root 217 May 14 2020 default-import.sls -rw-r--r-- 1 root root 222 May 14 2020 default.sls drwxr-xr-x 1 root root 276 Oct 5 12:55 files -rw-r--r-- 1 root root 74 May 14 2020 init.sls 2.2.2. Run the Ceph Health Commands Get overall health status admin:~ # ceph health HEALTH_OK admin:~ # ceph -s admin:~ # ceph status cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 5w) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 98m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr Run the \u201cstatus\u201d command for the monitors: admin:~ # ceph mon stat e1: 3 mons at { mon1=[v2:10.58.121.186:3300/0,v1:10.58.121.186:6789/0], mon2=[v2:10.58.121.187:3300/0,v1:10.58.121.187:6789/0], mon3=[v2:10.58.121.188:3300/0,v1:10.58.121.188:6789/0] }, election epoch 22, leader 0 mon1, quorum 0,1,2 mon1,mon2,mon3 Run the \u201cstatus\u201d command for the placement groups: admin:~ # ceph pg stat 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 852 B/s rd, 0 op/s Run the ceph \u201cstatus\u201d command while watching for changes to the status: admin:~ # ceph -s --watch-debug cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 5w) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 104m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr 2021-01-05 20:20:53.947298 mgr.mon1 [DBG] pgmap v1597415: 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 852 B/s rd, 0 op/s 2021-01-05 20:20:55.949294 mgr.mon1 [DBG] pgmap v1597416: 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 1.2 KiB/s rd, 1 op/s ....... 2.2.3. Manipulate Pools Task 1: Display a list of the current pools admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw List pools with their index numbgr. Note how the index numbgr matches the index numbgr of the detail listing above. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log Task 2: Display the usage data and stats of the current pools Display pool usages. Note again index \u201cID\u201d for the pool. admin:~ # ceph df RAW STORAGE: CLASS SIZE AVAIL USED RAW USED %RAW USED hdd 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 TOTAL 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 POOLS: POOL ID STORED OBJECTS USED %USED MAX AVAIL iscsi-images 1 389 B 2 192 KiB 0 25 GiB cephfs_data 2 0 B 0 0 B 0 25 GiB cephfs_metadata 3 7.2 KiB 48 1.5 MiB 0 25 GiB .rgw.root 4 1.2 KiB 4 768 KiB 0 25 GiB default.rgw.control 5 0 B 8 0 B 0 25 GiB default.rgw.meta 6 381 B 3 576 KiB 0 25 GiB default.rgw.log 7 35 KiB 208 35 KiB 0 25 GiB admin:~ # ceph df detail RAW STORAGE: CLASS SIZE AVAIL USED RAW USED %RAW USED hdd 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 TOTAL 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 POOLS: POOL ID STORED OBJECTS USED %USED MAX AVAIL QUOTA OBJECTS QUOTA BYTES DIRTY USED COMPR UNDER COMPR iscsi-images 1 389 B 2 192 KiB 0 25 GiB N/A N/A 2 0 B 0 B cephfs_data 2 0 B 0 0 B 0 25 GiB N/A N/A 0 0 B 0 B cephfs_metadata 3 7.2 KiB 48 1.5 MiB 0 25 GiB N/A N/A 48 0 B 0 B .rgw.root 4 1.2 KiB 4 768 KiB 0 25 GiB N/A N/A 4 0 B 0 B default.rgw.control 5 0 B 8 0 B 0 25 GiB N/A N/A 8 0 B 0 B default.rgw.meta 6 381 B 3 576 KiB 0 25 GiB N/A N/A 3 0 B 0 B default.rgw.log 7 35 KiB 208 35 KiB 0 25 GiB N/A N/A 208 0 B 0 B Display pool usages using rados command admin:~ # rados df POOL_NAME USED OBJECTS CLONES COPIES MISSING_ON_PRIMARY UNFOUND DEGRADED RD_OPS RD WR_OPS WR USED COMPR UNDER COMPR .rgw.root 768 KiB 4 0 12 0 0 0 40 40 KiB 4 4 KiB 0 B 0 B cephfs_data 0 B 0 0 0 0 0 0 0 0 B 0 0 B 0 B 0 B cephfs_metadata 1.5 MiB 48 0 144 0 0 0 0 0 B 111 42 KiB 0 B 0 B default.rgw.control 0 B 8 0 24 0 0 0 0 0 B 0 0 B 0 B 0 B default.rgw.log 35 KiB 208 0 624 0 0 0 5919671 5.6 GiB 3945118 946 KiB 0 B 0 B default.rgw.meta 576 KiB 3 0 9 0 0 0 38 28 KiB 4 3 KiB 0 B 0 B iscsi-images 192 KiB 2 0 6 0 0 0 4184657 4.0 GiB 8 2 KiB 0 B 0 B total_objects 246 total_used 14 GiB total_avail 82 GiB total_space 96 GiB Show the statistics of the pools: admin:~ # ceph osd pool stats pool iscsi-images id 1 client io 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr pool cephfs_data id 2 nothing is going on pool cephfs_metadata id 3 nothing is going on pool .rgw.root id 4 nothing is going on pool default.rgw.control id 5 nothing is going on pool default.rgw.meta id 6 nothing is going on pool default.rgw.log id 7 nothing is going on Show only the statistics about a specific pool: admin:~ # ceph osd pool stats .rgw.root pool .rgw.root id 4 nothing is going on Show which CRUSH Map ruleset was used to create the .rgw.root pool: admin:~ # ceph osd pool get .rgw.root crush_rule crush_rule: replicated_rule Show the list of all the attributes of a pool that can be queried: admin:~ # ceph osd pool get .rgw.root size min_size pg_num pgp_num crush_rule Hashpspool Nodelete Nopgchange Nosizechange write_fadvise_dontneed noscrub|nodeep-scrub hit_set_type hit_set_period hit_set_count hit_set_fpp use_gmt_hitset target_max_objects target_max_bytes cache_target_dirty_ratio cache_target_dirty_high_ratio cache_target_full_ratio cache_min_flush_age cache_min_evict_age erasure_code_profile min_read_recency_for_promote all|min_write_recency_for_promote fast_read|hit_set_grade_decay_rate hit_set_search_last_n scrub_min_interval scrub_max_interval deep_scrub_interval recovery_priority recovery_op_priority scrub_priority compression_mode compression_algorithm compression_required_ratio compression_max_blob_size compression_min_blob_size csum_type|csum_min_block csum_max_block allow_ec_overwrites fingerprint_algorithm pg_autoscale_mode pg_autoscale_bias pg_num_min target_size_bytes target_size_ratio Task 3: Create two new pools, one replicated, one EC 1). Create a new replicated pool that will be used for storing block data for RBD. Use the standard replicated_ruleset CRUSH Map: It would be tempting to the use the better_ruleset, but this demo environment doesn\u2019t have enough resources for that. This is a demo environment, so the PG numbgrs will be low. In your production environments, be sure to assign an appropriately high numbgr, or use the pg_autoscaler manager module. admin:~ # ceph osd pool create rbd_pool 4 4 replicated replicated_rule pool 'rbd_pool' created 2). Tell the cluster that you expect to have this new rbd_pool to use 50% of the total capacity: admin:~ # ceph osd pool set rbd_pool target_size_ratio .5 set pool 8 target_size_ratio to .5 3). Create a new EC pool that will be used for storing RGW buckets and objects. Use the usable_profile Erasure Code profile that was created in an earlier exercise. And use the ec_rule CRUSH Map ruleset that was created in an earlier exercise: admin:~ # ceph osd pool create bucket_pool 4 4 erasure usable_profile ec_rule pool 'bucket_pool' created 4). Tell the cluster that you expect to have this new bucket_pool to use 100GB of data: POOL_TARGET_SIZE_BYTES_OVERCOMMITTED admin:~ # ceph osd pool set bucket_pool target_size_bytes 100000000000 set pool 9 target_size_bytes to 100000000000 5). Enable the PG Autoscaler feature on the two new pools, to ensure that we have an appropriate assignment of placement groups in the demo cluster: This presumes that you completed an earlier exercise that enable the pg_autoscaler manager module. admin:~ # ceph osd pool set bucket_pool pg_autoscale_mode on set pool 9 pg_autoscale_mode to on admin:~ # ceph osd pool set rbd_pool pg_autoscale_mode on set pool 8 pg_autoscale_mode to on 6). Again display a list of all the pools, which will now include the two new pools that you\u2019ve just created: Notice in the detail listing that the two new pools don\u2019t have an application attribute assigned to them. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log 8 rbd_pool 9 bucket_pool admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw pool 8 'rbd_pool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 1415 lfor 0/0/1413 flags hashpspool stripe_width 0 target_size_ratio 0.5 pool 9 'bucket_pool' erasure size 3 min_size 2 crush_rule 3 object_hash rjenkins pg_num 4 pgp_num 4 autoscale_mode on last_change 1410 flags hashpspool stripe_width 8192 target_size_bytes 100000000000 7). Check the pg_autoscale status, particularly to see a comparison of how much raw space is being consumed by the two pools: See that the RATE column for all of the replicated pools shows the value of 3.0, while the value for the bucket_pool \u2013 which is an EC pool \u2013 is 1.5. The EC pool, with a K+M of 2+1 consumes considerably less raw storage space. See the TARGET RATIO for the rbd_pool. Notice that the autoscaler has automatically adjusted the numbgr PGs assigned to rbd_pool from \u201c4\u201d to \u201c128\u201d because you told the cluster to have the pool use 50% of the capacity. See the TARGET SIZE for the bucket_pool, roughly 100GB. But the cluster may not have changed the PG_NUM value yet. The autoscaler will adjust the numbgr of PGs gradually, so as not to disrupt the performance too dramatically. While you\u2019re here, you might also notice the RAW CAPACITY column. All pools are expecting to divide the cluster space equally, even though you\u2019ve explicitly told the cluster that rbd_pool and bucket_pool will deviate from that even division. admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 35900 3.0 98256M 0.0000 1.0 32 warn rbd_pool 0 3.0 98256M 0.0000 0.5000 1.0 32 on bucket_pool 0 95367M 1.5 98256M 1.4559 1.0 4 on Task 4: Assign an application to the two new pools 1). Assign the rbd application to the new rbd_pool that you created in the previous task: admin:~ # ceph osd pool application enable rbd_pool rbd enabled application 'rbd' on pool 'rbd_pool' 2). Instruct the cluster to prepare the new rbd_pool for storing block device images: admin:~ # rbd pool init rbd_pool 3). Assign the rgw application to the new bucket_pool that you created in the previous task: admin:~ # ceph osd pool application enable bucket_pool rgw enabled application 'rgw' on pool 'bucket_pool' 4). Display a list of all the pools again, this time noticing that the application attribute is set on the two new pools. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log 8 rbd_pool 9 bucket_pool admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw pool 8 'rbd_pool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 1420 lfor 0/0/1413 flags hashpspool,selfmanaged_snaps stripe_width 0 target_size_ratio 0.5 application rbd removed_snaps [1~3] pool 9 'bucket_pool' erasure size 3 min_size 2 crush_rule 3 object_hash rjenkins pg_num 4 pgp_num 4 autoscale_mode on last_change 1422 flags hashpspool stripe_width 8192 target_size_bytes 100000000000 application rgw 5). Another way to display which application is assigned to a pool is: admin:~ # ceph osd pool application get bucket_pool { \"rgw\": {} } admin:~ # ceph osd pool application get rbd_pool { \"rbd\": {} } Task 5: Manage snapshots of the new RGW bucket pool 1). Display a list of the snapshots that exist of the bucket_pool that you created in the previous task: The output show that there are \u201c0 snaps.\u201d Right, it is a little funny that you only list the snapshots with rados command; no such functionality exists with the ceph osd pool command. admin:~ # rados -p bucket_pool lssnap 0 snaps 2). Take (make) a snapshot of the rbd_pool: admin:~ # ceph osd pool mksnap bucket_pool brand_new_pool_snapshot created pool bucket_pool snap brand_new_pool_snapshot 3). Display the list of the snapshots again: admin:~ # rados -p bucket_pool lssnap 1 brand_new_pool_snapshot 2021.01.05 22:23:23 1 snaps 4). Remove the snapshot: admin:~ # ceph osd pool rmsnap bucket_pool brand_new_pool_snapshot removed pool bucket_pool snap brand_new_pool_snapshot 5). Display the list of the snapshots again: admin:~ # rados -p bucket_pool lssnap 0 snaps 2.2.4. Maintain consistency of data with Scrub and Repair Scrubbing is like \u201cfsck,\u201d which ensures that OSDs have durable, consistent data. Most of the scrubbing of OSDs happens automatically on a periodic basis. Task 1: Display a few of the Scrub settings 1). Show the possible configuration settings related to scrub: If you simply grep for \u201cscrub\u201d you\u2019ll get more than you really want; there are some mon_scrub settings that aren\u2019t related to this exercise. admin:~ # ceph config ls | grep osd_scrub osd_scrub_invalid_stats osd_scrub_during_recovery osd_scrub_begin_hour osd_scrub_end_hour osd_scrub_begin_week_day osd_scrub_end_week_day osd_scrub_load_threshold osd_scrub_min_interval osd_scrub_max_interval osd_scrub_interval_randomize_ratio osd_scrub_backoff_ratio osd_scrub_chunk_min osd_scrub_chunk_max osd_scrub_sleep osd_scrub_auto_repair osd_scrub_auto_repair_num_errors osd_scrub_max_preemptions osd_scrub_priority osd_scrub_cost admin:~ # ceph config ls | grep osd_deep_scrub osd_deep_scrub_interval osd_deep_scrub_randomize_ratio osd_deep_scrub_stride osd_deep_scrub_keys osd_deep_scrub_update_digest_min_age osd_deep_scrub_large_omap_object_key_threshold osd_deep_scrub_large_omap_object_value_sum_threshold admin:~ # ceph config ls | grep scrub mon_warn_pg_not_scrubbed_ratio mon_warn_pg_not_deep_scrubbed_ratio mon_scrub_interval mon_scrub_timeout mon_scrub_max_keys mon_scrub_inject_crc_mismatch mon_scrub_inject_missing_keys osd_op_queue_mclock_scrub_res osd_op_queue_mclock_scrub_wgt osd_op_queue_mclock_scrub_lim osd_scrub_invalid_stats osd_max_scrubs osd_scrub_during_recovery osd_scrub_begin_hour osd_scrub_end_hour osd_scrub_begin_week_day osd_scrub_end_week_day osd_scrub_load_threshold osd_scrub_min_interval osd_scrub_max_interval osd_scrub_interval_randomize_ratio osd_scrub_backoff_ratio osd_scrub_chunk_min osd_scrub_chunk_max osd_scrub_sleep osd_scrub_auto_repair osd_scrub_auto_repair_num_errors osd_scrub_max_preemptions osd_deep_scrub_interval osd_deep_scrub_randomize_ratio osd_deep_scrub_stride osd_deep_scrub_keys osd_deep_scrub_update_digest_min_age osd_deep_scrub_large_omap_object_key_threshold osd_deep_scrub_large_omap_object_value_sum_threshold osd_debug_deep_scrub_sleep osd_scrub_priority osd_scrub_cost osd_requested_scrub_priority mds_max_scrub_ops_in_progress 2). Get the value of a few of the different scrub schedule settings: Note that \u201c0\u201d and \u201c24\u201d are the same setting. admin:~ # ceph config get osd.* osd_scrub_begin_hour 0 admin:~ # ceph config get osd.* osd_scrub_end_hour 24 3). Get the value of the scrub and repair settings: The \u201cauto repair\u201d feature is turned off, and the maximum numbgr of errors that \u201cauto repair\u201d would automatically repair is 5. admin:~ # ceph config get osd.* osd_scrub_auto_repair false admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 5 Task 2: Change the Scrub settings in ceph.conf 1). Display the ceph.conf, and verify that the file doesn\u2019t have any settings defined yet that are related to scrub. The settings would be located in the [global] section of the file: # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.186, 10.58.121.187, 10.58.121.188 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 2). Change to the Salt File Server directory that will have Salt control the master ceph.conf configuration file: admin:~ # cd /srv/salt/ceph/configuration/files/ceph.conf.d/ 3). List the content of the directory: The directory is empty. (Well, there is a README, but no other functional files.) admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ls -l -rw-r--r-- 1 root root 1989 May 14 2020 README 4). Create and edit a new file called global.conf. You don\u2019t have to use vi, but this step uses vi as one way of doing it: Be sure that you spell everything correctly, including the absence of \u201c_\u201d characters; there are spaces. Save the file and exit out of the editor. admin:/srv/salt/ceph/configuration/files/ceph.conf.d # vi global.conf Add the following content to the file: osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 5). Use DeepSea (Salt) to stage the file properly in Salt\u2019s File Server on the Salt Master (admin): admin:/srv/salt/ceph/configuration/files/ceph.conf.d # salt admin* state.apply ceph.configuration.create admin.sha.me.corp: Name: /var/cache/salt/minion/files/base/ceph/configuration - Function: file.absent - Result: Changed Started: - 22:42:34.900173 Duration: 20.891 ms Name: /srv/salt/ceph/configuration/cache/ceph.conf - Function: file.managed - Result: Changed Started: - 22:42:34.921454 Duration: 8576.516 ms Name: find /var/cache/salt/master/jobs -user root -exec chown salt:salt {} ';' - Function: cmd.run - Result: Changed Started: - 22:42:43.535022 Duration: 71.957 ms Summary for admin.sha.me.corp ------------ Succeeded: 3 (changed=3) Failed: 0 ------------ Total states run: 3 Total run time: 8.669 s 6). Using DeepSea (Salt), distribute the new ceph.conf configuration settings to all the nodes in the cluster: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # salt \\* state.apply ceph.configuration mon3.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:07.986661 Duration: 101.977 ms Summary for mon3.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 101.977 ms mon1.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.012479 Duration: 108.888 ms Summary for mon1.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 108.888 ms data3.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.052247 Duration: 98.681 ms Summary for data3.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 98.681 ms admin.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.072402 Duration: 97.231 ms Summary for admin.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 97.231 ms data1.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.076279 Duration: 104.169 ms Summary for data1.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 104.169 ms data4.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.081635 Duration: 105.13 ms Summary for data4.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 105.130 ms mon2.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.155758 Duration: 105.004 ms Summary for mon2.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 105.004 ms data2.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.252200 Duration: 109.552 ms Summary for data2.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 109.552 ms 7). Verify that the new ceph.conf settings have been put into place on the admin node: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 8). Also verify that other minions in the cluster have also received the updated configuration file, such as on the mon1 and data2 nodes: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ssh mon1 cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ssh data1 cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 9). Apply the settings of the ceph.conf file to appropriate nodes in the cluster: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ceph config assimilate-conf -i /etc/ceph/ceph.conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_health_preluminous_compat = true mon_health_preluminous_compat_warning = false mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 mon_initial_membgrs = mon1, mon2, mon3 Task 3: Change the Scrub settings directly in the Configuration DB 1). Query the configuration database to see the value of \u201cosd_scrub_auto_repair_num_errors\u201d: You changed this value to \u201c10\u201d in the previous Task. admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 10 2). Change the value of \u201cosd_scrub_auto_repair_num_errors\u201d to \u201c8\u201d: admin:~ # ceph config set osd.* osd_scrub_auto_repair_num_errors 8 3). Show that the change has taken immediate effect by re-running the same command that was used in the first step: admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 8 Task 4: Manually scrub and repair an OSD and a PG This won\u2019t do much in this demo environment, because the OSDs aren\u2019t storing very much data. But it\u2019s worth having some practice. 1). Start a scrubbing of one of the OSDs: admin:~ # ceph osd scrub osd.1 instructed osd(s) 1 to scrub 2). Scrub a Placement Group: admin:~ # ceph pg scrub 8.1 instructing pg 8.1 on osd.0 to scrub 3). Repair an OSD: admin:~ # ceph osd repair osd.1 instructed osd(s) 1 to repair 4). Repair a PG: admin:~ # ceph pg repair 8.1 instructing pg 8.1 on osd.0 to repair 5). Show what\u2019s currently happening to the OSD that you instructed to have scrubbed and repaired: admin:~ # ceph osd dump | grep osd.1 max_osd 12 osd.1 up in weight 1 up_from 10 up_thru 1415 down_at 0 last_clean_interval [0,0) v1:10.58.121.185:6800/11157 v1:10.58.121.185:6801/11157 exists,up 32c78078-1878-4fac-9738-00d8bf80deea osd.10 up in weight 1 up_from 18 up_thru 1413 down_at 0 last_clean_interval [0,0) v1:10.58.121.182:6808/11130 v1:10.58.121.182:6809/11130 exists,up 6cb26fdc-09b1-42de-8855-7203931a0101 osd.11 up in weight 1 up_from 18 up_thru 1415 down_at 0 last_clean_interval [0,0) v1:10.58.121.185:6808/11995 v1:10.58.121.185:6809/11995 exists,up cc22107d-0239-4874-8308-6c137c8a0931 6). Show what\u2019s currently happening to the PG that you instructed to have scrubbed and repaired: admin:~ # ceph pg dump | grep \"8\\.1\" dumped all 8.16 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.383909 0'0 1423:27 [6,4,5] 6 [6,4,5] 6 0'0 2021-01-05 20:53:47.314062 0'0 2021-01-05 20:53:47.314062 0 8.17 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:01.044252 0'0 1424:30 [1,6,8] 1 [1,6,8] 1 0'0 2021-01-05 22:57:01.044098 0'0 2021-01-05 22:57:01.044098 0 8.14 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:56:56.081480 0'0 1424:30 [1,2,4] 1 [1,2,4] 1 0'0 2021-01-05 22:56:56.081356 0'0 2021-01-05 22:56:56.081356 0 8.15 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.375386 0'0 1423:27 [3,5,0] 3 [3,5,0] 3 0'0 2021-01-05 20:53:53.231124 0'0 2021-01-05 20:48:05.301705 0 8.12 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.370121 0'0 1423:27 [11,2,8] 11 [11,2,8] 11 0'0 2021-01-05 20:53:48.149449 0'0 2021-01-05 20:48:05.301705 0 2.18 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 16:44:58.986205 0'0 1423:1630 [10,1,8] 10 [10,1,8] 10 0'0 2021-01-05 13:02:00.365382 0'0 2021-01-02 00:38:58.134100 0 8.13 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.387832 0'0 1423:27 [0,8,1] 0 [0,8,1] 0 0'0 2021-01-05 20:53:56.132358 0'0 2021-01-05 20:48:05.301705 0 8.10 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.368416 0'0 1423:27 [11,3,6] 11 [11,3,6] 11 0'0 2021-01-05 20:53:51.152790 0'0 2021-01-05 20:48:05.301705 0 8.11 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.377871 0'0 1423:24 [3,10,5] 3 [3,10,5] 3 0'0 2021-01-05 20:53:45.195257 0'0 2021-01-05 20:48:05.301705 0 8.1e 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.391754 0'0 1423:47 [0,11,8] 0 [0,11,8] 0 0'0 2021-01-05 20:53:55.081582 0'0 2021-01-05 20:48:05.301705 0 8.1 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:56:39.829397 0'0 1424:54 [0,7,10] 0 [0,7,10] 0 0'0 2021-01-05 22:56:39.829241 0'0 2021-01-05 22:56:39.829241 0 8.1f 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.392315 0'0 1423:27 [7,5,9] 7 [7,5,9] 7 0'0 2021-01-05 20:53:59.988252 0'0 2021-01-05 20:48:05.301705 0 5.4 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 18:21:28.179266 0'0 1423:1554 [7,9,6] 7 [7,9,6] 7 0'0 2021-01-05 18:21:28.179166 0'0 2021-01-05 18:21:28.179166 0 5.b 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 18:37:01.467457 0'0 1423:1547 [2,0,11] 2 [2,0,11] 2 0'0 2021-01-04 23:46:58.132824 0'0 2021-01-02 03:35:41.214192 0 8.19 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:06.059090 0'0 1424:30 [1,8,2] 1 [1,8,2] 1 0'0 2021-01-05 22:57:06.058935 0'0 2021-01-05 22:57:06.058935 0 8.18 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:05.097742 0'0 1424:30 [1,3,6] 1 [1,3,6] 1 0'0 2021-01-05 22:57:05.097670 0'0 2021-01-05 22:57:05.097670 0 1.11 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 00:30:18.193988 0'0 1423:1605 [0,8,6] 0 [0,8,6] 0 0'0 2021-01-05 00:30:18.193868 0'0 2020-12-29 06:30:58.897565 0 8.1b 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:13.146469 0'0 1424:30 [1,4,6] 1 [1,4,6] 1 0'0 2021-01-05 22:57:13.146390 0'0 2021-01-05 22:57:13.146390 0 8.1a 1 0 0 0 0 19 0 0 2 2 active+clean 2021-01-05 21:01:16.386166 1420'2 1423:29 [9,11,10] 9 [9,11,10] 9 0'0 2021-01-05 20:53:48.690239 0'0 2021-01-05 20:48:05.301705 0 8.1d 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.388079 0'0 1423:56 [0,2,3] 0 [0,2,3] 0 0'0 2021-01-05 20:53:54.121281 0'0 2021-01-05 20:48:05.301705 0 8.1c 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.385846 0'0 1423:27 [2,11,7] 2 [2,11,7] 2 0'0 2021-01-05 20:53:55.458714 0'0 2021-01-05 20:48:05.301705 0 2.2.5. Manipulate Manager Modules Task 1: Display the list of enabled Manager Modules 1). Run the following command to show the list of enabled manager modules: Note that several modules are already enabled, such as: dashboard, iostat, pg_autosclater, prometheus, and restful. Even though they are not listed, the crash module and the balancer module are already enabled by default. admin:~ # ceph mgr module ls | head { \"always_on_modules\": [ \"balancer\", \"crash\", \"devicehealth\", \"orchestrator_cli\", \"progress\", \"rbd_support\", \"status\", \"volumes\" 2). Demonstrate that the crash module is enabled by running its command with no arguments: A list of \u201c7 closest matches\u201d is displayed, representing possible additional arguments to be used with the crash command. The crash module is therefore available. admin:~ # ceph crash crash info <id> crash ls crash ls-new crash post crash prune <keep> crash rm <id> crash stat crash json_report <hours> crash archive <id> crash archive-all admin:~ # ceph crash stat 0 crashes recorded Task 2: Use the iostat module to display statistics for the IO of the cluster The iostat module is really simple, but very helpful. Run the command: admin:~ # ceph iostat +-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+ | Read | Write | Total | Read IOPS | Write IOPS | Total IOPS | +-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+ | 1024 B/s | 0 B/s | 1024 B/s | 1 | 0 | 1 | | 1024 B/s | 0 B/s | 1024 B/s | 1 | 0 | 1 | | 0 B/s | 0 B/s | 0 B/s | 0 | 0 | 0 | Task 3: Enable and configure the telemetry manager module 1). Enable the telemetry manager module: admin:~ # ceph mgr module enable telemetry 2). Show the various sub-commands that are associated with the telemetry command: A list of \u201c5 closest matches\u201d is displayed, showing various options. admin:~ # ceph telemetry telemetry status telemetry send {ceph|device [ceph|device...]} {<license>} telemetry show {<channels> [<channels>...]} telemetry show-device telemetry on {<license>} telemetry off 3). Show the status of the telemetry module: Notice that the output is returned as key/value pairs. Notice also that although the module has been enabled (which you accomplished in the first step of this task), the functionality is not enabled (enable=false). And for most of the keys, a null value is set. See that the url value is set to https://telemetry.ceph.com/report. That means that crash reports and other usage information about this cluster are going to be sent to the Ceph Community. admin:~ # ceph telemetry status { \"url\": \"https://telemetry.ceph.com/report\", \"device_url\": \"https://telemetry.ceph.com/device\", \"enabled\": false, \"last_opt_revision\": 1, \"leaderboard\": false, \"description\": null, \"contact\": null, \"organization\": null, \"proxy\": null, \"interval\": 24, \"channel_basic\": true, \"channel_ident\": false, \"channel_crash\": true, \"channel_device\": true, \"last_upload\": null } 4). Set the description, contact, and organization values: admin:~ # ceph config set mgr mgr/telemetry/contact 'JD <james@example.net>' admin:~ # ceph config set mgr mgr/telemetry/description 'Training Cluster' admin:~ # ceph config set mgr mgr/telemetry/organization 'SUSE Training' 5). Display the telemetry data that is collected to be sent: admin:~ # ceph telemetry show | less 6). With the contact information properly set, enable the telemetry functionality: This is a demo cluster with no connection to the internet, so no telemetry data will actually be sent. admin:~ # ceph telemetry on Error EPERM: Telemetry data is licensed under the Community Data License Agreement - Sharing - Version 1.0 (https://cdla.io/sharing-1-0/). To enable, add '--license sharing-1-0' to the 'ceph telemetry on' command. admin:~ # ceph telemetry on --license sharing-1-0 7). Disable the telemetry module: admin:~ # ceph mgr module disable telemetry admin:~ # ceph telemetry show | less Error ENOTSUP: Module 'telemetry' is not enabled (required by command 'telemetry show'): use `ceph mgr module enable telemetry` to enable it Task 4: Briefly attempt to use the crash manager module 1). Show (again) the various sub-commands that are associated with the crash command: admin:~ # ceph crash crash info <id> crash ls crash ls-new crash post crash prune <keep> crash rm <id> crash stat crash json_report <hours> crash archive <id> crash archive-all 2). Show the current status of the crash database, including the numbgr of crash reports that have been collected so far: It\u2019s likely that the numbgr of crashes recorded in the demo environment is 0. admin:~ # ceph crash stat 0 crashes recorded 2.2.6. Introduction to the Tell command Tell is a very powerful command within Ceph to control the cluster. You don\u2019t use it everyday, but you need to know how to use it when the occasion to use it arises. It\u2019s mostly an Advanced Command, but exposure to it now reduces the stress of learning about it in a more advanced setting later. Run the tell command in a few different circumstances to control the behavior of various Ceph services. Task 1: Run a benchmark test on an OSD 1). Run the following command to run and see the result of a benchmark test on osd.8: admin:~ # ceph tell osd.8 bench { \"bytes_written\": 1073741824, \"blocksize\": 4194304, \"elapsed_sec\": 3.7797023200000002, \"bytes_per_sec\": 284081055.35676152, \"iops\": 67.730201567831401 } Task 2: Change the protection setting regarding the deletion of pools 1). The default behavior in Ceph is that you can\u2019t delete pools. Try to delete a pool: The output says that you have to be VERY careful and provide more arguments in order to delete a pool admin:~ # ceph osd pool delete rbd_pool Error EPERM: WARNING: this will *PERMANENTLY DESTROY* all data stored in pool rbd_pool. If you are *ABSOLUTELY CERTAIN* that is what you want, pass the pool name *twice*, followed by --yes-i-really-really-mean-it. 2). Try deleting the pool again, this time with the extra arguments: Ceph still won\u2019t let you do it because the mon allow pool delete setting has the value of false. admin:~ # ceph osd pool delete rbd_pool rbd_pool --yes-i-really-really-mean-it Error EPERM: pool deletion is disabled; you must first set the mon_allow_pool_delete config option to true before you can destroy a pool 3). Show that the mon allow pool delete setting has the value of false: Indeed, the output shows that the value is false. admin:~ # ceph config get mon.mon\\* mon_allow_pool_delete false 4). Change to value of the setting using injectargs: Note that the \u201c-\u201d and \u201c_\u201d characters can be confusing. And note that the setting is preceded with the double \u201c--\u201d. The injected args must be enclosed in single quotes. You could have done this with ceph config set, but this is an alternative way to directly \u201ctell\u201d the cluster to change a setting. admin:~ # ceph tell mon.\\* injectargs '--mon-allow-pool-delete=true' mon.mon1: injectargs:mon_allow_pool_delete = 'true' mon.mon2: injectargs:mon_allow_pool_delete = 'true' mon.mon3: injectargs:mon_allow_pool_delete = 'true' 2.3. Ceph Dashboard 2.3.1. Access Dashboard Task 1: Set the password for the admin user of the Ceph Dashboard 1). In a Bash terminal as the root user, show that the Dashboard module is enabled: \u201cdashboard\u201d should be included in the list of \u201cenabled_modules\u201d at the top of the output. admin:~ # ceph mgr module ls | more \"enabled_modules\": [ \"dashboard\", \"iostat\", \"pg_autoscaler\", \"prometheus\", \"restful\" ], 2). Show the valid dashboard users that have already been created by DeepSea during initial deployment: It\u2019s possible that other users will be listed, but at least the \u201cadmin\u201d user should be displayed in the output. admin:~ # ceph dashboard ac-user-show [\"admin\"] 3). Show the \u201cadmin\u201d user\u2019s information as stored in the user database: You can see that the admin user has a password set, but it is stored as a hash. So you don\u2019t really know what the password is, and have no way of discovering it. admin:~ # ceph dashboard ac-user-show admin {\"username\": \"admin\", \"password\": <your password>, \"roles\": [\"administrator\"], \"name\": null, \"email\": null, \"lastUpdate\": 1601874928} 4). Change the \u201cadmin\u201d user\u2019s password for the dashboard: This sets the \u201cadmin\u201d user\u2019s password to the string: mypassword admin:~ # ceph dashboard ac-user-set-password admin mypassword {\"username\": \"admin\", \"password\": <your password>, \"roles\": [\"administrator\"], \"name\": null, \"email\": null, \"lastUpdate\": 1609860842} admin:~ # Task 3: Visit the Ceph Dashboard URL admin:~ # salt-call grains.get dashboard_creds local: ---------- admin: <your password> admin:~ # ceph mgr services { \"dashboard\": \"https://mon1.sha.me.corp:8443/\", \"prometheus\": \"http://mon1.sha.me.corp:9283/\" } admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 25m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 5h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 9 pools, 244 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 244 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr URL: https://mon1.sha.me.corp:8443/ https://10.58.121.186:8443 2.3.2. Explore the Dashboard Health, Performance, Status Dashboard Status Cluster Status Monitors OSDs Manager Daemons Hosts Object Gateway Metadata Service iSCSI Gateway Performance Client IOPS Client Throughput Client Read/Write Recovery Throughput Scrub Capacity Pools Raw Capacity Objects PGs per OSD PG Status [SUSE Enterprise Storage Portal Cluster-->Configuration Cluster-->Manager Modules Pools-->Create Pool 2.4. Storage Data Access 2.4.1. Ensure the SES Cluster is Healthy Task 1: Check the Cluster\u2019s health 1). Run the following command to check the status (health) of the SES cluster: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 18h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 23h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr 2). Evaluate the output. The cluster in this demonstration environment often doesn\u2019t startup correctly due to the nature of a demo environment and it\u2019s less-predictable resources. Depending on whether any of the following tasks are necessary, followup accordingly to ensure that the cluster is healthy before proceeding with the course lectures or any further exercises. 3). Run the following series of commands to restart the Monitor daemons on each of the Monitor nodes: It\u2019s certainly not necessary to restart the monitor daemons on all of the monitor nodes if only one is down. If you prefer, you can take a different approach to starting the daemon on a single monitor node. admin:~ # for h in mon1 mon2 mon3; \\ do \\ ssh $h systemctl restart ceph-mon@$h; \\ done 4). After waiting a few moments for the daemons to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 15s) mgr: mon1(active, since 21h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 767 B/s rd, 0 op/s rd, 0 op/s wr 5). Run the following series of commands to restart the Manager daemons on each of the Monitor nodes: admin:~ # for h in mon1 mon2 mon3; \\ do \\ ssh $h systemctl restart ceph-mgr@$h; \\ done 6). After waiting a few moments for the daemons to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 8m) mgr: mon1(active, since 18s) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.1 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr 7). Run the following command to restart the MDS daemon on the MDS node (mon1): admin:~ # ssh mon1 systemctl restart ceph-mds@mon1.service 8). After waiting a few moments for the mds daemon to restart, check the status again: Look for the mds service to be plain active rather than laggy or crashed admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 17m) mgr: mon1(active, since 8m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr 9). Verify if the OSDs \u201cup\u201d and running properly. It is only necessary if the output of ceph -s shows that there are fewer than 9 OSDs shown as being \u201cup\u201d. It\u2019s most likely that a storage node is simply not quite fully booted yet, such that the OSD daemons haven\u2019t fully come up. But if you suspect that the solution requires something different than simply waiting a little longer, you should try the following steps. First, identify which server is hosting the down\u2019d OSDs. One way of doing that is with this command: admin:~ # ceph osd tree ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.09357 root default -9 0.02339 host data1 2 hdd 0.00780 osd.2 up 1.00000 1.00000 6 hdd 0.00780 osd.6 up 1.00000 1.00000 10 hdd 0.00780 osd.10 up 1.00000 1.00000 -3 0.02339 host data2 0 hdd 0.00780 osd.0 up 1.00000 1.00000 4 hdd 0.00780 osd.4 up 1.00000 1.00000 9 hdd 0.00780 osd.9 up 1.00000 1.00000 -7 0.02339 host data3 3 hdd 0.00780 osd.3 up 1.00000 1.00000 7 hdd 0.00780 osd.7 up 1.00000 1.00000 8 hdd 0.00780 osd.8 up 1.00000 1.00000 -5 0.02339 host data4 1 hdd 0.00780 osd.1 up 1.00000 1.00000 5 hdd 0.00780 osd.5 up 1.00000 1.00000 11 hdd 0.00780 osd.11 up 1.00000 1.00000 Simply try restarting the storage daemon processes on the affected host, such as with this example: admin:~ # ssh data2 systemctl restart ceph-osd@9.service admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 32m) mgr: mon1(active, since 24m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 27s), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr If the OSD daemon processes are being stubborn and uncooperative, you may choose to reboot the storage virtual machine entirely. This is one way to do that: admin:~ # ssh data1 systemctl reboot After waiting some time for the daemons to get started, verify that all the OSDs are \u201cup\u201d and that the cluster is healthy: admin:~ # ceph osd tree admin:~ # ceph status 10). Run the following command to restart the RADOS Gateway daemon on the node that is hosting the gateway (mon3): admin:~ # ssh mon3 systemctl restart ceph-radosgw@rgw.mon3.service admin:~ # ssh mon3 systemctl status ceph-radosgw@rgw.mon3.service \u25cf ceph-radosgw@rgw.mon3.service - Ceph rados gateway Loaded: loaded (/usr/lib/systemd/system/ceph-radosgw@.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2021-01-06 21:37:53 CST; 23s ago Main PID: 781880 (radosgw) Tasks: 588 CGroup: /system.slice/system-ceph\\x2dradosgw.slice/ceph-radosgw@rgw.mon3.service \u2514\u2500781880 /usr/bin/radosgw -f --cluster ceph --name client.rgw.mon3 --setuser ceph --setgroup ceph Jan 06 21:37:53 mon3 systemd[1]: Started Ceph rados gateway. 11). After waiting a few moments for the daemon to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 39m) mgr: mon1(active, since 30m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 6m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr 2.4.2. Use the S3 API to Interact with the RADOS Gateway In this lab we used the s3cmd and radosgw-admin utilities to interact with the SUSE Enterprise Storage cluster. We created a new user, a new bucket, and a new file. We then uploaded the file to the cluster and verified that the object gateway stored it to the cluster. Task 1: Using the s3cmd tool and create an S3 user 1). As the root user (password is linux) in a shell or terminal, verify that the s3cmd is available on the admin node: You will likely see an error about configuration files missing, etc. This is enough information to validate the utility is installed. admin:~ # pip --version pip 10.0.1 from /usr/lib/python3.6/site-packages/pip (python 3.6) admin:~ # pip install s3cmd Collecting s3cmd Downloading https://files.pythonhosted.org/packages/26/44/19e08f69b2169003f7307565f19449d997895251c6a6566ce21d5d636435/s3cmd-2.1.0-py2.py3-none-any.whl (145kB) 100% | 153kB 2.7MB/s Collecting python-magic (from s3cmd) Downloading https://files.pythonhosted.org/packages/59/77/c76dc35249df428ce2c38a3196e2b2e8f9d2f847a8ca1d4d7a3973c28601/python_magic-0.4.18-py2.py3-none-any.whl Requirement already satisfied: python-dateutil in /usr/lib/python3.6/site-packages (from s3cmd) (2.7.3) Requirement already satisfied: six>=1.5 in /usr/lib/python3.6/site-packages (from python-dateutil->s3cmd) (1.11.0) Installing collected packages: python-magic, s3cmd Successfully installed python-magic-0.4.18 s3cmd-2.1.0 2). Create a new S3 user to be used: The output will include an access_key value and a secret_key value. You will need both of those values in later steps. admin:~ # radosgw-admin user create --uid=s3user --display-name=S3 User --email=s3user@example.net { \"user_id\": \"s3user\", \"display_name\": \"S3\", \"email\": \"s3user@example.net\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [], \"keys\": [ { \"user\": \"s3user\", \"access_key\": <your key>, \"secret_key\": <your key> } ], \"swift_keys\": [], \"caps\": [], \"op_mask\": \"read, write, delete\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] } Retrieve above information admin:~ # radosgw-admin user info --uid=s3user Task 2: Create a new s3cmd configuration file and a new S3 bucket 1). Generate a new s3cmd configuration file from a shell on the admin node: Fill in as listed below: admin:~ # cd ~ admin:~ # s3cmd --configure Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: <your key> Secret Key: <your key> Default Region [US]: <leave blank> Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: mon3.sha.me.corp Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: %(bucket)s.mon3.sha.me.corp Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: <leave blank> Path to GPG program [/usr/bin/gpg]: <leave blank> When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: No On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: <leave blank> New settings: Access Key: <your key> Secret Key: <your key> Default Region: US S3 Endpoint: mon3.sha.me.corp DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.mon3.sha.me.corp Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Configuration saved to '/root/.s3cfg' 2). Test the configuration by checking for existing files or directories: Since no buckets or files have been made available for the user, no items are listed and the command returns you to the prompt with no output. This is normal. If there is an error, your configuration may have a typo in it. The configuration file will have been saved as .s3cfg. Edit the file to match the configuration in step one. admin:~ # s3cmd ls 3). Create a new bucket for uploading files to using the s3cmd: You should see feedback that the bucket has been created. Although not technically required by the S3 API, the bucket name needs to be in all uppercase to avoid a bug with the s3cmd tool itself. admin:~ # s3cmd mb s3://S3CMDTEST Bucket 's3://S3CMDTEST/' created admin:~ # s3cmd ls 2021-01-06 14:04 s3://S3CMDTEST (it's GMT timezone) Task3: Create and upload a file to a bucket using the S3 API 1). Create a file with a few words of text: admin:~ # echo \"The mountains are beautiful\" > newfile 2). Put the new file into your bucket using s3cmd: You should see the file being uploaded. admin:~ # s3cmd put newfile s3://S3CMDTEST upload: 'newfile' -> 's3://S3CMDTEST/newfile' [1 of 1] 28 of 28 100% in 3s 7.66 B/s done 3). Verify the file is now in your bucket, safely stored in you SES cluster: admin:~ # s3cmd ls s3://S3CMDTEST 2021-01-06 14:11 28 s3://S3CMDTEST/newfile 2.4.3. Use the swift API to Interact with the RADOS Gateway OpenStack packages for SUSE Install and configure the storage nodes for openSUSE and SUSE Linux Enterprise SUSE Package Hub: python-PasteDeploy Enable SUSE Package Hub extension admin:~ # SUSEConnect -p PackageHub/15.1/x86_64 Install python3-PasteDeploy, which is dependency of python-swift installation admin:~ # zypper in python3-PasteDeploy admin:~ # rpm -ivh python3-PyECLib-1.6.0-1.6.x86_64.rpm warning: python3-PyECLib-1.6.0-1.6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 3dbdc284: NOKEY error: Failed dependencies: python(abi) = 3.8 is needed by python3-PyECLib-1.6.0-1.6.x86_64 rpmlib(PayloadIsZstd) <= 5.4.18-1 is needed by python3-PyECLib-1.6.0-1.6.x86_64 Add OpenStack Swift Repository for SUSE admin:~ # zypper addrepo -f obs://Cloud:OpenStack:Train/SLE_15_SP1 Train admin:~ # zypper in openstack-swift openstack-swift-account openstack-swift-container openstack-swift-object Task 1: Create a swift subuser 1). In a shell or terminal as the root user (password of linux) on the admin node, create a new subuser: The output will contain the access and secret keys for the s3user and a secret key for the new swift subuser.. admin:~ # radosgw-admin subuser create --uid=s3user --subuser=s3user:swift --access=full { \"user_id\": \"s3user\", \"display_name\": \"S3\", \"email\": \"s3user@example.net\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [ { \"id\": \"s3user:swift\", \"permissions\": \"full-control\" } ], \"keys\": [ { \"user\": \"s3user\", \"access_key\": <your key>, \"secret_key\": <your key> } ], \"swift_keys\": [ { \"user\": \"s3user:swift\", \"secret_key\": <your key> } ], \"caps\": [], \"op_mask\": \"read, write, delete\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] } 2). Verify that the subuser has access to at least one bucket and list the buckets with a swift command: swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '{SECRET_KEY_FROM_STEP_1}' list admin:~ # swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '<your key>' list S3CMDTEST Task 2: Use the swift command to access a file created with the S3cmd tool 1). Since the S3 API and the swift API are accessing the same SUSE Enterprise Storage cluster, and since the RADOS gateway is built to be inter-operable with both, you can use the swift API to retrieve the object which was uploaded to SES via the S3 API: swift -A http://mon3.example.net/auth/1.0 -U s3user:swift -K '{SECRET_KEY_FROM_STEP_1}' download -a An example of the command is listed here: admin:~ # swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '<your key>' download -a Although we have taken a shortcut by using the -a option (meaning grab every object this user has access to), it illustrates the tool\u2019s capability. We\u2019ve uploaded the newfile with S3, we\u2019ve retrieved it with swift. 2.4.4. Create Snapshots on SES using RBD In this lab we worked with rbd images. We mapped an rbd image to a Linux device file, then created a filesystem and mounted it. Then we created snapshots to preserve the images data state at a particular time, and rolled it back to demonstrate functionality. Task 1: Create a new pool for RBD images 1). Access https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 2). Log in with the following credentials: Username: admin Password: mypassword 3). Click on the Pools tab near the top of the page 4). Click the Create button and use the following in the available fields: Name: rbd-images Pool type: replicated Placement groups: 16 Crush ruleset: replicated_rule Replicted size: 2 Applications: rbd Compression Mode: none 5). Click Create Pool Task 2: Create a new RBD image in the rbd-images pool 6). Create a new RBD image using the rbd command: admin:~ # rbd create --size 1024 rbd-images/barfoo 7). Verify the new image has been created in the rbd-images pool: The new image named barfoo should be displayed. admin:~ # rbd ls -p rbd-images barfoo Task 3: Mount the new image on the admin node and create a filesystem 1). As the root user in a shell or terminal on the admin node, map the new rbd image to a block device: admin:~ # rbd map rbd-images/barfoo /dev/rbd0 2). Create a filesystem on the newly mapped device: admin:~ # mkfs.ext4 /dev/rbd0 mke2fs 1.43.8 (1-Jan-2018) Discarding device blocks: done Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: 19da6b86-1989-4834-a365-2f654fcce6f6 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 3). Mount the image to the /mnt directory: admin:~ # mount /dev/rbd0 /mnt admin:~ # l /mnt total 20 drwxr-xr-x 3 root root 4096 Jan 6 23:48 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ drwx------ 2 root root 16384 Jan 6 23:48 lost+found/ Task 4: Create a file on the new filesystem and snapshot the rbd image and make some additional changes 1). Change to the /mnt directory and create a simple file: admin:~ # cd /mnt admin:/mnt # echo \"This is some sample text\" > start.txt 2). List the directories contents to see that the start.txt file has been created on the storage cluster. admin:/mnt # ls -l total 20 drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 3). Create a snapshot of what the rbd image contained: Wait for confirmation that the snapshot has been created. It should only take a few seconds. admin:/mnt # rbd snap create rbd-images/barfoo@begin 4). List the rbd snapshots for the rbd-images/barfoo image: You should see the new snap called begin listed. admin:/mnt # rbd snap ls rbd-images/barfoo SNAPID NAME SIZE PROTECTED TIMESTAMP 4 begin 1 GiB Wed Jan 6 23:51:12 2021 5). Add another file to the filesystem: admin:/mnt # echo \"Some more text\" > end.txt 6). List the contents of the /mnt to verify the existence of two files. admin:/mnt # ls -l total 24 -rw-r--r-- 1 root root 15 Jan 6 23:52 end.txt drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 7). Create a second snapshot of the rbd-images/barfoo image: admin:/mnt # rbd snap create rbd-images/barfoo@finish 8). List the rbd snapshots: There should be begin and finish snapshots. admin:/mnt # rbd snap ls rbd-images/barfoo SNAPID NAME SIZE PROTECTED TIMESTAMP 4 begin 1 GiB Wed Jan 6 23:51:12 2021 5 finish 1 GiB Wed Jan 6 23:53:15 2021 9). List the contents of the /mnt directory again and verify the two files. 10). Rollback the data to the begin snapshot: This process will be relatively quick because the size of the image is small and we have very little data on it. admin:/mnt # rbd snap rollback rbd-images/barfoo@begin Rolling back to snapshot: 100% complete...done. 11). Change to the root user\u2019s home directory, then remount the image in order to see that the rbd image has been rolled back: admin:/mnt # cd ~ admin:~ # umount /mnt admin:~ # mount /dev/rbd0 /mnt 12). List the contents of the /mnt directory to verify that only the start.txt file exists on the image. admin:/mnt # ls -l total 20 drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 13). Rollback the data to the finish snapshot: admin:/mnt # rbd snap rollback rbd-images/barfoo@finish Rolling back to snapshot: 100% complete...done. 14). Unmount and remount the image: admin:/mnt # cd ~ admin:~ # umount /mnt admin:~ # mount /dev/rbd0 /mnt 15). List the contents of the /mnt directory to show it has indeed been rolled back and contains the start.txt and end.txt files admin:/mnt # ls -l total 24 -rw-r--r-- 1 root root 15 Jan 6 23:52 end.txt drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 16). Change to the root user\u2019s home directory and unmount the image: admin:/mnt # cd ~ admin:~ # umount /mnt 2.4.5. Create and manage COW Clones with rbd In this lab you will created a new pool and block device image in the pool. You then mapped the block storage to a linux device and took a snapshot. Finally you protected the snapshot from modification. This would be done so the snapshot can be safely used as a parent cow image which can then be cloned to create new virtual machines. Task 1: Create a new pool 1). View the current osds and pools: admin:~ # ceph osd ls 0 1 2 3 4 5 6 7 8 9 10 11 admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images 2). Create a new pool called cow-pool: admin:~ # ceph osd pool create cow-pool 128 pool 'cow-pool' created 3). List the available pools to view the new pool using either of the following commands: admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images cow-pool admin:~ # rados lspools iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images cow-pool Task 2: Create a block device image in a pool 1). Create a format 2 rbd image called cow-base in the cow-pool storage pool with a size of 1GB *Note that the \u2013image-format statement is optional as format 2 is default admin:~ # rbd create -p cow-pool cow-base --size 1024 --image-format 2 2). Check that the image has been created, that the format is 2 and that layering (COW Clones) is supported admin:~ # rbd -p cow-pool list cow-base admin:~ # rbd -p cow-pool info cow-base rbd image 'cow-base': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 269d5b817222aa block_name_prefix: rbd_data.269d5b817222aa format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:12:31 2021 access_timestamp: Thu Jan 7 10:12:31 2021 modify_timestamp: Thu Jan 7 10:12:31 2021 Task 3: Map the block storage image to a Linux host 1). In a shell or terminal as user root open a terminal window. Using the rbd map command, map an rbd device to the block-storage image created above. admin:~ # rbd map -p cow-pool --image cow-base /dev/rbd1 2). View the mapped block devices admin:~ # rbd showmapped id pool namespace image snap device 0 rbd-images barfoo - /dev/rbd0 1 cow-pool cow-base - /dev/rbd1 3). Note the rbd index numbgr (e.g. rbd0, rbd1) associated with the cow-base image: RBD ___1____ 4). View the devices in /dev. Note the device name(s) admin:~ # ls -l /dev/rbd* brw-rw---- 1 root disk 252, 0 Jan 6 23:49 /dev/rbd0 brw-rw---- 1 root disk 252, 16 Jan 7 10:14 /dev/rbd1 /dev/rbd: total 0 drwxr-xr-x 2 root root 60 Jan 7 10:14 cow-pool drwxr-xr-x 2 root root 60 Jan 6 23:48 rbd-images 5). View the block device:(use the device numbgr from step above) admin:~ # fdisk -l /dev/rbd1 Disk /dev/rbd1: 1 GiB, 1073741824 bytes, 2097152 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 4194304 bytes / 4194304 bytes 6). Format the device with an ext4 filesystem: admin:~ # mkfs.ext4 /dev/rbd1 mke2fs 1.43.8 (1-Jan-2018) Discarding device blocks: done Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: 64c9a973-cf31-4239-881f-ec5642bf34e3 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 7). Mount the block device on the local filesystem: admin:~ # mkdir /mnt/cow-base admin:~ # mount /dev/rbd1 /mnt/cow-base 8). Test the storage access by creating a file: admin:~ # cd /mnt/cow-base admin:/mnt/cow-base # touch base-image-file admin:/mnt/cow-base # ls base-image-file lost+found Task 4: Snapshot the rbd image and protect the snapshot 1). List the snapshots in the cow-base image: admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base 2). Create a snapshot of the cow-base rbd image which contains the base-image-file file admin:/mnt/cow-base # rbd snap create cow-pool/cow-base@base-snap 3). List the snapshot: admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base SNAPID NAME SIZE PROTECTED TIMESTAMP 4 base-snap 1 GiB Thu Jan 7 10:37:13 2021 4). This snapshot will form the parent snapshot for COW clone images so you will now protected it from modification: admin:/mnt/cow-base # rbd snap protect cow-pool/cow-base@base-snap admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base SNAPID NAME SIZE PROTECTED TIMESTAMP 4 base-snap 1 GiB yes Thu Jan 7 10:37:13 2021 Task 5: Create writable COW clones from the parent snapshot 1). Create a COW clone from the cow-base with the base-snap snapshot as the parent image admin:/mnt/cow-base # rbd clone cow-pool/cow-base@base-snap cow-pool/cow-image1 2). Check the information for the new image admin:/mnt/cow-base # rbd -p cow-pool --image cow-image1 info rbd image 'cow-image1': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a1209678cad4 block_name_prefix: rbd_data.26a1209678cad4 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:38:58 2021 access_timestamp: Thu Jan 7 10:38:58 2021 modify_timestamp: Thu Jan 7 10:38:58 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB 3). Note that the image has details of the parent image and overlap 4). Repeat steps 2 & 3 for an additional image called cow-image2 admin:/mnt/cow-base # rbd clone cow-pool/cow-base@base-snap cow-pool/cow-image2 admin:/mnt/cow-base # rbd -p cow-pool --image cow-image2 info rbd image 'cow-image2': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a2fbcec7b8d9 block_name_prefix: rbd_data.26a2fbcec7b8d9 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:47:28 2021 access_timestamp: Thu Jan 7 10:47:28 2021 modify_timestamp: Thu Jan 7 10:47:28 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB Task 6: Test that the COW clones are functional 1). Create a new directory and mount the COW clone called cow-image1 Note the rbd device name and use it to mount the file system admin:/mnt # mkdir /mnt/cow-image1 admin:/mnt # rbd map -p cow-pool --image cow-image1 /dev/rbd2 admin:/mnt # l total 4 drwxr-xr-x 1 root root 36 Jan 7 10:54 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ drwxr-xr-x 3 root root 4096 Jan 7 10:19 cow-base/ drwxr-xr-x 1 root root 0 Jan 7 10:54 cow-image1/ admin:/mnt # ls -l /dev/rbd* brw-rw---- 1 root disk 252, 0 Jan 6 23:49 /dev/rbd0 brw-rw---- 1 root disk 252, 16 Jan 7 10:18 /dev/rbd1 brw-rw---- 1 root disk 252, 32 Jan 7 10:55 /dev/rbd2 /dev/rbd: total 0 drwxr-xr-x 2 root root 80 Jan 7 10:55 cow-pool drwxr-xr-x 2 root root 60 Jan 6 23:48 rbd-images admin:/mnt # mount /dev/rbd2 /mnt/cow-image1 2). Check that the base-image-file which was created in the parent snapshot is present admin:/mnt # cd /mnt/cow-image1 admin:/mnt/cow-image1 # ls base-image-file lost+found 3). Repeat steps 1 and 2 for cow-image2 admin:/mnt # mkdir /mnt/cow-image2 admin:/mnt # rbd map -p cow-pool --image cow-image2 /dev/rbd3 admin:/mnt # mount /dev/rbd3 /mnt/cow-image2 admin:/mnt # ls ./cow-image2/ base-image-file lost+found --> same file with image1 4). Create a new file in the directory where cow-image1 is mounted admin:/mnt # cd cow-image1 admin:/mnt/cow-image1 # touch additional-file admin:/mnt/cow-image1 # ls additional-file base-image-file lost+found 5). Look in the cow-image2 directory. Although they share the same parent snapshot, you can see that the files contained in each COW image are now different. admin:/mnt # ls ./cow-image2/ base-image-file lost+found Task 7: Flatten a COW Clone and remove the parent image 1). Convert the COW clone called cow-image1 to a standalone rbd image Wait while the flatten process completes. Unlike a clone process this is not instantaneous and can take considerable time. admin:/mnt # rbd flatten cow-pool/cow-image1 Image flatten: 100% complete...done. 2). Check to see that the flatten process has removed the link to the parent snapshot admin:/mnt # rbd -p cow-pool --image cow-image1 info rbd image 'cow-image1': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a1209678cad4 block_name_prefix: rbd_data.26a1209678cad4 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:38:58 2021 access_timestamp: Thu Jan 7 10:38:58 2021 modify_timestamp: Thu Jan 7 10:38:58 2021 admin:/mnt # rbd -p cow-pool --image cow-image2 info rbd image 'cow-image2': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a2fbcec7b8d9 block_name_prefix: rbd_data.26a2fbcec7b8d9 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:47:28 2021 access_timestamp: Thu Jan 7 10:47:28 2021 modify_timestamp: Thu Jan 7 10:47:28 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB 3). Unmount the images admin:/mnt # umount /mnt/cow-image1 admin:/mnt # umount /mnt/cow-image2 admin:/mnt # umount /mnt/cow-base 2.4.6. Configure iSCSI on SES In this lab an iSCSI Target was configured via the iSCSI gateway on our SUSE Enterprise Storage. An image was added to it. An iSCSI initiator then connected to the target, created a filesystem, and mounted it. Task 1: Create a new RBD image in the iscsi-images pool 1). Create a new RBD image using the rbd command: admin:~ # rbd create --size 1024 iscsi-images/fooiscsi 2). Verify the new image has been created in the iscsi-images pool: The new image named fooiscsi should be displayed. admin:~ # rbd ls iscsi-images fooiscsi Task 2: Define a new iSCSI target with the Ceph Dashboard 1). Access the Ceph Dashboard and log in: https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 Username: admin Password: mypassword 2). Once logged in, click on the Block drop-down item near the top. Select iSCSI. 3). With the Overview tab showing for iSCSI, click on the Targets tab near the top. Note: When clicking on the Targets tab, if you see an error that says something about \u201cUnsupported `ceph-iscsi` config version\u2026\u201d, perform the following steps: 1. Close the browser window where the error occurred 2. Restart the mon1 virtual machine. Do this with the following steps: from the Virtual Machine Manager on your lab machine (not in the admin virtual machine), restart the mon1 virtual machine by right-clicking on the mon1 virtual machine > Shut Down > Reboot 3. Wait at least 30 seconds, then from the admin node, open up the browser again and log in to the Ceph Dashboard: https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 Username: admin Password: mypassword 4. Continue the lab as directed below by navigating to the Block > iSCSI section, clicking on the Targets tab, and completing the steps below 4). Click Add. Use the following values: Target IQN: <accept default> Portals: mon2.example.net:172.17.6.132 Images: iscsi-images/fooiscsi ACL authentication: <leave unchecked> Click Create Target. Task 3: Access the new iSCSI target from the admin node 1). On the admin node, launch YaST either the ncurses or GUI interface, and select the iSCSI Initiator module: YaST > Network Services > iSCSI Initiator 2). Select the Discovered Targets tab (alt-v) 3). Select Discovery at the bottom of the frame (alt-d) 4). Add the ip address of mon2: 10.58.121.187. Leave the port as the default of 3260. Select Next. 5). Once again on the Discovered Targets tab, the mon2 target should be listed. With the new target highlighted, select Connect (alt-e) at the bottom of the frame. 6). Leave the Startup (in YaST2) or On boot (in YaST) value as manual. Select Next. 7). Select OK to exit the iscsi client configuration module 8). To verify that the iscsi device is now connected, use the lsscsi command to list devices: You should see there is one disk of type RBD connected on a device file similar to the following: admin:~ # lsscsi [0:0:0:0] cd/dvd QEMU QEMU DVD-ROM 1.4. /dev/sr0 [2:0:0:0] disk SUSE RBD 4.0 /dev/sda 9). Create an ext4 filesystem on the connected device file: admin:~ # mkfs.ext4 /dev/sda mke2fs 1.43.8 (1-Jan-2018) Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: e3896f7e-0664-4b14-85db-0f77cb234c43 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 10). Mount the device to /mnt: admin:~ # mount /dev/sda /mnt 11). Use the mount command to list the connected device: admin:/mnt # mount | grep sda /dev/sda on /mnt type ext4 (rw,relatime,stripe=1024,data=ordered) 12).Change the root user\u2019s home directory and unmount the device: admin:/mnt # cd .. admin:/ # umount /mnt 2.4.7. Mount CephFS Provided by SUSE Enterprise Storage In this lab a ceph user was configured to mount the ceph filesystem provided by the SUSE Enterprise Cluster. A keyfile was generated, then used in the process. Task 1: Verify cephfs configuration of the SES cluster 1). Cephfs requires two pools for operation: one for data, the other for metadata. Verify that the cluster has two pools for this purpose: admin:~ # ceph fs ls name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ] Task 2: Create a secret key file for the admin user on the admin node 1). Because cephx authentication is enabled by default on SUSE Enterprise Storage, a secret key will need to be provided to allow access to mount the ceph filesystem. The admin user (identified \u2013 in this case \u2013 on the system as root) on the admin node has a key, but we will need to either provide it on the command line during the mount process (less secure), or put it in a permissions-restricted file and point to the file when mounting (more secure). If we do not specify the key or a file with the key, we will get an error. The following command will return an error: admin:~ # mount -t ceph mon1:6789:/ /mnt 2021-01-07 14:16:36.924 7f45108a9d80 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.guest.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory mount error 22 = Invalid argument 2). Take secret key value found in the /etc/ceph/ceph.client.admin.keyring file and put it in a new file: admin:~ # cat /etc/ceph/ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" 3). Create a new file and paste the secret key value into it: admin:~ # vi /etc/ceph/admin.secret Put the key value <your key> into the file and save it. 4). Change the permissions of the file to be read only by the user: admin:~ # ls -l /etc/ceph/admin.secret -r-------- 1 root root 41 Jan 5 20:05 /etc/ceph/admin.secret Task 3: Mount the ceph filesystem on the admin node 1). Now that the keyfile is created, we can mount the filesystem: admin:~ # mount -t ceph mon1:6789:/ /mnt -o name=admin,secretfile=/etc/ceph/admin.secret admin:~ # ls -l /mnt total 0 2). Verify that the mount shows as expected: admin:~ # mount | grep ceph 10.58.121.186:6789:/ on /mnt type ceph (rw,relatime,name=admin,secret=<hidden>,acl) 3). Change to the root user\u2019s home directory and unmount the filesystem: admin:~ # cd ~ admin:~ # umount /mnt 2.4.8. Export an NFS Share from SES with NFS Ganesha Task 0: Install and configure Ganesha (Ganesha config location is not configured. Please set the GANESHA_RADOS_POOL_NAMESPACE setting.) admin:~ # zypper in nfs-ganesha admin:/etc/ganesha # cat ganesha.conf NFSv4 { RecoveryBackend = 'rados_cluster'; #RecoveryBackend = 'rados_ng'; } RADOS_URLS { ceph_conf = '/etc/ceph/ceph.conf'; userid = \"admin\"; watch_url = \"rados://data/ganesha-export-index/conf-nfs1\"; } RADOS_KV { pool = \"metadata\"; namespace = \"ganesha-grace\"; nodeid = \"nfs1\"; } %url rados://data/ganesha-export-index/conf-nfs1 admin:/etc/ganesha # ganesha-rados-grace -p metadata -n ganesha-grace add nfs1 nfs2 nfs3 admin:/etc/ganesha # ganesha-rados-grace -p metadata -n ganesha-grace cur=1 rec=0 ====================================================== nfs1 E nfs2 E nfs3 E http://images.45drives.com/ceph/cephfs/nfs-ganesha-ceph.conf Task 1: Create an NFS export using the Ceph Dashboard 1). In a browser, navigate to a monitor to access the Ceph Dashboard and log in: https://10.58.121.186:8443/ Username: admin Password: mypassword 2). Click on the NFS tab near the top of the page 3). Click on the green Add button 4). Click on the Add daemon button to the right and select mon1 5). Complete the configuration with the following values: Storage Backend: Object Gateway Object Storage User: s3user Path: S3CMDTEST NFS Protocol: NFSv3 and NFSv4 checked NFS Tag: <leave blank> Pseudo: /S3BKT Access Type: RW Squash: root_squash Transport Protocol: UDP and TCP checked Clients: <leave default> Click Submit Task 2: Mount the NFS export on the admin node 1). As the root user on the admin node, query the NFS Ganesha gateway node to see what mounts are available: showmount -e mon1 You should see something similar to the following: Export list for mon1: S3CMDTEST (everyone) 2). Mount the available nfs share to the /mnt directory on the admin server: mount -t nfs mon1:/S3BKT /mnt 3). List the nfs mount: mount | grep mnt Note the type listed as nfs4 4). Change to the root user\u2019s home directory and unmount the export: cd umount /mnt 2.4.9. Configure and Mount CIFS In this lab the Samba gateway was configured. A keyring for the Samba gateway was created, the Samba service was modified, and a user created to allow CIFS access to the SES cluster. Task 1: Prepare the CephFS share for CIFS 1). In order for CIFS to work in our SES environment, a valid CephFS share must be available. The CephFS lab previously done in this workbook is sufficient. Using the same configuration that we used previously, mount the CephFS share and give permissions to all users at the root of the share: admin:~ # mount -t ceph mon1:6789:/ /mnt -o name=admin,secretfile=/etc/ceph/admin.secret admin:~ # chmod 777 /mnt admin:~ # l /mnt total 0 drwxrwxrwx 2 root root 0 Oct 5 14:30 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ admin:~ # umount /mnt Task 2: Create a Samba gateway specific keyring on the Ceph admin node and copy it to the Samba gateway node 1). A new keyring will be needed for the Samba gateway to allow access to the Ceph cluster. As root, perform the following: admin:~ # ceph auth get-or-create client.samba.gw mon 'allow r' osd 'allow *' mds 'allow *' -o ceph.client.samba.gw.keyring 2). Copy the new keyring to the Samba gateway node: admin:~ # scp ceph.client.samba.gw.keyring mon1:/etc/ceph/ ceph.client.samba.gw.keyring admin:~ # ssh mon1 Last login: Thu Jan 7 14:35:58 2021 from 10.58.121.181 mon1:~ # ls -l /etc/ceph/ total 12 -rw-r--r-- 1 root root 66 Jan 7 15:15 ceph.client.samba.gw.keyring -rw-r--r-- 1 root root 1095 Jan 5 22:44 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap Task 3: Configure Samba on the Samba gateway node 1). The /etc/samba/smb.conf file will need to be edited to allow CIFS access to the storage cluster. On the mon1 node, replace all of the contents of the file with the following: admin:~ # ssh mon1 mon1:~ # vi /etc/samba/smb.conf mon1:/etc/samba # cat smb.conf [global] netbios name = SAMBA-GW clustering = no idmap config * : backend = tdb2 passdb backend = tdbsam # disable print server load printers = no smbd: backgroundqueue = no [ceph-smb] path = / vfs objects = ceph ceph: config_file = /etc/ceph/ceph.conf ceph: user_id = samba.gw read only = no oplocks = no kernel share modes = no 2). Create a smb user on the mon1 node named joesmb with a password of mypassword: mon1:/etc/samba # useradd joesmb mon1:/etc/samba # passwd joesmb ---> 123 Add joesmb to the smb password database with a password of mypassword: mon1:/etc/samba # smbpasswd -a joesmb New SMB password: ---> 123 Retype new SMB password: ---> 123 Added user joesmb. 3). Start and enable the smb and nmb daemons on mon1: mon1:/etc/samba # systemctl start smb nmb mon1:/etc/samba # systemctl enable smb nmb Created symlink /etc/systemd/system/multi-user.target.wants/smb.service \u2192 /usr/lib/systemd/system/smb.service. Created symlink /etc/systemd/system/multi-user.target.wants/nmb.service \u2192 /usr/lib/systemd/system/nmb.service. 4). Unmount the filesystem: mon1:~ # umount /mnt umount: /mnt: not mounted. Task 4: Connect a client to the Samba gateway 1). On the admin node, verify that the Samba gateway is sharing via CIFS. The password is 123 admin:~ # smbclient -U joesmb -L //mon1 Enter WORKGROUP\\joesmb's password: ---> 123 Sharename Type Comment --------- ---- ------- ceph-smb Disk IPC$ IPC IPC Service (Samba 4.9.5-git.373.26895a83dbf3.44.1-SUSE-oS15.0-x86_64) Reconnecting with SMB1 for workgroup listing. Server Comment --------- ------- Workgroup Master --------- ------- GLOBAL CNPVGVSYB900 WORKGROUP SAMBA-GW 2). Connect to the ceph-smb share as joesmb. The password is 123 admin:~ # smbclient -U joesmb //mon1/ceph-smb Enter WORKGROUP\\joesmb's password: ---> 123 tree connect failed: NT_STATUS_BAD_NETWORK_NAME You should see output similar to the following: Try \u201chelp\u201d to get a list of possible commands. smb: \\>","title":"SUSE Enterprise Storage 6 Installation and Basic Operation"},{"location":"linux/SES/linux_ses_demo/#suse-enterprise-storage-6-installation-and-basic-operation","text":"","title":"SUSE Enterprise Storage 6 Installation and Basic Operation"},{"location":"linux/SES/linux_ses_demo/#1-installation","text":"","title":"1. Installation"},{"location":"linux/SES/linux_ses_demo/#11-environment-setup","text":"In this demo, I use below environment, including VM setting and software installed. All VMs installed here was built on a physical host 10.58.121.68 . Host Server: 10.58.121.68 root / rootroot Account root / root123 Gateway: 10.58.120.1 Network Mask: 255.255.254.0 Nameserver: 10.58.32.32 10.33.50.20 Domain Search sha.me.corp dhcp.sha.me.corp me.corp ind.me.corp bgr.me.corp SUSE Server 15 SP1 Extensions and Modules were installed as below. [x] SUSE Enterprise Storage 6 [x] Basesystem Module 15 SP1 x86_64 [x] Server Applications Module 15 SP1 x86_64 Disable Services is as below: AppArmor Firewall Enable Services is as below. SSH Register SLES15.1 to local SMT. # SUSEConnect --url https://smtproxy.ind.me.corp Demo Environment summary is below. Alias Host Name Memory Disk eth0 eth0 mac address sles01 admin (salt-master) 16GB Disk1: 20G 10.58.121.181/23 52:54:00:23:7d:cd sles02 data1 16GB Disk1: 20G 10.58.121.182/23 52:54:00:5f:ce:6f Disk2: 8G Disk3: 8G Disk4: 8G sles03 data2 16GB Disk1: 20G 10.58.121.183/23 52:54:00:6f:f2:23 Disk2: 8G Disk3: 8G Disk4: 8G sles04 data3 16GB Disk1: 20G 10.58.121.184/23 52:54:00:93:4c:67 Disk2: 8G Disk3: 8G Disk4: 8G sles05 data4 16GB Disk1: 20G 10.58.121.185/23 52:54:00:90:b0:b0 Disk2: 8G Disk3: 8G Disk4: 8G sles06 mon1 16GB Disk1: 20G 10.58.121.186/23 52:54:00:46:43:7a sles07 mon2 16GB Disk1: 20G 10.58.121.187/23 52:54:00:00:fe:6b sles08 mon3 16GB Disk1: 20G 10.58.121.188/23 52:54:00:60:a3:92 Add hostname to file /etc/hosts (all nodes) If you do not specify a cluster network during Ceph deployment, it assumes a single public network environment. Make sure that the fully qualified domain name (FQDN) of each node can be resolved to the public network IP address by all other nodes. # vi /etc/hosts 10.58.121.181 admin.sha.me.corp admin salt 10.58.121.182 data1.sha.me.corp data1 10.58.121.183 data2.sha.me.corp data2 10.58.121.184 data3.sha.me.corp data3 10.58.121.185 data4.sha.me.corp data4 10.58.121.186 mon1.sha.me.corp mon1 10.58.121.187 mon2.sha.me.corp mon2 10.58.121.188 mon3.sha.me.corp mon3 Add all nodes as trust ssh access (root account) # cd ~ # ssh-keygen -t rsa # ssh-copy-id -i ~/.ssh/id_rsa.pub root@admin # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data1 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data2 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data3 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@data4 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon1 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon2 # ssh-copy-id -i ~/.ssh/id_rsa.pub root@mon3 # ssh admin.sha.me.corp # ssh data1.sha.me.corp # ssh data2.sha.me.corp # ssh data3.sha.me.corp # ssh data4.sha.me.corp # ssh mon1.sha.me.corp # ssh mon2.sha.me.corp # ssh mon3.sha.me.corp # ssh salt # ssh admin # ssh data1 # ssh data2 # ssh data3 # ssh data4 # ssh mon1 # ssh mon2 # ssh mon3 Disable firewall (all nodes) # sudo /sbin/SuSEfirewall2 off # firewall-cmd --state not running # systemctl stop firewalld.service # systemctl status firewalld.service firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: man:firewalld(1) Disable IPv6 (all nodes) and Set kernel pid to max value (all nodes) # vi /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 kernel.pid_max = 4194303 # sysctl -p Set DEV_ENV=true in /etc/profile.local in all nodes Install basic software (all nodes) # zypper in -y -t pattern yast2_basis base # zypper in -y net-tools vim man sudo tuned irqbalance # zypper in -y ethtool rsyslog iputils less supportutils-plugin-ses # zypper in -y net-tools-deprecated tree wget Configure NTP service (all nodes), Setting via YaST2 and add server cn.pool.ntp.,org . And /etc/chrony.conf file looks like below. admin:~ # cat /etc/chrony.conf # Use public servers from the pool.ntp.org project. pool cn.pool.ntp.org iburst ! pool pool.ntp.org iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second. makestep 1.0 3 # Enable kernel synchronization of the real-time clock (RTC). rtcsync # Enable hardware timestamping on all interfaces that support it. #hwtimestamp * # Increase the minimum numbgr of selectable sources required to adjust # the system clock. #minsources 2 # Allow NTP client access from local network. #allow 192.168.0.0/16 # Serve time even if not synchronized to a time source. #local stratum 10 # Specify file containing keys for NTP authentication. #keyfile /etc/chrony.keys # Get TAI-UTC offset and leap seconds from the system tz database. #leapsectz right/UTC # Specify directory for log files. logdir /var/log/chrony # Select which information is logged. #log measurements statistics tracking # Also include any directives found in configuration files in /etc/chrony.d include /etc/chrony.d/*.conf Make /etc/chrony.conf effective. # systemctl enable chronyd.service # systemctl restart chronyd.service # systemctl status chronyd.service # chronyc sources","title":"1.1. Environment Setup"},{"location":"linux/SES/linux_ses_demo/#12-install-packages","text":"Install salt-minion on all nodes. And start the service. Hostname is in file `/etc/salt/minion_id` # zypper in -y salt-minion Uncomment below to let all nodes know who is master # vi /etc/salt/minion master: salt # systemctl enable salt-minion.service # systemctl start salt-minion.service # systemctl status salt-minion.service Install Ceph in admin node. Check log in /var/log/salt admin:~ # zypper in -y salt-master admin:~ # systemctl enable salt-master.service admin:~ # systemctl start salt-master.service admin:~ # systemctl status salt-master.service Note: ganesha will be installed on mon1, not admin node. admin:~ # zypper se ganesha admin:~ # zypper in nfs-ganesha admin:~ # systemctl enable nfs-ganesha admin:~ # systemctl start nfs-ganesha admin:~ # systemctl status nfs-ganesha admin:~ # cd /var/log/salt List fingerprints of all unaccepted minion keys on the Salt master. admin:~ # salt-key -F Local Keys: master.pem: c0:e5:***:04:c7 master.pub: 43:73:***:6a:34 Unaccepted Keys: admin.sha.me.corp: fe:51:***:b9:48 mon1.sha.me.corp: 94:13:***:91:63 mon2.sha.me.corp: c0:fd:***:39:3f mon3.sha.me.corp: 38:fc:***:2e:05 data1.sha.me.corp: b6:6c:***:63:4f data2.sha.me.corp: ab:14:***:c8:ac data3.sha.me.corp: 90:3f:***:76:3b data4.sha.me.corp: d8:12:***:f1:20 If the minions' fingerprints match, accept them admin:~ # salt-key --accept-all The following keys are going to be accepted: Unaccepted Keys: admin.sha.me.corp mon1.sha.me.corp mon2.sha.me.corp mon3.sha.me.corp data1.sha.me.corp data2.sha.me.corp data3.sha.me.corp data4.sha.me.corp Proceed? [n/Y] Y Key for minion admin.sha.me.corp accepted. Key for minion mon1.sha.me.corp accepted. Key for minion mon2.sha.me.corp accepted. Key for minion mon3.sha.me.corp accepted. Key for minion data1.sha.me.corp accepted. Key for minion data2.sha.me.corp accepted. Key for minion data3.sha.me.corp accepted. Key for minion data4.sha.me.corp accepted. Verify that the keys have been accepted admin:~ # salt-key -F admin:~ # salt-key --list-all Accepted Keys: admin.sha.me.corp data1.sha.me.corp data2.sha.me.corp data3.sha.me.corp data4.sha.me.corp mon1.sha.me.corp mon2.sha.me.corp mon3.sha.me.corp Denied Keys: Unaccepted Keys: Rejected Keys: Zero out all drivers which will be used as OSDs (optional) data1:~ lsblk data1:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done data2:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done data3:~ # for I in {b,c,d}; do dd if=/dev/zero of=dev/sd$i bs=512 count=40 oflag=direct; done Install DeepSea admin:~ # zypper in -y deepsea Edit the /srv/pillar/ceph/deepsea_minions.sls file on the Salt master (admin node) and add or replace the following line: admin:~ # vi /srv/pillar/ceph/deepsea_minions.sls # Choose minions with a deepsea grain deepsea_minions: 'G@deepsea:*' #Match all Salt minions in the cluster # Choose all minions # deepsea_minions: '*' #Match all minions with the 'deepsea' grain # Choose custom Salt targeting # deepsea_minions: 'ses*' # deepsea_minions: 'ceph* or salt' Target the Minions Affirm salt-master (admin node) can communicate with the minions. And deploy the grains from admin node to all minions. admin:~ # salt '*' test.ping mon1.sha.me.corp: True data4.sha.me.corp: True data3.sha.me.corp: True data2.sha.me.corp: True data1.sha.me.corp: True mon3.sha.me.corp: True admin.sha.me.corp: True mon2.sha.me.corp: True Apply the 'deepsea' grain to a group of minions, and target with a DeepSea Grain admin:~ # salt '*' grains.append deepsea default data3.sha.me.corp: The val default was already in the list deepsea mon2.sha.me.corp: The val default was already in the list deepsea data1.sha.me.corp: The val default was already in the list deepsea data4.sha.me.corp: The val default was already in the list deepsea data2.sha.me.corp: The val default was already in the list deepsea mon3.sha.me.corp: The val default was already in the list deepsea admin.sha.me.corp: The val default was already in the list deepsea mon1.sha.me.corp: The val default was already in the list deepsea admin:~ # salt -G 'deepsea:*' test.ping (The following command is an equivalent) admin:~ # salt -C 'G@deepsea:*' test.ping admin.sha.me.corp: True data3.sha.me.corp: True mon1.sha.me.corp: True mon2.sha.me.corp: True data2.sha.me.corp: True data4.sha.me.corp: True mon3.sha.me.corp: True data1.sha.me.corp: True","title":"1.2. Install Packages"},{"location":"linux/SES/linux_ses_demo/#13-stage-0-the-preparation","text":"Run Stage 0\u2014the preparation During this stage, all required updates are applied and your system may be rebooted. If there are errors, re-run the stage. admin:~ # deepsea stage run ceph.stage.0 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.0 admin:~ # salt-run state.orch ceph.stage.prep Run Stage 1\u2014the discovery Here all hardware in your cluster is being detected and necessary information for the Ceph configuration is being collected. The discovery stage collects data from all minions and creates configuration fragments that are stored in the directory /srv/pillar/ceph/proposals . The data are stored in the YAML format in *.sls or *.yml files admin:~ # deepsea stage run ceph.stage.1 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.1 admin:~ # salt-run state.orch ceph.stage.discovery","title":"1.3. Stage 0 \u2014 the preparation"},{"location":"linux/SES/linux_ses_demo/#14-stage-2-the-configuration","text":"Run Stage 2 \u2014 the configuration \u2014 you need to prepare configuration data in a particular format. The assignment follows this pattern: role-ROLE_NAME/PATH/FILES_TO_INCLUDE (NOTE, the parent directory of PATH is /srv/pillar/ceph/ ) To avoid trouble with performance and the upgrade procedure, do not deploy the Ceph OSD, Metadata Server, or Ceph Monitor role to the Admin Node. Monitors, Metadata Server, and gateways can be co-located on the OSD nodes. If you are using CephFS, S3/Swift, iSCSI, at least two instances of the respective roles (Metadata Server, Object Gateway, iSCSI) are required for redundancy and availability. admin:~ # cp /usr/share/doc/packages/deepsea/examples/policy.cfg-rolebased /srv/pillar/ceph/proposals/policy.cfg admin:~ # vi /srv/pillar/ceph/proposals/policy.cfg ## Cluster Assignment # Add all nodes into Ceph cluster cluster-ceph/cluster/*.sls ## Roles # The Admin node fills the \u201cmaster\u201d and \u201cadmin\u201d roles for DeepSea # The master role is mandatory, always add a similar line to the following role-master/cluster/admin*.sls role-admin/cluster/admin*.sls # Monitoring # Cluster monitoring and data graphs, most commonly they run on Admin node # NFS Ganesha is configured via the file /etc/ganesha/ganesha.conf # As additional configuration is required to install NFS Ganesha, you can install NFS Ganesha later. # The following requirements need to be met before DeepSea stages 2 and 4 can be executed to install NFS Ganesha: # a)At least one node needs to be assigned the role-ganesha. # b)You can define only one role-ganesha per minion. # c)NFS Ganesha needs either an Object Gateway or CephFS to work, otherwise the validation will fail in Stage 3. # d)The kernel based NFS needs to be disabled on minions with the role-ganesha role. role-prometheus/cluster/admin*.sls role-grafana/cluster/mon1*.sls # MON # The minion will provide the monitor service to the Ceph cluster role-mon/cluster/mon*.sls # MGR # The Ceph manager daemon which collects all the state information from the whole cluster # Deploy it on all minions where you plan to deploy the Ceph monitor role role-mgr/cluster/mon1*.sls # MDS # The minion will provide the metadata service to support CephFS role-mds/cluster/mon*.sls # IGW # The minion will act as an iSCSI Gateway role-igw/cluster/mon2*.sls # RGW # The minion will act as an Object Gateway role-rgw/cluster/mon3*.sls # Storage # Use this role to specify storage nodes # It points to data1~4 nodes with a wildcard. role-storage/cluster/data*.sls # COMMON # It includes configuration files generated during the discovery (Stage 1) # Accept the default values for common configuration parameters such as fsid and public_network config/stack/default/global.yml config/stack/default/ceph/cluster.yml admin:~ # deepsea stage run ceph.stage.2 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.2 admin:~ # salt-run state.orch ceph.stage.configure After the command succeeds, run below command to view the pillar data for the specified minions admin:~ # salt 'mon*' pillar.items admin:~ # salt '*' saltutil.pillar_refresh Check time server (admin node) (the directory /srv/pillar/ceph/stack was initialized after deepsea installed, but global.yml file was not created yet until stage 2) By default, DeepSea uses the Admin Node as the time server for other cluster nodes. admin:~ # cat /srv/pillar/ceph/stack/default/global.yml (this file will be generated after stage 2) monitoring: prometheus: metric_relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] rule_files: [] scrape_interval: ceph: 10s grafana: 10s node_exporter: 10s prometheus: 10s target_partition: ceph: 1/1 grafana: 1/1 node_exporter: 1/1 prometheus: 1/1 time_server: admin.sha.me.corp Verify network (the directory /srv/pillar/ceph/stack was initialized after deepsea installed, but cluster.yml file was not created until stage 2 ) admin:~ # cat /srv/pillar/ceph/stack/ceph/cluster.yml --nothing admin:~ # cat /srv/pillar/ceph/stack/default/ceph/cluster.yml available_roles: - storage - admin - mon - mds - mgr - igw - grafana - prometheus - storage - rgw - ganesha - client-cephfs - client-radosgw - client-iscsi - client-nfs - benchmark-rbd - benchmark-blockdev - benchmark-fs - master cluster_network: 10.58.120.0/23 fsid: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 public_network: 10.58.120.0/23 Note: customized file will overwrite default one. Default file: /srv/pillar/ceph/stack/default/ceph/cluster.yml Customized file: /srv/pillar/ceph/stack/ceph/cluster.yml Check DriveGroup DriveGroups specify the layouts of OSDs in the Ceph cluster. They are defined in a single file /srv/salt/ceph/configuration/files/drive_groups.yml admin:~ # cat /srv/salt/ceph/configuration/files/drive_groups.yml default_drive_group_name: target: 'data*' <--original: 'I@role:storage' data_devices: all: true admin:~ # salt 'data*' pillar.items | grep -B5 stroage","title":"1.4. Stage 2 \u2014 the configuration"},{"location":"linux/SES/linux_ses_demo/#15-stage-3-the-deployment","text":"Run Stage 3 \u2014 the deployment \u2014 creates a basic Ceph cluster with mandatory Ceph services. This Deployment stage has more than 60 automated steps. Be patient and make sure the stage completes successfully before proceeding. Set dev environment and disable subvolume: admin:~ # vi /srv/pillar/ceph/stack/global.yml admin:~ # vi /srv/pillar/ceph/stack/default/global.yml monitoring: prometheus: metric_relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] relabel_config: ceph: [] grafana: [] node_exporter: [] prometheus: [] rule_files: [] scrape_interval: ceph: 10s grafana: 10s node_exporter: 10s prometheus: 10s target_partition: ceph: 1/1 grafana: 1/1 node_exporter: 1/1 prometheus: 1/1 time_server: admin.sha.me.corp DEV_ENV: True subvolume_init: disabled admin:~ # salt '*' saltutil.pillar_refresh Note: customized file will overwrite default one. Default file: /srv/pillar/ceph/stack/default/global.yml Customized file: /srv/pillar/ceph/stack/global.yml admin:~ # deepsea stage run ceph.stage.3 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.3 admin:~ # salt-run state.orch ceph.stage.deploy After the command succeeds, run the following to check the status: admin:~ # ceph -s Below comands return you a structure of matching disks based on your DriveGroups. (will show available information after stage 3) admin:~ # salt-run disks.Report admin:~ # salt-run disks.list admin:~ # salt-run disks.details","title":"1.5. Stage 3 \u2014 the deployment"},{"location":"linux/SES/linux_ses_demo/#16-stage-4-the-services","text":"Run Stage 4 \u2014 the services \u2014 additional features of Ceph like iSCSI, Object Gateway and CephFS can be installed in this stage. Each is optional. admin:~ # deepsea stage run ceph.stage.4 (The following commands are equivalents) admin:~ # salt-run state.orch ceph.stage.4 admin:~ # salt-run state.orch ceph.stage.services admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log Before logon to dashboard via url, need get credentials first admin:~ # salt-call grains.get dashboard_creds local: ---------- admin: <your password> --> the password was changed to mypassword to log on to dashboard admin:~ # ceph mgr services { \"dashboard\": \"https://mon1.sha.me.corp:8443/\", \"prometheus\": \"http://mon1.sha.me.corp:9283/\" } https://10.58.121.186:8443 http://10.58.121.186:9283 admin:~ # watch ceph -s Every 2.0s: ceph -s admin: Mon Oct 5 14:41:51 2020 cluster: id: <id> health: HEALTH_OK services:s: ceph -s mon: 3 daemons, quorum mon1,mon2,mon3 (age 87m) mgr: mon1(active, since 82m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 85m), 12 in (since 85m) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 576 pgs objects: 213 objects, 4.2 KiB usage: 12 GiB used, 84 GiB / 96 GiB avail pgs: 576 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr","title":"1.6. Stage 4 \u2014 the services"},{"location":"linux/SES/linux_ses_demo/#17-stage-5-the-removal-stage","text":"Run Stage 5 \u2014 the removal stage. This stage is not mandatory and during the initial setup it is usually not needed. In this stage the roles of minions and also the cluster configuration are removed. You need to run this stage when you need to remove a storage node from your cluster. admin:~ # deepsea stage run ceph.stage.","title":"1.7. Stage 5 \u2014 the removal stage"},{"location":"linux/SES/linux_ses_demo/#18-installation-guide","text":"Deployment Guide (EN) Deployment Guide (ZH)","title":"1.8. Installation Guide"},{"location":"linux/SES/linux_ses_demo/#19-issues-during-installation","text":"[ERROR]: The Salt Master has cached the public key for this node SOLUTION : Restart minions service [ERROR]: This server_id is computed nor by Adler32 neither by CRC32 [QUESTION]: How to change new salt key Stop salt-minion service # systemctl stop salt-minion Delete salt-minion pulic key # rm /etc/salt/pki/minion/minion.pub # rm /etc/salt/pki/minion/minion.pem Change new minion_id admin:~ # echo admin.sha.me.corp > /etc/salt/minion_id data1:~ # echo data1.sha.me.corp > /etc/salt/minion_id data2:~ # echo data2.sha.me.corp > /etc/salt/minion_id data3:~ # echo data3.sha.me.corp > /etc/salt/minion_id data4:~ # echo data4.sha.me.corp > /etc/salt/minion_id mon1:~ # echo mon1.sha.me.corp > /etc/salt/minion_id mon2:~ # echo mon2.sha.me.corp > /etc/salt/minion_id mon3:~ # echo mon3.sha.me.corp > /etc/salt/minion_id Delete old ID on admin node # salt-key -D Restart salt-minion service # systemctl restart salt-minion Accept all new key on admin node admin:~ # salt-key -L admin:~ # salt-key -A or admin:~ # salt-key -a admin.sha.me.corp data1:~ # salt-key -a data1.sha.me.corp data2:~ # salt-key -a data2.sha.me.corp data3:~ # salt-key -a data3.sha.me.corp data4:~ # salt-key -a data4.sha.me.corp mon1:~ # salt-key -a mon1.sha.me.corp mon2:~ # salt-key -a mon2.sha.me.corp mon3:~ # salt-key -a mon3.sha.me.corp [ERROR] ['/var/lib/ceph subvolume missing on mon3.sha.me.corp', '/var/lib/ceph subvolume missing on mon1.sha.me.corp', '/var/lib/ceph subvolume missing on mon2.sha.me.corp', 'See /srv/salt/ceph/subvolume/README.md'] SOLUTION Edit /srv/pillar/ceph/stack/global.yml and add the following line: subvolume_init: disabled Then refresh the Salt pillar and re-run DeepSea stage.3: admin:~ # salt '*' saltutil.refresh_pillar admin:~ # salt-run state.orch ceph.stage.3 After DeepSea successfully finished stage.3, the Ceph Dashboard will be running. Refer to Book \u201cAdministration Guide\u201d, Chapter 20 \u201cCeph Dashboard\u201d for a detailed overview of Ceph Dashboard features. To list nodes running dashboard, run: admin:~ # ceph mgr services | grep dashboard To list admin credentials, run: admin:~ # salt-call grains.get dashboard_creds [ERROR] module function cephprocesses.wait executed on nodes mon1~3 and data1~4 in Stage 0 SOLUTION Check below on all nodes # salt-call cephprocesses.check ERROR: process ceph-mds for role mds is not running ERROR: process radosgw for role rgw is not running admin:~ # ceph -s Clock skew detected on mon ceph (mon.mon2, mon.mon3) Set time server to public server (China) # chronyc sources","title":"1.9. Issues during installation"},{"location":"linux/SES/linux_ses_demo/#110-shutting-down-the-whole-ceph-cluster","text":"Shut down or disconnect any clients accessing the cluster. To prevent CRUSH from automatically rebalancing the cluster, set the cluster to noout: # ceph osd set noout Other flags you can set per osd: nodown noup noin noout Disable safety measures and run the ceph.shutdown runner: admin:~ # salt-run disengage.safety safety is now disabled for cluster ceph admin:~ # salt-run state.orch ceph.shutdown admin.sha.me.corp_master: Name: set noout - Function: salt.state - Result: Changed Started: - 14:32:14.398022 Duration: 2266.75 ms Name: Shutting down radosgw for rgw - Function: salt.state - Result: Changed Started: - 14:32:16.665452 Duration: 1461.23 ms Name: Shutting down cephfs - Function: salt.state - Result: Changed Started: - 14:32:18.127353 Duration: 30326.193 ms Name: Shutting down iscsi - Function: salt.state - Result: Clean Started: - 14:32:48.454187 Duration: 30142.468 ms Name: Shutting down storage - Function: salt.state - Result: Changed Started: - 14:33:18.597321 Duration: 10841.45 ms Name: Shutting down mgr - Function: salt.state - Result: Changed Started: - 14:33:29.439442 Duration: 29209.141 ms Name: Shutting down mon - Function: salt.state - Result: Changed Started: - 14:33:58.649221 Duration: 30519.97 ms Summary for admin.sha.me.corp_master ------------ Succeeded: 7 (changed=6) Failed: 0 ------------ Total states run: 7 Total run time: 134.767 s Power off all cluster nodes: admin:~ # salt -C 'G@deepsea:*' cmd.run \"shutdown -h\" Broadcast message from root@admin (Sat 2021-03-06 14:40:37 CST): The system is going down for poweroff at Sat 2021-03-06 14:41:37 CST! admin.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon2.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data2.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon3.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data3.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data4.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. mon1.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel. data1.sha.me.corp: Shutdown scheduled for Sat 2021-03-06 14:41:37 CST, use 'shutdown -c' to cancel.","title":"1.10. Shutting Down the Whole Ceph Cluster"},{"location":"linux/SES/linux_ses_demo/#111-starting-stopping-and-restarting-services-using-targets","text":"# ls /usr/lib/systemd/system/ceph*.target ceph.target ceph-osd.target ceph-mon.target ceph-mgr.target ceph-mds.target ceph-radosgw.target ceph-rbd-mirror.target To start/stop/restart all Ceph services on the node, run: # systemctl start ceph.target # systemctl stop ceph.target # systemctl restart ceph.target To start/stop/restart all OSDs on the node, run: # systemctl start ceph-osd.target # systemctl stop ceph-osd.target # systemctl restart ceph-osd.target Starting, Stopping, and Restarting Individual Services # systemctl list-unit-files --all --type=service ceph* ceph-osd@.service ceph-mon@.service ceph-mds@.service ceph-mgr@.service ceph-radosgw@.service ceph-rbd-mirror@.service Example : # systemctl status ceph-mon@HOSTNAME.service (e.g., ceph-mon@mon1.service) # systemctl start ceph-osd@1.service # systemctl stop ceph-osd@1.service # systemctl restart ceph-osd@1.service # systemctl status ceph-osd@1.service","title":"1.11. Starting, Stopping, and Restarting Services Using Targets"},{"location":"linux/SES/linux_ses_demo/#112-restarting-all-services","text":"# salt-run state.orch ceph.restart","title":"1.12. Restarting All Services"},{"location":"linux/SES/linux_ses_demo/#113-restarting-specific-services","text":"Example: salt-run state.orch ceph.restart.service_name # salt-run state.orch ceph.restart.mon # salt-run state.orch ceph.restart.mgr # salt-run state.orch ceph.restart.osd # salt-run state.orch ceph.restart.mds # salt-run state.orch ceph.restart.rgw # salt-run state.orch ceph.restart.igw # salt-run state.orch ceph.restart.ganesha Default log file path of salt-run: /var/log/salt/master","title":"1.13. Restarting Specific Services"},{"location":"linux/SES/linux_ses_demo/#2-basic-operation","text":"","title":"2. Basic Operation"},{"location":"linux/SES/linux_ses_demo/#21-pools-and-data-placement","text":"","title":"2.1. Pools and Data Placement"},{"location":"linux/SES/linux_ses_demo/#211-enable-the-pg-autoscaler-and-balancer-modules","text":"","title":"2.1.1. Enable the PG Autoscaler and Balancer Modules"},{"location":"linux/SES/linux_ses_demo/#task-1-view-the-state-of-all-the-manager-modules","text":"List all the existing Manager Modules admin:~ # ceph mgr module ls | less","title":"Task 1: View the state of all the Manager Modules"},{"location":"linux/SES/linux_ses_demo/#task-2-list-the-existing-pools","text":"List the pools that already exist in the cluster admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log List the pools again, but this time using the rados command: admin:~ # rados lspools iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log View the output of placement group autoscale-status command for the pools admin:~ # ceph osd pool autoscale-status Error ENOTSUP: Module 'pg_autoscaler' is not enabled (required by command 'osd pool autoscale-status'): use `ceph mgr module enable pg_autoscaler` to enable it","title":"Task 2: List the Existing Pools"},{"location":"linux/SES/linux_ses_demo/#task-3-enable-the-pg_autoscaler-module","text":"Enable the pg_autoscaler module admin:~ # ceph mgr module enable pg_autoscaler admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 128 32 warn cephfs_data 0 3.0 98256M 0.0000 1.0 256 32 warn cephfs_metadata 7285 3.0 98256M 0.0000 4.0 64 16 warn .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 18078 3.0 98256M 0.0000 1.0 32 warn Note that for the iscsi-images pool the PG_NUM value is 128. And note that the NEW PG_NUM value is 32. The PGs won\u2019t be adjusted automatically because the default setting for the autoscaler is \u201cwarn\u201d. Note the last column (mode) that shows status \u201cwarn\u201d for all the pools. Check current status. \u201chave too many placement groups\u201d. That\u2019s exactly what we want the pg_autoscaler to tell us. admin:~ # ceph health HEALTH_WARN 3 pools have too many placement groups Turn off the pg_autoscaler feature for CephFS pools admin:~ # ceph osd pool set cephfs_data pg_autoscale_mode off set pool 2 pg_autoscale_mode to off admin:~ # ceph osd pool set cephfs_metadata pg_autoscale_mode off set pool 3 pg_autoscale_mode to off admin:~ # ceph health HEALTH_WARN 1 pools have too many placement groups Set the pg_autoscaler mode to \u201con\u201d for the iscs-images pool: admin:~ # ceph osd pool set iscsi-images pg_autoscale_mode on set pool 1 pg_autoscale_mode to on admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 128 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 256 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 64 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 18078 3.0 98256M 0.0000 1.0 32 warn Turn on the pg_autoscaler feature for CephFS pools admin:~ # ceph osd pool set cephfs_data pg_autoscale_mode on set pool 2 pg_autoscale_mode to on admin:~ # ceph osd pool set cephfs_metadata pg_autoscale_mode on set pool 3 pg_autoscale_mode to on PG numbgrs must always be a power of 2 admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 35900 3.0 98256M 0.0000 1.0 32 warn Show the cluster health admin:~ # ceph -s cluster: id: <id> health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 4w) mgr: mon1(active, since 46h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 8w), 12 in (since 8w) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 433 pgs objects: 246 objects, 4.7 KiB usage: 13 GiB used, 83 GiB / 96 GiB avail pgs: 0.462% pgs not active 431 active+clean 2 peering io: client: 45 KiB/s rd, 0 B/s wr, 44 op/s rd, 28 op/s wr","title":"Task 3: Enable the pg_autoscaler module"},{"location":"linux/SES/linux_ses_demo/#task-4-turn-on-the-placement-group-balancer-feature","text":"1). Show the \u201cstatus\u201d of the balancer: admin:~ # ceph balancer status { \"plans\": [], \"active\": false, \"last_optimize_started\": \"\", \"last_optimize_duration\": \"\", \"optimize_result\": \"\", \"mode\": \"none\" } admin:~ # ceph balancer on admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:22:57 2021\", \"last_optimize_duration\": \"0:00:00.001379\", \"optimize_result\": \"Please do \\\"ceph balancer mode\\\" to choose a valid mode first\", \"mode\": \"none\" } 2). Set the mode for the balancer to \u201cupmap\u201d: admin:~ # ceph balancer mode upmap Error EPERM: min_compat_client \"jewel\" < \"luminous\", which is required for pg-upmap. Try \"ceph osd set-require-min-compat-client luminous\" before enabling this mode admin:~ # ceph osd set-require-min-compat-client luminous --yes-i-really-mean-it set require_min_compat_client to luminous admin:~ # ceph balancer mode upmap admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:23:57 2021\", \"last_optimize_duration\": \"0:00:00.001807\", \"optimize_result\": \"Please do \\\"ceph balancer mode\\\" to choose a valid mode first\", \"mode\": \"upmap\" } 3). Create a balancer optimization plan called basic-plan. Ceph won\u2019t let you do this yet. Because you just recently enabled the pg_autoscaler, Ceph is moving objects around, and the PGs are quite busy with re-peering. admin:~ # ceph balancer optimize basic-plan Error EINVAL: Balancer enabled, disable to optimize manually 4). Show the details of the plan: This shows what \u201cexecute\u201d-ing the plan will do, itemizing which PGs will be affected. admin:~ # ceph balancer show basic-plan Error ENOENT: plan basic-plan not found <--- failed here 5). Show the effectiveness of the plan by comparing the current score for the pre-planned balancing and the score for the planned balancing: admin:~ # ceph balancer eval current cluster score 0.118731 (lower is better) admin:~ # ceph balancer eval basic-plan Error EINVAL: option \"basic-plan\" not a plan or a pool 6). Show the status of the balancer, now with all of these settings having been set, but before putting them into effect: The pg_autoscaler has already optimized the balance of PGs sufficiently. That\u2019s because this cluster is very small and has no significant content stored in it yet. If that\u2019s the case, you would see a message like \u201cError EALREADY: Unable to find further optimization, or pool(s)' pg_num is decreasing, or distribution is already perfect.\u201d If you receive this message, then you will not be able to complete this task. At some later time in the course you may choose to revisit this task to complete it. admin:~ # ceph balancer status { \"plans\": [], \"active\": true, \"last_optimize_started\": \"Mon Jan 4 20:32:59 2021\", \"last_optimize_duration\": \"0:00:00.004170\", \"optimize_result\": \"Unable to find further optimization, or pool(s) pg_num is decreasing, or distribution is already perfect\", \"mode\": \"upmap\" } 7). Set the basic-plan into effect: admin:~ # ceph balancer execute basic-plan Error EINVAL: Balancer enabled, disable to execute a plan 8). Now re-show the current score for the balanced cluster: admin:~ # ceph balancer eval current cluster score 0.118731 (lower is better)","title":"Task 4: Turn on the Placement Group balancer feature"},{"location":"linux/SES/linux_ses_demo/#212-manipulate-erasure-code-profiles","text":"","title":"2.1.2. Manipulate Erasure Code Profiles"},{"location":"linux/SES/linux_ses_demo/#task-1-display-a-list-of-the-current-erasure-code-profiles","text":"admin:~ # ceph osd erasure-code-profile no valid command found; 4 closest matches: osd erasure-code-profile set <name> {<profile> [<profile>...]} {--force} osd erasure-code-profile get <name> osd erasure-code-profile rm <name> osd erasure-code-profile ls Error EINVAL: invalid command admin:~ # ceph osd erasure-code-profile ls default","title":"Task 1: Display a list of the current Erasure Code profiles"},{"location":"linux/SES/linux_ses_demo/#task-2-examine-the-details-of-the-default-ec-profile","text":"admin:~ # ceph osd erasure-code-profile get default k=2 m=1 plugin=jerasure technique=reed_sol_van","title":"Task 2: Examine the details of the default EC profile"},{"location":"linux/SES/linux_ses_demo/#task-3-create-and-remove-a-new-ec-profile","text":"1. Create a new EC profile from the command line. This is going to be a \u201cbad\u201d profile that will be removed in a moment: admin:~ # ceph osd erasure-code-profile set bad_profile k=2 m=4 plugin=jerasure admin:~ # ceph osd erasure-code-profile ls bad_profile default admin:~ # ceph osd erasure-code-profile get bad_profile crush-device-class= crush-failure-domain=host crush-root=default jerasure-per-chunk-alignment=false k=2 m=4 plugin=jerasure technique=reed_sol_van w=8 admin:~ # ceph osd erasure-code-profile rm bad_profile admin:~ # ceph osd erasure-code-profile ls default","title":"Task 3: Create and remove a new EC profile"},{"location":"linux/SES/linux_ses_demo/#task-4-create-a-better-ec-profile","text":"admin:~ # ceph osd erasure-code-profile set usable_profile k=2 m=1 plugin=jerasure technique=reed_sol_van stripe_unit=4K crush-failure-domain=host admin:~ # ceph osd erasure-code-profile get usable_profile crush-device-class= crush-failure-domain=host crush-root=default jerasure-per-chunk-alignment=false k=2 m=1 plugin=jerasure stripe_unit=4K technique=reed_sol_van w=8","title":"Task 4: Create a better EC profile"},{"location":"linux/SES/linux_ses_demo/#213-manipulate-crush-map-rulesets","text":"","title":"2.1.3. Manipulate CRUSH Map Rulesets"},{"location":"linux/SES/linux_ses_demo/#task-1-display-a-list-of-the-current-crush-map-rules","text":"admin:~ # ceph osd crush rule ls replicated_rule admin:~ # ceph osd crush osd crush rule ls osd crush rule ls-by-class <class> osd crush rule dump {<name>} osd crush dump osd crush set {<int>} osd crush add-bucket <name> <type> {<args> [<args>...]} osd crush rename-bucket <srcname> <dstname> osd crush set <osdname (id|osd.id)> <float[0.0-]> <args> [<args>...] osd crush add <osdname (id|osd.id)> <float[0.0-]> <args> [<args>...] osd crush set-all-straw-buckets-to-straw2 admin:~ # ceph osd crush rule osd crush rule ls osd crush rule ls-by-class <class> osd crush rule dump {<name>} osd crush rule create-simple <name> <root> <type> {firstn|indep} osd crush rule create-replicated <name> <root> <type> {<class>} osd crush rule create-erasure <name> {<profile>} osd crush rule rm <name> osd crush rule rename <srcname> <dstname> List the existing CRUSH Map rulesets that have been defined according to a particular device class: admin:~ # ceph osd crush rule ls-by-class hdd admin:~ # ceph osd crush rule ls-by-class ssd Error ENOENT: failed to get rules by class 'ssd' admin:~ # ceph osd crush rule ls-by-class nvme Error ENOENT: failed to get rules by class 'nvme'","title":"Task 1: Display a list of the current CRUSH Map rules"},{"location":"linux/SES/linux_ses_demo/#task-2-examine-the-details-of-the-default-crush-map-rule","text":"Show the details of the default CRUSH Map rule with the dump sub-command: The \u201crule_id\u201d and \u201cruleset\u201d values just numbgrs to keep track of rules similar to a DB key id. \u201cmin_size\u201d and \u201cmax_size\u201d are related to how CRUSH behaves when a certain numbgr of replicas are created. The \u201csteps\u201d section is the most functional portion of the rule, providing an ordered set of rules for how CRUSH should behave. Note that there are three \u201cop\u201d parts, one each for \u201ctake\u201d, \u201cchooseleaf_firstn\u201d, and \u201cemit\u201d. \u201ctake\u201d in a replicated rule is always the first step, and \u201cemit\u201d is always the last step. The \u201citem_type\u201d in the \u201ctake\u201d step is the crush_root value, and the \u201chost\u201d in the \u201cchooseleaf_firstn\u201d step is the failure_domain. admin:~ # ceph osd crush rule dump replicated_rule { \"rule_id\": 0, \"rule_name\": \"replicated_rule\", \"ruleset\": 0, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] }","title":"Task 2: Examine the details of the default CRUSH Map rule"},{"location":"linux/SES/linux_ses_demo/#task-3-create-and-remove-a-new-crush-map-rule","text":"1). Create a new CRUSH ruleset from the command line.We made two mistakes here: First, we named it \u201cbud\u201d instead of \u201cbad\u201d. admin:~ # ceph osd crush rule create-replicated bud_ruleset default host admin:~ # ceph osd crush rule ls replicated_rule bud_ruleset 2). Rename the ruleset: admin:~ # ceph osd crush rule rename bud_ruleset bad_ruleset admin:~ # ceph osd crush rule ls replicated_rule bad_ruleset 3). The second mistake was that we specified the failure-domain at the host-bucket level. This is technically not a bad thing to do, in fact it would be a common use case. But for this demo we want to set the failure domain at the rack-bucket level. We can\u2019t change a defined CRUSH Map ruleset, so delete the bad one: admin:~ # ceph osd crush rule rm bad_ruleset admin:~ # ceph osd crush rule ls replicated_rule","title":"Task 3: Create and remove a new CRUSH Map rule"},{"location":"linux/SES/linux_ses_demo/#task-4-create-a-better-crush-map-rule","text":"Create a more appropriate CRUSH Map rule from the CLI, that will survive the failure of a rack: admin:~ # ceph osd crush rule create-replicated better_ruleset default rack admin:~ # ceph osd crush rule dump better_ruleset { \"rule_id\": 1, \"rule_name\": \"better_ruleset\", \"ruleset\": 1, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"rack\" }, { \"op\": \"emit\" } ] }","title":"Task 4: Create a better CRUSH Map rule"},{"location":"linux/SES/linux_ses_demo/#task-5-create-crush-map-rules-for-different-classes-of-devices","text":"1). Create two different CRUSH Map rules from the CLI, that will accommodate a slow set of devices (HDDs) and a fast set of devices (SDDs): The error of 2nd is because the cluster does not have any SSD devices. admin:~ # ceph osd crush rule create-replicated slow_devices default host hdd admin:~ # ceph osd crush rule create-replicated fast_devices default host sdd Error EINVAL: device class sdd does not exist 2). Display the details of the new \u201cslow\u201d rule: admin:~ # ceph osd crush rule dump slow_devices { \"rule_id\": 2, \"rule_name\": \"slow_devices\", \"ruleset\": 2, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -2, \"item_name\": \"default~hdd\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] }","title":"Task 5: Create CRUSH Map rules for different classes of devices"},{"location":"linux/SES/linux_ses_demo/#task-6-change-the-ruleset-used-by-a-pool","text":"1). Show which CRUSH Map Ruleset is being used by the cephfs_data pool: The rule should be listed as replicated_rule. admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: replicated_rule 2). Change the cephfs_data pool to use the new CRUSH Map ruleset that you created in the previous task. admin:~ # ceph osd pool set cephfs_data crush_rule better_ruleset set pool 2 crush_rule to better_ruleset 3). Verify that the rule has been changed by re-running the earlier command: admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: better_ruleset 4). In this demo cluster, making the cephfs_data pool use the \u201cbetter_ruleset\u201d will result in problems. (There\u2019s no rack for the CRUSH Map, and not enough nodes to accommodate the requirement for a large numbgr of PGs.) So change the setting back to the replicated_rule. admin:~ # ceph osd pool set cephfs_data crush_rule replicated_rule set pool 2 crush_rule to replicated_rule admin:~ # ceph osd pool get cephfs_data crush_rule crush_rule: replicated_rule Task 7: Create a CRUSH Map rule enhanced with an EC profile 1). Combine the benefits of Erasure Coding with a CRUSH Map rule: This will only work if you have already created an appropriate EC profile called usable_profile. In this demo you would have done in an earlier exercise. And in this demo you need to tie this ec_rule to the usable_profile, not the better_profile.Or else any pool that you create using the ec_rule will fail due to insufficient resources. admin:~ # ceph osd crush rule create-erasure ec_rule usable_profile Link the CRUSH map rule (ec_rule) to EC profile (usable_profile) created rule ec_rule at 3 P.S., The useable_profile was created by : admin:~ # ceph osd erasure-code-profile set usable_profile k=2 m=1 plugin=jerasure technique=reed_sol_van stripe_unit=4K crush-failure-domain=host 2). Display the details of the EC-enhanced CRUSH Map rule: See the added, extra \u201cop\u201d steps. You might also notice the different values for \u201ctype,\u201d \u201cmin_size,\u201d and \u201cmax_size\u201d than what you saw in the standard replicated rules. admin:~ # ceph osd crush rule dump ec_rule { \"rule_id\": 3, \"rule_name\": \"ec_rule\", \"ruleset\": 3, \"type\": 3, \"min_size\": 3, \"max_size\": 3, \"steps\": [ { \"op\": \"set_chooseleaf_tries\", \"num\": 5 }, { \"op\": \"set_choose_tries\", \"num\": 100 }, { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_indep\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule ls replicated_rule better_ruleset slow_devices ec_rule admin:~ # ceph osd crush rule create-replicated better_ruleset default rack admin:~ # ceph osd crush rule create-replicated slow_devices default host hdd admin:~ # ceph osd crush rule create-erasure ec_rule usable_profile admin:~ # ceph osd crush rule dump replicated_rule { \"rule_id\": 0, \"rule_name\": \"replicated_rule\", \"ruleset\": 0, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule dump better_ruleset { \"rule_id\": 1, \"rule_name\": \"better_ruleset\", \"ruleset\": 1, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -1, \"item_name\": \"default\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"rack\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd crush rule dump slow_devices { \"rule_id\": 2, \"rule_name\": \"slow_devices\", \"ruleset\": 2, \"type\": 1, \"min_size\": 1, \"max_size\": 10, \"steps\": [ { \"op\": \"take\", \"item\": -2, \"item_name\": \"default~hdd\" }, { \"op\": \"chooseleaf_firstn\", \"num\": 0, \"type\": \"host\" }, { \"op\": \"emit\" } ] } admin:~ # ceph osd pool osd pool stats {<poolname>} osd pool scrub <poolname> [<poolname>...] osd pool deep-scrub <poolname> [<poolname>...] osd pool repair <poolname> [<poolname>...] osd pool force-recovery <poolname> [<poolname>...] osd pool force-backfill <poolname> [<poolname>...] osd pool cancel-force-recovery <poolname> [<poolname>...] osd pool cancel-force-backfill <poolname> [<poolname>...] osd pool autoscale-status osd pool mksnap <poolname> <snap> admin:~ # ceph osd pool get <poolname> size min_size pg_num pgp_num crush_rule Hashpspool Nodelete Nopgchange Nosizechange write_fadvise_dontneed Noscrub nodeep-scrub hit_set_type hit_set_period hit_set_count hit_set_fpp use_gmt_hitset target_max_objects target_max_bytes cache_target_dirty_ratio cache_target_dirty_high_ratio cache_target_full_ratio cache_min_flush_age cache_min_evict_age erasure_code_profile min_read_recency_for_promote All min_write_recency_for_promote fast_read hit_set_grade_decay_rate hit_set_search_last_n scrub_min_interval scrub_max_interval deep_scrub_interval recovery_priority recovery_op_priority scrub_priority compression_mode compression_algorithm compression_required_ratio compression_max_blob_size compression_min_blob_size csum_type csum_min_block csum_max_block allow_ec_overwrites fingerprint_algorithm pg_autoscale_mode pg_autoscale_bias pg_num_min target_size_bytes target_size_ratio","title":"Task 6: Change the ruleset used by a pool"},{"location":"linux/SES/linux_ses_demo/#214-investigate-bluestore","text":"","title":"2.1.4. Investigate BlueStore"},{"location":"linux/SES/linux_ses_demo/#task-1-explore-the-drive_groupsyml-configuration","text":"After deployment, the drive_groups.yml file is where the storage administrator defines the configuration of the cluster\u2019s storage devices. Note the \u201cdata_devices\u201d parameter. In this demo, \u201call\u201d storage devices are data devices for BlueStore. Note that there are no definitions for \u201cwal_devices\u201d or \u201cdb_devices.\u201d That\u2019s because in this demo environment we don\u2019t have any other \u201cfast\u201d devices that would be appropriate for these roles. Since BlueStore is the default, there is no definition of a \u201cformat\u201d for the devices. Otherwise, a \u201cFormat: bluestore\u201d key-value pair might exist to ensure that BlueStore is used. admin:~ # cd /srv/salt/ceph/configuration/files admin:/srv/salt/ceph/configuration/files # cat drive_groups.yml # default: <- just a name - can be anything # target: 'data*' <- must be resolvable by salt's targeting processor # data_devices: # size: 20G # db_devices: # size: 10G # rotational: 1 # allflash: # target: 'fast_nodes*' # data_devices: # size: 100G # db_devices: # size: 50G # rotational: 0 # This is the default configuration and # will create an OSD on all available drives default: target: 'data*' data_devices: all: true","title":"Task 1: Explore the drive_groups.yml configuration"},{"location":"linux/SES/linux_ses_demo/#task-2-examine-a-storage-hosts-storage-devices","text":"admin:~ # ssh data1 Last login: Tue Jan 5 18:06:40 2021 from 10.58.121.181 Should see 3 devices, which are named ceph LVM-type devices data1:~ # lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 8G 0 disk \u2514\u2500ceph--14c886af--269d--475f--8ee3--f5e4abbb222d-osd--data--38911b2d--f30a--4b09--9010--8dd6fad2fcc6 254:0 0 8G 0 lvm sdb 8:16 0 8G 0 disk \u2514\u2500ceph--9ec4a77a--5d67--4b21--be53--d7e9221082de-osd--data--00cb3dc6--c28b--41ae--95de--efb86da254da 254:1 0 8G 0 lvm sdc 8:32 0 8G 0 disk \u2514\u2500ceph--5eaea8a8--bb68--49dd--a1e3--b82c5464ab1f-osd--data--a4a05f70--53d9--41d4--a273--4f47a088968a 254:2 0 8G 0 lvm sr0 11:0 1 672M 0 rom vda 253:0 0 20G 0 disk \u251c\u2500vda1 253:1 0 8M 0 part \u251c\u2500vda2 253:2 0 18.4G 0 part / \u2514\u2500vda3 253:3 0 1.7G 0 part [SWAP] See the raw ceph devices data1:~ # ls -lad /dev/ceph* drwxr-xr-x 2 root root 60 Oct 5 13:15 /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d drwxr-xr-x 2 root root 60 Oct 5 13:16 /dev/ceph-5eaea8a8-bb68-49dd-a1e3-b82c5464ab1f drwxr-xr-x 2 root root 60 Oct 5 13:15 /dev/ceph-9ec4a77a-5d67-4b21-be53-d7e9221082de Dig down even farther by examining the content of one of the directories, see a symlink to an LVM device-mapper device. All the devices are tied together with LVM. Note that the name of the symlink is named osd-data- . data1:~ # ls -l /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d lrwxrwxrwx 1 ceph ceph 7 Oct 5 13:15 osd-data-38911b2d-f30a-4b09-9010-8dd6fad2fcc6 -> ../dm-0 data1:~ # l /dev/dm* brw-rw---- 1 ceph ceph 254, 0 Jan 5 18:10 /dev/dm-0 brw-rw---- 1 ceph ceph 254, 1 Jan 5 18:10 /dev/dm-1 brw-rw---- 1 ceph ceph 254, 2 Jan 5 18:10 /dev/dm-2","title":"Task 2: Examine a storage host\u2019s storage devices"},{"location":"linux/SES/linux_ses_demo/#task-3-examine-a-storage-hosts-osd-details","text":"data1:~ # cd /var/lib/ceph/ data1:/var/lib/ceph # ls -l drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-mds drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-mgr drwxr-x--- 1 ceph ceph 24 Oct 5 13:15 bootstrap-osd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rbd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rbd-mirror drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 bootstrap-rgw drwxr-x--- 1 ceph ceph 12 Oct 5 09:04 crash drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mds drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mgr drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 mon drwxr-x--- 1 ceph ceph 38 Oct 5 13:16 osd drwxr-x--- 1 ceph ceph 0 Aug 24 22:03 tmp See 3 different sub-directories, each representing the 3 different OSDs (ceph-2, ceph-6, ceph-10) that are running on this storage server data1:/var/lib/ceph # cd osd/ data1:/var/lib/ceph/osd # ls -l drwxrwxrwt 2 ceph ceph 320 Oct 5 13:16 ceph-10 drwxrwxrwt 2 ceph ceph 320 Oct 5 13:15 ceph-2 drwxrwxrwt 2 ceph ceph 320 Oct 5 13:16 ceph-6 See some functional files associated with the OSD and BlueStore. See a block file, which is a symlink to one of the ceph devices, which stores the raw objects for the OSD. data1:/var/lib/ceph/osd # cd ceph-2 data1:/var/lib/ceph/osd/ceph-2 # ls -l -rw-r--r-- 1 ceph ceph 400 Oct 5 13:15 activate.monmap lrwxrwxrwx 1 ceph ceph 92 Oct 5 13:15 block -> /dev/ceph-14c886af-269d-475f-8ee3-f5e4abbb222d/osd-data-38911b2d-f30a-4b09-9010-8dd6fad2fcc6 -rw------- 1 ceph ceph 2 Oct 5 13:15 bluefs -rw------- 1 ceph ceph 37 Oct 5 13:15 ceph_fsid -rw-r--r-- 1 ceph ceph 37 Oct 5 13:15 fsid -rw------- 1 ceph ceph 55 Oct 5 13:15 keyring -rw------- 1 ceph ceph 8 Oct 5 13:15 kv_backend -rw------- 1 ceph ceph 21 Oct 5 13:15 magic -rw------- 1 ceph ceph 4 Oct 5 13:15 mkfs_done -rw------- 1 ceph ceph 41 Oct 5 13:15 osd_key -rw------- 1 ceph ceph 6 Oct 5 13:15 ready -rw------- 1 ceph ceph 3 Oct 5 13:15 require_osd_release -rw------- 1 ceph ceph 10 Oct 5 13:15 type -rw------- 1 ceph ceph 2 Oct 5 13:15 whoami data1:/var/lib/ceph/osd/ceph-2 # cat ceph_fsid # The unique ID of this Ceph cluster 343ee7d3-232f-4c71-8216-1edbc55ac6e0 data1:/var/lib/ceph/osd/ceph-2 # cat fsid # The unique ID of this OSD 6df58ebc-dbfe-4822-9714-90212c06ea05 data1:/var/lib/ceph/osd/ceph-2 # cat keyring # The Ceph key for this OSD [osd.2] key = <your key> data1:/var/lib/ceph/osd/ceph-2 # cat ready # Indication of the readiness of this OSD ready data1:/var/lib/ceph/osd/ceph-2 # cat type # filestore or bluestore (in this case: bluestore) bluestore data1:/var/lib/ceph/osd/ceph-2 # cat whoami # The integer id of this OSD (in this case: 2) 2","title":"Task 3: Examine a storage host\u2019s OSD details"},{"location":"linux/SES/linux_ses_demo/#task-4-display-bluestore-information-using-ceph-bluestore-tool","text":"Show BlueStore metadata for osd.2: data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool show-label --path /var/lib/ceph/osd/ceph-2 inferring bluefs devices from bluestore path { \"/var/lib/ceph/osd/ceph-2/block\": { \"osd_uuid\": \"6df58ebc-dbfe-4822-9714-90212c06ea05\", \"size\": 8585740288, \"btime\": \"2020-10-05 13:15:51.227799\", \"description\": \"main\", \"bluefs\": \"1\", \"ceph_fsid\": \"343ee7d3-232f-4c71-8216-1edbc55ac6e0\", \"kv_backend\": \"rocksdb\", \"magic\": \"ceph osd volume v026\", \"mkfs_done\": \"yes\", \"osd_key\": <your key>, \"ready\": \"ready\", \"require_osd_release\": \"14\", \"whoami\": \"2\" } Run a manual \u201cscrub\u201d on osd.7 using ceph-blestore-tool. (Received error, the tool won\u2019t allow you to do this while the OSD is running.) data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool fsck --path /var/lib/ceph/osd/ceph-2 error from fsck: (11) Resource temporarily unavailable 2021-01-05 18:32:25.528 7f4abad6e180 -1 bluestore(/var/lib/ceph/osd/ceph-2) _lock_fsid failed to lock /var/lib/ceph/osd/ceph-2/fsid (is another ceph-osd still running?)(11) Resource temporarily unavailable Simulate that the OSD is down, shutdown the OSD: data1:/var/lib/ceph/osd/ceph-2 # systemctl stop ceph-osd@2.service Now run the \u201cfsck\u201d command again. This time the \u201cfsck\u201d has worked, with the output showing: \u201cfsck success\u201d data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool fsck --path /var/lib/ceph/osd/ceph-2 fsck success Restart the OSD: data1:/var/lib/ceph/osd/ceph-2 # systemctl start ceph-osd@2.service data1:/var/lib/ceph/osd/ceph-2 # ceph-bluestore-tool show-label --path /var/lib/ceph/osd/ceph-2 inferring bluefs devices from bluestore path { \"/var/lib/ceph/osd/ceph-2/block\": { \"osd_uuid\": \"6df58ebc-dbfe-4822-9714-90212c06ea05\", \"size\": 8585740288, \"btime\": \"2020-10-05 13:15:51.227799\", \"description\": \"main\", \"bluefs\": \"1\", \"ceph_fsid\": \"343ee7d3-232f-4c71-8216-1edbc55ac6e0\", \"kv_backend\": \"rocksdb\", \"magic\": \"ceph osd volume v026\", \"mkfs_done\": \"yes\", \"osd_key\": <your key>, \"ready\": \"ready\", \"require_osd_release\": \"14\", \"whoami\": \"2\" } }","title":"Task 4: Display BlueStore information using ceph-bluestore-tool"},{"location":"linux/SES/linux_ses_demo/#22-common-day-1-tasks-using-the-cli","text":"Including ollowing topics in relation to the commandline: Users and Ceph Configuration Health commands Erasure Code Profiles CRUSH Map rules Pools Scrubbing OSDs and Placement Groups Manager modules The tell commands","title":"2.2. Common Day 1 Tasks Using the CLI"},{"location":"linux/SES/linux_ses_demo/#221-ceph-users-and-configuration","text":"","title":"2.2.1. Ceph Users and Configuration"},{"location":"linux/SES/linux_ses_demo/#task-1-view-the-current-user-keyrings","text":"Ceph keyrings are stored in below directory admin:~ # cd /etc/ceph/ admin:/etc/ceph # ls -l -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap The value of 'key' is the key that\u2019s on the keyring. The admin keyring is \u201callow\u201ded all capabilities (permissions) to all services in the cluster, as expected. there are more than just client keys. admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" Display the existing users with the \u201cauth\u201d command: Below two commands are equivalent admin:/etc/ceph # ceph -n client.admin -keyring=/etc/ceph/ceph.client.admin.keyring auth ls -- failed??? no valid command found admin:/etc/ceph # ceph auth ls installed auth entries: mds.mon1 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx mds.mon2 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx mds.mon3 key: <your key> caps: [mds] allow * caps: [mgr] allow profile mds caps: [mon] allow profile mds caps: [osd] allow rwx osd.0 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.1 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.10 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.11 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.2 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.3 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.4 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.5 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.6 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.7 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.8 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * osd.9 key: <your key> caps: [mgr] allow profile osd caps: [mon] allow profile osd caps: [osd] allow * client.admin key: <your key> caps: [mds] allow * caps: [mgr] allow * caps: [mon] allow * caps: [osd] allow * client.bootstrap-mds key: <your key> caps: [mon] allow profile bootstrap-mds client.bootstrap-mgr key: <your key> caps: [mon] allow profile bootstrap-mgr client.bootstrap-osd key: <your key> caps: [mgr] allow r caps: [mon] allow profile bootstrap-osd client.bootstrap-rbd key: <your key> caps: [mon] allow profile bootstrap-rbd client.bootstrap-rbd-mirror key: <your key> caps: [mon] allow profile bootstrap-rbd-mirror client.bootstrap-rgw key: <your key> caps: [mon] allow profile bootstrap-rgw client.igw.mon2 key: <your key> caps: [mgr] allow r caps: [mon] allow * caps: [osd] allow * client.rgw.mon3 key: <your key> caps: [mgr] allow r caps: [mon] allow rwx caps: [osd] allow rwx client.storage key: <your key> caps: [mon] allow rw mgr.mon1 key: <your key> caps: [mds] allow * caps: [mon] allow profile mgr caps: [osd] allow *","title":"Task 1: View the current user keyrings"},{"location":"linux/SES/linux_ses_demo/#task-2-create-a-new-keyring-and-associated-user","text":"1). There are several different ways to create a new keyring and user. This is just one way. Create a new keyring and associated user named James . Remembgr that typically all new users will need read rights for the mon capability, and will need read/write rights for the osd capability, including a specification of rights to a pool. admin:/etc/ceph # ceph-authtool -g -n client.james --cap mon 'allow r' --cap osd 'allow rw pool=iscsi-images' -C /etc/ceph/ceph.client.james.keyring creating /etc/ceph/ceph.client.james.keyring admin:/etc/ceph # l total 16 drwxr-xr-x 1 root root 130 Jan 5 19:31 ./ drwxr-xr-x 1 root root 4392 Oct 5 13:03 ../ -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap 2). Show the content of the newly created keyring: admin:/etc/ceph # cat ceph.client.james.keyring [client.james] key = <your key> caps mon = \"allow r\" caps osd = \"allow rw pool=iscsi-images\" 3). Officially add the new keyring to Ceph: admin:/etc/ceph # ceph auth add client.james -i /etc/ceph/ceph.client.james.keyring added key for client.james 4). Show the key information using the \u201cauth\u201d function: admin:/etc/ceph # ceph auth get client.james exported keyring for client.james [client.james] key = <your key> caps mon = \"allow r\" caps osd = \"allow rw pool=iscsi-images\"","title":"Task 2: Create a new keyring and associated user"},{"location":"linux/SES/linux_ses_demo/#task-3-create-a-client-key-for-rbd","text":"1). Change to the directory that contains the ceph keyrings. admin:~ # cd /etc/ceph/ 2). List the content of the directory: Although you see the admin users\u2019s keyring, ceph.client.admin.keyring, there is not yet a file that is appropriate for a specific application to use. Also note that the permissions on the keyring file are quite restrictive: 0600 admin:/etc/ceph # ls -l -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap 3). Show the content of the admin user\u2019s keyring: You will use the value associated with the \u201ckey\u201d key to create a new file. Copy the \u201ckey\u201d value using your favorite method. admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" 4). Open a new file for editing called admin.secret using your favorite editor (such as vi): The name of the file isn\u2019t very important, but naming it this way will help to identify its purpose: it\u2019s a secret key for the admin user. Note that there are many ways to do this. An alternative way is mentioned in the tip below that will do this in one step using grep and awk. admin:/etc/ceph # vi admin.secret 5). Paste the \u201ckey\u201d value into the new file. It will be the only content of the file. It will look like this (in fact it\u2019s probably exactly the same as this, if you\u2019re using the demo environment provided to you): admin:/etc/ceph # cat admin.secret <your key> 6). Save the file and exist out of the editor. 7). Change the permissions of the file so that no other user on the host can see the content of the file: admin:/etc/ceph # chmod 0600 admin.secret admin:/etc/ceph # l drwxr-xr-x 1 root root 154 Jan 5 20:03 ./ drwxr-xr-x 1 root root 4392 Oct 5 13:03 ../ -rw------- 1 root root 41 Jan 5 20:03 admin.secret -rw------- 1 root root 151 Oct 5 13:13 ceph.client.admin.keyring -rw------- 1 root root 126 Jan 5 19:31 ceph.client.james.keyring -rw-r--r-- 1 root root 980 Oct 5 13:13 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap Tip: An alternative way to create this key file is to simply use grep/awk together in one bash command, like this: admin:/etc/ceph # grep \"key =\" ceph.client.admin.keyring | awk -F\" = \" '{ print $2 }' <your key> admin:/etc/ceph # grep \"key =\" ceph.client.admin.keyring | awk -F\" = \" '{ print $2 }' > admin.secret admin:/etc/ceph # cat admin.secret <your key>","title":"Task 3: Create a client key for RBD"},{"location":"linux/SES/linux_ses_demo/#task-4-view-the-ceph-master-configuration-file","text":"View the content of the file. The file is managed and controlled by DeepSea. The comment makes reference to the control files in the /srv/salt/ceph/configuration/ directory hierarchy. This is a very simple storage cluster. In a more diverse and sophisticated ceph cluster there may be more configuration settings defined. Although this exercise doesn\u2019t call out any more specific information about this configuration file, you may take a moment to consider the content of the file before finishing the task. admin:/etc/ceph # cat ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.186, 10.58.121.187, 10.58.121.188 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] admin:/etc/ceph # ls -l /srv/salt/ceph/configuration/ drwxr-xr-x 1 salt salt 18 Oct 5 13:13 cache drwxr-xr-x 1 root root 38 Oct 5 09:04 check drwxr-xr-x 1 root root 74 Oct 5 09:04 create -rw-r--r-- 1 root root 217 May 14 2020 default-import.sls -rw-r--r-- 1 root root 222 May 14 2020 default.sls drwxr-xr-x 1 root root 276 Oct 5 12:55 files -rw-r--r-- 1 root root 74 May 14 2020 init.sls","title":"Task 4: View the Ceph master configuration file"},{"location":"linux/SES/linux_ses_demo/#222-run-the-ceph-health-commands","text":"Get overall health status admin:~ # ceph health HEALTH_OK admin:~ # ceph -s admin:~ # ceph status cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 5w) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 98m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr Run the \u201cstatus\u201d command for the monitors: admin:~ # ceph mon stat e1: 3 mons at { mon1=[v2:10.58.121.186:3300/0,v1:10.58.121.186:6789/0], mon2=[v2:10.58.121.187:3300/0,v1:10.58.121.187:6789/0], mon3=[v2:10.58.121.188:3300/0,v1:10.58.121.188:6789/0] }, election epoch 22, leader 0 mon1, quorum 0,1,2 mon1,mon2,mon3 Run the \u201cstatus\u201d command for the placement groups: admin:~ # ceph pg stat 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 852 B/s rd, 0 op/s Run the ceph \u201cstatus\u201d command while watching for changes to the status: admin:~ # ceph -s --watch-debug cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 5w) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 104m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr 2021-01-05 20:20:53.947298 mgr.mon1 [DBG] pgmap v1597415: 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 852 B/s rd, 0 op/s 2021-01-05 20:20:55.949294 mgr.mon1 [DBG] pgmap v1597416: 208 pgs: 208 active+clean; 4.7 KiB data, 2.1 GiB used, 82 GiB / 96 GiB avail; 1.2 KiB/s rd, 1 op/s .......","title":"2.2.2. Run the Ceph Health Commands"},{"location":"linux/SES/linux_ses_demo/#223-manipulate-pools","text":"","title":"2.2.3. Manipulate Pools"},{"location":"linux/SES/linux_ses_demo/#task-1-display-a-list-of-the-current-pools","text":"admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw List pools with their index numbgr. Note how the index numbgr matches the index numbgr of the detail listing above. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log","title":"Task 1: Display a list of the current pools"},{"location":"linux/SES/linux_ses_demo/#task-2-display-the-usage-data-and-stats-of-the-current-pools","text":"Display pool usages. Note again index \u201cID\u201d for the pool. admin:~ # ceph df RAW STORAGE: CLASS SIZE AVAIL USED RAW USED %RAW USED hdd 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 TOTAL 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 POOLS: POOL ID STORED OBJECTS USED %USED MAX AVAIL iscsi-images 1 389 B 2 192 KiB 0 25 GiB cephfs_data 2 0 B 0 0 B 0 25 GiB cephfs_metadata 3 7.2 KiB 48 1.5 MiB 0 25 GiB .rgw.root 4 1.2 KiB 4 768 KiB 0 25 GiB default.rgw.control 5 0 B 8 0 B 0 25 GiB default.rgw.meta 6 381 B 3 576 KiB 0 25 GiB default.rgw.log 7 35 KiB 208 35 KiB 0 25 GiB admin:~ # ceph df detail RAW STORAGE: CLASS SIZE AVAIL USED RAW USED %RAW USED hdd 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 TOTAL 96 GiB 82 GiB 2.1 GiB 14 GiB 14.81 POOLS: POOL ID STORED OBJECTS USED %USED MAX AVAIL QUOTA OBJECTS QUOTA BYTES DIRTY USED COMPR UNDER COMPR iscsi-images 1 389 B 2 192 KiB 0 25 GiB N/A N/A 2 0 B 0 B cephfs_data 2 0 B 0 0 B 0 25 GiB N/A N/A 0 0 B 0 B cephfs_metadata 3 7.2 KiB 48 1.5 MiB 0 25 GiB N/A N/A 48 0 B 0 B .rgw.root 4 1.2 KiB 4 768 KiB 0 25 GiB N/A N/A 4 0 B 0 B default.rgw.control 5 0 B 8 0 B 0 25 GiB N/A N/A 8 0 B 0 B default.rgw.meta 6 381 B 3 576 KiB 0 25 GiB N/A N/A 3 0 B 0 B default.rgw.log 7 35 KiB 208 35 KiB 0 25 GiB N/A N/A 208 0 B 0 B Display pool usages using rados command admin:~ # rados df POOL_NAME USED OBJECTS CLONES COPIES MISSING_ON_PRIMARY UNFOUND DEGRADED RD_OPS RD WR_OPS WR USED COMPR UNDER COMPR .rgw.root 768 KiB 4 0 12 0 0 0 40 40 KiB 4 4 KiB 0 B 0 B cephfs_data 0 B 0 0 0 0 0 0 0 0 B 0 0 B 0 B 0 B cephfs_metadata 1.5 MiB 48 0 144 0 0 0 0 0 B 111 42 KiB 0 B 0 B default.rgw.control 0 B 8 0 24 0 0 0 0 0 B 0 0 B 0 B 0 B default.rgw.log 35 KiB 208 0 624 0 0 0 5919671 5.6 GiB 3945118 946 KiB 0 B 0 B default.rgw.meta 576 KiB 3 0 9 0 0 0 38 28 KiB 4 3 KiB 0 B 0 B iscsi-images 192 KiB 2 0 6 0 0 0 4184657 4.0 GiB 8 2 KiB 0 B 0 B total_objects 246 total_used 14 GiB total_avail 82 GiB total_space 96 GiB Show the statistics of the pools: admin:~ # ceph osd pool stats pool iscsi-images id 1 client io 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr pool cephfs_data id 2 nothing is going on pool cephfs_metadata id 3 nothing is going on pool .rgw.root id 4 nothing is going on pool default.rgw.control id 5 nothing is going on pool default.rgw.meta id 6 nothing is going on pool default.rgw.log id 7 nothing is going on Show only the statistics about a specific pool: admin:~ # ceph osd pool stats .rgw.root pool .rgw.root id 4 nothing is going on Show which CRUSH Map ruleset was used to create the .rgw.root pool: admin:~ # ceph osd pool get .rgw.root crush_rule crush_rule: replicated_rule Show the list of all the attributes of a pool that can be queried: admin:~ # ceph osd pool get .rgw.root size min_size pg_num pgp_num crush_rule Hashpspool Nodelete Nopgchange Nosizechange write_fadvise_dontneed noscrub|nodeep-scrub hit_set_type hit_set_period hit_set_count hit_set_fpp use_gmt_hitset target_max_objects target_max_bytes cache_target_dirty_ratio cache_target_dirty_high_ratio cache_target_full_ratio cache_min_flush_age cache_min_evict_age erasure_code_profile min_read_recency_for_promote all|min_write_recency_for_promote fast_read|hit_set_grade_decay_rate hit_set_search_last_n scrub_min_interval scrub_max_interval deep_scrub_interval recovery_priority recovery_op_priority scrub_priority compression_mode compression_algorithm compression_required_ratio compression_max_blob_size compression_min_blob_size csum_type|csum_min_block csum_max_block allow_ec_overwrites fingerprint_algorithm pg_autoscale_mode pg_autoscale_bias pg_num_min target_size_bytes target_size_ratio","title":"Task 2: Display the usage data and stats of the current pools"},{"location":"linux/SES/linux_ses_demo/#task-3-create-two-new-pools-one-replicated-one-ec","text":"1). Create a new replicated pool that will be used for storing block data for RBD. Use the standard replicated_ruleset CRUSH Map: It would be tempting to the use the better_ruleset, but this demo environment doesn\u2019t have enough resources for that. This is a demo environment, so the PG numbgrs will be low. In your production environments, be sure to assign an appropriately high numbgr, or use the pg_autoscaler manager module. admin:~ # ceph osd pool create rbd_pool 4 4 replicated replicated_rule pool 'rbd_pool' created 2). Tell the cluster that you expect to have this new rbd_pool to use 50% of the total capacity: admin:~ # ceph osd pool set rbd_pool target_size_ratio .5 set pool 8 target_size_ratio to .5 3). Create a new EC pool that will be used for storing RGW buckets and objects. Use the usable_profile Erasure Code profile that was created in an earlier exercise. And use the ec_rule CRUSH Map ruleset that was created in an earlier exercise: admin:~ # ceph osd pool create bucket_pool 4 4 erasure usable_profile ec_rule pool 'bucket_pool' created 4). Tell the cluster that you expect to have this new bucket_pool to use 100GB of data: POOL_TARGET_SIZE_BYTES_OVERCOMMITTED admin:~ # ceph osd pool set bucket_pool target_size_bytes 100000000000 set pool 9 target_size_bytes to 100000000000 5). Enable the PG Autoscaler feature on the two new pools, to ensure that we have an appropriate assignment of placement groups in the demo cluster: This presumes that you completed an earlier exercise that enable the pg_autoscaler manager module. admin:~ # ceph osd pool set bucket_pool pg_autoscale_mode on set pool 9 pg_autoscale_mode to on admin:~ # ceph osd pool set rbd_pool pg_autoscale_mode on set pool 8 pg_autoscale_mode to on 6). Again display a list of all the pools, which will now include the two new pools that you\u2019ve just created: Notice in the detail listing that the two new pools don\u2019t have an application attribute assigned to them. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log 8 rbd_pool 9 bucket_pool admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw pool 8 'rbd_pool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 1415 lfor 0/0/1413 flags hashpspool stripe_width 0 target_size_ratio 0.5 pool 9 'bucket_pool' erasure size 3 min_size 2 crush_rule 3 object_hash rjenkins pg_num 4 pgp_num 4 autoscale_mode on last_change 1410 flags hashpspool stripe_width 8192 target_size_bytes 100000000000 7). Check the pg_autoscale status, particularly to see a comparison of how much raw space is being consumed by the two pools: See that the RATE column for all of the replicated pools shows the value of 3.0, while the value for the bucket_pool \u2013 which is an EC pool \u2013 is 1.5. The EC pool, with a K+M of 2+1 consumes considerably less raw storage space. See the TARGET RATIO for the rbd_pool. Notice that the autoscaler has automatically adjusted the numbgr PGs assigned to rbd_pool from \u201c4\u201d to \u201c128\u201d because you told the cluster to have the pool use 50% of the capacity. See the TARGET SIZE for the bucket_pool, roughly 100GB. But the cluster may not have changed the PG_NUM value yet. The autoscaler will adjust the numbgr of PGs gradually, so as not to disrupt the performance too dramatically. While you\u2019re here, you might also notice the RAW CAPACITY column. All pools are expecting to divide the cluster space equally, even though you\u2019ve explicitly told the cluster that rbd_pool and bucket_pool will deviate from that even division. admin:~ # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE iscsi-images 389 3.0 98256M 0.0000 1.0 32 on cephfs_data 0 3.0 98256M 0.0000 1.0 32 off cephfs_metadata 7412 3.0 98256M 0.0000 4.0 16 off .rgw.root 1245 3.0 98256M 0.0000 1.0 32 warn default.rgw.control 0 3.0 98256M 0.0000 1.0 32 warn default.rgw.meta 381 3.0 98256M 0.0000 1.0 32 warn default.rgw.log 35900 3.0 98256M 0.0000 1.0 32 warn rbd_pool 0 3.0 98256M 0.0000 0.5000 1.0 32 on bucket_pool 0 95367M 1.5 98256M 1.4559 1.0 4 on","title":"Task 3: Create two new pools, one replicated, one EC"},{"location":"linux/SES/linux_ses_demo/#task-4-assign-an-application-to-the-two-new-pools","text":"1). Assign the rbd application to the new rbd_pool that you created in the previous task: admin:~ # ceph osd pool application enable rbd_pool rbd enabled application 'rbd' on pool 'rbd_pool' 2). Instruct the cluster to prepare the new rbd_pool for storing block device images: admin:~ # rbd pool init rbd_pool 3). Assign the rgw application to the new bucket_pool that you created in the previous task: admin:~ # ceph osd pool application enable bucket_pool rgw enabled application 'rgw' on pool 'bucket_pool' 4). Display a list of all the pools again, this time noticing that the application attribute is set on the two new pools. admin:~ # ceph osd lspools 1 iscsi-images 2 cephfs_data 3 cephfs_metadata 4 .rgw.root 5 default.rgw.control 6 default.rgw.meta 7 default.rgw.log 8 rbd_pool 9 bucket_pool admin:~ # ceph osd pool ls detail pool 1 'iscsi-images' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 448 lfor 0/448/446 flags hashpspool stripe_width 0 application rbd pool 2 'cephfs_data' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 last_change 1395 lfor 0/1374/1372 flags hashpspool stripe_width 0 application cephfs pool 3 'cephfs_metadata' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 16 pgp_num 16 last_change 1385 lfor 0/975/973 flags hashpspool stripe_width 0 pg_autoscale_bias 4 pg_num_min 16 recovery_priority 5 application cephfs pool 4 '.rgw.root' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 31 flags hashpspool stripe_width 0 application rgw pool 5 'default.rgw.control' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 33 flags hashpspool stripe_width 0 application rgw pool 6 'default.rgw.meta' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 35 flags hashpspool stripe_width 0 application rgw pool 7 'default.rgw.log' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode warn last_change 37 flags hashpspool stripe_width 0 application rgw pool 8 'rbd_pool' replicated size 3 min_size 2 crush_rule 0 object_hash rjenkins pg_num 32 pgp_num 32 autoscale_mode on last_change 1420 lfor 0/0/1413 flags hashpspool,selfmanaged_snaps stripe_width 0 target_size_ratio 0.5 application rbd removed_snaps [1~3] pool 9 'bucket_pool' erasure size 3 min_size 2 crush_rule 3 object_hash rjenkins pg_num 4 pgp_num 4 autoscale_mode on last_change 1422 flags hashpspool stripe_width 8192 target_size_bytes 100000000000 application rgw 5). Another way to display which application is assigned to a pool is: admin:~ # ceph osd pool application get bucket_pool { \"rgw\": {} } admin:~ # ceph osd pool application get rbd_pool { \"rbd\": {} }","title":"Task 4: Assign an application to the two new pools"},{"location":"linux/SES/linux_ses_demo/#task-5-manage-snapshots-of-the-new-rgw-bucket-pool","text":"1). Display a list of the snapshots that exist of the bucket_pool that you created in the previous task: The output show that there are \u201c0 snaps.\u201d Right, it is a little funny that you only list the snapshots with rados command; no such functionality exists with the ceph osd pool command. admin:~ # rados -p bucket_pool lssnap 0 snaps 2). Take (make) a snapshot of the rbd_pool: admin:~ # ceph osd pool mksnap bucket_pool brand_new_pool_snapshot created pool bucket_pool snap brand_new_pool_snapshot 3). Display the list of the snapshots again: admin:~ # rados -p bucket_pool lssnap 1 brand_new_pool_snapshot 2021.01.05 22:23:23 1 snaps 4). Remove the snapshot: admin:~ # ceph osd pool rmsnap bucket_pool brand_new_pool_snapshot removed pool bucket_pool snap brand_new_pool_snapshot 5). Display the list of the snapshots again: admin:~ # rados -p bucket_pool lssnap 0 snaps","title":"Task 5: Manage snapshots of the new RGW bucket pool"},{"location":"linux/SES/linux_ses_demo/#224-maintain-consistency-of-data-with-scrub-and-repair","text":"Scrubbing is like \u201cfsck,\u201d which ensures that OSDs have durable, consistent data. Most of the scrubbing of OSDs happens automatically on a periodic basis.","title":"2.2.4. Maintain consistency of data with Scrub and Repair"},{"location":"linux/SES/linux_ses_demo/#task-1-display-a-few-of-the-scrub-settings","text":"1). Show the possible configuration settings related to scrub: If you simply grep for \u201cscrub\u201d you\u2019ll get more than you really want; there are some mon_scrub settings that aren\u2019t related to this exercise. admin:~ # ceph config ls | grep osd_scrub osd_scrub_invalid_stats osd_scrub_during_recovery osd_scrub_begin_hour osd_scrub_end_hour osd_scrub_begin_week_day osd_scrub_end_week_day osd_scrub_load_threshold osd_scrub_min_interval osd_scrub_max_interval osd_scrub_interval_randomize_ratio osd_scrub_backoff_ratio osd_scrub_chunk_min osd_scrub_chunk_max osd_scrub_sleep osd_scrub_auto_repair osd_scrub_auto_repair_num_errors osd_scrub_max_preemptions osd_scrub_priority osd_scrub_cost admin:~ # ceph config ls | grep osd_deep_scrub osd_deep_scrub_interval osd_deep_scrub_randomize_ratio osd_deep_scrub_stride osd_deep_scrub_keys osd_deep_scrub_update_digest_min_age osd_deep_scrub_large_omap_object_key_threshold osd_deep_scrub_large_omap_object_value_sum_threshold admin:~ # ceph config ls | grep scrub mon_warn_pg_not_scrubbed_ratio mon_warn_pg_not_deep_scrubbed_ratio mon_scrub_interval mon_scrub_timeout mon_scrub_max_keys mon_scrub_inject_crc_mismatch mon_scrub_inject_missing_keys osd_op_queue_mclock_scrub_res osd_op_queue_mclock_scrub_wgt osd_op_queue_mclock_scrub_lim osd_scrub_invalid_stats osd_max_scrubs osd_scrub_during_recovery osd_scrub_begin_hour osd_scrub_end_hour osd_scrub_begin_week_day osd_scrub_end_week_day osd_scrub_load_threshold osd_scrub_min_interval osd_scrub_max_interval osd_scrub_interval_randomize_ratio osd_scrub_backoff_ratio osd_scrub_chunk_min osd_scrub_chunk_max osd_scrub_sleep osd_scrub_auto_repair osd_scrub_auto_repair_num_errors osd_scrub_max_preemptions osd_deep_scrub_interval osd_deep_scrub_randomize_ratio osd_deep_scrub_stride osd_deep_scrub_keys osd_deep_scrub_update_digest_min_age osd_deep_scrub_large_omap_object_key_threshold osd_deep_scrub_large_omap_object_value_sum_threshold osd_debug_deep_scrub_sleep osd_scrub_priority osd_scrub_cost osd_requested_scrub_priority mds_max_scrub_ops_in_progress 2). Get the value of a few of the different scrub schedule settings: Note that \u201c0\u201d and \u201c24\u201d are the same setting. admin:~ # ceph config get osd.* osd_scrub_begin_hour 0 admin:~ # ceph config get osd.* osd_scrub_end_hour 24 3). Get the value of the scrub and repair settings: The \u201cauto repair\u201d feature is turned off, and the maximum numbgr of errors that \u201cauto repair\u201d would automatically repair is 5. admin:~ # ceph config get osd.* osd_scrub_auto_repair false admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 5","title":"Task 1: Display a few of the Scrub settings"},{"location":"linux/SES/linux_ses_demo/#task-2-change-the-scrub-settings-in-cephconf","text":"1). Display the ceph.conf, and verify that the file doesn\u2019t have any settings defined yet that are related to scrub. The settings would be located in the [global] section of the file: # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.186, 10.58.121.187, 10.58.121.188 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 2). Change to the Salt File Server directory that will have Salt control the master ceph.conf configuration file: admin:~ # cd /srv/salt/ceph/configuration/files/ceph.conf.d/ 3). List the content of the directory: The directory is empty. (Well, there is a README, but no other functional files.) admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ls -l -rw-r--r-- 1 root root 1989 May 14 2020 README 4). Create and edit a new file called global.conf. You don\u2019t have to use vi, but this step uses vi as one way of doing it: Be sure that you spell everything correctly, including the absence of \u201c_\u201d characters; there are spaces. Save the file and exit out of the editor. admin:/srv/salt/ceph/configuration/files/ceph.conf.d # vi global.conf Add the following content to the file: osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 5). Use DeepSea (Salt) to stage the file properly in Salt\u2019s File Server on the Salt Master (admin): admin:/srv/salt/ceph/configuration/files/ceph.conf.d # salt admin* state.apply ceph.configuration.create admin.sha.me.corp: Name: /var/cache/salt/minion/files/base/ceph/configuration - Function: file.absent - Result: Changed Started: - 22:42:34.900173 Duration: 20.891 ms Name: /srv/salt/ceph/configuration/cache/ceph.conf - Function: file.managed - Result: Changed Started: - 22:42:34.921454 Duration: 8576.516 ms Name: find /var/cache/salt/master/jobs -user root -exec chown salt:salt {} ';' - Function: cmd.run - Result: Changed Started: - 22:42:43.535022 Duration: 71.957 ms Summary for admin.sha.me.corp ------------ Succeeded: 3 (changed=3) Failed: 0 ------------ Total states run: 3 Total run time: 8.669 s 6). Using DeepSea (Salt), distribute the new ceph.conf configuration settings to all the nodes in the cluster: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # salt \\* state.apply ceph.configuration mon3.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:07.986661 Duration: 101.977 ms Summary for mon3.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 101.977 ms mon1.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.012479 Duration: 108.888 ms Summary for mon1.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 108.888 ms data3.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.052247 Duration: 98.681 ms Summary for data3.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 98.681 ms admin.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.072402 Duration: 97.231 ms Summary for admin.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 97.231 ms data1.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.076279 Duration: 104.169 ms Summary for data1.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 104.169 ms data4.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.081635 Duration: 105.13 ms Summary for data4.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 105.130 ms mon2.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.155758 Duration: 105.004 ms Summary for mon2.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 105.004 ms data2.sha.me.corp: Name: /etc/ceph/ceph.conf - Function: file.managed - Result: Changed Started: - 22:44:08.252200 Duration: 109.552 ms Summary for data2.sha.me.corp ------------ Succeeded: 1 (changed=1) Failed: 0 ------------ Total states run: 1 Total run time: 109.552 ms 7). Verify that the new ceph.conf settings have been put into place on the admin node: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 8). Also verify that other minions in the cluster have also received the updated configuration file, such as on the mon1 and data2 nodes: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ssh mon1 cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ssh data1 cat /etc/ceph/ceph.conf # DeepSea default configuration. Changes in this file will be overwritten on # package update. Include custom configuration fragments in # /srv/salt/ceph/configuration/files/ceph.conf.d/[global,osd,mon,mgr,mds,client].conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_initial_membgrs = mon1, mon2, mon3 mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 auth_cluster_required = cephx auth_service_required = cephx auth_client_required = cephx public_network = 10.58.120.0/23 cluster_network = 10.58.120.0/23 ms_bind_msgr2 = false # enable old ceph health format in the json output. This fixes the # ceph_exporter. This option will only stay until the prometheus plugin takes # over mon_health_preluminous_compat = true mon health preluminous compat warning = false rbd default features = 3 osd scrub begin hour = 23 osd scrub end hour = 5 osd scrub auto repair = True osd scrub auto repair num errors = 10 [client.rgw.mon3] rgw frontends = \"beast port=80\" rgw dns name = mon3.sha.me.corp rgw enable usage log = true [osd] [mon] [mgr] [mds] [client] 9). Apply the settings of the ceph.conf file to appropriate nodes in the cluster: admin:/srv/salt/ceph/configuration/files/ceph.conf.d # ceph config assimilate-conf -i /etc/ceph/ceph.conf [global] fsid = 343ee7d3-232f-4c71-8216-1edbc55ac6e0 mon_health_preluminous_compat = true mon_health_preluminous_compat_warning = false mon_host = 10.58.121.188, 10.58.121.187, 10.58.121.186 mon_initial_membgrs = mon1, mon2, mon3","title":"Task 2: Change the Scrub settings in ceph.conf"},{"location":"linux/SES/linux_ses_demo/#task-3-change-the-scrub-settings-directly-in-the-configuration-db","text":"1). Query the configuration database to see the value of \u201cosd_scrub_auto_repair_num_errors\u201d: You changed this value to \u201c10\u201d in the previous Task. admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 10 2). Change the value of \u201cosd_scrub_auto_repair_num_errors\u201d to \u201c8\u201d: admin:~ # ceph config set osd.* osd_scrub_auto_repair_num_errors 8 3). Show that the change has taken immediate effect by re-running the same command that was used in the first step: admin:~ # ceph config get osd.* osd_scrub_auto_repair_num_errors 8","title":"Task 3: Change the Scrub settings directly in the Configuration DB"},{"location":"linux/SES/linux_ses_demo/#task-4-manually-scrub-and-repair-an-osd-and-a-pg","text":"This won\u2019t do much in this demo environment, because the OSDs aren\u2019t storing very much data. But it\u2019s worth having some practice. 1). Start a scrubbing of one of the OSDs: admin:~ # ceph osd scrub osd.1 instructed osd(s) 1 to scrub 2). Scrub a Placement Group: admin:~ # ceph pg scrub 8.1 instructing pg 8.1 on osd.0 to scrub 3). Repair an OSD: admin:~ # ceph osd repair osd.1 instructed osd(s) 1 to repair 4). Repair a PG: admin:~ # ceph pg repair 8.1 instructing pg 8.1 on osd.0 to repair 5). Show what\u2019s currently happening to the OSD that you instructed to have scrubbed and repaired: admin:~ # ceph osd dump | grep osd.1 max_osd 12 osd.1 up in weight 1 up_from 10 up_thru 1415 down_at 0 last_clean_interval [0,0) v1:10.58.121.185:6800/11157 v1:10.58.121.185:6801/11157 exists,up 32c78078-1878-4fac-9738-00d8bf80deea osd.10 up in weight 1 up_from 18 up_thru 1413 down_at 0 last_clean_interval [0,0) v1:10.58.121.182:6808/11130 v1:10.58.121.182:6809/11130 exists,up 6cb26fdc-09b1-42de-8855-7203931a0101 osd.11 up in weight 1 up_from 18 up_thru 1415 down_at 0 last_clean_interval [0,0) v1:10.58.121.185:6808/11995 v1:10.58.121.185:6809/11995 exists,up cc22107d-0239-4874-8308-6c137c8a0931 6). Show what\u2019s currently happening to the PG that you instructed to have scrubbed and repaired: admin:~ # ceph pg dump | grep \"8\\.1\" dumped all 8.16 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.383909 0'0 1423:27 [6,4,5] 6 [6,4,5] 6 0'0 2021-01-05 20:53:47.314062 0'0 2021-01-05 20:53:47.314062 0 8.17 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:01.044252 0'0 1424:30 [1,6,8] 1 [1,6,8] 1 0'0 2021-01-05 22:57:01.044098 0'0 2021-01-05 22:57:01.044098 0 8.14 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:56:56.081480 0'0 1424:30 [1,2,4] 1 [1,2,4] 1 0'0 2021-01-05 22:56:56.081356 0'0 2021-01-05 22:56:56.081356 0 8.15 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.375386 0'0 1423:27 [3,5,0] 3 [3,5,0] 3 0'0 2021-01-05 20:53:53.231124 0'0 2021-01-05 20:48:05.301705 0 8.12 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.370121 0'0 1423:27 [11,2,8] 11 [11,2,8] 11 0'0 2021-01-05 20:53:48.149449 0'0 2021-01-05 20:48:05.301705 0 2.18 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 16:44:58.986205 0'0 1423:1630 [10,1,8] 10 [10,1,8] 10 0'0 2021-01-05 13:02:00.365382 0'0 2021-01-02 00:38:58.134100 0 8.13 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.387832 0'0 1423:27 [0,8,1] 0 [0,8,1] 0 0'0 2021-01-05 20:53:56.132358 0'0 2021-01-05 20:48:05.301705 0 8.10 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.368416 0'0 1423:27 [11,3,6] 11 [11,3,6] 11 0'0 2021-01-05 20:53:51.152790 0'0 2021-01-05 20:48:05.301705 0 8.11 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.377871 0'0 1423:24 [3,10,5] 3 [3,10,5] 3 0'0 2021-01-05 20:53:45.195257 0'0 2021-01-05 20:48:05.301705 0 8.1e 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.391754 0'0 1423:47 [0,11,8] 0 [0,11,8] 0 0'0 2021-01-05 20:53:55.081582 0'0 2021-01-05 20:48:05.301705 0 8.1 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:56:39.829397 0'0 1424:54 [0,7,10] 0 [0,7,10] 0 0'0 2021-01-05 22:56:39.829241 0'0 2021-01-05 22:56:39.829241 0 8.1f 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.392315 0'0 1423:27 [7,5,9] 7 [7,5,9] 7 0'0 2021-01-05 20:53:59.988252 0'0 2021-01-05 20:48:05.301705 0 5.4 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 18:21:28.179266 0'0 1423:1554 [7,9,6] 7 [7,9,6] 7 0'0 2021-01-05 18:21:28.179166 0'0 2021-01-05 18:21:28.179166 0 5.b 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 18:37:01.467457 0'0 1423:1547 [2,0,11] 2 [2,0,11] 2 0'0 2021-01-04 23:46:58.132824 0'0 2021-01-02 03:35:41.214192 0 8.19 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:06.059090 0'0 1424:30 [1,8,2] 1 [1,8,2] 1 0'0 2021-01-05 22:57:06.058935 0'0 2021-01-05 22:57:06.058935 0 8.18 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:05.097742 0'0 1424:30 [1,3,6] 1 [1,3,6] 1 0'0 2021-01-05 22:57:05.097670 0'0 2021-01-05 22:57:05.097670 0 1.11 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 00:30:18.193988 0'0 1423:1605 [0,8,6] 0 [0,8,6] 0 0'0 2021-01-05 00:30:18.193868 0'0 2020-12-29 06:30:58.897565 0 8.1b 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 22:57:13.146469 0'0 1424:30 [1,4,6] 1 [1,4,6] 1 0'0 2021-01-05 22:57:13.146390 0'0 2021-01-05 22:57:13.146390 0 8.1a 1 0 0 0 0 19 0 0 2 2 active+clean 2021-01-05 21:01:16.386166 1420'2 1423:29 [9,11,10] 9 [9,11,10] 9 0'0 2021-01-05 20:53:48.690239 0'0 2021-01-05 20:48:05.301705 0 8.1d 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.388079 0'0 1423:56 [0,2,3] 0 [0,2,3] 0 0'0 2021-01-05 20:53:54.121281 0'0 2021-01-05 20:48:05.301705 0 8.1c 0 0 0 0 0 0 0 0 0 0 active+clean 2021-01-05 21:01:16.385846 0'0 1423:27 [2,11,7] 2 [2,11,7] 2 0'0 2021-01-05 20:53:55.458714 0'0 2021-01-05 20:48:05.301705 0","title":"Task 4: Manually scrub and repair an OSD and a PG"},{"location":"linux/SES/linux_ses_demo/#225-manipulate-manager-modules","text":"","title":"2.2.5. Manipulate Manager Modules"},{"location":"linux/SES/linux_ses_demo/#task-1-display-the-list-of-enabled-manager-modules","text":"1). Run the following command to show the list of enabled manager modules: Note that several modules are already enabled, such as: dashboard, iostat, pg_autosclater, prometheus, and restful. Even though they are not listed, the crash module and the balancer module are already enabled by default. admin:~ # ceph mgr module ls | head { \"always_on_modules\": [ \"balancer\", \"crash\", \"devicehealth\", \"orchestrator_cli\", \"progress\", \"rbd_support\", \"status\", \"volumes\" 2). Demonstrate that the crash module is enabled by running its command with no arguments: A list of \u201c7 closest matches\u201d is displayed, representing possible additional arguments to be used with the crash command. The crash module is therefore available. admin:~ # ceph crash crash info <id> crash ls crash ls-new crash post crash prune <keep> crash rm <id> crash stat crash json_report <hours> crash archive <id> crash archive-all admin:~ # ceph crash stat 0 crashes recorded Task 2: Use the iostat module to display statistics for the IO of the cluster The iostat module is really simple, but very helpful. Run the command: admin:~ # ceph iostat +-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+ | Read | Write | Total | Read IOPS | Write IOPS | Total IOPS | +-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+-----------------------------+ | 1024 B/s | 0 B/s | 1024 B/s | 1 | 0 | 1 | | 1024 B/s | 0 B/s | 1024 B/s | 1 | 0 | 1 | | 0 B/s | 0 B/s | 0 B/s | 0 | 0 | 0 | Task 3: Enable and configure the telemetry manager module 1). Enable the telemetry manager module: admin:~ # ceph mgr module enable telemetry 2). Show the various sub-commands that are associated with the telemetry command: A list of \u201c5 closest matches\u201d is displayed, showing various options. admin:~ # ceph telemetry telemetry status telemetry send {ceph|device [ceph|device...]} {<license>} telemetry show {<channels> [<channels>...]} telemetry show-device telemetry on {<license>} telemetry off 3). Show the status of the telemetry module: Notice that the output is returned as key/value pairs. Notice also that although the module has been enabled (which you accomplished in the first step of this task), the functionality is not enabled (enable=false). And for most of the keys, a null value is set. See that the url value is set to https://telemetry.ceph.com/report. That means that crash reports and other usage information about this cluster are going to be sent to the Ceph Community. admin:~ # ceph telemetry status { \"url\": \"https://telemetry.ceph.com/report\", \"device_url\": \"https://telemetry.ceph.com/device\", \"enabled\": false, \"last_opt_revision\": 1, \"leaderboard\": false, \"description\": null, \"contact\": null, \"organization\": null, \"proxy\": null, \"interval\": 24, \"channel_basic\": true, \"channel_ident\": false, \"channel_crash\": true, \"channel_device\": true, \"last_upload\": null } 4). Set the description, contact, and organization values: admin:~ # ceph config set mgr mgr/telemetry/contact 'JD <james@example.net>' admin:~ # ceph config set mgr mgr/telemetry/description 'Training Cluster' admin:~ # ceph config set mgr mgr/telemetry/organization 'SUSE Training' 5). Display the telemetry data that is collected to be sent: admin:~ # ceph telemetry show | less 6). With the contact information properly set, enable the telemetry functionality: This is a demo cluster with no connection to the internet, so no telemetry data will actually be sent. admin:~ # ceph telemetry on Error EPERM: Telemetry data is licensed under the Community Data License Agreement - Sharing - Version 1.0 (https://cdla.io/sharing-1-0/). To enable, add '--license sharing-1-0' to the 'ceph telemetry on' command. admin:~ # ceph telemetry on --license sharing-1-0 7). Disable the telemetry module: admin:~ # ceph mgr module disable telemetry admin:~ # ceph telemetry show | less Error ENOTSUP: Module 'telemetry' is not enabled (required by command 'telemetry show'): use `ceph mgr module enable telemetry` to enable it","title":"Task 1: Display the list of enabled Manager Modules"},{"location":"linux/SES/linux_ses_demo/#task-4-briefly-attempt-to-use-the-crash-manager-module","text":"1). Show (again) the various sub-commands that are associated with the crash command: admin:~ # ceph crash crash info <id> crash ls crash ls-new crash post crash prune <keep> crash rm <id> crash stat crash json_report <hours> crash archive <id> crash archive-all 2). Show the current status of the crash database, including the numbgr of crash reports that have been collected so far: It\u2019s likely that the numbgr of crashes recorded in the demo environment is 0. admin:~ # ceph crash stat 0 crashes recorded","title":"Task 4: Briefly attempt to use the crash manager module"},{"location":"linux/SES/linux_ses_demo/#226-introduction-to-the-tell-command","text":"Tell is a very powerful command within Ceph to control the cluster. You don\u2019t use it everyday, but you need to know how to use it when the occasion to use it arises. It\u2019s mostly an Advanced Command, but exposure to it now reduces the stress of learning about it in a more advanced setting later. Run the tell command in a few different circumstances to control the behavior of various Ceph services.","title":"2.2.6. Introduction to the Tell command"},{"location":"linux/SES/linux_ses_demo/#task-1-run-a-benchmark-test-on-an-osd","text":"1). Run the following command to run and see the result of a benchmark test on osd.8: admin:~ # ceph tell osd.8 bench { \"bytes_written\": 1073741824, \"blocksize\": 4194304, \"elapsed_sec\": 3.7797023200000002, \"bytes_per_sec\": 284081055.35676152, \"iops\": 67.730201567831401 }","title":"Task 1: Run a benchmark test on an OSD"},{"location":"linux/SES/linux_ses_demo/#task-2-change-the-protection-setting-regarding-the-deletion-of-pools","text":"1). The default behavior in Ceph is that you can\u2019t delete pools. Try to delete a pool: The output says that you have to be VERY careful and provide more arguments in order to delete a pool admin:~ # ceph osd pool delete rbd_pool Error EPERM: WARNING: this will *PERMANENTLY DESTROY* all data stored in pool rbd_pool. If you are *ABSOLUTELY CERTAIN* that is what you want, pass the pool name *twice*, followed by --yes-i-really-really-mean-it. 2). Try deleting the pool again, this time with the extra arguments: Ceph still won\u2019t let you do it because the mon allow pool delete setting has the value of false. admin:~ # ceph osd pool delete rbd_pool rbd_pool --yes-i-really-really-mean-it Error EPERM: pool deletion is disabled; you must first set the mon_allow_pool_delete config option to true before you can destroy a pool 3). Show that the mon allow pool delete setting has the value of false: Indeed, the output shows that the value is false. admin:~ # ceph config get mon.mon\\* mon_allow_pool_delete false 4). Change to value of the setting using injectargs: Note that the \u201c-\u201d and \u201c_\u201d characters can be confusing. And note that the setting is preceded with the double \u201c--\u201d. The injected args must be enclosed in single quotes. You could have done this with ceph config set, but this is an alternative way to directly \u201ctell\u201d the cluster to change a setting. admin:~ # ceph tell mon.\\* injectargs '--mon-allow-pool-delete=true' mon.mon1: injectargs:mon_allow_pool_delete = 'true' mon.mon2: injectargs:mon_allow_pool_delete = 'true' mon.mon3: injectargs:mon_allow_pool_delete = 'true'","title":"Task 2: Change the protection setting regarding the deletion of pools"},{"location":"linux/SES/linux_ses_demo/#23-ceph-dashboard","text":"","title":"2.3. Ceph Dashboard"},{"location":"linux/SES/linux_ses_demo/#231-access-dashboard","text":"","title":"2.3.1. Access Dashboard"},{"location":"linux/SES/linux_ses_demo/#task-1-set-the-password-for-the-admin-user-of-the-ceph-dashboard","text":"1). In a Bash terminal as the root user, show that the Dashboard module is enabled: \u201cdashboard\u201d should be included in the list of \u201cenabled_modules\u201d at the top of the output. admin:~ # ceph mgr module ls | more \"enabled_modules\": [ \"dashboard\", \"iostat\", \"pg_autoscaler\", \"prometheus\", \"restful\" ], 2). Show the valid dashboard users that have already been created by DeepSea during initial deployment: It\u2019s possible that other users will be listed, but at least the \u201cadmin\u201d user should be displayed in the output. admin:~ # ceph dashboard ac-user-show [\"admin\"] 3). Show the \u201cadmin\u201d user\u2019s information as stored in the user database: You can see that the admin user has a password set, but it is stored as a hash. So you don\u2019t really know what the password is, and have no way of discovering it. admin:~ # ceph dashboard ac-user-show admin {\"username\": \"admin\", \"password\": <your password>, \"roles\": [\"administrator\"], \"name\": null, \"email\": null, \"lastUpdate\": 1601874928} 4). Change the \u201cadmin\u201d user\u2019s password for the dashboard: This sets the \u201cadmin\u201d user\u2019s password to the string: mypassword admin:~ # ceph dashboard ac-user-set-password admin mypassword {\"username\": \"admin\", \"password\": <your password>, \"roles\": [\"administrator\"], \"name\": null, \"email\": null, \"lastUpdate\": 1609860842} admin:~ #","title":"Task 1: Set the password for the admin user of the Ceph Dashboard"},{"location":"linux/SES/linux_ses_demo/#task-3-visit-the-ceph-dashboard-url","text":"admin:~ # salt-call grains.get dashboard_creds local: ---------- admin: <your password> admin:~ # ceph mgr services { \"dashboard\": \"https://mon1.sha.me.corp:8443/\", \"prometheus\": \"http://mon1.sha.me.corp:9283/\" } admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 25m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 5h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 9 pools, 244 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 244 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr URL: https://mon1.sha.me.corp:8443/ https://10.58.121.186:8443","title":"Task 3: Visit the Ceph Dashboard URL"},{"location":"linux/SES/linux_ses_demo/#232-explore-the-dashboard-health-performance-status","text":"Dashboard Status Cluster Status Monitors OSDs Manager Daemons Hosts Object Gateway Metadata Service iSCSI Gateway Performance Client IOPS Client Throughput Client Read/Write Recovery Throughput Scrub Capacity Pools Raw Capacity Objects PGs per OSD PG Status [SUSE Enterprise Storage Portal Cluster-->Configuration Cluster-->Manager Modules Pools-->Create Pool","title":"2.3.2. Explore the Dashboard Health, Performance, Status"},{"location":"linux/SES/linux_ses_demo/#24-storage-data-access","text":"","title":"2.4. Storage Data Access"},{"location":"linux/SES/linux_ses_demo/#241-ensure-the-ses-cluster-is-healthy","text":"","title":"2.4.1. Ensure the SES Cluster is Healthy"},{"location":"linux/SES/linux_ses_demo/#task-1-check-the-clusters-health","text":"1). Run the following command to check the status (health) of the SES cluster: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 9w) mgr: mon1(active, since 18h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 23h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr 2). Evaluate the output. The cluster in this demonstration environment often doesn\u2019t startup correctly due to the nature of a demo environment and it\u2019s less-predictable resources. Depending on whether any of the following tasks are necessary, followup accordingly to ensure that the cluster is healthy before proceeding with the course lectures or any further exercises. 3). Run the following series of commands to restart the Monitor daemons on each of the Monitor nodes: It\u2019s certainly not necessary to restart the monitor daemons on all of the monitor nodes if only one is down. If you prefer, you can take a different approach to starting the daemon on a single monitor node. admin:~ # for h in mon1 mon2 mon3; \\ do \\ ssh $h systemctl restart ceph-mon@$h; \\ done 4). After waiting a few moments for the daemons to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 15s) mgr: mon1(active, since 21h) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 5.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 767 B/s rd, 0 op/s rd, 0 op/s wr 5). Run the following series of commands to restart the Manager daemons on each of the Monitor nodes: admin:~ # for h in mon1 mon2 mon3; \\ do \\ ssh $h systemctl restart ceph-mgr@$h; \\ done 6). After waiting a few moments for the daemons to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 8m) mgr: mon1(active, since 18s) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.1 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr 7). Run the following command to restart the MDS daemon on the MDS node (mon1): admin:~ # ssh mon1 systemctl restart ceph-mds@mon1.service 8). After waiting a few moments for the mds daemon to restart, check the status again: Look for the mds service to be plain active rather than laggy or crashed admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 17m) mgr: mon1(active, since 8m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 26h), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr 9). Verify if the OSDs \u201cup\u201d and running properly. It is only necessary if the output of ceph -s shows that there are fewer than 9 OSDs shown as being \u201cup\u201d. It\u2019s most likely that a storage node is simply not quite fully booted yet, such that the OSD daemons haven\u2019t fully come up. But if you suspect that the solution requires something different than simply waiting a little longer, you should try the following steps. First, identify which server is hosting the down\u2019d OSDs. One way of doing that is with this command: admin:~ # ceph osd tree ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF -1 0.09357 root default -9 0.02339 host data1 2 hdd 0.00780 osd.2 up 1.00000 1.00000 6 hdd 0.00780 osd.6 up 1.00000 1.00000 10 hdd 0.00780 osd.10 up 1.00000 1.00000 -3 0.02339 host data2 0 hdd 0.00780 osd.0 up 1.00000 1.00000 4 hdd 0.00780 osd.4 up 1.00000 1.00000 9 hdd 0.00780 osd.9 up 1.00000 1.00000 -7 0.02339 host data3 3 hdd 0.00780 osd.3 up 1.00000 1.00000 7 hdd 0.00780 osd.7 up 1.00000 1.00000 8 hdd 0.00780 osd.8 up 1.00000 1.00000 -5 0.02339 host data4 1 hdd 0.00780 osd.1 up 1.00000 1.00000 5 hdd 0.00780 osd.5 up 1.00000 1.00000 11 hdd 0.00780 osd.11 up 1.00000 1.00000 Simply try restarting the storage daemon processes on the affected host, such as with this example: admin:~ # ssh data2 systemctl restart ceph-osd@9.service admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 32m) mgr: mon1(active, since 24m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 27s), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 852 B/s rd, 0 op/s rd, 0 op/s wr If the OSD daemon processes are being stubborn and uncooperative, you may choose to reboot the storage virtual machine entirely. This is one way to do that: admin:~ # ssh data1 systemctl reboot After waiting some time for the daemons to get started, verify that all the OSDs are \u201cup\u201d and that the cluster is healthy: admin:~ # ceph osd tree admin:~ # ceph status 10). Run the following command to restart the RADOS Gateway daemon on the node that is hosting the gateway (mon3): admin:~ # ssh mon3 systemctl restart ceph-radosgw@rgw.mon3.service admin:~ # ssh mon3 systemctl status ceph-radosgw@rgw.mon3.service \u25cf ceph-radosgw@rgw.mon3.service - Ceph rados gateway Loaded: loaded (/usr/lib/systemd/system/ceph-radosgw@.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2021-01-06 21:37:53 CST; 23s ago Main PID: 781880 (radosgw) Tasks: 588 CGroup: /system.slice/system-ceph\\x2dradosgw.slice/ceph-radosgw@rgw.mon3.service \u2514\u2500781880 /usr/bin/radosgw -f --cluster ceph --name client.rgw.mon3 --setuser ceph --setgroup ceph Jan 06 21:37:53 mon3 systemd[1]: Started Ceph rados gateway. 11). After waiting a few moments for the daemon to restart, check the status again: admin:~ # ceph -s cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_WARN 1 subtrees have overcommitted pool target_size_bytes 1 pools have too few placement groups services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 39m) mgr: mon1(active, since 30m) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 6m), 12 in (since 3M) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 10 pools, 248 pgs objects: 247 objects, 6.2 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 248 active+clean io: client: 1.2 KiB/s rd, 1 op/s rd, 0 op/s wr","title":"Task 1: Check the Cluster\u2019s health"},{"location":"linux/SES/linux_ses_demo/#242-use-the-s3-api-to-interact-with-the-rados-gateway","text":"In this lab we used the s3cmd and radosgw-admin utilities to interact with the SUSE Enterprise Storage cluster. We created a new user, a new bucket, and a new file. We then uploaded the file to the cluster and verified that the object gateway stored it to the cluster.","title":"2.4.2. Use the S3 API to Interact with the RADOS Gateway"},{"location":"linux/SES/linux_ses_demo/#task-1-using-the-s3cmd-tool-and-create-an-s3-user","text":"1). As the root user (password is linux) in a shell or terminal, verify that the s3cmd is available on the admin node: You will likely see an error about configuration files missing, etc. This is enough information to validate the utility is installed. admin:~ # pip --version pip 10.0.1 from /usr/lib/python3.6/site-packages/pip (python 3.6) admin:~ # pip install s3cmd Collecting s3cmd Downloading https://files.pythonhosted.org/packages/26/44/19e08f69b2169003f7307565f19449d997895251c6a6566ce21d5d636435/s3cmd-2.1.0-py2.py3-none-any.whl (145kB) 100% | 153kB 2.7MB/s Collecting python-magic (from s3cmd) Downloading https://files.pythonhosted.org/packages/59/77/c76dc35249df428ce2c38a3196e2b2e8f9d2f847a8ca1d4d7a3973c28601/python_magic-0.4.18-py2.py3-none-any.whl Requirement already satisfied: python-dateutil in /usr/lib/python3.6/site-packages (from s3cmd) (2.7.3) Requirement already satisfied: six>=1.5 in /usr/lib/python3.6/site-packages (from python-dateutil->s3cmd) (1.11.0) Installing collected packages: python-magic, s3cmd Successfully installed python-magic-0.4.18 s3cmd-2.1.0 2). Create a new S3 user to be used: The output will include an access_key value and a secret_key value. You will need both of those values in later steps. admin:~ # radosgw-admin user create --uid=s3user --display-name=S3 User --email=s3user@example.net { \"user_id\": \"s3user\", \"display_name\": \"S3\", \"email\": \"s3user@example.net\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [], \"keys\": [ { \"user\": \"s3user\", \"access_key\": <your key>, \"secret_key\": <your key> } ], \"swift_keys\": [], \"caps\": [], \"op_mask\": \"read, write, delete\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] } Retrieve above information admin:~ # radosgw-admin user info --uid=s3user","title":"Task 1: Using the s3cmd tool and create an S3 user"},{"location":"linux/SES/linux_ses_demo/#task-2-create-a-new-s3cmd-configuration-file-and-a-new-s3-bucket","text":"1). Generate a new s3cmd configuration file from a shell on the admin node: Fill in as listed below: admin:~ # cd ~ admin:~ # s3cmd --configure Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: <your key> Secret Key: <your key> Default Region [US]: <leave blank> Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: mon3.sha.me.corp Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: %(bucket)s.mon3.sha.me.corp Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: <leave blank> Path to GPG program [/usr/bin/gpg]: <leave blank> When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: No On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: <leave blank> New settings: Access Key: <your key> Secret Key: <your key> Default Region: US S3 Endpoint: mon3.sha.me.corp DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.mon3.sha.me.corp Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Configuration saved to '/root/.s3cfg' 2). Test the configuration by checking for existing files or directories: Since no buckets or files have been made available for the user, no items are listed and the command returns you to the prompt with no output. This is normal. If there is an error, your configuration may have a typo in it. The configuration file will have been saved as .s3cfg. Edit the file to match the configuration in step one. admin:~ # s3cmd ls 3). Create a new bucket for uploading files to using the s3cmd: You should see feedback that the bucket has been created. Although not technically required by the S3 API, the bucket name needs to be in all uppercase to avoid a bug with the s3cmd tool itself. admin:~ # s3cmd mb s3://S3CMDTEST Bucket 's3://S3CMDTEST/' created admin:~ # s3cmd ls 2021-01-06 14:04 s3://S3CMDTEST (it's GMT timezone)","title":"Task 2: Create a new s3cmd configuration file and a new S3 bucket"},{"location":"linux/SES/linux_ses_demo/#task3-create-and-upload-a-file-to-a-bucket-using-the-s3-api","text":"1). Create a file with a few words of text: admin:~ # echo \"The mountains are beautiful\" > newfile 2). Put the new file into your bucket using s3cmd: You should see the file being uploaded. admin:~ # s3cmd put newfile s3://S3CMDTEST upload: 'newfile' -> 's3://S3CMDTEST/newfile' [1 of 1] 28 of 28 100% in 3s 7.66 B/s done 3). Verify the file is now in your bucket, safely stored in you SES cluster: admin:~ # s3cmd ls s3://S3CMDTEST 2021-01-06 14:11 28 s3://S3CMDTEST/newfile","title":"Task3: Create and upload a file to a bucket using the S3 API"},{"location":"linux/SES/linux_ses_demo/#243-use-the-swift-api-to-interact-with-the-rados-gateway","text":"OpenStack packages for SUSE Install and configure the storage nodes for openSUSE and SUSE Linux Enterprise SUSE Package Hub: python-PasteDeploy Enable SUSE Package Hub extension admin:~ # SUSEConnect -p PackageHub/15.1/x86_64 Install python3-PasteDeploy, which is dependency of python-swift installation admin:~ # zypper in python3-PasteDeploy admin:~ # rpm -ivh python3-PyECLib-1.6.0-1.6.x86_64.rpm warning: python3-PyECLib-1.6.0-1.6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 3dbdc284: NOKEY error: Failed dependencies: python(abi) = 3.8 is needed by python3-PyECLib-1.6.0-1.6.x86_64 rpmlib(PayloadIsZstd) <= 5.4.18-1 is needed by python3-PyECLib-1.6.0-1.6.x86_64 Add OpenStack Swift Repository for SUSE admin:~ # zypper addrepo -f obs://Cloud:OpenStack:Train/SLE_15_SP1 Train admin:~ # zypper in openstack-swift openstack-swift-account openstack-swift-container openstack-swift-object","title":"2.4.3. Use the swift API to Interact with the RADOS Gateway"},{"location":"linux/SES/linux_ses_demo/#task-1-create-a-swift-subuser","text":"1). In a shell or terminal as the root user (password of linux) on the admin node, create a new subuser: The output will contain the access and secret keys for the s3user and a secret key for the new swift subuser.. admin:~ # radosgw-admin subuser create --uid=s3user --subuser=s3user:swift --access=full { \"user_id\": \"s3user\", \"display_name\": \"S3\", \"email\": \"s3user@example.net\", \"suspended\": 0, \"max_buckets\": 1000, \"subusers\": [ { \"id\": \"s3user:swift\", \"permissions\": \"full-control\" } ], \"keys\": [ { \"user\": \"s3user\", \"access_key\": <your key>, \"secret_key\": <your key> } ], \"swift_keys\": [ { \"user\": \"s3user:swift\", \"secret_key\": <your key> } ], \"caps\": [], \"op_mask\": \"read, write, delete\", \"default_placement\": \"\", \"default_storage_class\": \"\", \"placement_tags\": [], \"bucket_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"user_quota\": { \"enabled\": false, \"check_on_raw\": false, \"max_size\": -1, \"max_size_kb\": 0, \"max_objects\": -1 }, \"temp_url_keys\": [], \"type\": \"rgw\", \"mfa_ids\": [] } 2). Verify that the subuser has access to at least one bucket and list the buckets with a swift command: swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '{SECRET_KEY_FROM_STEP_1}' list admin:~ # swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '<your key>' list S3CMDTEST","title":"Task 1: Create a swift subuser"},{"location":"linux/SES/linux_ses_demo/#task-2-use-the-swift-command-to-access-a-file-created-with-the-s3cmd-tool","text":"1). Since the S3 API and the swift API are accessing the same SUSE Enterprise Storage cluster, and since the RADOS gateway is built to be inter-operable with both, you can use the swift API to retrieve the object which was uploaded to SES via the S3 API: swift -A http://mon3.example.net/auth/1.0 -U s3user:swift -K '{SECRET_KEY_FROM_STEP_1}' download -a An example of the command is listed here: admin:~ # swift -A http://mon3.sha.me.corp/auth/1.0 -U s3user:swift -K '<your key>' download -a Although we have taken a shortcut by using the -a option (meaning grab every object this user has access to), it illustrates the tool\u2019s capability. We\u2019ve uploaded the newfile with S3, we\u2019ve retrieved it with swift.","title":"Task 2: Use the swift command to access a file created with the S3cmd tool"},{"location":"linux/SES/linux_ses_demo/#244-create-snapshots-on-ses-using-rbd","text":"In this lab we worked with rbd images. We mapped an rbd image to a Linux device file, then created a filesystem and mounted it. Then we created snapshots to preserve the images data state at a particular time, and rolled it back to demonstrate functionality.","title":"2.4.4. Create Snapshots on SES using RBD"},{"location":"linux/SES/linux_ses_demo/#task-1-create-a-new-pool-for-rbd-images","text":"1). Access https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 2). Log in with the following credentials: Username: admin Password: mypassword 3). Click on the Pools tab near the top of the page 4). Click the Create button and use the following in the available fields: Name: rbd-images Pool type: replicated Placement groups: 16 Crush ruleset: replicated_rule Replicted size: 2 Applications: rbd Compression Mode: none 5). Click Create Pool","title":"Task 1: Create a new pool for RBD images"},{"location":"linux/SES/linux_ses_demo/#task-2-create-a-new-rbd-image-in-the-rbd-images-pool","text":"6). Create a new RBD image using the rbd command: admin:~ # rbd create --size 1024 rbd-images/barfoo 7). Verify the new image has been created in the rbd-images pool: The new image named barfoo should be displayed. admin:~ # rbd ls -p rbd-images barfoo","title":"Task 2: Create a new RBD image in the rbd-images pool"},{"location":"linux/SES/linux_ses_demo/#task-3-mount-the-new-image-on-the-admin-node-and-create-a-filesystem","text":"1). As the root user in a shell or terminal on the admin node, map the new rbd image to a block device: admin:~ # rbd map rbd-images/barfoo /dev/rbd0 2). Create a filesystem on the newly mapped device: admin:~ # mkfs.ext4 /dev/rbd0 mke2fs 1.43.8 (1-Jan-2018) Discarding device blocks: done Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: 19da6b86-1989-4834-a365-2f654fcce6f6 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 3). Mount the image to the /mnt directory: admin:~ # mount /dev/rbd0 /mnt admin:~ # l /mnt total 20 drwxr-xr-x 3 root root 4096 Jan 6 23:48 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ drwx------ 2 root root 16384 Jan 6 23:48 lost+found/","title":"Task 3: Mount the new image on the admin node and create a filesystem"},{"location":"linux/SES/linux_ses_demo/#task-4-create-a-file-on-the-new-filesystem-and-snapshot-the-rbd-image-and-make-some-additional-changes","text":"1). Change to the /mnt directory and create a simple file: admin:~ # cd /mnt admin:/mnt # echo \"This is some sample text\" > start.txt 2). List the directories contents to see that the start.txt file has been created on the storage cluster. admin:/mnt # ls -l total 20 drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 3). Create a snapshot of what the rbd image contained: Wait for confirmation that the snapshot has been created. It should only take a few seconds. admin:/mnt # rbd snap create rbd-images/barfoo@begin 4). List the rbd snapshots for the rbd-images/barfoo image: You should see the new snap called begin listed. admin:/mnt # rbd snap ls rbd-images/barfoo SNAPID NAME SIZE PROTECTED TIMESTAMP 4 begin 1 GiB Wed Jan 6 23:51:12 2021 5). Add another file to the filesystem: admin:/mnt # echo \"Some more text\" > end.txt 6). List the contents of the /mnt to verify the existence of two files. admin:/mnt # ls -l total 24 -rw-r--r-- 1 root root 15 Jan 6 23:52 end.txt drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 7). Create a second snapshot of the rbd-images/barfoo image: admin:/mnt # rbd snap create rbd-images/barfoo@finish 8). List the rbd snapshots: There should be begin and finish snapshots. admin:/mnt # rbd snap ls rbd-images/barfoo SNAPID NAME SIZE PROTECTED TIMESTAMP 4 begin 1 GiB Wed Jan 6 23:51:12 2021 5 finish 1 GiB Wed Jan 6 23:53:15 2021 9). List the contents of the /mnt directory again and verify the two files. 10). Rollback the data to the begin snapshot: This process will be relatively quick because the size of the image is small and we have very little data on it. admin:/mnt # rbd snap rollback rbd-images/barfoo@begin Rolling back to snapshot: 100% complete...done. 11). Change to the root user\u2019s home directory, then remount the image in order to see that the rbd image has been rolled back: admin:/mnt # cd ~ admin:~ # umount /mnt admin:~ # mount /dev/rbd0 /mnt 12). List the contents of the /mnt directory to verify that only the start.txt file exists on the image. admin:/mnt # ls -l total 20 drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 13). Rollback the data to the finish snapshot: admin:/mnt # rbd snap rollback rbd-images/barfoo@finish Rolling back to snapshot: 100% complete...done. 14). Unmount and remount the image: admin:/mnt # cd ~ admin:~ # umount /mnt admin:~ # mount /dev/rbd0 /mnt 15). List the contents of the /mnt directory to show it has indeed been rolled back and contains the start.txt and end.txt files admin:/mnt # ls -l total 24 -rw-r--r-- 1 root root 15 Jan 6 23:52 end.txt drwx------ 2 root root 16384 Jan 6 23:48 lost+found -rw-r--r-- 1 root root 25 Jan 6 23:50 start.txt 16). Change to the root user\u2019s home directory and unmount the image: admin:/mnt # cd ~ admin:~ # umount /mnt","title":"Task 4: Create a file on the new filesystem and snapshot the rbd image and make some additional changes"},{"location":"linux/SES/linux_ses_demo/#245-create-and-manage-cow-clones-with-rbd","text":"In this lab you will created a new pool and block device image in the pool. You then mapped the block storage to a linux device and took a snapshot. Finally you protected the snapshot from modification. This would be done so the snapshot can be safely used as a parent cow image which can then be cloned to create new virtual machines.","title":"2.4.5. Create and manage COW Clones with rbd"},{"location":"linux/SES/linux_ses_demo/#task-1-create-a-new-pool","text":"1). View the current osds and pools: admin:~ # ceph osd ls 0 1 2 3 4 5 6 7 8 9 10 11 admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images 2). Create a new pool called cow-pool: admin:~ # ceph osd pool create cow-pool 128 pool 'cow-pool' created 3). List the available pools to view the new pool using either of the following commands: admin:~ # ceph osd pool ls iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images cow-pool admin:~ # rados lspools iscsi-images cephfs_data cephfs_metadata .rgw.root default.rgw.control default.rgw.meta default.rgw.log rbd_pool bucket_pool EC_RBD_Pool default.rgw.buckets.index default.rgw.buckets.data rbd-images cow-pool Task 2: Create a block device image in a pool 1). Create a format 2 rbd image called cow-base in the cow-pool storage pool with a size of 1GB *Note that the \u2013image-format statement is optional as format 2 is default admin:~ # rbd create -p cow-pool cow-base --size 1024 --image-format 2 2). Check that the image has been created, that the format is 2 and that layering (COW Clones) is supported admin:~ # rbd -p cow-pool list cow-base admin:~ # rbd -p cow-pool info cow-base rbd image 'cow-base': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 269d5b817222aa block_name_prefix: rbd_data.269d5b817222aa format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:12:31 2021 access_timestamp: Thu Jan 7 10:12:31 2021 modify_timestamp: Thu Jan 7 10:12:31 2021 Task 3: Map the block storage image to a Linux host 1). In a shell or terminal as user root open a terminal window. Using the rbd map command, map an rbd device to the block-storage image created above. admin:~ # rbd map -p cow-pool --image cow-base /dev/rbd1 2). View the mapped block devices admin:~ # rbd showmapped id pool namespace image snap device 0 rbd-images barfoo - /dev/rbd0 1 cow-pool cow-base - /dev/rbd1 3). Note the rbd index numbgr (e.g. rbd0, rbd1) associated with the cow-base image: RBD ___1____ 4). View the devices in /dev. Note the device name(s) admin:~ # ls -l /dev/rbd* brw-rw---- 1 root disk 252, 0 Jan 6 23:49 /dev/rbd0 brw-rw---- 1 root disk 252, 16 Jan 7 10:14 /dev/rbd1 /dev/rbd: total 0 drwxr-xr-x 2 root root 60 Jan 7 10:14 cow-pool drwxr-xr-x 2 root root 60 Jan 6 23:48 rbd-images 5). View the block device:(use the device numbgr from step above) admin:~ # fdisk -l /dev/rbd1 Disk /dev/rbd1: 1 GiB, 1073741824 bytes, 2097152 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 4194304 bytes / 4194304 bytes 6). Format the device with an ext4 filesystem: admin:~ # mkfs.ext4 /dev/rbd1 mke2fs 1.43.8 (1-Jan-2018) Discarding device blocks: done Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: 64c9a973-cf31-4239-881f-ec5642bf34e3 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 7). Mount the block device on the local filesystem: admin:~ # mkdir /mnt/cow-base admin:~ # mount /dev/rbd1 /mnt/cow-base 8). Test the storage access by creating a file: admin:~ # cd /mnt/cow-base admin:/mnt/cow-base # touch base-image-file admin:/mnt/cow-base # ls base-image-file lost+found","title":"Task 1: Create a new pool"},{"location":"linux/SES/linux_ses_demo/#task-4-snapshot-the-rbd-image-and-protect-the-snapshot","text":"1). List the snapshots in the cow-base image: admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base 2). Create a snapshot of the cow-base rbd image which contains the base-image-file file admin:/mnt/cow-base # rbd snap create cow-pool/cow-base@base-snap 3). List the snapshot: admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base SNAPID NAME SIZE PROTECTED TIMESTAMP 4 base-snap 1 GiB Thu Jan 7 10:37:13 2021 4). This snapshot will form the parent snapshot for COW clone images so you will now protected it from modification: admin:/mnt/cow-base # rbd snap protect cow-pool/cow-base@base-snap admin:/mnt/cow-base # rbd snap ls cow-pool/cow-base SNAPID NAME SIZE PROTECTED TIMESTAMP 4 base-snap 1 GiB yes Thu Jan 7 10:37:13 2021 Task 5: Create writable COW clones from the parent snapshot 1). Create a COW clone from the cow-base with the base-snap snapshot as the parent image admin:/mnt/cow-base # rbd clone cow-pool/cow-base@base-snap cow-pool/cow-image1 2). Check the information for the new image admin:/mnt/cow-base # rbd -p cow-pool --image cow-image1 info rbd image 'cow-image1': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a1209678cad4 block_name_prefix: rbd_data.26a1209678cad4 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:38:58 2021 access_timestamp: Thu Jan 7 10:38:58 2021 modify_timestamp: Thu Jan 7 10:38:58 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB 3). Note that the image has details of the parent image and overlap 4). Repeat steps 2 & 3 for an additional image called cow-image2 admin:/mnt/cow-base # rbd clone cow-pool/cow-base@base-snap cow-pool/cow-image2 admin:/mnt/cow-base # rbd -p cow-pool --image cow-image2 info rbd image 'cow-image2': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a2fbcec7b8d9 block_name_prefix: rbd_data.26a2fbcec7b8d9 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:47:28 2021 access_timestamp: Thu Jan 7 10:47:28 2021 modify_timestamp: Thu Jan 7 10:47:28 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB Task 6: Test that the COW clones are functional 1). Create a new directory and mount the COW clone called cow-image1 Note the rbd device name and use it to mount the file system admin:/mnt # mkdir /mnt/cow-image1 admin:/mnt # rbd map -p cow-pool --image cow-image1 /dev/rbd2 admin:/mnt # l total 4 drwxr-xr-x 1 root root 36 Jan 7 10:54 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ drwxr-xr-x 3 root root 4096 Jan 7 10:19 cow-base/ drwxr-xr-x 1 root root 0 Jan 7 10:54 cow-image1/ admin:/mnt # ls -l /dev/rbd* brw-rw---- 1 root disk 252, 0 Jan 6 23:49 /dev/rbd0 brw-rw---- 1 root disk 252, 16 Jan 7 10:18 /dev/rbd1 brw-rw---- 1 root disk 252, 32 Jan 7 10:55 /dev/rbd2 /dev/rbd: total 0 drwxr-xr-x 2 root root 80 Jan 7 10:55 cow-pool drwxr-xr-x 2 root root 60 Jan 6 23:48 rbd-images admin:/mnt # mount /dev/rbd2 /mnt/cow-image1 2). Check that the base-image-file which was created in the parent snapshot is present admin:/mnt # cd /mnt/cow-image1 admin:/mnt/cow-image1 # ls base-image-file lost+found 3). Repeat steps 1 and 2 for cow-image2 admin:/mnt # mkdir /mnt/cow-image2 admin:/mnt # rbd map -p cow-pool --image cow-image2 /dev/rbd3 admin:/mnt # mount /dev/rbd3 /mnt/cow-image2 admin:/mnt # ls ./cow-image2/ base-image-file lost+found --> same file with image1 4). Create a new file in the directory where cow-image1 is mounted admin:/mnt # cd cow-image1 admin:/mnt/cow-image1 # touch additional-file admin:/mnt/cow-image1 # ls additional-file base-image-file lost+found 5). Look in the cow-image2 directory. Although they share the same parent snapshot, you can see that the files contained in each COW image are now different. admin:/mnt # ls ./cow-image2/ base-image-file lost+found","title":"Task 4: Snapshot the rbd image and protect the snapshot"},{"location":"linux/SES/linux_ses_demo/#task-7-flatten-a-cow-clone-and-remove-the-parent-image","text":"1). Convert the COW clone called cow-image1 to a standalone rbd image Wait while the flatten process completes. Unlike a clone process this is not instantaneous and can take considerable time. admin:/mnt # rbd flatten cow-pool/cow-image1 Image flatten: 100% complete...done. 2). Check to see that the flatten process has removed the link to the parent snapshot admin:/mnt # rbd -p cow-pool --image cow-image1 info rbd image 'cow-image1': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a1209678cad4 block_name_prefix: rbd_data.26a1209678cad4 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:38:58 2021 access_timestamp: Thu Jan 7 10:38:58 2021 modify_timestamp: Thu Jan 7 10:38:58 2021 admin:/mnt # rbd -p cow-pool --image cow-image2 info rbd image 'cow-image2': size 1 GiB in 256 objects order 22 (4 MiB objects) snapshot_count: 0 id: 26a2fbcec7b8d9 block_name_prefix: rbd_data.26a2fbcec7b8d9 format: 2 features: layering op_features: flags: create_timestamp: Thu Jan 7 10:47:28 2021 access_timestamp: Thu Jan 7 10:47:28 2021 modify_timestamp: Thu Jan 7 10:47:28 2021 parent: cow-pool/cow-base@base-snap overlap: 1 GiB 3). Unmount the images admin:/mnt # umount /mnt/cow-image1 admin:/mnt # umount /mnt/cow-image2 admin:/mnt # umount /mnt/cow-base","title":"Task 7: Flatten a COW Clone and remove the parent image"},{"location":"linux/SES/linux_ses_demo/#246-configure-iscsi-on-ses","text":"In this lab an iSCSI Target was configured via the iSCSI gateway on our SUSE Enterprise Storage. An image was added to it. An iSCSI initiator then connected to the target, created a filesystem, and mounted it.","title":"2.4.6. Configure iSCSI on SES"},{"location":"linux/SES/linux_ses_demo/#task-1-create-a-new-rbd-image-in-the-iscsi-images-pool","text":"1). Create a new RBD image using the rbd command: admin:~ # rbd create --size 1024 iscsi-images/fooiscsi 2). Verify the new image has been created in the iscsi-images pool: The new image named fooiscsi should be displayed. admin:~ # rbd ls iscsi-images fooiscsi","title":"Task 1: Create a new RBD image in the iscsi-images pool"},{"location":"linux/SES/linux_ses_demo/#task-2-define-a-new-iscsi-target-with-the-ceph-dashboard","text":"1). Access the Ceph Dashboard and log in: https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 Username: admin Password: mypassword 2). Once logged in, click on the Block drop-down item near the top. Select iSCSI. 3). With the Overview tab showing for iSCSI, click on the Targets tab near the top. Note: When clicking on the Targets tab, if you see an error that says something about \u201cUnsupported `ceph-iscsi` config version\u2026\u201d, perform the following steps: 1. Close the browser window where the error occurred 2. Restart the mon1 virtual machine. Do this with the following steps: from the Virtual Machine Manager on your lab machine (not in the admin virtual machine), restart the mon1 virtual machine by right-clicking on the mon1 virtual machine > Shut Down > Reboot 3. Wait at least 30 seconds, then from the admin node, open up the browser again and log in to the Ceph Dashboard: https://mon1.pvg.me.corp:8443 or https://10.58.121.186:8443 Username: admin Password: mypassword 4. Continue the lab as directed below by navigating to the Block > iSCSI section, clicking on the Targets tab, and completing the steps below 4). Click Add. Use the following values: Target IQN: <accept default> Portals: mon2.example.net:172.17.6.132 Images: iscsi-images/fooiscsi ACL authentication: <leave unchecked> Click Create Target.","title":"Task 2: Define a new iSCSI target with the Ceph Dashboard"},{"location":"linux/SES/linux_ses_demo/#task-3-access-the-new-iscsi-target-from-the-admin-node","text":"1). On the admin node, launch YaST either the ncurses or GUI interface, and select the iSCSI Initiator module: YaST > Network Services > iSCSI Initiator 2). Select the Discovered Targets tab (alt-v) 3). Select Discovery at the bottom of the frame (alt-d) 4). Add the ip address of mon2: 10.58.121.187. Leave the port as the default of 3260. Select Next. 5). Once again on the Discovered Targets tab, the mon2 target should be listed. With the new target highlighted, select Connect (alt-e) at the bottom of the frame. 6). Leave the Startup (in YaST2) or On boot (in YaST) value as manual. Select Next. 7). Select OK to exit the iscsi client configuration module 8). To verify that the iscsi device is now connected, use the lsscsi command to list devices: You should see there is one disk of type RBD connected on a device file similar to the following: admin:~ # lsscsi [0:0:0:0] cd/dvd QEMU QEMU DVD-ROM 1.4. /dev/sr0 [2:0:0:0] disk SUSE RBD 4.0 /dev/sda 9). Create an ext4 filesystem on the connected device file: admin:~ # mkfs.ext4 /dev/sda mke2fs 1.43.8 (1-Jan-2018) Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: e3896f7e-0664-4b14-85db-0f77cb234c43 Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done 10). Mount the device to /mnt: admin:~ # mount /dev/sda /mnt 11). Use the mount command to list the connected device: admin:/mnt # mount | grep sda /dev/sda on /mnt type ext4 (rw,relatime,stripe=1024,data=ordered) 12).Change the root user\u2019s home directory and unmount the device: admin:/mnt # cd .. admin:/ # umount /mnt","title":"Task 3: Access the new iSCSI target from the admin node"},{"location":"linux/SES/linux_ses_demo/#247-mount-cephfs-provided-by-suse-enterprise-storage","text":"In this lab a ceph user was configured to mount the ceph filesystem provided by the SUSE Enterprise Cluster. A keyfile was generated, then used in the process.","title":"2.4.7. Mount CephFS Provided by SUSE Enterprise Storage"},{"location":"linux/SES/linux_ses_demo/#task-1-verify-cephfs-configuration-of-the-ses-cluster","text":"1). Cephfs requires two pools for operation: one for data, the other for metadata. Verify that the cluster has two pools for this purpose: admin:~ # ceph fs ls name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ] Task 2: Create a secret key file for the admin user on the admin node 1). Because cephx authentication is enabled by default on SUSE Enterprise Storage, a secret key will need to be provided to allow access to mount the ceph filesystem. The admin user (identified \u2013 in this case \u2013 on the system as root) on the admin node has a key, but we will need to either provide it on the command line during the mount process (less secure), or put it in a permissions-restricted file and point to the file when mounting (more secure). If we do not specify the key or a file with the key, we will get an error. The following command will return an error: admin:~ # mount -t ceph mon1:6789:/ /mnt 2021-01-07 14:16:36.924 7f45108a9d80 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.guest.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory mount error 22 = Invalid argument 2). Take secret key value found in the /etc/ceph/ceph.client.admin.keyring file and put it in a new file: admin:~ # cat /etc/ceph/ceph.client.admin.keyring [client.admin] key = <your key> caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" 3). Create a new file and paste the secret key value into it: admin:~ # vi /etc/ceph/admin.secret Put the key value <your key> into the file and save it. 4). Change the permissions of the file to be read only by the user: admin:~ # ls -l /etc/ceph/admin.secret -r-------- 1 root root 41 Jan 5 20:05 /etc/ceph/admin.secret","title":"Task 1: Verify cephfs configuration of the SES cluster"},{"location":"linux/SES/linux_ses_demo/#task-3-mount-the-ceph-filesystem-on-the-admin-node","text":"1). Now that the keyfile is created, we can mount the filesystem: admin:~ # mount -t ceph mon1:6789:/ /mnt -o name=admin,secretfile=/etc/ceph/admin.secret admin:~ # ls -l /mnt total 0 2). Verify that the mount shows as expected: admin:~ # mount | grep ceph 10.58.121.186:6789:/ on /mnt type ceph (rw,relatime,name=admin,secret=<hidden>,acl) 3). Change to the root user\u2019s home directory and unmount the filesystem: admin:~ # cd ~ admin:~ # umount /mnt","title":"Task 3: Mount the ceph filesystem on the admin node"},{"location":"linux/SES/linux_ses_demo/#248-export-an-nfs-share-from-ses-with-nfs-ganesha","text":"","title":"2.4.8. Export an NFS Share from SES with NFS Ganesha"},{"location":"linux/SES/linux_ses_demo/#task-0-install-and-configure-ganesha-ganesha-config-location-is-not-configured-please-set-the-ganesha_rados_pool_namespace-setting","text":"admin:~ # zypper in nfs-ganesha admin:/etc/ganesha # cat ganesha.conf NFSv4 { RecoveryBackend = 'rados_cluster'; #RecoveryBackend = 'rados_ng'; } RADOS_URLS { ceph_conf = '/etc/ceph/ceph.conf'; userid = \"admin\"; watch_url = \"rados://data/ganesha-export-index/conf-nfs1\"; } RADOS_KV { pool = \"metadata\"; namespace = \"ganesha-grace\"; nodeid = \"nfs1\"; } %url rados://data/ganesha-export-index/conf-nfs1 admin:/etc/ganesha # ganesha-rados-grace -p metadata -n ganesha-grace add nfs1 nfs2 nfs3 admin:/etc/ganesha # ganesha-rados-grace -p metadata -n ganesha-grace cur=1 rec=0 ====================================================== nfs1 E nfs2 E nfs3 E http://images.45drives.com/ceph/cephfs/nfs-ganesha-ceph.conf","title":"Task 0: Install and configure Ganesha (Ganesha config location is not configured. Please set the GANESHA_RADOS_POOL_NAMESPACE setting.)"},{"location":"linux/SES/linux_ses_demo/#task-1-create-an-nfs-export-using-the-ceph-dashboard","text":"1). In a browser, navigate to a monitor to access the Ceph Dashboard and log in: https://10.58.121.186:8443/ Username: admin Password: mypassword 2). Click on the NFS tab near the top of the page 3). Click on the green Add button 4). Click on the Add daemon button to the right and select mon1 5). Complete the configuration with the following values: Storage Backend: Object Gateway Object Storage User: s3user Path: S3CMDTEST NFS Protocol: NFSv3 and NFSv4 checked NFS Tag: <leave blank> Pseudo: /S3BKT Access Type: RW Squash: root_squash Transport Protocol: UDP and TCP checked Clients: <leave default> Click Submit","title":"Task 1: Create an NFS export using the Ceph Dashboard"},{"location":"linux/SES/linux_ses_demo/#task-2-mount-the-nfs-export-on-the-admin-node","text":"1). As the root user on the admin node, query the NFS Ganesha gateway node to see what mounts are available: showmount -e mon1 You should see something similar to the following: Export list for mon1: S3CMDTEST (everyone) 2). Mount the available nfs share to the /mnt directory on the admin server: mount -t nfs mon1:/S3BKT /mnt 3). List the nfs mount: mount | grep mnt Note the type listed as nfs4 4). Change to the root user\u2019s home directory and unmount the export: cd umount /mnt","title":"Task 2: Mount the NFS export on the admin node"},{"location":"linux/SES/linux_ses_demo/#249-configure-and-mount-cifs","text":"In this lab the Samba gateway was configured. A keyring for the Samba gateway was created, the Samba service was modified, and a user created to allow CIFS access to the SES cluster.","title":"2.4.9. Configure and Mount CIFS"},{"location":"linux/SES/linux_ses_demo/#task-1-prepare-the-cephfs-share-for-cifs","text":"1). In order for CIFS to work in our SES environment, a valid CephFS share must be available. The CephFS lab previously done in this workbook is sufficient. Using the same configuration that we used previously, mount the CephFS share and give permissions to all users at the root of the share: admin:~ # mount -t ceph mon1:6789:/ /mnt -o name=admin,secretfile=/etc/ceph/admin.secret admin:~ # chmod 777 /mnt admin:~ # l /mnt total 0 drwxrwxrwx 2 root root 0 Oct 5 14:30 ./ drwxr-xr-x 1 root root 156 Oct 5 08:53 ../ admin:~ # umount /mnt","title":"Task 1: Prepare the CephFS share for CIFS"},{"location":"linux/SES/linux_ses_demo/#task-2-create-a-samba-gateway-specific-keyring-on-the-ceph-admin-node-and-copy-it-to-the-samba-gateway-node","text":"1). A new keyring will be needed for the Samba gateway to allow access to the Ceph cluster. As root, perform the following: admin:~ # ceph auth get-or-create client.samba.gw mon 'allow r' osd 'allow *' mds 'allow *' -o ceph.client.samba.gw.keyring 2). Copy the new keyring to the Samba gateway node: admin:~ # scp ceph.client.samba.gw.keyring mon1:/etc/ceph/ ceph.client.samba.gw.keyring admin:~ # ssh mon1 Last login: Thu Jan 7 14:35:58 2021 from 10.58.121.181 mon1:~ # ls -l /etc/ceph/ total 12 -rw-r--r-- 1 root root 66 Jan 7 15:15 ceph.client.samba.gw.keyring -rw-r--r-- 1 root root 1095 Jan 5 22:44 ceph.conf -rw-r--r-- 1 root root 92 Aug 24 22:03 rbdmap","title":"Task 2: Create a Samba gateway specific keyring on the Ceph admin node and copy it to the Samba gateway node"},{"location":"linux/SES/linux_ses_demo/#task-3-configure-samba-on-the-samba-gateway-node","text":"1). The /etc/samba/smb.conf file will need to be edited to allow CIFS access to the storage cluster. On the mon1 node, replace all of the contents of the file with the following: admin:~ # ssh mon1 mon1:~ # vi /etc/samba/smb.conf mon1:/etc/samba # cat smb.conf [global] netbios name = SAMBA-GW clustering = no idmap config * : backend = tdb2 passdb backend = tdbsam # disable print server load printers = no smbd: backgroundqueue = no [ceph-smb] path = / vfs objects = ceph ceph: config_file = /etc/ceph/ceph.conf ceph: user_id = samba.gw read only = no oplocks = no kernel share modes = no 2). Create a smb user on the mon1 node named joesmb with a password of mypassword: mon1:/etc/samba # useradd joesmb mon1:/etc/samba # passwd joesmb ---> 123 Add joesmb to the smb password database with a password of mypassword: mon1:/etc/samba # smbpasswd -a joesmb New SMB password: ---> 123 Retype new SMB password: ---> 123 Added user joesmb. 3). Start and enable the smb and nmb daemons on mon1: mon1:/etc/samba # systemctl start smb nmb mon1:/etc/samba # systemctl enable smb nmb Created symlink /etc/systemd/system/multi-user.target.wants/smb.service \u2192 /usr/lib/systemd/system/smb.service. Created symlink /etc/systemd/system/multi-user.target.wants/nmb.service \u2192 /usr/lib/systemd/system/nmb.service. 4). Unmount the filesystem: mon1:~ # umount /mnt umount: /mnt: not mounted.","title":"Task 3: Configure Samba on the Samba gateway node"},{"location":"linux/SES/linux_ses_demo/#task-4-connect-a-client-to-the-samba-gateway","text":"1). On the admin node, verify that the Samba gateway is sharing via CIFS. The password is 123 admin:~ # smbclient -U joesmb -L //mon1 Enter WORKGROUP\\joesmb's password: ---> 123 Sharename Type Comment --------- ---- ------- ceph-smb Disk IPC$ IPC IPC Service (Samba 4.9.5-git.373.26895a83dbf3.44.1-SUSE-oS15.0-x86_64) Reconnecting with SMB1 for workgroup listing. Server Comment --------- ------- Workgroup Master --------- ------- GLOBAL CNPVGVSYB900 WORKGROUP SAMBA-GW 2). Connect to the ceph-smb share as joesmb. The password is 123 admin:~ # smbclient -U joesmb //mon1/ceph-smb Enter WORKGROUP\\joesmb's password: ---> 123 tree connect failed: NT_STATUS_BAD_NETWORK_NAME You should see output similar to the following: Try \u201chelp\u201d to get a list of possible commands. smb: \\>","title":"Task 4: Connect a client to the Samba gateway"},{"location":"linux/SES/linux_ses_memo/","text":"SUSE Enterprise Storage Foundation Ceph\u2019s RADOS Everything in Ceph is stored in the RADOS cluster as Objects. Ceph\u2019s RADOS: Reliable Autonomous Distributed Object Store Ceph\u2019s RADOS is composed of storage devices represented as: Raw storage device with LVM (BlueStore) Standard filesystem (FileStore) The Object Storage Daemon (OSD) integrates each disk device as part of the RADOS cluster. Ceph architecture Ceph is made of two groups of core components The RADOS cluster Provides the clustered object storage Native Object Access methods Gateways Access to the object store via standard protocols librados Direct access to the object store using a native API Examples: iSCSI Gateway (block) -- IGW - iSCSI is a storage area network (SAN) protocol. Exports RADOS Block Device (--RBD) (images as iSCSI disks). iSCSI access to RDB images. lrbd is no longer used in SES6. RADOS Gateway (object) -- RGW Is an object storage interface built on top of librados CephFS (file) A MetaData Service (MDS) is required. Direct access to RADOS (no LIBRADOS layer) Traditional filesystem interface. NFS Ganesha (object, file) Provides NFS exports to: RGW buckets for access the object store The CephFS filesystem Client access the storage services of the cluster via Gateways and Librados The librados API allows interaction with the following daemons: The Ceph Monitor, which maintains a master copy of the cluster map The Ceph OSD Daemon (OSD), which stores data as objects on a storage node. Enhanced SES Architecture Diagram Object Storage The state of the art of distributed SDS storage Unstructured, to better accommodate large files and large quantities of files For large files and large quantities of files, it performs far better than other storage mechanisms Agile, scalable, extensible, and very customizable Invisible to the end-user, ideal for backends Perfect for systemic, application-based use cases. Not necessarily perfect for direct Human use Through associated metadata, ideal for computational analytics And CRUSH takes full advantage of this (CRUSH = Controllable Replication Under Scalable Hashing) Ceph Object Storage supports two interfaces: S3-compatible Swift-compatible Object-based storage has become the standard backend storage mechanism for nearly all modern Enterprise Storage Solutions. Ceph OSDs (Object Storage Daemon) A Ceph OSD (object storage daemon, ceph-osd) stores data, handles data replication, recovery, rebalancing, and provides some monitoring information to Ceph Monitors and Managers by checking other Ceph OSD Daemons for a heartbeat. The Ceph Storage Cluster receives data from Ceph Clients. Clients (dedicated access points, e.g., gateway) could be a Ceph Block Device, Ceph Object Storage, the Ceph Filesystem or a custom implementation using librados. The client requests the cluster status from a monitor node The client uses the status information to identify the location of objects in the cluster The client accesses the objects directly via the OSD node The OSD then stores the data as objects. Each object corresponds to a file in a filesystem which is stored on an OSD. The OSD Daemons take care of the reads and writes on the storage disks. When OSDs are deployed in SES5 the default is to use BlueStore which uses the raw disk and does not require a linux file system to be placed on the disk before it can be used. OSD Daemons store all data as objects in a flat namespace, i.e. no hierarchy of directories. At least 3 Ceph OSDs are normally required for redundancy and high availability. Ceph Mons (Monitor Servers) A Ceph Monitor (ceph-mon) maintains maps of the cluster state, including Monitor Map Manager Map OSD Map PG Map CRUSH Map Epoch These maps are critical cluster state required for Ceph daemons to coordinate with each other. Monitors are also responsible for managing authentication between daemons and clients. At least 3 monitors are normally required for redundancy and high availability. An odd number of MONs is required (Paxos requires). Typically 5 is sufficient for mid or large size cluster. Paxos is an algorithm used for cluster durability. Leader MON expects 50% quality to create quorum. Lowest IP address becomes leader. After new leader selected, all MONs polled for epoch. Leader Mon provides lease to non-leader MONs. MONs are NOT in the data path. They merely serve maps to clients so that the client can go directly to the appropriate OSD storage daemon. Monitor nodes MONs do not serve objects to clients Ceph MGRs (Manager Daemon) A Ceph Manager daemon (ceph-mgr) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization current performance metrics system load The Ceph Manager daemons also host python-based plugins to manage and expose Ceph cluster information, including a web-based dashboard and REST API. At least two managers are normally required for high availability. MON/MGR daemons are required to run on the same node in SES Ceph MDS (Metadata) A Ceph Metadata Server (MDS, ceph-mds) stores metadata on behalf of the Ceph Filesystem. Ceph Metadata Servers allow POSIX file system users to execute basic commands, for example ls -al without placing an large load on the Ceph Storage Cluster. Ceph Admin Node The Admin node fills the \u201cmaster\u201d and \u201cadmin\u201d roles for DeepSea. Salt is central to SES. SES\u2019s deployment and life-cycle management tool. The Admin node keeps master Ceph authentication keys. Prometheus and Grafana provide cluster monitoring and data graphs Ceph Dashboard Runs as a Ceph Manager module; runs via the MON/MGR node. Client Access Object Storage (RADOSGW or RGW) Block Storage (RDB). RBD is built on top of librados. CephFS iSCSI Gateway NFS Ganesha SMB/CIFS Native protocols via librados Objects in Ceph Everything stored in the Ceph cluster is an object. Default object size is 4MB. Each object has a unique ID. ID is unique across the entire cluster. Objects have associated metadata, in Key: Value pairs. In Ceph we use Storage Pools to organize or arrange our objects. Pools are logical partitions to manage objects Parameters to manage Pools Number of data replicas (Replica pools), or configuration of Erasure Code (size) (Erasure Code pools) Erasure Code is an alternative to Replication SIZE for Erasure Coding is K+M K = Data chunks, M = \u201cParity\u201d chunks EC reduces the hit to raw storage capacity EC incurs a greater hit to CPU on the OSDs as a tradeoff Placement Groups (PG) PG is used to manage objects within a pool. PGs are associated with OSDs for data placement PGs are a central feature of CRUSH that help to provide data durability by way of distribution No PG is owned by an OSD. (And an OSD is not owned by a PG.) PGs are just randomly assigned by CRUSH through all of the OSDs to spread the distribution of data Locating data among PGs is all handled economically, deterministically by way of CRUSH calculations PGs are subdivisions of pools Number of PGs = (Number of OSDs * 100) / Size (Size = either num of replicas, or K+M) The final PG number must be a power of 2 The default number of PGs for a new pool is 8 (it's too small for enterprise solution) In general, PG and PGP numbers should be the same pg_num is the number of placement groups for the pool (placement group, \u5b58\u50a8\u6c60\u7684\u76ee\u5f55\u4e2a\u6570 ) pgp_num is the number of placement groups that will be considered for placement (placement group for placement purpose, pg\u53ef\u7528\u7684osd\u6392\u5217\u7ec4\u5408\u6570\u91cf) \u4ec5\u589e\u5927pg_num\uff1a \u56e0\u4e3apgp_num\u6ca1\u53d8\uff0cpg\u7684osd\u7ec4\u5408\u4ecd\u53ea\u80fd\u4ece\u5f53\u524dpgp_num\u79cd\u7ec4\u5408\u91cc\u9762\u6311\u9009\uff0c\u5bfc\u81f4\u65b0\u589e\u7684pg\u548c\u65e7pg\u4f1a\u6709\u91cd\u590d\u7684osd\u7ec4\u5408\uff0c\u8be5\u73b0\u8c61\u79f0\u4e4b\u4e3a\u5206\u88c2\uff1b\u6b64\u65f6pg\u548cosd\u7684\u6620\u5c04\u6ca1\u6709\u53d8\uff1b \u7ee7\u7eed\u589e\u5927pgp_num\uff0c\u4f7f\u5176\u7b49\u4e8epg_num\uff1a \u65e7pg\u6ca1\u6709\u53d8\u5316\uff0c\u4f46\u65b0\u589epg\u7684osd\u7ec4\u5408\u53d1\u751f\u53d8\u5316\uff0c\u5373\u5f00\u59cb\u91cd\u65b0\u5206\u5e03 Placement Group (PG) \u5f52\u7f6e\u7ec4\u72b6\u6001 Creating \u521b\u5efa\u5b58\u50a8\u6c60\u65f6\uff0c\u5b83\u4f1a\u521b\u5efa\u6307\u5b9a\u6570\u91cf\u7684\u5f52\u7f6e\u7ec4\u3002 ceph \u5728\u521b\u5efa\u4e00\u6216\u591a\u4e2a\u5f52\u7f6e\u7ec4\u65f6\u4f1a\u663e\u793a creating\u3002 \u521b\u5efa\u5b8c\u540e\uff0c\u5728\u5176\u5f52\u7f6e\u7ec4\u7684 Acting Set \u91cc\u7684 OSD \u5c06\u5efa\u7acb\u4e92\u8054\u3002 \u4e00\u65e6\u4e92\u8054\u5b8c\u6210\uff0c\u5f52\u7f6e\u7ec4\u72b6\u6001\u5e94\u8be5\u53d8\u4e3a active+clean\uff0c\u610f\u601d\u662fceph \u5ba2\u6237\u7aef\u53ef\u4ee5\u5411\u5f52\u7f6e\u7ec4\u5199\u5165\u6570\u636e\u4e86\u3002 peering ceph \u4e3a\u5f52\u7f6e\u7ec4\u5efa\u7acb\u4e92\u8054\u65f6\uff0c\u4f1a\u8ba9\u5b58\u50a8\u5f52\u7f6e\u7ec4\u526f\u672c\u7684 OSD \u4e4b\u95f4\u5c31\u5176\u4e2d\u7684\u5bf9\u8c61\u548c\u5143\u6570\u636e\u72b6\u6001\u8fbe\u6210\u4e00\u81f4\u3002 ceph \u5b8c\u6210\u4e86\u4e92\u8054\uff0c\u4e5f\u5c31\u610f\u5473\u7740\u5b58\u50a8\u7740\u5f52\u7f6e\u7ec4\u7684 OSD \u5c31\u5176\u5f53\u524d\u72b6\u6001\u8fbe\u6210\u4e86\u4e00\u81f4\u3002 \u7136\u800c\uff0c\u4e92\u8054\u8fc7\u7a0b\u7684\u5b8c\u6210\u5e76\u4e0d\u80fd\u8868\u660e\u5404\u526f\u672c\u90fd\u6709\u4e86\u6570\u636e\u7684\u6700\u65b0\u7248\u672c\u3002 active ceph \u5b8c\u6210\u4e92\u8054\u8fdb\u7a0b\u540e,\u4e00\u5f52\u7f6e\u7ec4\u5c31\u53ef\u53d8\u4e3a active\u3002 active \u72b6\u6001\u901a\u5e38\u610f\u5473\u7740\u5728\u4e3b\u5f52\u7f6e\u7ec4\u548c\u526f\u672c\u4e2d\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u8bfb\u5199\u3002 clean \u67d0\u4e00\u5f52\u7f6e\u7ec4\u5904\u4e8e clean \u72b6\u6001\u65f6\uff0c\u4e3b OSD \u548c\u526f\u672c OSD \u5df2\u6210\u529f\u4e92\u8054\uff0c\u5e76\u4e14\u6ca1\u6709\u504f\u79bb\u7684\u5f52\u7f6e\u7ec4\u3002 ceph \u5df2\u628a\u5f52\u7f6e\u7ec4\u4e2d\u7684\u5bf9\u8c61\u590d\u5236\u4e86\u89c4\u5b9a\u6b21\u6570\u3002 degraded \u5f53\u5ba2\u6237\u7aef\u5411\u4e3b OSD \u5199\u5165\u6570\u636e\u65f6\uff0c\u7531\u4e3b OSD \u8d1f\u8d23\u628a\u526f\u672c\u5199\u5165\u5176\u4f59\u590d\u5236 OSD\u3002 \u4e3b OSD \u628a\u5bf9\u8c61\u5199\u5165\u590d\u5236 OSD \u540e\uff0c\u5728\u6ca1\u6536\u5230\u6210\u529f\u5b8c\u6210\u7684\u786e\u8ba4\u524d\uff0c\u4e3b OSD \u4f1a\u4e00\u76f4\u505c\u7559\u5728 degraded \u72b6\u6001\u3002 \u5f52\u7f6e\u7ec4\u72b6\u6001\u53ef\u4ee5\u662f active+degraded \u72b6\u6001\uff0c\u539f\u56e0\u5728\u4e8e\u4e00 OSD \u5373\u4f7f\u6ca1\u6240\u6709\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u5904\u4e8e active \u72b6\u6001\u3002 \u5982\u679c\u4e00OSD \u6302\u4e86\uff0cceph \u4f1a\u628a\u76f8\u5173\u7684\u5f52\u7f6e\u7ec4\u90fd\u6807\u8bb0\u4e3a degraded\u3002 \u90a3\u4e2a OSD \u91cd\u751f\u540e\uff0c\u5b83\u4eec\u5fc5\u987b\u91cd\u65b0\u4e92\u8054\u3002 \u7136\u800c\uff0c\u5982\u679c\u5f52\u7f6e\u7ec4\u4ecd\u5904\u4e8e active \u72b6\u6001\uff0c\u5373\u4fbf\u5b83\u5904\u4e8e degraded \u72b6\u6001\uff0c\u5ba2\u6237\u7aef\u8fd8\u53ef\u4ee5\u5411\u5176\u5199\u5165\u65b0\u5bf9\u8c61\u3002 \u5982\u679c\u4e00 OSD \u6302\u4e86\uff0c\u4e14 degraded \u72b6\u6001\u6301\u7eed\uff0cceph \u4f1a\u628a down \u7684 OSD \u6807\u8bb0\u4e3a\u5728\u96c6\u7fa4\u5916(out)\u3001\u5e76\u628a\u90a3\u4e9b down \u6389\u7684 OSD \u4e0a\u7684\u6570\u636e\u91cd\u6620\u5c04\u5230\u5176\u5b83 OSD\u3002 \u4ece\u6807\u8bb0\u4e3a down \u5230 out \u7684\u65f6\u95f4\u95f4\u9694\u7531 mon osd down out interval \u63a7\u5236,\u9ed8\u8ba4\u662f 300 \u79d2\u3002 \u5f52\u7f6e\u7ec4\u4e5f\u4f1a\u88ab\u964d\u7ea7(degraded)\uff0c\u56e0\u4e3a\u5f52\u7f6e\u7ec4\u627e\u4e0d\u5230\u672c\u5e94\u5b58\u5728\u4e8e\u5f52\u7f6e\u7ec4\u4e2d\u7684\u4e00\u6216\u591a\u4e2a\u5bf9\u8c61\uff0c\u8fd9\u65f6\uff0c\u4f60\u4e0d\u80fd\u8bfb\u6216\u5199\u627e\u4e0d\u5230\u7684\u5bf9\u8c61\uff0c\u4f46\u4ecd\u80fd\u8bbf\u95ee\u5176\u5b83\u4f4d\u4e8e\u964d\u7ea7\u5f52\u7f6e\u7ec4\u4e2d\u7684\u5bf9\u8c61\u3002 recovering ceph \u88ab\u8bbe\u8ba1\u4e3a\u53ef\u5bb9\u9519\uff0c\u53ef\u62b5\u5fa1\u4e00\u5b9a\u89c4\u6a21\u7684\u8f6f\u3001\u786c\u4ef6\u95ee\u9898\u3002 \u5f53\u67d0 OSD \u6302\u4e86(down)\u65f6\uff0c\u5176\u5185\u5bb9\u7248\u672c\u4f1a\u843d\u540e\u4e8e\u5f52\u7f6e\u7ec4\u5185\u7684\u5176\u5b83\u526f\u672c\u3002 \u5b83\u91cd\u751f(up)\u65f6\uff0c\u5f52\u7f6e\u7ec4\u5185\u5bb9\u5fc5\u987b\u66f4\u65b0\uff0c\u4ee5\u53cd\u6620\u5f53\u524d\u72b6\u6001\u3002 \u5728\u6b64\u671f\u95f4\uff0cOSD \u5728recovering \u72b6\u6001\u3002 \u4e00\u6b21\u786c\u4ef6\u5931\u8d25\u53ef\u80fd\u7275\u8fde\u591a\u4e2a OSD\u3002\u6bd4\u5982\u4e00\u4e2a\u673a\u67dc\u7684\u7f51\u7edc\u4ea4\u6362\u673a\u5931\u8d25\u4e86\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u591a\u4e2a\u4e3b\u673a\u843d\u540e\u4e8e\u96c6\u7fa4\u7684\u5f53\u524d\u72b6\u6001\uff0c\u95ee\u9898\u89e3\u51b3\u540e\u6bcf\u4e00\u4e2a OSD \u90fd\u5fc5\u987b\u6062\u590d\u3002 ceph \u63d0\u4f9b\u4e86\u5f88\u591a\u9009\u9879\u6765\u5747\u8861\u8d44\u6e90\u7ade\u4e89\uff0c\u5982\u65b0\u670d\u52a1\u8bf7\u6c42\u3001\u6062\u590d\u6570\u636e\u5bf9\u8c61\u548c\u6062\u590d\u5f52\u7f6e\u7ec4\u5230\u5f53\u524d\u72b6\u6001\u3002 osd recovery delay start \u9009\u9879\u5141\u8bb8\u4e00 OSD \u5728\u5f00\u59cb\u6062\u590d\u8fdb\u7a0b\u524d\uff0c\u5148\u91cd\u542f\u3001\u91cd\u5efa\u4e92\u8054\u3001\u751a\u81f3\u5904\u7406\u4e00\u4e9b\u91cd\u653e\u8bf7\u6c42\u3002 osd recovery threads \u9009\u9879\u9650\u5236\u6062\u590d\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u6570\uff0c\u9ed8\u8ba4\u4e3a 1 \u7ebf\u7a0b\u3002 osd recovery thread timeout \u8bbe\u7f6e\u7ebf\u7a0b\u8d85\u65f6\uff0c\u56e0\u4e3a\u591a\u4e2aOSD \u53ef\u80fd\u4ea4\u66ff\u5931\u8d25\u3001\u91cd\u542f\u548c\u91cd\u5efa\u4e92\u8054\u3002 osd recovery max active \u9009\u9879\u9650\u5236\u4e00 OSD \u6700\u591a\u540c\u65f6\u63a5\u53d7\u591a\u5c11\u8bf7\u6c42\uff0c\u4ee5\u9632\u5b83\u538b\u529b\u8fc7\u5927\u800c\u4e0d\u80fd\u6b63\u5e38\u670d\u52a1\u3002 osd recovery max chunk \u9009\u9879\u9650\u5236\u6062\u590d\u6570\u636e\u5757\u5c3a\u5bf8\uff0c\u4ee5\u9632\u7f51\u7edc\u62e5\u585e\u3002 back filling \u6709\u65b0 OSD \u52a0\u5165\u96c6\u7fa4\u65f6\uff0cCRUSH \u4f1a\u628a\u73b0\u6709\u96c6\u7fa4\u5185\u7684\u5f52\u7f6e\u7ec4\u91cd\u5206\u914d\u7ed9\u5b83\u3002 \u5f3a\u5236\u65b0 OSD \u7acb\u5373\u63a5\u53d7\u91cd\u5206\u914d\u7684\u5f52\u7f6e\u7ec4\u4f1a\u4f7f\u4e4b\u8fc7\u8f7d\uff0c\u7528\u5f52\u7f6e\u7ec4\u56de\u586b\u53ef\u4f7f\u8fd9\u4e2a\u8fc7\u7a0b\u5728\u540e\u53f0\u5f00\u59cb\u3002 \u56de\u586b\u5b8c\u6210\u540e\uff0c\u65b0 OSD \u51c6\u5907\u597d\u65f6\u5c31\u53ef\u4ee5\u5bf9\u5916\u670d\u52a1\u4e86\u3002 remapped \u67d0\u4e00\u5f52\u7f6e\u7ec4\u7684 Acting Set \u53d8\u66f4\u65f6\uff0c\u6570\u636e\u8981\u4ece\u65e7\u96c6\u5408\u8fc1\u79fb\u5230\u65b0\u7684\u3002 \u4e3b OSD \u8981\u82b1\u8d39\u4e00\u4e9b\u65f6\u95f4\u624d\u80fd\u63d0\u4f9b\u670d\u52a1\uff0c\u6240\u4ee5\u5b83\u53ef\u4ee5\u8ba9\u8001\u7684\u4e3b OSD \u6301\u7eed\u670d\u52a1\u3001\u76f4\u5230\u5f52\u7f6e\u7ec4\u8fc1\u79fb\u5b8c\u3002 \u6570\u636e\u8fc1\u79fb\u5b8c\u540e,\u4e3b OSD \u4f1a\u6620\u5c04\u5230\u65b0 acting set\u3002 stale \u867d\u7136 ceph \u7528\u5fc3\u8df3\u6765\u4fdd\u8bc1\u4e3b\u673a\u548c\u5b88\u62a4\u8fdb\u7a0b\u5728\u8fd0\u884c\uff0c\u4f46\u662f ceph-osd \u4ecd\u6709\u53ef\u80fd\u8fdb\u5165 stuck \u72b6\u6001\uff0c\u5b83\u4eec\u6ca1\u6709\u6309\u65f6\u62a5\u544a\u5176\u72b6\u6001(\u5982\u7f51\u7edc\u77ac\u65ad)\u3002 \u9ed8\u8ba4OSD \u5b88\u62a4\u8fdb\u7a0b\u6bcf\u534a\u79d2(0.5)\u4f1a\u4e00\u6b21\u62a5\u544a\u5176\u5f52\u7f6e\u7ec4\u3001\u51fa\u6d41\u91cf\u3001\u5f15\u5bfc\u548c\u5931\u8d25\u7edf\u8ba1\u72b6\u6001\uff0c\u6b64\u9891\u7387\u9ad8\u4e8e\u5fc3\u8df3\u9600\u503c\u3002 \u5982\u679c\u4e00\u5f52\u7f6e\u7ec4\u7684\u4e3b OSD \u6240\u5728\u7684 acting set \u6ca1\u80fd\u5411\u76d1\u89c6\u5668\u62a5\u544a\u3001\u6216\u8005\u5176\u5b83\u76d1\u89c6\u5668\u5df2\u7ecf\u62a5\u544a\u4e86\u90a3\u4e2a\u4e3b OSD \u5df2 down\uff0c\u76d1\u89c6\u5668\u4eec\u5c31\u4f1a\u628a\u6b64\u5f52\u7f6e\u7ec4\u6807\u8bb0\u4e3a stale\u3002 \u542f\u52a8\u96c6\u7fa4\u65f6\uff0c\u4f1a\u7ecf\u5e38\u770b\u5230 stale \u72b6\u6001\uff0c\u76f4\u5230\u4e92\u8054\u5b8c\u6210\u3002 \u96c6\u7fa4\u8fd0\u884c\u4e00\u9635\u540e\uff0c\u5982\u679c\u8fd8\u80fd\u770b\u5230\u6709\u5f52\u7f6e\u7ec4\u4f4d\u4e8e stale \u72b6\u6001\uff0c\u5c31\u8bf4\u660e\u90a3\u4e9b\u5f52\u7f6e\u7ec4\u7684\u4e3b OSD \u6302\u4e86(down)\u3001\u6216\u6ca1\u5728\u5411\u76d1\u89c6\u5668\u62a5\u544a\u7edf\u8ba1\u4fe1\u606f\u3002 Each pool has its own autoscaler settings The PG balancer optimizes the placement of PGs across OSD crush-compat mode It's default mode Uses the compat weight-set feature upmap mode. It's perfect mode, which an equal number of PGs on each OSD Use fine-grained control over the PG mapping Snapshots Rulesets to manage CRUSH placement Each pool has a defined CRUSH ruleset A CRUSH ruleset is a definition of how the OSDs organize data This allows configuration of data distribution to be managed per pool A single CRUSH ruleset can be reused by multiple pools A ruleset can take into account: \u9700\u8981\u8003\u8651\u7684\u70b9 physical layout of nodes in the cluster organization of network infrastructure selection of OSDs backed by SSDs versus HDDs, etc Each pool can use either Replication or Erasure Coding Replication is the original, default approach to resiliency Erasure Coded pools have an EC Profile assigned Different than CRUSH rulesets, but similar: define how OSDs organize data The profile defines K, M values; encoding method/plugin; etc CRUSH (Controllable Replication Under Scalable Hashing) CRUSH is a key piece of the Ceph storage solution With the CRUSH algorithm used by Ceph: Data is not centrally stored, it is distributed CRUSH calculates the storage location for each object dynamically No requirement to store a global index of object locations CRUSH Algorithm The CRUSH algorithm deterministically calculates the location of any object in the Ceph RADOS cluster Overhead is low and calculation is performed by each client As no metadata store is required, CRUSH removes the limitations of traditional metadata based management No direct control over the placement of your data in the cluster Higher CPU requirements CRUSH Maps and Rulesets CRUSH Rulesets are the named sets of rules: Combining all of the customizable CRUSH behavior settings Assigned to pool to govern how the pool\u2019s data is distributed in the cluster CRUSH Maps are central to how Ceph distributes data, and maintaining the durability of the data When the cluster is deployed, Ceph creates a simple default ruleset for replicated pools: replicated_rule CRUSH behavior depends on the behaviors and performance of storage devices CRUSH Maps should be crafted to take advantage of those behaviors Rulesets should be used to clearly identify how the devices in your environment should be employed Device Classes exist to indicate performance behavior: hdd, ssd, nvme Ceph OSDs will automatically set the Device Class of a storage device when the OSD is started Working with CRUSH Map Rulesets List the OSDs, which host each OSD belongs to: ceph osd tree ceph osd df tree ceph osd df tree -f json-pretty Find the host of a specific OSD: ceph osd find 8 Show the existing defined rulesets: ceph osd crush rule ls Examine the definition of an existing ruleset: ceph osd crush rule dump <rulesetname> There are 3 options for creating a new ruleset: simple replicated erasure Creating new rulesets: ceph osd crush rule create-replicated <name> ceph osd crush rule create-erasure <name> <ec_profile> Create a new ruleset using a Device Class: create-replicated <name> <root> <failure-domain-level> <device-class> <root> Description : The name of the node under which data should be placed. Type : String Example : default (rarely would you need to make this different than \u201cdefault\u201d) <failure-domain-type> or <failure-doamin-level> Description : The type of CRUSH node (bucket) across which replicas should be separated. Type : String Example : rack <device-class> Description : The device class data should be placed on. Type : String Example : ssd CRUSH Weight You may need to move data around New nodes degraded nodes rebalancing View the current CRUSH weights ceph osd crush tree ceph osd df tree Change the weight for an OSD ceph osd crush reweight <osd.N> <weight> The important difference between ceph osd reweight and ceph osd crush reweight \"ceph osd crush reweight\" sets the CRUSH weight of the OSD. This weight is an arbitrary value (generally the size of the disk in TB or something) and controls how much data the system tries to allocate to the OSD. \"ceph osd reweight\" sets an override weight on the OSD. This value is in the range 0 to 1, and forces CRUSH to re-place (1-weight) of the data that would otherwise live on this drive. It does not change the weights assigned to the buckets above the OSD, and is a corrective measure in case the normal CRUSH distribution isn\u2019t working out quite right. \"ceph osd reweight\" is temporary. \"ceph osd crush reweight\" is sticky, permanent (until you change it again). Setting a weight of an OSD to 0 is effectively setting the OSD \"out\" - you don\u2019t want it to store data. The Monitor\u2019s Cluster Map contains Monitor Map Unique Cluster ID, details of each Mon node, current epoch, date/time of last change OSD Map Contains the cluster fsid, when the map was created and last modified, a list of pools, replica sizes, PG numbers, a list of OSDs and their status PG Map Contains the PG version, its time stamp, the last OSD map epoch, the full ratios, and details on each placement group such as the PG ID, the Up Set, the Acting Set, the state of the PG (e.g., active + clean), and data usage statistics for each pool MDS Map Contains the current MDS map epoch, references to pool(s) for storing metadata, list of MDS servers, and which metadata servers are up and in CRUSH Map Contains a list of storage devices, the failure domain hierarchy (e.g., device, host, rack, row, room, etc.), and rules for traversing the hierarchy when storing data CRUSH Hierarchy The CRUSH Map includes details of physical & network infrastructure The CRUSH Map hierarchy is defined by a storage architect The default hierarchical list of infrastructure elements: (Hierarchy of CRUSH buckets) OSD host chassis \u5200\u7247\u673a\u7bb1 rack \u673a\u67b6 row pdu \u7535\u6e90\u5206\u914d\u5355\u5143 pod \u6027\u80fd\u4f18\u5316\u7684\u6570\u636e\u4e2d\u5fc3(Performance Optimize Datacenter)\uff0c\u57fa\u4e8e\u6807\u51c6\u5316\u8bbe\u65bd\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u6bcf\u4e2aPOD\u5185IT\u90e8\u5206\u5305\u542b\u76845000\u53f0\u670d\u52a1\u5668\uff0c\u5206\u5c5e\u5230200\u4e2a\u673a\u67b6\uff0c\u5982\u679c\u4ee5\u6bcf\u53f0\u670d\u52a1\u5668400W\u529f\u7387\u8ba1\u7b97\u7684\u8bdd\uff0c\u6bcf\u4e2a\u673a\u67dc\u9700\u898110KW\u7684\u4f9b\u7535\uff0c\u5373\u6bcf\u4e2aPOD\u7684IT\u8d1f\u8f7d\u5bb9\u91cf\u662f2MW\u3002 room datacenter region root CRUSH is the algorithm and calculation for distributing data through the cluster. CRUSH Map obviously plays a part in how those CRUSH calculations work. CRUSH Map Sections (Six main sections) tunables: adjustments to legacy behavior devices: The list of OSDs (usually no customization needed) \u25cb \"device class\" is meaningful; useful in relation to creating/using CRUSH rulesets \u25cb Standard \"device class\" values are \"hdd.\", \"ssd.\", and \"nvme.\" \u25cb Example: device 7 osd.7 types: types of buckets (usually no customization needed) buckets: the most functional, customizable aspect of the Map \u25cb A bucket typically represents a physical location in the cluster, has a \u201ctype\u201d \u25cb Nodes (containers such as hosts) and leaves (storage devices such as OSDs) rules: define policies of how data should be distributed \u25cb The behind-the-scenes rules that CRUSH follows for data placement \u25cb IMPORTANT: this is NOT the same as the \"ruleset\". In fact, a ruleset is the combined set of all of these six Map sections. choose_args (optional): Rarely used exceptional settings to adjust weights From the documentation: \"choose_args are alternative weights associated with the hierarchy that have been adjusted to optimize data placement. A single choose_args map can be used for the entire cluster, or one can be created for each individual pool.\" Erasure Coding In information theory : an erasure code is a forward error correction (FEC, \u524d\u5411\u7ea0\u9519) code for the binary erasure channel, which transforms a message of k symbols into a longer message (code word) with n symbols such that the original message can be recovered from a subset of the n symbols. The fraction r = k/n is called the code rate The fraction k\u2019/k, where k\u2019 denotes the number of symbols required for recovery, is called reception efficiency Another (easier) way of describing EC: It\u2019s like RAID in Clustered Storage Erasure Coding in SES The default resilience strategy in SES is simple replication * SES Simple replication has overheads, size=3 means 3 times the storage requirements Simplistic EC details: k = number of \u201cdata\u201d chunks, split across \u201ck\u201d number of OSDs m = number of \u201cparity\u201d chunks, split across \u201cm\u201d number of OSDs Ceph calls these \u201ccoding chunks\u201d r (size) = k + m admin:~ # ceph osd crush rule ls replicated_rule Replication vs Erasure Code Replication (default): Use Case: active data Simple and fast Uses more disk space Erasure coding: Use Case: archive data, more static data Calculates recovery data (needs more CPU power) Definable redundancy level Example: K data chunks = 2 , M code chunks = 1 Similar to a replication size of 2 But with only 50% more raw storage consumed Example: for 1GB of effective storage replication pool of size of 2 needs 2GB raw storage erasure coded pool with k=2/m=1 only requires 1.5GB raw storage EC Overwrites Historically, EC only works properly with Objects EC only allowed appends; overwrites were not allowed Works perfectly for objects in buckets but doesn\u2019t work well with Block or CephFS With recent releases of SES, EC can work well with Block and CephFS Facilitated by \u201cEC Overwrites\u201d feature Store data in an EC Pool, and store object metadata in a Replicated Pool Requires a little extra work when defining pools, but worth it ceph osd pool set allow_ec_overwrites true EC Profiles Using Erasure Coding, each Pool is assigned an EC Profile Multiple pools can share a single Profile The profile is just a definition Each Profile has multiple settings The common required settings for all Profiles are K, M EC Profiles must be created before EC Pools can be created Created from the Dashboard or CLI Once an EC Profile is created, you can create a CRUSH Ruleset based on the EC profile Once a pool is created, its EC Profile properties cannot be changed Main profile parameters K: M: stripe_unit - allows you to adjust the size of the data chunk Default size is 4K stripe_unit : size of data striped across devices; default 4K This variable can also be set in the master configuration (osd_erasure_code_stripe_unit) EC plugins - choose your favorite EC algorithm via a plugin jerasure/gf-complete (default, free, open, and very fast) (www.jerasure.org) ISA (Intel library; optimized for modern Intel processors) (only runs on Intel processors) LRC (\u201cLocally Repairable Code\u201d; layers over existing plugins) SHEC (\u201cShingled EC\u201d; trades extra storage for recovery efficiency) CLAY (\u201cCoupled LAYer\u201d; good for reduced network traffic) Creating Erasure Code Profiles and Pools Syntax: ceph osd erasure-code-profile OPTIONS Option Description get - view details of an existing EC profile set - set a profile (create a profile), requires k and m values, with optional values such as ruleset, plugin. Once you create a profile, you can\u2019t change it. ceph osd erasure-code-profile set <name> k=<int> m=<int> [plugin=<plugin>] [stripe_unit=<string>] ls - list profiles rm - Remove an EC profile ceph osd erasure-code-profile rm <name> Common example (below) The default profile \u2012 2+1=3; data is written over 3 OSDs \u2012 Two data chunks \u2012 One code (parity) chunk \u2012 Uses jerasure plugin with standard Reed/Solomon (reed_sol_van) technique Setting a Custom EC Profile Option: \u2012 Profile name \u2012 K : number of stripes required \u2012 M : number of failed units Example: ceph osd erasure-code-profile set example-profile k=8 m=2 ruleset-failure-domain=host ruleset-failure-domain = crush bucket level for failure admin:/etc/ceph # ceph osd erasure-code-profile \\ set common_profile \\ k=4 \\ m=2 \\ plugin=jerasure \\ technique=reed_sol_van \\ stripe_unit=4K \\ crush-root=default \\ crush-failure-domain=rackcrush-device-class=ssd admin:/etc/ceph # ceph osd erasure-code-profile ls default admin:~ # ceph osd erasure-code-profile get default k=2 m=1 plugin=jerasure technique=reed_sol_van Pools Pools are at the heart of Storage Pools are tied to OSDs Display a list of existing pools: ceph osd pool ls or ceph osd lspools View the statistics and characteristics of pools: ceph osd pool stats ceph osd pool stats <poolname> ceph osd pool get <poolname> <attrib> Show usage and related details of existing pools: rados df or ceph df or ceph df detail All storage revolves around Pools Each pool must be dedicated to a purpose: Object, Block, File Must specify # of Placement Groups and PG Placements Must specify whether using Replication or EC Must specify a CRUSH ruleset Create a Replicated Pool Syntax: ceph osd pool create <poolname> <pg_num> <pgp_num> replicated <crush-rule-name> = number of placement groups for the pool = number of PGs for placement; routinely will be the same as pg_num Always a power of 2 Don\u2019t make the number too small; don\u2019t err on the high side, either Practices For a new pool, the pgp_num will generally (likley) just be the same as the pg_num When increasing the PGs in a pool, you may want to retain the smaller pgp_num to minimize rebalancing, and increase pgp_num later when rebalancing is more convenient If decreasing the PGs in a pool, the pgp_num is adjusted automatically Create an EC Pool (using an EC Profile) Syntax: ceph osd pool create <poolname> <pg_num> <pgp_num> erasure <erasure-code-profile> <crush-rule-name> Example: ceph osd pool create EC-pool 128 128 erasure my-ec-profile Pools \u2013 Application Assignment Each Pool must have a stated purpose; application This defines which capabilities the Pool must support The applications are: Block (rbd), Object (rgw), and File (cephfs) There are subtypes of cephfs: i.e. cephfs:data, cephfs:metadata Application assignment happens after creating a pool It\u2019s effortless (and required) to assign an application on a new pool ceph osd pool application enable <poolname> <application> Changing application assignment after a pool is in use is \u201chard\u201d. Not recommended, only to be done as an expert Pools \u2013 Quotas One of the more desirable features of SDS is to set a maximum usage of a Pool - Quotas Prevent the over-use of a pool Set quotas based on number of objects or number of bytes ceph osd pool set-quota <poolname> max_objects <integer> ceph osd pool set-quota <poolname> max_bytes <integer> Show quota settings ceph osd pool get-quota To remove a quota, set the existing quota setting to 0 There are also application-level quotas For rgw and cephfs (not rbd; images are already limited in size) Pool Quotas vs. Application Quotas. When a pool quota nears its limit, the HEALTH mechanisms will display a \u201cPOOL_NEAR_FULL\u201d warning to the storage administrator. When the quota limit has been exceeded, the HEALTH mechanisms will display a \u201cPOOL_FULL\u201d warning to the storage administrator. Applications (clients) don\u2019t always handle the quotas cleanly. In most cases, once the Pool Quota is exceeded, the application will simply stop writing to the pool, and error messages and behavior at the application are inconsistent (if there are any messages at all). Pools \u2013 Snapshots Take (make) a snapshot of an existing pool ceph osd pool mksnap <poolname> <snapname> Remove a snapshot of a pool ceph osd pool rmsnap <poolname> <snapname> List pool snapshots rados -p <poolname> lssnap Rollback the pool to an earlier snapshot rados -p <poolname> rollback <snapname> Images and cephfs have their own snapshot facilities. Object and Bucket snapshotting features related to rgw don\u2019t exist. Pools Snapshots versus App Snapshots The two different snapshot features cannot be used at the same time on a pool Either Pool Snapshots, or Application Snapshots; not both. (snap_mode = pool versus snap_mode = selfmanaged) Once you commit to pool snapshots for an RBD pool, you can\u2019t change to using RBD snapshots Pros and Cons of each, depending on your Use Case admin:~ # ceph osd pool ls detail -f json-pretty | grep snap_mode \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", BlueStore BlueStore is the default storage backend in SES Highlighted features: compressing, no double-writes, faster checksums Ceph FileStore Model It is not ideal for a specialized purpose like a highly scalable distributed storage system. Only recommend that XFS be used. Both btrfs and ext4 have known bugs. The FileStore model uses cache from the filesystem (XFS). Memory for cache is managed by filesystem kernel module. Ceph BlueStore Model BlueStore consumes raw block devices. Metadata management with RocksDB. BlueStore employs RocksDB\u2019s key/value database in order to manage internal metadata, such as the mapping from object names to block locations on disk. Full data and metadata checksumming. By default all data and metadata written to BlueStore is protected by one or more checksums. A small specialized filesystem called BlueFS. This provides just enough of a filesystem to allow RocksDB to store its \"key/value files\" to share metadata across all the raw device(s) No data or metadata will be read from disk or returned to the user without being verified. Multi-device metadata tiering. BlueStore allows its internal journal (write-ahead log) to be written to a separate, highspeed device (like an SSD, NVMe, or NVDIMM) to increased performance. Efficient copy-on-write. RBD and CephFS snapshots rely on a copy-on-write clone mechanism that is implemented efficiently in BlueStore. BlueStore is a userspace model that provides its own memory management and cache. No need to clear the storage device cache OSDs help facilitate the performance of caching Default: cache the reads, don\u2019t cache the writes RocksDB\uff1a rocksdb\u662ffacebook\u57fa\u4e8eleveldb\u5f00\u53d1\u7684\u4e00\u6b3ekv\u6570\u636e\u5e93\uff0cBlueStore\u5c06\u5143\u6570\u636e\u5168\u90e8\u5b58\u653e\u81f3RocksDB\u4e2d\uff0c\u8fd9\u4e9b\u5143\u6570\u636e\u5305\u62ec\u5b58\u50a8\u9884\u5199\u5f0f\u65e5\u5fd7\u3001\u6570\u636e\u5bf9\u8c61\u5143\u6570\u636e\u3001Ceph\u7684omap\u6570\u636e\u4fe1\u606f\u3001\u4ee5\u53ca\u5206\u914d\u5668\u7684\u5143\u6570\u636e \u3002 BlueRocksEnv\uff1a \u662fRocksDB\u4e0eBlueFS\u4ea4\u4e92\u7684\u63a5\u53e3\uff1bRocksDB\u63d0\u4f9b\u4e86\u6587\u4ef6\u64cd\u4f5c\u7684\u63a5\u53e3EnvWrapper\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f\u5b9e\u73b0\u8be5\u63a5\u53e3\u6765\u81ea\u5b9a\u4e49\u5e95\u5c42\u7684\u8bfb\u5199\u64cd\u4f5c\uff0cBlueRocksEnv\u5c31\u662f\u7ee7\u627f\u81eaEnvWrapper\u5b9e\u73b0\u5bf9BlueFS\u7684\u8bfb\u5199\u3002 BlueFS\uff1a BlueFS\u662fBlueStore\u9488\u5bf9RocksDB\u5f00\u53d1\u7684\u8f7b\u91cf\u7ea7\u6587\u4ef6\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b58\u653eRocksDB\u4ea7\u751f\u7684.sst\u548c.log\u7b49\u6587\u4ef6\u3002 BlockDecive\uff1a BlueStore\u629b\u5f03\u4e86\u4f20\u7edf\u7684ext4\u3001xfs\u6587\u4ef6\u7cfb\u7edf\uff0c\u4f7f\u7528\u76f4\u63a5\u7ba1\u7406\u88f8\u76d8\u7684\u65b9\u5f0f\uff1b BlueStore\u652f\u6301\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u8bbe\u5907\uff0c\u5728\u903b\u8f91\u4e0aBlueStore\u5c06\u5b58\u50a8\u7a7a\u95f4\u5212\u5206\u4e3a\u4e09\u5c42\uff1a\u6162\u901f\uff08Slow\uff09\u7a7a\u95f4\u3001\u9ad8\u901f\uff08DB\uff09\u7a7a\u95f4\u3001\u8d85\u9ad8\u901f\uff08WAL\uff09\u7a7a\u95f4\uff0c\u4e0d\u540c\u7684\u7a7a\u95f4\u53ef\u4ee5\u6307\u5b9a\u4f7f\u7528\u4e0d\u540c\u7684\u8bbe\u5907\u7c7b\u578b\uff0c\u5f53\u7136\u4e5f\u53ef\u4f7f\u7528\u540c\u4e00\u5757\u8bbe\u5907\u3002 Allocator\uff1a\u8d1f\u8d23\u88f8\u8bbe\u5907\u7684\u7a7a\u95f4\u7ba1\u7406\uff0c\u53ea\u5728\u5185\u5b58\u505a\u6807\u8bb0\uff0c\u76ee\u524d\u652f\u6301StupidAllocator\u548cBitmapAllocator\u4e24\u79cd\u5206\u914d\u5668,Stupid\u57fa\u4e8eextent\u7684\u65b9\u5f0f\u5b9e\u73b0 Ceph BlueStore with Mixed Devices BlueStore Cache Parameters Under most circumstances, autotune is best bluestore_cache_autotune Description: Automatically tune the ratios assigned to different bluestore caches while respecting minimum values Type: Boolean Required: Yes Default: True (enabled) Related settings: bluestore_cache_autotune_chunk_size, bluestore_cache_autotune_interval, and others bluestore_cache_size Description: The amount of memory BlueStore will use for its cache. If zero, bluestore_cache_size_hdd or bluestore_cache_size_ssd will be used instead. Type: Integer Required: Yes Default: 0 bluestore_cache_size_hdd Description: The default amount of memory BlueStore will use for its cache when backed by an HDD Type: Integer Required: Yes Default: 1 * 1024 * 1024 * 1024 (1 GB) bluestore_cache_size_ssd Description: The default amount of memory BlueStore will use for its cache when backed by an SSD. Type: Integer Required: Yes Default: 3 * 1024 * 1024 * 1024 (3 GB) bluestore_cache_meta_ratio Description: The ratio of cache devoted to metadata. Type: Floating point Default: .01 bluestore_cache_kv_ratio Description: The ratio of cache devoted to key/value data (rocksdb). Type : Floating point Default: .99 bluestore_cache_kv_max Description : The maximum amount of cache devoted to key/value data (rocksdb). Type : Unsigned Integer Default : 512 * 1024*1024 (512 MB) BlueStore Device Types BlueStore has three types of roles for devices: The DATA role: Required: main device (block symlink) stores all object data. If no other types: \u201cdata\u201d device serves all the other roles The DB role: Optional: DB device (block.db symlink) stores metadata in RocksDB Whatever doesn\u2019t fit will spill back onto the \u201cdata\u201d device The Write Ahead Log (WAL/Journal) role: Optional: WAL device (block.wal symlink) stores the internal journal Can combine all 3 roles into one physical device Or combine DB/WAL onto a single device with the DATA device separate Or all three on seperate devices BlueStore Configuration Recommendations Devote DB and WAL to SSD or NVMe Allocate 64 GB to the RocksDB Allocate 4-6 GB to the WAL Assign the \u201cdata\u201d role to the slower (HDD) devices If combining WAL/DB on one device, use a single partition for both You can use a single SSD/NVMe to store multiple journals Architecture Overview of Object, Block, Filesystem Access Object Storage The state of the art of distributed storage Object storage is the Cloud Storage mechanism of choice Unstructured, to better accommodate large files and large quantities of files Ideal for large media files, like streaming videos, audio Scales really well, large capacities Ceph provides access to the storage via all three major data access methods: Block, Object, and File. For the storage backend, Object Storage is ideal Block Storage Traditional Block Storage: Volumes as a collection of blocks Blocks can be of various sizes, but all the same within a volume Typically a filesystem is installed on top of the volume Hard Drives, CDs, USB sticks, etc The standard disk device mechanism for Unix, Linux, Windows, etc. Ceph presents RADOS as block device (RBD = RADOS Block Device) Ceph calls these block devices \u201cimages\u201d Provides clients with access like a \u201cdisk drive\u201d KVM/QEMU; libvirt; or remote Linux system A native Windows client that can access the Block storage of Ceph directly is in progress RADOS Block Device (RBD) RBD is the RADOS Block Device A specific RBD instance in the cluster is called an \u201cimage\u201d RBD images can be accessed by OSs other than linux librbd provides interface for gateways like iSCSI RBD allows the client to decide what to do with the storage Filesystem type; raw disk, such as for a DB; etc RBD images can accommodate 16Eb file system sizes No matter the size, the storage is distributed durably throughout the cluster Data is striped across the RADOS cluster in object sized chunks 4MB default Provides high performance and durability Notable Benefits Ability to mount with Linux or QEMU KVM clients Thinly provisioned Resizable images Image import/export Image copy or rename Read-only snapshots Revert to snapshots Copy on Write clones Useful for standing up lots of virtual machines with same base configuration High performance due to striping across cluster nodes RBD image definition: Defined storage area presented as a block device to a client RBD Storage File Storage POSIX Filesystem via CephFS File access is a significant use case Home directories Historical comfort with files and directories Ease of managing \u201csmall\u201d stuff broadly, in a distributed system A Use Case that\u2019s growing in popularity: HPC CephFS is fast, scalable, and flexible Fits into many existing paradigms, rather seamlessly In particular: NFS, Samba/CIFS But even better: extending Linux filesystems Requires Metadata Service (MDS) for POSIX capabilities SUSE does NOT support any FUSE clients. Ceph Users and Authentication Ceph Users are generally applications; applications that use the storage cluster The must common user is Admin A ceph admin user and credentials must exist Additional users and associated credentials are useful Each user must have credentials to access the storage cluster The most fundamental form of credentials in Ceph is keys Ceph Users and Keys The admin user has rights to all Ceph resources. Other users can be setup to have a subset of rights There are basically two types of Users (Actors): An individual (a person) An application (like a gateway, or some other kind of system) Most users are of the type client, and are represented as a dotted string, such as: client.admin, or client.steve, or client.swift The root linux user on the Admin node is effectively the Admin Ceph user, since the root user has all privileges to all filesystem objects on the Adminnode, including the ceph.client.admin.keyring. The root user on any of the nodes in the cluster can \u201cimpersonate\u201d all of the Ceph clients. Linux user accounts do not have any affect on the Ceph Users as managed in the dashboard. Take care to keep backups of the /etc/ceph/ directory structure, so that you don\u2019t lose these keys/keyrings. Each user must have a key/keyring, for example: /etc/ceph/ceph.client.admin.keyring on the Admin node /etc/ceph/ceph.client.storage.keyring on a storage node admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = AQD6pHpfAAAAABAAHJvkvLhOKZyQxm9lgnR5Qg== caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" data1:/etc/ceph # cat ceph.client.storage.keyring [client.storage] key = AQD8pHpfAAAAABAAHecCBgBsLIyPrJf+27eXUQ== caps mon = \"allow rw\" Ceph Keys and Keyrings A keyring contains one or more keys Each user can have its own keyring A keyring can contain multiple keys Different clients and users must have their own key, but multiple keys can be joined together in a single keyring Normally a key will be contained in a keyring Core Ceph will only recognize and use keys from keyrings Stand-alone keys are useful for other tools, like clients Ceph Authentication List The Admin node (and client.admin) can list all Users ceph auth list Create a Ceph User A typical user will have read rights to MONs, and read/write rights to a pool (osd) ceph auth get/add/get-or-create xxxxxx Create a User with ceph-authtool Create a keyring ceph-authtool -C /etc/ceph/ceph.client.richard.keyring Create a key, and place it on the keyring ceph-authtool --gen-key -n client.richard --cap osd 'allow rw pool=data' --cap mon 'allow r' /etc/ceph/ceph.client.richard.keyring Now officially tell the cluster about the key (add user to the key) ceph auth add client.richard -i /etc/ceph/ceph.client.richard.keyring Authentication with cephx The mechanism for passing keys around is cephx Authentication for users and daemons Does not provide data encryption, only authentication with keys cephx simply ensures the authenticity of actors So that no man-in-the-middle attacks can occur Other authentication mechanisms are theoretically possible Attempts to integrate LDAP and Kerberos have been made \u2026 but they have not come to full fruition yet Ceph Configuration Historically, the Ceph configuration was kept only in a file on the Admin node: /etc/ceph/ceph.conf, and sync'd to MONs and Storage Nodes SES DeepSea manages the ceph.conf file. Don\u2019t edit it directly; use Salt and DeepSea With Ceph Nautilus, most configuration held as objects in the Monitors using Dashboard or CLI for operation Ceph Configuration Stored in the MONs The MONs keep a configuration database Show all the configuration keys: admin:/etc/ceph # ceph config ls |less Show the configuration settings that have been customized. The dumped output also indicates an EXPERTISE LEVEL The keys also have a \u201cwho\u201d attribute. In below case, \"osd.*\" represents the \"who\", which is getting the general setting for all OSDs Ceph Configuration Settings Show configuration settings that have been customized: admin:/etc/ceph # ceph config dump WHO MASK LEVEL OPTION VALUE RO mgr advanced mgr/dashboard/GRAFANA_API_URL https://mon1.pvgl.sap.corp:3000 * mgr advanced mgr/dashboard/RGW_API_ACCESS_KEY M11I3JGQHAQM94CS910K * mgr advanced mgr/dashboard/RGW_API_HOST mon3.pvgl.sap.corp * mgr advanced mgr/dashboard/RGW_API_PORT 80 * mgr advanced mgr/dashboard/RGW_API_SECRET_KEY YWyRc3mayEPiOEUzQ2o76KePSKmVKN4fIWxgqTt6 * mgr advanced mgr/dashboard/RGW_API_USER_ID admin * mgr advanced mgr/dashboard/ssl_server_port 8443 admin:/etc/ceph # ceph config get osd.* osd_max_object_size 134217728 admin:/etc/ceph # ceph config show osd.0 \u2026\u2026 admin:/etc/ceph # ceph config show osd.11 (4 data nodes, 3 osds in each node) \u25cb Each of the configuration settings have default values ceph config show-with-defaults osd.2 | less \u25cb Ceph keeps a log of configuration changes admin:/etc/ceph # ceph config log --- 8 --- 2020-10-05 14:31:51.425902 --- + mgr/mgr/dashboard/RGW_API_USER_ID = admin --- 7 --- 2020-10-05 14:31:50.418622 --- + mgr/mgr/dashboard/RGW_API_HOST = mon3.pvgl.sap.corp --- 6 --- 2020-10-05 14:31:49.398448 --- + mgr/mgr/dashboard/RGW_API_PORT = 80 --- 5 --- 2020-10-05 14:31:48.403965 --- + mgr/mgr/dashboard/RGW_API_SECRET_KEY = YWyRc3mayEPiOEUzQ2o76KePSKmVKN4fIWxgqTt6 --- 4 --- 2020-10-05 14:31:46.905701 --- + mgr/mgr/dashboard/RGW_API_ACCESS_KEY = M11I3JGQHAQM94CS910K --- 3 --- 2020-10-05 13:15:29.530355 --- + mgr/mgr/dashboard/GRAFANA_API_URL = https://mon1.pvgl.sap.corp:3000 --- 2 --- 2020-10-05 13:15:14.349623 --- + mgr/mgr/dashboard/ssl_server_port = 8443 --- 1 --- 2020-10-05 13:13:55.637896 --- Health Show status admin:/etc/ceph # ceph status cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 6w) mgr: mon1(active, since 13d) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 9w), 12 in (since 9w) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 11 KiB/s rd, 0 B/s wr, 11 op/s rd, 6 op/s wr admin:/etc/ceph # ceph health HEALTH_OK admin:/etc/ceph # ceph health detail HEALTH_OK admin:/etc/ceph # ceph mon stat e1: 3 mons at {mon1=[v2:10.58.121.186:3300/0,v1:10.58.121.186:6789/0],mon2=[v2:10.58.121.187:3300/0,v1:10.58.121.187:6789/0],mon3=[v2:10.58.121.188:3300/0v1:10.58.121.188:6789/0]}, election epoch 22, leader 0 mon1, quorum 0,1,2 mon1,mon2,mon3 admin:/etc/ceph # ceph osd stat 12 osds: 12 up (since 9w), 12 in (since 9w); epoch: e1375 admin:/etc/ceph # ceph pg stat 208 pgs: 208 active+clean; 4.7 KiB data, 2.0 GiB used, 82 GiB / 96 GiB avail; 1.2 KiB/s rd, 1 op/s Watch status -w, --watch : Watch live cluster changes --watch-debug : Watch debug events --watch-info : Watch info events --watch-sec : Watch security events --watch-warn : Watch warning events --watch-error : Watch error Scrub and Deep-Scrub \"Scrub\" is the process of doing a data consistency check Basically like running fsck on the cluster In Replicas: compare object metadata among replicas In EC: verify \u201ccode\u201d chunks Manual scrubbing can be done per OSD or per PG. \"osd scrub\" is just a collaborative wrapper of \"pg scrub\". ceph osd scrub osd.11 ceph pg scrub 3.33 \"scrub\" is a light process, daily Checks object size and attributes \"deep-scrub\" is a more thorough process, weekly Reads all data and checks the checksums Scrub \u2013 Manual vs Automatic You can let Ceph just do the default Run scrub daily, run deep-scrub weekly Ceph pays attention to usage and backs off when necessary You can change the defaults for both scrub and deepscrub, examples: osd_scrub_begin_week_day=6 (Saturday) osd_scrub_end_week_day=7 (Sunday) You can manually run scrubbings at any time if you suspect it\u2019s wanted or needed Manual scrubbings are not common Adjustments to Scrub Settings For most circumstances the default behavior of Scrub is adequate See current Scrub configuration settings: ceph config ls | grep osd_scrub ceph config ls | grep osd_deep_scrub ceph config get osd.* osd_scrub_begin_hour Change the settings immediately in the MON DB ceph config set osd.* osd_scrub_begin_hour 23 ceph config set osd.* osd_scrub_end_hour 5 Adjust Settings in ceph.conf with DeepSea To permanently change settings in ceph.conf This is the \u201cold\u201d way, but is still valid Remember that ceph.conf is controlled by DeepSea Add changes to /srv/salt/ceph/configuration/files/ceph.conf.d/global.conf Run the following DeepSea (Salt) commands: salt admin* state.apply ceph.configuration.create salt \\* state.apply ceph.configuration Wait for services/servers to be restarted, or tell Ceph to assimilate the ceph.conf settings now ceph config assimilate-conf -i /etc/ceph/ceph.conf Repair Problems Found by Scrubbing * If data (in an OSD or PG) becomes inconsistent, it will need to be repaired. You can configure scrubbing to automatically repair errors * osd_scrub_auto_repair=True * osd_scrub_auto_repair_num_errors=5 * Manually repair when appropriate * ceph osd repair osd.11 * ceph pg repair 3.33 Ceph Manager Modules Manager Modules help to extend the capabilities of Ceph List of Modules Supported in SES Balancer (always on) rash (always on) Dashboard DeepSea iostat Orchestrator (always on) progress (always on, tech preview) Prometheus RESTful rbd_support (always on) status (always on) telemetry volume (always on) Zabbix (plugin only, not the required agent) Enabling Manager Modules Show a list of Manager Modules ceph mgr module ls | less The output is quite long; best to pipe it through less The top of the output shows those modules that have been enabled The exhaustive output also displays the \u201cAPI\u201d of each module Manager modules are quite easy to enable and disable ceph mgr module enable <modulename> ceph mgr module disable <modulename> Show list of services that are active from the Modules ceph mgr services Module Capabilities Each module has its own settings, configuration Once the module is enabled, the ceph command accepts commands for the module No need to run the command as ceph mgr ... Examples: ceph crash stat ceph telemetry show Setting parameters (key/value pairs) of Modules ceph config set mgr mgr/telemetry/contact 'JD <john@example.net>' ceph config set mgr mgr/telemetry/description 'Training Cluster' Ceph Tell Tell commands are actually directed to the target service by way of the MONs ceph tell is a tool to tell a ceph daemon to perform a task \u2026 change a setting \u2026 execute a subroutine The target of ceph tell can be a single daemon or a collection of daemons All MONs: ceph tell mon.* injectargs '--mon-pg-warn-max-per-osd 4096' A specific OSD: ceph tell osd.9 bench ceph tell is the most common way to change logging for troubleshooting ceph tell <type>.<id> injectargs '--debug-<subsys> <int>' ceph tell osd.7 injectargs '--debug-osd 20' ceph tell osd.7 config set debug_osd 20 A \u201c/\u201d allows you to change both the file log and memory log settings simultaneously ceph tell mon.3 injectargs '--debug-mon 0/10' (The first is the file parameter, the second is the memory parameter) Since logging can fill space, important to restore settings after investigating ceph tell mon.3 injectargs '--debug-mon 1/5' ceph tell sends its instructions via the Monitors. So what if the MONs are having problems? To avoid running commands through the MONs, go directly to thenode running the daemon ssh storage1 ceph daemon osd.29 config show ceph daemon osd.29 config set debug_osd 0/20 Use with great care Ceph Dashboard What's Ceph Dashboard SES WEB-based Management Interface A Ceph MGR module, built-in to Ceph The open source \"port\" of openATTIC to Ceph. Technically it\u2019s not a port of openATTIC. SUSE and Ceph Community worked on implementing the openATTIC capabilities directly within Ceph Role-based and Multi-User Management of the SES cluster Create, manage, and monitor Pools, RBDs Manage users, access keys, quotas and buckets of RGW Manage NFS exports, iSCSI targets and portals, CephFS View cluster nodes/roles, monitor performance metrics Manage Ceph settings/configuration Reduces the need to understand complex Ceph commands The dashboard is stateless, it will reflect any changes to the Ceph cluster, Highlighted Enterprise Behavior via Ceph Dashboard Uses SSL/TLS By default will use a CA and certificate created by DeepSea or provide your own CA and certificate Can run without SSL/TLS (not recommended) Multi-User and Role Management Variety of mappings, i.e.: read, create, update, delete Single Sign-On, complying with SAML 2.0 Single Sign-On, complying with SAML 2.0 Auditing on the backend, to monitor specific user activity Internationalization (I18N), with a variety of language translations Ceph Dashboard Architecture Backend is based on CherryPy framework (CherryPy is a Minimalist Python Web Framework) Frontend WebUI is based on Angular/TypeScript A custom REST API Monitoring facilitated by Prometheus Visualization of data facilitated by Grafana Dependent upon DBUS, systemd, and systems\u2019 shell Dashboard as Manager Module Ceph Dashboard runs as a Manager module Runs on each MON/MGR node Really only actively available via the active MGR Runs on \u201cstandby\u201d on the standby MGR nodes Standby Dashboards will redirect to active MGR URL Dashboard automatically switches to active MGR node Helpful High Availability feature As a MGR module, enabled and configured by DeepSea Can be disabled if unwanted URL example: https://10.58.121.186:8443 Grafana and Prometheus Prometheus collects various data about the cluster Grafana represents the data as graphs Ceph Dashboard uses both to improve insight into SES Prometheus Open source event monitoring software \"Scrapes\" (collects) data from nodes/services in the cluster Real-time Time series Custom scrapers have been created for Ceph Stores scraped data in memory and on disk Presents data to other software for graphical representation Integrated nicely with Grafana Grafana The leading open source software for time series analytics \"Dashboards\" of panels, graphs, metrics, etc. \"Dashboard\" is a slightly conflicting term, but still meaningful Renders data in a graphical way collected from Prometheus Graphs are customized for use on the Ceph Dashboard Dashboard Users Always need an \u201cAdmin\u201d user for the Dashboard \u00a7 The admin keys of the root user on the \u201cAdmin\u201d node in the cluster Dashboard Users are accounts that relate only to using the Dashboard \u00a7 Not the same as Ceph CLI users and client keys; but could coincide Any person who wants to interact with the storage cluster via the Dashboard must have a user account Variety of Users established by the Admin User, and various permissions based on Admin-defined Roles User Authentication Dashboard Administrators can setup users with specific privileges The privileges and permissions are managed as \"roles\" User accounts can be created directly in the Dashboard Stored as objects in Ceph User accounts can also be tied to other authentication mechanisms: Single Sign-On Service; SAML 2.0 compliant protocol Dashboard accounts can be managed from the Dashboard or from the CLI Example: ceph dashboard ac-user-show [<username>] The Admin Dashboard User (the term \u201cadmin\u201d is used differently in different places) The Dashboard Admin User is not the same as other admins The \u201cadmin\u201d node is obviously not directly tied to any admin user The Admin Dashboard User is created at Deployment time Given a random password by DeepSea You must use the CLI to establish the admin password ceph dashboard ac-user-show admin ceph dashboard ac-user-set-password admin <password> \u25cb The SES Deployment Course has set the password to mypassword admin:~ # ceph dashboard ac-user-show [\"admin\"] admin:~ # ceph dashboard ac-user-show admin {\"username\": \"admin\", \"password\": \"$2b$12$4lC/AU7jc6midTZufj4P4.rBtVzRGf7Zy7fUbD6G9YfdfVEwkwuUy\", \"roles\": [\"administrator\"], \"name\": null \"email\":null\"lastUpdate\": 1601874928} Health from the Dashboard Cluster Status Monitors OSDs Manager Daemons Hosts Object Gateways Metadata Service iSCSI Gateways Cluster Performance from Dashboard Client IOPS Client Throughput Client Read/Write Recovery Throughput Scrub Performance Data Hosts: Overall Performance Monitors: Performance Counters OSDs: Relative Read/Write bar graphs, and Overall Performance Pools: Relative Read/Write bar graphs, and Overall Performance Block images: Overall Performance CephFS: Performance Details RGW: Overall Performance Cluster Capacity from Dashboard Capacity data: Number of Pools Raw Capacity Number of Objects (Ceph objects, not user objects from RGW) Placement Groups per OSD Placement Group Status Basic Troubleshooting Ceph Logs Logs normally stored in /var/log/ceph/ No real logs on the admin node Each service has its own log on the MON, Storage and Gateway nodes Logs handled routinely by logrotate Ceph has logs that are stored to files and in memory (triggered by event or manual request) There are 21 different levels of logging: 0-20 (0 is no logging; 20 is the most verbose logging) There are many subsystems that do their own logging, and can be configured independently Most common: mon, osd, mgr, rados, rbd, mds, rgw Others: asok, auth, client, filestore, journal, monc, ms, paxos, and more There are only 3 types of daemons: osd, mon, mds Using Tell to Change Log Levels 1) Check the Dashboard and Health. Common commands ceph status ceph osd status ceph osd df ceph osd utilization ceph osd pool stats ceph osd tree ceph pg stat 2) Network Troubleshooting Always be sure that the network (and related services) are working properly Ceph depends heavily on tightly synchronized time; make sure network time services are working on each node DNS hostnames are similarly essential 3) Check the Logs Go to the node of the component implicated in HEALTH 4: Raise the DEBUG Level. Follow this simple formula: Raise the debug level (a little each time until you see the problem) Check the logs Repeat as necessary Don\u2019t forget to restore the debug level back to its normal level 5) Check the Storage Device If the problem is with an OSD or a storage device, go straight to the device: hdparm smartctl And check out the details of the combination of OSD and storage device: lsblk /var/lib/ceph/osd/ 6) Scrub (or not) Sometimes simply scrubbing an OSD or PG can cause the checksum-ing process to reveal problems At least some problems can be made more clear with the result of scrub and/or deep-scrub Even doing a scrub can kick Ceph into fixing the problem itself And don\u2019t forget ceph osd repair On the other hand, sometimes Scrub can make things worse. If you suspect Scrub is part of the problem, turn it off: ceph osd set noscrub ceph osd unset noscrub 7) Placement Groups When Placement Groups cause problems: * ceph pg dump summary * ceph pg dump pools * ceph pg dump_jason * ceph pg dump | less Followed by a strategic \u201crepair\u201d of the PG * ceph pg repair <pgid> 8) Running supportconfig YaST Support Module From CLI: supportconfig The collected data is stored in a file called /var/log/nts_<hostname>_<datetime>.txz","title":"SUSE Enterprise Storage Foundation"},{"location":"linux/SES/linux_ses_memo/#suse-enterprise-storage-foundation","text":"","title":"SUSE Enterprise Storage Foundation"},{"location":"linux/SES/linux_ses_memo/#cephs-rados","text":"Everything in Ceph is stored in the RADOS cluster as Objects. Ceph\u2019s RADOS: Reliable Autonomous Distributed Object Store Ceph\u2019s RADOS is composed of storage devices represented as: Raw storage device with LVM (BlueStore) Standard filesystem (FileStore) The Object Storage Daemon (OSD) integrates each disk device as part of the RADOS cluster.","title":"Ceph\u2019s RADOS"},{"location":"linux/SES/linux_ses_memo/#ceph-architecture","text":"Ceph is made of two groups of core components The RADOS cluster Provides the clustered object storage Native Object Access methods Gateways Access to the object store via standard protocols librados Direct access to the object store using a native API Examples: iSCSI Gateway (block) -- IGW - iSCSI is a storage area network (SAN) protocol. Exports RADOS Block Device (--RBD) (images as iSCSI disks). iSCSI access to RDB images. lrbd is no longer used in SES6. RADOS Gateway (object) -- RGW Is an object storage interface built on top of librados CephFS (file) A MetaData Service (MDS) is required. Direct access to RADOS (no LIBRADOS layer) Traditional filesystem interface. NFS Ganesha (object, file) Provides NFS exports to: RGW buckets for access the object store The CephFS filesystem Client access the storage services of the cluster via Gateways and Librados The librados API allows interaction with the following daemons: The Ceph Monitor, which maintains a master copy of the cluster map The Ceph OSD Daemon (OSD), which stores data as objects on a storage node.","title":"Ceph architecture"},{"location":"linux/SES/linux_ses_memo/#enhanced-ses-architecture-diagram","text":"","title":"Enhanced SES Architecture Diagram"},{"location":"linux/SES/linux_ses_memo/#object-storage","text":"The state of the art of distributed SDS storage Unstructured, to better accommodate large files and large quantities of files For large files and large quantities of files, it performs far better than other storage mechanisms Agile, scalable, extensible, and very customizable Invisible to the end-user, ideal for backends Perfect for systemic, application-based use cases. Not necessarily perfect for direct Human use Through associated metadata, ideal for computational analytics And CRUSH takes full advantage of this (CRUSH = Controllable Replication Under Scalable Hashing) Ceph Object Storage supports two interfaces: S3-compatible Swift-compatible Object-based storage has become the standard backend storage mechanism for nearly all modern Enterprise Storage Solutions.","title":"Object Storage"},{"location":"linux/SES/linux_ses_memo/#ceph-osds-object-storage-daemon","text":"A Ceph OSD (object storage daemon, ceph-osd) stores data, handles data replication, recovery, rebalancing, and provides some monitoring information to Ceph Monitors and Managers by checking other Ceph OSD Daemons for a heartbeat. The Ceph Storage Cluster receives data from Ceph Clients. Clients (dedicated access points, e.g., gateway) could be a Ceph Block Device, Ceph Object Storage, the Ceph Filesystem or a custom implementation using librados. The client requests the cluster status from a monitor node The client uses the status information to identify the location of objects in the cluster The client accesses the objects directly via the OSD node The OSD then stores the data as objects. Each object corresponds to a file in a filesystem which is stored on an OSD. The OSD Daemons take care of the reads and writes on the storage disks. When OSDs are deployed in SES5 the default is to use BlueStore which uses the raw disk and does not require a linux file system to be placed on the disk before it can be used. OSD Daemons store all data as objects in a flat namespace, i.e. no hierarchy of directories. At least 3 Ceph OSDs are normally required for redundancy and high availability.","title":"Ceph OSDs (Object Storage Daemon)"},{"location":"linux/SES/linux_ses_memo/#ceph-mons-monitor-servers","text":"A Ceph Monitor (ceph-mon) maintains maps of the cluster state, including Monitor Map Manager Map OSD Map PG Map CRUSH Map Epoch These maps are critical cluster state required for Ceph daemons to coordinate with each other. Monitors are also responsible for managing authentication between daemons and clients. At least 3 monitors are normally required for redundancy and high availability. An odd number of MONs is required (Paxos requires). Typically 5 is sufficient for mid or large size cluster. Paxos is an algorithm used for cluster durability. Leader MON expects 50% quality to create quorum. Lowest IP address becomes leader. After new leader selected, all MONs polled for epoch. Leader Mon provides lease to non-leader MONs. MONs are NOT in the data path. They merely serve maps to clients so that the client can go directly to the appropriate OSD storage daemon. Monitor nodes MONs do not serve objects to clients","title":"Ceph Mons (Monitor Servers)"},{"location":"linux/SES/linux_ses_memo/#ceph-mgrs-manager-daemon","text":"A Ceph Manager daemon (ceph-mgr) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization current performance metrics system load The Ceph Manager daemons also host python-based plugins to manage and expose Ceph cluster information, including a web-based dashboard and REST API. At least two managers are normally required for high availability. MON/MGR daemons are required to run on the same node in SES","title":"Ceph MGRs (Manager Daemon)"},{"location":"linux/SES/linux_ses_memo/#ceph-mds-metadata","text":"A Ceph Metadata Server (MDS, ceph-mds) stores metadata on behalf of the Ceph Filesystem. Ceph Metadata Servers allow POSIX file system users to execute basic commands, for example ls -al without placing an large load on the Ceph Storage Cluster.","title":"Ceph MDS (Metadata)"},{"location":"linux/SES/linux_ses_memo/#ceph-admin-node","text":"The Admin node fills the \u201cmaster\u201d and \u201cadmin\u201d roles for DeepSea. Salt is central to SES. SES\u2019s deployment and life-cycle management tool. The Admin node keeps master Ceph authentication keys. Prometheus and Grafana provide cluster monitoring and data graphs","title":"Ceph Admin Node"},{"location":"linux/SES/linux_ses_memo/#ceph-dashboard","text":"Runs as a Ceph Manager module; runs via the MON/MGR node.","title":"Ceph Dashboard"},{"location":"linux/SES/linux_ses_memo/#client-access","text":"Object Storage (RADOSGW or RGW) Block Storage (RDB). RBD is built on top of librados. CephFS iSCSI Gateway NFS Ganesha SMB/CIFS Native protocols via librados","title":"Client Access"},{"location":"linux/SES/linux_ses_memo/#objects-in-ceph","text":"Everything stored in the Ceph cluster is an object. Default object size is 4MB. Each object has a unique ID. ID is unique across the entire cluster. Objects have associated metadata, in Key: Value pairs. In Ceph we use Storage Pools to organize or arrange our objects. Pools are logical partitions to manage objects Parameters to manage Pools Number of data replicas (Replica pools), or configuration of Erasure Code (size) (Erasure Code pools) Erasure Code is an alternative to Replication SIZE for Erasure Coding is K+M K = Data chunks, M = \u201cParity\u201d chunks EC reduces the hit to raw storage capacity EC incurs a greater hit to CPU on the OSDs as a tradeoff Placement Groups (PG) PG is used to manage objects within a pool. PGs are associated with OSDs for data placement PGs are a central feature of CRUSH that help to provide data durability by way of distribution No PG is owned by an OSD. (And an OSD is not owned by a PG.) PGs are just randomly assigned by CRUSH through all of the OSDs to spread the distribution of data Locating data among PGs is all handled economically, deterministically by way of CRUSH calculations PGs are subdivisions of pools Number of PGs = (Number of OSDs * 100) / Size (Size = either num of replicas, or K+M) The final PG number must be a power of 2 The default number of PGs for a new pool is 8 (it's too small for enterprise solution) In general, PG and PGP numbers should be the same pg_num is the number of placement groups for the pool (placement group, \u5b58\u50a8\u6c60\u7684\u76ee\u5f55\u4e2a\u6570 ) pgp_num is the number of placement groups that will be considered for placement (placement group for placement purpose, pg\u53ef\u7528\u7684osd\u6392\u5217\u7ec4\u5408\u6570\u91cf) \u4ec5\u589e\u5927pg_num\uff1a \u56e0\u4e3apgp_num\u6ca1\u53d8\uff0cpg\u7684osd\u7ec4\u5408\u4ecd\u53ea\u80fd\u4ece\u5f53\u524dpgp_num\u79cd\u7ec4\u5408\u91cc\u9762\u6311\u9009\uff0c\u5bfc\u81f4\u65b0\u589e\u7684pg\u548c\u65e7pg\u4f1a\u6709\u91cd\u590d\u7684osd\u7ec4\u5408\uff0c\u8be5\u73b0\u8c61\u79f0\u4e4b\u4e3a\u5206\u88c2\uff1b\u6b64\u65f6pg\u548cosd\u7684\u6620\u5c04\u6ca1\u6709\u53d8\uff1b \u7ee7\u7eed\u589e\u5927pgp_num\uff0c\u4f7f\u5176\u7b49\u4e8epg_num\uff1a \u65e7pg\u6ca1\u6709\u53d8\u5316\uff0c\u4f46\u65b0\u589epg\u7684osd\u7ec4\u5408\u53d1\u751f\u53d8\u5316\uff0c\u5373\u5f00\u59cb\u91cd\u65b0\u5206\u5e03 Placement Group (PG) \u5f52\u7f6e\u7ec4\u72b6\u6001 Creating \u521b\u5efa\u5b58\u50a8\u6c60\u65f6\uff0c\u5b83\u4f1a\u521b\u5efa\u6307\u5b9a\u6570\u91cf\u7684\u5f52\u7f6e\u7ec4\u3002 ceph \u5728\u521b\u5efa\u4e00\u6216\u591a\u4e2a\u5f52\u7f6e\u7ec4\u65f6\u4f1a\u663e\u793a creating\u3002 \u521b\u5efa\u5b8c\u540e\uff0c\u5728\u5176\u5f52\u7f6e\u7ec4\u7684 Acting Set \u91cc\u7684 OSD \u5c06\u5efa\u7acb\u4e92\u8054\u3002 \u4e00\u65e6\u4e92\u8054\u5b8c\u6210\uff0c\u5f52\u7f6e\u7ec4\u72b6\u6001\u5e94\u8be5\u53d8\u4e3a active+clean\uff0c\u610f\u601d\u662fceph \u5ba2\u6237\u7aef\u53ef\u4ee5\u5411\u5f52\u7f6e\u7ec4\u5199\u5165\u6570\u636e\u4e86\u3002 peering ceph \u4e3a\u5f52\u7f6e\u7ec4\u5efa\u7acb\u4e92\u8054\u65f6\uff0c\u4f1a\u8ba9\u5b58\u50a8\u5f52\u7f6e\u7ec4\u526f\u672c\u7684 OSD \u4e4b\u95f4\u5c31\u5176\u4e2d\u7684\u5bf9\u8c61\u548c\u5143\u6570\u636e\u72b6\u6001\u8fbe\u6210\u4e00\u81f4\u3002 ceph \u5b8c\u6210\u4e86\u4e92\u8054\uff0c\u4e5f\u5c31\u610f\u5473\u7740\u5b58\u50a8\u7740\u5f52\u7f6e\u7ec4\u7684 OSD \u5c31\u5176\u5f53\u524d\u72b6\u6001\u8fbe\u6210\u4e86\u4e00\u81f4\u3002 \u7136\u800c\uff0c\u4e92\u8054\u8fc7\u7a0b\u7684\u5b8c\u6210\u5e76\u4e0d\u80fd\u8868\u660e\u5404\u526f\u672c\u90fd\u6709\u4e86\u6570\u636e\u7684\u6700\u65b0\u7248\u672c\u3002 active ceph \u5b8c\u6210\u4e92\u8054\u8fdb\u7a0b\u540e,\u4e00\u5f52\u7f6e\u7ec4\u5c31\u53ef\u53d8\u4e3a active\u3002 active \u72b6\u6001\u901a\u5e38\u610f\u5473\u7740\u5728\u4e3b\u5f52\u7f6e\u7ec4\u548c\u526f\u672c\u4e2d\u7684\u6570\u636e\u90fd\u53ef\u4ee5\u8bfb\u5199\u3002 clean \u67d0\u4e00\u5f52\u7f6e\u7ec4\u5904\u4e8e clean \u72b6\u6001\u65f6\uff0c\u4e3b OSD \u548c\u526f\u672c OSD \u5df2\u6210\u529f\u4e92\u8054\uff0c\u5e76\u4e14\u6ca1\u6709\u504f\u79bb\u7684\u5f52\u7f6e\u7ec4\u3002 ceph \u5df2\u628a\u5f52\u7f6e\u7ec4\u4e2d\u7684\u5bf9\u8c61\u590d\u5236\u4e86\u89c4\u5b9a\u6b21\u6570\u3002 degraded \u5f53\u5ba2\u6237\u7aef\u5411\u4e3b OSD \u5199\u5165\u6570\u636e\u65f6\uff0c\u7531\u4e3b OSD \u8d1f\u8d23\u628a\u526f\u672c\u5199\u5165\u5176\u4f59\u590d\u5236 OSD\u3002 \u4e3b OSD \u628a\u5bf9\u8c61\u5199\u5165\u590d\u5236 OSD \u540e\uff0c\u5728\u6ca1\u6536\u5230\u6210\u529f\u5b8c\u6210\u7684\u786e\u8ba4\u524d\uff0c\u4e3b OSD \u4f1a\u4e00\u76f4\u505c\u7559\u5728 degraded \u72b6\u6001\u3002 \u5f52\u7f6e\u7ec4\u72b6\u6001\u53ef\u4ee5\u662f active+degraded \u72b6\u6001\uff0c\u539f\u56e0\u5728\u4e8e\u4e00 OSD \u5373\u4f7f\u6ca1\u6240\u6709\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u5904\u4e8e active \u72b6\u6001\u3002 \u5982\u679c\u4e00OSD \u6302\u4e86\uff0cceph \u4f1a\u628a\u76f8\u5173\u7684\u5f52\u7f6e\u7ec4\u90fd\u6807\u8bb0\u4e3a degraded\u3002 \u90a3\u4e2a OSD \u91cd\u751f\u540e\uff0c\u5b83\u4eec\u5fc5\u987b\u91cd\u65b0\u4e92\u8054\u3002 \u7136\u800c\uff0c\u5982\u679c\u5f52\u7f6e\u7ec4\u4ecd\u5904\u4e8e active \u72b6\u6001\uff0c\u5373\u4fbf\u5b83\u5904\u4e8e degraded \u72b6\u6001\uff0c\u5ba2\u6237\u7aef\u8fd8\u53ef\u4ee5\u5411\u5176\u5199\u5165\u65b0\u5bf9\u8c61\u3002 \u5982\u679c\u4e00 OSD \u6302\u4e86\uff0c\u4e14 degraded \u72b6\u6001\u6301\u7eed\uff0cceph \u4f1a\u628a down \u7684 OSD \u6807\u8bb0\u4e3a\u5728\u96c6\u7fa4\u5916(out)\u3001\u5e76\u628a\u90a3\u4e9b down \u6389\u7684 OSD \u4e0a\u7684\u6570\u636e\u91cd\u6620\u5c04\u5230\u5176\u5b83 OSD\u3002 \u4ece\u6807\u8bb0\u4e3a down \u5230 out \u7684\u65f6\u95f4\u95f4\u9694\u7531 mon osd down out interval \u63a7\u5236,\u9ed8\u8ba4\u662f 300 \u79d2\u3002 \u5f52\u7f6e\u7ec4\u4e5f\u4f1a\u88ab\u964d\u7ea7(degraded)\uff0c\u56e0\u4e3a\u5f52\u7f6e\u7ec4\u627e\u4e0d\u5230\u672c\u5e94\u5b58\u5728\u4e8e\u5f52\u7f6e\u7ec4\u4e2d\u7684\u4e00\u6216\u591a\u4e2a\u5bf9\u8c61\uff0c\u8fd9\u65f6\uff0c\u4f60\u4e0d\u80fd\u8bfb\u6216\u5199\u627e\u4e0d\u5230\u7684\u5bf9\u8c61\uff0c\u4f46\u4ecd\u80fd\u8bbf\u95ee\u5176\u5b83\u4f4d\u4e8e\u964d\u7ea7\u5f52\u7f6e\u7ec4\u4e2d\u7684\u5bf9\u8c61\u3002 recovering ceph \u88ab\u8bbe\u8ba1\u4e3a\u53ef\u5bb9\u9519\uff0c\u53ef\u62b5\u5fa1\u4e00\u5b9a\u89c4\u6a21\u7684\u8f6f\u3001\u786c\u4ef6\u95ee\u9898\u3002 \u5f53\u67d0 OSD \u6302\u4e86(down)\u65f6\uff0c\u5176\u5185\u5bb9\u7248\u672c\u4f1a\u843d\u540e\u4e8e\u5f52\u7f6e\u7ec4\u5185\u7684\u5176\u5b83\u526f\u672c\u3002 \u5b83\u91cd\u751f(up)\u65f6\uff0c\u5f52\u7f6e\u7ec4\u5185\u5bb9\u5fc5\u987b\u66f4\u65b0\uff0c\u4ee5\u53cd\u6620\u5f53\u524d\u72b6\u6001\u3002 \u5728\u6b64\u671f\u95f4\uff0cOSD \u5728recovering \u72b6\u6001\u3002 \u4e00\u6b21\u786c\u4ef6\u5931\u8d25\u53ef\u80fd\u7275\u8fde\u591a\u4e2a OSD\u3002\u6bd4\u5982\u4e00\u4e2a\u673a\u67dc\u7684\u7f51\u7edc\u4ea4\u6362\u673a\u5931\u8d25\u4e86\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u591a\u4e2a\u4e3b\u673a\u843d\u540e\u4e8e\u96c6\u7fa4\u7684\u5f53\u524d\u72b6\u6001\uff0c\u95ee\u9898\u89e3\u51b3\u540e\u6bcf\u4e00\u4e2a OSD \u90fd\u5fc5\u987b\u6062\u590d\u3002 ceph \u63d0\u4f9b\u4e86\u5f88\u591a\u9009\u9879\u6765\u5747\u8861\u8d44\u6e90\u7ade\u4e89\uff0c\u5982\u65b0\u670d\u52a1\u8bf7\u6c42\u3001\u6062\u590d\u6570\u636e\u5bf9\u8c61\u548c\u6062\u590d\u5f52\u7f6e\u7ec4\u5230\u5f53\u524d\u72b6\u6001\u3002 osd recovery delay start \u9009\u9879\u5141\u8bb8\u4e00 OSD \u5728\u5f00\u59cb\u6062\u590d\u8fdb\u7a0b\u524d\uff0c\u5148\u91cd\u542f\u3001\u91cd\u5efa\u4e92\u8054\u3001\u751a\u81f3\u5904\u7406\u4e00\u4e9b\u91cd\u653e\u8bf7\u6c42\u3002 osd recovery threads \u9009\u9879\u9650\u5236\u6062\u590d\u8fdb\u7a0b\u7684\u7ebf\u7a0b\u6570\uff0c\u9ed8\u8ba4\u4e3a 1 \u7ebf\u7a0b\u3002 osd recovery thread timeout \u8bbe\u7f6e\u7ebf\u7a0b\u8d85\u65f6\uff0c\u56e0\u4e3a\u591a\u4e2aOSD \u53ef\u80fd\u4ea4\u66ff\u5931\u8d25\u3001\u91cd\u542f\u548c\u91cd\u5efa\u4e92\u8054\u3002 osd recovery max active \u9009\u9879\u9650\u5236\u4e00 OSD \u6700\u591a\u540c\u65f6\u63a5\u53d7\u591a\u5c11\u8bf7\u6c42\uff0c\u4ee5\u9632\u5b83\u538b\u529b\u8fc7\u5927\u800c\u4e0d\u80fd\u6b63\u5e38\u670d\u52a1\u3002 osd recovery max chunk \u9009\u9879\u9650\u5236\u6062\u590d\u6570\u636e\u5757\u5c3a\u5bf8\uff0c\u4ee5\u9632\u7f51\u7edc\u62e5\u585e\u3002 back filling \u6709\u65b0 OSD \u52a0\u5165\u96c6\u7fa4\u65f6\uff0cCRUSH \u4f1a\u628a\u73b0\u6709\u96c6\u7fa4\u5185\u7684\u5f52\u7f6e\u7ec4\u91cd\u5206\u914d\u7ed9\u5b83\u3002 \u5f3a\u5236\u65b0 OSD \u7acb\u5373\u63a5\u53d7\u91cd\u5206\u914d\u7684\u5f52\u7f6e\u7ec4\u4f1a\u4f7f\u4e4b\u8fc7\u8f7d\uff0c\u7528\u5f52\u7f6e\u7ec4\u56de\u586b\u53ef\u4f7f\u8fd9\u4e2a\u8fc7\u7a0b\u5728\u540e\u53f0\u5f00\u59cb\u3002 \u56de\u586b\u5b8c\u6210\u540e\uff0c\u65b0 OSD \u51c6\u5907\u597d\u65f6\u5c31\u53ef\u4ee5\u5bf9\u5916\u670d\u52a1\u4e86\u3002 remapped \u67d0\u4e00\u5f52\u7f6e\u7ec4\u7684 Acting Set \u53d8\u66f4\u65f6\uff0c\u6570\u636e\u8981\u4ece\u65e7\u96c6\u5408\u8fc1\u79fb\u5230\u65b0\u7684\u3002 \u4e3b OSD \u8981\u82b1\u8d39\u4e00\u4e9b\u65f6\u95f4\u624d\u80fd\u63d0\u4f9b\u670d\u52a1\uff0c\u6240\u4ee5\u5b83\u53ef\u4ee5\u8ba9\u8001\u7684\u4e3b OSD \u6301\u7eed\u670d\u52a1\u3001\u76f4\u5230\u5f52\u7f6e\u7ec4\u8fc1\u79fb\u5b8c\u3002 \u6570\u636e\u8fc1\u79fb\u5b8c\u540e,\u4e3b OSD \u4f1a\u6620\u5c04\u5230\u65b0 acting set\u3002 stale \u867d\u7136 ceph \u7528\u5fc3\u8df3\u6765\u4fdd\u8bc1\u4e3b\u673a\u548c\u5b88\u62a4\u8fdb\u7a0b\u5728\u8fd0\u884c\uff0c\u4f46\u662f ceph-osd \u4ecd\u6709\u53ef\u80fd\u8fdb\u5165 stuck \u72b6\u6001\uff0c\u5b83\u4eec\u6ca1\u6709\u6309\u65f6\u62a5\u544a\u5176\u72b6\u6001(\u5982\u7f51\u7edc\u77ac\u65ad)\u3002 \u9ed8\u8ba4OSD \u5b88\u62a4\u8fdb\u7a0b\u6bcf\u534a\u79d2(0.5)\u4f1a\u4e00\u6b21\u62a5\u544a\u5176\u5f52\u7f6e\u7ec4\u3001\u51fa\u6d41\u91cf\u3001\u5f15\u5bfc\u548c\u5931\u8d25\u7edf\u8ba1\u72b6\u6001\uff0c\u6b64\u9891\u7387\u9ad8\u4e8e\u5fc3\u8df3\u9600\u503c\u3002 \u5982\u679c\u4e00\u5f52\u7f6e\u7ec4\u7684\u4e3b OSD \u6240\u5728\u7684 acting set \u6ca1\u80fd\u5411\u76d1\u89c6\u5668\u62a5\u544a\u3001\u6216\u8005\u5176\u5b83\u76d1\u89c6\u5668\u5df2\u7ecf\u62a5\u544a\u4e86\u90a3\u4e2a\u4e3b OSD \u5df2 down\uff0c\u76d1\u89c6\u5668\u4eec\u5c31\u4f1a\u628a\u6b64\u5f52\u7f6e\u7ec4\u6807\u8bb0\u4e3a stale\u3002 \u542f\u52a8\u96c6\u7fa4\u65f6\uff0c\u4f1a\u7ecf\u5e38\u770b\u5230 stale \u72b6\u6001\uff0c\u76f4\u5230\u4e92\u8054\u5b8c\u6210\u3002 \u96c6\u7fa4\u8fd0\u884c\u4e00\u9635\u540e\uff0c\u5982\u679c\u8fd8\u80fd\u770b\u5230\u6709\u5f52\u7f6e\u7ec4\u4f4d\u4e8e stale \u72b6\u6001\uff0c\u5c31\u8bf4\u660e\u90a3\u4e9b\u5f52\u7f6e\u7ec4\u7684\u4e3b OSD \u6302\u4e86(down)\u3001\u6216\u6ca1\u5728\u5411\u76d1\u89c6\u5668\u62a5\u544a\u7edf\u8ba1\u4fe1\u606f\u3002 Each pool has its own autoscaler settings The PG balancer optimizes the placement of PGs across OSD crush-compat mode It's default mode Uses the compat weight-set feature upmap mode. It's perfect mode, which an equal number of PGs on each OSD Use fine-grained control over the PG mapping Snapshots Rulesets to manage CRUSH placement Each pool has a defined CRUSH ruleset A CRUSH ruleset is a definition of how the OSDs organize data This allows configuration of data distribution to be managed per pool A single CRUSH ruleset can be reused by multiple pools A ruleset can take into account: \u9700\u8981\u8003\u8651\u7684\u70b9 physical layout of nodes in the cluster organization of network infrastructure selection of OSDs backed by SSDs versus HDDs, etc Each pool can use either Replication or Erasure Coding Replication is the original, default approach to resiliency Erasure Coded pools have an EC Profile assigned Different than CRUSH rulesets, but similar: define how OSDs organize data The profile defines K, M values; encoding method/plugin; etc","title":"Objects in Ceph"},{"location":"linux/SES/linux_ses_memo/#crush-controllable-replication-under-scalable-hashing","text":"CRUSH is a key piece of the Ceph storage solution With the CRUSH algorithm used by Ceph: Data is not centrally stored, it is distributed CRUSH calculates the storage location for each object dynamically No requirement to store a global index of object locations","title":"CRUSH (Controllable Replication Under Scalable Hashing)"},{"location":"linux/SES/linux_ses_memo/#crush-algorithm","text":"The CRUSH algorithm deterministically calculates the location of any object in the Ceph RADOS cluster Overhead is low and calculation is performed by each client As no metadata store is required, CRUSH removes the limitations of traditional metadata based management No direct control over the placement of your data in the cluster Higher CPU requirements","title":"CRUSH Algorithm"},{"location":"linux/SES/linux_ses_memo/#crush-maps-and-rulesets","text":"CRUSH Rulesets are the named sets of rules: Combining all of the customizable CRUSH behavior settings Assigned to pool to govern how the pool\u2019s data is distributed in the cluster CRUSH Maps are central to how Ceph distributes data, and maintaining the durability of the data When the cluster is deployed, Ceph creates a simple default ruleset for replicated pools: replicated_rule CRUSH behavior depends on the behaviors and performance of storage devices CRUSH Maps should be crafted to take advantage of those behaviors Rulesets should be used to clearly identify how the devices in your environment should be employed Device Classes exist to indicate performance behavior: hdd, ssd, nvme Ceph OSDs will automatically set the Device Class of a storage device when the OSD is started Working with CRUSH Map Rulesets List the OSDs, which host each OSD belongs to: ceph osd tree ceph osd df tree ceph osd df tree -f json-pretty Find the host of a specific OSD: ceph osd find 8 Show the existing defined rulesets: ceph osd crush rule ls Examine the definition of an existing ruleset: ceph osd crush rule dump <rulesetname> There are 3 options for creating a new ruleset: simple replicated erasure Creating new rulesets: ceph osd crush rule create-replicated <name> ceph osd crush rule create-erasure <name> <ec_profile> Create a new ruleset using a Device Class: create-replicated <name> <root> <failure-domain-level> <device-class> <root> Description : The name of the node under which data should be placed. Type : String Example : default (rarely would you need to make this different than \u201cdefault\u201d) <failure-domain-type> or <failure-doamin-level> Description : The type of CRUSH node (bucket) across which replicas should be separated. Type : String Example : rack <device-class> Description : The device class data should be placed on. Type : String Example : ssd","title":"CRUSH Maps and Rulesets"},{"location":"linux/SES/linux_ses_memo/#crush-weight","text":"You may need to move data around New nodes degraded nodes rebalancing View the current CRUSH weights ceph osd crush tree ceph osd df tree Change the weight for an OSD ceph osd crush reweight <osd.N> <weight> The important difference between ceph osd reweight and ceph osd crush reweight \"ceph osd crush reweight\" sets the CRUSH weight of the OSD. This weight is an arbitrary value (generally the size of the disk in TB or something) and controls how much data the system tries to allocate to the OSD. \"ceph osd reweight\" sets an override weight on the OSD. This value is in the range 0 to 1, and forces CRUSH to re-place (1-weight) of the data that would otherwise live on this drive. It does not change the weights assigned to the buckets above the OSD, and is a corrective measure in case the normal CRUSH distribution isn\u2019t working out quite right. \"ceph osd reweight\" is temporary. \"ceph osd crush reweight\" is sticky, permanent (until you change it again). Setting a weight of an OSD to 0 is effectively setting the OSD \"out\" - you don\u2019t want it to store data.","title":"CRUSH Weight"},{"location":"linux/SES/linux_ses_memo/#the-monitors-cluster-map-contains","text":"Monitor Map Unique Cluster ID, details of each Mon node, current epoch, date/time of last change OSD Map Contains the cluster fsid, when the map was created and last modified, a list of pools, replica sizes, PG numbers, a list of OSDs and their status PG Map Contains the PG version, its time stamp, the last OSD map epoch, the full ratios, and details on each placement group such as the PG ID, the Up Set, the Acting Set, the state of the PG (e.g., active + clean), and data usage statistics for each pool MDS Map Contains the current MDS map epoch, references to pool(s) for storing metadata, list of MDS servers, and which metadata servers are up and in CRUSH Map Contains a list of storage devices, the failure domain hierarchy (e.g., device, host, rack, row, room, etc.), and rules for traversing the hierarchy when storing data","title":"The Monitor\u2019s Cluster Map contains"},{"location":"linux/SES/linux_ses_memo/#crush-hierarchy","text":"The CRUSH Map includes details of physical & network infrastructure The CRUSH Map hierarchy is defined by a storage architect The default hierarchical list of infrastructure elements: (Hierarchy of CRUSH buckets) OSD host chassis \u5200\u7247\u673a\u7bb1 rack \u673a\u67b6 row pdu \u7535\u6e90\u5206\u914d\u5355\u5143 pod \u6027\u80fd\u4f18\u5316\u7684\u6570\u636e\u4e2d\u5fc3(Performance Optimize Datacenter)\uff0c\u57fa\u4e8e\u6807\u51c6\u5316\u8bbe\u65bd\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u6bcf\u4e2aPOD\u5185IT\u90e8\u5206\u5305\u542b\u76845000\u53f0\u670d\u52a1\u5668\uff0c\u5206\u5c5e\u5230200\u4e2a\u673a\u67b6\uff0c\u5982\u679c\u4ee5\u6bcf\u53f0\u670d\u52a1\u5668400W\u529f\u7387\u8ba1\u7b97\u7684\u8bdd\uff0c\u6bcf\u4e2a\u673a\u67dc\u9700\u898110KW\u7684\u4f9b\u7535\uff0c\u5373\u6bcf\u4e2aPOD\u7684IT\u8d1f\u8f7d\u5bb9\u91cf\u662f2MW\u3002 room datacenter region root CRUSH is the algorithm and calculation for distributing data through the cluster. CRUSH Map obviously plays a part in how those CRUSH calculations work.","title":"CRUSH Hierarchy"},{"location":"linux/SES/linux_ses_memo/#crush-map-sections-six-main-sections","text":"tunables: adjustments to legacy behavior devices: The list of OSDs (usually no customization needed) \u25cb \"device class\" is meaningful; useful in relation to creating/using CRUSH rulesets \u25cb Standard \"device class\" values are \"hdd.\", \"ssd.\", and \"nvme.\" \u25cb Example: device 7 osd.7 types: types of buckets (usually no customization needed) buckets: the most functional, customizable aspect of the Map \u25cb A bucket typically represents a physical location in the cluster, has a \u201ctype\u201d \u25cb Nodes (containers such as hosts) and leaves (storage devices such as OSDs) rules: define policies of how data should be distributed \u25cb The behind-the-scenes rules that CRUSH follows for data placement \u25cb IMPORTANT: this is NOT the same as the \"ruleset\". In fact, a ruleset is the combined set of all of these six Map sections. choose_args (optional): Rarely used exceptional settings to adjust weights From the documentation: \"choose_args are alternative weights associated with the hierarchy that have been adjusted to optimize data placement. A single choose_args map can be used for the entire cluster, or one can be created for each individual pool.\"","title":"CRUSH Map Sections (Six main sections)"},{"location":"linux/SES/linux_ses_memo/#erasure-coding","text":"In information theory : an erasure code is a forward error correction (FEC, \u524d\u5411\u7ea0\u9519) code for the binary erasure channel, which transforms a message of k symbols into a longer message (code word) with n symbols such that the original message can be recovered from a subset of the n symbols. The fraction r = k/n is called the code rate The fraction k\u2019/k, where k\u2019 denotes the number of symbols required for recovery, is called reception efficiency Another (easier) way of describing EC: It\u2019s like RAID in Clustered Storage","title":"Erasure Coding"},{"location":"linux/SES/linux_ses_memo/#erasure-coding-in-ses","text":"The default resilience strategy in SES is simple replication * SES Simple replication has overheads, size=3 means 3 times the storage requirements Simplistic EC details: k = number of \u201cdata\u201d chunks, split across \u201ck\u201d number of OSDs m = number of \u201cparity\u201d chunks, split across \u201cm\u201d number of OSDs Ceph calls these \u201ccoding chunks\u201d r (size) = k + m admin:~ # ceph osd crush rule ls replicated_rule","title":"Erasure Coding in SES"},{"location":"linux/SES/linux_ses_memo/#replication-vs-erasure-code","text":"Replication (default): Use Case: active data Simple and fast Uses more disk space Erasure coding: Use Case: archive data, more static data Calculates recovery data (needs more CPU power) Definable redundancy level Example: K data chunks = 2 , M code chunks = 1 Similar to a replication size of 2 But with only 50% more raw storage consumed Example: for 1GB of effective storage replication pool of size of 2 needs 2GB raw storage erasure coded pool with k=2/m=1 only requires 1.5GB raw storage","title":"Replication vs Erasure Code"},{"location":"linux/SES/linux_ses_memo/#ec-overwrites","text":"Historically, EC only works properly with Objects EC only allowed appends; overwrites were not allowed Works perfectly for objects in buckets but doesn\u2019t work well with Block or CephFS With recent releases of SES, EC can work well with Block and CephFS Facilitated by \u201cEC Overwrites\u201d feature Store data in an EC Pool, and store object metadata in a Replicated Pool Requires a little extra work when defining pools, but worth it ceph osd pool set allow_ec_overwrites true","title":"EC Overwrites"},{"location":"linux/SES/linux_ses_memo/#ec-profiles","text":"Using Erasure Coding, each Pool is assigned an EC Profile Multiple pools can share a single Profile The profile is just a definition Each Profile has multiple settings The common required settings for all Profiles are K, M EC Profiles must be created before EC Pools can be created Created from the Dashboard or CLI Once an EC Profile is created, you can create a CRUSH Ruleset based on the EC profile Once a pool is created, its EC Profile properties cannot be changed Main profile parameters K: M: stripe_unit - allows you to adjust the size of the data chunk Default size is 4K stripe_unit : size of data striped across devices; default 4K This variable can also be set in the master configuration (osd_erasure_code_stripe_unit) EC plugins - choose your favorite EC algorithm via a plugin jerasure/gf-complete (default, free, open, and very fast) (www.jerasure.org) ISA (Intel library; optimized for modern Intel processors) (only runs on Intel processors) LRC (\u201cLocally Repairable Code\u201d; layers over existing plugins) SHEC (\u201cShingled EC\u201d; trades extra storage for recovery efficiency) CLAY (\u201cCoupled LAYer\u201d; good for reduced network traffic)","title":"EC Profiles"},{"location":"linux/SES/linux_ses_memo/#creating-erasure-code-profiles-and-pools","text":"Syntax: ceph osd erasure-code-profile OPTIONS Option Description get - view details of an existing EC profile set - set a profile (create a profile), requires k and m values, with optional values such as ruleset, plugin. Once you create a profile, you can\u2019t change it. ceph osd erasure-code-profile set <name> k=<int> m=<int> [plugin=<plugin>] [stripe_unit=<string>] ls - list profiles rm - Remove an EC profile ceph osd erasure-code-profile rm <name> Common example (below) The default profile \u2012 2+1=3; data is written over 3 OSDs \u2012 Two data chunks \u2012 One code (parity) chunk \u2012 Uses jerasure plugin with standard Reed/Solomon (reed_sol_van) technique Setting a Custom EC Profile Option: \u2012 Profile name \u2012 K : number of stripes required \u2012 M : number of failed units Example: ceph osd erasure-code-profile set example-profile k=8 m=2 ruleset-failure-domain=host ruleset-failure-domain = crush bucket level for failure admin:/etc/ceph # ceph osd erasure-code-profile \\ set common_profile \\ k=4 \\ m=2 \\ plugin=jerasure \\ technique=reed_sol_van \\ stripe_unit=4K \\ crush-root=default \\ crush-failure-domain=rackcrush-device-class=ssd admin:/etc/ceph # ceph osd erasure-code-profile ls default admin:~ # ceph osd erasure-code-profile get default k=2 m=1 plugin=jerasure technique=reed_sol_van Pools Pools are at the heart of Storage Pools are tied to OSDs Display a list of existing pools: ceph osd pool ls or ceph osd lspools View the statistics and characteristics of pools: ceph osd pool stats ceph osd pool stats <poolname> ceph osd pool get <poolname> <attrib> Show usage and related details of existing pools: rados df or ceph df or ceph df detail All storage revolves around Pools Each pool must be dedicated to a purpose: Object, Block, File Must specify # of Placement Groups and PG Placements Must specify whether using Replication or EC Must specify a CRUSH ruleset Create a Replicated Pool Syntax: ceph osd pool create <poolname> <pg_num> <pgp_num> replicated <crush-rule-name> = number of placement groups for the pool = number of PGs for placement; routinely will be the same as pg_num Always a power of 2 Don\u2019t make the number too small; don\u2019t err on the high side, either Practices For a new pool, the pgp_num will generally (likley) just be the same as the pg_num When increasing the PGs in a pool, you may want to retain the smaller pgp_num to minimize rebalancing, and increase pgp_num later when rebalancing is more convenient If decreasing the PGs in a pool, the pgp_num is adjusted automatically Create an EC Pool (using an EC Profile) Syntax: ceph osd pool create <poolname> <pg_num> <pgp_num> erasure <erasure-code-profile> <crush-rule-name> Example: ceph osd pool create EC-pool 128 128 erasure my-ec-profile Pools \u2013 Application Assignment Each Pool must have a stated purpose; application This defines which capabilities the Pool must support The applications are: Block (rbd), Object (rgw), and File (cephfs) There are subtypes of cephfs: i.e. cephfs:data, cephfs:metadata Application assignment happens after creating a pool It\u2019s effortless (and required) to assign an application on a new pool ceph osd pool application enable <poolname> <application> Changing application assignment after a pool is in use is \u201chard\u201d. Not recommended, only to be done as an expert Pools \u2013 Quotas One of the more desirable features of SDS is to set a maximum usage of a Pool - Quotas Prevent the over-use of a pool Set quotas based on number of objects or number of bytes ceph osd pool set-quota <poolname> max_objects <integer> ceph osd pool set-quota <poolname> max_bytes <integer> Show quota settings ceph osd pool get-quota To remove a quota, set the existing quota setting to 0 There are also application-level quotas For rgw and cephfs (not rbd; images are already limited in size) Pool Quotas vs. Application Quotas. When a pool quota nears its limit, the HEALTH mechanisms will display a \u201cPOOL_NEAR_FULL\u201d warning to the storage administrator. When the quota limit has been exceeded, the HEALTH mechanisms will display a \u201cPOOL_FULL\u201d warning to the storage administrator. Applications (clients) don\u2019t always handle the quotas cleanly. In most cases, once the Pool Quota is exceeded, the application will simply stop writing to the pool, and error messages and behavior at the application are inconsistent (if there are any messages at all). Pools \u2013 Snapshots Take (make) a snapshot of an existing pool ceph osd pool mksnap <poolname> <snapname> Remove a snapshot of a pool ceph osd pool rmsnap <poolname> <snapname> List pool snapshots rados -p <poolname> lssnap Rollback the pool to an earlier snapshot rados -p <poolname> rollback <snapname> Images and cephfs have their own snapshot facilities. Object and Bucket snapshotting features related to rgw don\u2019t exist. Pools Snapshots versus App Snapshots The two different snapshot features cannot be used at the same time on a pool Either Pool Snapshots, or Application Snapshots; not both. (snap_mode = pool versus snap_mode = selfmanaged) Once you commit to pool snapshots for an RBD pool, you can\u2019t change to using RBD snapshots Pros and Cons of each, depending on your Use Case admin:~ # ceph osd pool ls detail -f json-pretty | grep snap_mode \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\", \"snap_mode\": \"selfmanaged\",","title":"Creating Erasure Code Profiles and Pools"},{"location":"linux/SES/linux_ses_memo/#bluestore","text":"BlueStore is the default storage backend in SES Highlighted features: compressing, no double-writes, faster checksums Ceph FileStore Model It is not ideal for a specialized purpose like a highly scalable distributed storage system. Only recommend that XFS be used. Both btrfs and ext4 have known bugs. The FileStore model uses cache from the filesystem (XFS). Memory for cache is managed by filesystem kernel module. Ceph BlueStore Model BlueStore consumes raw block devices. Metadata management with RocksDB. BlueStore employs RocksDB\u2019s key/value database in order to manage internal metadata, such as the mapping from object names to block locations on disk. Full data and metadata checksumming. By default all data and metadata written to BlueStore is protected by one or more checksums. A small specialized filesystem called BlueFS. This provides just enough of a filesystem to allow RocksDB to store its \"key/value files\" to share metadata across all the raw device(s) No data or metadata will be read from disk or returned to the user without being verified. Multi-device metadata tiering. BlueStore allows its internal journal (write-ahead log) to be written to a separate, highspeed device (like an SSD, NVMe, or NVDIMM) to increased performance. Efficient copy-on-write. RBD and CephFS snapshots rely on a copy-on-write clone mechanism that is implemented efficiently in BlueStore. BlueStore is a userspace model that provides its own memory management and cache. No need to clear the storage device cache OSDs help facilitate the performance of caching Default: cache the reads, don\u2019t cache the writes RocksDB\uff1a rocksdb\u662ffacebook\u57fa\u4e8eleveldb\u5f00\u53d1\u7684\u4e00\u6b3ekv\u6570\u636e\u5e93\uff0cBlueStore\u5c06\u5143\u6570\u636e\u5168\u90e8\u5b58\u653e\u81f3RocksDB\u4e2d\uff0c\u8fd9\u4e9b\u5143\u6570\u636e\u5305\u62ec\u5b58\u50a8\u9884\u5199\u5f0f\u65e5\u5fd7\u3001\u6570\u636e\u5bf9\u8c61\u5143\u6570\u636e\u3001Ceph\u7684omap\u6570\u636e\u4fe1\u606f\u3001\u4ee5\u53ca\u5206\u914d\u5668\u7684\u5143\u6570\u636e \u3002 BlueRocksEnv\uff1a \u662fRocksDB\u4e0eBlueFS\u4ea4\u4e92\u7684\u63a5\u53e3\uff1bRocksDB\u63d0\u4f9b\u4e86\u6587\u4ef6\u64cd\u4f5c\u7684\u63a5\u53e3EnvWrapper\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f\u5b9e\u73b0\u8be5\u63a5\u53e3\u6765\u81ea\u5b9a\u4e49\u5e95\u5c42\u7684\u8bfb\u5199\u64cd\u4f5c\uff0cBlueRocksEnv\u5c31\u662f\u7ee7\u627f\u81eaEnvWrapper\u5b9e\u73b0\u5bf9BlueFS\u7684\u8bfb\u5199\u3002 BlueFS\uff1a BlueFS\u662fBlueStore\u9488\u5bf9RocksDB\u5f00\u53d1\u7684\u8f7b\u91cf\u7ea7\u6587\u4ef6\u7cfb\u7edf\uff0c\u7528\u4e8e\u5b58\u653eRocksDB\u4ea7\u751f\u7684.sst\u548c.log\u7b49\u6587\u4ef6\u3002 BlockDecive\uff1a BlueStore\u629b\u5f03\u4e86\u4f20\u7edf\u7684ext4\u3001xfs\u6587\u4ef6\u7cfb\u7edf\uff0c\u4f7f\u7528\u76f4\u63a5\u7ba1\u7406\u88f8\u76d8\u7684\u65b9\u5f0f\uff1b BlueStore\u652f\u6301\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u8bbe\u5907\uff0c\u5728\u903b\u8f91\u4e0aBlueStore\u5c06\u5b58\u50a8\u7a7a\u95f4\u5212\u5206\u4e3a\u4e09\u5c42\uff1a\u6162\u901f\uff08Slow\uff09\u7a7a\u95f4\u3001\u9ad8\u901f\uff08DB\uff09\u7a7a\u95f4\u3001\u8d85\u9ad8\u901f\uff08WAL\uff09\u7a7a\u95f4\uff0c\u4e0d\u540c\u7684\u7a7a\u95f4\u53ef\u4ee5\u6307\u5b9a\u4f7f\u7528\u4e0d\u540c\u7684\u8bbe\u5907\u7c7b\u578b\uff0c\u5f53\u7136\u4e5f\u53ef\u4f7f\u7528\u540c\u4e00\u5757\u8bbe\u5907\u3002 Allocator\uff1a\u8d1f\u8d23\u88f8\u8bbe\u5907\u7684\u7a7a\u95f4\u7ba1\u7406\uff0c\u53ea\u5728\u5185\u5b58\u505a\u6807\u8bb0\uff0c\u76ee\u524d\u652f\u6301StupidAllocator\u548cBitmapAllocator\u4e24\u79cd\u5206\u914d\u5668,Stupid\u57fa\u4e8eextent\u7684\u65b9\u5f0f\u5b9e\u73b0 Ceph BlueStore with Mixed Devices","title":"BlueStore"},{"location":"linux/SES/linux_ses_memo/#bluestore-cache-parameters","text":"Under most circumstances, autotune is best bluestore_cache_autotune Description: Automatically tune the ratios assigned to different bluestore caches while respecting minimum values Type: Boolean Required: Yes Default: True (enabled) Related settings: bluestore_cache_autotune_chunk_size, bluestore_cache_autotune_interval, and others bluestore_cache_size Description: The amount of memory BlueStore will use for its cache. If zero, bluestore_cache_size_hdd or bluestore_cache_size_ssd will be used instead. Type: Integer Required: Yes Default: 0 bluestore_cache_size_hdd Description: The default amount of memory BlueStore will use for its cache when backed by an HDD Type: Integer Required: Yes Default: 1 * 1024 * 1024 * 1024 (1 GB) bluestore_cache_size_ssd Description: The default amount of memory BlueStore will use for its cache when backed by an SSD. Type: Integer Required: Yes Default: 3 * 1024 * 1024 * 1024 (3 GB) bluestore_cache_meta_ratio Description: The ratio of cache devoted to metadata. Type: Floating point Default: .01 bluestore_cache_kv_ratio Description: The ratio of cache devoted to key/value data (rocksdb). Type : Floating point Default: .99 bluestore_cache_kv_max Description : The maximum amount of cache devoted to key/value data (rocksdb). Type : Unsigned Integer Default : 512 * 1024*1024 (512 MB)","title":"BlueStore Cache Parameters"},{"location":"linux/SES/linux_ses_memo/#bluestore-device-types","text":"BlueStore has three types of roles for devices: The DATA role: Required: main device (block symlink) stores all object data. If no other types: \u201cdata\u201d device serves all the other roles The DB role: Optional: DB device (block.db symlink) stores metadata in RocksDB Whatever doesn\u2019t fit will spill back onto the \u201cdata\u201d device The Write Ahead Log (WAL/Journal) role: Optional: WAL device (block.wal symlink) stores the internal journal Can combine all 3 roles into one physical device Or combine DB/WAL onto a single device with the DATA device separate Or all three on seperate devices","title":"BlueStore Device Types"},{"location":"linux/SES/linux_ses_memo/#bluestore-configuration-recommendations","text":"Devote DB and WAL to SSD or NVMe Allocate 64 GB to the RocksDB Allocate 4-6 GB to the WAL Assign the \u201cdata\u201d role to the slower (HDD) devices If combining WAL/DB on one device, use a single partition for both You can use a single SSD/NVMe to store multiple journals","title":"BlueStore Configuration Recommendations"},{"location":"linux/SES/linux_ses_memo/#architecture-overview-of-object-block-filesystem-access","text":"","title":"Architecture Overview of Object, Block, Filesystem Access"},{"location":"linux/SES/linux_ses_memo/#object-storage_1","text":"The state of the art of distributed storage Object storage is the Cloud Storage mechanism of choice Unstructured, to better accommodate large files and large quantities of files Ideal for large media files, like streaming videos, audio Scales really well, large capacities Ceph provides access to the storage via all three major data access methods: Block, Object, and File. For the storage backend, Object Storage is ideal","title":"Object Storage"},{"location":"linux/SES/linux_ses_memo/#block-storage","text":"Traditional Block Storage: Volumes as a collection of blocks Blocks can be of various sizes, but all the same within a volume Typically a filesystem is installed on top of the volume Hard Drives, CDs, USB sticks, etc The standard disk device mechanism for Unix, Linux, Windows, etc. Ceph presents RADOS as block device (RBD = RADOS Block Device) Ceph calls these block devices \u201cimages\u201d Provides clients with access like a \u201cdisk drive\u201d KVM/QEMU; libvirt; or remote Linux system A native Windows client that can access the Block storage of Ceph directly is in progress","title":"Block Storage"},{"location":"linux/SES/linux_ses_memo/#rados-block-device-rbd","text":"RBD is the RADOS Block Device A specific RBD instance in the cluster is called an \u201cimage\u201d RBD images can be accessed by OSs other than linux librbd provides interface for gateways like iSCSI RBD allows the client to decide what to do with the storage Filesystem type; raw disk, such as for a DB; etc RBD images can accommodate 16Eb file system sizes No matter the size, the storage is distributed durably throughout the cluster Data is striped across the RADOS cluster in object sized chunks 4MB default Provides high performance and durability Notable Benefits Ability to mount with Linux or QEMU KVM clients Thinly provisioned Resizable images Image import/export Image copy or rename Read-only snapshots Revert to snapshots Copy on Write clones Useful for standing up lots of virtual machines with same base configuration High performance due to striping across cluster nodes RBD image definition: Defined storage area presented as a block device to a client RBD Storage","title":"RADOS Block Device (RBD)"},{"location":"linux/SES/linux_ses_memo/#file-storage","text":"POSIX Filesystem via CephFS File access is a significant use case Home directories Historical comfort with files and directories Ease of managing \u201csmall\u201d stuff broadly, in a distributed system A Use Case that\u2019s growing in popularity: HPC CephFS is fast, scalable, and flexible Fits into many existing paradigms, rather seamlessly In particular: NFS, Samba/CIFS But even better: extending Linux filesystems Requires Metadata Service (MDS) for POSIX capabilities SUSE does NOT support any FUSE clients.","title":"File Storage"},{"location":"linux/SES/linux_ses_memo/#ceph-users-and-authentication","text":"Ceph Users are generally applications; applications that use the storage cluster The must common user is Admin A ceph admin user and credentials must exist Additional users and associated credentials are useful Each user must have credentials to access the storage cluster The most fundamental form of credentials in Ceph is keys Ceph Users and Keys The admin user has rights to all Ceph resources. Other users can be setup to have a subset of rights There are basically two types of Users (Actors): An individual (a person) An application (like a gateway, or some other kind of system) Most users are of the type client, and are represented as a dotted string, such as: client.admin, or client.steve, or client.swift The root linux user on the Admin node is effectively the Admin Ceph user, since the root user has all privileges to all filesystem objects on the Adminnode, including the ceph.client.admin.keyring. The root user on any of the nodes in the cluster can \u201cimpersonate\u201d all of the Ceph clients. Linux user accounts do not have any affect on the Ceph Users as managed in the dashboard. Take care to keep backups of the /etc/ceph/ directory structure, so that you don\u2019t lose these keys/keyrings. Each user must have a key/keyring, for example: /etc/ceph/ceph.client.admin.keyring on the Admin node /etc/ceph/ceph.client.storage.keyring on a storage node admin:/etc/ceph # cat ceph.client.admin.keyring [client.admin] key = AQD6pHpfAAAAABAAHJvkvLhOKZyQxm9lgnR5Qg== caps mds = \"allow *\" caps mon = \"allow *\" caps osd = \"allow *\" caps mgr = \"allow *\" data1:/etc/ceph # cat ceph.client.storage.keyring [client.storage] key = AQD8pHpfAAAAABAAHecCBgBsLIyPrJf+27eXUQ== caps mon = \"allow rw\" Ceph Keys and Keyrings A keyring contains one or more keys Each user can have its own keyring A keyring can contain multiple keys Different clients and users must have their own key, but multiple keys can be joined together in a single keyring Normally a key will be contained in a keyring Core Ceph will only recognize and use keys from keyrings Stand-alone keys are useful for other tools, like clients Ceph Authentication List The Admin node (and client.admin) can list all Users ceph auth list Create a Ceph User A typical user will have read rights to MONs, and read/write rights to a pool (osd) ceph auth get/add/get-or-create xxxxxx Create a User with ceph-authtool Create a keyring ceph-authtool -C /etc/ceph/ceph.client.richard.keyring Create a key, and place it on the keyring ceph-authtool --gen-key -n client.richard --cap osd 'allow rw pool=data' --cap mon 'allow r' /etc/ceph/ceph.client.richard.keyring Now officially tell the cluster about the key (add user to the key) ceph auth add client.richard -i /etc/ceph/ceph.client.richard.keyring Authentication with cephx The mechanism for passing keys around is cephx Authentication for users and daemons Does not provide data encryption, only authentication with keys cephx simply ensures the authenticity of actors So that no man-in-the-middle attacks can occur Other authentication mechanisms are theoretically possible Attempts to integrate LDAP and Kerberos have been made \u2026 but they have not come to full fruition yet","title":"Ceph Users and Authentication"},{"location":"linux/SES/linux_ses_memo/#ceph-configuration","text":"Historically, the Ceph configuration was kept only in a file on the Admin node: /etc/ceph/ceph.conf, and sync'd to MONs and Storage Nodes SES DeepSea manages the ceph.conf file. Don\u2019t edit it directly; use Salt and DeepSea With Ceph Nautilus, most configuration held as objects in the Monitors using Dashboard or CLI for operation Ceph Configuration Stored in the MONs The MONs keep a configuration database Show all the configuration keys: admin:/etc/ceph # ceph config ls |less Show the configuration settings that have been customized. The dumped output also indicates an EXPERTISE LEVEL The keys also have a \u201cwho\u201d attribute. In below case, \"osd.*\" represents the \"who\", which is getting the general setting for all OSDs Ceph Configuration Settings Show configuration settings that have been customized: admin:/etc/ceph # ceph config dump WHO MASK LEVEL OPTION VALUE RO mgr advanced mgr/dashboard/GRAFANA_API_URL https://mon1.pvgl.sap.corp:3000 * mgr advanced mgr/dashboard/RGW_API_ACCESS_KEY M11I3JGQHAQM94CS910K * mgr advanced mgr/dashboard/RGW_API_HOST mon3.pvgl.sap.corp * mgr advanced mgr/dashboard/RGW_API_PORT 80 * mgr advanced mgr/dashboard/RGW_API_SECRET_KEY YWyRc3mayEPiOEUzQ2o76KePSKmVKN4fIWxgqTt6 * mgr advanced mgr/dashboard/RGW_API_USER_ID admin * mgr advanced mgr/dashboard/ssl_server_port 8443 admin:/etc/ceph # ceph config get osd.* osd_max_object_size 134217728 admin:/etc/ceph # ceph config show osd.0 \u2026\u2026 admin:/etc/ceph # ceph config show osd.11 (4 data nodes, 3 osds in each node) \u25cb Each of the configuration settings have default values ceph config show-with-defaults osd.2 | less \u25cb Ceph keeps a log of configuration changes admin:/etc/ceph # ceph config log --- 8 --- 2020-10-05 14:31:51.425902 --- + mgr/mgr/dashboard/RGW_API_USER_ID = admin --- 7 --- 2020-10-05 14:31:50.418622 --- + mgr/mgr/dashboard/RGW_API_HOST = mon3.pvgl.sap.corp --- 6 --- 2020-10-05 14:31:49.398448 --- + mgr/mgr/dashboard/RGW_API_PORT = 80 --- 5 --- 2020-10-05 14:31:48.403965 --- + mgr/mgr/dashboard/RGW_API_SECRET_KEY = YWyRc3mayEPiOEUzQ2o76KePSKmVKN4fIWxgqTt6 --- 4 --- 2020-10-05 14:31:46.905701 --- + mgr/mgr/dashboard/RGW_API_ACCESS_KEY = M11I3JGQHAQM94CS910K --- 3 --- 2020-10-05 13:15:29.530355 --- + mgr/mgr/dashboard/GRAFANA_API_URL = https://mon1.pvgl.sap.corp:3000 --- 2 --- 2020-10-05 13:15:14.349623 --- + mgr/mgr/dashboard/ssl_server_port = 8443 --- 1 --- 2020-10-05 13:13:55.637896 ---","title":"Ceph Configuration"},{"location":"linux/SES/linux_ses_memo/#health","text":"Show status admin:/etc/ceph # ceph status cluster: id: 343ee7d3-232f-4c71-8216-1edbc55ac6e0 health: HEALTH_OK services: mon: 3 daemons, quorum mon1,mon2,mon3 (age 6w) mgr: mon1(active, since 13d) mds: cephfs:1 {0=mon3=up:active} 2 up:standby osd: 12 osds: 12 up (since 9w), 12 in (since 9w) rgw: 1 daemon active (mon3) task status: scrub status: mds.mon3: idle data: pools: 7 pools, 208 pgs objects: 246 objects, 4.7 KiB usage: 14 GiB used, 82 GiB / 96 GiB avail pgs: 208 active+clean io: client: 11 KiB/s rd, 0 B/s wr, 11 op/s rd, 6 op/s wr admin:/etc/ceph # ceph health HEALTH_OK admin:/etc/ceph # ceph health detail HEALTH_OK admin:/etc/ceph # ceph mon stat e1: 3 mons at {mon1=[v2:10.58.121.186:3300/0,v1:10.58.121.186:6789/0],mon2=[v2:10.58.121.187:3300/0,v1:10.58.121.187:6789/0],mon3=[v2:10.58.121.188:3300/0v1:10.58.121.188:6789/0]}, election epoch 22, leader 0 mon1, quorum 0,1,2 mon1,mon2,mon3 admin:/etc/ceph # ceph osd stat 12 osds: 12 up (since 9w), 12 in (since 9w); epoch: e1375 admin:/etc/ceph # ceph pg stat 208 pgs: 208 active+clean; 4.7 KiB data, 2.0 GiB used, 82 GiB / 96 GiB avail; 1.2 KiB/s rd, 1 op/s Watch status -w, --watch : Watch live cluster changes --watch-debug : Watch debug events --watch-info : Watch info events --watch-sec : Watch security events --watch-warn : Watch warning events --watch-error : Watch error","title":"Health"},{"location":"linux/SES/linux_ses_memo/#scrub-and-deep-scrub","text":"\"Scrub\" is the process of doing a data consistency check Basically like running fsck on the cluster In Replicas: compare object metadata among replicas In EC: verify \u201ccode\u201d chunks Manual scrubbing can be done per OSD or per PG. \"osd scrub\" is just a collaborative wrapper of \"pg scrub\". ceph osd scrub osd.11 ceph pg scrub 3.33 \"scrub\" is a light process, daily Checks object size and attributes \"deep-scrub\" is a more thorough process, weekly Reads all data and checks the checksums Scrub \u2013 Manual vs Automatic You can let Ceph just do the default Run scrub daily, run deep-scrub weekly Ceph pays attention to usage and backs off when necessary You can change the defaults for both scrub and deepscrub, examples: osd_scrub_begin_week_day=6 (Saturday) osd_scrub_end_week_day=7 (Sunday) You can manually run scrubbings at any time if you suspect it\u2019s wanted or needed Manual scrubbings are not common Adjustments to Scrub Settings For most circumstances the default behavior of Scrub is adequate See current Scrub configuration settings: ceph config ls | grep osd_scrub ceph config ls | grep osd_deep_scrub ceph config get osd.* osd_scrub_begin_hour Change the settings immediately in the MON DB ceph config set osd.* osd_scrub_begin_hour 23 ceph config set osd.* osd_scrub_end_hour 5 Adjust Settings in ceph.conf with DeepSea To permanently change settings in ceph.conf This is the \u201cold\u201d way, but is still valid Remember that ceph.conf is controlled by DeepSea Add changes to /srv/salt/ceph/configuration/files/ceph.conf.d/global.conf Run the following DeepSea (Salt) commands: salt admin* state.apply ceph.configuration.create salt \\* state.apply ceph.configuration Wait for services/servers to be restarted, or tell Ceph to assimilate the ceph.conf settings now ceph config assimilate-conf -i /etc/ceph/ceph.conf","title":"Scrub and Deep-Scrub"},{"location":"linux/SES/linux_ses_memo/#repair","text":"Problems Found by Scrubbing * If data (in an OSD or PG) becomes inconsistent, it will need to be repaired. You can configure scrubbing to automatically repair errors * osd_scrub_auto_repair=True * osd_scrub_auto_repair_num_errors=5 * Manually repair when appropriate * ceph osd repair osd.11 * ceph pg repair 3.33","title":"Repair"},{"location":"linux/SES/linux_ses_memo/#ceph-manager-modules","text":"Manager Modules help to extend the capabilities of Ceph List of Modules Supported in SES Balancer (always on) rash (always on) Dashboard DeepSea iostat Orchestrator (always on) progress (always on, tech preview) Prometheus RESTful rbd_support (always on) status (always on) telemetry volume (always on) Zabbix (plugin only, not the required agent) Enabling Manager Modules Show a list of Manager Modules ceph mgr module ls | less The output is quite long; best to pipe it through less The top of the output shows those modules that have been enabled The exhaustive output also displays the \u201cAPI\u201d of each module Manager modules are quite easy to enable and disable ceph mgr module enable <modulename> ceph mgr module disable <modulename> Show list of services that are active from the Modules ceph mgr services Module Capabilities Each module has its own settings, configuration Once the module is enabled, the ceph command accepts commands for the module No need to run the command as ceph mgr ... Examples: ceph crash stat ceph telemetry show Setting parameters (key/value pairs) of Modules ceph config set mgr mgr/telemetry/contact 'JD <john@example.net>' ceph config set mgr mgr/telemetry/description 'Training Cluster'","title":"Ceph Manager Modules"},{"location":"linux/SES/linux_ses_memo/#ceph-tell","text":"Tell commands are actually directed to the target service by way of the MONs ceph tell is a tool to tell a ceph daemon to perform a task \u2026 change a setting \u2026 execute a subroutine The target of ceph tell can be a single daemon or a collection of daemons All MONs: ceph tell mon.* injectargs '--mon-pg-warn-max-per-osd 4096' A specific OSD: ceph tell osd.9 bench ceph tell is the most common way to change logging for troubleshooting ceph tell <type>.<id> injectargs '--debug-<subsys> <int>' ceph tell osd.7 injectargs '--debug-osd 20' ceph tell osd.7 config set debug_osd 20 A \u201c/\u201d allows you to change both the file log and memory log settings simultaneously ceph tell mon.3 injectargs '--debug-mon 0/10' (The first is the file parameter, the second is the memory parameter) Since logging can fill space, important to restore settings after investigating ceph tell mon.3 injectargs '--debug-mon 1/5' ceph tell sends its instructions via the Monitors. So what if the MONs are having problems? To avoid running commands through the MONs, go directly to thenode running the daemon ssh storage1 ceph daemon osd.29 config show ceph daemon osd.29 config set debug_osd 0/20 Use with great care","title":"Ceph Tell"},{"location":"linux/SES/linux_ses_memo/#ceph-dashboard_1","text":"What's Ceph Dashboard SES WEB-based Management Interface A Ceph MGR module, built-in to Ceph The open source \"port\" of openATTIC to Ceph. Technically it\u2019s not a port of openATTIC. SUSE and Ceph Community worked on implementing the openATTIC capabilities directly within Ceph Role-based and Multi-User Management of the SES cluster Create, manage, and monitor Pools, RBDs Manage users, access keys, quotas and buckets of RGW Manage NFS exports, iSCSI targets and portals, CephFS View cluster nodes/roles, monitor performance metrics Manage Ceph settings/configuration Reduces the need to understand complex Ceph commands The dashboard is stateless, it will reflect any changes to the Ceph cluster, Highlighted Enterprise Behavior via Ceph Dashboard Uses SSL/TLS By default will use a CA and certificate created by DeepSea or provide your own CA and certificate Can run without SSL/TLS (not recommended) Multi-User and Role Management Variety of mappings, i.e.: read, create, update, delete Single Sign-On, complying with SAML 2.0 Single Sign-On, complying with SAML 2.0 Auditing on the backend, to monitor specific user activity Internationalization (I18N), with a variety of language translations Ceph Dashboard Architecture Backend is based on CherryPy framework (CherryPy is a Minimalist Python Web Framework) Frontend WebUI is based on Angular/TypeScript A custom REST API Monitoring facilitated by Prometheus Visualization of data facilitated by Grafana Dependent upon DBUS, systemd, and systems\u2019 shell Dashboard as Manager Module Ceph Dashboard runs as a Manager module Runs on each MON/MGR node Really only actively available via the active MGR Runs on \u201cstandby\u201d on the standby MGR nodes Standby Dashboards will redirect to active MGR URL Dashboard automatically switches to active MGR node Helpful High Availability feature As a MGR module, enabled and configured by DeepSea Can be disabled if unwanted URL example: https://10.58.121.186:8443 Grafana and Prometheus Prometheus collects various data about the cluster Grafana represents the data as graphs Ceph Dashboard uses both to improve insight into SES Prometheus Open source event monitoring software \"Scrapes\" (collects) data from nodes/services in the cluster Real-time Time series Custom scrapers have been created for Ceph Stores scraped data in memory and on disk Presents data to other software for graphical representation Integrated nicely with Grafana Grafana The leading open source software for time series analytics \"Dashboards\" of panels, graphs, metrics, etc. \"Dashboard\" is a slightly conflicting term, but still meaningful Renders data in a graphical way collected from Prometheus Graphs are customized for use on the Ceph Dashboard Dashboard Users Always need an \u201cAdmin\u201d user for the Dashboard \u00a7 The admin keys of the root user on the \u201cAdmin\u201d node in the cluster Dashboard Users are accounts that relate only to using the Dashboard \u00a7 Not the same as Ceph CLI users and client keys; but could coincide Any person who wants to interact with the storage cluster via the Dashboard must have a user account Variety of Users established by the Admin User, and various permissions based on Admin-defined Roles User Authentication Dashboard Administrators can setup users with specific privileges The privileges and permissions are managed as \"roles\" User accounts can be created directly in the Dashboard Stored as objects in Ceph User accounts can also be tied to other authentication mechanisms: Single Sign-On Service; SAML 2.0 compliant protocol Dashboard accounts can be managed from the Dashboard or from the CLI Example: ceph dashboard ac-user-show [<username>] The Admin Dashboard User (the term \u201cadmin\u201d is used differently in different places) The Dashboard Admin User is not the same as other admins The \u201cadmin\u201d node is obviously not directly tied to any admin user The Admin Dashboard User is created at Deployment time Given a random password by DeepSea You must use the CLI to establish the admin password ceph dashboard ac-user-show admin ceph dashboard ac-user-set-password admin <password> \u25cb The SES Deployment Course has set the password to mypassword admin:~ # ceph dashboard ac-user-show [\"admin\"] admin:~ # ceph dashboard ac-user-show admin {\"username\": \"admin\", \"password\": \"$2b$12$4lC/AU7jc6midTZufj4P4.rBtVzRGf7Zy7fUbD6G9YfdfVEwkwuUy\", \"roles\": [\"administrator\"], \"name\": null \"email\":null\"lastUpdate\": 1601874928} Health from the Dashboard Cluster Status Monitors OSDs Manager Daemons Hosts Object Gateways Metadata Service iSCSI Gateways Cluster Performance from Dashboard Client IOPS Client Throughput Client Read/Write Recovery Throughput Scrub Performance Data Hosts: Overall Performance Monitors: Performance Counters OSDs: Relative Read/Write bar graphs, and Overall Performance Pools: Relative Read/Write bar graphs, and Overall Performance Block images: Overall Performance CephFS: Performance Details RGW: Overall Performance Cluster Capacity from Dashboard Capacity data: Number of Pools Raw Capacity Number of Objects (Ceph objects, not user objects from RGW) Placement Groups per OSD Placement Group Status","title":"Ceph Dashboard"},{"location":"linux/SES/linux_ses_memo/#basic-troubleshooting","text":"Ceph Logs Logs normally stored in /var/log/ceph/ No real logs on the admin node Each service has its own log on the MON, Storage and Gateway nodes Logs handled routinely by logrotate Ceph has logs that are stored to files and in memory (triggered by event or manual request) There are 21 different levels of logging: 0-20 (0 is no logging; 20 is the most verbose logging) There are many subsystems that do their own logging, and can be configured independently Most common: mon, osd, mgr, rados, rbd, mds, rgw Others: asok, auth, client, filestore, journal, monc, ms, paxos, and more There are only 3 types of daemons: osd, mon, mds Using Tell to Change Log Levels 1) Check the Dashboard and Health. Common commands ceph status ceph osd status ceph osd df ceph osd utilization ceph osd pool stats ceph osd tree ceph pg stat 2) Network Troubleshooting Always be sure that the network (and related services) are working properly Ceph depends heavily on tightly synchronized time; make sure network time services are working on each node DNS hostnames are similarly essential 3) Check the Logs Go to the node of the component implicated in HEALTH 4: Raise the DEBUG Level. Follow this simple formula: Raise the debug level (a little each time until you see the problem) Check the logs Repeat as necessary Don\u2019t forget to restore the debug level back to its normal level 5) Check the Storage Device If the problem is with an OSD or a storage device, go straight to the device: hdparm smartctl And check out the details of the combination of OSD and storage device: lsblk /var/lib/ceph/osd/ 6) Scrub (or not) Sometimes simply scrubbing an OSD or PG can cause the checksum-ing process to reveal problems At least some problems can be made more clear with the result of scrub and/or deep-scrub Even doing a scrub can kick Ceph into fixing the problem itself And don\u2019t forget ceph osd repair On the other hand, sometimes Scrub can make things worse. If you suspect Scrub is part of the problem, turn it off: ceph osd set noscrub ceph osd unset noscrub 7) Placement Groups When Placement Groups cause problems: * ceph pg dump summary * ceph pg dump pools * ceph pg dump_jason * ceph pg dump | less Followed by a strategic \u201crepair\u201d of the PG * ceph pg repair <pgid> 8) Running supportconfig YaST Support Module From CLI: supportconfig The collected data is stored in a file called /var/log/nts_<hostname>_<datetime>.txz","title":"Basic Troubleshooting"},{"location":"python/DataAnalysis/ch01/","text":"NumPy\u57fa\u7840 \u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a \u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61 \u901a\u7528\u51fd\u6570 \u9762\u5411\u6570\u7ec4\u7f16\u7a0b \u4f7f\u7528\u6570\u7ec4\u8fdb\u884c\u6587\u4ef6\u8f93\u5165\u548c\u8f93\u51fa \u7ebf\u6027\u4ee3\u6570 \u4f2a\u968f\u673a\u6570\u751f\u6210 \u793a\u4f8b\uff1a\u968f\u673a\u6f2b\u6b65 \u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61ndarry \u522b\u540d\u7ea6\u5b9a import numpy as np import pandas as pd import matplotlib.pyplot as plt \u5b89\u88c5matplotlib\u4e2d\u6587\u5b57\u4f53 \u67e5\u770b\u5b57\u4f53\u8def\u5f84 >>> import matplotlib >>> print(matplotlib.matplotlib_fname()) /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc \u4e0b\u8f7d\u4e2d\u6587\u5b57\u4f53\u3002\u7f51\u5740 https://www.fontpalace.com/font-download/SimHei/,\u5e76\u62f7\u8d1d\u5230\u4e0b\u9762\u7684\u8def\u5f84\u4e0b james@lizard:~/Downloads> cp SimHei.ttf /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/ \u67e5\u770bmatplotlib\u7684\u5b57\u4f53\u7f13\u5b58\u76ee\u5f55\u3002 >>> import matplotlib >>> print(matplotlib.get_cachedir()) /home/james/.cache/matplotlib \u5220\u9664\u8fd9\u4e2a\u76ee\u5f55 james@lizard:~> rm -rf /home/james/.cache/matplotlib \u7f16\u8f91matplotlibrc\u6587\u4ef6 /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc \uff0c\u505a\u5982\u4e0b\u4fee\u6539\u3002 \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # font.family: sans-serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u6dfb\u52a0 SimHei \uff0c\u4fee\u6539\u540e\u4e3a font.serif: SimHei, DejaVu Serif, Bitstream Vera Serif, Computer Modern Roman, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u6dfb\u52a0 SimHei \uff0c\u4fee\u6539\u540e\u4e3a font.sans-serif: SimHei, DejaVu Sans, Bitstream Vera Sans, Computer Modern Sans Serif, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u628a True \u6539\u4e3a False \uff0c\u4fee\u6539\u540e\u4e3a axes.unicode_minus: False \u8bbe\u7f6ematplotlib\u540e\u7aef\u6e32\u67d3\u5668 \u5728\u4f7f\u7528matplotlib\u8f93\u51fa\u56fe\u50cf\u65f6\uff0c\u5982\u679c\u9047\u5230\u65e0\u6cd5\u663e\u793a\u56fe\u50cf\u7684\u9519\u8bef UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure\u3002 \uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4e0b\u9762\u7684\u6b65\u9aa4\u89e3\u51b3\u3002 \u5b89\u88c5 python3-tk \u5305 james@lizard:~> sudo zypper in python3-tk \u6216\u8005\u901a\u8fc7 pip \u5b89\u88c5 tk \u5305 james@lizard:~> pip3 install tk Defaulting to user installation because normal site-packages is not writeable Collecting tk Downloading tk-0.1.0-py3-none-any.whl (3.9 kB) Installing collected packages: tk Successfully installed tk-0.1.0 \u4e00\u822c\u5b8c\u6210\u4e0a\u9762\u5b89\u88c5\u540e\uff0c\u7a0b\u5e8f\u5c31\u80fd\u81ea\u52a8\u663e\u793a\u56fe\u4e86\uff0c\u5982\u679c\u8fd8\u662f\u4e0d\u80fd\u663e\u793a\uff0c\u518d\u5c1d\u8bd5\u91cd\u65b0\u5b89\u88c5 matplotlib \u3002 pip3 ininstall matplotlib pip3 install matplotlib ndarray: N-\u7ef4\u6570\u7ec4\u5bf9\u8c61 \u4e00\u4e2andarray\u662f\u4e00\u4e2a\u901a\u7528\u7684\u591a\u7ef4\u540c\u7c7b\u6570\u636e\u5bb9\u5668\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u5305\u542b\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u5747\u4e3a \u76f8\u540c\u7c7b\u578b \uff1b \u6bcf\u4e00\u4e2a\u6570\u7ec4\u90fd\u6709\u4e00\u4e2ashape\u5c5e\u6027\uff0c\u7528\u6765\u8868\u5f81\u6570\u7ec4\u6bcf\u4e00\u7ef4\u5ea6\u7684\u6570\u91cf\uff1b \u6bcf\u4e00\u4e2a\u6570\u7ec4\u90fd\u6709\u4e00\u4e2adtype\u5c5e\u6027\uff0c\u7528\u6765\u63cf\u8ff0\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\uff1b \u4e0b\u9762\u662f\u6807\u51c6\u6570\u7ec4\u7684\u751f\u6210\u51fd\u6570 array: \u5c06\u8f93\u5165\u6570\u636e\uff08\u5217\u8868\u3001\u5143\u7ec4\u3001\u6570\u7ec4\uff0c\u5176\u4ed6\u5e8f\u5217\uff09\u8f6c\u6362\u4e3andarray\uff0c\u5982\u679c\u4e0d\u663e\u5f0f\u6307\u660e\u6570\u636e\u7c7b\u578b\uff0c\u5c06\u81ea\u52a8\u63a8\u65ad\uff1b\u9ed8\u8ba4\u590d\u5236\u6240\u6709\u7684\u8f93\u5165\u6570\u636e\u3002 asarray\uff1a\u5c06\u8f93\u5165\u8f6c\u6362\u4e3andarray\uff0c\u4f46\u5982\u679c\u8f93\u5165\u5df2\u7ecf\u662fndarray\u5219\u4e0d\u518d\u590d\u5236\u3002 arange\uff1aPython\u5185\u7f6e\u51fd\u6570range\u7684\u6570\u7ec4\u7248\uff0c\u8fd4\u56de\u4e00\u4e2a\u6570\u7ec4\u3002 \u4e0b\u9762\u662f\u7528 Numpy.random() \u4e00\u4e2a\u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\u7ec4\u7684\u4f8b\u5b50\uff0c\u6ce8\u610f data01 \u7684\u7c7b\u578b\u662f'numpy.ndarray'\u3002\u53ef\u4ee5\u5728ndarray\u7c7b\u578b\u6570\u7ec4\u4e0a\u53e0\u52a0\u4e00\u4e0b\u6570\u5b66\u64cd\u4f5c\u3002 data01 = np.random.randn(2, 3) print(type(data01)) # <class 'numpy.ndarray'> print(data01) # [[ 0.12047302 -1.13499045 -0.39311368] # [ 1.54046881 0.01254838 -3.65090952]] print(data01 * 10) # \u7ed9data\u52a0\u4e0a\u4e00\u4e2a\u6570\u5b66\u64cd\u4f5c, \u6240\u6709\u7684\u5143\u7d20\u90fd\u540c\u65f6\u4e58\u4ee5\u4e8610 # [[ 1.20473022 -11.3499045 -3.93113676] # [ 15.40468806 0.12548383 -36.50909515]] print(data01 + data01) # \u7ed9data\u52a0\u4e0a\u4e00\u4e2a\u6570\u5b66\u64cd\u4f5c, \u6570\u7ec4\u4e2d\u7684\u5bf9\u5e94\u5143\u7d20\u8fdb\u884c\u4e86\u76f8\u52a0 # [[ 0.24094604 -2.2699809 -0.78622735] # [ 3.08093761 0.02509677 -7.30181903]] print(data01.shape) # (2, 3) print(data01.dtype) # float64 \u5f53\u8868\u8fbe\u201c\u6570\u7ec4\u201d\u3001\u201cNumPy\u6570\u7ec4\u201d\u6216\u201cndarray\u201d\u65f6\uff0c\u90fd\u8868\u793a\u540c\u4e00\u4e2a\u5bf9\u8c61\uff1andarray\u5bf9\u8c61\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a data01 \u662f\u4e00\u4e2a\u5217\u8868\uff08list\uff09\u7c7b\u578b\uff0c\u901a\u8fc7 Numpy.array \u8f6c\u6362\u6210Numpy\u7684 ndarray \u7c7b\u578b\u3002 \u5728 np.array \u4e2d\uff0c\u9664\u975e\u663e\u5f0f\u5730\u6307\u5b9a\uff0c\u5982 np.array(data01, dtype=np.int8) \uff0c\u5426\u5219np.array\u4f1a\u81ea\u52a8\u63a8\u65ad\u751f\u6210\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b array01.dtype \u3002 \u4f7f\u7528 astype() \u65b9\u6cd5\u663e\u5f0f\u5730\u8f6c\u6362\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\u3002\u4f7f\u7528 astype() \u65f6\u603b\u662f\u751f\u6210\u4e00\u4e2a \u65b0\u7684\u6570\u7ec4 \uff0c\u5373\u4f7f\u4f60\u4f20\u5165\u7684dtype\u4e0e\u4e4b\u524d\u4e00\u6837\u3002 data02 \u662f\u4e00\u4e2a\u5d4c\u5957\u5217\u8868 [[1, 2, 3, 4], [5, 6, 7, 8]] \uff0c\u901a\u8fc7np.array()\u65b9\u6cd5\u8f6c\u6362\u6210\u591a\u7ef4\u6570\u7ec4\uff0c\u524d\u63d0\u662f\u6bcf\u4e2a\u5b50\u5217\u8868\u7684\u957f\u5ea6\u8981\u4e00\u81f4\u3002 data01 = [6, 7.5, 8, 0, 1] print(data01) # [6, 7.5, 8, 0, 1] print(type(data01)) # <class 'list'> array01 = np.array(data01) print(\"\u77e9\u9635\u7c7b\u578b\", type(array01)) # \u77e9\u9635\u7c7b\u578b <class 'numpy.ndarray'> print(\"\u6837\u672c\u77e9\u9635\", array01) # \u6837\u672c\u77e9\u9635 [6. 7.5 8. 0. 1. ] print(\"\u6570\u7ec4\u7ef4\u5ea6\", array01.ndim) # \u6570\u7ec4\u7ef4\u5ea6 1 print(\"\u77e9\u9635\u5f62\u72b6\", array01.shape) # \u77e9\u9635\u5f62\u72b6 (5,) \u4e00\u884c\u4e94\u5217 print(\"\u77e9\u9635\u6570\u636e\u7c7b\u578b\", array01.dtype) # float64 data02 = [[1, 2, 3, 4], [5, 6, 7, 8]] array02 = np.array(data02) print(\"\u6837\u672c\u77e9\u9635\\n\", array02) # \u6837\u672c\u77e9\u9635 # [[1 2 3 4] # [5 6 7 8]] print(\"\u6570\u7ec4\u7ef4\u5ea6\", array02.ndim) # \u6570\u7ec4\u7ef4\u5ea6 2 print(\"\u77e9\u9635\u5f62\u72b6\", array02.shape) # \u77e9\u9635\u5f62\u72b6 (2, 4) print(\"\u77e9\u9635\u6570\u636e\u7c7b\u578b\", array02.dtype) # \u77e9\u9635\u6570\u636e\u7c7b\u578b int64 print(\"\u77e9\u96350\u8f74\u5411\u6c42\u548c\", array02.sum(axis=0)) # \u77e9\u96350\u8f74\u5411\u6c42\u548c [ 6 8 10 12] print(\"\u77e9\u96351\u8f74\u5411\u6c42\u548c\", array02.sum(axis=1)) # \u77e9\u96351\u8f74\u5411\u6c42\u548c [10 26] array03 = array02.astype(np.float64) print(array03.dtype) # float64 print(array03) # [[1. 2. 3. 4.] # [5. 6. 7. 8.]] zeros() \u65b9\u6cd5\u53ef\u4ee5\u4e00\u6b21\u6027\u521b\u9020\u51680\u6570\u7ec4\u3002 print(np.zeros(10)) # [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ones() \u65b9\u6cd5\u53ef\u4ee5\u4e00\u6b21\u6027\u521b\u9020\u51681\u6570\u7ec4\u3002\u6ce8\u610f\uff0c\u4f20\u53c2shape\u662f\u4e00\u4e2a\u5143\u7ec4 (3, 5) \u3002 print(np.ones((3, 5))) # [[1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.]] empty() \u65b9\u6cd5\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u6ca1\u6709\u521d\u59cb\u5316\u6570\u503c\u7684\u6570\u7ec4\u3002\u4f46\u662f\uff0c\u4f7f\u7528np.empty\u6765\u751f\u6210\u4e00\u4e2a\u51680\u6570\u7ec4\uff0c\u5e76\u4e0d\u53ef\u9760\uff0c\u6709\u4e9b\u65f6\u5019\u5b83\u53ef\u80fd\u4f1a\u8fd4\u56de\u672a\u521d\u59cb\u5316\u7684\u5783\u573e\u6570\u503c print(np.empty((2, 3, 2))) # [[[2.30116964e-316 0.00000000e+000] # [2.10077583e-312 6.79038654e-313] # [2.22809558e-312 2.14321575e-312]] # # [[2.35541533e-312 6.79038654e-313] # [2.22809558e-312 2.14321575e-312] # [2.46151512e-312 2.41907520e-312]]] NumPy\u8f74 \u4e00\u53e5\u8bdd\u603b\u7ed3\uff1a\u5c06NumPy\u8f74\u89c6\u4e3a\u6211\u4eec\u53ef\u4ee5\u6267\u884c\u64cd\u4f5c\u7684\u65b9\u5411\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a arr_1 = np.array([[1, 1, 1], [1, 1, 1]]) arr_2 = np.array([[9, 9, 9], [9, 9, 9]]) print(arr_1) # [[1 1 1] # [1 1 1]] print(arr_2) # [[9 9 9] # [9 9 9]] \u6cbf0\u8f74\u5408\u5e76\u7684\u601d\u8def\u662f\uff0c\u4e24\u4e2a\u6570\u7ec4\u6cbf0\u8f74\u65b9\u5411\uff0c\u54110\u8f74\u201c\u584c\u7f29\u201d\uff08collapse\uff09\u3002 result = np.concatenate([arr_1, arr_2], axis=0) print(result) # [[1 1 1] # [1 1 1] # [9 9 9] # [9 9 9]] \u6cbf1\u8f74\u5408\u5e76\u7684\u601d\u8def\u662f\uff0c\u4e24\u4e2a\u6570\u7ec4\u6cbf1\u8f74\u65b9\u5411\uff0c\u54111\u8f74\u201c\u584c\u7f29\u201d result = np.concatenate([arr_1, arr_2], axis=1) print(result) # [[1 1 1 9 9 9] # [1 1 1 9 9 9]] \u6211\u4eec\u6765\u770bNumPy\u7684\u4e09\u7ef4\u6570\u7ec4\u3002 array1 = np.arange(36).reshape((3, 3, 4)) print(array1) # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] \u8fd9\u6837\u770b\u4f1a\u5bb9\u6613\u7406\u89e3\u4e00\u4e9b\uff0c0\u8f74\u67093\u884c\uff0c1\u8f74\u67093\u5217\uff0c2\u8f74\u67094\u4e2a\u5143\u7d20\uff1a [[[ 0 1 2 3], [ 4 5 6 7], [ 8 9 10 11]] [[12 13 14 15], [16 17 18 19], [20 21 22 23]] [[24 25 26 27], [28 29 30 31], [32 33 34 35]]] \u8f93\u51fa\uff1a\u8f740\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f741\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f742\u7d22\u5f15\u53f7\uff1a\u5168\u90e8 print(array1[0, 0, :]) # [0 1 2 3] \u8f93\u51fa\uff1a\u8f740\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f741\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f742\u7d22\u5f15\u53f7\uff1a1 print(array1[0, 0, 1]) # 1 NumPy\u6570\u7ec4\u7b97\u672f \u4e00\u4e2a \u6807\u91cf \u5c31\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u6570\u3002\u4e00\u4e2a\u5411\u91cf\u5c31\u662f\u4e00\u5217\u6570\uff0c\u8fd9\u4e9b\u6570\u662f\u6709\u5e8f\u6392\u5217\u7684\u3002 \u77e9\u9635\u662f\u4e8c\u7ef4\u6570\u7ec4\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u88ab\u4e24\u4e2a\u7d22\u5f15\u800c\u975e\u4e00\u4e2a\u6240\u786e\u5b9a\u3002 \u51e0\u4f55\u4ee3\u6570\u4e2d\u5b9a\u4e49\u7684 \u5f20\u91cf \u662f\u57fa\u4e8e\u5411\u91cf\u548c\u77e9\u9635\u7684\u63a8\u5e7f\uff0c\u6211\u4eec\u53ef\u4ee5 \u5c06\u6807\u91cf\u89c6\u4e3a\u96f6\u9636\u5f20\u91cf \uff0c \u77e2\u91cf \u89c6\u4e3a\u4e00\u9636\u5f20\u91cf\uff0c\u90a3\u4e48 \u77e9\u9635\u5c31\u662f\u4e8c\u9636\u5f20\u91cf \u3002 \u5e26\u6709\u6807\u91cf\u8ba1\u7b97\u7684\u7b97\u672f\u64cd\u4f5c\uff0c\u4f1a\u628a\u8ba1\u7b97\u53c2\u6570\u4f20\u9012\u7ed9\u6570\u7ec4\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u3002 \u540c\u5c3a\u5bf8\u6570\u7ec4\u4e4b\u95f4\u7684\u6bd4\u8f83 array04 == array04 \uff0c\u4f1a\u4ea7\u751f\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4 \u4e0d\u540c\u5c3a\u5bf8\u7684\u6570\u7ec4\u95f4\u7684\u64cd\u4f5c\uff0c\u5c06\u4f1a\u7528\u5230 \u5e7f\u64ad\u7279\u6027\uff08broadcasting\uff09 \u3002 array04 = np.array([ [1, 2, 3, 4, 5], [3, 4, 5, 6, 7], [5, 6, 7, 8, 9] ], dtype=int) print(array04 + array04) # [[ 2 4 6 8 10] # [ 6 8 10 12 14] # [10 12 14 16 18]] print(array04 - array04) # [[0 0 0 0 0] # [0 0 0 0 0] # [0 0 0 0 0]] print(array04 * array04) # [[ 1 4 9 16 25] # [ 9 16 25 36 49] # [25 36 49 64 81]] print(array04 / array04) # [[1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.]] print(1 / array04) # [[1. 0.5 0.33333333 0.25 0.2 ] # [0.33333333 0.25 0.2 0.16666667 0.14285714] # [0.2 0.16666667 0.14285714 0.125 0.11111111]] print(array04 == array04) # [[ True True True True True] # [ True True True True True] # [ True True True True True]] \u57fa\u7840\u7d22\u5f15\u4e0e\u5207\u7247 ndarray\u5bf9\u8c61\u7684\u5185\u5bb9\u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\uff08indexing\uff09\u6216\u5207\u7247\uff08slicing\uff09\u6765\u8bbf\u95ee\u548c\u4fee\u6539\uff0cndarray\u5bf9\u8c61\u4e2d\u7684\u5143\u7d20\u7d22\u5f15\u4ece\u96f6\u5f00\u59cb\u3002 \u6709\u4e09\u79cd\u53ef\u7528\u7684\u7d22\u5f15\u65b9\u6cd5\uff1a\u5b57\u6bb5\u8bbf\u95ee\uff0c\u57fa\u672c\u5207\u7247\u548c\u9ad8\u7ea7\u7d22\u5f15\u3002 \u7d22\u5f15\uff08indexing\uff09\uff1a\u83b7\u53d6\u6570\u7ec4\u4e2d\u7279\u5b9a\u4f4d\u7f6e\u5143\u7d20\u7684\u8fc7\u7a0b\u3002 \u5207\u7247\uff08slicing\uff09\uff1a\u83b7\u53d6\u6570\u7ec4\u5143\u7d20\u5b50\u96c6\u7684\u8fc7\u7a0b\u3002\u6570\u7ec4\u7684\u5207\u7247\u662f\u539f\u6570\u7ec4\u7684\u89c6\u56fe\u3002\u8fd9\u610f\u5473\u7740\u4efb\u4f55 \u5bf9\u4e8e\u89c6\u56fe\u7684\u4fee\u6539\u90fd\u4f1a\u53cd\u6620\u5230\u539f\u6570\u7ec4\u4e0a \u3002\u6570\u7ec4\u7684\u5207\u7247, \u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u964d\u4f4e\u4e00\u4e2a\u7ef4\u5ea6\u7684\u6570\u7ec4\u3002 \u4e00\u7ef4\u6570\u7ec4\u7684\u7d22\u5f15\u548c\u5207\u7247\uff1a\u4e0ePython\u7684\u5217\u8868\u7c7b\u4f3c\uff1a a[n] \uff1a\u8fd4\u56de\u7b2c n+1 \u4e2a\u5143\u7d20\u3002\u5982\u679c n \u4e3a\u8d1f\u6570\uff0c\u5219\u8fd4\u56de\u5012\u6570\u7b2c n \u4e2a\u5143\u7d20\u3002 a[n:m:k] \uff1a\u8d77\u59cb\u7f16\u53f7 n \uff0c\u7ec8\u6b62\u7f16\u53f7 m \uff0c\u6b65\u957f k \uff0c\u7528\u5192\u53f7\u5206\u5272\u3002 \u9075\u5faa\u5de6\u95ed\u53f3\u5f00\u7684\u539f\u5219 \uff0c\u5373 [n, m) \u3002\u5982\u679c n \u4e3a\u7a7a\uff0c\u5373 n = 0 \uff1b\u5982\u679c m \u4e3a\u7a7a\uff0c\u5373 m = len(a) \u3002 \u591a\u7ef4\u6570\u7ec4\u7684\u7d22\u5f15\u548c\u5207\u7247\uff1a a[n,m,k,...] \uff1a\u6bcf\u4e2a\u7ef4\u5ea6\u4e00\u4e2a\u7d22\u5f15\u503c\uff0c\u6700\u5916\u5c42\u5217\u8868\uff08list\uff09\u4e2d\u7b2c n \u4e2a\u5143\u7d20\uff0c\u6b21\u5916\u5c42\u5217\u8868\uff08list\uff09\u4e2d\u7b2c m \u4e2a\u5143\u7d20\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002\u5982\u679c n \u4e3a\u8d1f\u6570\uff0c\u5219\u8fd4\u56de\u5012\u6570\u7b2c n \u4e2a\u5143\u7d20\u3002 a[n1:m1:k1,n2:m2:k2,n3:m3:k3,...] \uff1a\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u5207\u7247\u65b9\u6cd5\u4e0e\u4e00\u7ef4\u6570\u7ec4\u76f8\u540c\u3002\u987a\u5e8f\u4e3a\u4ece\u5916\u5230\u5185\u3002 array05 = np.arange(10) print(array05) # [0 1 2 3 4 5 6 7 8 9] # \u4ece\u7d22\u5f15\u503c5\u5f00\u59cb\u5230\u7d22\u5f15\u503c7\u7684\u4e00\u4e2a\u5207\u7247\u3002 print(array05[5:8]) # [5 6 7] array06 = array05[5:8] # \u4f20\u5165\u4e00\u4e2a\u6570\u503c\u7ed9\u6570\u7ec4\u7684\u5207\u7247\uff0c\u6570\u503c\u88ab\u4f20\u9012\u7ed9\u4e86\u6574\u4e2a\u5207\u7247\u3002\u4e0d\u5199\u5207\u7247\u503c\u7684[:]\u5c06\u4f1a\u5f15\u7528\u6570\u7ec4\u7684\u6240\u6709\u503c array06[:] = 12 print(array06) # [12 12 12] # \u5207\u7247\u7684\u4fee\u6539\u4f1a\u53cd\u6620\u5230\u539f\u6570\u7ec4\u4e0a print(array05) # [ 0 1 2 3 4 12 12 12 8 9] # \u8f93\u51fa3\u7ef4\u77e9\u9635\uff0c3\u884c3\u5217\uff0c\u51719\u4e2a\u5143\u7d20\uff0c\u6bcf\u4e2a\u5143\u7d20\u662f\u4e00\u4e2a\u542b3\u4e2a\u5143\u7d20\u7684\u5217\u8868 array07 = np.array([ [[0, 1, 2], [3, 4, 5], [6, 7, 8]], [[9, 0, 1], [2, 3, 4], [5, 6, 7]], [[8, 9, 0], [1, 2, 3], [4, 5, 6]], ]) # \u8f93\u51fa3\u7ef4\u77e9\u9635\uff0c\u663e\u793a\u539f\u77e9\u9635\u7684\u7b2c1\uff0c2\u884c\u76842\uff0c3\u5217\u5143\u7d20\uff0c\u4e0d\u8981\u628a\u7d22\u5f15\u53f7\u548c\u8fd9\u91cc\u7684\u8868\u8ff0\u884c\u53f7\u6df7\u6dc6\u3002 print(array07[:2, 1:]) # [[[3 4 5] [6 7 8]] # [[2 3 4] [5 6 7]]] print(array07[:2, 1:].shape) # (2, 2, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c print(array07[2]) # [[8 9 0] [1 2 3] [4 5 6]] print(array07[2].shape) # (3, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c print(array07[2, :]) # [[8 9 0] [1 2 3] [4 5 6]] print(array07[2, :].shape) # (3, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c\uff08\u53ea\u6709\u4e09\u884c\uff0c\u6240\u4ee5[2:, :]\u7b49\u540c\u4e8e[2, :]\uff09 print(array07[2:, :]) # [[[8 9 0] [1 2 3] [4 5 6]]] print(array07[2:, :].shape) # (1, 3, 3) # \u8f93\u51fa\u539f\u77e9\u9635\u76841\uff0c2\u5217 print(array07[:, :2]) # [[[0 1 2] [3 4 5]] # [[9 0 1] [2 3 4]] # [[8 9 0] [1 2 3]]] print(array07[:, :2].shape) # (3, 2, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u524d2\u4e2a\u5143\u7d20 print(array07[1, :2]) # [[9 0 1] [2 3 4]] print(array07[1, :2].shape) # (2, 3) # \u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u524d2\u4e2a\u5143\u7d20 print(array07[1:2, :2]) # [[[9 0 1] [2 3 4]]] print(array07[1:2, :2].shape) # (1, 2, 3) # \u5c06\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u8d4b\u503c\u7ed9\u53d8\u91cf old_value = array07[2].copy() print(old_value) # [[8 9 0] [1 2 3] [4 5 6]] # \u4fee\u6539\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u7684\u503c\uff0c\u6807\u91cf\u548c\u6570\u7ec4\u90fd\u53ef\u4ee5\u4f20\u9012\u7ed9 array07[2] array07[2] = 25 print(array07) # [[[ 0 1 2] [ 3 4 5] [ 6 7 8]] # [[ 9 0 1] [ 2 3 4] [ 5 6 7]] # [[25 25 25] [25 25 25] [25 25 25]]] # \u5c06\u53d8\u91cf\u503c\u8d4b\u503c\u7ed9\u539f\u77e9\u9635\u7684\u7b2c2\u884c array07[2] = old_value print(array07) # [[[0 1 2] [3 4 5] [6 7 8]] # [[9 0 1] [2 3 4] [5 6 7]] # [[8 9 0] [1 2 3] [4 5 6]]] \u5e03\u5c14\u7d22\u5f15 \u5e03\u5c14\u503c\u7d22\u5f15\uff08Boolean indexing\uff09\u662f\u901a\u8fc7\u4e00\u4e2a\u5e03\u5c14\u6570\u7ec4\u6765\u7d22\u5f15\u76ee\u6807\u6570\u7ec4\uff0c\u4ee5\u6b64\u627e\u51fa\u4e0e\u5e03\u5c14\u6570\u7ec4\u4e2d\u503c\u4e3aTrue\u7684\u5bf9\u5e94\u7684\u76ee\u6807\u6570\u7ec4\u4e2d\u7684\u6570\u636e\u3002\u5e03\u5c14\u6570\u7ec4\u7684\u957f\u5ea6\u5fc5\u987b\u4e0e\u76ee\u6807\u6570\u7ec4\u5bf9\u5e94\u7684\u8f74\u7684\u957f\u5ea6\u4e00\u81f4\u3002 \u4f7f\u7528\u5e03\u5c14\u503c\u7d22\u5f15\uff08Boolean indexing\uff09\u9009\u62e9\u6570\u636e\u65f6\uff0c\u603b\u662f\u751f\u6210\u6570\u636e\u7684\u62f7\u8d1d\uff0c\u5373\u4f7f\u8fd4\u56de\u7684\u6570\u7ec4\u5e76\u6ca1\u6709\u4efb\u4f55\u53d8\u5316\u3002 \u5047\u8bbe\u6211\u4eec\u7684\u6570\u636e\u90fd\u5728\u6570\u7ec4\u4e2d\uff0c\u5e76\u4e14\u6570\u7ec4\u4e2d\u7684\u6570\u636e\u662f\u4e00\u4e9b\u5b58\u5728\u91cd\u590d\u7684\u4eba\u540d\u3002\u7528randn\u51fd\u6570\u751f\u6210\u4e00\u4e9b\u6807\u51c6\u6b63\u6001(standard normal)\u5206\u5e03\u7684\u6570\u636e\u3002\u5047\u8bbe\u6bcf\u4e2a\u4eba\u540d\u90fd\u548cdata\u6570\u7ec4\u4e2d\u7684\u4e00\u884c\u76f8\u5bf9\u5e94\uff0c\u5e76\u4e14\u6211\u4eec\u60f3\u8981\u9009\u4e2d\u6240\u6709\u2019Bob\u2019\u5bf9\u5e94\u7684\u884c\u3002 names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], dtype='<U4') data = np.random.randn(7, 4) print(names) # ['Bob' 'Joe' 'Will' 'Bob' 'Will' 'Joe' 'Joe'] print(data) # [[ 0.19233985 -0.22530396 -0.68464485 0.03961609] # [ 0.26189893 -0.86823302 0.72726864 0.16122945] # [-0.70564457 0.59179465 0.05572085 -1.79999391] # [-0.21465342 0.09236611 0.02982635 -1.08500576] # [ 1.17260699 -0.53172414 0.16224439 0.60597493] # [ 0.49879926 -0.64871168 0.57597095 0.86329327] # [-0.64902274 -0.92406415 0.40021708 -0.18222566]] print(names == 'Bob') # [ True False False True False False False] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob']) # [[ 0.19233985 -0.22530396 -0.68464485 0.03961609] # [-0.21465342 0.09236611 0.02982635 -1.08500576]] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u4e14\u5217\u7d22\u5f15\u4e3a2\u30013\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob', 2:]) # [[-0.68464485 0.03961609] [ 0.02982635 -1.08500576]] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u4e14\u5217\u7d22\u5f15\u4e3a3\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob', 3]) # [ 0.03961609 -1.08500576] \u4f7f\u7528 != \u6216\u5728\u6761\u4ef6\u8868\u8fbe\u5f0f\u524d\u4f7f\u7528 \uff5e \u5bf9\u6761\u4ef6\u53d6\u53cd, \u9009\u62e9\u9664\u4e86\u2019Bob\u2019\u4ee5\u5916\u7684\u5176\u4ed6\u6570\u636e\u3002 print(names != 'Bob') print(data[~(names == 'Bob')]) \u9009\u62e9\u4e09\u4e2a\u540d\u5b57\u4e2d\u7684\u4e24\u4e2a\u65f6\uff0c\u53ef\u4ee5\u5bf9\u591a\u4e2a\u5e03\u5c14\u503c\u6761\u4ef6\u8fdb\u884c\u8054\u5408\uff0c\u4f7f\u7528\u6570\u5b66\u64cd\u4f5c\u7b26\u5982 & \uff08and\uff09\u548c | \uff08or\uff09\u3002 mask = (names == 'Bob') | (names == 'Will') print(mask) # [ True False True True True False False] # \u66f4\u65b0\u76f4\u63a5\u4f5c\u7528\u5728`data`\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u662f\u5728\u526f\u672c\u4e2d\u4fee\u6539\u3002 data[names == 'Joe'] = 7 print(data) # [[ 1.12584226 -1.09988707 0.49842702 0.76308186] # [ 7. 7. 7. 7. ] # [ 1.54212949 -0.34487439 -1.47775736 -0.25724376] # [ 0.60943059 -0.0164697 0.26681455 -1.70871624] # [ 0.28010374 -0.32339505 -0.95289544 2.76739316] # [ 7. 7. 7. 7. ] # [ 7. 7. 7. 7. ]] \u795e\u5947\u7d22\u5f15\uff08\u82b1\u5f0f\u7d22\u5f15\uff09 \u795e\u5947\u7d22\u5f15\uff08Fancy Indexing\uff09 \uff0c\u4e5f\u7ffb\u8bd1\u4e3a \u82b1\u5f0f\u7d22\u5f15 \u6216 \u590d\u6742\u7d22\u5f15 \uff0c\u7528\u4e8e\u63cf\u8ff0\u4f7f\u7528\u6574\u6570\u6570\u7ec4\u8fdb\u884c\u6570\u636e\u7d22\u5f15\uff0c\u8fd9\u91cc\u7684\u6570\u7ec4\uff0c\u53ef\u4ee5\u662fNumPy\u7684\u6570\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u662fpython\u81ea\u5e26\u7684\u5217\u8868\uff08list\uff09\u3002\u795e\u5947\u7d22\u5f15\u4e0e\u5207\u7247\u4e0d\u540c\uff0c\u5b83\u603b\u662f\u5c06\u6570\u636e \u590d\u5236 \u5230\u4e00\u4e2a\u65b0\u7684\u6570\u7ec4\u4e2d\uff08\u526f\u672c\uff09\u3002 \u7279\u522b\u6ce8\u610f\u7684\u4e00\u70b9\u662f\uff0c\u4f7f\u7528fancy indexing\u8fd4\u56de\u6570\u7ec4\u7684shape\uff0c\u662f\u7d22\u5f15\u6570\u7ec4\u7684shape\uff0c\u800c\u4e0d\u662f\u88ab\u7d22\u5f15\u7684\u539f\u6570\u7ec4\u7684shape\u3002 \u4f7f\u7528fancy indexing\u65f6\u8981\u7279\u522b\u6ce8\u610f\u7684\u4e00\u70b9\u662f\u8fd4\u56de\u6570\u7ec4\u7684shape\u53cd\u6620\u7684\u662f\u7d22\u5f15\u6570\u7ec4\u7684shape\u800c\u4e0d\u662f\u88ab\u7d22\u5f15\u7684\u539f\u6570\u7ec4\u7684shape\u3002 \u5047\u8bbe\u6709\u4e00\u4e2a8\u00d74\u7684\u6570\u7ec4\uff1a array08 = np.empty((8, 4)) # \u53c2\u6570\u662f\u4e2a\u5143\u7ec4(8, 4)\u3002 for i in range(8): array08[i] = i print(array08) # [[0. 0. 0. 0.] # [1. 1. 1. 1.] # [2. 2. 2. 2.] # [3. 3. 3. 3.] # [4. 4. 4. 4.] # [5. 5. 5. 5.] # [6. 6. 6. 6.] # [7. 7. 7. 7.]] # \u8f93\u51fa\u7d22\u5f15\u4e3a2\u548c-2\u7684\u884c\u503c\u3002\u4f20\u9012\u4e00\u4e2a\u5305\u542b\u6307\u660e\u6240\u9700\u987a\u5e8f\u7684\u5217\u8868[2, -2]\uff08\u6216\u6570\u7ec4\uff09\uff0c\u9009\u51fa\u4e00\u4e2a\u7b26\u5408\u7279\u5b9a\u987a\u5e8f\u7684\u5b50\u96c6 print(array08[[2, -2]]) # [[2. 2. 2. 2.] # [6. 6. 6. 6.]] # \u75280~31\u751f\u6210\u4e00\u4e2a8x4\u6570\u7ec4 array09 = np.arange(32).reshape((8, 4)) print(array09) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11] # [12 13 14 15] # [16 17 18 19] # [20 21 22 23] # [24 25 26 27] # [28 29 30 31]] print(array09[[1, 5, 7, 2]]) # \u6570\u7ec4[1, 5, 7, 2]\u6307\u5b9a\u4e86\u8f93\u51fa\u987a\u5e8f # [[ 4 5 6 7] # [20 21 22 23] # [28 29 30 31] # [ 8 9 10 11]] print(array09[[0, 3, 1, 2]]) # [[ 0 1 2 3] # [12 13 14 15] # [ 4 5 6 7] # [ 8 9 10 11]] print(array09[[1, 5, 7, 2], [0, 3, 1, 2]]) # [ 4 23 29 10] array09[[1, 5, 7, 2]] \u4e2d\u901a\u8fc7\u4e00\u4e2a\u5217\u8868 [1, 5, 7, 2] \u6765\u6307\u5b9a\u8f93\u51fa\u987a\u5e8f\u3002 array09[[1, 5, 7, 2], [0, 3, 1, 2]] \u53ef\u4ee5\u7406\u89e3\u4e3a\u57fa\u4e8e array09[[1, 5, 7, 2]] \u8f93\u51fa\u7684\u77e9\u9635\uff0c\u901a\u8fc7[0, 3, 1, 2]\u6307\u5b9a\u4e86\u7ed3\u679c\u96c6\u7684\u6bcf\u4e00\u884c\u9009\u53d6\u7684\u503c\uff0c\u6bd4\u5982\uff0c3\u4ee3\u8868\u7ed3\u679c\u96c6[20 21 22 23]\u7684\u7b2c\u4e09\u4e2a\u5143\u7d20\uff0823\uff09\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\uff0c\u5143\u7d20\uff081, 0\uff09\u3001\uff085, 3\uff09\u3001\uff087, 1\uff09\u548c\uff082, 2\uff09\u88ab\u9009\u4e2d\u3002 \u6570\u7ec4\u8f6c\u7f6e\u548c\u6362\u8f74 \u6570\u7ec4\u8f6c\u7f6e\uff0c\u6709T\u5c5e\u6027\u3001 transpose() \u65b9\u6cd5\u3001 swapaxes() \u65b9\u6cd5\u3002 swapaxes() \u65b9\u6cd5\u9ed8\u8ba4\u662f(0\u8f74, 1\u8f74)\uff0c\u5373 swapaxes(0, 1) \uff0c\u8fd4\u56de\u7684\u662f\u6570\u636e\u7684\u89c6\u56fe\uff0c\u6ca1\u6709\u5bf9\u6570\u636e\u8fdb\u884c\u590d\u5236\u3002 array10 = np.arange(15).reshape((3, 5)) print(array10) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08T\u5c5e\u6027\uff09 print(array10.T) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08transpose()\u65b9\u6cd5\uff09 print(array10.transpose()) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08swapaxes()\u65b9\u6cd5\uff09 print(array10.swapaxes(1, 0)) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] \u901a\u8fc7T\u5c5e\u6027\uff0c\u8ba1\u7b97\u77e9\u9635\u5185\u79ef\uff08Inner Product\uff09\u3002\u77e9\u9635\u5185\u79ef\u53c2\u7167\u5411\u91cf\u5185\u79ef\u7684\u5b9a\u4e49\u662f\uff1a\u4e24\u4e2a\u5411\u91cf\u5bf9\u5e94\u5206\u91cf\u4e58\u79ef\u4e4b\u548c\u3002 array10 = np.arange(6).reshape((2, 3)) print(array10) # [[0 1 2] # [3 4 5]] print(array10.T) # [[0 3] # [1 4] # [2 5]] print(np.dot(array10, array10.T)) # [[ 5 14] # [14 50]] \u5bf9\u4e8e\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u7ec4\uff0c transpose() \u65b9\u6cd5\u53ef\u4ee5\u63a5\u6536\u5305\u542b\u8f74\u7f16\u53f7\u7684\u5143\u7ec4\uff0c\u7528\u4e8e\u7f6e\u6362\u8f74\u3002 array11 = np.arange(36).reshape((3, 3, 4)) print(array11) # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] print(array11.transpose((0, 1, 2))) # \u9ed8\u8ba4\u662f(0\u8f74, 1\u8f74, 2\u8f74)\u3002\u6240\u4ee5\u8f93\u51fa\u539f\u77e9\u9635 # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] print(array11.transpose((1, 0, 2))) # \u8f93\u51fa\u987a\u5e8f\u8c03\u6574\u4e3a\u539f\u77e9\u9635\u7684(1\u8f74, 0\u8f74, 2\u8f74) # [[[ 0 1 2 3] # [12 13 14 15] # [24 25 26 27]] # # [[ 4 5 6 7] # [16 17 18 19] # [28 29 30 31]] # # [[ 8 9 10 11] # [20 21 22 23] # [32 33 34 35]]] print(array11.swapaxes(1, 0)) # \u540c\u4e0atranspose((1, 0, 2)) # [[[ 0 1 2 3] # [12 13 14 15] # [24 25 26 27]] # # [[ 4 5 6 7] # [16 17 18 19] # [28 29 30 31]] # # [[ 8 9 10 11] # [20 21 22 23] # [32 33 34 35]]] print(array11.transpose((2, 1, 0))) # [[[ 0 12 24] # [ 4 16 28] # [ 8 20 32]] # # [[ 1 13 25] # [ 5 17 29] # [ 9 21 33]] # # [[ 2 14 26] # [ 6 18 30] # [10 22 34]] # [[ 3 15 27] # [ 7 19 31] # [11 23 35]]] \u901a\u7528\u51fd\u6570 \u901a\u7528\u51fd\u6570 \u4e5f\u79f0\u4e3aufunc\uff0c\u662f\u4e00\u79cd\u5728ndarray\u6570\u636e\u4e2d\u8fdb\u884c\u9010\u5143\u7d20\u64cd\u4f5c\u7684\u51fd\u6570\uff0c\u5373\u5feb\u901f\u7684\u9010\u5143\u7d20\u6570\u7ec4\u51fd\u6570\u3002 \u67d0\u4e9b\u7b80\u5355\u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u91cf\u6570\u503c\uff0c\u5e76\u4ea7\u751f\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u91cf\u7ed3\u679c\uff0c\u800c \u901a\u7528\u51fd\u6570\u5c31\u662f\u5bf9\u8fd9\u4e9b\u7b80\u5355\u51fd\u6570\u7684\u5411\u91cf\u5316\u5c01\u88c5 \u3002 \u4e00\u5143\u901a\u7528\u51fd\u6570 abs\u3001fabs\uff1a\u9010\u5143\u7d20\u5730\u8ba1\u7b97\u6574\u6570\u3001\u6d6e\u70b9\u6570\u6216\u590d\u6570\u7684\u7edd\u5bf9\u503c sqrt\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\u6839\uff08\u4e0earr**0.5\u76f8\u7b49\uff09 square\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\uff08\u4e0earr**2\u76f8\u7b49\uff09 exp\uff1a\u8ba1\u7b97\u4ee5e\u4e3a\u5e95, \u6570\u7ec4\u5143\u7d20\u4e3a\u5e42\u6b21\u7684\u6307\u6570\u51fd\u6570 \u4e8c\u5143\u901a\u7528\u51fd\u6570 add\uff1a\u5c06\u6570\u7ec4\u7684\u5bf9\u5e94\u5143\u7d20\u76f8\u52a0\u3002 subtract\uff1a\u5728\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u4e2d\uff0c\u5c06\u7b2c\u4e00\u4e2a\u6570\u7ec4\u4e2d\u5305\u542b\u7684\u5143\u7d20\u53bb\u9664\u3002 multiply\uff1a\u5c06\u6570\u7ec4\u7684\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\u3002 divide\uff0cfloor_divide\uff1a\u9664\u3001\u6216\u6574\u9664\uff08\u653e\u5f03\u4f59\u6570\uff09 power\uff1a\u5c06\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u7684\u5143\u7d20\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u6570\u7ec4\u5bf9\u5e94\u5143\u7d20\u7684\u5e42\u6b21\u65b9\u3002 maximun\u3001fmax\uff1a\u9010\u4e2a\u5143\u7d20\u8ba1\u7b97\u6700\u5927\u503c\uff0cfmax\u5ffd\u7565NaN\u3002 minimum\u3001fmin\uff1a\u9010\u4e2a\u5143\u7d20\u8ba1\u7b97\u6700\u5c0f\u503c\uff0cfmin\u5ffd\u7565NaN\u3002 mod\uff1a\u6309\u5143\u7d20\u7684\u6c42\u6a21\u8ba1\u7b97\uff08\u5373\u6c42\u9664\u6cd5\u7684\u4f59\u6570\uff09\u3002 copysign\uff1a\u5c06\u7b2c\u4e00\u4e2a\u6570\u7ec4\u7684\u7b26\u53f7\u503c\u6539\u4e3a\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u7684\u7b26\u53f7\u503c\u3002 greater\u3001greater_euqal\u3001less\u3001less_equal\u3001equal\u3001not_euqal\uff1a\u8fdb\u884c\u9010\u4e2a\u5143\u7d20\u7684\u6bd4\u8f83\uff0c\u8fd4\u56de\u5e03\u5c14\u503c\u6570\u7ec4\u3002 logical_and\u3001logical_or\u3001logical_xor\uff1a\u8fdb\u884c\u9010\u4e2a\u5143\u7d20\u7684\u903b\u8f91\u64cd\u4f5c\u3002 \u770b\u4e0b\u4f8b\uff0c\u5bf9\u591a\u7ef4\u6570\u7ec4\u8ba1\u7b97exp\u51fd\u6570\u3002 array12 = np.arange(10).reshape((2, 5)) print(array12) # [[0 1 2 3 4] # [5 6 7 8 9]] print(np.sqrt(array12)) # [[0. 1. 1.41421356 1.73205081 2. ] # [2.23606798 2.44948974 2.64575131 2.82842712 3. ]] print(np.exp(array12)) # [[1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01 5.45981500e+01] # [1.48413159e+02 4.03428793e+02 1.09663316e+03 2.98095799e+03 8.10308393e+03]] \u4e0b\u4f8b\u4e2d\uff0c numpy.maximum \u9010\u5143\u7d20\u5730\u5c06\u6570\u7ec4 x \u548c y \u4e2d\u7684\u6700\u5927\u503c\u8ba1\u7b97\u51fa\u6765\u3002 numpy.add \u9010\u5143\u7d20\u5730\u5c06\u6570\u7ec4 x \u548c y \u7684\u548c\u8ba1\u7b97\u51fa\u6765\u3002 array13 = [1, 4, 5, 8, 9] array14 = [2, 3, 6, 7, 10] print(np.maximum(array13, array14)) # [ 2 4 6 8 10] print(np.add(array13, array14)) # [ 3 7 11 15 19] \u4e0b\u4f8b\u4e2d\uff0c modf \u8fd4\u56de\u4e00\u4e2a\u6d6e\u70b9\u503c\u6570\u7ec4\u7684\u5c0f\u6570\u90e8\u5206\u548c\u6574\u6570\u90e8\u5206 array15 = np.random.randn(7) * 5 print(array15) # [-7.54395135 -0.065131 2.71582306 2.2432261 11.02637158 6.73968036 2.96895379] remainder, whole_part = np.modf(array15) print(remainder) # [-0.54395135 -0.065131 0.71582306 0.2432261 0.02637158 0.73968036 0.96895379] print(whole_part) # [-7. -0. 2. 2. 11. 6. 2.] \u9762\u5411\u6570\u7ec4\u7f16\u7a0b \u5229\u7528 \u6570\u7ec4\u8868\u8fbe\u5f0f \u6765\u66ff\u4ee3\u663e\u5f0f\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u5411\u91cf\u5316 \u3002 \u5411\u91cf\u5316\u7684\u6570\u7ec4\u64cd\u4f5c\u4f1a\u6bd4\u7eafPython\u7684\u7b49\u4ef7\u5b9e\u73b0\u5728\u901f\u5ea6\u4e0a\u5feb\u4e00\u5230\u4e24\u4e2a\u6570\u91cf\u7ea7\uff08\u751a\u81f3\u66f4\u591a\uff09\u3002 \u4e0b\u4f8b\u4e2d\uff0cnp.meshgrid\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u4e00\u7ef4\u6570\u7ec4\uff0c\u5e76\u6839\u636e\u4e24\u4e2a\u6570\u7ec4\u7684\u6240\u6709(x, y)\u5bf9\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u77e9\u9635\u3002 array = np.arange(-5, 5, 1, dtype=int) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) xs, ys = np.meshgrid(array, array) print(\"\u751f\u6210x\u8f74\u54112\u7ef4\u77e9\u9635 \\n\", xs) print(\"\u751f\u6210y\u8f74\u54112\u7ef4\u77e9\u9635 \\n\", ys) # \u6837\u672c\u77e9\u9635 # [-5 -4 -3 -2 -1 0 1 2 3 4] # \u751f\u6210x\u8f74\u54112\u7ef4\u77e9\u9635 # [[-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4]] # \u751f\u6210y\u8f74\u54112\u7ef4\u77e9\u9635 # [[-5 -5 -5 -5 -5 -5 -5 -5 -5 -5] # [-4 -4 -4 -4 -4 -4 -4 -4 -4 -4] # [-3 -3 -3 -3 -3 -3 -3 -3 -3 -3] # [-2 -2 -2 -2 -2 -2 -2 -2 -2 -2] # [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1] # [ 0 0 0 0 0 0 0 0 0 0] # [ 1 1 1 1 1 1 1 1 1 1] # [ 2 2 2 2 2 2 2 2 2 2] # [ 3 3 3 3 3 3 3 3 3 3] # [ 4 4 4 4 4 4 4 4 4 4]] \u4e0b\u9762\u7528\u56fe\u5f62\u5316\u6765\u8f93\u51fa\u4e0a\u4f8b\u4e2d\u751f\u6210\u7684NumPy\u7684\u6570\u7ec4\u3002 import numpy as np import matplotlib.pyplot as plt array = np.arange(-5, 5, 1, dtype=int) xs, ys = np.meshgrid(array, array) z = np.sqrt(xs**2 + ys**2) print(\"\u6837\u672c\u77e9\u9635 \\n\", z) # \u6837\u672c\u77e9\u9635 # [[7.07106781 6.40312424 5.83095189 5.38516481 5.09901951 5. 5.09901951 5.38516481 5.83095189 6.40312424] # [6.40312424 5.65685425 5. 4.47213595 4.12310563 4. 4.12310563 4.47213595 5. 5.65685425] # [5.83095189 5. 4.24264069 3.60555128 3.16227766 3. 3.16227766 3.60555128 4.24264069 5. ] # [5.38516481 4.47213595 3.60555128 2.82842712 2.23606798 2. 2.23606798 2.82842712 3.60555128 4.47213595] # [5.09901951 4.12310563 3.16227766 2.23606798 1.41421356 1. 1.41421356 2.23606798 3.16227766 4.12310563] # [5. 4. 3. 2. 1. 0. 1. 2. 3. 4. ] # [5.09901951 4.12310563 3.16227766 2.23606798 1.41421356 1. 1.41421356 2.23606798 3.16227766 4.12310563] # [5.38516481 4.47213595 3.60555128 2.82842712 2.23606798 2. 2.23606798 2.82842712 3.60555128 4.47213595] # [5.83095189 5. 4.24264069 3.60555128 3.16227766 3. 3.16227766 3.60555128 4.24264069 5. ] # [6.40312424 5.65685425 5. 4.47213595 4.12310563 4. 4.12310563 4.47213595 5. 5.65685425]] # \u4f7f\u7528matplotlib\u6765\u751f\u6210\u8fd9\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u7684\u53ef\u89c6\u5316 plt.imshow(z, cmap=plt.cm.gray) print(plt.colorbar) # <function colorbar at 0x7f9c91193f70> # \u56fe\u50cf\u6807\u9898 plt.title(\"$\\sqrt{x^2 + y^2}$ \u8ba1\u7b97\u503c\u7684\u7f51\u683c\u56fe\") # \u8f93\u51fa\u56fe\u50cf plt.show() \u8f93\u51fa\u56fe\u50cf\u4e3a\uff1a \u901a\u8fc7\u6761\u4ef6\u903b\u8f91\u64cd\u4f5c\u6570\u7ec4 numpy.where \u51fd\u6570\u662f\u4e09\u5143\u8868\u8fbe\u5f0f x if condition else y \u7684\u5411\u91cf\u5316\u7248\u672c\u3002 np.where \u7684\u7b2c\u4e8c\u4e2a\u548c\u7b2c\u4e09\u4e2a\u53c2\u6570\u5e76\u4e0d\u9700\u8981\u662f\u6570\u7ec4\uff0c\u5b83\u4eec\u53ef\u4ee5\u662f\u6807\u91cf\u3002 np.where \u5728\u6570\u636e\u5206\u6790\u4e2d\u7684\u4e00\u4e2a\u5178\u578b\u7528\u6cd5\u662f\u6839\u636e\u4e00\u4e2a\u6570\u7ec4\u6765\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u6570\u7ec4\u3002 \u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u548c\u4e24\u4e2a\u6570\u503c\u6570\u7ec4\u3002\u5047\u8bbe cond \u4e2d\u7684\u5143\u7d20\u4e3a True \u65f6\uff0c\u6211\u4eec\u53d6 xarr \u4e2d\u7684\u5bf9\u5e94\u5143\u7d20\u503c\uff0c\u5426\u5219\u53d6 yarr \u4e2d\u7684\u5143\u7d20\u3002 xarray = np.array([1.1, 1.2, 1.3, 1.4, 1.5]) yarray = np.array([2.1, 2.2, 2.3, 2.4, 2.5]) cond = np.array([True, False, True, True, False]) \u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u6765\u5b9e\u73b0\u4e0a\u8ff0\u9700\u6c42\u3002 \u7f3a\u70b9: \u9996\u5148\uff0c\u5982\u679c\u6570\u7ec4\u5f88\u5927\u7684\u8bdd\uff0c\u901f\u5ea6\u4f1a\u5f88\u6162\uff08\u56e0\u4e3a\u6240\u6709\u7684\u5de5\u4f5c\u90fd\u662f\u901a\u8fc7\u89e3\u91ca\u5668\u6765\u89e3\u91caPython\u4ee3\u7801\u5b8c\u6210\uff09\u3002 \u5176\u6b21\uff0c\u5f53\u6570\u7ec4\u662f\u591a\u7ef4\u65f6\uff0c\u5c31\u65e0\u6cd5\u51d1\u6548\u4e86\u3002 # \u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u6765\u5b9e\u73b0 result = [(x if c else y) for x, y, c in zip(xarray, yarray, cond)] print(result) # [1.1, 2.2, 1.3, 1.4, 2.5] \u901a\u8fc7 np.where \u6765\u5b9e\u73b0\u4e0a\u8ff0\u9700\u6c42\u3002 result = np.where(cond, xarray, yarray) print(result) # [1.1 2.2 1.3 1.4 2.5] \u5047\u8bbe\u6709\u4e00\u4e2a\u968f\u673a\u751f\u6210\u7684\u77e9\u9635\u6570\u636e\uff0c\u4e0b\u9762\u4f7f\u7528np.where\u5b9e\u73b0\u66ff\u6362\u3002 array = np.random.randn(4, 4) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u77e9\u9635\u5143\u7d20\u662f\u5426\u5927\u4e8e0 \\n\", array > 0) # \u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 result03 = np.where(array > 0, 2, -2) print(\"\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 \\n\", result03) # \u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 result04 = np.where(array > 0, 2, array) print(\"\u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 \\n\", result04) # \u6837\u672c\u77e9\u9635 # [[-0.57177422 -0.34917512 2.20268075 1.99959296] # [ 0.67966599 2.67915099 -0.40528454 -0.80339907] # [-0.74406888 2.33802717 -0.74582936 0.59347128] # [ 0.68624473 0.65953112 -0.40871415 -0.68698878]] # \u77e9\u9635\u5143\u7d20\u662f\u5426\u5927\u4e8e0 # [[False False True True] # [ True True False False] # [False True False True] # [ True True False False]] # \u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 # [[-2 -2 2 2] # [ 2 2 -2 -2] # [-2 2 -2 2] # [ 2 2 -2 -2]] # \u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 # [[-0.57177422 -0.34917512 2. 2. ] # [ 2. 2. -0.40528454 -0.80339907] # [-0.74406888 2. -0.74582936 2. ] # [ 2. 2. -0.40871415 -0.68698878]] \u6570\u5b66\u548c\u7edf\u8ba1\u65b9\u6cd5 NumPy\u6709\u4e00\u4e9b\u4e13\u95e8\u7684\u6570\u5b66\u51fd\u6570\uff0c\u7528\u6765\u8ba1\u7b97\u6574\u4e2a\u6570\u7ec4\u7edf\u8ba1\u503c\u6216\u8f74\u5411\u6570\u636e\u7684\u8ba1\u7b97\u3002\u4f8b\u5982\uff0c\u805a\u5408\u51fd\u6570\uff08\u901a\u5e38\u4e5f\u53eb\u7f29\u51cf\u51fd\u6570\uff09\uff0c\u5982sum\u3001mean\u548cstd\uff08\u6807\u51c6\u5dee\uff09\u3002 \u65e2\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u6570\u7ec4\u5b9e\u4f8b\u7684\u65b9\u6cd5\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u9876\u5c42\u7684NumPy\u51fd\u6570\u3002 \u4e3e\u4f8b\uff1a\u751f\u6210\u4e00\u4e9b\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u6570\uff0c\u8ba1\u7b97\u90e8\u5206\u805a\u5408\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u91cc\u518d\u5bf9\u8f74\u5411\u505a\u4e2a\u89e3\u91ca\uff0c np.random.randn(5, 4) \u4ea7\u751f\u7684\u4e8c\u7ef4\u6570\u7ec4\u662f\uff1a0\u8f74\u54115\u4e2a\u5143\u7d20, 1\u8f74\u54114\u4e2a\u5143\u7d20\u3002 # \u751f\u62102\u8f74\u6570\u7ec4 array = np.random.randn(5, 4) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c\", array.mean()) print(\"\u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c\", np.mean(array)) print(\"\u77e9\u9635\u5143\u7d20\u548c\", array.sum()) print(\"\u77e9\u9635\u5143\u7d20\u548c\", np.sum(array)) print(\"0\u8f74\u5411\u7684\u7d2f\u548c\", array.sum(axis=0)) print(\"1\u8f74\u5411\u7684\u7d2f\u548c\", array.sum(axis=1)) print(\"1\u8f74\u5411\u7684\u5e73\u5747\u503c\", array.mean(axis=1)) # \u6837\u672c\u77e9\u9635 shape=(5, 4) 0\u8f74\u54115\u4e2a\u5143\u7d20, 1\u8f74\u54114\u4e2a\u5143\u7d20 # [[ 0.32532911 -0.00177984 -1.59432632 1.58375133] # [ 1.48921763 0.25202456 0.44076148 -1.02277289] # [-0.73490219 0.19197171 -0.22374362 0.52610852] # [-1.03531076 1.0595528 -0.11566501 0.34063544] # [-0.2122241 -0.81348187 1.70989712 -0.00732696]] # \u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c 0.10788580775057008 # \u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c 0.10788580775057008 # \u77e9\u9635\u5143\u7d20\u548c 2.1577161550114017 # \u77e9\u9635\u5143\u7d20\u548c 2.1577161550114017 # 0\u8f74\u5411\u7684\u7d2f\u548c [-0.16789031 0.68828737 0.21692365 1.42039545] # 1\u8f74\u5411\u7684\u7d2f\u548c [ 0.31297429 1.15923078 -0.24056558 0.24921247 0.67686419] # 1\u8f74\u5411\u7684\u5e73\u5747\u503c [ 0.07824357 0.28980769 -0.06014139 0.06230312 0.16921605] \u4e0b\u9762\u5217\u4e3e\u4e86\u5e38\u7528\u7684\u57fa\u7840\u6570\u7ec4\u7edf\u8ba1\u65b9\u6cd5\u3002 array = np.array([ [1, 2, 3, 4, 5], [3, 4, 5, 6, 7], [5, 6, 7, 8, 9] ], dtype=int) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u8f74\u5411\u6c42\u548c\", array.sum()) print(\"\u8f74\u5411\u6c42\u548c\", array.sum(axis=0)) print(\"\u6570\u5b66\u5e73\u5747\", array.mean()) print(\"\u8f74\u5411\u6570\u5b66\u5e73\u5747\", array.mean(axis=0)) print(\"\u6807\u51c6\u5dee\", array.std(), \"\u65b9\u5dee\", array.var()) print(\"\u8f74\u5411\u6807\u51c6\u5dee\", array.std(axis=0), \"\u8f74\u5411\u65b9\u5dee\", array.var(axis=0)) print(\"\u6700\u5c0f\u503c\", array.min(), \"\u6700\u5927\u503c\", array.max()) print(\"\u8f74\u5411\u6700\u5c0f\u503c\", array.min(axis=0), \"\u8f74\u5411\u6700\u5927\u503c\", array.max(axis=0)) print(\"\u6700\u5c0f\u503c\u4f4d\u7f6e\", array.argmin(), \"\u6700\u5927\u503c\u4f4d\u7f6e\", array.argmax()) print(\"\u8f74\u5411\u6700\u5c0f\u503c\u4f4d\u7f6e\", array.argmin(axis=0), \"\u8f74\u5411\u6700\u5927\u503c\u4f4d\u7f6e\", array.argmax(axis=0)) print(\"\u7d2f\u79ef\u548c \\n\", array.cumsum()) print(\"\u8f74\u5411\u7d2f\u79ef\u548c \\n\", array.cumsum(axis=1)) print(\"\u7d2f\u79ef\u4e58\u79ef \\n\", array.cumprod()) print(\"\u8f74\u5411\u7d2f\u79ef\u4e58\u79ef \\n\", array.cumprod(axis=1)) # \u6837\u672c\u77e9\u9635 # [[1 2 3 4 5] # [3 4 5 6 7] # [5 6 7 8 9]] # \u8f74\u5411\u6c42\u548c 75 # \u8f74\u5411\u6c42\u548c [ 9 12 15 18 21] # \u6570\u5b66\u5e73\u5747 5.0 # \u8f74\u5411\u6570\u5b66\u5e73\u5747 [3. 4. 5. 6. 7.] # \u6807\u51c6\u5dee 2.160246899469287 \u65b9\u5dee 4.666666666666667 # \u8f74\u5411\u6807\u51c6\u5dee [1.63299316 1.63299316 1.63299316 1.63299316 1.63299316] \u8f74\u5411\u65b9\u5dee [2.66666667 2.66666667 2.66666667 2.66666667 2.66666667] # \u6700\u5c0f\u503c 1 \u6700\u5927\u503c 9 # \u8f74\u5411\u6700\u5c0f\u503c [1 2 3 4 5] \u8f74\u5411\u6700\u5927\u503c [5 6 7 8 9] # \u6700\u5c0f\u503c\u4f4d\u7f6e 0 \u6700\u5927\u503c\u4f4d\u7f6e 14 # \u8f74\u5411\u6700\u5c0f\u503c\u4f4d\u7f6e [0 0 0 0 0] \u8f74\u5411\u6700\u5927\u503c\u4f4d\u7f6e [2 2 2 2 2] # \u7d2f\u79ef\u548c # [ 1 3 6 10 15 18 22 27 33 40 45 51 58 66 75] # \u8f74\u5411\u7d2f\u79ef\u548c # [[ 1 3 6 10 15] # [ 3 7 12 18 25] # [ 5 11 18 26 35]] # \u7d2f\u79ef\u4e58\u79ef # [ 1 2 6 24 120 360 # 1440 7200 43200 302400 1512000 9072000 # 63504000 508032000 4572288000] # \u8f74\u5411\u7d2f\u79ef\u4e58\u79ef # [[ 1 2 6 24 120] # [ 3 12 60 360 2520] # [ 5 30 210 1680 15120]] \u5e03\u5c14\u503c\u6570\u7ec4(Boolean Array)\u7684\u65b9\u6cd5 \u5e03\u5c14\u503c\u6570\u7ec4\uff0c\u6709\u4e24\u4e2a\u975e\u5e38\u6709\u7528\u7684\u65b9\u6cd5any\u548call\u3002 * any\u68c0\u67e5\u6570\u7ec4\u4e2d\u662f\u5426\u81f3\u5c11\u6709\u4e00\u4e2aTrue\uff0c * all\u68c0\u67e5\u662f\u5426\u6bcf\u4e2a\u503c\u90fd\u662fTrue bools = np.array([False, False, True, False]) print(bools.any()) # True print(bools.all()) # False \u4e0b\u9762\u662f\u4e00\u4e2a\u8fd0\u7528\u5e03\u5c14\u503c\u6570\u7ec4\uff08Boolean Array\uff09\u8fdb\u884c\u6c42\u548c\u7684\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5176\u4e2d (array > 0) \u672c\u8eab\u662f\u4e00\u4e2a\u5e03\u5c14\u578b\u7684\u6570\u7ec4\u3002 array = np.random.randn(100) result = (array > 0).sum() # \u8ba1\u7b97\u6b63\u503c\u7684\u4e2a\u6570 print(result) # 59 \u4e0b\u9762\u662f\u8fd0\u7528\u5e03\u5c14\u503c\u6570\u7ec4\u7684\u751f\u6210\u65b0\u6570\u7ec4\u7684\u4f8b\u5b50\u3002 arr = [[8, 9, 10, 11], [0, 1, 2, 3], [4, 5, 6, 7]] arr = np.array(arr) print(arr.shape) # (3, 4) print(arr) # [[ 8 9 10 11] # [ 0 1 2 3] # [ 4 5 6 7]] idx = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]] idx = np.array(idx) print(idx.shape) # (3, 4) print(idx) # [[1 0 0 0] # [0 1 0 0] # [0 0 1 0]] result = arr[idx] # <class 'numpy.ndarray'> print(result.shape) # (3, 4, 4) print(result) # [[[ 0 1 2 3] # [ 8 9 10 11] # [ 8 9 10 11] # [ 8 9 10 11]] # [[ 8 9 10 11] # [ 0 1 2 3] # [ 8 9 10 11] # [ 8 9 10 11]] # [[ 8 9 10 11] # [ 8 9 10 11] # [ 0 1 2 3] # [ 8 9 10 11]]] result = arr[idx == 1] print(result.shape) print(result) # [8 1 6] \u6392\u5e8f \u548cPython\u7684\u5185\u5efa\u5217\u8868\u7c7b\u578b\u76f8\u4f3c\uff0cNumPy\u6570\u7ec4\u53ef\u4ee5\u4f7f\u7528sort\u65b9\u6cd5\u6309\u4f4d\u7f6e\u6392\u5e8f\u3002 \u9876\u5c42\u7684np.sort\u65b9\u6cd5\u8fd4\u56de\u7684\u662f\u5df2\u7ecf\u6392\u5e8f\u597d\u7684\u6570\u7ec4 \u62f7\u8d1d \uff0c\u800c\u4e0d\u662f\u5bf9\u539f\u6570\u7ec4\u6309\u4f4d\u7f6e\u6392\u5e8f\u3002 array = np.random.randn(6) print(\"\u6837\u672c\u77e9\u9635\", array) array.sort() print(\"\u6392\u5e8f\u540e\u77e9\u9635\", array) # \u6837\u672c\u77e9\u9635 [-0.03119521 0.01839556 0.79238537 -2.46622775 0.62522211 0.22430846] # \u6392\u5e8f\u540e\u77e9\u9635 [-2.46622775 -0.03119521 0.01839556 0.22430846 0.62522211 0.79238537] \u591a\u7ef4\u6570\u7ec4\u4e2d\u6839\u636e\u4f20\u9012\u7684axis\u503c\uff0c\u6cbf\u7740\u8f74\u5411\u5bf9\u6bcf\u4e2a\u4e00\u7ef4\u6570\u636e\u6bb5\u8fdb\u884c\u6392\u5e8f\u3002 array = np.random.randn(5, 3) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) array.sort(1) print(\"\u5bf91\u8f74\u6392\u5e8f\u540e\u77e9\u9635 \\n\", array) # \u6837\u672c\u77e9\u9635 # [[-0.88057833 0.30160954 -2.08788148] # [ 0.27969618 0.62923028 -0.58157581] # [-1.87194465 -1.1102104 1.09589605] # [ 0.1467938 -1.01558304 -0.25905165] # [-0.17294279 0.62369511 0.17947059]] # \u5bf91\u8f74\u6392\u5e8f\u540e\u77e9\u9635 # [[-2.08788148 -0.88057833 0.30160954] # [-0.58157581 0.27969618 0.62923028] # [-1.87194465 -1.1102104 1.09589605] # [-1.01558304 -0.25905165 0.1467938 ] # [-0.17294279 0.17947059 0.62369511]] \u552f\u4e00\u503c\u4e0e\u5176\u4ed6\u96c6\u5408\u903b\u8f91 NumPy\u5305\u542b\u4e00\u4e9b\u9488\u5bf9\u4e00\u7ef4 ndarray \u6570\u7ec4\u7684\u57fa\u7840\u96c6\u5408\u64cd\u4f5c\u3002 np.unique(x, y) \u8ba1\u7b97x\u7684\u552f\u4e00\u503c\uff0c\u5e76\u6392\u5e8f\u3002 names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe']) result = np.unique(names) # NumPy\u5b9e\u73b0 print(result) # ['Bob' 'Joe' 'Will'] result = sorted(set(names)) # \u7eafPython\u5b9e\u73b0 print(result) # ['Bob' 'Joe' 'Will'] inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) result = np.unique(inits) print(result) # [1 2 3 5] np.in1d(x, y) \u8ba1\u7b97x\u4e2d\u7684\u5143\u7d20\u662f\u5426\u5305\u542b\u5728y\u4e2d\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.in1d(inits, [3, 4, 5])) # [ True True True False False False False True True] np.intersect1d(x, y) \uff0c\u8ba1\u7b97x\u548cy\u7684\u4ea4\u96c6\uff0c\u5e76\u6392\u5e8f\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.intersect1d(inits, [3, 4, 5])) # [3 5] np.union1d(x, y) \u8ba1\u7b97x\u548cy\u7684\u5e76\u96c6\uff0c\u5e76\u6392\u5e8f\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.union1d(inits, [3, 4, 5])) # [1 2 3 4 5] np.setdiff1d(x, y) \u5dee\u96c6\uff0c\u5728x\u4e2d\u4f46\u4e0d\u5728y\u4e2d\u7684\u5143\u7d20\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.setdiff1d(inits, [3, 4, 5])) # [1 2] np.setxor1d(x, y) \u5f02\u6216\u96c6\uff0c\u5728x\u6216\u8005y\u4e2d\uff0c\u4f46\u4e0d\u5c5e\u4e8ex\uff0cy\u4ea4\u96c6\u7684\u5143\u7d20\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.setxor1d(inits, [3, 4, 5])) # [1 2 4] \u4f7f\u7528\u6570\u7ec4\u8fdb\u884c\u6587\u4ef6\u8f93\u5165\u548c\u8f93\u51fa NumPy\u53ef\u4ee5\u5728\u786c\u76d8\u4e2d\u5c06\u6570\u636e\u4ee5\u6587\u672c\u6216\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u5f62\u5f0f\u8fdb\u884c\u5b58\u5165\u786c\u76d8\u6216\u7531\u786c\u76d8\u8f7d\u5165\u3002 \u5f53\u524d\u53ea\u5173\u6ce8NumPy\u7684\u5185\u5efa\u4e8c\u8fdb\u5236\u683c\u5f0f\uff0c\u56e0\u4e3a\u5927\u90e8\u5206\u7528\u6237\u66f4\u503e\u5411\u4e8e\u4f7f\u7528pandas\u6216\u5176\u4ed6\u5de5\u5177\u6765\u8f7d\u5165\u6587\u672c\u6216\u8868\u683c\u578b\u6570\u636e\u3002 np.save \u548c np.load \u662f\u9ad8\u6548\u5b58\u53d6\u786c\u76d8\u6570\u636e\u7684\u4e24\u5927\u5de5\u5177\u51fd\u6570\u3002\u6570\u7ec4\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u662f\u4ee5 \u672a\u538b\u7f29 \u7684\u683c\u5f0f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u540e\u7f00\u540d\u662f.npy\u3002 import numpy as np array1 = np.arange(10) array2 = np.arange(15).reshape(3, 5) array3 = np.arange(30).reshape(3, 2, 5) print(array1) # [0 1 2 3 4 5 6 7 8 9] print(array2) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] print(array3) # [[[ 0 1 2 3 4] # [ 5 6 7 8 9]] # [[10 11 12 13 14] # [15 16 17 18 19]] # [[20 21 22 23 24] # [25 26 27 28 29]]] # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myProject/mySite' # \u66f4\u6539\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myProject/mySite/docs/python/datasets/examples') # \u4fdd\u5b58\u5230\u9ed8\u8ba4\u8def\u5f84\u3002npy\u540e\u7f00\u540d\u4f1a\u88ab\u81ea\u52a8\u52a0\u4e0a np.save('some_array', array1) # \u8bfb\u53d6\u6240\u4fdd\u5b58\u7684\u6587\u4ef6 result = np.load('some_array.npy') # \u5bf9\u6bd4\u7ed3\u679c\u4e00\u81f4\u3002 print(result) # [0 1 2 3 4 5 6 7 8 9] # \u5c06\u591a\u4e2a\u6570\u7ec4\u4fdd\u5b58\u5230\u672a\u538b\u7f29\u7684\u5355\u4e2a\u6587\u4ef6\u4e2d\uff0c.npz\u683c\u5f0f np.savez('some_array_archive.npz', a=array2, b=array3) result = np.load('some_array_archive.npz') # reslt\u662f\u4e00\u4e2a\u5b57\u5178\u578b\u7684\u5bf9\u8c61 print(result['b']) # \u8f7d\u5165\u5355\u4e2a\u6570\u7ec4b # [[[ 0 1 2 3 4] # [ 5 6 7 8 9]] # [[10 11 12 13 14] # [15 16 17 18 19]] # [[20 21 22 23 24] # [25 26 27 28 29]]] \u7ebf\u6027\u4ee3\u6570 \u53c2\u8003\u94fe\u63a5\uff1a https://www.numpy.org.cn/reference/routines/linalg.html https://github.com/teadocs/numpy-cn \u5e0c\u814a\u5b57\u6bcd: \u0391 \u03b1 /'\u00e6lf\u0259/ alpha \u0392 \u03b2 /'bi:t\u0259/ beta \u0393 \u03b3 /'g\u00e6m\u0259/ gamma \u0394 \u03b4 /'delt\u0259/ delta \u0395 \u03b5 /'eps\u026al\u0252n/ epsilon \u0396 \u03b6 /'zi:t\u0259/ zeta \u0397 \u03b7 /'i:t\u0259/ eta \u0398 \u03b8 /'\u03b8i:t\u0259/ theta \u0399 \u03b9 /'a\u026a\u0259\u028at\u0259/ iota \u039a \u03ba /'k\u00e6p\u0259/ kappa \u2227 \u03bb /'l\u00e6md\u0259/ lambda \u039c \u03bc /mju:/ mu \u039d \u03bd /nju:/ nu \u039e \u03be /ksi/ xi \u039f \u03bf /\u0259u\u02c8maikr\u0259n/ omicron \u220f \u03c0 /pa\u026a/ pi \u03a1 \u03c1 /r\u0259\u028a/ rho \u2211 \u03c3 /'s\u026a\u0261m\u0259/ sigma \u03a4 \u03c4 /t\u0254:/ tau \u03a5 \u03c5 /\u02c8ips\u026alon/ upsilon \u03a6 \u03c6 /fa\u026a/ phi \u03a7 \u03c7 /ka\u026a/ chi \u03a8 \u03c8 /psa\u026a/ psi \u03a9 \u03c9 /'\u0259\u028am\u026a\u0261\u0259/ omega numpy.linalg \u6a21\u5757\u5305\u542b\u7ebf\u6027\u4ee3\u6570\u7684\u51fd\u6570\u3002\u4f7f\u7528\u8fd9\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u8ba1\u7b97\u9006\u77e9\u9635\u3001\u6c42\u7279\u5f81\u503c\u3001\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u4ee5\u53ca\u6c42\u89e3\u884c\u5217\u5f0f\u7b49\u3002 import numpy as np from numpy import linalg as LA from numpy import * from numpy.linalg import inv import matplotlib.pyplot as plt diag np.diag \u5c06\u4e00\u4e2a\u65b9\u9635\u7684\u5bf9\u89d2\uff08\u6216\u975e\u5bf9\u89d2\uff09\u5143\u7d20\u4f5c\u4e3a\u4e00\u7ef4\u6570\u7ec4\u8fd4\u56de\uff0c\u6216\u8005\u5c06\u4e00\u7ef4\u6570\u7ec4\u8f6c\u6362\u6210\u4e00\u4e2a\u65b9\u9635\uff0c\u5e76\u4e14\u5728\u975e\u5bf9\u89d2\u7ebf\u4e0a\u6709\u96f6\u70b9\u3002 a1 = np.arange(9, dtype=float).reshape((3, 3)) r1 = np.diag(a1) r2 = np.diag(a1, k=1) r3 = np.diag(a1, k=-1) r4 = np.diag(np.diag(a1)) # \u5bf9\u89d2\u77e9\u9635 print(\"\u6837\u672c\u77e9\u9635 \\n\", a1) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\", r1) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0a\u504f\u79fb\", r2) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0b\u504f\u79fb\", r3) print(\"\u5bf9\u89d2\u77e9\u9635 \\n\", r4) # \u6837\u672c\u77e9\u9635 # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] # \u77e9\u9635\u5bf9\u89d2\u7ebf [0. 4. 8.] # \u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0a\u504f\u79fb [1. 5.] # \u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0b\u504f\u79fb [3. 7.] # \u5bf9\u89d2\u77e9\u9635 # [[0. 0. 0.] # [0. 4. 0.] # [0. 0. 8.]] dot np.dot \u5c06\u5411\u91cf\u4e2d\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0c\u518d\u76f8\u52a0\u6240\u5f97\u3002\u5373\u666e\u901a\u7684\u5411\u91cf\u4e58\u6cd5\u8fd0\u7b97\uff0c\u6216 \u77e9\u9635\u70b9\u4e58 \u3002 a1 = np.dot(3, 4) print(a1) # 12 a2 = np.arange(9, dtype=float).reshape((3, 3)) r2 = np.dot(a2, a2) print(a2) # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] print(r2) # [[ 15. 18. 21.] # [ 42. 54. 66.] # [ 69. 90. 111.]] r3 = np.dot([2j, 3j], [2j, 3j]) print(r3) # (-13+0j) trace np.trace \u8ba1\u7b97\u5bf9\u89d2\u5143\u7d20\u548c\u3002 a1 = np.arange(9, dtype=float).reshape((3, 3)) print(\"\u6837\u672c\u77e9\u9635 \\n\", a1) r1 = np.trace(a1) print(\"\u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c\", r1) a2 = np.arange(24, dtype=float).reshape((2, 3, 4)) r2 = np.trace(a2) print(\"\u6837\u672c\u77e9\u9635 \\n\", a2) print(\"\u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c\", r2) # \u6837\u672c\u77e9\u9635 # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] # \u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c 12.0 # \u6837\u672c\u77e9\u9635 # [[[ 0. 1. 2. 3.] # [ 4. 5. 6. 7.] # [ 8. 9. 10. 11.]] # # [[12. 13. 14. 15.] # [16. 17. 18. 19.] # [20. 21. 22. 23.]]] # \u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c [16. 18. 20. 22.] det np.det \u8ba1\u7b97\u77e9\u9635\u7684\u884c\u5217\u5f0f\uff08\u65b9\u9635\uff09\u3002 \u4e8c\u9636\u884c\u5217\u5f0f[[a, b], [c, d]]\u7684\u503c\u662fad - bc \u4e09\u9636\u884c\u5217\u5f0f [[a, b, c], [d, e, f], [g, h, i]]\u7684\u503c\u662f aei + bfd + cdh - ceg - bdi - afh \u4e09\u9636\u884c\u5217\u5f0f\u7684\u6027\u8d28 \u6027\u8d281\uff1a\u884c\u5217\u5f0f\u4e0e\u5b83\u7684\u8f6c\u7f6e\u884c\u5217\u5f0f\u76f8\u7b49\u3002 \u6027\u8d282\uff1a\u4e92\u6362\u884c\u5217\u5f0f\u7684\u4e24\u884c(\u5217)\uff0c\u884c\u5217\u5f0f\u53d8\u53f7\u3002 \u63a8\u8bba\uff1a\u5982\u679c\u884c\u5217\u5f0f\u6709\u4e24\u884c(\u5217)\u5b8c\u5168\u76f8\u540c\uff0c\u5219\u6b64\u884c\u5217\u5f0f\u4e3a\u96f6\u3002 \u6027\u8d283\uff1a\u884c\u5217\u5f0f\u7684\u67d0\u4e00\u884c(\u5217)\u4e2d\u6240\u6709\u7684\u5143\u7d20\u90fd\u4e58\u4ee5\u540c\u4e00\u6570k\uff0c\u7b49\u4e8e\u7528\u6570k\u4e58\u6b64\u884c\u5217\u5f0f\u3002 \u63a8\u8bba\uff1a\u884c\u5217\u5f0f\u4e2d\u67d0\u4e00\u884c(\u5217)\u7684\u6240\u6709\u5143\u7d20\u7684\u516c\u56e0\u5b50\u53ef\u4ee5\u63d0\u5230\u884c\u5217\u5f0f\u7b26\u53f7\u7684\u5916\u9762\u3002 \u6027\u8d284\uff1a\u884c\u5217\u5f0f\u4e2d\u5982\u679c\u6709\u4e24\u884c(\u5217)\u5143\u7d20\u6210\u6bd4\u4f8b\uff0c\u5219\u6b64\u884c\u5217\u5f0f\u7b49\u4e8e\u96f6\u3002 \u6027\u8d285\uff1a\u628a\u884c\u5217\u5f0f\u7684\u67d0\u4e00\u5217(\u884c)\u7684\u5404\u5143\u7d20\u4e58\u4ee5\u540c\u4e00\u6570\u7136\u540e\u52a0\u5230\u53e6\u4e00\u5217(\u884c)\u5bf9\u5e94\u7684\u5143\u7d20\u4e0a\u53bb\uff0c\u884c\u5217\u5f0f\u4e0d\u53d8\u3002 a1 = np.array([[1, 2], [3, 4]]) r1 = np.linalg.det(a1) print(\"\u4e8c\u9636\u65b9\u9635 \\n\", a1) print(\"\u4e8c\u9636\u884c\u5217\u5f0f\u7684\u503c\", r1) # \u4e8c\u9636\u65b9\u9635 # [[1 2] # [3 4]] # \u4e8c\u9636\u884c\u5217\u5f0f\u7684\u503c -2.0000000000000004 # \u5e0c\u814a\u5b57\u6bcd # \u03b1, \u03b2, \u03b3,\u03b4, \u03b5, \u03b6, \u03b7, \u03b8, \u03b9, \u03ba, \u03bb, \u03bc, \u03bd, # \u03be, \u03bf, \u03c0, \u03c1, \u03c2, \u03c3, \u03c4, \u03c5, \u03c6, \u03c7, \u03c8, \u03c9, a2 = np.arange(9).reshape(3, 3) r2 = np.linalg.det(a2) print(\"\u4e09\u9636\u65b9\u9635 \\n\", a2) print(\"\u4e09\u9636\u884c\u5217\u5f0f\u7684\u503c\", r2) # \u4e09\u9636\u65b9\u9635 # [[0 1 2] # [3 4 5] # [6 7 8]] # \u4e09\u9636\u884c\u5217\u5f0f\u7684\u503c 0.0 a3 = np.arange(16).reshape(4, 4) r3 = np.linalg.det(a3) print(\"\u56db\u9636\u65b9\u9635 \\n\", a3) print(\"\u56db\u9636\u884c\u5217\u5f0f\u7684\u503c\", r3) # \u56db\u9636\u65b9\u9635 # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]# \u5e0c\u814a\u5b57\u6bcd # \u03b1, \u03b2, \u03b3,\u03b4, \u03b5, \u03b6, \u03b7, \u03b8, \u03b9, \u03ba, \u03bb, \u03bc, \u03bd, # \u03be, \u03bf, \u03c0, \u03c1, \u03c2, \u03c3, \u03c4, \u03c5, \u03c6, \u03c7, \u03c8, \u03c9, # [12 13 14 15]] # \u56db\u9636\u884c\u5217\u5f0f\u7684\u503c 0.0 eig np.eig \u8ba1\u7b97\u65b9\u9635\u7684\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\u3002 \u7279\u5f81\u503c\u4e0e\u7279\u5f81\u5411\u91cf\u7684\u5b9a\u4e49\uff1a\u8bbeA\u662fn\u9636\u65b9\u9635\uff0c\u82e5\u6570\u03bb\u548cn\u7ef4\u975e\u96f6\u5217\u5411\u91cfx\uff0c\u4f7f\u5f97Ax = \u03bbx\u6210\u7acb\uff0c\u5219\u79f0\u03bb\u662f\u65b9\u9635A\u7684\u4e00\u4e2a\u7279\u5f81\u503c\uff0cx\u4e3a\u65b9\u9635A\u7684\u5bf9\u5e94\u4e8e\u7279\u5f81\u503c\u03bb\u7684\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\u3002 A\u662f\u65b9\u9635\u3002\uff08\u5bf9\u4e8e\u975e\u65b9\u9635\uff0c\u662f\u6ca1\u6709\u7279\u5f81\u503c\u7684\uff0c\u4f46\u4f1a\u6709\u6761\u4ef6\u6570\u3002\uff09\u7279\u5f81\u5411\u91cfx\u4e3a\u975e\u96f6\u5217\u5411\u91cf\u3002 v_eigenvectors, v_eigenvalues = LA.eig(np.diag((1, 2, 3))) print(\"\u7279\u5f81\u5411\u91cf\", v_eigenvectors) print(\"\u7279\u5f81\u503c \\n\", v_eigenvalues) # \u7279\u5f81\u5411\u91cf [1. 2. 3.] # \u7279\u5f81\u503c # [[1. 0. 0.] # [0. 1. 0.] # [0. 0. 1.]] v_eigenvectors, v_eigenvalues = LA.eig(np.array([[1, -1], [1, 1]])) print(\"\u7279\u5f81\u5411\u91cf\", v_eigenvectors) print(\"\u7279\u5f81\u503c \\n\", v_eigenvalues) # \u7279\u5f81\u5411\u91cf [1.+1.j 1.-1.j] # \u7279\u5f81\u503c # [[0.70710678+0.j 0.70710678-0.j ] # [0. -0.70710678j 0. +0.70710678j]] inv np.inv \u8ba1\u7b97\u65b9\u9635\u7684\u9006\u77e9\u9635\u3002 a1 = np.array([[1, 2], [3, 4]]) r1 = inv(a1) r2 = inv(np.matrix(a1)) print(\"\u539f\u77e9\u9635 \\n\", a1) print(\"\u9006\u77e9\u9635 \\n\", r1) print(\"\u9006\u77e9\u9635 \\n\", r2) # \u539f\u77e9\u9635 # [[1 2] # [3 4]] # \u9006\u77e9\u9635 # [[-2. 1. ] # [ 1.5 -0.5]] # \u9006\u77e9\u9635 # [[-2. 1. ] # [ 1.5 -0.5]] pinv np.pinv \u8ba1\u7b97\u77e9\u9635\u7684Moore-Penrose\u4f2a\u9006(\u6469\u5c14\uff0d\u5f6d\u82e5\u65af\u5e7f\u4e49\u9006)\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u68c0\u9a8c a * a+ * a == a \u548c a+ * a * a+ == a+ a = np.random.randn(9, 6) B = np.linalg.pinv(a) r1 = np.allclose(a, np.dot(a, np.dot(B, a))) r2 = np.allclose(B, np.dot(B, np.dot(a, B))) print(a) print(B) print(r1) # True print(r2) # True # a: # [[-2.30316101 -0.63217332 1.24134743 -0.72492307 0.12456801 -0.14192548] # [ 1.37573495 0.07626697 -0.71870843 1.26824984 -0.79485727 -0.24630455] # [ 0.29003175 -1.23931665 -0.50864107 -0.31140718 0.45467649 -2.44973999] # [-0.70748664 -1.2995059 0.85126149 -1.10918804 -2.10042342 0.75942293] # [ 1.91765238 1.23892103 1.58516486 -1.65520154 0.11894439 0.84536298] # [ 1.03220791 0.1715148 0.85595408 0.58569706 1.34066384 -1.5782386 ] # [-0.54432889 -0.0114189 1.55403934 0.89852512 1.15586365 -0.30733805] # [-0.80874673 0.14602121 1.04680044 1.98722514 0.39766383 0.75178788] # [ 0.01664663 0.06243353 -0.50725334 -0.37707204 -1.76701091 -0.33866559]] # B: # [[-0.25055838 0.13963115 0.08990923 0.16280282 0.12997291 0.05088469 -0.01541299 -0.01656133 -0.21731387] # [ 0.22862622 -0.05108109 -0.2639602 -0.47835978 0.11776862 0.09324694 0.00436756 -0.00609393 0.61995597] # [ 0.10422554 0.03985857 0.00198025 0.15139023 0.17165026 0.15697725 0.17360246 0.13150089 0.08378135] # [-0.07021378 0.17665487 -0.04109252 0.0015022 -0.11998477 0.0543575 0.08649033 0.21190785 0.04065729] # [-0.08110336 -0.15274536 0.05601496 -0.07967802 -0.02454705 -0.04152356 0.00071268 -0.05981012 -0.43996066] # [-0.17998537 -0.03160871 -0.12587707 0.16856246 0.00565094 -0.21038026 -0.06060039 0.04322126 -0.42038066]] qr np.qr \u8ba1\u7b97QR\u5206\u89e3\u3002QR\uff08\u6b63\u4ea4\u4e09\u89d2\uff09\u5206\u89e3\u6cd5\u662f\u6c42\u4e00\u822c\u77e9\u9635\u5168\u90e8\u7279\u5f81\u503c\u7684\u6700\u6709\u6548\u5e76\u5e7f\u6cdb\u5e94\u7528\u7684\u65b9\u6cd5\u3002 \u4e00\u822c\u77e9\u9635\u5148\u7ecf\u8fc7\u6b63\u4ea4\u76f8\u4f3c\u53d8\u5316\u6210\u4e3aHessenberg\u77e9\u9635\uff0c\u7136\u540e\u518d\u5e94\u7528QR\u65b9\u6cd5\u6c42\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\u3002QR\u5206\u89e3\u6cd5\u662f\u5c06\u77e9\u9635\u5206\u89e3\u6210\u4e00\u4e2a\u6b63\u89c4\u6b63\u4ea4\u77e9\u9635Q\u4e0e\u4e0a\u4e09\u89d2\u5f62\u77e9\u9635R\uff0c\u6240\u4ee5\u79f0\u4e3aQR\u5206\u89e3\u6cd5\u3002 a = np.arange(9).reshape(3, 3) q, r = np.linalg.qr(a) print(\"\u539f\u77e9\u9635 \\n\", a) print(\"\u6b63\u4ea4\u77e9\u9635 \\n\", q) print(\"\u4e0a\u4e09\u89d2\u77e9\u9635 \\n\", r) # \u539f\u77e9\u9635 # [[0 1 2] # [3 4 5] # [6 7 8]] # \u6b63\u4ea4\u77e9\u9635 # [[ 0. 0.91287093 0.40824829] # [-0.4472136 0.36514837 -0.81649658] # [-0.89442719 -0.18257419 0.40824829]] # \u4e0a\u4e09\u89d2\u77e9\u9635 # [[-6.70820393e+00 -8.04984472e+00 -9.39148551e+00] # [ 0.00000000e+00 1.09544512e+00 2.19089023e+00] # [ 0.00000000e+00 0.00000000e+00 -8.88178420e-16]] svd np.svd \u8ba1\u7b97\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u3002 \u51e0\u4f55\u610f\u4e49\uff1aSVD\u5206\u89e3\u7684\u51e0\u4f55\u610f\u4e49\u662f\u4efb\u4f55\u4e00\u4e2a\u77e9\u9635A\u5728\u4e00\u7cfb\u5217\u65cb\u8f6c\u548c\u5e73\u79fb\u4e0b\u90fd\u80fd\u8f6c\u5316\u6210\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\u2211 , \u5176\u4e2d\u9149\u9635U, V\u7684\u51e0\u4f55\u610f\u4e49\u5c31\u662f\u4e00\u7cfb\u5217\u65cb\u8f6c\u548c\u5e73\u79fb\u7684\u53e0\u52a0\u3002 a = mat([[1, 2, 3],[4, 5, 6]]) U, sigma, V = np.linalg.svd(a) print(\"\u539f\u77e9\u9635 \\n\", a) print(\"\u5de6\u5947\u5f02\u503cU \\n\", U) print(\"\u5947\u5f02\u503cSigma \\n\", sigma) print(\"\u53f3\u5947\u5f02\u503cV \\n\", V) # \u539f\u77e9\u9635 # [[1 2 3] # [4 5 6]] # \u5de6\u5947\u5f02\u503cU # [[-0.3863177 -0.92236578] # [-0.92236578 0.3863177 ]] # \u5947\u5f02\u503cSigma # [9.508032 0.77286964] # \u53f3\u5947\u5f02\u503cV # [[-0.42866713 -0.56630692 -0.7039467 ] # [ 0.80596391 0.11238241 -0.58119908] # [ 0.40824829 -0.81649658 0.40824829]] solve np.solve \u6c42\u89e3x\u7684\u7ebf\u6027\u7cfb\u7edfAx = b\uff0c\u5176\u4e2dA\u662f\u65b9\u9635\u3002 \u89e3\u65b9\u7a0b\u7ec4\uff1a x + 2y = 1 3x + 5y = 2 a = np.array([[1, 2], [3, 5]]) b = np.array([1, 2]) x = np.linalg.solve(a, b) print(x) # [-1. 1.] lstsq np.lstsq \u8ba1\u7b97Ax = b\u7684\u6700\u5c0f\u4e8c\u4e58\u89e3\u3002 \u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u62df\u5408\u6570\u636e\u5f97\u5230\u4e00\u4e2a\u5f62\u5982y = mx + c\u7684\u7ebf\u6027\u65b9\u7a0b\uff08Return the least-squares solution to a linear matrix equation\uff09\u3002 x = np.array([0, 1, 2, 3]) # \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807 y = np.array([-1, 0.2, 0.9, 2.1]) # \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807 print(x) # [0 1 2 3] print(y) # [-1. 0.2 0.9 2.1] A = np.vstack([x, np.ones(len(x))]).T # \u6784\u9020\u7cfb\u6570\u77e9\u9635 print(A) # [[0. 1.] # [1. 1.] # [2. 1.] # [3. 1.]] m, c = np.linalg.lstsq(A, y, rcond=None)[0] # \u89e3\u51fa\u659c\u7387a\u548c\u7eb5\u622a\u8dddc plt.plot(x, y, 'o', label='Original data', markersize=10) # \u505a\u51fa\u539f\u59cb\u6570\u636e\u6563\u70b9\u56fe plt.plot(x, m*x + c, 'r', label='Fitted line') # \u7528\u4e0a\u9762\u89e3\u51fa\u7684\u53c2\u6570\u505a\u51fa\u62df\u5408\u66f2\u7ebfy=mx+c plt.legend() plt.show() \u4f2a\u968f\u673a\u6570\u751f\u6210 numpy.random \u6a21\u5757\u586b\u8865\u4e86Python\u5185\u5efa\u7684 random \u6a21\u5757\u7684\u4e0d\u8db3\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u751f\u6210\u591a\u79cd\u6982\u7387\u5206\u5e03\u4e0b\u7684\u5b8c\u6574\u6837\u672c\u503c\u6570\u7ec4\u3002 numpy.random \u4e2d\u7684\u6570\u636e\u751f\u6210\u51fd\u6570\u516c\u7528\u4e86\u4e00\u4e2a\u5168\u5c40\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002 \u4f7f\u7528 numpy.random.RandomState \u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u4f7f\u6570\u636e\u72ec\u7acb\u4e8e\u5176\u4ed6\u7684\u968f\u673a\u6570\u72b6\u6001\u3002 \u901a\u8fc7 np.random.seed \u66f4\u6539NumPy\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002 numpy.random \u4e2d\u7684\u90e8\u5206\u51fd\u6570\u5217\u8868 seed: \u5411\u968f\u673a\u6570\u751f\u6210\u5668\u4f20\u9012\u968f\u673a\u72b6\u6001\u79cd\u5b50 permutation: \u8fd4\u56de\u4e00\u4e2a\u5e8f\u5217\u7684\u968f\u673a\u6392\u5217\uff0c\u6216\u8005\u8fd4\u56de\u4e00\u4e2a\u4e71\u5e8f\u7684\u6574\u6570\u8303\u56f4\u5e8f\u5217 shuffle: \u968f\u673a\u6392\u5217\u4e00\u4e2a\u5e8f\u5217 rand: \u4ece\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c randint: \u6839\u636e\u7ed9\u5b9a\u7684\u7531\u4f4e\u5230\u9ad8\u7684\u8303\u56f4\u62bd\u53d6\u968f\u673a\u6574\u6570 randn: \u4ece\u5747\u503c0\u65b9\u5dee1\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c(MATLAB\u578b\u63a5\u53e3\uff09 binomial: \u4ece\u4e8c\u9879\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c normal: \u4ece\u6b63\u6001\uff08\u9ad8\u65af\uff09\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c beta\u4ecebeta: \u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c chisquare: \u4ece\u5361\u65b9\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c \u4f8b\u5982\uff0c\u4f7f\u7528normal\u6765\u83b7\u5f97\u4e00\u4e2a4\u00d74\u7684\u6b63\u6001\u5206\u5e03\u6837\u672c\u6570\u7ec4\uff0c\u79f0\u4e3a\u4f2a\u968f\u673a\u6570\u3002 import numpy as np samples = np.random.normal(size=(4, 4)) print(samples) # [[ 0.78583658 -0.27462104 -0.53027675 -0.62675004] # [ 0.39054781 1.20503691 -0.0057432 0.17243182] # [-0.41516669 -0.93335854 0.01996088 -0.12707275] # [ 0.42952379 2.56998319 0.14848737 -0.42871493]] \u793a\u4f8b\uff1a\u968f\u673a\u6f2b\u6b65 import matplotlib.pyplot as plt import numpy as np position = 0 walk = [position] nwalks = 5000 nsteps = 1000 draws = np.random.randint(0, 2, size=(nwalks, nsteps)) steps = np.where(draws > 0, 1, -1) walks = steps.cumsum() plt.plot(walks[:500000000000000000000000000]) plt.show() \u8f93\u51fa\u56fe\u50cf\uff1a","title":"NumPy\u57fa\u7840"},{"location":"python/DataAnalysis/ch01/#numpy","text":"\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a \u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61 \u901a\u7528\u51fd\u6570 \u9762\u5411\u6570\u7ec4\u7f16\u7a0b \u4f7f\u7528\u6570\u7ec4\u8fdb\u884c\u6587\u4ef6\u8f93\u5165\u548c\u8f93\u51fa \u7ebf\u6027\u4ee3\u6570 \u4f2a\u968f\u673a\u6570\u751f\u6210 \u793a\u4f8b\uff1a\u968f\u673a\u6f2b\u6b65","title":"NumPy\u57fa\u7840"},{"location":"python/DataAnalysis/ch01/#ndarry","text":"","title":"\u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61ndarry"},{"location":"python/DataAnalysis/ch01/#_1","text":"import numpy as np import pandas as pd import matplotlib.pyplot as plt","title":"\u522b\u540d\u7ea6\u5b9a"},{"location":"python/DataAnalysis/ch01/#matplotlib","text":"\u67e5\u770b\u5b57\u4f53\u8def\u5f84 >>> import matplotlib >>> print(matplotlib.matplotlib_fname()) /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc \u4e0b\u8f7d\u4e2d\u6587\u5b57\u4f53\u3002\u7f51\u5740 https://www.fontpalace.com/font-download/SimHei/,\u5e76\u62f7\u8d1d\u5230\u4e0b\u9762\u7684\u8def\u5f84\u4e0b james@lizard:~/Downloads> cp SimHei.ttf /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/ \u67e5\u770bmatplotlib\u7684\u5b57\u4f53\u7f13\u5b58\u76ee\u5f55\u3002 >>> import matplotlib >>> print(matplotlib.get_cachedir()) /home/james/.cache/matplotlib \u5220\u9664\u8fd9\u4e2a\u76ee\u5f55 james@lizard:~> rm -rf /home/james/.cache/matplotlib \u7f16\u8f91matplotlibrc\u6587\u4ef6 /home/james/.local/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc \uff0c\u505a\u5982\u4e0b\u4fee\u6539\u3002 \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # font.family: sans-serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u6dfb\u52a0 SimHei \uff0c\u4fee\u6539\u540e\u4e3a font.serif: SimHei, DejaVu Serif, Bitstream Vera Serif, Computer Modern Roman, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u6dfb\u52a0 SimHei \uff0c\u4fee\u6539\u540e\u4e3a font.sans-serif: SimHei, DejaVu Sans, Bitstream Vera Sans, Computer Modern Sans Serif, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif \u5b9a\u4f4d\u8fd9\u4e00\u884c\uff0c\u53bb\u6389\u6ce8\u91ca\u7b26 # \uff0c\u5e76\u628a True \u6539\u4e3a False \uff0c\u4fee\u6539\u540e\u4e3a axes.unicode_minus: False","title":"\u5b89\u88c5matplotlib\u4e2d\u6587\u5b57\u4f53"},{"location":"python/DataAnalysis/ch01/#matplotlib_1","text":"\u5728\u4f7f\u7528matplotlib\u8f93\u51fa\u56fe\u50cf\u65f6\uff0c\u5982\u679c\u9047\u5230\u65e0\u6cd5\u663e\u793a\u56fe\u50cf\u7684\u9519\u8bef UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure\u3002 \uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4e0b\u9762\u7684\u6b65\u9aa4\u89e3\u51b3\u3002 \u5b89\u88c5 python3-tk \u5305 james@lizard:~> sudo zypper in python3-tk \u6216\u8005\u901a\u8fc7 pip \u5b89\u88c5 tk \u5305 james@lizard:~> pip3 install tk Defaulting to user installation because normal site-packages is not writeable Collecting tk Downloading tk-0.1.0-py3-none-any.whl (3.9 kB) Installing collected packages: tk Successfully installed tk-0.1.0 \u4e00\u822c\u5b8c\u6210\u4e0a\u9762\u5b89\u88c5\u540e\uff0c\u7a0b\u5e8f\u5c31\u80fd\u81ea\u52a8\u663e\u793a\u56fe\u4e86\uff0c\u5982\u679c\u8fd8\u662f\u4e0d\u80fd\u663e\u793a\uff0c\u518d\u5c1d\u8bd5\u91cd\u65b0\u5b89\u88c5 matplotlib \u3002 pip3 ininstall matplotlib pip3 install matplotlib","title":"\u8bbe\u7f6ematplotlib\u540e\u7aef\u6e32\u67d3\u5668"},{"location":"python/DataAnalysis/ch01/#ndarray-n-","text":"\u4e00\u4e2andarray\u662f\u4e00\u4e2a\u901a\u7528\u7684\u591a\u7ef4\u540c\u7c7b\u6570\u636e\u5bb9\u5668\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u5305\u542b\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u5747\u4e3a \u76f8\u540c\u7c7b\u578b \uff1b \u6bcf\u4e00\u4e2a\u6570\u7ec4\u90fd\u6709\u4e00\u4e2ashape\u5c5e\u6027\uff0c\u7528\u6765\u8868\u5f81\u6570\u7ec4\u6bcf\u4e00\u7ef4\u5ea6\u7684\u6570\u91cf\uff1b \u6bcf\u4e00\u4e2a\u6570\u7ec4\u90fd\u6709\u4e00\u4e2adtype\u5c5e\u6027\uff0c\u7528\u6765\u63cf\u8ff0\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\uff1b \u4e0b\u9762\u662f\u6807\u51c6\u6570\u7ec4\u7684\u751f\u6210\u51fd\u6570 array: \u5c06\u8f93\u5165\u6570\u636e\uff08\u5217\u8868\u3001\u5143\u7ec4\u3001\u6570\u7ec4\uff0c\u5176\u4ed6\u5e8f\u5217\uff09\u8f6c\u6362\u4e3andarray\uff0c\u5982\u679c\u4e0d\u663e\u5f0f\u6307\u660e\u6570\u636e\u7c7b\u578b\uff0c\u5c06\u81ea\u52a8\u63a8\u65ad\uff1b\u9ed8\u8ba4\u590d\u5236\u6240\u6709\u7684\u8f93\u5165\u6570\u636e\u3002 asarray\uff1a\u5c06\u8f93\u5165\u8f6c\u6362\u4e3andarray\uff0c\u4f46\u5982\u679c\u8f93\u5165\u5df2\u7ecf\u662fndarray\u5219\u4e0d\u518d\u590d\u5236\u3002 arange\uff1aPython\u5185\u7f6e\u51fd\u6570range\u7684\u6570\u7ec4\u7248\uff0c\u8fd4\u56de\u4e00\u4e2a\u6570\u7ec4\u3002 \u4e0b\u9762\u662f\u7528 Numpy.random() \u4e00\u4e2a\u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\u7ec4\u7684\u4f8b\u5b50\uff0c\u6ce8\u610f data01 \u7684\u7c7b\u578b\u662f'numpy.ndarray'\u3002\u53ef\u4ee5\u5728ndarray\u7c7b\u578b\u6570\u7ec4\u4e0a\u53e0\u52a0\u4e00\u4e0b\u6570\u5b66\u64cd\u4f5c\u3002 data01 = np.random.randn(2, 3) print(type(data01)) # <class 'numpy.ndarray'> print(data01) # [[ 0.12047302 -1.13499045 -0.39311368] # [ 1.54046881 0.01254838 -3.65090952]] print(data01 * 10) # \u7ed9data\u52a0\u4e0a\u4e00\u4e2a\u6570\u5b66\u64cd\u4f5c, \u6240\u6709\u7684\u5143\u7d20\u90fd\u540c\u65f6\u4e58\u4ee5\u4e8610 # [[ 1.20473022 -11.3499045 -3.93113676] # [ 15.40468806 0.12548383 -36.50909515]] print(data01 + data01) # \u7ed9data\u52a0\u4e0a\u4e00\u4e2a\u6570\u5b66\u64cd\u4f5c, \u6570\u7ec4\u4e2d\u7684\u5bf9\u5e94\u5143\u7d20\u8fdb\u884c\u4e86\u76f8\u52a0 # [[ 0.24094604 -2.2699809 -0.78622735] # [ 3.08093761 0.02509677 -7.30181903]] print(data01.shape) # (2, 3) print(data01.dtype) # float64 \u5f53\u8868\u8fbe\u201c\u6570\u7ec4\u201d\u3001\u201cNumPy\u6570\u7ec4\u201d\u6216\u201cndarray\u201d\u65f6\uff0c\u90fd\u8868\u793a\u540c\u4e00\u4e2a\u5bf9\u8c61\uff1andarray\u5bf9\u8c61\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a data01 \u662f\u4e00\u4e2a\u5217\u8868\uff08list\uff09\u7c7b\u578b\uff0c\u901a\u8fc7 Numpy.array \u8f6c\u6362\u6210Numpy\u7684 ndarray \u7c7b\u578b\u3002 \u5728 np.array \u4e2d\uff0c\u9664\u975e\u663e\u5f0f\u5730\u6307\u5b9a\uff0c\u5982 np.array(data01, dtype=np.int8) \uff0c\u5426\u5219np.array\u4f1a\u81ea\u52a8\u63a8\u65ad\u751f\u6210\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b array01.dtype \u3002 \u4f7f\u7528 astype() \u65b9\u6cd5\u663e\u5f0f\u5730\u8f6c\u6362\u6570\u7ec4\u7684\u6570\u636e\u7c7b\u578b\u3002\u4f7f\u7528 astype() \u65f6\u603b\u662f\u751f\u6210\u4e00\u4e2a \u65b0\u7684\u6570\u7ec4 \uff0c\u5373\u4f7f\u4f60\u4f20\u5165\u7684dtype\u4e0e\u4e4b\u524d\u4e00\u6837\u3002 data02 \u662f\u4e00\u4e2a\u5d4c\u5957\u5217\u8868 [[1, 2, 3, 4], [5, 6, 7, 8]] \uff0c\u901a\u8fc7np.array()\u65b9\u6cd5\u8f6c\u6362\u6210\u591a\u7ef4\u6570\u7ec4\uff0c\u524d\u63d0\u662f\u6bcf\u4e2a\u5b50\u5217\u8868\u7684\u957f\u5ea6\u8981\u4e00\u81f4\u3002 data01 = [6, 7.5, 8, 0, 1] print(data01) # [6, 7.5, 8, 0, 1] print(type(data01)) # <class 'list'> array01 = np.array(data01) print(\"\u77e9\u9635\u7c7b\u578b\", type(array01)) # \u77e9\u9635\u7c7b\u578b <class 'numpy.ndarray'> print(\"\u6837\u672c\u77e9\u9635\", array01) # \u6837\u672c\u77e9\u9635 [6. 7.5 8. 0. 1. ] print(\"\u6570\u7ec4\u7ef4\u5ea6\", array01.ndim) # \u6570\u7ec4\u7ef4\u5ea6 1 print(\"\u77e9\u9635\u5f62\u72b6\", array01.shape) # \u77e9\u9635\u5f62\u72b6 (5,) \u4e00\u884c\u4e94\u5217 print(\"\u77e9\u9635\u6570\u636e\u7c7b\u578b\", array01.dtype) # float64 data02 = [[1, 2, 3, 4], [5, 6, 7, 8]] array02 = np.array(data02) print(\"\u6837\u672c\u77e9\u9635\\n\", array02) # \u6837\u672c\u77e9\u9635 # [[1 2 3 4] # [5 6 7 8]] print(\"\u6570\u7ec4\u7ef4\u5ea6\", array02.ndim) # \u6570\u7ec4\u7ef4\u5ea6 2 print(\"\u77e9\u9635\u5f62\u72b6\", array02.shape) # \u77e9\u9635\u5f62\u72b6 (2, 4) print(\"\u77e9\u9635\u6570\u636e\u7c7b\u578b\", array02.dtype) # \u77e9\u9635\u6570\u636e\u7c7b\u578b int64 print(\"\u77e9\u96350\u8f74\u5411\u6c42\u548c\", array02.sum(axis=0)) # \u77e9\u96350\u8f74\u5411\u6c42\u548c [ 6 8 10 12] print(\"\u77e9\u96351\u8f74\u5411\u6c42\u548c\", array02.sum(axis=1)) # \u77e9\u96351\u8f74\u5411\u6c42\u548c [10 26] array03 = array02.astype(np.float64) print(array03.dtype) # float64 print(array03) # [[1. 2. 3. 4.] # [5. 6. 7. 8.]] zeros() \u65b9\u6cd5\u53ef\u4ee5\u4e00\u6b21\u6027\u521b\u9020\u51680\u6570\u7ec4\u3002 print(np.zeros(10)) # [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ones() \u65b9\u6cd5\u53ef\u4ee5\u4e00\u6b21\u6027\u521b\u9020\u51681\u6570\u7ec4\u3002\u6ce8\u610f\uff0c\u4f20\u53c2shape\u662f\u4e00\u4e2a\u5143\u7ec4 (3, 5) \u3002 print(np.ones((3, 5))) # [[1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.]] empty() \u65b9\u6cd5\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u6ca1\u6709\u521d\u59cb\u5316\u6570\u503c\u7684\u6570\u7ec4\u3002\u4f46\u662f\uff0c\u4f7f\u7528np.empty\u6765\u751f\u6210\u4e00\u4e2a\u51680\u6570\u7ec4\uff0c\u5e76\u4e0d\u53ef\u9760\uff0c\u6709\u4e9b\u65f6\u5019\u5b83\u53ef\u80fd\u4f1a\u8fd4\u56de\u672a\u521d\u59cb\u5316\u7684\u5783\u573e\u6570\u503c print(np.empty((2, 3, 2))) # [[[2.30116964e-316 0.00000000e+000] # [2.10077583e-312 6.79038654e-313] # [2.22809558e-312 2.14321575e-312]] # # [[2.35541533e-312 6.79038654e-313] # [2.22809558e-312 2.14321575e-312] # [2.46151512e-312 2.41907520e-312]]]","title":"ndarray: N-\u7ef4\u6570\u7ec4\u5bf9\u8c61"},{"location":"python/DataAnalysis/ch01/#numpy_1","text":"\u4e00\u53e5\u8bdd\u603b\u7ed3\uff1a\u5c06NumPy\u8f74\u89c6\u4e3a\u6211\u4eec\u53ef\u4ee5\u6267\u884c\u64cd\u4f5c\u7684\u65b9\u5411\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a arr_1 = np.array([[1, 1, 1], [1, 1, 1]]) arr_2 = np.array([[9, 9, 9], [9, 9, 9]]) print(arr_1) # [[1 1 1] # [1 1 1]] print(arr_2) # [[9 9 9] # [9 9 9]] \u6cbf0\u8f74\u5408\u5e76\u7684\u601d\u8def\u662f\uff0c\u4e24\u4e2a\u6570\u7ec4\u6cbf0\u8f74\u65b9\u5411\uff0c\u54110\u8f74\u201c\u584c\u7f29\u201d\uff08collapse\uff09\u3002 result = np.concatenate([arr_1, arr_2], axis=0) print(result) # [[1 1 1] # [1 1 1] # [9 9 9] # [9 9 9]] \u6cbf1\u8f74\u5408\u5e76\u7684\u601d\u8def\u662f\uff0c\u4e24\u4e2a\u6570\u7ec4\u6cbf1\u8f74\u65b9\u5411\uff0c\u54111\u8f74\u201c\u584c\u7f29\u201d result = np.concatenate([arr_1, arr_2], axis=1) print(result) # [[1 1 1 9 9 9] # [1 1 1 9 9 9]] \u6211\u4eec\u6765\u770bNumPy\u7684\u4e09\u7ef4\u6570\u7ec4\u3002 array1 = np.arange(36).reshape((3, 3, 4)) print(array1) # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] \u8fd9\u6837\u770b\u4f1a\u5bb9\u6613\u7406\u89e3\u4e00\u4e9b\uff0c0\u8f74\u67093\u884c\uff0c1\u8f74\u67093\u5217\uff0c2\u8f74\u67094\u4e2a\u5143\u7d20\uff1a [[[ 0 1 2 3], [ 4 5 6 7], [ 8 9 10 11]] [[12 13 14 15], [16 17 18 19], [20 21 22 23]] [[24 25 26 27], [28 29 30 31], [32 33 34 35]]] \u8f93\u51fa\uff1a\u8f740\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f741\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f742\u7d22\u5f15\u53f7\uff1a\u5168\u90e8 print(array1[0, 0, :]) # [0 1 2 3] \u8f93\u51fa\uff1a\u8f740\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f741\u7d22\u5f15\u53f7\uff1a0\uff1b\u8f742\u7d22\u5f15\u53f7\uff1a1 print(array1[0, 0, 1]) # 1","title":"NumPy\u8f74"},{"location":"python/DataAnalysis/ch01/#numpy_2","text":"\u4e00\u4e2a \u6807\u91cf \u5c31\u662f\u4e00\u4e2a\u5355\u72ec\u7684\u6570\u3002\u4e00\u4e2a\u5411\u91cf\u5c31\u662f\u4e00\u5217\u6570\uff0c\u8fd9\u4e9b\u6570\u662f\u6709\u5e8f\u6392\u5217\u7684\u3002 \u77e9\u9635\u662f\u4e8c\u7ef4\u6570\u7ec4\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u88ab\u4e24\u4e2a\u7d22\u5f15\u800c\u975e\u4e00\u4e2a\u6240\u786e\u5b9a\u3002 \u51e0\u4f55\u4ee3\u6570\u4e2d\u5b9a\u4e49\u7684 \u5f20\u91cf \u662f\u57fa\u4e8e\u5411\u91cf\u548c\u77e9\u9635\u7684\u63a8\u5e7f\uff0c\u6211\u4eec\u53ef\u4ee5 \u5c06\u6807\u91cf\u89c6\u4e3a\u96f6\u9636\u5f20\u91cf \uff0c \u77e2\u91cf \u89c6\u4e3a\u4e00\u9636\u5f20\u91cf\uff0c\u90a3\u4e48 \u77e9\u9635\u5c31\u662f\u4e8c\u9636\u5f20\u91cf \u3002 \u5e26\u6709\u6807\u91cf\u8ba1\u7b97\u7684\u7b97\u672f\u64cd\u4f5c\uff0c\u4f1a\u628a\u8ba1\u7b97\u53c2\u6570\u4f20\u9012\u7ed9\u6570\u7ec4\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u3002 \u540c\u5c3a\u5bf8\u6570\u7ec4\u4e4b\u95f4\u7684\u6bd4\u8f83 array04 == array04 \uff0c\u4f1a\u4ea7\u751f\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4 \u4e0d\u540c\u5c3a\u5bf8\u7684\u6570\u7ec4\u95f4\u7684\u64cd\u4f5c\uff0c\u5c06\u4f1a\u7528\u5230 \u5e7f\u64ad\u7279\u6027\uff08broadcasting\uff09 \u3002 array04 = np.array([ [1, 2, 3, 4, 5], [3, 4, 5, 6, 7], [5, 6, 7, 8, 9] ], dtype=int) print(array04 + array04) # [[ 2 4 6 8 10] # [ 6 8 10 12 14] # [10 12 14 16 18]] print(array04 - array04) # [[0 0 0 0 0] # [0 0 0 0 0] # [0 0 0 0 0]] print(array04 * array04) # [[ 1 4 9 16 25] # [ 9 16 25 36 49] # [25 36 49 64 81]] print(array04 / array04) # [[1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.] # [1. 1. 1. 1. 1.]] print(1 / array04) # [[1. 0.5 0.33333333 0.25 0.2 ] # [0.33333333 0.25 0.2 0.16666667 0.14285714] # [0.2 0.16666667 0.14285714 0.125 0.11111111]] print(array04 == array04) # [[ True True True True True] # [ True True True True True] # [ True True True True True]]","title":"NumPy\u6570\u7ec4\u7b97\u672f"},{"location":"python/DataAnalysis/ch01/#_2","text":"ndarray\u5bf9\u8c61\u7684\u5185\u5bb9\u53ef\u4ee5\u901a\u8fc7\u7d22\u5f15\uff08indexing\uff09\u6216\u5207\u7247\uff08slicing\uff09\u6765\u8bbf\u95ee\u548c\u4fee\u6539\uff0cndarray\u5bf9\u8c61\u4e2d\u7684\u5143\u7d20\u7d22\u5f15\u4ece\u96f6\u5f00\u59cb\u3002 \u6709\u4e09\u79cd\u53ef\u7528\u7684\u7d22\u5f15\u65b9\u6cd5\uff1a\u5b57\u6bb5\u8bbf\u95ee\uff0c\u57fa\u672c\u5207\u7247\u548c\u9ad8\u7ea7\u7d22\u5f15\u3002 \u7d22\u5f15\uff08indexing\uff09\uff1a\u83b7\u53d6\u6570\u7ec4\u4e2d\u7279\u5b9a\u4f4d\u7f6e\u5143\u7d20\u7684\u8fc7\u7a0b\u3002 \u5207\u7247\uff08slicing\uff09\uff1a\u83b7\u53d6\u6570\u7ec4\u5143\u7d20\u5b50\u96c6\u7684\u8fc7\u7a0b\u3002\u6570\u7ec4\u7684\u5207\u7247\u662f\u539f\u6570\u7ec4\u7684\u89c6\u56fe\u3002\u8fd9\u610f\u5473\u7740\u4efb\u4f55 \u5bf9\u4e8e\u89c6\u56fe\u7684\u4fee\u6539\u90fd\u4f1a\u53cd\u6620\u5230\u539f\u6570\u7ec4\u4e0a \u3002\u6570\u7ec4\u7684\u5207\u7247, \u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u964d\u4f4e\u4e00\u4e2a\u7ef4\u5ea6\u7684\u6570\u7ec4\u3002 \u4e00\u7ef4\u6570\u7ec4\u7684\u7d22\u5f15\u548c\u5207\u7247\uff1a\u4e0ePython\u7684\u5217\u8868\u7c7b\u4f3c\uff1a a[n] \uff1a\u8fd4\u56de\u7b2c n+1 \u4e2a\u5143\u7d20\u3002\u5982\u679c n \u4e3a\u8d1f\u6570\uff0c\u5219\u8fd4\u56de\u5012\u6570\u7b2c n \u4e2a\u5143\u7d20\u3002 a[n:m:k] \uff1a\u8d77\u59cb\u7f16\u53f7 n \uff0c\u7ec8\u6b62\u7f16\u53f7 m \uff0c\u6b65\u957f k \uff0c\u7528\u5192\u53f7\u5206\u5272\u3002 \u9075\u5faa\u5de6\u95ed\u53f3\u5f00\u7684\u539f\u5219 \uff0c\u5373 [n, m) \u3002\u5982\u679c n \u4e3a\u7a7a\uff0c\u5373 n = 0 \uff1b\u5982\u679c m \u4e3a\u7a7a\uff0c\u5373 m = len(a) \u3002 \u591a\u7ef4\u6570\u7ec4\u7684\u7d22\u5f15\u548c\u5207\u7247\uff1a a[n,m,k,...] \uff1a\u6bcf\u4e2a\u7ef4\u5ea6\u4e00\u4e2a\u7d22\u5f15\u503c\uff0c\u6700\u5916\u5c42\u5217\u8868\uff08list\uff09\u4e2d\u7b2c n \u4e2a\u5143\u7d20\uff0c\u6b21\u5916\u5c42\u5217\u8868\uff08list\uff09\u4e2d\u7b2c m \u4e2a\u5143\u7d20\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002\u5982\u679c n \u4e3a\u8d1f\u6570\uff0c\u5219\u8fd4\u56de\u5012\u6570\u7b2c n \u4e2a\u5143\u7d20\u3002 a[n1:m1:k1,n2:m2:k2,n3:m3:k3,...] \uff1a\u6bcf\u4e2a\u7ef4\u5ea6\u7684\u5207\u7247\u65b9\u6cd5\u4e0e\u4e00\u7ef4\u6570\u7ec4\u76f8\u540c\u3002\u987a\u5e8f\u4e3a\u4ece\u5916\u5230\u5185\u3002 array05 = np.arange(10) print(array05) # [0 1 2 3 4 5 6 7 8 9] # \u4ece\u7d22\u5f15\u503c5\u5f00\u59cb\u5230\u7d22\u5f15\u503c7\u7684\u4e00\u4e2a\u5207\u7247\u3002 print(array05[5:8]) # [5 6 7] array06 = array05[5:8] # \u4f20\u5165\u4e00\u4e2a\u6570\u503c\u7ed9\u6570\u7ec4\u7684\u5207\u7247\uff0c\u6570\u503c\u88ab\u4f20\u9012\u7ed9\u4e86\u6574\u4e2a\u5207\u7247\u3002\u4e0d\u5199\u5207\u7247\u503c\u7684[:]\u5c06\u4f1a\u5f15\u7528\u6570\u7ec4\u7684\u6240\u6709\u503c array06[:] = 12 print(array06) # [12 12 12] # \u5207\u7247\u7684\u4fee\u6539\u4f1a\u53cd\u6620\u5230\u539f\u6570\u7ec4\u4e0a print(array05) # [ 0 1 2 3 4 12 12 12 8 9] # \u8f93\u51fa3\u7ef4\u77e9\u9635\uff0c3\u884c3\u5217\uff0c\u51719\u4e2a\u5143\u7d20\uff0c\u6bcf\u4e2a\u5143\u7d20\u662f\u4e00\u4e2a\u542b3\u4e2a\u5143\u7d20\u7684\u5217\u8868 array07 = np.array([ [[0, 1, 2], [3, 4, 5], [6, 7, 8]], [[9, 0, 1], [2, 3, 4], [5, 6, 7]], [[8, 9, 0], [1, 2, 3], [4, 5, 6]], ]) # \u8f93\u51fa3\u7ef4\u77e9\u9635\uff0c\u663e\u793a\u539f\u77e9\u9635\u7684\u7b2c1\uff0c2\u884c\u76842\uff0c3\u5217\u5143\u7d20\uff0c\u4e0d\u8981\u628a\u7d22\u5f15\u53f7\u548c\u8fd9\u91cc\u7684\u8868\u8ff0\u884c\u53f7\u6df7\u6dc6\u3002 print(array07[:2, 1:]) # [[[3 4 5] [6 7 8]] # [[2 3 4] [5 6 7]]] print(array07[:2, 1:].shape) # (2, 2, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c print(array07[2]) # [[8 9 0] [1 2 3] [4 5 6]] print(array07[2].shape) # (3, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c print(array07[2, :]) # [[8 9 0] [1 2 3] [4 5 6]] print(array07[2, :].shape) # (3, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c3\u884c\uff08\u53ea\u6709\u4e09\u884c\uff0c\u6240\u4ee5[2:, :]\u7b49\u540c\u4e8e[2, :]\uff09 print(array07[2:, :]) # [[[8 9 0] [1 2 3] [4 5 6]]] print(array07[2:, :].shape) # (1, 3, 3) # \u8f93\u51fa\u539f\u77e9\u9635\u76841\uff0c2\u5217 print(array07[:, :2]) # [[[0 1 2] [3 4 5]] # [[9 0 1] [2 3 4]] # [[8 9 0] [1 2 3]]] print(array07[:, :2].shape) # (3, 2, 3) # \u964d\u7ef4\uff0c\u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u524d2\u4e2a\u5143\u7d20 print(array07[1, :2]) # [[9 0 1] [2 3 4]] print(array07[1, :2].shape) # (2, 3) # \u8f93\u51fa\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u524d2\u4e2a\u5143\u7d20 print(array07[1:2, :2]) # [[[9 0 1] [2 3 4]]] print(array07[1:2, :2].shape) # (1, 2, 3) # \u5c06\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u8d4b\u503c\u7ed9\u53d8\u91cf old_value = array07[2].copy() print(old_value) # [[8 9 0] [1 2 3] [4 5 6]] # \u4fee\u6539\u539f\u77e9\u9635\u7684\u7b2c2\u884c\u7684\u503c\uff0c\u6807\u91cf\u548c\u6570\u7ec4\u90fd\u53ef\u4ee5\u4f20\u9012\u7ed9 array07[2] array07[2] = 25 print(array07) # [[[ 0 1 2] [ 3 4 5] [ 6 7 8]] # [[ 9 0 1] [ 2 3 4] [ 5 6 7]] # [[25 25 25] [25 25 25] [25 25 25]]] # \u5c06\u53d8\u91cf\u503c\u8d4b\u503c\u7ed9\u539f\u77e9\u9635\u7684\u7b2c2\u884c array07[2] = old_value print(array07) # [[[0 1 2] [3 4 5] [6 7 8]] # [[9 0 1] [2 3 4] [5 6 7]] # [[8 9 0] [1 2 3] [4 5 6]]]","title":"\u57fa\u7840\u7d22\u5f15\u4e0e\u5207\u7247"},{"location":"python/DataAnalysis/ch01/#_3","text":"\u5e03\u5c14\u503c\u7d22\u5f15\uff08Boolean indexing\uff09\u662f\u901a\u8fc7\u4e00\u4e2a\u5e03\u5c14\u6570\u7ec4\u6765\u7d22\u5f15\u76ee\u6807\u6570\u7ec4\uff0c\u4ee5\u6b64\u627e\u51fa\u4e0e\u5e03\u5c14\u6570\u7ec4\u4e2d\u503c\u4e3aTrue\u7684\u5bf9\u5e94\u7684\u76ee\u6807\u6570\u7ec4\u4e2d\u7684\u6570\u636e\u3002\u5e03\u5c14\u6570\u7ec4\u7684\u957f\u5ea6\u5fc5\u987b\u4e0e\u76ee\u6807\u6570\u7ec4\u5bf9\u5e94\u7684\u8f74\u7684\u957f\u5ea6\u4e00\u81f4\u3002 \u4f7f\u7528\u5e03\u5c14\u503c\u7d22\u5f15\uff08Boolean indexing\uff09\u9009\u62e9\u6570\u636e\u65f6\uff0c\u603b\u662f\u751f\u6210\u6570\u636e\u7684\u62f7\u8d1d\uff0c\u5373\u4f7f\u8fd4\u56de\u7684\u6570\u7ec4\u5e76\u6ca1\u6709\u4efb\u4f55\u53d8\u5316\u3002 \u5047\u8bbe\u6211\u4eec\u7684\u6570\u636e\u90fd\u5728\u6570\u7ec4\u4e2d\uff0c\u5e76\u4e14\u6570\u7ec4\u4e2d\u7684\u6570\u636e\u662f\u4e00\u4e9b\u5b58\u5728\u91cd\u590d\u7684\u4eba\u540d\u3002\u7528randn\u51fd\u6570\u751f\u6210\u4e00\u4e9b\u6807\u51c6\u6b63\u6001(standard normal)\u5206\u5e03\u7684\u6570\u636e\u3002\u5047\u8bbe\u6bcf\u4e2a\u4eba\u540d\u90fd\u548cdata\u6570\u7ec4\u4e2d\u7684\u4e00\u884c\u76f8\u5bf9\u5e94\uff0c\u5e76\u4e14\u6211\u4eec\u60f3\u8981\u9009\u4e2d\u6240\u6709\u2019Bob\u2019\u5bf9\u5e94\u7684\u884c\u3002 names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], dtype='<U4') data = np.random.randn(7, 4) print(names) # ['Bob' 'Joe' 'Will' 'Bob' 'Will' 'Joe' 'Joe'] print(data) # [[ 0.19233985 -0.22530396 -0.68464485 0.03961609] # [ 0.26189893 -0.86823302 0.72726864 0.16122945] # [-0.70564457 0.59179465 0.05572085 -1.79999391] # [-0.21465342 0.09236611 0.02982635 -1.08500576] # [ 1.17260699 -0.53172414 0.16224439 0.60597493] # [ 0.49879926 -0.64871168 0.57597095 0.86329327] # [-0.64902274 -0.92406415 0.40021708 -0.18222566]] print(names == 'Bob') # [ True False False True False False False] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob']) # [[ 0.19233985 -0.22530396 -0.68464485 0.03961609] # [-0.21465342 0.09236611 0.02982635 -1.08500576]] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u4e14\u5217\u7d22\u5f15\u4e3a2\u30013\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob', 2:]) # [[-0.68464485 0.03961609] [ 0.02982635 -1.08500576]] # \u4e0a\u8ff0data\u7684\u884c\u7d22\u5f15\u4e3a0\u30013\u4e14\u5217\u7d22\u5f15\u4e3a3\u7684\u503c\uff08\u5bf9\u5e94\u4e8eBob\u4e3aTrue\uff09 print(data[names == 'Bob', 3]) # [ 0.03961609 -1.08500576] \u4f7f\u7528 != \u6216\u5728\u6761\u4ef6\u8868\u8fbe\u5f0f\u524d\u4f7f\u7528 \uff5e \u5bf9\u6761\u4ef6\u53d6\u53cd, \u9009\u62e9\u9664\u4e86\u2019Bob\u2019\u4ee5\u5916\u7684\u5176\u4ed6\u6570\u636e\u3002 print(names != 'Bob') print(data[~(names == 'Bob')]) \u9009\u62e9\u4e09\u4e2a\u540d\u5b57\u4e2d\u7684\u4e24\u4e2a\u65f6\uff0c\u53ef\u4ee5\u5bf9\u591a\u4e2a\u5e03\u5c14\u503c\u6761\u4ef6\u8fdb\u884c\u8054\u5408\uff0c\u4f7f\u7528\u6570\u5b66\u64cd\u4f5c\u7b26\u5982 & \uff08and\uff09\u548c | \uff08or\uff09\u3002 mask = (names == 'Bob') | (names == 'Will') print(mask) # [ True False True True True False False] # \u66f4\u65b0\u76f4\u63a5\u4f5c\u7528\u5728`data`\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u662f\u5728\u526f\u672c\u4e2d\u4fee\u6539\u3002 data[names == 'Joe'] = 7 print(data) # [[ 1.12584226 -1.09988707 0.49842702 0.76308186] # [ 7. 7. 7. 7. ] # [ 1.54212949 -0.34487439 -1.47775736 -0.25724376] # [ 0.60943059 -0.0164697 0.26681455 -1.70871624] # [ 0.28010374 -0.32339505 -0.95289544 2.76739316] # [ 7. 7. 7. 7. ] # [ 7. 7. 7. 7. ]]","title":"\u5e03\u5c14\u7d22\u5f15"},{"location":"python/DataAnalysis/ch01/#_4","text":"\u795e\u5947\u7d22\u5f15\uff08Fancy Indexing\uff09 \uff0c\u4e5f\u7ffb\u8bd1\u4e3a \u82b1\u5f0f\u7d22\u5f15 \u6216 \u590d\u6742\u7d22\u5f15 \uff0c\u7528\u4e8e\u63cf\u8ff0\u4f7f\u7528\u6574\u6570\u6570\u7ec4\u8fdb\u884c\u6570\u636e\u7d22\u5f15\uff0c\u8fd9\u91cc\u7684\u6570\u7ec4\uff0c\u53ef\u4ee5\u662fNumPy\u7684\u6570\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u662fpython\u81ea\u5e26\u7684\u5217\u8868\uff08list\uff09\u3002\u795e\u5947\u7d22\u5f15\u4e0e\u5207\u7247\u4e0d\u540c\uff0c\u5b83\u603b\u662f\u5c06\u6570\u636e \u590d\u5236 \u5230\u4e00\u4e2a\u65b0\u7684\u6570\u7ec4\u4e2d\uff08\u526f\u672c\uff09\u3002 \u7279\u522b\u6ce8\u610f\u7684\u4e00\u70b9\u662f\uff0c\u4f7f\u7528fancy indexing\u8fd4\u56de\u6570\u7ec4\u7684shape\uff0c\u662f\u7d22\u5f15\u6570\u7ec4\u7684shape\uff0c\u800c\u4e0d\u662f\u88ab\u7d22\u5f15\u7684\u539f\u6570\u7ec4\u7684shape\u3002 \u4f7f\u7528fancy indexing\u65f6\u8981\u7279\u522b\u6ce8\u610f\u7684\u4e00\u70b9\u662f\u8fd4\u56de\u6570\u7ec4\u7684shape\u53cd\u6620\u7684\u662f\u7d22\u5f15\u6570\u7ec4\u7684shape\u800c\u4e0d\u662f\u88ab\u7d22\u5f15\u7684\u539f\u6570\u7ec4\u7684shape\u3002 \u5047\u8bbe\u6709\u4e00\u4e2a8\u00d74\u7684\u6570\u7ec4\uff1a array08 = np.empty((8, 4)) # \u53c2\u6570\u662f\u4e2a\u5143\u7ec4(8, 4)\u3002 for i in range(8): array08[i] = i print(array08) # [[0. 0. 0. 0.] # [1. 1. 1. 1.] # [2. 2. 2. 2.] # [3. 3. 3. 3.] # [4. 4. 4. 4.] # [5. 5. 5. 5.] # [6. 6. 6. 6.] # [7. 7. 7. 7.]] # \u8f93\u51fa\u7d22\u5f15\u4e3a2\u548c-2\u7684\u884c\u503c\u3002\u4f20\u9012\u4e00\u4e2a\u5305\u542b\u6307\u660e\u6240\u9700\u987a\u5e8f\u7684\u5217\u8868[2, -2]\uff08\u6216\u6570\u7ec4\uff09\uff0c\u9009\u51fa\u4e00\u4e2a\u7b26\u5408\u7279\u5b9a\u987a\u5e8f\u7684\u5b50\u96c6 print(array08[[2, -2]]) # [[2. 2. 2. 2.] # [6. 6. 6. 6.]] # \u75280~31\u751f\u6210\u4e00\u4e2a8x4\u6570\u7ec4 array09 = np.arange(32).reshape((8, 4)) print(array09) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11] # [12 13 14 15] # [16 17 18 19] # [20 21 22 23] # [24 25 26 27] # [28 29 30 31]] print(array09[[1, 5, 7, 2]]) # \u6570\u7ec4[1, 5, 7, 2]\u6307\u5b9a\u4e86\u8f93\u51fa\u987a\u5e8f # [[ 4 5 6 7] # [20 21 22 23] # [28 29 30 31] # [ 8 9 10 11]] print(array09[[0, 3, 1, 2]]) # [[ 0 1 2 3] # [12 13 14 15] # [ 4 5 6 7] # [ 8 9 10 11]] print(array09[[1, 5, 7, 2], [0, 3, 1, 2]]) # [ 4 23 29 10] array09[[1, 5, 7, 2]] \u4e2d\u901a\u8fc7\u4e00\u4e2a\u5217\u8868 [1, 5, 7, 2] \u6765\u6307\u5b9a\u8f93\u51fa\u987a\u5e8f\u3002 array09[[1, 5, 7, 2], [0, 3, 1, 2]] \u53ef\u4ee5\u7406\u89e3\u4e3a\u57fa\u4e8e array09[[1, 5, 7, 2]] \u8f93\u51fa\u7684\u77e9\u9635\uff0c\u901a\u8fc7[0, 3, 1, 2]\u6307\u5b9a\u4e86\u7ed3\u679c\u96c6\u7684\u6bcf\u4e00\u884c\u9009\u53d6\u7684\u503c\uff0c\u6bd4\u5982\uff0c3\u4ee3\u8868\u7ed3\u679c\u96c6[20 21 22 23]\u7684\u7b2c\u4e09\u4e2a\u5143\u7d20\uff0823\uff09\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\uff0c\u5143\u7d20\uff081, 0\uff09\u3001\uff085, 3\uff09\u3001\uff087, 1\uff09\u548c\uff082, 2\uff09\u88ab\u9009\u4e2d\u3002","title":"\u795e\u5947\u7d22\u5f15\uff08\u82b1\u5f0f\u7d22\u5f15\uff09"},{"location":"python/DataAnalysis/ch01/#_5","text":"\u6570\u7ec4\u8f6c\u7f6e\uff0c\u6709T\u5c5e\u6027\u3001 transpose() \u65b9\u6cd5\u3001 swapaxes() \u65b9\u6cd5\u3002 swapaxes() \u65b9\u6cd5\u9ed8\u8ba4\u662f(0\u8f74, 1\u8f74)\uff0c\u5373 swapaxes(0, 1) \uff0c\u8fd4\u56de\u7684\u662f\u6570\u636e\u7684\u89c6\u56fe\uff0c\u6ca1\u6709\u5bf9\u6570\u636e\u8fdb\u884c\u590d\u5236\u3002 array10 = np.arange(15).reshape((3, 5)) print(array10) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08T\u5c5e\u6027\uff09 print(array10.T) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08transpose()\u65b9\u6cd5\uff09 print(array10.transpose()) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] # \u77e9\u9635\u8f6c\u7f6e\uff08swapaxes()\u65b9\u6cd5\uff09 print(array10.swapaxes(1, 0)) # [[ 0 5 10] # [ 1 6 11] # [ 2 7 12] # [ 3 8 13] # [ 4 9 14]] \u901a\u8fc7T\u5c5e\u6027\uff0c\u8ba1\u7b97\u77e9\u9635\u5185\u79ef\uff08Inner Product\uff09\u3002\u77e9\u9635\u5185\u79ef\u53c2\u7167\u5411\u91cf\u5185\u79ef\u7684\u5b9a\u4e49\u662f\uff1a\u4e24\u4e2a\u5411\u91cf\u5bf9\u5e94\u5206\u91cf\u4e58\u79ef\u4e4b\u548c\u3002 array10 = np.arange(6).reshape((2, 3)) print(array10) # [[0 1 2] # [3 4 5]] print(array10.T) # [[0 3] # [1 4] # [2 5]] print(np.dot(array10, array10.T)) # [[ 5 14] # [14 50]] \u5bf9\u4e8e\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u7ec4\uff0c transpose() \u65b9\u6cd5\u53ef\u4ee5\u63a5\u6536\u5305\u542b\u8f74\u7f16\u53f7\u7684\u5143\u7ec4\uff0c\u7528\u4e8e\u7f6e\u6362\u8f74\u3002 array11 = np.arange(36).reshape((3, 3, 4)) print(array11) # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] print(array11.transpose((0, 1, 2))) # \u9ed8\u8ba4\u662f(0\u8f74, 1\u8f74, 2\u8f74)\u3002\u6240\u4ee5\u8f93\u51fa\u539f\u77e9\u9635 # [[[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] # # [[12 13 14 15] # [16 17 18 19] # [20 21 22 23]] # # [[24 25 26 27] # [28 29 30 31] # [32 33 34 35]]] print(array11.transpose((1, 0, 2))) # \u8f93\u51fa\u987a\u5e8f\u8c03\u6574\u4e3a\u539f\u77e9\u9635\u7684(1\u8f74, 0\u8f74, 2\u8f74) # [[[ 0 1 2 3] # [12 13 14 15] # [24 25 26 27]] # # [[ 4 5 6 7] # [16 17 18 19] # [28 29 30 31]] # # [[ 8 9 10 11] # [20 21 22 23] # [32 33 34 35]]] print(array11.swapaxes(1, 0)) # \u540c\u4e0atranspose((1, 0, 2)) # [[[ 0 1 2 3] # [12 13 14 15] # [24 25 26 27]] # # [[ 4 5 6 7] # [16 17 18 19] # [28 29 30 31]] # # [[ 8 9 10 11] # [20 21 22 23] # [32 33 34 35]]] print(array11.transpose((2, 1, 0))) # [[[ 0 12 24] # [ 4 16 28] # [ 8 20 32]] # # [[ 1 13 25] # [ 5 17 29] # [ 9 21 33]] # # [[ 2 14 26] # [ 6 18 30] # [10 22 34]] # [[ 3 15 27] # [ 7 19 31] # [11 23 35]]]","title":"\u6570\u7ec4\u8f6c\u7f6e\u548c\u6362\u8f74"},{"location":"python/DataAnalysis/ch01/#_6","text":"\u901a\u7528\u51fd\u6570 \u4e5f\u79f0\u4e3aufunc\uff0c\u662f\u4e00\u79cd\u5728ndarray\u6570\u636e\u4e2d\u8fdb\u884c\u9010\u5143\u7d20\u64cd\u4f5c\u7684\u51fd\u6570\uff0c\u5373\u5feb\u901f\u7684\u9010\u5143\u7d20\u6570\u7ec4\u51fd\u6570\u3002 \u67d0\u4e9b\u7b80\u5355\u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u91cf\u6570\u503c\uff0c\u5e76\u4ea7\u751f\u4e00\u4e2a\u6216\u591a\u4e2a\u6807\u91cf\u7ed3\u679c\uff0c\u800c \u901a\u7528\u51fd\u6570\u5c31\u662f\u5bf9\u8fd9\u4e9b\u7b80\u5355\u51fd\u6570\u7684\u5411\u91cf\u5316\u5c01\u88c5 \u3002 \u4e00\u5143\u901a\u7528\u51fd\u6570 abs\u3001fabs\uff1a\u9010\u5143\u7d20\u5730\u8ba1\u7b97\u6574\u6570\u3001\u6d6e\u70b9\u6570\u6216\u590d\u6570\u7684\u7edd\u5bf9\u503c sqrt\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\u6839\uff08\u4e0earr**0.5\u76f8\u7b49\uff09 square\uff1a\u8ba1\u7b97\u6bcf\u4e2a\u5143\u7d20\u7684\u5e73\u65b9\uff08\u4e0earr**2\u76f8\u7b49\uff09 exp\uff1a\u8ba1\u7b97\u4ee5e\u4e3a\u5e95, \u6570\u7ec4\u5143\u7d20\u4e3a\u5e42\u6b21\u7684\u6307\u6570\u51fd\u6570 \u4e8c\u5143\u901a\u7528\u51fd\u6570 add\uff1a\u5c06\u6570\u7ec4\u7684\u5bf9\u5e94\u5143\u7d20\u76f8\u52a0\u3002 subtract\uff1a\u5728\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u4e2d\uff0c\u5c06\u7b2c\u4e00\u4e2a\u6570\u7ec4\u4e2d\u5305\u542b\u7684\u5143\u7d20\u53bb\u9664\u3002 multiply\uff1a\u5c06\u6570\u7ec4\u7684\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\u3002 divide\uff0cfloor_divide\uff1a\u9664\u3001\u6216\u6574\u9664\uff08\u653e\u5f03\u4f59\u6570\uff09 power\uff1a\u5c06\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u7684\u5143\u7d20\u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u6570\u7ec4\u5bf9\u5e94\u5143\u7d20\u7684\u5e42\u6b21\u65b9\u3002 maximun\u3001fmax\uff1a\u9010\u4e2a\u5143\u7d20\u8ba1\u7b97\u6700\u5927\u503c\uff0cfmax\u5ffd\u7565NaN\u3002 minimum\u3001fmin\uff1a\u9010\u4e2a\u5143\u7d20\u8ba1\u7b97\u6700\u5c0f\u503c\uff0cfmin\u5ffd\u7565NaN\u3002 mod\uff1a\u6309\u5143\u7d20\u7684\u6c42\u6a21\u8ba1\u7b97\uff08\u5373\u6c42\u9664\u6cd5\u7684\u4f59\u6570\uff09\u3002 copysign\uff1a\u5c06\u7b2c\u4e00\u4e2a\u6570\u7ec4\u7684\u7b26\u53f7\u503c\u6539\u4e3a\u7b2c\u4e8c\u4e2a\u6570\u7ec4\u7684\u7b26\u53f7\u503c\u3002 greater\u3001greater_euqal\u3001less\u3001less_equal\u3001equal\u3001not_euqal\uff1a\u8fdb\u884c\u9010\u4e2a\u5143\u7d20\u7684\u6bd4\u8f83\uff0c\u8fd4\u56de\u5e03\u5c14\u503c\u6570\u7ec4\u3002 logical_and\u3001logical_or\u3001logical_xor\uff1a\u8fdb\u884c\u9010\u4e2a\u5143\u7d20\u7684\u903b\u8f91\u64cd\u4f5c\u3002 \u770b\u4e0b\u4f8b\uff0c\u5bf9\u591a\u7ef4\u6570\u7ec4\u8ba1\u7b97exp\u51fd\u6570\u3002 array12 = np.arange(10).reshape((2, 5)) print(array12) # [[0 1 2 3 4] # [5 6 7 8 9]] print(np.sqrt(array12)) # [[0. 1. 1.41421356 1.73205081 2. ] # [2.23606798 2.44948974 2.64575131 2.82842712 3. ]] print(np.exp(array12)) # [[1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01 5.45981500e+01] # [1.48413159e+02 4.03428793e+02 1.09663316e+03 2.98095799e+03 8.10308393e+03]] \u4e0b\u4f8b\u4e2d\uff0c numpy.maximum \u9010\u5143\u7d20\u5730\u5c06\u6570\u7ec4 x \u548c y \u4e2d\u7684\u6700\u5927\u503c\u8ba1\u7b97\u51fa\u6765\u3002 numpy.add \u9010\u5143\u7d20\u5730\u5c06\u6570\u7ec4 x \u548c y \u7684\u548c\u8ba1\u7b97\u51fa\u6765\u3002 array13 = [1, 4, 5, 8, 9] array14 = [2, 3, 6, 7, 10] print(np.maximum(array13, array14)) # [ 2 4 6 8 10] print(np.add(array13, array14)) # [ 3 7 11 15 19] \u4e0b\u4f8b\u4e2d\uff0c modf \u8fd4\u56de\u4e00\u4e2a\u6d6e\u70b9\u503c\u6570\u7ec4\u7684\u5c0f\u6570\u90e8\u5206\u548c\u6574\u6570\u90e8\u5206 array15 = np.random.randn(7) * 5 print(array15) # [-7.54395135 -0.065131 2.71582306 2.2432261 11.02637158 6.73968036 2.96895379] remainder, whole_part = np.modf(array15) print(remainder) # [-0.54395135 -0.065131 0.71582306 0.2432261 0.02637158 0.73968036 0.96895379] print(whole_part) # [-7. -0. 2. 2. 11. 6. 2.]","title":"\u901a\u7528\u51fd\u6570"},{"location":"python/DataAnalysis/ch01/#_7","text":"\u5229\u7528 \u6570\u7ec4\u8868\u8fbe\u5f0f \u6765\u66ff\u4ee3\u663e\u5f0f\u5faa\u73af\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u5411\u91cf\u5316 \u3002 \u5411\u91cf\u5316\u7684\u6570\u7ec4\u64cd\u4f5c\u4f1a\u6bd4\u7eafPython\u7684\u7b49\u4ef7\u5b9e\u73b0\u5728\u901f\u5ea6\u4e0a\u5feb\u4e00\u5230\u4e24\u4e2a\u6570\u91cf\u7ea7\uff08\u751a\u81f3\u66f4\u591a\uff09\u3002 \u4e0b\u4f8b\u4e2d\uff0cnp.meshgrid\u51fd\u6570\u63a5\u6536\u4e24\u4e2a\u4e00\u7ef4\u6570\u7ec4\uff0c\u5e76\u6839\u636e\u4e24\u4e2a\u6570\u7ec4\u7684\u6240\u6709(x, y)\u5bf9\u751f\u6210\u4e00\u4e2a\u4e8c\u7ef4\u77e9\u9635\u3002 array = np.arange(-5, 5, 1, dtype=int) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) xs, ys = np.meshgrid(array, array) print(\"\u751f\u6210x\u8f74\u54112\u7ef4\u77e9\u9635 \\n\", xs) print(\"\u751f\u6210y\u8f74\u54112\u7ef4\u77e9\u9635 \\n\", ys) # \u6837\u672c\u77e9\u9635 # [-5 -4 -3 -2 -1 0 1 2 3 4] # \u751f\u6210x\u8f74\u54112\u7ef4\u77e9\u9635 # [[-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4] # [-5 -4 -3 -2 -1 0 1 2 3 4]] # \u751f\u6210y\u8f74\u54112\u7ef4\u77e9\u9635 # [[-5 -5 -5 -5 -5 -5 -5 -5 -5 -5] # [-4 -4 -4 -4 -4 -4 -4 -4 -4 -4] # [-3 -3 -3 -3 -3 -3 -3 -3 -3 -3] # [-2 -2 -2 -2 -2 -2 -2 -2 -2 -2] # [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1] # [ 0 0 0 0 0 0 0 0 0 0] # [ 1 1 1 1 1 1 1 1 1 1] # [ 2 2 2 2 2 2 2 2 2 2] # [ 3 3 3 3 3 3 3 3 3 3] # [ 4 4 4 4 4 4 4 4 4 4]] \u4e0b\u9762\u7528\u56fe\u5f62\u5316\u6765\u8f93\u51fa\u4e0a\u4f8b\u4e2d\u751f\u6210\u7684NumPy\u7684\u6570\u7ec4\u3002 import numpy as np import matplotlib.pyplot as plt array = np.arange(-5, 5, 1, dtype=int) xs, ys = np.meshgrid(array, array) z = np.sqrt(xs**2 + ys**2) print(\"\u6837\u672c\u77e9\u9635 \\n\", z) # \u6837\u672c\u77e9\u9635 # [[7.07106781 6.40312424 5.83095189 5.38516481 5.09901951 5. 5.09901951 5.38516481 5.83095189 6.40312424] # [6.40312424 5.65685425 5. 4.47213595 4.12310563 4. 4.12310563 4.47213595 5. 5.65685425] # [5.83095189 5. 4.24264069 3.60555128 3.16227766 3. 3.16227766 3.60555128 4.24264069 5. ] # [5.38516481 4.47213595 3.60555128 2.82842712 2.23606798 2. 2.23606798 2.82842712 3.60555128 4.47213595] # [5.09901951 4.12310563 3.16227766 2.23606798 1.41421356 1. 1.41421356 2.23606798 3.16227766 4.12310563] # [5. 4. 3. 2. 1. 0. 1. 2. 3. 4. ] # [5.09901951 4.12310563 3.16227766 2.23606798 1.41421356 1. 1.41421356 2.23606798 3.16227766 4.12310563] # [5.38516481 4.47213595 3.60555128 2.82842712 2.23606798 2. 2.23606798 2.82842712 3.60555128 4.47213595] # [5.83095189 5. 4.24264069 3.60555128 3.16227766 3. 3.16227766 3.60555128 4.24264069 5. ] # [6.40312424 5.65685425 5. 4.47213595 4.12310563 4. 4.12310563 4.47213595 5. 5.65685425]] # \u4f7f\u7528matplotlib\u6765\u751f\u6210\u8fd9\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u7684\u53ef\u89c6\u5316 plt.imshow(z, cmap=plt.cm.gray) print(plt.colorbar) # <function colorbar at 0x7f9c91193f70> # \u56fe\u50cf\u6807\u9898 plt.title(\"$\\sqrt{x^2 + y^2}$ \u8ba1\u7b97\u503c\u7684\u7f51\u683c\u56fe\") # \u8f93\u51fa\u56fe\u50cf plt.show() \u8f93\u51fa\u56fe\u50cf\u4e3a\uff1a","title":"\u9762\u5411\u6570\u7ec4\u7f16\u7a0b"},{"location":"python/DataAnalysis/ch01/#_8","text":"numpy.where \u51fd\u6570\u662f\u4e09\u5143\u8868\u8fbe\u5f0f x if condition else y \u7684\u5411\u91cf\u5316\u7248\u672c\u3002 np.where \u7684\u7b2c\u4e8c\u4e2a\u548c\u7b2c\u4e09\u4e2a\u53c2\u6570\u5e76\u4e0d\u9700\u8981\u662f\u6570\u7ec4\uff0c\u5b83\u4eec\u53ef\u4ee5\u662f\u6807\u91cf\u3002 np.where \u5728\u6570\u636e\u5206\u6790\u4e2d\u7684\u4e00\u4e2a\u5178\u578b\u7528\u6cd5\u662f\u6839\u636e\u4e00\u4e2a\u6570\u7ec4\u6765\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u6570\u7ec4\u3002 \u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u548c\u4e24\u4e2a\u6570\u503c\u6570\u7ec4\u3002\u5047\u8bbe cond \u4e2d\u7684\u5143\u7d20\u4e3a True \u65f6\uff0c\u6211\u4eec\u53d6 xarr \u4e2d\u7684\u5bf9\u5e94\u5143\u7d20\u503c\uff0c\u5426\u5219\u53d6 yarr \u4e2d\u7684\u5143\u7d20\u3002 xarray = np.array([1.1, 1.2, 1.3, 1.4, 1.5]) yarray = np.array([2.1, 2.2, 2.3, 2.4, 2.5]) cond = np.array([True, False, True, True, False]) \u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u6765\u5b9e\u73b0\u4e0a\u8ff0\u9700\u6c42\u3002 \u7f3a\u70b9: \u9996\u5148\uff0c\u5982\u679c\u6570\u7ec4\u5f88\u5927\u7684\u8bdd\uff0c\u901f\u5ea6\u4f1a\u5f88\u6162\uff08\u56e0\u4e3a\u6240\u6709\u7684\u5de5\u4f5c\u90fd\u662f\u901a\u8fc7\u89e3\u91ca\u5668\u6765\u89e3\u91caPython\u4ee3\u7801\u5b8c\u6210\uff09\u3002 \u5176\u6b21\uff0c\u5f53\u6570\u7ec4\u662f\u591a\u7ef4\u65f6\uff0c\u5c31\u65e0\u6cd5\u51d1\u6548\u4e86\u3002 # \u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u6765\u5b9e\u73b0 result = [(x if c else y) for x, y, c in zip(xarray, yarray, cond)] print(result) # [1.1, 2.2, 1.3, 1.4, 2.5] \u901a\u8fc7 np.where \u6765\u5b9e\u73b0\u4e0a\u8ff0\u9700\u6c42\u3002 result = np.where(cond, xarray, yarray) print(result) # [1.1 2.2 1.3 1.4 2.5] \u5047\u8bbe\u6709\u4e00\u4e2a\u968f\u673a\u751f\u6210\u7684\u77e9\u9635\u6570\u636e\uff0c\u4e0b\u9762\u4f7f\u7528np.where\u5b9e\u73b0\u66ff\u6362\u3002 array = np.random.randn(4, 4) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u77e9\u9635\u5143\u7d20\u662f\u5426\u5927\u4e8e0 \\n\", array > 0) # \u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 result03 = np.where(array > 0, 2, -2) print(\"\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 \\n\", result03) # \u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 result04 = np.where(array > 0, 2, array) print(\"\u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 \\n\", result04) # \u6837\u672c\u77e9\u9635 # [[-0.57177422 -0.34917512 2.20268075 1.99959296] # [ 0.67966599 2.67915099 -0.40528454 -0.80339907] # [-0.74406888 2.33802717 -0.74582936 0.59347128] # [ 0.68624473 0.65953112 -0.40871415 -0.68698878]] # \u77e9\u9635\u5143\u7d20\u662f\u5426\u5927\u4e8e0 # [[False False True True] # [ True True False False] # [False True False True] # [ True True False False]] # \u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2\uff0c\u5c06\u6240\u6709\u7684\u8d1f\u503c\u66ff\u6362\u4e3a-2 # [[-2 -2 2 2] # [ 2 2 -2 -2] # [-2 2 -2 2] # [ 2 2 -2 -2]] # \u4ec5\u5c06\u5176\u4e2d\u7684\u6b63\u503c\u90fd\u66ff\u6362\u4e3a2 # [[-0.57177422 -0.34917512 2. 2. ] # [ 2. 2. -0.40528454 -0.80339907] # [-0.74406888 2. -0.74582936 2. ] # [ 2. 2. -0.40871415 -0.68698878]]","title":"\u901a\u8fc7\u6761\u4ef6\u903b\u8f91\u64cd\u4f5c\u6570\u7ec4"},{"location":"python/DataAnalysis/ch01/#_9","text":"NumPy\u6709\u4e00\u4e9b\u4e13\u95e8\u7684\u6570\u5b66\u51fd\u6570\uff0c\u7528\u6765\u8ba1\u7b97\u6574\u4e2a\u6570\u7ec4\u7edf\u8ba1\u503c\u6216\u8f74\u5411\u6570\u636e\u7684\u8ba1\u7b97\u3002\u4f8b\u5982\uff0c\u805a\u5408\u51fd\u6570\uff08\u901a\u5e38\u4e5f\u53eb\u7f29\u51cf\u51fd\u6570\uff09\uff0c\u5982sum\u3001mean\u548cstd\uff08\u6807\u51c6\u5dee\uff09\u3002 \u65e2\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u6570\u7ec4\u5b9e\u4f8b\u7684\u65b9\u6cd5\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u9876\u5c42\u7684NumPy\u51fd\u6570\u3002 \u4e3e\u4f8b\uff1a\u751f\u6210\u4e00\u4e9b\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u6570\uff0c\u8ba1\u7b97\u90e8\u5206\u805a\u5408\u7edf\u8ba1\u6570\u636e\u3002 \u8fd9\u91cc\u518d\u5bf9\u8f74\u5411\u505a\u4e2a\u89e3\u91ca\uff0c np.random.randn(5, 4) \u4ea7\u751f\u7684\u4e8c\u7ef4\u6570\u7ec4\u662f\uff1a0\u8f74\u54115\u4e2a\u5143\u7d20, 1\u8f74\u54114\u4e2a\u5143\u7d20\u3002 # \u751f\u62102\u8f74\u6570\u7ec4 array = np.random.randn(5, 4) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c\", array.mean()) print(\"\u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c\", np.mean(array)) print(\"\u77e9\u9635\u5143\u7d20\u548c\", array.sum()) print(\"\u77e9\u9635\u5143\u7d20\u548c\", np.sum(array)) print(\"0\u8f74\u5411\u7684\u7d2f\u548c\", array.sum(axis=0)) print(\"1\u8f74\u5411\u7684\u7d2f\u548c\", array.sum(axis=1)) print(\"1\u8f74\u5411\u7684\u5e73\u5747\u503c\", array.mean(axis=1)) # \u6837\u672c\u77e9\u9635 shape=(5, 4) 0\u8f74\u54115\u4e2a\u5143\u7d20, 1\u8f74\u54114\u4e2a\u5143\u7d20 # [[ 0.32532911 -0.00177984 -1.59432632 1.58375133] # [ 1.48921763 0.25202456 0.44076148 -1.02277289] # [-0.73490219 0.19197171 -0.22374362 0.52610852] # [-1.03531076 1.0595528 -0.11566501 0.34063544] # [-0.2122241 -0.81348187 1.70989712 -0.00732696]] # \u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c 0.10788580775057008 # \u77e9\u9635\u5143\u7d20\u5e73\u5747\u503c 0.10788580775057008 # \u77e9\u9635\u5143\u7d20\u548c 2.1577161550114017 # \u77e9\u9635\u5143\u7d20\u548c 2.1577161550114017 # 0\u8f74\u5411\u7684\u7d2f\u548c [-0.16789031 0.68828737 0.21692365 1.42039545] # 1\u8f74\u5411\u7684\u7d2f\u548c [ 0.31297429 1.15923078 -0.24056558 0.24921247 0.67686419] # 1\u8f74\u5411\u7684\u5e73\u5747\u503c [ 0.07824357 0.28980769 -0.06014139 0.06230312 0.16921605] \u4e0b\u9762\u5217\u4e3e\u4e86\u5e38\u7528\u7684\u57fa\u7840\u6570\u7ec4\u7edf\u8ba1\u65b9\u6cd5\u3002 array = np.array([ [1, 2, 3, 4, 5], [3, 4, 5, 6, 7], [5, 6, 7, 8, 9] ], dtype=int) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) print(\"\u8f74\u5411\u6c42\u548c\", array.sum()) print(\"\u8f74\u5411\u6c42\u548c\", array.sum(axis=0)) print(\"\u6570\u5b66\u5e73\u5747\", array.mean()) print(\"\u8f74\u5411\u6570\u5b66\u5e73\u5747\", array.mean(axis=0)) print(\"\u6807\u51c6\u5dee\", array.std(), \"\u65b9\u5dee\", array.var()) print(\"\u8f74\u5411\u6807\u51c6\u5dee\", array.std(axis=0), \"\u8f74\u5411\u65b9\u5dee\", array.var(axis=0)) print(\"\u6700\u5c0f\u503c\", array.min(), \"\u6700\u5927\u503c\", array.max()) print(\"\u8f74\u5411\u6700\u5c0f\u503c\", array.min(axis=0), \"\u8f74\u5411\u6700\u5927\u503c\", array.max(axis=0)) print(\"\u6700\u5c0f\u503c\u4f4d\u7f6e\", array.argmin(), \"\u6700\u5927\u503c\u4f4d\u7f6e\", array.argmax()) print(\"\u8f74\u5411\u6700\u5c0f\u503c\u4f4d\u7f6e\", array.argmin(axis=0), \"\u8f74\u5411\u6700\u5927\u503c\u4f4d\u7f6e\", array.argmax(axis=0)) print(\"\u7d2f\u79ef\u548c \\n\", array.cumsum()) print(\"\u8f74\u5411\u7d2f\u79ef\u548c \\n\", array.cumsum(axis=1)) print(\"\u7d2f\u79ef\u4e58\u79ef \\n\", array.cumprod()) print(\"\u8f74\u5411\u7d2f\u79ef\u4e58\u79ef \\n\", array.cumprod(axis=1)) # \u6837\u672c\u77e9\u9635 # [[1 2 3 4 5] # [3 4 5 6 7] # [5 6 7 8 9]] # \u8f74\u5411\u6c42\u548c 75 # \u8f74\u5411\u6c42\u548c [ 9 12 15 18 21] # \u6570\u5b66\u5e73\u5747 5.0 # \u8f74\u5411\u6570\u5b66\u5e73\u5747 [3. 4. 5. 6. 7.] # \u6807\u51c6\u5dee 2.160246899469287 \u65b9\u5dee 4.666666666666667 # \u8f74\u5411\u6807\u51c6\u5dee [1.63299316 1.63299316 1.63299316 1.63299316 1.63299316] \u8f74\u5411\u65b9\u5dee [2.66666667 2.66666667 2.66666667 2.66666667 2.66666667] # \u6700\u5c0f\u503c 1 \u6700\u5927\u503c 9 # \u8f74\u5411\u6700\u5c0f\u503c [1 2 3 4 5] \u8f74\u5411\u6700\u5927\u503c [5 6 7 8 9] # \u6700\u5c0f\u503c\u4f4d\u7f6e 0 \u6700\u5927\u503c\u4f4d\u7f6e 14 # \u8f74\u5411\u6700\u5c0f\u503c\u4f4d\u7f6e [0 0 0 0 0] \u8f74\u5411\u6700\u5927\u503c\u4f4d\u7f6e [2 2 2 2 2] # \u7d2f\u79ef\u548c # [ 1 3 6 10 15 18 22 27 33 40 45 51 58 66 75] # \u8f74\u5411\u7d2f\u79ef\u548c # [[ 1 3 6 10 15] # [ 3 7 12 18 25] # [ 5 11 18 26 35]] # \u7d2f\u79ef\u4e58\u79ef # [ 1 2 6 24 120 360 # 1440 7200 43200 302400 1512000 9072000 # 63504000 508032000 4572288000] # \u8f74\u5411\u7d2f\u79ef\u4e58\u79ef # [[ 1 2 6 24 120] # [ 3 12 60 360 2520] # [ 5 30 210 1680 15120]]","title":"\u6570\u5b66\u548c\u7edf\u8ba1\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch01/#boolean-array","text":"\u5e03\u5c14\u503c\u6570\u7ec4\uff0c\u6709\u4e24\u4e2a\u975e\u5e38\u6709\u7528\u7684\u65b9\u6cd5any\u548call\u3002 * any\u68c0\u67e5\u6570\u7ec4\u4e2d\u662f\u5426\u81f3\u5c11\u6709\u4e00\u4e2aTrue\uff0c * all\u68c0\u67e5\u662f\u5426\u6bcf\u4e2a\u503c\u90fd\u662fTrue bools = np.array([False, False, True, False]) print(bools.any()) # True print(bools.all()) # False \u4e0b\u9762\u662f\u4e00\u4e2a\u8fd0\u7528\u5e03\u5c14\u503c\u6570\u7ec4\uff08Boolean Array\uff09\u8fdb\u884c\u6c42\u548c\u7684\u4e00\u4e2a\u4f8b\u5b50\uff0c\u5176\u4e2d (array > 0) \u672c\u8eab\u662f\u4e00\u4e2a\u5e03\u5c14\u578b\u7684\u6570\u7ec4\u3002 array = np.random.randn(100) result = (array > 0).sum() # \u8ba1\u7b97\u6b63\u503c\u7684\u4e2a\u6570 print(result) # 59 \u4e0b\u9762\u662f\u8fd0\u7528\u5e03\u5c14\u503c\u6570\u7ec4\u7684\u751f\u6210\u65b0\u6570\u7ec4\u7684\u4f8b\u5b50\u3002 arr = [[8, 9, 10, 11], [0, 1, 2, 3], [4, 5, 6, 7]] arr = np.array(arr) print(arr.shape) # (3, 4) print(arr) # [[ 8 9 10 11] # [ 0 1 2 3] # [ 4 5 6 7]] idx = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]] idx = np.array(idx) print(idx.shape) # (3, 4) print(idx) # [[1 0 0 0] # [0 1 0 0] # [0 0 1 0]] result = arr[idx] # <class 'numpy.ndarray'> print(result.shape) # (3, 4, 4) print(result) # [[[ 0 1 2 3] # [ 8 9 10 11] # [ 8 9 10 11] # [ 8 9 10 11]] # [[ 8 9 10 11] # [ 0 1 2 3] # [ 8 9 10 11] # [ 8 9 10 11]] # [[ 8 9 10 11] # [ 8 9 10 11] # [ 0 1 2 3] # [ 8 9 10 11]]] result = arr[idx == 1] print(result.shape) print(result) # [8 1 6]","title":"\u5e03\u5c14\u503c\u6570\u7ec4(Boolean Array)\u7684\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch01/#_10","text":"\u548cPython\u7684\u5185\u5efa\u5217\u8868\u7c7b\u578b\u76f8\u4f3c\uff0cNumPy\u6570\u7ec4\u53ef\u4ee5\u4f7f\u7528sort\u65b9\u6cd5\u6309\u4f4d\u7f6e\u6392\u5e8f\u3002 \u9876\u5c42\u7684np.sort\u65b9\u6cd5\u8fd4\u56de\u7684\u662f\u5df2\u7ecf\u6392\u5e8f\u597d\u7684\u6570\u7ec4 \u62f7\u8d1d \uff0c\u800c\u4e0d\u662f\u5bf9\u539f\u6570\u7ec4\u6309\u4f4d\u7f6e\u6392\u5e8f\u3002 array = np.random.randn(6) print(\"\u6837\u672c\u77e9\u9635\", array) array.sort() print(\"\u6392\u5e8f\u540e\u77e9\u9635\", array) # \u6837\u672c\u77e9\u9635 [-0.03119521 0.01839556 0.79238537 -2.46622775 0.62522211 0.22430846] # \u6392\u5e8f\u540e\u77e9\u9635 [-2.46622775 -0.03119521 0.01839556 0.22430846 0.62522211 0.79238537] \u591a\u7ef4\u6570\u7ec4\u4e2d\u6839\u636e\u4f20\u9012\u7684axis\u503c\uff0c\u6cbf\u7740\u8f74\u5411\u5bf9\u6bcf\u4e2a\u4e00\u7ef4\u6570\u636e\u6bb5\u8fdb\u884c\u6392\u5e8f\u3002 array = np.random.randn(5, 3) print(\"\u6837\u672c\u77e9\u9635 \\n\", array) array.sort(1) print(\"\u5bf91\u8f74\u6392\u5e8f\u540e\u77e9\u9635 \\n\", array) # \u6837\u672c\u77e9\u9635 # [[-0.88057833 0.30160954 -2.08788148] # [ 0.27969618 0.62923028 -0.58157581] # [-1.87194465 -1.1102104 1.09589605] # [ 0.1467938 -1.01558304 -0.25905165] # [-0.17294279 0.62369511 0.17947059]] # \u5bf91\u8f74\u6392\u5e8f\u540e\u77e9\u9635 # [[-2.08788148 -0.88057833 0.30160954] # [-0.58157581 0.27969618 0.62923028] # [-1.87194465 -1.1102104 1.09589605] # [-1.01558304 -0.25905165 0.1467938 ] # [-0.17294279 0.17947059 0.62369511]]","title":"\u6392\u5e8f"},{"location":"python/DataAnalysis/ch01/#_11","text":"NumPy\u5305\u542b\u4e00\u4e9b\u9488\u5bf9\u4e00\u7ef4 ndarray \u6570\u7ec4\u7684\u57fa\u7840\u96c6\u5408\u64cd\u4f5c\u3002 np.unique(x, y) \u8ba1\u7b97x\u7684\u552f\u4e00\u503c\uff0c\u5e76\u6392\u5e8f\u3002 names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe']) result = np.unique(names) # NumPy\u5b9e\u73b0 print(result) # ['Bob' 'Joe' 'Will'] result = sorted(set(names)) # \u7eafPython\u5b9e\u73b0 print(result) # ['Bob' 'Joe' 'Will'] inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) result = np.unique(inits) print(result) # [1 2 3 5] np.in1d(x, y) \u8ba1\u7b97x\u4e2d\u7684\u5143\u7d20\u662f\u5426\u5305\u542b\u5728y\u4e2d\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.in1d(inits, [3, 4, 5])) # [ True True True False False False False True True] np.intersect1d(x, y) \uff0c\u8ba1\u7b97x\u548cy\u7684\u4ea4\u96c6\uff0c\u5e76\u6392\u5e8f\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.intersect1d(inits, [3, 4, 5])) # [3 5] np.union1d(x, y) \u8ba1\u7b97x\u548cy\u7684\u5e76\u96c6\uff0c\u5e76\u6392\u5e8f\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.union1d(inits, [3, 4, 5])) # [1 2 3 4 5] np.setdiff1d(x, y) \u5dee\u96c6\uff0c\u5728x\u4e2d\u4f46\u4e0d\u5728y\u4e2d\u7684\u5143\u7d20\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.setdiff1d(inits, [3, 4, 5])) # [1 2] np.setxor1d(x, y) \u5f02\u6216\u96c6\uff0c\u5728x\u6216\u8005y\u4e2d\uff0c\u4f46\u4e0d\u5c5e\u4e8ex\uff0cy\u4ea4\u96c6\u7684\u5143\u7d20\u3002 inits = np.array([3, 3, 3, 2, 2, 1, 1, 5, 5]) print(np.setxor1d(inits, [3, 4, 5])) # [1 2 4]","title":"\u552f\u4e00\u503c\u4e0e\u5176\u4ed6\u96c6\u5408\u903b\u8f91"},{"location":"python/DataAnalysis/ch01/#_12","text":"NumPy\u53ef\u4ee5\u5728\u786c\u76d8\u4e2d\u5c06\u6570\u636e\u4ee5\u6587\u672c\u6216\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u5f62\u5f0f\u8fdb\u884c\u5b58\u5165\u786c\u76d8\u6216\u7531\u786c\u76d8\u8f7d\u5165\u3002 \u5f53\u524d\u53ea\u5173\u6ce8NumPy\u7684\u5185\u5efa\u4e8c\u8fdb\u5236\u683c\u5f0f\uff0c\u56e0\u4e3a\u5927\u90e8\u5206\u7528\u6237\u66f4\u503e\u5411\u4e8e\u4f7f\u7528pandas\u6216\u5176\u4ed6\u5de5\u5177\u6765\u8f7d\u5165\u6587\u672c\u6216\u8868\u683c\u578b\u6570\u636e\u3002 np.save \u548c np.load \u662f\u9ad8\u6548\u5b58\u53d6\u786c\u76d8\u6570\u636e\u7684\u4e24\u5927\u5de5\u5177\u51fd\u6570\u3002\u6570\u7ec4\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u662f\u4ee5 \u672a\u538b\u7f29 \u7684\u683c\u5f0f\u8fdb\u884c\u5b58\u50a8\u7684\uff0c\u540e\u7f00\u540d\u662f.npy\u3002 import numpy as np array1 = np.arange(10) array2 = np.arange(15).reshape(3, 5) array3 = np.arange(30).reshape(3, 2, 5) print(array1) # [0 1 2 3 4 5 6 7 8 9] print(array2) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] print(array3) # [[[ 0 1 2 3 4] # [ 5 6 7 8 9]] # [[10 11 12 13 14] # [15 16 17 18 19]] # [[20 21 22 23 24] # [25 26 27 28 29]]] # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myProject/mySite' # \u66f4\u6539\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myProject/mySite/docs/python/datasets/examples') # \u4fdd\u5b58\u5230\u9ed8\u8ba4\u8def\u5f84\u3002npy\u540e\u7f00\u540d\u4f1a\u88ab\u81ea\u52a8\u52a0\u4e0a np.save('some_array', array1) # \u8bfb\u53d6\u6240\u4fdd\u5b58\u7684\u6587\u4ef6 result = np.load('some_array.npy') # \u5bf9\u6bd4\u7ed3\u679c\u4e00\u81f4\u3002 print(result) # [0 1 2 3 4 5 6 7 8 9] # \u5c06\u591a\u4e2a\u6570\u7ec4\u4fdd\u5b58\u5230\u672a\u538b\u7f29\u7684\u5355\u4e2a\u6587\u4ef6\u4e2d\uff0c.npz\u683c\u5f0f np.savez('some_array_archive.npz', a=array2, b=array3) result = np.load('some_array_archive.npz') # reslt\u662f\u4e00\u4e2a\u5b57\u5178\u578b\u7684\u5bf9\u8c61 print(result['b']) # \u8f7d\u5165\u5355\u4e2a\u6570\u7ec4b # [[[ 0 1 2 3 4] # [ 5 6 7 8 9]] # [[10 11 12 13 14] # [15 16 17 18 19]] # [[20 21 22 23 24] # [25 26 27 28 29]]]","title":"\u4f7f\u7528\u6570\u7ec4\u8fdb\u884c\u6587\u4ef6\u8f93\u5165\u548c\u8f93\u51fa"},{"location":"python/DataAnalysis/ch01/#_13","text":"\u53c2\u8003\u94fe\u63a5\uff1a https://www.numpy.org.cn/reference/routines/linalg.html https://github.com/teadocs/numpy-cn \u5e0c\u814a\u5b57\u6bcd: \u0391 \u03b1 /'\u00e6lf\u0259/ alpha \u0392 \u03b2 /'bi:t\u0259/ beta \u0393 \u03b3 /'g\u00e6m\u0259/ gamma \u0394 \u03b4 /'delt\u0259/ delta \u0395 \u03b5 /'eps\u026al\u0252n/ epsilon \u0396 \u03b6 /'zi:t\u0259/ zeta \u0397 \u03b7 /'i:t\u0259/ eta \u0398 \u03b8 /'\u03b8i:t\u0259/ theta \u0399 \u03b9 /'a\u026a\u0259\u028at\u0259/ iota \u039a \u03ba /'k\u00e6p\u0259/ kappa \u2227 \u03bb /'l\u00e6md\u0259/ lambda \u039c \u03bc /mju:/ mu \u039d \u03bd /nju:/ nu \u039e \u03be /ksi/ xi \u039f \u03bf /\u0259u\u02c8maikr\u0259n/ omicron \u220f \u03c0 /pa\u026a/ pi \u03a1 \u03c1 /r\u0259\u028a/ rho \u2211 \u03c3 /'s\u026a\u0261m\u0259/ sigma \u03a4 \u03c4 /t\u0254:/ tau \u03a5 \u03c5 /\u02c8ips\u026alon/ upsilon \u03a6 \u03c6 /fa\u026a/ phi \u03a7 \u03c7 /ka\u026a/ chi \u03a8 \u03c8 /psa\u026a/ psi \u03a9 \u03c9 /'\u0259\u028am\u026a\u0261\u0259/ omega numpy.linalg \u6a21\u5757\u5305\u542b\u7ebf\u6027\u4ee3\u6570\u7684\u51fd\u6570\u3002\u4f7f\u7528\u8fd9\u4e2a\u6a21\u5757\uff0c\u53ef\u4ee5\u8ba1\u7b97\u9006\u77e9\u9635\u3001\u6c42\u7279\u5f81\u503c\u3001\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u4ee5\u53ca\u6c42\u89e3\u884c\u5217\u5f0f\u7b49\u3002 import numpy as np from numpy import linalg as LA from numpy import * from numpy.linalg import inv import matplotlib.pyplot as plt","title":"\u7ebf\u6027\u4ee3\u6570"},{"location":"python/DataAnalysis/ch01/#diag","text":"np.diag \u5c06\u4e00\u4e2a\u65b9\u9635\u7684\u5bf9\u89d2\uff08\u6216\u975e\u5bf9\u89d2\uff09\u5143\u7d20\u4f5c\u4e3a\u4e00\u7ef4\u6570\u7ec4\u8fd4\u56de\uff0c\u6216\u8005\u5c06\u4e00\u7ef4\u6570\u7ec4\u8f6c\u6362\u6210\u4e00\u4e2a\u65b9\u9635\uff0c\u5e76\u4e14\u5728\u975e\u5bf9\u89d2\u7ebf\u4e0a\u6709\u96f6\u70b9\u3002 a1 = np.arange(9, dtype=float).reshape((3, 3)) r1 = np.diag(a1) r2 = np.diag(a1, k=1) r3 = np.diag(a1, k=-1) r4 = np.diag(np.diag(a1)) # \u5bf9\u89d2\u77e9\u9635 print(\"\u6837\u672c\u77e9\u9635 \\n\", a1) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\", r1) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0a\u504f\u79fb\", r2) print(\"\u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0b\u504f\u79fb\", r3) print(\"\u5bf9\u89d2\u77e9\u9635 \\n\", r4) # \u6837\u672c\u77e9\u9635 # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] # \u77e9\u9635\u5bf9\u89d2\u7ebf [0. 4. 8.] # \u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0a\u504f\u79fb [1. 5.] # \u77e9\u9635\u5bf9\u89d2\u7ebf\u5411\u4e0b\u504f\u79fb [3. 7.] # \u5bf9\u89d2\u77e9\u9635 # [[0. 0. 0.] # [0. 4. 0.] # [0. 0. 8.]]","title":"diag"},{"location":"python/DataAnalysis/ch01/#dot","text":"np.dot \u5c06\u5411\u91cf\u4e2d\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0c\u518d\u76f8\u52a0\u6240\u5f97\u3002\u5373\u666e\u901a\u7684\u5411\u91cf\u4e58\u6cd5\u8fd0\u7b97\uff0c\u6216 \u77e9\u9635\u70b9\u4e58 \u3002 a1 = np.dot(3, 4) print(a1) # 12 a2 = np.arange(9, dtype=float).reshape((3, 3)) r2 = np.dot(a2, a2) print(a2) # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] print(r2) # [[ 15. 18. 21.] # [ 42. 54. 66.] # [ 69. 90. 111.]] r3 = np.dot([2j, 3j], [2j, 3j]) print(r3) # (-13+0j)","title":"dot"},{"location":"python/DataAnalysis/ch01/#trace","text":"np.trace \u8ba1\u7b97\u5bf9\u89d2\u5143\u7d20\u548c\u3002 a1 = np.arange(9, dtype=float).reshape((3, 3)) print(\"\u6837\u672c\u77e9\u9635 \\n\", a1) r1 = np.trace(a1) print(\"\u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c\", r1) a2 = np.arange(24, dtype=float).reshape((2, 3, 4)) r2 = np.trace(a2) print(\"\u6837\u672c\u77e9\u9635 \\n\", a2) print(\"\u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c\", r2) # \u6837\u672c\u77e9\u9635 # [[0. 1. 2.] # [3. 4. 5.] # [6. 7. 8.]] # \u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c 12.0 # \u6837\u672c\u77e9\u9635 # [[[ 0. 1. 2. 3.] # [ 4. 5. 6. 7.] # [ 8. 9. 10. 11.]] # # [[12. 13. 14. 15.] # [16. 17. 18. 19.] # [20. 21. 22. 23.]]] # \u5bf9\u89d2\u7ebf\u5143\u7d20\u6c42\u548c [16. 18. 20. 22.]","title":"trace"},{"location":"python/DataAnalysis/ch01/#det","text":"np.det \u8ba1\u7b97\u77e9\u9635\u7684\u884c\u5217\u5f0f\uff08\u65b9\u9635\uff09\u3002 \u4e8c\u9636\u884c\u5217\u5f0f[[a, b], [c, d]]\u7684\u503c\u662fad - bc \u4e09\u9636\u884c\u5217\u5f0f [[a, b, c], [d, e, f], [g, h, i]]\u7684\u503c\u662f aei + bfd + cdh - ceg - bdi - afh \u4e09\u9636\u884c\u5217\u5f0f\u7684\u6027\u8d28 \u6027\u8d281\uff1a\u884c\u5217\u5f0f\u4e0e\u5b83\u7684\u8f6c\u7f6e\u884c\u5217\u5f0f\u76f8\u7b49\u3002 \u6027\u8d282\uff1a\u4e92\u6362\u884c\u5217\u5f0f\u7684\u4e24\u884c(\u5217)\uff0c\u884c\u5217\u5f0f\u53d8\u53f7\u3002 \u63a8\u8bba\uff1a\u5982\u679c\u884c\u5217\u5f0f\u6709\u4e24\u884c(\u5217)\u5b8c\u5168\u76f8\u540c\uff0c\u5219\u6b64\u884c\u5217\u5f0f\u4e3a\u96f6\u3002 \u6027\u8d283\uff1a\u884c\u5217\u5f0f\u7684\u67d0\u4e00\u884c(\u5217)\u4e2d\u6240\u6709\u7684\u5143\u7d20\u90fd\u4e58\u4ee5\u540c\u4e00\u6570k\uff0c\u7b49\u4e8e\u7528\u6570k\u4e58\u6b64\u884c\u5217\u5f0f\u3002 \u63a8\u8bba\uff1a\u884c\u5217\u5f0f\u4e2d\u67d0\u4e00\u884c(\u5217)\u7684\u6240\u6709\u5143\u7d20\u7684\u516c\u56e0\u5b50\u53ef\u4ee5\u63d0\u5230\u884c\u5217\u5f0f\u7b26\u53f7\u7684\u5916\u9762\u3002 \u6027\u8d284\uff1a\u884c\u5217\u5f0f\u4e2d\u5982\u679c\u6709\u4e24\u884c(\u5217)\u5143\u7d20\u6210\u6bd4\u4f8b\uff0c\u5219\u6b64\u884c\u5217\u5f0f\u7b49\u4e8e\u96f6\u3002 \u6027\u8d285\uff1a\u628a\u884c\u5217\u5f0f\u7684\u67d0\u4e00\u5217(\u884c)\u7684\u5404\u5143\u7d20\u4e58\u4ee5\u540c\u4e00\u6570\u7136\u540e\u52a0\u5230\u53e6\u4e00\u5217(\u884c)\u5bf9\u5e94\u7684\u5143\u7d20\u4e0a\u53bb\uff0c\u884c\u5217\u5f0f\u4e0d\u53d8\u3002 a1 = np.array([[1, 2], [3, 4]]) r1 = np.linalg.det(a1) print(\"\u4e8c\u9636\u65b9\u9635 \\n\", a1) print(\"\u4e8c\u9636\u884c\u5217\u5f0f\u7684\u503c\", r1) # \u4e8c\u9636\u65b9\u9635 # [[1 2] # [3 4]] # \u4e8c\u9636\u884c\u5217\u5f0f\u7684\u503c -2.0000000000000004 # \u5e0c\u814a\u5b57\u6bcd # \u03b1, \u03b2, \u03b3,\u03b4, \u03b5, \u03b6, \u03b7, \u03b8, \u03b9, \u03ba, \u03bb, \u03bc, \u03bd, # \u03be, \u03bf, \u03c0, \u03c1, \u03c2, \u03c3, \u03c4, \u03c5, \u03c6, \u03c7, \u03c8, \u03c9, a2 = np.arange(9).reshape(3, 3) r2 = np.linalg.det(a2) print(\"\u4e09\u9636\u65b9\u9635 \\n\", a2) print(\"\u4e09\u9636\u884c\u5217\u5f0f\u7684\u503c\", r2) # \u4e09\u9636\u65b9\u9635 # [[0 1 2] # [3 4 5] # [6 7 8]] # \u4e09\u9636\u884c\u5217\u5f0f\u7684\u503c 0.0 a3 = np.arange(16).reshape(4, 4) r3 = np.linalg.det(a3) print(\"\u56db\u9636\u65b9\u9635 \\n\", a3) print(\"\u56db\u9636\u884c\u5217\u5f0f\u7684\u503c\", r3) # \u56db\u9636\u65b9\u9635 # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]# \u5e0c\u814a\u5b57\u6bcd # \u03b1, \u03b2, \u03b3,\u03b4, \u03b5, \u03b6, \u03b7, \u03b8, \u03b9, \u03ba, \u03bb, \u03bc, \u03bd, # \u03be, \u03bf, \u03c0, \u03c1, \u03c2, \u03c3, \u03c4, \u03c5, \u03c6, \u03c7, \u03c8, \u03c9, # [12 13 14 15]] # \u56db\u9636\u884c\u5217\u5f0f\u7684\u503c 0.0","title":"det"},{"location":"python/DataAnalysis/ch01/#eig","text":"np.eig \u8ba1\u7b97\u65b9\u9635\u7684\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\u3002 \u7279\u5f81\u503c\u4e0e\u7279\u5f81\u5411\u91cf\u7684\u5b9a\u4e49\uff1a\u8bbeA\u662fn\u9636\u65b9\u9635\uff0c\u82e5\u6570\u03bb\u548cn\u7ef4\u975e\u96f6\u5217\u5411\u91cfx\uff0c\u4f7f\u5f97Ax = \u03bbx\u6210\u7acb\uff0c\u5219\u79f0\u03bb\u662f\u65b9\u9635A\u7684\u4e00\u4e2a\u7279\u5f81\u503c\uff0cx\u4e3a\u65b9\u9635A\u7684\u5bf9\u5e94\u4e8e\u7279\u5f81\u503c\u03bb\u7684\u4e00\u4e2a\u7279\u5f81\u5411\u91cf\u3002 A\u662f\u65b9\u9635\u3002\uff08\u5bf9\u4e8e\u975e\u65b9\u9635\uff0c\u662f\u6ca1\u6709\u7279\u5f81\u503c\u7684\uff0c\u4f46\u4f1a\u6709\u6761\u4ef6\u6570\u3002\uff09\u7279\u5f81\u5411\u91cfx\u4e3a\u975e\u96f6\u5217\u5411\u91cf\u3002 v_eigenvectors, v_eigenvalues = LA.eig(np.diag((1, 2, 3))) print(\"\u7279\u5f81\u5411\u91cf\", v_eigenvectors) print(\"\u7279\u5f81\u503c \\n\", v_eigenvalues) # \u7279\u5f81\u5411\u91cf [1. 2. 3.] # \u7279\u5f81\u503c # [[1. 0. 0.] # [0. 1. 0.] # [0. 0. 1.]] v_eigenvectors, v_eigenvalues = LA.eig(np.array([[1, -1], [1, 1]])) print(\"\u7279\u5f81\u5411\u91cf\", v_eigenvectors) print(\"\u7279\u5f81\u503c \\n\", v_eigenvalues) # \u7279\u5f81\u5411\u91cf [1.+1.j 1.-1.j] # \u7279\u5f81\u503c # [[0.70710678+0.j 0.70710678-0.j ] # [0. -0.70710678j 0. +0.70710678j]]","title":"eig"},{"location":"python/DataAnalysis/ch01/#inv","text":"np.inv \u8ba1\u7b97\u65b9\u9635\u7684\u9006\u77e9\u9635\u3002 a1 = np.array([[1, 2], [3, 4]]) r1 = inv(a1) r2 = inv(np.matrix(a1)) print(\"\u539f\u77e9\u9635 \\n\", a1) print(\"\u9006\u77e9\u9635 \\n\", r1) print(\"\u9006\u77e9\u9635 \\n\", r2) # \u539f\u77e9\u9635 # [[1 2] # [3 4]] # \u9006\u77e9\u9635 # [[-2. 1. ] # [ 1.5 -0.5]] # \u9006\u77e9\u9635 # [[-2. 1. ] # [ 1.5 -0.5]]","title":"inv"},{"location":"python/DataAnalysis/ch01/#pinv","text":"np.pinv \u8ba1\u7b97\u77e9\u9635\u7684Moore-Penrose\u4f2a\u9006(\u6469\u5c14\uff0d\u5f6d\u82e5\u65af\u5e7f\u4e49\u9006)\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u68c0\u9a8c a * a+ * a == a \u548c a+ * a * a+ == a+ a = np.random.randn(9, 6) B = np.linalg.pinv(a) r1 = np.allclose(a, np.dot(a, np.dot(B, a))) r2 = np.allclose(B, np.dot(B, np.dot(a, B))) print(a) print(B) print(r1) # True print(r2) # True # a: # [[-2.30316101 -0.63217332 1.24134743 -0.72492307 0.12456801 -0.14192548] # [ 1.37573495 0.07626697 -0.71870843 1.26824984 -0.79485727 -0.24630455] # [ 0.29003175 -1.23931665 -0.50864107 -0.31140718 0.45467649 -2.44973999] # [-0.70748664 -1.2995059 0.85126149 -1.10918804 -2.10042342 0.75942293] # [ 1.91765238 1.23892103 1.58516486 -1.65520154 0.11894439 0.84536298] # [ 1.03220791 0.1715148 0.85595408 0.58569706 1.34066384 -1.5782386 ] # [-0.54432889 -0.0114189 1.55403934 0.89852512 1.15586365 -0.30733805] # [-0.80874673 0.14602121 1.04680044 1.98722514 0.39766383 0.75178788] # [ 0.01664663 0.06243353 -0.50725334 -0.37707204 -1.76701091 -0.33866559]] # B: # [[-0.25055838 0.13963115 0.08990923 0.16280282 0.12997291 0.05088469 -0.01541299 -0.01656133 -0.21731387] # [ 0.22862622 -0.05108109 -0.2639602 -0.47835978 0.11776862 0.09324694 0.00436756 -0.00609393 0.61995597] # [ 0.10422554 0.03985857 0.00198025 0.15139023 0.17165026 0.15697725 0.17360246 0.13150089 0.08378135] # [-0.07021378 0.17665487 -0.04109252 0.0015022 -0.11998477 0.0543575 0.08649033 0.21190785 0.04065729] # [-0.08110336 -0.15274536 0.05601496 -0.07967802 -0.02454705 -0.04152356 0.00071268 -0.05981012 -0.43996066] # [-0.17998537 -0.03160871 -0.12587707 0.16856246 0.00565094 -0.21038026 -0.06060039 0.04322126 -0.42038066]]","title":"pinv"},{"location":"python/DataAnalysis/ch01/#qr","text":"np.qr \u8ba1\u7b97QR\u5206\u89e3\u3002QR\uff08\u6b63\u4ea4\u4e09\u89d2\uff09\u5206\u89e3\u6cd5\u662f\u6c42\u4e00\u822c\u77e9\u9635\u5168\u90e8\u7279\u5f81\u503c\u7684\u6700\u6709\u6548\u5e76\u5e7f\u6cdb\u5e94\u7528\u7684\u65b9\u6cd5\u3002 \u4e00\u822c\u77e9\u9635\u5148\u7ecf\u8fc7\u6b63\u4ea4\u76f8\u4f3c\u53d8\u5316\u6210\u4e3aHessenberg\u77e9\u9635\uff0c\u7136\u540e\u518d\u5e94\u7528QR\u65b9\u6cd5\u6c42\u7279\u5f81\u503c\u548c\u7279\u5f81\u5411\u91cf\u3002QR\u5206\u89e3\u6cd5\u662f\u5c06\u77e9\u9635\u5206\u89e3\u6210\u4e00\u4e2a\u6b63\u89c4\u6b63\u4ea4\u77e9\u9635Q\u4e0e\u4e0a\u4e09\u89d2\u5f62\u77e9\u9635R\uff0c\u6240\u4ee5\u79f0\u4e3aQR\u5206\u89e3\u6cd5\u3002 a = np.arange(9).reshape(3, 3) q, r = np.linalg.qr(a) print(\"\u539f\u77e9\u9635 \\n\", a) print(\"\u6b63\u4ea4\u77e9\u9635 \\n\", q) print(\"\u4e0a\u4e09\u89d2\u77e9\u9635 \\n\", r) # \u539f\u77e9\u9635 # [[0 1 2] # [3 4 5] # [6 7 8]] # \u6b63\u4ea4\u77e9\u9635 # [[ 0. 0.91287093 0.40824829] # [-0.4472136 0.36514837 -0.81649658] # [-0.89442719 -0.18257419 0.40824829]] # \u4e0a\u4e09\u89d2\u77e9\u9635 # [[-6.70820393e+00 -8.04984472e+00 -9.39148551e+00] # [ 0.00000000e+00 1.09544512e+00 2.19089023e+00] # [ 0.00000000e+00 0.00000000e+00 -8.88178420e-16]]","title":"qr"},{"location":"python/DataAnalysis/ch01/#svd","text":"np.svd \u8ba1\u7b97\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u3002 \u51e0\u4f55\u610f\u4e49\uff1aSVD\u5206\u89e3\u7684\u51e0\u4f55\u610f\u4e49\u662f\u4efb\u4f55\u4e00\u4e2a\u77e9\u9635A\u5728\u4e00\u7cfb\u5217\u65cb\u8f6c\u548c\u5e73\u79fb\u4e0b\u90fd\u80fd\u8f6c\u5316\u6210\u4e00\u4e2a\u5bf9\u89d2\u77e9\u9635\u2211 , \u5176\u4e2d\u9149\u9635U, V\u7684\u51e0\u4f55\u610f\u4e49\u5c31\u662f\u4e00\u7cfb\u5217\u65cb\u8f6c\u548c\u5e73\u79fb\u7684\u53e0\u52a0\u3002 a = mat([[1, 2, 3],[4, 5, 6]]) U, sigma, V = np.linalg.svd(a) print(\"\u539f\u77e9\u9635 \\n\", a) print(\"\u5de6\u5947\u5f02\u503cU \\n\", U) print(\"\u5947\u5f02\u503cSigma \\n\", sigma) print(\"\u53f3\u5947\u5f02\u503cV \\n\", V) # \u539f\u77e9\u9635 # [[1 2 3] # [4 5 6]] # \u5de6\u5947\u5f02\u503cU # [[-0.3863177 -0.92236578] # [-0.92236578 0.3863177 ]] # \u5947\u5f02\u503cSigma # [9.508032 0.77286964] # \u53f3\u5947\u5f02\u503cV # [[-0.42866713 -0.56630692 -0.7039467 ] # [ 0.80596391 0.11238241 -0.58119908] # [ 0.40824829 -0.81649658 0.40824829]]","title":"svd"},{"location":"python/DataAnalysis/ch01/#solve","text":"np.solve \u6c42\u89e3x\u7684\u7ebf\u6027\u7cfb\u7edfAx = b\uff0c\u5176\u4e2dA\u662f\u65b9\u9635\u3002 \u89e3\u65b9\u7a0b\u7ec4\uff1a x + 2y = 1 3x + 5y = 2 a = np.array([[1, 2], [3, 5]]) b = np.array([1, 2]) x = np.linalg.solve(a, b) print(x) # [-1. 1.]","title":"solve"},{"location":"python/DataAnalysis/ch01/#lstsq","text":"np.lstsq \u8ba1\u7b97Ax = b\u7684\u6700\u5c0f\u4e8c\u4e58\u89e3\u3002 \u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u62df\u5408\u6570\u636e\u5f97\u5230\u4e00\u4e2a\u5f62\u5982y = mx + c\u7684\u7ebf\u6027\u65b9\u7a0b\uff08Return the least-squares solution to a linear matrix equation\uff09\u3002 x = np.array([0, 1, 2, 3]) # \u539f\u59cb\u6570\u636e\u70b9\u7684\u6a2a\u5750\u6807 y = np.array([-1, 0.2, 0.9, 2.1]) # \u539f\u59cb\u6570\u636e\u70b9\u7684\u7eb5\u5750\u6807 print(x) # [0 1 2 3] print(y) # [-1. 0.2 0.9 2.1] A = np.vstack([x, np.ones(len(x))]).T # \u6784\u9020\u7cfb\u6570\u77e9\u9635 print(A) # [[0. 1.] # [1. 1.] # [2. 1.] # [3. 1.]] m, c = np.linalg.lstsq(A, y, rcond=None)[0] # \u89e3\u51fa\u659c\u7387a\u548c\u7eb5\u622a\u8dddc plt.plot(x, y, 'o', label='Original data', markersize=10) # \u505a\u51fa\u539f\u59cb\u6570\u636e\u6563\u70b9\u56fe plt.plot(x, m*x + c, 'r', label='Fitted line') # \u7528\u4e0a\u9762\u89e3\u51fa\u7684\u53c2\u6570\u505a\u51fa\u62df\u5408\u66f2\u7ebfy=mx+c plt.legend() plt.show()","title":"lstsq"},{"location":"python/DataAnalysis/ch01/#_14","text":"numpy.random \u6a21\u5757\u586b\u8865\u4e86Python\u5185\u5efa\u7684 random \u6a21\u5757\u7684\u4e0d\u8db3\uff0c\u53ef\u4ee5\u9ad8\u6548\u5730\u751f\u6210\u591a\u79cd\u6982\u7387\u5206\u5e03\u4e0b\u7684\u5b8c\u6574\u6837\u672c\u503c\u6570\u7ec4\u3002 numpy.random \u4e2d\u7684\u6570\u636e\u751f\u6210\u51fd\u6570\u516c\u7528\u4e86\u4e00\u4e2a\u5168\u5c40\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002 \u4f7f\u7528 numpy.random.RandomState \u751f\u6210\u4e00\u4e2a\u968f\u673a\u6570\u751f\u6210\u5668\uff0c\u4f7f\u6570\u636e\u72ec\u7acb\u4e8e\u5176\u4ed6\u7684\u968f\u673a\u6570\u72b6\u6001\u3002 \u901a\u8fc7 np.random.seed \u66f4\u6539NumPy\u7684\u968f\u673a\u6570\u79cd\u5b50\u3002 numpy.random \u4e2d\u7684\u90e8\u5206\u51fd\u6570\u5217\u8868 seed: \u5411\u968f\u673a\u6570\u751f\u6210\u5668\u4f20\u9012\u968f\u673a\u72b6\u6001\u79cd\u5b50 permutation: \u8fd4\u56de\u4e00\u4e2a\u5e8f\u5217\u7684\u968f\u673a\u6392\u5217\uff0c\u6216\u8005\u8fd4\u56de\u4e00\u4e2a\u4e71\u5e8f\u7684\u6574\u6570\u8303\u56f4\u5e8f\u5217 shuffle: \u968f\u673a\u6392\u5217\u4e00\u4e2a\u5e8f\u5217 rand: \u4ece\u5747\u5300\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c randint: \u6839\u636e\u7ed9\u5b9a\u7684\u7531\u4f4e\u5230\u9ad8\u7684\u8303\u56f4\u62bd\u53d6\u968f\u673a\u6574\u6570 randn: \u4ece\u5747\u503c0\u65b9\u5dee1\u7684\u6b63\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c(MATLAB\u578b\u63a5\u53e3\uff09 binomial: \u4ece\u4e8c\u9879\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c normal: \u4ece\u6b63\u6001\uff08\u9ad8\u65af\uff09\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c beta\u4ecebeta: \u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c chisquare: \u4ece\u5361\u65b9\u5206\u5e03\u4e2d\u62bd\u53d6\u6837\u672c \u4f8b\u5982\uff0c\u4f7f\u7528normal\u6765\u83b7\u5f97\u4e00\u4e2a4\u00d74\u7684\u6b63\u6001\u5206\u5e03\u6837\u672c\u6570\u7ec4\uff0c\u79f0\u4e3a\u4f2a\u968f\u673a\u6570\u3002 import numpy as np samples = np.random.normal(size=(4, 4)) print(samples) # [[ 0.78583658 -0.27462104 -0.53027675 -0.62675004] # [ 0.39054781 1.20503691 -0.0057432 0.17243182] # [-0.41516669 -0.93335854 0.01996088 -0.12707275] # [ 0.42952379 2.56998319 0.14848737 -0.42871493]]","title":"\u4f2a\u968f\u673a\u6570\u751f\u6210"},{"location":"python/DataAnalysis/ch01/#_15","text":"import matplotlib.pyplot as plt import numpy as np position = 0 walk = [position] nwalks = 5000 nsteps = 1000 draws = np.random.randint(0, 2, size=(nwalks, nsteps)) steps = np.where(draws > 0, 1, -1) walks = steps.cumsum() plt.plot(walks[:500000000000000000000000000]) plt.show() \u8f93\u51fa\u56fe\u50cf\uff1a","title":"\u793a\u4f8b\uff1a\u968f\u673a\u6f2b\u6b65"},{"location":"python/DataAnalysis/ch02/","text":"Pandas\u5165\u95e8 \u7ea6\u5b9a\uff1a import numpy as np import pandas as pd from pandas import Series, DataFrame import pandas_datareader as web pandas\u6570\u636e\u7ed3\u6784\u4ecb\u7ecd Series Series\u662f\u4e00\u79cd\u4e00\u7ef4\u7684\u6570\u7ec4\u578b\u5bf9\u8c61\uff0c\u5b83\u5305\u542b\u4e86\u4e00\u4e2a\u503c\u5e8f\u5217\uff08\u4e0eNumPy\u4e2d\u7684\u7c7b\u578b\u76f8\u4f3c\uff09\uff0c\u5e76\u4e14\u5305\u542b\u4e86\u6570\u636e\u6807\u7b7e\uff0c\u79f0\u4e3a \u7d22\u5f15\uff08index\uff09 \u3002 \u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u8003\u8651Series\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5b83\u662f\u4e00\u4e2a \u957f\u5ea6\u56fa\u5b9a\u4e14\u6709\u5e8f\u7684\u5b57\u5178 \uff0c\u56e0\u4e3a\u5b83\u5c06\u7d22\u5f15\u503c\u548c\u6570\u636e\u503c\u6309\u4f4d\u7f6e\u914d\u5bf9\u3002\u7d22\u5f15\u5728\u5de6\u8fb9\uff0c\u503c\u5728\u53f3\u8fb9\u3002 obj = pd.Series([4, 7, -5, 3]) print(obj) # 0 4 # 1 7 # 2 -5 # 3 3 # dtype: int64 print(obj.values) # [ 4 7 -5 3 print(obj.index) # RangeIndex(start=0, stop=4, step=1) \u81ea\u5b9a\u4e49index obj = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c']) print(obj) # d 4 # b 7 # a -5 # c 3 # dtype: int64 print(obj.values) # [ 4 7 -5 3] print(obj.index) # Index(['d', 'b', 'a', 'c'], dtype='object') # \u8f93\u51fa\u7d22\u5f15\u503c\u4e3a'a'\u7684Series\u503c print(obj['a']) # -5 # \u4f7f\u7528\u5e03\u5c14\u503c\u6570\u7ec4\u8fdb\u884c\u8fc7\u6ee4Series\u503c print(obj[obj > 3]) # d 4 # b 7 # dtype: int64 # \u5bf9Series\u503c\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97 print(obj * 2) # d 8 # b 14 # a -10 # c 6 # dtype: int64 # \u5bf9Series\u503c\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97 print(np.exp(obj)) # d 54.598150 # b 1096.633158 # a 0.006738 # c 20.085537 # dtype: float64 # \u66f4\u65b0Series\u6570\u7ec4\u503c obj['a'] = 9 # \u8f93\u51fa\u6307\u5b9a\u7d22\u5f15\u503c\u7684Series\u503c\uff0c\u6ce8\u610f\uff0c\u7d22\u5f15\u6761\u4ef6\u662f\u5217\u8868 print(obj[['a', 'b', 'c']]) # a 9 # b 7 # c 3 # dtype: int64 # \u6ce8\u610f\uff0c\u4e0b\u9762\u7684\u5224\u65ad\u662f\u7d22\u5f15\u503c\uff0c\u975eSeries\u503c print(obj) print(7 in obj) # False print('a' in obj) # True \u901a\u8fc7\u5b57\u5178\u751f\u6210\u4e00\u4e2aSeries\u3002 NaN \uff08not a number\uff09\uff0c\u8fd9\u662fpandas\u4e2d\u6807\u8bb0\u7f3a\u5931\u503c\u6216NA\u503c\u7684\u65b9\u5f0f\u3002 \u5f53\u628a\u5b57\u5178\u4f20\u9012\u7ed9Series\u6784\u9020\u51fd\u6570\u65f6\uff0c\u4ea7\u751f\u7684Series\u7684\u7d22\u5f15\u5c06\u662f\u6392\u5e8f\u597d\u7684\u5b57\u5178\u952e\u3002\u53ef\u4ee5\u5c06\u5b57\u5178\u952e\u6309\u7167\u4f60\u6240\u60f3\u8981\u7684\u987a\u5e8f\u4f20\u9012\u7ed9\u6784\u9020\u51fd\u6570\uff0c\u4ece\u800c\u4f7f\u751f\u6210\u7684Series\u7684\u7d22\u5f15\u987a\u5e8f\u7b26\u5408\u9884\u671f\u3002 \u770b\u4e0b\u4f8b\uff0c\u901a\u8fc7\u5b57\u5178sdata\u751f\u6210Series\u3002 sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} obj3 = pd.Series(sdata) print(sdata) # {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} print(obj3) # Ohio 35000 # Texas 71000 # Oregon 16000 # Utah 5000 # dtype: int64 \u901a\u8fc7\u6307\u5b9a\u7d22\u5f15states\u53bb\u5339\u914d\u5b57\u5178sdata\u751f\u6210\u57fa\u4e8e\u65b0\u7d22\u5f15states\u7684Series\u3002 states = ['California', 'Ohio', 'Oregon', 'Texas'] obj4 = pd.Series(sdata, index=states) print(obj4) # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64 \u5bf9Series\u8fdb\u884c\u5e03\u5c14\u503c\u5224\u65ad\u3002 print(pd.isnull(obj4)) # California True # Ohio False # Oregon False # Texas False # dtype: bool print(pd.notnull(obj4)) # California False # Ohio True # Oregon True # Texas True # dtype: bool \u5bf9Series\u8fdb\u884c\u5e03\u5c14\u503c\u5224\u65ad\u3002 print(obj4.isnull) # <bound method Series.isnull of California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64> print(obj4.notnull) # <bound method Series.notnull of California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64> Series\u7684\u81ea\u52a8\u5bf9\u9f50\u7d22\u5f15\uff0c\u4e0e\u6570\u636e\u5e93\u7684join\u64cd\u4f5c\u662f\u975e\u5e38\u76f8\u4f3c\u3002 print(\"obj3 \\n\", obj3) # obj3 # Ohio 35000 # Texas 71000 # Oregon 16000 # Utah 5000 # dtype: int64 print(\"obj4 \\n\", obj4) # obj4 # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64 print(\"obj3+obj4 \\n\", obj3 + obj4) # obj3+obj4 # California NaN # Ohio 70000.0 # Oregon 32000.0 # Texas 142000.0 # Utah NaN # dtype: float64 # \u4e0b\u9762\u662fobj3\u548cobj4\u7684\u503c\uff0c\u5e2e\u52a9\u7406\u89e3\u4e0a\u9762obj3 + obj4\u7684\u64cd\u4f5c\u3002 # obj3 obj4 # Ohio 35000 California NaN # Texas 71000 Ohio 35000.0 # Oregon 16000 Oregon 16000.0 # Utah 5000 Texas 71000.0 # dtype: int64 dtype: float64 Series\u5bf9\u8c61\u81ea\u8eab\u548c\u5176\u7d22\u5f15\u90fd\u6709name\u5c5e\u6027\u3002 obj4.name = 'population' obj4.index.name = 'state' print(obj4) # state # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # Name: population, dtype: float64 \u66ff\u6362Series\u7684\u7d22\u5f15\u540d\u3002 obj = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c']) print(obj) obj.index = ['Bob', 'Steve', 'Jeff', 'Ryan'] print(obj) # Bob 4 # Steve 7 # Jeff -5 # Ryan 3 # dtype: int64 DataFrame DataFrame\u8868\u793a\u7684\u662f\u77e9\u9635\u7684\u6570\u636e\u8868\uff0c\u5b83\u5305\u542b\u5df2\u6392\u5e8f\u7684\u5217\u96c6\u5408\uff0c\u6bcf\u4e00\u5217\u53ef\u4ee5\u662f\u4e0d\u540c\u7684\u503c\u7c7b\u578b\uff08\u6570\u503c\u3001\u5b57\u7b26\u4e32\u3001\u5e03\u5c14\u503c\u7b49\uff09\u3002 DataFrame\u65e2\u6709\u884c\u7d22\u5f15\u4e5f\u6709\u5217\u7d22\u5f15\uff0c\u5b83\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5171\u4eab\u76f8\u540c\u7d22\u5f15\u7684Series\u7684\u5b57\u5178\uff0c\u6bd4\u5982\u6240\u6709\u5217\u5171\u4eab\u540c\u4e00\u4e2a\u5217\u7d22\u5f15\u3002 \u5728DataFrame\u4e2d\uff0c\u6570\u636e\u88ab\u5b58\u50a8\u4e3a\u4e00\u4e2a\u4ee5\u4e0a\u7684\u4e8c\u7ef4\u5757\uff0c\u800c\u4e0d\u662f\u5217\u8868\u3001\u5b57\u5178\u6216\u5176\u4ed6\u4e00\u7ef4\u6570\u7ec4\u7684\u96c6\u5408\u3002 DataFrame\u662f\u4e8c\u7ef4\u7684\uff0c\u4f46\u53ef\u4ee5\u5229\u7528 \u5206\u5c42\u7d22\u5f15 \u5728DataFrame\u4e2d\u5c55\u73b0\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u636e\u3002 \u4eceDataFrame\u4e2d\u9009\u53d6\u7684\u5217\u662f\u6570\u636e\u7684\u89c6\u56fe\uff0c\u800c\u4e0d\u662f\u62f7\u8d1d \u3002\u56e0\u6b64\uff0c\u5bf9Series\u7684\u4fee\u6539\u4f1a\u6620\u5c04\u5230DataFrame\u4e2d\u3002\u5982\u679c\u9700\u8981\u590d\u5236\uff0c\u5219\u5e94\u5f53\u663e\u5f0f\u5730\u4f7f\u7528Series\u7684copy\u65b9\u6cd5\u3002 \u7531\u5b57\u5178\u6784\u6210DataFrame \u57fa\u4e8e\u5b57\u5178 data \u4ea7\u751f\u7684DataFrame\u4f1a\u81ea\u52a8\u4e3aSereies\u5206\u914d\u7d22\u5f15\uff0c\u5e76\u4e14\u5217\u4f1a\u6309\u7167\u6392\u5e8f\u7684\u987a\u5e8f\u6392\u5217\u3002 data = { 'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002, 2003], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2] } frame = pd.DataFrame(data) print(frame) # state year pop # 0 Ohio 2000 1.5 # 1 Ohio 2001 1.7 # 2 Ohio 2002 3.6 # 3 Nevada 2001 2.4 # 4 Nevada 2002 2.9 # 5 Nevada 2003 3.2 # \u5bf9\u4e8e\u5927\u578bDataFrame, head\u65b9\u6cd5\u5c06\u4f1a\u53ea\u9009\u51fa\u5934\u90e8\u7684\u82e5\u5e72\u884c, \u9ed8\u8ba4\u662f\u524d\u4e94\u884c\u3002 print(frame.head(3)) # state year pop # 0 Ohio 2000 1.5 # 1 Ohio 2001 1.7 # 2 Ohio 2002 3.6 \u5982\u679c\u6307\u5b9a\u4e86\u5217\u7684\u987a\u5e8f\uff0cDataFrame\u7684\u5217\u5c06\u4f1a\u6309\u7167\u6307\u5b9a\u987a\u5e8f\u6392\u5217\u3002 frame = pd.DataFrame(data, columns=['year', 'state', 'pop']) print(frame) # year state pop # 0 2000 Ohio 1.5 # 1 2001 Ohio 1.7 # 2 2002 Ohio 3.6 # 3 2001 Nevada 2.4 # 4 2002 Nevada 2.9 # 5 2003 Nevada 3.2 \u5982\u679c\u4f20\u7684\u5217\uff08 debt \uff09\u4e0d\u5305\u542b\u5728\u5b57\u5178\uff08 data \uff09\u4e2d\uff0c\u5c06\u4f1a\u5728\u7ed3\u679c\u4e2d\u51fa\u73b0\u7f3a\u5931\u503c\u3002 frame2 = pd.DataFrame( data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five', 'six'] ) print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 NaN # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 NaN # five 2002 Nevada 2.9 NaN # six 2003 Nevada 3.2 NaN \u9009\u53d6\u884c, \u53ef\u4ee5\u901a\u8fc7\u4f4d\u7f6e\u6216\u884c\u7d22\u5f15\u6807\u7b7e loc \u8fdb\u884c\u9009\u53d6\u3002 print(frame2.loc['three']) # year 2002 # state Ohio # pop 3.6 # debt NaN # Name: three, dtype: object DataFrame\u4e2d\u7684\u4e00\u5217\uff0c\u53ef\u4ee5\u6309\u5b57\u5178\u578b\u6807\u8bb0\u6216\u5c5e\u6027\u90a3\u6837\u68c0\u7d22\u4e3aSeries\u3002 frame2[colunm] \u5bf9\u4e8e\u4efb\u610f\u5217\u540d\u5747\u6709\u6548\uff0c\u4f46\u662f frame2.column \u53ea\u5728\u5217\u540d\u662f\u6709\u6548\u7684Python\u53d8\u91cf\u540d\u65f6\u6709\u6548\u3002 \u8fd4\u56de\u7684Series\u4e0e\u539fDataFrame\u6709\u76f8\u540c\u7684\u7d22\u5f15\uff0c\u4e14Series\u7684 name \u5c5e\u6027\u4e5f\u4f1a\u88ab\u5408\u7406\u5730\u8bbe\u7f6e\u3002 print(frame2['state']) # one Ohio # two Ohio # three Ohio # four Nevada # five Nevada # six Nevada # Name: state, dtype: object print(frame2.state) # \u5c5e\u6027\u578b\u8fde\u63a5 # one Ohio # two Ohio # three Ohio # four Nevada # five Nevada # six Nevada # Name: state, dtype: object \u5217\u7684\u5f15\u7528\u662f\u53ef\u4ee5\u4fee\u6539\u7684\u3002\u503c\u7684\u957f\u5ea6\u5fc5\u987b\u548cDataFrame\u7684\u957f\u5ea6\u76f8\u5339\u914d,\u6bd4\u5982\uff0c\u4e0b\u4f8b\u4e2d np.arange(6.) \u548c frame2['debt'] \u7684\u957f\u5ea6\u90fd\u662f6\u3002 frame2['debt'] = 16.5 print(frame2) # Name: state, dtype: object # year state pop debt # one 2000 Ohio 1.5 16.5 # two 2001 Ohio 1.7 16.5 # three 2002 Ohio 3.6 16.5 # four 2001 Nevada 2.4 16.5 # five 2002 Nevada 2.9 16.5 # six 2003 Nevada 3.2 16.5 frame2['debt'] = np.arange(6.) print(frame2) # year state pop debt # one 2000 Ohio 1.5 0.0 # two 2001 Ohio 1.7 1.0 # three 2002 Ohio 3.6 2.0 # four 2001 Nevada 2.4 3.0 # five 2002 Nevada 2.9 4.0 # six 2003 Nevada 3.2 5.0 \u5982\u679c\u5c06Series\u8d4b\u503c\u7ed9\u4e00\u5217\u65f6\uff0cSeries\u7684\u7d22\u5f15\u5c06\u4f1a\u6309\u7167DataFrame\u7684\u7d22\u5f15\u91cd\u65b0\u6392\u5217\uff0c\u5e76\u5728\u7a7a\u7f3a\u7684\u5730\u65b9\u586b\u5145\u7f3a\u5931\u503c val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five']) frame2['debt'] = val print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 -1.2 # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 -1.5 # five 2002 Nevada 2.9 -1.7 # six 2003 Nevada 3.2 NaN \u5982\u679c\u88ab\u8d4b\u503c\u7684\u5217( eastern \u5217)\u5e76\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u5217\u3002 frame2.state == 'Ohio' \u8fd4\u56de\u7684\u662f\u5e03\u5c14\u503c\uff0c\u8d4b\u503c\u7ed9 eastern \u3002 frame2['eastern'] = frame2.state == 'Ohio' print(frame2) # year state pop debt eastern # one 2000 Ohio 1.5 NaN True # two 2001 Ohio 1.7 -1.2 True # three 2002 Ohio 3.6 NaN True # four 2001 Nevada 2.4 -1.5 False # five 2002 Nevada 2.9 -1.7 False # six 2003 Nevada 3.2 NaN False print(frame2.eastern) # one True # two True # three True # four False # five False # six False # Name: eastern, dtype: bool del \u5173\u952e\u5b57\u53ef\u4ee5\u50cf\u5728\u5b57\u5178\u4e2d\u90a3\u6837\u5bf9DataFrame\u5220\u9664\u5217\u3002 del frame2['eastern'] print(frame2.columns) # Index(['year', 'state', 'pop', 'debt'], dtype='object') \u4f7f\u7528\u5d4c\u5957\u5b57\u5178\u6784\u5efaDataFrame pandas\u4f1a\u5c06\u5b57\u5178\u7684\u952e\u4f5c\u4e3a\u5217('Nevada', etc.)\uff0c\u5c06\u5185\u90e8\u5b57\u5178\u7684\u952e\u4f5c\u4e3a\u884c\u7d22\u5f15(2001, etc.) pop = { 'Nevada': { 2001: 2.4, 2002: 2.9 }, 'Ohio': { 2000: 1.5, 2001: 1.7, 2002: 3.6 } } # \u4e0d\u6307\u5b9a\u7d22\u5f15\uff0c\u9ed8\u8ba4\u4f7f\u7528\u5b57\u5178\u7d22\u5f15 frame3 = pd.DataFrame(pop) print(frame3) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 # \u6307\u5b9a\u5b57\u5178\u67d0\u5217\u4f5c\u4e3a\u7d22\u5f15 print(pd.DataFrame(pop, index=[2001, 2002, 2003])) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2003 NaN NaN # \u6307\u5b9a\u4e0d\u76f8\u5e72\u7d22\u5f15 print(pd.DataFrame(pop, index=['a', 'b', 'c'])) # Nevada Ohio # a NaN NaN # b NaN NaN # c NaN NaN \u8f6c\u7f6e\u64cd\u4f5c\uff08\u8c03\u6362\u884c\u548c\u5217\uff09 print(frame3.T) # 2001 2002 2000 # Nevada 2.4 2.9 NaN # Ohio 1.7 3.6 1.5 \u4f7f\u7528\u542bSeries\u7684\u5b57\u5178\u6784\u9020DataFrame frame3['Ohio'][:-1] \u662f\u503c\u4e3a Ohio \u7684Series\u76840~\u5012\u6570\u7b2c\u4e00\u4e2a\u5143\u7d20\uff08\u4e0d\u542b\uff09\uff0c\u4e00\u51713\u4e2a\u3002 frame3['Nevada'][:2] \u662f\u503c\u4e3a Nevada \u7684Series\u7684\u524d2\u4e2a\u5143\u7d20\u3002 pdata = { 'Ohio': frame3['Ohio'][:-1], 'Nevada': frame3['Nevada'][:2] } print(pd.DataFrame(pdata)) # Ohio Nevada # 2001 1.7 2.4 # 2002 3.6 2.9 \u6307\u5b9aDataframe frame3 \u7684\u5217\u540d\u3002 frame3.index.name = 'year' frame3.columns.name = 'state' print(frame3) # state Nevada Ohio # year # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 \u53ea\u8f93\u51faDataframe\u7684\u503c frame3.values \uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u3002 print(frame3.values) # [[2.4 1.7] # [2.9 3.6] # [nan 1.5]] \u53ea\u8f93\u51faDataframe\u7684\u503c frame2.values \uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u3002 print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 -1.2 # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 -1.5 # five 2002 Nevada 2.9 -1.7 # six 2003 Nevada 3.2 NaN print(frame2.values) # [[2000 'Ohio' 1.5 nan] # [2001 'Ohio' 1.7 -1.2] # [2002 'Ohio' 3.6 nan] # [2001 'Nevada' 2.4 -1.5] # [2002 'Nevada' 2.9 -1.7] # [2003 'Nevada' 3.2 nan]] \u7d22\u5f15\u5bf9\u8c61 pandas\u4e2d\u7684 \u7d22\u5f15\u5bf9\u8c61 \u662f\u7528\u4e8e\u5b58\u50a8\u8f74\u6807\u7b7e\u548c\u5176\u4ed6\u5143\u6570\u636e\u7684\uff08\u4f8b\u5982\u8f74\u540d\u79f0\u6216\u6807\u7b7e\uff09\u3002 \u5728\u6784\u9020Series\u6216DataFrame\u65f6\uff0c\u4f60\u6240\u4f7f\u7528\u7684\u4efb\u610f\u6570\u7ec4\u6216\u6807\u7b7e\u5e8f\u5217\u90fd\u53ef\u4ee5\u5728\u5185\u90e8\u8f6c\u6362\u4e3a\u7d22\u5f15\u5bf9\u8c61\u3002 \u7d22\u5f15\u5bf9\u8c61\u662f\u4e0d\u53ef\u53d8\u7684\u3002 \u9664\u4e86\u7c7b\u4f3c\u6570\u7ec4\uff0c\u7d22\u5f15\u5bf9\u8c61\u4e5f\u50cf\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u96c6\u5408\u3002\u4e0ePython\u96c6\u5408\u4e0d\u540c\uff0c pandas\u7d22\u5f15\u5bf9\u8c61\u53ef\u4ee5\u5305\u542b\u91cd\u590d\u6807\u7b7e \u3002 \u56e0\u4e3a\u4e00\u4e9b\u64cd\u4f5c\u4f1a\u4ea7\u751f\u5305\u542b\u7d22\u5f15\u5316\u6570\u636e\u7684\u7ed3\u679c\uff0c\u7406\u89e3\u7d22\u5f15\u5982\u4f55\u5de5\u4f5c\u8fd8\u662f\u5f88\u91cd\u8981\u7684\u3002 \u4e0b\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u8bfb\u53d6Dataframe\u7684\u7d22\u5f15\u503c\u3002 obj = pd.Series(range(3), index=['a', 'b', 'c']) index = obj.index print(obj) # a 0 # b 1 # c 2 # dtype: int64 print(index) # Index(['a', 'b', 'c'], dtype='object') print(index[1:]) # Index(['b', 'c'], dtype='object') \u4e0b\u4f8b\u6f14\u793a\u4e86\u901a\u8fc7\u4e00\u4e2a\u6307\u5b9a\u7684Dataframe\u7d22\u5f15 labels \u6765\u751f\u6210Dataframe obj2 \u3002 labels = pd.Index(np.arange(3)) print(labels) # Int64Index([0, 1, 2], dtype='int64') obj2 = pd.Series([1.5, -2.5, 0], index=labels) print(obj2) # 0 1.5 # 1 -2.5 # 2 0.0 # dtype: float64 print(obj2.index is labels) # True \u4e0b\u4f8b\u6f14\u793a\u4e86\u4e0d\u6307\u5b9a\u7d22\u5f15\uff0c\u9ed8\u8ba4\u4f7f\u7528\u5b57\u5178\u7d22\u5f15\u6765\u521b\u5efaDataframe\u3002 pop = { 'Nevada': { 2001: 2.4, 2002: 2.9 }, 'Ohio': { 2000: 1.5, 2001: 1.7, 2002: 3.6 } } frame3 = pd.DataFrame(pop) print(frame3) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 print(frame3) # state Nevada Ohio # year # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 print(frame3.columns) # Index(['Nevada', 'Ohio'], dtype='object', name='state') print(frame3.index) # Int64Index([2001, 2002, 2000], dtype='int64', name='year') print('Ohio' in frame3.columns) # True print(2003 in frame3.index) # False pandas\u7d22\u5f15\u5bf9\u8c61\u5141\u8bb8\u5305\u542b\u91cd\u590d\u6807\u7b7e\u3002\u6839\u636e\u91cd\u590d\u6807\u7b7e\u8fdb\u884c\u7b5b\u9009\uff0c\u4f1a\u9009\u53d6\u6240\u6709\u91cd\u590d\u6807\u7b7e\u5bf9\u5e94\u7684\u6570\u636e\u3002 dup_labels = pd.Index(['foo', 'foo', 'bar', 'bar']) print(dup_labels) # Index(['foo', 'foo', 'bar', 'bar'], dtype='object') \u4e00\u4e9b\u5e38\u7528\u7d22\u5f15\u5bf9\u8c61\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u3002 obj1 = pd.Series(range(3), index=['a', 'b', 'c']) index1 = obj1.index obj2 = pd.Series(range(3), index=['c', 'f', 'g']) index2 = obj2.index print(index1) # Index(['a', 'b', 'c'], dtype='object') print(index2) # Index(['c', 'f', 'g'], dtype='object') append \u65b9\u6cd5\uff1a\u5c06\u5916\u90e8\u7684\u7d22\u5f15\u5bf9\u8c61\u7c98\u8d34\u5230\u539f\u7d22\u5f15\u540e\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684\u7d22\u5f15\u3002 \u63a5\u4e0a\u4f8b\uff0c\u628a index2 \u5bf9\u8c61\u8ffd\u52a0\u5230 index1 \u5bf9\u8c61\u3002 print(index1.append(index2)) # Index(['a', 'b', 'c', 'c', 'f', 'g'], dtype='object') difference \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u5dee\u96c6\u3002 print(index1.difference(index2)) # Index(['a', 'b'], dtype='object') intersection \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u4ea4\u96c6\u3002 print(index1.intersection(index2)) # Index(['c'], dtype='object') union \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u5e76\u96c6\uff08\u53bb\u91cd\uff09\u3002 print(index1.union(index2)) # Index(['a', 'b', 'c', 'f', 'g'], dtype='object') isin \u65b9\u6cd5: \u8ba1\u7b97\u8868\u793a\u6bcf\u4e00\u4e2a\u503c\u662f\u5426\u5728\u4f20\u503c\u5bb9\u5668\u4e2d\uff0c\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5e03\u5c14\u6570\u7ec4\u3002 print(index1.isin(index2)) # [False False True] delete \u65b9\u6cd5: \u5c06\u4f4d\u7f6ei\uff08\u4ece0\u5f00\u59cb\u7f16\u53f7\uff09\u7684\u5143\u7d20\u5220\u9664\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15\u3002 print(index1.delete('b')) # IndexError: arrays used as indices must be of integer (or boolean) type print(index1.delete(1)) # Index(['a', 'c'], dtype='object') print(index1) # Index(['a', 'b', 'c'], dtype='object') drop \u65b9\u6cd5: \u6839\u636e\u4f20\u53c2\u5220\u9664\u6307\u5b9a\u7d22\u5f15\u503c\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15, \u5bf9\u6bd4\u548cdelete\u7684\u533a\u522b\uff0c delete \u65b9\u6cd5\u662f\u8f93\u5165\u4f4d\u7f6e\uff0c drop \u65b9\u6cd5\u662f\u8f93\u5165\u7d22\u5f15\u540d\u79f0\u3002 print(index2.drop(1)) # KeyError: '[1] not found in axis' print(index2.drop('f')) # Index(['c', 'g'], dtype='object') print(index2) # Index(['c', 'f', 'g'], dtype='object') insert \u65b9\u6cd5: \u5728\u4f4d\u7f6e i \u63d2\u5165\u5143\u7d20\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15\u3002 print(index1.insert(1, 'e')) # Index(['a', 'e', 'b', 'c'], dtype='object') print(index1) # Index(['a', 'b', 'c'], dtype='object') is_monotonic \u65b9\u6cd5: \u5982\u679c\u7d22\u5f15\u5e8f\u5217\u9012\u589e\uff0c\u5219\u8fd4\u56de True \u3002 print(index1.is_monotonic) # True print(index1.insert(1, 'e').is_monotonic) # False is_unique \u65b9\u6cd5: \u5982\u679c\u7d22\u5f15\u5e8f\u5217\u552f\u4e00\u5219\u8fd4\u56de True \u3002 print(index1.is_unique) # True print(index1.append(index2).is_unique) # False unique \u65b9\u6cd5: \u8ba1\u7b97\u7d22\u5f15\u7684\u552f\u4e00\u503c\u5e8f\u5217\uff08\u5bf9\u6bd4Union\uff09\u3002 print(index1.unique()) # Index(['a', 'b', 'c'], dtype='object') print(index1.append(index2).unique()) # Index(['a', 'b', 'c', 'f', 'g'], dtype='object') pandas\u57fa\u672c\u529f\u80fd \u91cd\u5efa\u7d22\u5f15 Series\u8c03\u7528 reindex \u65b9\u6cd5\u65f6\uff0c\u4f1a\u5c06\u6570\u636e\u6309\u7167\u65b0\u7684\u7d22\u5f15\u8fdb\u884c\u6392\u5217\uff0c\u5982\u679c\u67d0\u4e2a\u7d22\u5f15\u503c\u4e4b\u524d\u5e76\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u5f15\u5165\u7f3a\u5931\u503c\u3002 \u4e0b\u4f8b\u4e2d\uff0c\u5bf9 obj1 \u505a reindex \uff0c reindex \u65b9\u6cd5\u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7d22\u5f15\u5bf9\u8c61 obj2 \uff0c\u7d22\u5f15\u503c e \u4e4b\u524d\u5e76\u4e0d\u5b58\u5728\uff0c\u6240\u4ee5\u586b\u5165\u7f3a\u5931\u503c\u3002 \u5982\u679c\u5bf9obj1\u505a reindex \u65f6\u6307\u5b9a method='ffill' \uff0c\u4f1a\u62a5\u9519 index must be monotonic increasing or decreasing \u3002 obj1 = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c']) print(obj1) # d 4.5 # b 7.2 # a -5.3 # c 3.6 # dtype: float64 obj2 = obj1.reindex(['a', 'b', 'c', 'd', 'e']) print(obj2) # a -5.3 # b 7.2 # c 3.6 # d 4.5 # e NaN # dtype: float64 obj2 = obj1.reindex(['a', 'b', 'c', 'd', 'e'], method='ffill') # ValueError: index must be monotonic increasing or decreasing \u5bf9\u4e8e\u987a\u5e8f\u6570\u636e\uff0c\u6bd4\u5982\u65f6\u95f4\u5e8f\u5217\uff0c\u5728\u91cd\u5efa\u7d22\u5f15\u65f6\u53ef\u80fd\u4f1a\u9700\u8981\u8fdb\u884c\u63d2\u503c\u6216\u586b\u503c\u3002 ffill \u65b9\u6cd5\u5728\u91cd\u5efa\u7d22\u5f15\u65f6\u63d2\u503c\uff0c\u5c06\u503c\u524d\u5411\u586b\u5145\u3002 obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4]) print(obj3.reindex(range(6), method='ffill')) # 0 blue # 1 blue # 2 purple # 3 purple # 4 yellow # 5 yellow # dtype: object \u5728DataFrame\u4e2d\uff0c reindex \u53ef\u4ee5\u6539\u53d8\u884c\u7d22\u5f15\u3001\u5217\u7d22\u5f15\uff0c\u4e5f\u53ef\u4ee5\u540c\u65f6\u6539\u53d8\u4e8c\u8005\u3002\u5f53\u4ec5\u4f20\u5165\u4e00\u4e2a\u5e8f\u5217\u65f6\uff0c\u4f1a\u91cd\u5efa\u884c\u7d22\u5f15\u3002 \u4e0b\u4f8b\u4e2d\uff0c\u901a\u8fc7 indexes \u521b\u5efaDataframe frame \u3002 \u901a\u8fc7 frame.reindex(['a', 'b', 'c', 'd'])\u91cd\u5efa\u884c\u7d22\u5f15 \u3002 \u901a\u8fc7 frame2.reindex(columns=['Ohio', 'Uta', 'California']) \u91cd\u5efa\u5217\u7d22\u5f15\u3002 \u7f3a\u5931\u7684\u7d22\u5f15\u5217\u586b\u5165\u7f3a\u5931\u503c\u3002 indexes = index = ['a', 'b', 'c'] states = ['Ohio', 'Texas', 'California'] frame = pd.DataFrame( np.arange(9).reshape(3, 3), index=indexes, columns=states ) print(frame) # Ohio Texas California # a 0 1 2 # b 3 4 5 # c 6 7 8 frame2 = frame.reindex(['a', 'b', 'c', 'd']) # \u91cd\u5efa\u884c\u7d22\u5f15 print(frame2) # Ohio Texas California # a 0.0 1.0 2.0 # b 3.0 4.0 5.0 # c 6.0 7.0 8.0 # d NaN NaN NaN frame3 = frame2.reindex(columns=['Ohio', 'Uta', 'California']) # \u91cd\u5efa\u5217\u7d22\u5f15 print(frame3) # Ohio Uta California # a 0.0 NaN 2.0 # b 3.0 NaN 5.0 # c 6.0 NaN 8.0 # d NaN NaN NaN \u4f7f\u7528 loc \u8fdb\u884c\u66f4\u4e3a\u7b80\u6d01\u7684\u884c\u3001\u5217\u6807\u7b7e\u7d22\u5f15\u3002\u4e0b\u4f8b\u901a\u8fc7\u7b5b\u9009\u884c\u7d22\u5f15\u548c\u5217\u7d22\u5f15\u4ea7\u751f\u65b0\u7684Dataframe\u3002 frame4 = frame.loc[['a', 'b'], states] print(frame4) # Ohio Texas California # a 0 1 2 # b 3 4 5 \u8f74\u5411\u7d22\u5f15\u5220\u9664\u6761\u76ee set_index() , dropna() , fillna() , reset_index() , drop() , replace() \u8fd9\u4e9b\u65b9\u6cd5\u7684 inplace \u5c5e\u6027\u8bbe\u4e3a True \u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f1a\u4fee\u6539Series\u6216DataFrame\u7684\u5c3a\u5bf8\u6216\u5f62\u72b6\uff0c \u76f4\u63a5 \u64cd\u4f5c\u539f\u5bf9\u8c61\u800c\u4e0d\u8fd4\u56de\u65b0\u5bf9\u8c61\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj) # a 0 # b 1 # c 2 # d 3 # e 4 # dtype: int64 obj1 = obj.drop('c') print(obj1) # a 0 # b 1 # d 3 # e 4 # dtype: int64 print(obj1.drop(['d', 'e'])) # a 0 # b 1 # dtype: int64 \u5bf9\u6bd4 inplace=True \u548c False \u7684\u533a\u522b\u3002 inplace=False \u65f6\uff0c obj \u7684\u503c\u6ca1\u6709\u53d8\u5316\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj.drop('c', inplace=False)) # \u8bf4\u660e\u751f\u6210\u4e86\u65b0\u5bf9\u8c61 # a 0 # b 1 # d 3 # e 4 # dtype: int64 print(obj) # a 0 # b 1 # c 2 # d 3 # e 4 # dtype: int64 obj.drop('c', inplace=True) \u8f93\u51fa\u662f None \uff0c\u8bf4\u660e\u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61\uff0c\u53d8\u5316\u76f4\u63a5\u4f5c\u7528\u5230 obj \u4e0a\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj) print(obj.drop('c', inplace=True)) # \u8bf4\u660e\u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61 # None print(obj) # a 0 # b 1 # d 3 # e 4 # dtype: int64 \u4e0b\u4f8b\u6f14\u793a\u4e86\u8f74\u5411\u7684\u6548\u679c\u3002 \u5982\u679c\u4e0d\u6307\u5b9a\u8f74\u5411axis\uff0c drop() \u4f1a\u9ed8\u8ba4\u6cbf axis=0 \u8fdb\u884c\uff0c\u6240\u4ee5\uff0c\u57280\u8f74\u4e0a\u6267\u884c data.drop(['one', 'two']) \u4f1a\u62a5\u9519\u3002 axis='columns \u4e0e\u6307\u5b9a axis=1 \u540c\u6837\u6548\u679c\u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'] ) print(data) # one two three four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 # \u6cbf0\u8f74\u64cd\u4f5c\uff0c\u5220\u9664\u7b26\u5408\u6761\u4ef6\u7684\u884c\u8bb0\u5f55 print(data.drop(['Ohio', 'Colorado'])) # one two three four # Utah 8 9 10 11 # New York 12 13 14 15 print(data.drop(['one', 'two'])) # KeyError: \"['one' 'two'] not found in axis\" # \u6cbf1\u8f74\u64cd\u4f5c\uff0c\u5220\u9664\u7b26\u5408\u6761\u4ef6\u7684\u5217\u8bb0\u5f55 print(data.drop(['one', 'two'], axis=1)) # three four # Ohio 2 3 # Colorado 6 7 # Utah 10 11 # New York 14 15 print(data.drop(['one', 'two'], axis='columns')) # three four # Ohio 2 3 # Colorado 6 7 # Utah 10 11 # New York 14 15 \u518d\u901a\u8fc7\u4e0b\u4f8b\u4f53\u4f1a\u4e00\u4e0b inplace \u53c2\u6570\u7684\u4e0d\u540c\u6548\u679c\u3002 data = pd.DataFrame( { 'Name': ['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], 'class': [11, 12, 10, 9], 'Age': [18, 20, 21, 17] } ) print(data) # Name class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data.rename(columns={'Name': 'FirstName'}, inplace=False)) # FirstName class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data) # Name class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data.rename(columns={'Name': 'FirstName'}, inplace=True)) # \u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61 # None print(data) # FirstName class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 \u7d22\u5f15\u3001\u9009\u62e9\u4e0e\u8fc7\u6ee4 Series\u7684\u7d22\u5f15 obj[...] \u4e0eNumPy\u6570\u7ec4\u7d22\u5f15\u7684\u529f\u80fd\u7c7b\u4f3c\uff0c\u53ea\u4e0d\u8fc7Series\u7684\u7d22\u5f15\u503c\u53ef\u4ee5\u4e0d\u4ec5\u4ec5\u662f\u6574\u6570\u3002 \u4e0b\u4f8b\u4e2d\uff1a obj[1] \u901a\u8fc7\u7d22\u5f15\u4f4d 1 \u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c\u3002 obj[1] \u901a\u8fc7\u7d22\u5f15\u4f4d [1] \u68c0\u7d22\uff0c\u8f93\u51faSeries\u3002 obj['b'] \u901a\u8fc7\u7d22\u5f15\u503c 'b' \u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c\u3002 obj[['b']] \u901a\u8fc7\u7d22\u5f15\u503c ['b'] \u68c0\u7d22\uff0c\u8f93\u51faSeries\u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) print(obj) # a Shobhit # b vaibhav # c vimal # d Sourabh # dtype: object print(obj[1]) # \u901a\u8fc7\u7d22\u5f15\u4f4d\u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c # vaibhav print(obj[[1]]) # b vaibhav # dtype: object print(obj['b']) # \u901a\u8fc7\u7d22\u5f15\u503c\u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c # vaibhav print(obj[['b']]) # \u901a\u8fc7\u7d22\u5f15\u503c\u68c0\u7d22\uff0c\u8f93\u51faSeries # b vaibhav # dtype: object \u4e0b\u9762\u4e00\u7ec4\u7684\u8f93\u51fa\u4e2d\uff0c\u6ce8\u610f\u5bf9\u6bd4\u666e\u901aPython\u5207\u7247\u4e0eSeries\u7684\u5207\u7247\u7684\u5dee\u5f02\u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) print(obj[1]) # vaibhav print(obj[[1]]) # b vaibhav # dtype: object print(obj[1:3]) # b vaibhav # c vimal # dtype: object print(obj['b':'d']) # b vaibhav # c vimal # d Sourabh # dtype: object Series\u7684\u5207\u7247\u7684\u503c\u66f4\u65b0\u3002 obj['b': 'c'] = 5 \u662f\u901a\u8fc7\u7d22\u5f15\u503c\u8fdb\u884c\u66f4\u65b0\uff0c\u76f4\u63a5\u4f5c\u7528\u5728 obj \u3002 obj[1: 3] = 6 \u662f\u901a\u8fc7\u7d22\u5f15\u4f4d\u7f6e\u6765\u66f4\u65b0 obj \u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) obj['b': 'c'] = 5 print(obj) # a Shobhit # b 5 # c 5 # d Sourabh # dtype: object obj[1: 3] = 6 print(obj) # a Shobhit # b 6 # c 6 # d Sourabh # dtype: object DataFrame\u7684\u7d22\u5f15\u4e0e\u5207\u7247\u3002 data[['Three', 'Two']] \u9009\u53d6\u6307\u5b9a\u5217\uff0c\u6ce8\u610f\u8f93\u5165\u5217\u6761\u4ef6\u662f\u5217\u8868 ['Three', 'Two'] \u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['One', 'Two', 'Three', 'Four'] ) print(data) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 print(data['Two']) # Ohio 1 # Colorado 5 # Utah 9 # New York 13 # Name: Two, dtype: int64 print(data[['Three', 'Two']]) # Three Two # Ohio 2 1 # Colorado 6 5 # Utah 10 9 # New York 14 13 print(data[:2]) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 \u5d4c\u5957\uff1a\u6839\u636e\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u5207\u7247\u6216\u9009\u62e9\u6570\u636e\u3002 data['Three'] > 5 \u662f\u4e00\u4e2a\u5e03\u5c14\u503c\u5e8f\u5217\u3002 data[data['Three'] > 5] \u8f93\u51fa\u6761\u4ef6\u4e3aTrue\u7684\u7ed3\u679c\u96c6\u3002 print(data['Three'] > 5) # Ohio False # Colorado True # Utah True # New York True # Name: Three, dtype: bool print(data[data['Three'] > 5]) # One Two Three Four # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4f7f\u7528\u5e03\u5c14\u503cDataFrame\u8fdb\u884c\u7d22\u5f15\uff0c\u5df2\u7ecf\u66f4\u65b0\u3002 \u5728\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u8fd9\u79cd\u7d22\u5f15\u65b9\u5f0f\u4f7f\u5f97DataFrame\u5728\u8bed\u6cd5\u4e0a\u66f4\u50cf\u662fNumPy\u4e8c\u7ef4\u6570\u7ec4\u3002 print(data < 5) # One Two Three Four # Ohio True True True True # Colorado True False False False # Utah False False False False # New York False False False False data[data < 5] = 0 print(data) # One Two Three Four # Ohio 0 0 0 0 # Colorado 0 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4f7f\u7528loc\u548ciloc\u9009\u62e9\u6570\u636e\u3002 \u4f7f\u7528\u6807\u7b7e\u540d loc \u6216\u6807\u7b7e\u4f4d\u7f6e iloc \u4ee5NumPy\u98ce\u683c\u7684\u8bed\u6cd5\u4eceDataFrame\u4e2d\u9009\u51faDataframe\u7684\u884c\u548c\u5217\u7684\u5b50\u96c6\u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['One', 'Two', 'Three', 'Four'] ) print(data) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4e0b\u4f8b\u901a\u8fc7loc\u5bf9\u6807\u7b7e\u540d\u7b5b\u9009\u884c\u6216\u5217\u6570\u636e\u3002\u4f8b\u5982\uff0c\u8f93\u51fa Colorado \u884c\u6807\u7b7e\u7684 Two \u548c Three \u8fd9\u4e24\u5217\u7684\u503c\uff0c\u4ee5\u884c\u8bb0\u5f55\u7684\u65b9\u5f0f\u5c55\u73b0\u3002 print(data.loc['Colorado', ['Two', 'Three']]) # \u5207\u7247: # Two 5 # Three 6 # Name: Colorado, dtype: int64 print(data.loc[:'Ohio', :'Two']) # \u5207\u7247: 0\u884c\uff0c0,1\u5217 # One Two # Ohio 0 1 \u4e0b\u4f8b\u901a\u8fc7\u6807\u7b7e\u4f4d\u7f6e iloc \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u9009\u62e9\u3002 data.iloc[:3, :2][data > 4] \u6309\u6307\u5b9a\u6761\u4ef6\u8fdb\u884c\u884c\u3001\u5217\u7b5b\u9009\uff0c\u7b26\u5408\u6761\u4ef6 [data > 4] \u7684\u8f93\u51faDataframe\u503c\uff0c\u4e0d\u7b26\u5408\u6761\u4ef6\u7684\u8f93\u51faNaN\u3002 print(data.iloc[[0]]) # 0\u884c # One Two Three Four # Ohio 0 1 2 3 print(data.iloc[[0], [1]]) # \u5207\u7247: 0\u884c\uff0c1\u5217 # Two # Ohio 1 print(data.iloc[1:2, 1:2]) # \u5207\u7247: 1\u884c\uff0c2\u5217 # Two # Ohio 1 print(data.iloc[2, [3, 0, 1]]) # \u5207\u7247: 2\u884c\uff0c\u4f9d\u6b21\u53d63\uff0c0\uff0c1\u5217 # Four 11 # One 8 # Two 9 # Name: Utah, dtype: int64 print(data.iloc[:3, :2][data > 4]) # One Two # Ohio NaN NaN # Colorado NaN 5.0 # Utah 8.0 9.0 \u6574\u6570\u7d22\u5f15 Pandas\u7684Series\u7684\u7d22\u5f15\u503c\u662f\u6574\u6570\u7d22\u5f15\u3002 data = np.arange(3.) ser = pd.Series(data) print(ser) # 0 0.0 # 1 1.0 # 2 2.0 # dtype: float64 print(ser[:1]) # 0 0.0 # dtype: float64 print(ser.loc[:1]) # loc\u7528\u4e8e\u6807\u7b7e\u540d # 0 0.0 # 1 1.0 # dtype: float64 print(ser.iloc[:1]) # iloc\u7528\u4e8e\u6807\u7b7e\u4f4d\u7f6e # 0 0.0 # dtype: float64 data = ['1', 'b', 'e', 3] ser = pd.Series(data) print(ser) # 0 1 # 1 b # 2 e # 3 3 # dtype: object print(ser[:1]) # 0 1 # dtype: object print(ser.loc[:1]) # 0 1 # 1 b # dtype: object print(ser.iloc[:1]) # 0 1 # dtype: object \u5bf9DataFrame\u7684\u66f4\u65b0\u3002 df1 = pd.DataFrame(np.arange(4).reshape((2, 2)), columns=list('ab')) print(df1) # a b # 0 0 1 # 1 2 3 # \u6309\u6807\u7b7e\u540d\u66f4\u65b0 df1.loc[1, :'b'] = np.nan print(df1) # a b # 0 0.0 1.0 # 1 NaN NaN \u7b97\u672f\u548c\u6570\u636e\u5bf9\u9f50 Pandas\u652f\u6301\u5728Series\u6216\u8005DataFrame\u5bf9\u8c61\u4e4b\u95f4\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97\u3002 \u4f8b\uff1a\u4e24\u4e2aSeries\u505a\u7b97\u672f\u52a0\u6cd5\u3002 \u8fd4\u56de\u7684\u7ed3\u679c\u4e5f\u662f\u4e00\u4e2aSeries\u3002 \u8fd4\u56de\u7ed3\u679c\u7684\u7d22\u5f15\u662f\u6bcf\u4e2aSeries\u7684\u7d22\u5f15\u7684\u5e76\u96c6\u3002 \u51e1\u662f\u6ca1\u6709\u5728\u4e24\u4e2aSeries\u90fd\u51fa\u73b0\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0c\u5185\u90e8\u6570\u636e\u5bf9\u9f50\u4f1a\u586b\u5145\u7f3a\u5931\u503cNaN\u3002\u7f3a\u5931\u503c\u4f1a\u5728\u540e\u7eed\u7684\u5176\u5b83\u7b97\u672f\u64cd\u4f5c\u4e0a\u4ea7\u751f\u5f71\u54cd\u3002 \u540c\u65f6\u51fa\u73b0\u5728\u4e24\u4e2aSeries\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0cSeries\u7684\u503c\u505a\u7b97\u672f\u76f8\u52a0\u3002 s1 = pd.Series( [7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'] ) s2 = pd.Series( [-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'] ) print(s1) # a 7.3 # c -2.5 # d 3.4 # e 1.5 # dtype: float64 print(s2) # a -2.1 # c 3.6 # e -1.5 # f 4.0 # g 3.1 # dtype: float64 print(s1 + s2) # a 5.2 # c 1.1 # d NaN # e 0.0 # f NaN # g NaN # dtype: float64 \u4f8b\uff1a\u4e24\u4e2aDataframe\u505a\u7b97\u672f\u52a0\u6cd5 \u8fd4\u56de\u7ed3\u679c\u4e5f\u662f\u4e00\u4e2aDataframe\u3002 \u8fd4\u56de\u7ed3\u679c\u7684\u884c\u5217\u7d22\u5f15\u662f\u6bcf\u4e2aDataFrame\u7684\u884c\u5217\u7d22\u5f15\u7684\u5e76\u96c6\u3002 \u51e1\u662f\u6ca1\u6709\u5728\u4e24\u4e2aDataFrame\u90fd\u51fa\u73b0\u7684\u4f4d\u7f6e\u5c31\u4f1a\u88ab\u7f6e\u4e3aNaN\u3002 \u4e24\u4e2aDataFrame\u90fd\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5bf9Dataframe\u7684\u503c\u505a\u7b97\u672f\u52a0\u6cd5\u3002 df1 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'] ) df2 = pd.DataFrame( np.arange(12).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(df1) # b c d # Ohio 0 1 2 # Texas 3 4 5 # Colorado 6 7 8 print(df2) # b d e # Utah 0 1 2 # Ohio 3 4 5 # Texas 6 7 8 # Oregon 9 10 11 print(df1 + df2) # b c d e # Colorado NaN NaN NaN NaN # Ohio 3.0 NaN 6.0 NaN # Oregon NaN NaN NaN NaN # Texas 9.0 NaN 12.0 NaN # Utah NaN NaN NaN NaN \u5728Series\u6216\u8005DataFrame\u5bf9\u8c61\u4e4b\u95f4\u8fdb\u884c\u7b97\u672f\u64cd\u4f5c\u65f6\uff0c\u6709\u65f6\u9700\u8981\u5bf9\u7f3a\u5931\u503c\u6307\u5b9a\u586b\u5145\u503c\uff0c\u6bd4\u5982\u5f53\u8f74\u6807\u7b7e\u5728\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u5b58\u5728\uff0c\u5728\u53e6\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u4e0d\u5b58\u5728\u65f6\uff0c\u5c06\u7f3a\u5931\u503c\u586b\u5145\u4e3a0\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5982\u679c\u5728\u4e24\u4e2aDataFrame\u90fd\u7f3a\u5931\uff0c\u90a3\u4e48\u4f9d\u7136\u8fd8\u4f1a\u662fNaN\u3002 \u4e0b\u4f8b\u4e2da2\u662f\u5728 df1 \u548c df2 \u90fd\u7f3a\u5931\u7684\u4f4d\u7f6e\uff0c\u6240\u4ee5\u5373\u4f7f fill_value=0 \uff0ca2\u4ecd\u7136\u662fNaN\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('bcd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # b c d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 # \u5bf9df1\u548cdf2\u5c31\u7b97\u672f\u548c\uff0c\u5bf9\u5e94\u6ca1\u6709\u884c\u5217\u5171\u540c\u7684\u4ea4\u96c6\u7684\u5730\u65b9\u586b\u5145\u7a7a\u503cNaN\uff0c\u6709\u4ea4\u96c6\u7684\u5730\u65b9\u6c42\u7b97\u672f\u548c\u3002 print(df1.add(df2)) # a b c d # 0 NaN 1.0 NaN NaN # 1 NaN 6.0 NaN NaN # 2 NaN NaN NaN NaN # \u5bf9df1\u548cdf2\u5c31\u7b97\u672f\u548c\uff0c\u5bf9\u5e94\u6ca1\u6709\u884c\u5217\u5171\u540c\u7684\u4ea4\u96c6\u7684\u5730\u65b9\u586b\u5145\u7a7a\u503c0\uff0c\u6709\u4ea4\u96c6\u7684\u5730\u65b9\u6c42\u7b97\u672f\u548c\u3002 print(df1.add(df2, fill_value=0)) # df2.add(df1, fill_value=0) \u8fd4\u56de\u540c\u6837\u7684\u7ed3\u679c # a b c d # 0 0.0 1.0 1.0 2.0 # 1 2.0 6.0 4.0 5.0 # 2 NaN 6.0 7.0 8.0 \u4e0b\u4f8b\u4e2db2\u662f\u5728 df1 \u548c df2 \u90fd\u7f3a\u5931\u7684\u4f4d\u7f6e\uff0c\u6240\u4ee5\u5373\u4f7f fill_value=0 \uff0cb2\u4ecd\u7136\u662fNaN\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('acd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a c d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.add(df2, fill_value=0)) # a b c d # 0 0.0 1.0 1.0 2.0 # 1 5.0 3.0 4.0 5.0 # 2 6.0 NaN 7.0 8.0 \u4e0b\u4f8b\u4e2d\u6ca1\u6709\u4e24\u4e2aDataFrame\u5171\u540c\u7f3a\u5931\u7684\u60c5\u51b5\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('abd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a b d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.add(df2, fill_value=0)) # a b d # 0 0.0 2.0 2.0 # 1 5.0 7.0 5.0 # 2 6.0 7.0 8.0 \u4e0b\u9762\u662fSeries\u548cDataFrame\u7684\u7b97\u672f\u65b9\u6cd5\u3002 add\uff0cradd\uff1a\u52a0\u6cd5(+) sub\uff0crsub\uff1a\u51cf\u6cd5(-) div\uff0crdiv\uff1a\u9664\u6cd5(/) floordiv\uff0crfloordiv\uff1a\u6574\u9664(//) mul\uff0crmul\uff1a\u4e58\u6cd5(*) pow\uff0crpow\uff1a\u5e42\u6b21\u65b9(**) \u4e0a\u8ff0\u6bcf\u4e2a\u65b9\u6cd5\u90fd\u6709\u4e00\u4e2a\u4ee5r\u5f00\u5934\u7684\u526f\u672c\uff0c\u8fd9\u4e9b\u526f\u672c\u65b9\u6cd5\u7684\u53c2\u6570\u662f\u7ffb\u8f6c\u7684\u3002\u6bd4\u5982\uff0c\u6c42DataFrame\u5f53\u4e2d\u6240\u6709\u5143\u7d20\u7684\u5012\u6570 1/df \uff0c\u53ef\u4ee5\u5199\u6210df.rdiv(1)\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('abd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a b d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.radd(df2, fill_value=0)) # a b d # 0 0.0 2.0 2.0 # 1 5.0 7.0 5.0 # 2 6.0 7.0 8.0 print(df1.sub(df2, fill_value=0)) # a b d # 0 0.0 0.0 -2.0 # 1 -1.0 -1.0 -5.0 # 2 -6.0 -7.0 -8.0 print(df1.div(df2, fill_value=0)) # a b d # 0 NaN 1.00 0.0 # 1 0.666667 0.75 0.0 # 2 0.000000 0.00 0.0 print(df1.floordiv(df2, fill_value=0)) # a b d # 0 NaN 1.0 0.0 # 1 0.0 0.0 0.0 # 2 0.0 0.0 0.0 print(df1.mul(df2, fill_value=0)) # a b d # 0 0.0 1.0 0.0 # 1 6.0 12.0 0.0 # 2 0.0 0.0 0.0 print(df1.pow(df2, fill_value=0)) # a b d # 0 1.0 1.0 0.0 # 1 8.0 81.0 0.0 # 2 0.0 0.0 0.0 DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c\u4e0eNumPy\u4e2d\u4e0d\u540c\u7ef4\u5ea6\u6570\u7ec4\u95f4\u7684\u64cd\u4f5c\u7c7b\u4f3c\u3002 \u4e0d\u540c\u7ef4\u5ea6NumPy\u6570\u7ec4\u95f4\u7684\u7b97\u672f\u64cd\u4f5c \u4ecearr\u4e2d\u51cf\u53bbarr[0]\u65f6\uff0c\u51cf\u6cd5\u6cbf0\u8f74\u5728\u6bcf\u4e00\u884c\u90fd\u8fdb\u884c\u4e86\u64cd\u4f5c\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\u5e7f\u64ad\u673a\u5236\u3002 arr = np.arange(12).reshape((3, 4)) print(arr) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] print(arr[0]) # [0 1 2 3] print(arr - arr[0]) # [[0 0 0 0] # [4 4 4 4] # [8 8 8 8]] DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cDataFrame\u548cSeries\u7684\u6570\u5b66\u64cd\u4f5c\u4e2d\u4f1a\u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684 \u5217 \u8fdb\u884c\u5339\u914d\uff0c\u5e76 \u5e7f\u64ad\u5230\u5404\u884c . \u5982\u679c\u4e00\u4e2a\u7d22\u5f15\u503c\u4e0d\u5728DataFrame\u7684\u5217\u4e2d\uff0c\u4e5f\u4e0d\u5728Series\u7684\u7d22\u5f15\u4e2d\uff0c\u5219\u65b0\u5bf9\u8c61\u4f1a\u6784\u5efa\u5e76\u96c6\u7d22\u5f15\u3002 frame = pd.DataFrame( np.arange(12).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(frame) # b d e # Utah 0 1 2 # Ohio 3 4 5 # Texas 6 7 8 # Oregon 9 10 11 # \u622a\u53d6frame\u7684\u7b2c0\u884c\uff0c\u5217\u6807\u7b7e\u53d8\u6210\u65b0Serise\u7684\u7d22\u5f15\u3002 series = frame.iloc[0] print(series) # b 0 # d 1 # e 2 # Name: Utah, dtype: int64 series2 = pd.Series( range(3), index=list('bef') ) print(series2) # b 0 # e 1 # f 2 # dtype: int64 # \u622a\u53d6frame\u7684d\u5217\uff0c\u884c\u6807\u7b7e\u53d8\u6210\u65b0Serise\u7684\u7d22\u5f15\u3002 series3 = frame['d'] print(series3) # Utah 1 # Ohio 4 # Texas 7 # Oregon 10 # Name: d, dtype: int64 # \u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684\u5217\u6807\u7b7e\u8fdb\u884c\u5339\u914d\uff0cSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\u3002 print(frame - series) # frame: series Result: # b d e # b 0 # b d e # Utah 0 1 2 # d 1 # Utah 0 0 0 # Ohio 3 4 5 # e 2 # Ohio 3 3 3 # Texas 6 7 8 # Name: Utah, dtype: int64 # Texas 6 6 6 # Oregon 9 10 11 # Oregon 9 9 9 # \u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684\u5217\u6807\u7b7e\u8fdb\u884c\u5339\u914d\uff0cSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\uff0c\u7f3a\u5931\u4f4d\u7f6e\u586b\u5145\u7a7a\u503cNaN\u3002 print(frame - series2) # frame: series2 Result: # b d e # b 0 # b d e f # Utah 0 1 2 # e 1 # Utah 0.0 NaN 1.0 NaN # Ohio 3 4 5 # f 2 # Ohio 3.0 NaN 4.0 NaN # Texas 6 7 8 # dtype: int64 # Texas 6.0 NaN 7.0 NaN # Oregon 9 10 11 # Oregon 9.0 NaN 10.0 NaN # \u6539\u4e3a\u5728\u5217\u4e0a\u8fdb\u884c\u5e7f\u64ad\uff0c\u5728\u884c\u4e0a\u5339\u914d\uff0c\u5fc5\u987b\u4f5c\u7528\u5728\u67d0\u79cd\u7b97\u672f\u65b9\u6cd5\u4e0a\u3002\u4e0b\u4f8b\u4e2dSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\uff08\u6309index\u5339\u914d\u8fdb\u884c\u884c\u64cd\u4f5c\uff09\u3002 print(frame.sub(series3, axis='index')) # \u6216axis=0 # frame: series3 Result: # b d e # Utah 1 # b d e # Utah 0 1 2 # Ohio 4 # Utah -1 0 1 # Ohio 3 4 5 # Texas 7 # Ohio -1 0 1 # Texas 6 7 8 # Oregon 10 # Texas -1 0 1 # Oregon 9 10 11 # Name: d, dtype: int64 # Oregon -1 0 1 \u51fd\u6570\u5e94\u7528\u548c\u6620\u5c04 NumPy\u7684\u901a\u7528\u51fd\u6570\uff08\u9010\u5143\u7d20\u6570\u7ec4\u65b9\u6cd5\uff09\u5bf9pandas\u5bf9\u8c61\uff08DataFrame\u548cSeries\uff09\u4e5f\u6709\u6548\u3002 frame = pd.DataFrame( np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(frame) # b d e # Utah 2.737734 -0.379977 0.758933 # Ohio 0.847497 0.839583 -2.192021 # Texas -0.907544 -0.457436 -1.907396 # Oregon 0.389362 0.250170 1.065889 # \u5bf9DataFrame\u5bf9\u8c61\u8ba1\u7b97\u7edd\u5bf9\u503c\u3002 print(np.abs(frame)) # b d e # Utah 2.737734 0.379977 0.758933 # Ohio 0.847497 0.839583 2.192021 # Texas 0.907544 0.457436 1.907396 # Oregon 0.389362 0.250170 1.065889 # f\u8fd4\u56de\u4e00\u4e2a\u6807\u91cf\u503c f = lambda x: x.max() - x.min() # \u6cbf0\u8f74\u5e94\u7528f\uff08\u5bf9\u6bcf\u5217\u7684\u6240\u6709\u884c\u5143\u7d20\u8fdb\u884cf\u8ba1\u7b97\uff09, \u9ed8\u8ba4axis=0 print(frame.apply(f)) # b 3.645278 # d 1.297019 # e 3.257911 # dtype: float64 # \u6cbf1\u8f74\u5e94\u7528f\uff08\u5bf9\u6bcf\u884c\u7684\u6240\u6709\u5217\u5143\u7d20\u8fdb\u884cf\u8ba1\u7b97\uff09 print(frame.apply(f, axis=1)) # Utah 3.117711 # Ohio 3.039518 # Texas 1.449961 # Oregon 0.815720 # dtype: float64 # \u5b9a\u4e49\u51fd\u6570f\uff0c\u8fd4\u56de\u5e26\u6709\u591a\u4e2a\u503c\u7684Series\u3002 def f(x): return pd.Series( [x.min(), x.max()], index=['min', 'max'] ) print(frame.apply(f)) # b d e # min -0.907544 -0.457436 -2.192021 # max 2.737734 0.839583 1.065889 # \u5b9a\u4e49\u51fd\u6570f\uff0c\u4f7f\u7528applymap\u65b9\u6cd5\u683c\u5f0f\u5316\u5b57\u7b26\uff0c\u5c06\u4e00\u4e2a\u9010\u5143\u7d20\u7684\u51fd\u6570\u5e94\u7528\u5230Series\u4e0a\u3002 f = lambda x: '%.2f' % x print(frame.applymap(f)) # # b d e # Utah 2.74 -0.38 0.76 # Ohio 0.85 0.84 -2.19 # Texas -0.91 -0.46 -1.91 # Oregon 0.39 0.25 1.07 print(frame['e'].map(f)) # Utah 0.76 # Ohio -2.19 # Texas -1.91 # Oregon 1.07 # Name: e, dtype: object \u6392\u5e8f\u548c\u6392\u540d \u4f7f\u7528sort_index\u65b9\u6cd5\uff0c\u6309\u884c\u6216\u5217\u7d22\u5f15\u8fdb\u884c\u5b57\u5178\u578b\u6392\u5e8f\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u6392\u5e8f\u597d\u7684Pandas\u5bf9\u8c61\u3002 Series\u6392\u5e8f \u5bf9Series\u8fdb\u884c\u7d22\u5f15\u6392\u5e8f\u548c\u503c\u6392\u5e8f\u3002 obj = pd.Series( range(4), index=list('dabc') ) print(obj) # d 0 # a 1 # b 2 # c 3 # dtype: int64 print(obj.sort_index()) # a 1 # b 2 # c 3 # d 0 # dtype: int64 # print(obj.sort_values()) # d 0 # a 1 # b 2 # c 3 # dtype: int64 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7684\u7f3a\u5931\u503c\u90fd\u4f1a\u88ab\u6392\u5e8f\u81f3Series\u7684\u5c3e\u90e8\u3002 obj = pd.Series([4, np.nan, 7, np.nan, -3, 2]) print(obj) # 0 4.0 # 1 NaN # 2 7.0 # 3 NaN # 4 -3.0 # 5 2.0 # dtype: float64 print(obj.sort_values()) # 4 -3.0 # 5 2.0 # 0 4.0 # 2 7.0 # 1 NaN # 3 NaN # dtype: float64 DataFrame\u6392\u5e8f frame = pd.DataFrame( [[0, 1, 10, 3], [4, 5, 6, 21], [8, 9, 2, 21]], index=['three', 'one', 'five'], columns=list('dabc') ) print(frame) # d a b c # three 0 1 10 3 # one 4 5 6 21 # five 8 9 2 21 print(frame.index) # Index(['three', 'one', 'five'], dtype='object') # \u9ed8\u8ba40\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index()) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3 # \u6307\u5b9a0\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index(axis=0)) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3 # \u6307\u5b9a0\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u964d\u5e8f print(frame.sort_index(axis=0, ascending=False)) # d a b c # three 0 1 10 3 # one 4 5 6 21 # five 8 9 2 21 # \u6307\u5b9a1\u8f74\uff0c\u6240\u6709\u5217\u8fdb\u5217\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index(axis=1)) # a b c d # three 1 10 3 0 # one 5 6 21 4 # five 9 2 21 8 # \u6307\u5b9a1\u8f74\uff0c\u6240\u6709\u5217\u8fdb\u5217\u7d22\u5f15\u9996\u5b57\u6bcd\u964d\u5e8f print(frame.sort_index(axis=1, ascending=False)) # d c b a # three 0 3 10 1 # one 4 21 6 5 # five 8 21 2 9 # \u6309\u6307\u5b9a\u5355\u5217\u8fdb\u884c\u503c\u6392\u5e8f\uff08\u964d\u5e8f\uff09 print(frame.sort_values(by=['c'], ascending=False)) # d a b c # one 4 5 6 21 # five 8 9 2 21 # three 0 1 10 3 # \u6309\u6307\u5b9a\u591a\u5217\u8fdb\u884c\u503c\u6392\u5e8f\uff08\u964d\u5e8f\uff09\uff0c\u5148\u5bf9b\u964d\u5e8f\uff0c\u518d\u5bf9d\u964d\u5e8f print(frame.sort_values(by=['c', 'd'], ascending=False)) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3 \u6392\u540d \u6392\u540d \u662f\u6307\u5bf9\u6570\u7ec4\u4ece1\u5230\u6709\u6548\u6570\u636e\u70b9\u603b\u6570\u5206\u914d\u540d\u6b21\u7684\u64cd\u4f5c\u3002 Series\u548cDataFrame\u7684 rank \u65b9\u6cd5\u662f\u5b9e\u73b0\u6392\u540d\u7684\u65b9\u6cd5\uff0c df.rank(ascending=False, method='max') \u3002 ascending \uff1a\u6392\u540d\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4ece\u4f4e\u5230\u9ad8\uff0c ascending=False \u8868\u793a\u4ece\u9ad8\u5230\u4f4e\uff1b method \uff1a\u6392\u540d\u65b9\u5f0f\uff0c\u5305\u62ec\uff1a average:\u9ed8\u8ba4\uff0c\u5728\u76f8\u7b49\u5206\u7ec4\u4e2d\uff0c\u4e3a\u5404\u4e2a\u503c\u5206\u914d\u5e73\u5747\u6392\u540d\uff0c\u5373\u76f8\u540c\u503c\u7684\u548c\u9664\u4ee5\u8be5\u503c\u7684\u4e2a\u6570\uff0c\u5373\u4e3a\u8be5\u503c\u7684\u540d\u6b21\u3002 min:\u4f7f\u7528\u6574\u4e2a\u5206\u7ec4\u7684\u6700\u5c0f\u6392\u540d\uff0c\u5373\uff0c\u5bf9\u5e94\u76f8\u540c\u503c\uff0c\u53d6\u5728\u987a\u5e8f\u6392\u540d\u4e2d\u6700\u5c0f\u7684\u90a3\u4e2a\u6392\u540d\u4f5c\u4e3a\u6240\u6709\u8be5\u503c\u7684\u6392\u540d\u3002 max:\u4f7f\u7528\u6574\u4e2a\u5206\u7ec4\u7684\u6700\u5927\u6392\u540d\uff0c\u5373\uff0c\u5bf9\u5e94\u76f8\u540c\u503c\uff0c\u53d6\u5728\u987a\u5e8f\u6392\u540d\u4e2d\u6700\u5927\u7684\u90a3\u4e2a\u6392\u540d\u4f5c\u4e3a\u6240\u6709\u8be5\u503c\u7684\u6392\u540d\u3002 first:\u6309\u503c\u518d\u539f\u59cb\u6570\u636e\u4e2d\u51fa\u73b0\u987a\u5e8f\u5206\u914d\u6392\u540d\uff0c\u8c01\u51fa\u73b0\u7684\u4f4d\u7f6e\u9760\u524d\uff0c\u8c01\u7684\u6392\u540d\u9760\u524d\u3002 dense:\u7c7b\u4f3cmin\u65b9\u6cd5\uff0c\u4f46\u6392\u540d\u603b\u662f\u5728\u7ec4\u95f4\u589e\u52a01\uff0c\u800c\u4e0d\u662f\u7ec4\u4e2d\u76f8\u540c\u7684\u5143\u7d20\u6570\uff0c\u5373\u76f8\u540c\u503c\u7684\u6392\u540d\u76f8\u540c\uff0c\u5176\u4ed6\u4f9d\u6b21\u52a01\u5373\u53ef\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0crank\u662f\u901a\u8fc7\u201c\u4e3a\u5404\u7ec4\u5206\u914d\u4e00\u4e2a\u5e73\u5747\u6392\u540d\u201d\u7684\u65b9\u5f0f\u7834\u574f\u5e73\u7ea7\u5173\u7cfb # \u6309\u7167\u6bcf\u4e2a\u5143\u7d20\u7684\u5927\u5c0f\u987a\u5e8f\u7ed9\u51fa\u4e00\u4e2a\u5e73\u5747\u6392\u540d obj = pd.Series([7, -5, 7, 4, 2, 0, 4]) print(obj) # 0 7 # 1 -5 # 2 7 # 3 4 # 4 2 # 5 0 # 6 4 # dtype: int64 print(obj.rank()) # 0 6.5 # 1 1.0 # 2 6.5 # 3 4.5 # 4 3.0 # 5 2.0 # 6 4.5 # dtype: float64 # index value rank # 2 -5 1 # 6 0 2 # 5 2 3 # 4 4 4.5 # 7 4 4.5 # 1 7 6.5 # 3 7 6.5 # \u6839\u636e\u5143\u7d20\u7684\u89c2\u5bdf\u987a\u5e8f\u8fdb\u884c\u5206\u914d\u3002\u5143\u7d200\u548c2\u6ca1\u6709\u4f7f\u7528\u5e73\u5747\u6392\u540d6.5\uff0c\u5b83\u4eec\u88ab\u8bbe\u6210\u4e866\u548c7\uff0c\u56e0\u4e3a\u6570\u636e\u4e2d\u6807\u7b7e0\u4f4d\u4e8e\u6807\u7b7e2\u7684\u524d\u9762\u3002 print(obj.rank(method='first')) # 0 6.0 # 1 1.0 # 2 7.0 # 3 4.0 # 4 3.0 # 5 2.0 # 6 5.0 # dtype: float64 # \u6309\u7167max\u8fdb\u884c\u5347\u5e8f\u548c\u964d\u5e8f print(obj.rank(ascending=False, method='max')) print(obj.rank(ascending=True, method='max')) # Original Series Max with inc Max with dec # 0 7 # 0 2.0 (\u6700\u5c0f) # 0 7.0 (\u6700\u5927) # 1 -5 # 1 7.0 (\u6700\u5927) # 1 1.0 (\u6700\u5c0f) # 2 7 # 2 2.0 (\u6700\u5c0f) # 2 7.0 (\u6700\u5927) # 3 4 # 3 4.0 # 3 5.0 # 4 2 # 4 5.0 # 4 3.0 # 5 0 # 5 6.0 # 5 2.0 # 6 4 # 6 4.0 # 6 5.0 # dtype: float64 # dtype: float64 # dtype: float64 frame = pd.DataFrame( {'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1], 'c': [-2, 5, 8, -2]} ) print(frame) # b a c # 0 4.3 0 -2 # 1 7.0 1 5 # 2 -3.0 0 8 # 3 2.0 1 -2 # \u6cbf1\u8f74\u5bf9DataFrame\u8fdb\u884crank\u64cd\u4f5c\uff0c\u5373\uff0c\u6bcf\u4e00\u884c\u5404\u5143\u7d20\u8fdb\u884crank\u3002 print(frame.rank(axis='columns')) # axis=1 # b a c # 0 3.0 2.0 1.0 # 1 3.0 1.0 2.0 # 2 1.0 2.0 3.0 # 3 3.0 2.0 1.0 \u542b\u6709\u91cd\u590d\u6807\u7b7e\u7684\u8f74\u7d22\u5f15 \u5c3d\u7ba1\u5f88\u591apandas\u51fd\u6570\uff08\u6bd4\u5982reindex\uff09\u9700\u8981\u6807\u7b7e\u662f\u552f\u4e00\u7684\uff0c\u4f46\u8fd9\u4e2a\u5e76\u4e0d\u662f\u5f3a\u5236\u6027\u7684\u3002 \u7d22\u5f15\u7684is_unique\u5c5e\u6027\u53ef\u4ee5\u68c0\u67e5\u6807\u7b7e\u662f\u5426\u552f\u4e00\u3002 \u5e26\u6709\u91cd\u590d\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u7d22\u5f15\u6807\u7b7e\u4f1a\u4ee5\u5e8f\u5217\u65b9\u5f0f\u8fd4\u56de\u591a\u4e2a\u6761\u76ee\u3002\u4e0d\u91cd\u590d\u7684\u7d22\u5f15\u5219\u4f1a\u4ee5\u6807\u91cf\u503c\u7684\u5f62\u5f0f\u8fd4\u56de\u5355\u4e2a\u6761\u76ee\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4f7f\u4ee3\u7801\u66f4\u590d\u6742\u3002 obj = pd.Series(range(5), index=['a', 'b', 'a', 'c', 'b']) print(obj) # a 0 # b 1 # a 2 # c 3 # b 4 # dtype: int64 print(obj.is_unique) # True print(obj.index.is_unique) # False # \u8fd4\u56de\u91cd\u590d\u7d22\u5f15\u5bf9\u5e94\u503c\u7684\u5e8f\u5217\u3002 print(obj['a']) # a 0 # a 2 # dtype: int64 df = pd.DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b', 'b']) print(df) # 0 1 2 # a -0.726164 0.531540 -0.521611 # a -1.539807 -0.710880 -0.992789 # b -0.975970 -0.470725 0.121958 # b -0.301495 1.072322 -1.542296 print(df.index.is_unique) # False print(df.loc['b']) # 0 1 2 # b -0.520008 0.052574 0.638529 # b -1.928705 -1.099534 -1.605296 \u63cf\u8ff0\u6027\u7edf\u8ba1\u6982\u8ff0\u4e0e\u8ba1\u7b97 pandas\u5305\u542b\u4e86\u4e00\u4e9b\u5e38\u7528\u6570\u5b66\u3001\u7edf\u8ba1\u5b66\u65b9\u6cd5\u3002\u5176\u4e2d\u5927\u90e8\u5206\u5c5e\u4e8e\u5f52\u7ea6\u6216\u6c47\u603b\u7edf\u8ba1\u7684\u7c7b\u522b\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4eceDataFrame\u7684\u884c\u6216\u5217\u4e2d\u62bd\u53d6\u4e00\u4e2aSeries\u6216\u4e00\u7cfb\u5217\u503c\uff08\u5982\u603b\u548c\u6216\u5e73\u5747\u503c\uff09\u3002 \u4e0eNumPy\u6570\u7ec4\u4e2d\u7684\u7c7b\u4f3c\u65b9\u6cd5\u76f8\u6bd4\uff0cpandas\u5185\u5efa\u4e86\u5904\u7406\u7f3a\u5931\u503c\u7684\u529f\u80fd\u3002 \u5f52\u7ea6\u65b9\u6cd5: sum() \u79ef\u7d2f\u578b\u65b9\u6cd5: cumsun() \u65e2\u4e0d\u662f\u5f52\u7ea6\u578b\u65b9\u6cd5\u4e5f\u4e0d\u662f\u79ef\u7d2f\u578b\u65b9\u6cd5: describe() df = pd.DataFrame( [[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=list('abcd'), columns=['one', 'two'] ) print(df) # one two # a 1.40 NaN # b 7.10 -4.5 # c NaN NaN # d 0.75 -1.3 # axis=0, \u8fd4\u56de\u4e00\u4e2a\u6bcf\u5217\u7b97\u672f\u548c\u7684Series print(df.sum()) # one 9.25 # two -5.80 # dtype: float64 # axis=1\u4e14skipna=True, \u8fd4\u56de\u4e00\u4e2a\u6bcf\u884c\u548c\u7684Series, \u5ffd\u7565NA\u503c, \u586b0\u3002 print(df.sum(axis=1)) # a 1.40 # b 2.60 # c 0.00 # d -0.55 # dtype: float64 # \u4e0d\u5ffd\u7565NA\u503c\uff0c\u586bNaN\u3002 print(df.sum(axis=1, skipna=False)) # a NaN # b 2.60 # c NaN # d -0.55 # dtype: float64 # \u53ea\u67091\u7ea7\u7d22\u5f15\uff0c\u6240\u4ee5level=0\u548c\u539f\u7d22\u5f15\u6ca1\u6709\u533a\u522b\uff0cNaN\u586b\u51450\u3002 print(df.groupby(level=0).sum()) # one two # a 1.40 0.0 # b 7.10 -4.5 # c 0.00 0.0 # d 0.75 -1.3 # \u5217one\u7684\u6700\u5927\u503c\u662f\u5728\u7d22\u5f15b, \u5217two\u7684\u6700\u5927\u503c\u662f\u5728\u7d22\u5f15d print(df.idxmax()) # one b # two d # dtype: object print(df.idxmin()) # one d # two b # dtype: object # cumsun\u7684\u610f\u601d\u662f\u7b2cn\u6b21\u7684\u548c\u662fn-1\u6b21\u7684\u548c\u4e0en\u7684\u548c\uff0cone\u5217d\u884c\u7684\u548c\u5c31\u662fone\u5217a\u3001b\u3001c\u3001d\u503c\u7684\u603b\u548c\u3002 print(df.cumsum()) # one two # a 1.40 NaN # b 8.50 -4.5 # c NaN NaN # d 9.25 -5.8 \u901a\u8fc7describe\u4ea7\u751f\u7edf\u8ba1\u4fe1\u606f\uff0c\u6ce8\u610f\uff0c\u6570\u503c\u578b\u548c\u975e\u6570\u503c\u578b\u7684describe\u7684\u4fe1\u606f\u662f\u4e0d\u540c\u7684\u3002 # \u4e00\u6b21\u6027\u4ea7\u751f\u591a\u4e2a\u6c47\u603b\u7edf\u8ba1 print(df.describe()) # one two # count 3.000000 2.000000 # mean 3.083333 -2.900000 # std 3.493685 2.262742 # min 0.750000 -4.500000 # 25% 1.075000 -3.700000 # 50% 1.400000 -2.900000 # 75% 4.250000 -2.100000 # max 7.100000 -1.300000 obj = pd.Series(['a', 'a', 'b', 'c'] * 4) print(obj) # 0 a # 1 a # 2 b # 3 c # 4 a # 5 a # 6 b # 7 c # 8 a # 9 a # 10 b # 11 c # 12 a # 13 a # 14 b # 15 c # dtype: object # \u9488\u5bf9\u975e\u6570\u503c\u578b\u6570\u636e\uff0cdescribe\u4ea7\u751f\u53e6\u4e00\u79cd\u6c47\u603b\u7edf\u8ba1 print(obj.describe()) # count 16 # unique 3 # top a # freq 8 # dtype: object \u76f8\u5173\u6027\u548c\u534f\u65b9\u5dee \u534f\u65b9\u5dee\u4e0e\u76f8\u5173\u7cfb\u6570\u4e5f\u662f\u5728\u65f6\u57df\u5206\u6790\u65f6\u5e38\u89c1\u7684\u4e24\u4e2a\u6982\u5ff5\uff0c\u4ed6\u4eec\u90fd\u662f\u7528\u6765\u63cf\u8ff0\u6570\u636e\u201c\u50cf\u4e0d\u50cf\u201d\u7684\u3002 \u534f\u65b9\u5dee\u7684\u901a\u4fd7\u7406\u89e3\uff1a \u4e24\u4e2a\u53d8\u91cf\u5728\u53d8\u5316\u8fc7\u7a0b\u4e2d\u662f\u540c\u65b9\u5411\u53d8\u5316\u8fd8\u662f\u53cd\u65b9\u5411\u53d8\u5316\uff1f\u76f8\u540c\u6216\u8005\u76f8\u53cd\u7a0b\u5ea6\u5982\u4f55\uff1f \u4f60\u53d8\u5927\uff0c\u540c\u65f6\u6211\u53d8\u5927\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u662f\u540c\u5411\u53d8\u5316\uff0c\u8fd9\u65f6\u534f\u65b9\u5dee\u5c31\u662f\u6b63\u7684\u3002 \u4f60\u53d8\u5927\uff0c\u540c\u65f6\u6211\u53d8\u5c0f\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u662f\u53cd\u5411\u53d8\u5316\uff0c\u8fd9\u65f6\u534f\u65b9\u5dee\u5c31\u662f\u8d1f\u7684\u3002 \u4ece\u6570\u503c\u770b\uff0c\u534f\u65b9\u5dee\u7684\u6570\u503c\u8d8a\u5927\uff0c\u4e24\u4e2a\u53d8\u91cf\u540c\u5411\u7a0b\u5ea6\u4e5f\u5c31\u8d8a\u5927\u3002\u53cd\u4e4b\u4ea6\u7136\u3002 \u76f8\u5173\u7cfb\u6570\u7684\u901a\u4fd7\u7406\u89e3\uff1a \u7528X\uff0cY\u7684\u534f\u65b9\u5dee\u9664\u4ee5X\u7684\u6807\u51c6\u5dee\u548cY\u7684\u6807\u51c6\u5dee\u3002\u76f8\u5173\u7cfb\u6570\u4e5f\u53ef\u4ee5\u770b\u6210\u534f\u65b9\u5dee\uff0c\u4e00\u79cd\u63d0\u51fa\u4e86\u4e24\u4e2a\u53d8\u91cf\u91cf\u7eb2\u5f71\u54cd\u3001\u6807\u51c6\u5316\u540e\u7684\u7279\u6b8a\u534f\u65b9\u5dee\u3002\u6240\u4ee5\uff1a\u4e5f\u53ef\u4ee5\u53cd\u6620\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u662f\u540c\u5411\u8fd8\u662f\u53cd\u5411\uff0c\u5982\u679c\u540c\u5411\u53d8\u5316\u5c31\u4e3a\u6b63\uff0c\u53cd\u5411\u53d8\u5316\u5c31\u4e3a\u8d1f\u3002 \u7531\u4e8e\u662f\u6807\u51c6\u7248\u540e\u7684\u534f\u65b9\u5dee\uff0c\u76f8\u5173\u7cfb\u6570\u6d88\u9664\u4e86\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u5e45\u5ea6\u7684\u5f71\u54cd\uff0c\u800c\u53ea\u662f\u5355\u7eaf\u53cd\u5e94\u4e24\u4e2a\u53d8\u91cf\u6bcf\u5355\u4f4d\u53d8\u5316\u65f6\u7684\u76f8\u4f3c\u7a0b\u5ea6\u3002 \u603b\u7ed3\uff1a \u5bf9\u4e8e\u4e24\u4e2a\u53d8\u91cfX\u3001Y\uff0c \u5f53\u4ed6\u4eec\u7684\u76f8\u5173\u7cfb\u6570\u4e3a1\u65f6\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u7684\u6b63\u5411\u76f8\u4f3c\u5ea6\u6700\u5927\u3002 \u5f53\u4ed6\u4eec\u7684\u76f8\u5173\u7cfb\u6570\u4e3a\uff0d1\u65f6\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u7684\u53cd\u5411\u76f8\u4f3c\u5ea6\u6700\u5927\u3002 \u968f\u7740\u4ed6\u4eec\u76f8\u5173\u7cfb\u6570\u51cf\u5c0f\uff0c\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u7684\u76f8\u4f3c\u5ea6\u4e5f\u53d8\u5c0f\uff0c\u5f53\u76f8\u5173\u7cfb\u6570\u4e3a0\u65f6\uff0c\u4e24\u4e2a\u53d8\u91cf\u7684\u53d8\u5316\u8fc7\u7a0b\u6ca1\u6709\u4efb\u4f55\u76f8\u4f3c\u5ea6\uff0c\u4e5f\u5373\u4e24\u4e2a\u53d8\u91cf\u65e0\u5173\u3002 \u5f53\u76f8\u5173\u7cfb\u6570\u7ee7\u7eed\u53d8\u5c0f\uff0c\u5c0f\u4e8e0\u65f6\uff0c\u4e24\u4e2a\u53d8\u91cf\u5f00\u59cb\u51fa\u73b0\u53cd\u5411\u7684\u76f8\u4f3c\u5ea6\uff0c\u968f\u7740\u76f8\u5173\u7cfb\u6570\u7ee7\u7eed\u53d8\u5c0f\uff0c\u53cd\u5411\u76f8\u4f3c\u5ea6\u4f1a\u9010\u6e10\u53d8\u5927\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u4f7f\u7528 pandas-datareader\uff1a https://pypi.org/project/pandas-datareader/ https://pydata.github.io/pandas-datareader/) \u5728\u6240\u6709\u4f8b\u5b50\u4e2d\uff0c\u5728\u8ba1\u7b97\u76f8\u5173\u6027\u4e4b\u524d\uff0c\u6570\u636e\u70b9\u5df2\u7ecf\u6309\u6807\u7b7e\u8fdb\u884c\u4e86\u5bf9\u9f50\u3002 \u4e0b\u4f8b\u9700\u8981\u901a\u8fc7pandas-datareader\u5e93\u4eceYahoo! Finance\u4e0a\u83b7\u53d6\u7684\u5305\u542b\u80a1\u4ef7\u548c\u4ea4\u6613\u91cf\u7684DataFrame\u3002 import pandas_datareader.data as web all_data = { ticker: web.get_data_yahoo(ticker) for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG'] } price = pd.DataFrame( { ticker: data['Adj Close'] for ticker, data in all_data.items() } ) volume = pd.DataFrame( { ticker: data['Volume'] for ticker, data in all_data.items() } ) returns = price.pct_change() print(returns.tail()) # AAPL IBM MSFT GOOG # Date # 2021-08-09 -0.000342 -0.008424 -0.003904 0.007049 # 2021-08-10 -0.003354 0.000920 -0.006555 0.000685 # 2021-08-11 0.001786 0.005305 0.001781 -0.002947 # 2021-08-12 0.020773 0.006614 0.009967 0.005084 # 2021-08-13 0.001410 0.000769 0.010490 0.000119 Series\u7684corr\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u91cd\u53e0\u7684\u3001\u975eNA\u7684\u3001\u6309\u7d22\u5f15\u5bf9\u9f50\u7684\u503c\u7684\u76f8\u5173\u6027\u3002\u76f8\u5e94\u5730\uff0ccov\u8ba1\u7b97\u7684\u662f\u534f\u65b9\u5dee print(returns['MSFT']) # Date # 2016-08-15 NaN # 2016-08-16 -0.005540 # 2016-08-17 0.002089 # 2016-08-18 0.000695 # 2016-08-19 0.000347 # ... # 2021-08-09 -0.003904 # 2021-08-10 -0.006555 # 2021-08-11 0.001781 # 2021-08-12 0.009967 # 2021-08-13 0.010490 # Name: MSFT, Length: 1259, dtype: float64 # Series\u7684corr\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u91cd\u53e0\u7684\u3001\u975eNA\u7684\u3001\u6309\u7d22\u5f15\u5bf9\u9f50\u7684\u503c\u7684\u76f8\u5173\u6027\u3002 print(returns['MSFT'].corr(returns['IBM'])) # 0.5175237180581937 # \u7b49\u540c\u5199\u6cd5\uff0cMSFT\u662f\u4e00\u4e2a\u6709\u6548\u7684Python\u5c5e\u6027 print(returns.MSFT.corr(returns.IBM)) # 0.5175237180581937 # Series\u7684cov\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u503c\u7684\u534f\u65b9\u5dee\u3002 print(returns['MSFT'].cov(returns['IBM'])) # 0.0001452224236764915 DataFrame\u7684corr\u548ccov\u65b9\u6cd5\u4f1a\u5206\u522b\u4ee5DataFrame\u7684\u5f62\u5f0f\u8fd4\u56de\u76f8\u5173\u6027\u548c\u534f\u65b9\u5dee\u77e9\u9635\u3002 print(returns.corr()) # AAPL IBM MSFT GOOG # AAPL 1.000000 0.441111 0.735539 0.661961 # IBM 0.441111 1.000000 0.517524 0.484230 # MSFT 0.735539 0.517524 1.000000 0.775756 # GOOG 0.661961 0.484230 0.775756 1.000000 # \u7ed9corrwith\u65b9\u6cd5\uff0c\u4f20\u5165\u4e00\u4e2aSeries\u65f6\uff0c\u4f1a\u8fd4\u56de\u4e00\u4e2a\u542b\u6709\u4e3a\u6bcf\u5217\u8ba1\u7b97\u76f8\u5173\u6027\u503c\u7684Series print(returns.corrwith(returns['IBM'])) # AAPL 0.441111 # IBM 1.000000 # MSFT 0.517524 # GOOG 0.484230 # dtype: float64 # \u7ed9corrwith\u65b9\u6cd5\uff0c\u4f20\u5165\u4e00\u4e2aDataFrame\u65f6\uff0c\u4f1a\u8ba1\u7b97\u5339\u914d\u5230\u5217\u540d\u7684\u76f8\u5173\u6027\u6570\u503c\u3002\u4e0b\u9762\u662f\u8ba1\u7b97\u4ea4\u6613\u91cf\u767e\u5206\u6bd4\u53d8\u5316\u7684\u76f8\u5173\u6027 print(returns.corrwith(volume)) # AAPL -0.063111 # IBM -0.103721 # MSFT -0.056842 # GOOG -0.119026 # dtype: float64 print(returns.cov()) # AAPL IBM MSFT GOOG # AAPL 0.000361 0.000137 0.000240 0.000211 # IBM 0.000137 0.000268 0.000145 0.000133 # MSFT 0.000240 0.000145 0.000294 0.000224 # GOOG 0.000211 0.000133 0.000224 0.000282 \u552f\u4e00\u503c\u3001\u8ba1\u6570\u548c\u6210\u5458\u5c5e\u6027 obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c']) print(obj) # 0 c # 1 a # 2 d # 3 a # 4 a # 5 a # 6 b # 7 b # 8 c # 9 c # dtype: object \u51fd\u6570 unique \u7ed9\u51faSeries\u4e2d\u7684\u552f\u4e00\u503c\u3002 print(obj.unique()) # ['c' 'a' 'd' 'b'] print(obj.sort_values().unique()) # ['a' 'b' 'c' 'd'] # value_counts\u8ba1\u7b97Series\u5305\u542b\u7684\u503c\u7684\u4e2a\u6570 print(obj.value_counts()) # a 4 # c 3 # b 2 # d 1 # dtype: int64 # \u8fd9\u91ccvalue_counts\u4e0d\u662fSeries\u7684\u65b9\u6cd5\uff0c\u662fpandas\u9876\u5c42\u65b9\u6cd5 print(pd.value_counts(obj.values, sort=True)) # a 4 # c 3 # b 2 # d 1 # dtype: int64 print(obj.isin(['b', 'c'])) # 0 True # 1 False # 2 False # 3 False # 4 False # 5 False # 6 True # 7 True # 8 True # 9 True # dtype: bool # \u5c06\u4e0a\u9762\u7684\u7ed3\u679c\u4f5c\u4e3a\u5217\u8868\u8f93\u5165\u7684\u6761\u4ef6\uff0c\u8f93\u51fa\u4e3aTrue\u7684\u7ed3\u679c print(obj[obj.isin(['b', 'c'])]) # 0 c # 6 b # 7 b # 8 c # 9 c # dtype: object \u53c2\u8003: pandas.Index.get_indexer obj1 = pd.Series(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c']) obj2 = pd.Series(['c', 'a', 'b']) print(pd.Index(obj1)) # Index(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c'], dtype='object') print(pd.Index(obj2)) # Index(['c', 'a', 'b'], dtype='object') # \u8fd9\u91cc0\u5bf9\u5e94obj2\u91cc\u9762\u7684c\u5728job1\u7684\u4f4d\u7f6e\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u751f\u6210\u65b0\u7684\u7d22\u5f15\u5217\u8868 print(pd.Index(obj2).get_indexer(obj1)) # [ 0 1 -1 1 1 1 2 2 0 0] \u8ba1\u7b97DataFrame\u591a\u4e2a\u76f8\u5173\u5217\u7684\u76f4\u65b9\u56fe\u3002 data = pd.DataFrame( { 'Que1': [1, 3, 4, 3, 4], 'Que2': [2, 3, 1, 2, 3], 'Que3': [1, 5, 2, 4, 4], } ) print(data) # Que1 Que2 Que3 # 0 1 2 1 # 1 3 3 5 # 2 4 1 2 # 3 3 2 4 # 4 4 3 4 result = data.apply(pd.value_counts).fillna(0) # \u4e0b\u9762\u7ed3\u679c\u4e2d\u7684\u884c\u6807\u7b7e\u662f\u6240\u6709\u5217\u4e2d\u51fa\u73b0\u7684\u4e0d\u540c\u503c\uff0c\u6570\u503c\u5219\u662f\u8fd9\u4e9b\u4e0d\u540c\u503c\u5728\u6bcf\u4e2a\u5217\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u4f8b\u5982\uff1a\u6570\u5b575\u53ea\u5728Que3\u91cc\u9762\u51fa\u73b0\u4e86\u4e00\u6b21 print(result) # Que1 Que2 Que3 # 1 1.0 1.0 1.0 # 2 0.0 2.0 1.0 # 3 2.0 2.0 0.0 # 4 2.0 0.0 2.0 # 5 0.0 0.0 1.0","title":"Pandas\u5165\u95e8"},{"location":"python/DataAnalysis/ch02/#pandas","text":"\u7ea6\u5b9a\uff1a import numpy as np import pandas as pd from pandas import Series, DataFrame import pandas_datareader as web","title":"Pandas\u5165\u95e8"},{"location":"python/DataAnalysis/ch02/#pandas_1","text":"","title":"pandas\u6570\u636e\u7ed3\u6784\u4ecb\u7ecd"},{"location":"python/DataAnalysis/ch02/#series","text":"Series\u662f\u4e00\u79cd\u4e00\u7ef4\u7684\u6570\u7ec4\u578b\u5bf9\u8c61\uff0c\u5b83\u5305\u542b\u4e86\u4e00\u4e2a\u503c\u5e8f\u5217\uff08\u4e0eNumPy\u4e2d\u7684\u7c7b\u578b\u76f8\u4f3c\uff09\uff0c\u5e76\u4e14\u5305\u542b\u4e86\u6570\u636e\u6807\u7b7e\uff0c\u79f0\u4e3a \u7d22\u5f15\uff08index\uff09 \u3002 \u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u8003\u8651Series\uff0c\u53ef\u4ee5\u8ba4\u4e3a\u5b83\u662f\u4e00\u4e2a \u957f\u5ea6\u56fa\u5b9a\u4e14\u6709\u5e8f\u7684\u5b57\u5178 \uff0c\u56e0\u4e3a\u5b83\u5c06\u7d22\u5f15\u503c\u548c\u6570\u636e\u503c\u6309\u4f4d\u7f6e\u914d\u5bf9\u3002\u7d22\u5f15\u5728\u5de6\u8fb9\uff0c\u503c\u5728\u53f3\u8fb9\u3002 obj = pd.Series([4, 7, -5, 3]) print(obj) # 0 4 # 1 7 # 2 -5 # 3 3 # dtype: int64 print(obj.values) # [ 4 7 -5 3 print(obj.index) # RangeIndex(start=0, stop=4, step=1) \u81ea\u5b9a\u4e49index obj = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c']) print(obj) # d 4 # b 7 # a -5 # c 3 # dtype: int64 print(obj.values) # [ 4 7 -5 3] print(obj.index) # Index(['d', 'b', 'a', 'c'], dtype='object') # \u8f93\u51fa\u7d22\u5f15\u503c\u4e3a'a'\u7684Series\u503c print(obj['a']) # -5 # \u4f7f\u7528\u5e03\u5c14\u503c\u6570\u7ec4\u8fdb\u884c\u8fc7\u6ee4Series\u503c print(obj[obj > 3]) # d 4 # b 7 # dtype: int64 # \u5bf9Series\u503c\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97 print(obj * 2) # d 8 # b 14 # a -10 # c 6 # dtype: int64 # \u5bf9Series\u503c\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97 print(np.exp(obj)) # d 54.598150 # b 1096.633158 # a 0.006738 # c 20.085537 # dtype: float64 # \u66f4\u65b0Series\u6570\u7ec4\u503c obj['a'] = 9 # \u8f93\u51fa\u6307\u5b9a\u7d22\u5f15\u503c\u7684Series\u503c\uff0c\u6ce8\u610f\uff0c\u7d22\u5f15\u6761\u4ef6\u662f\u5217\u8868 print(obj[['a', 'b', 'c']]) # a 9 # b 7 # c 3 # dtype: int64 # \u6ce8\u610f\uff0c\u4e0b\u9762\u7684\u5224\u65ad\u662f\u7d22\u5f15\u503c\uff0c\u975eSeries\u503c print(obj) print(7 in obj) # False print('a' in obj) # True \u901a\u8fc7\u5b57\u5178\u751f\u6210\u4e00\u4e2aSeries\u3002 NaN \uff08not a number\uff09\uff0c\u8fd9\u662fpandas\u4e2d\u6807\u8bb0\u7f3a\u5931\u503c\u6216NA\u503c\u7684\u65b9\u5f0f\u3002 \u5f53\u628a\u5b57\u5178\u4f20\u9012\u7ed9Series\u6784\u9020\u51fd\u6570\u65f6\uff0c\u4ea7\u751f\u7684Series\u7684\u7d22\u5f15\u5c06\u662f\u6392\u5e8f\u597d\u7684\u5b57\u5178\u952e\u3002\u53ef\u4ee5\u5c06\u5b57\u5178\u952e\u6309\u7167\u4f60\u6240\u60f3\u8981\u7684\u987a\u5e8f\u4f20\u9012\u7ed9\u6784\u9020\u51fd\u6570\uff0c\u4ece\u800c\u4f7f\u751f\u6210\u7684Series\u7684\u7d22\u5f15\u987a\u5e8f\u7b26\u5408\u9884\u671f\u3002 \u770b\u4e0b\u4f8b\uff0c\u901a\u8fc7\u5b57\u5178sdata\u751f\u6210Series\u3002 sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} obj3 = pd.Series(sdata) print(sdata) # {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} print(obj3) # Ohio 35000 # Texas 71000 # Oregon 16000 # Utah 5000 # dtype: int64 \u901a\u8fc7\u6307\u5b9a\u7d22\u5f15states\u53bb\u5339\u914d\u5b57\u5178sdata\u751f\u6210\u57fa\u4e8e\u65b0\u7d22\u5f15states\u7684Series\u3002 states = ['California', 'Ohio', 'Oregon', 'Texas'] obj4 = pd.Series(sdata, index=states) print(obj4) # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64 \u5bf9Series\u8fdb\u884c\u5e03\u5c14\u503c\u5224\u65ad\u3002 print(pd.isnull(obj4)) # California True # Ohio False # Oregon False # Texas False # dtype: bool print(pd.notnull(obj4)) # California False # Ohio True # Oregon True # Texas True # dtype: bool \u5bf9Series\u8fdb\u884c\u5e03\u5c14\u503c\u5224\u65ad\u3002 print(obj4.isnull) # <bound method Series.isnull of California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64> print(obj4.notnull) # <bound method Series.notnull of California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64> Series\u7684\u81ea\u52a8\u5bf9\u9f50\u7d22\u5f15\uff0c\u4e0e\u6570\u636e\u5e93\u7684join\u64cd\u4f5c\u662f\u975e\u5e38\u76f8\u4f3c\u3002 print(\"obj3 \\n\", obj3) # obj3 # Ohio 35000 # Texas 71000 # Oregon 16000 # Utah 5000 # dtype: int64 print(\"obj4 \\n\", obj4) # obj4 # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # dtype: float64 print(\"obj3+obj4 \\n\", obj3 + obj4) # obj3+obj4 # California NaN # Ohio 70000.0 # Oregon 32000.0 # Texas 142000.0 # Utah NaN # dtype: float64 # \u4e0b\u9762\u662fobj3\u548cobj4\u7684\u503c\uff0c\u5e2e\u52a9\u7406\u89e3\u4e0a\u9762obj3 + obj4\u7684\u64cd\u4f5c\u3002 # obj3 obj4 # Ohio 35000 California NaN # Texas 71000 Ohio 35000.0 # Oregon 16000 Oregon 16000.0 # Utah 5000 Texas 71000.0 # dtype: int64 dtype: float64 Series\u5bf9\u8c61\u81ea\u8eab\u548c\u5176\u7d22\u5f15\u90fd\u6709name\u5c5e\u6027\u3002 obj4.name = 'population' obj4.index.name = 'state' print(obj4) # state # California NaN # Ohio 35000.0 # Oregon 16000.0 # Texas 71000.0 # Name: population, dtype: float64 \u66ff\u6362Series\u7684\u7d22\u5f15\u540d\u3002 obj = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c']) print(obj) obj.index = ['Bob', 'Steve', 'Jeff', 'Ryan'] print(obj) # Bob 4 # Steve 7 # Jeff -5 # Ryan 3 # dtype: int64","title":"Series"},{"location":"python/DataAnalysis/ch02/#dataframe","text":"DataFrame\u8868\u793a\u7684\u662f\u77e9\u9635\u7684\u6570\u636e\u8868\uff0c\u5b83\u5305\u542b\u5df2\u6392\u5e8f\u7684\u5217\u96c6\u5408\uff0c\u6bcf\u4e00\u5217\u53ef\u4ee5\u662f\u4e0d\u540c\u7684\u503c\u7c7b\u578b\uff08\u6570\u503c\u3001\u5b57\u7b26\u4e32\u3001\u5e03\u5c14\u503c\u7b49\uff09\u3002 DataFrame\u65e2\u6709\u884c\u7d22\u5f15\u4e5f\u6709\u5217\u7d22\u5f15\uff0c\u5b83\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5171\u4eab\u76f8\u540c\u7d22\u5f15\u7684Series\u7684\u5b57\u5178\uff0c\u6bd4\u5982\u6240\u6709\u5217\u5171\u4eab\u540c\u4e00\u4e2a\u5217\u7d22\u5f15\u3002 \u5728DataFrame\u4e2d\uff0c\u6570\u636e\u88ab\u5b58\u50a8\u4e3a\u4e00\u4e2a\u4ee5\u4e0a\u7684\u4e8c\u7ef4\u5757\uff0c\u800c\u4e0d\u662f\u5217\u8868\u3001\u5b57\u5178\u6216\u5176\u4ed6\u4e00\u7ef4\u6570\u7ec4\u7684\u96c6\u5408\u3002 DataFrame\u662f\u4e8c\u7ef4\u7684\uff0c\u4f46\u53ef\u4ee5\u5229\u7528 \u5206\u5c42\u7d22\u5f15 \u5728DataFrame\u4e2d\u5c55\u73b0\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u636e\u3002 \u4eceDataFrame\u4e2d\u9009\u53d6\u7684\u5217\u662f\u6570\u636e\u7684\u89c6\u56fe\uff0c\u800c\u4e0d\u662f\u62f7\u8d1d \u3002\u56e0\u6b64\uff0c\u5bf9Series\u7684\u4fee\u6539\u4f1a\u6620\u5c04\u5230DataFrame\u4e2d\u3002\u5982\u679c\u9700\u8981\u590d\u5236\uff0c\u5219\u5e94\u5f53\u663e\u5f0f\u5730\u4f7f\u7528Series\u7684copy\u65b9\u6cd5\u3002","title":"DataFrame"},{"location":"python/DataAnalysis/ch02/#dataframe_1","text":"\u57fa\u4e8e\u5b57\u5178 data \u4ea7\u751f\u7684DataFrame\u4f1a\u81ea\u52a8\u4e3aSereies\u5206\u914d\u7d22\u5f15\uff0c\u5e76\u4e14\u5217\u4f1a\u6309\u7167\u6392\u5e8f\u7684\u987a\u5e8f\u6392\u5217\u3002 data = { 'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002, 2003], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2] } frame = pd.DataFrame(data) print(frame) # state year pop # 0 Ohio 2000 1.5 # 1 Ohio 2001 1.7 # 2 Ohio 2002 3.6 # 3 Nevada 2001 2.4 # 4 Nevada 2002 2.9 # 5 Nevada 2003 3.2 # \u5bf9\u4e8e\u5927\u578bDataFrame, head\u65b9\u6cd5\u5c06\u4f1a\u53ea\u9009\u51fa\u5934\u90e8\u7684\u82e5\u5e72\u884c, \u9ed8\u8ba4\u662f\u524d\u4e94\u884c\u3002 print(frame.head(3)) # state year pop # 0 Ohio 2000 1.5 # 1 Ohio 2001 1.7 # 2 Ohio 2002 3.6 \u5982\u679c\u6307\u5b9a\u4e86\u5217\u7684\u987a\u5e8f\uff0cDataFrame\u7684\u5217\u5c06\u4f1a\u6309\u7167\u6307\u5b9a\u987a\u5e8f\u6392\u5217\u3002 frame = pd.DataFrame(data, columns=['year', 'state', 'pop']) print(frame) # year state pop # 0 2000 Ohio 1.5 # 1 2001 Ohio 1.7 # 2 2002 Ohio 3.6 # 3 2001 Nevada 2.4 # 4 2002 Nevada 2.9 # 5 2003 Nevada 3.2 \u5982\u679c\u4f20\u7684\u5217\uff08 debt \uff09\u4e0d\u5305\u542b\u5728\u5b57\u5178\uff08 data \uff09\u4e2d\uff0c\u5c06\u4f1a\u5728\u7ed3\u679c\u4e2d\u51fa\u73b0\u7f3a\u5931\u503c\u3002 frame2 = pd.DataFrame( data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five', 'six'] ) print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 NaN # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 NaN # five 2002 Nevada 2.9 NaN # six 2003 Nevada 3.2 NaN \u9009\u53d6\u884c, \u53ef\u4ee5\u901a\u8fc7\u4f4d\u7f6e\u6216\u884c\u7d22\u5f15\u6807\u7b7e loc \u8fdb\u884c\u9009\u53d6\u3002 print(frame2.loc['three']) # year 2002 # state Ohio # pop 3.6 # debt NaN # Name: three, dtype: object DataFrame\u4e2d\u7684\u4e00\u5217\uff0c\u53ef\u4ee5\u6309\u5b57\u5178\u578b\u6807\u8bb0\u6216\u5c5e\u6027\u90a3\u6837\u68c0\u7d22\u4e3aSeries\u3002 frame2[colunm] \u5bf9\u4e8e\u4efb\u610f\u5217\u540d\u5747\u6709\u6548\uff0c\u4f46\u662f frame2.column \u53ea\u5728\u5217\u540d\u662f\u6709\u6548\u7684Python\u53d8\u91cf\u540d\u65f6\u6709\u6548\u3002 \u8fd4\u56de\u7684Series\u4e0e\u539fDataFrame\u6709\u76f8\u540c\u7684\u7d22\u5f15\uff0c\u4e14Series\u7684 name \u5c5e\u6027\u4e5f\u4f1a\u88ab\u5408\u7406\u5730\u8bbe\u7f6e\u3002 print(frame2['state']) # one Ohio # two Ohio # three Ohio # four Nevada # five Nevada # six Nevada # Name: state, dtype: object print(frame2.state) # \u5c5e\u6027\u578b\u8fde\u63a5 # one Ohio # two Ohio # three Ohio # four Nevada # five Nevada # six Nevada # Name: state, dtype: object \u5217\u7684\u5f15\u7528\u662f\u53ef\u4ee5\u4fee\u6539\u7684\u3002\u503c\u7684\u957f\u5ea6\u5fc5\u987b\u548cDataFrame\u7684\u957f\u5ea6\u76f8\u5339\u914d,\u6bd4\u5982\uff0c\u4e0b\u4f8b\u4e2d np.arange(6.) \u548c frame2['debt'] \u7684\u957f\u5ea6\u90fd\u662f6\u3002 frame2['debt'] = 16.5 print(frame2) # Name: state, dtype: object # year state pop debt # one 2000 Ohio 1.5 16.5 # two 2001 Ohio 1.7 16.5 # three 2002 Ohio 3.6 16.5 # four 2001 Nevada 2.4 16.5 # five 2002 Nevada 2.9 16.5 # six 2003 Nevada 3.2 16.5 frame2['debt'] = np.arange(6.) print(frame2) # year state pop debt # one 2000 Ohio 1.5 0.0 # two 2001 Ohio 1.7 1.0 # three 2002 Ohio 3.6 2.0 # four 2001 Nevada 2.4 3.0 # five 2002 Nevada 2.9 4.0 # six 2003 Nevada 3.2 5.0 \u5982\u679c\u5c06Series\u8d4b\u503c\u7ed9\u4e00\u5217\u65f6\uff0cSeries\u7684\u7d22\u5f15\u5c06\u4f1a\u6309\u7167DataFrame\u7684\u7d22\u5f15\u91cd\u65b0\u6392\u5217\uff0c\u5e76\u5728\u7a7a\u7f3a\u7684\u5730\u65b9\u586b\u5145\u7f3a\u5931\u503c val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five']) frame2['debt'] = val print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 -1.2 # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 -1.5 # five 2002 Nevada 2.9 -1.7 # six 2003 Nevada 3.2 NaN \u5982\u679c\u88ab\u8d4b\u503c\u7684\u5217( eastern \u5217)\u5e76\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u5217\u3002 frame2.state == 'Ohio' \u8fd4\u56de\u7684\u662f\u5e03\u5c14\u503c\uff0c\u8d4b\u503c\u7ed9 eastern \u3002 frame2['eastern'] = frame2.state == 'Ohio' print(frame2) # year state pop debt eastern # one 2000 Ohio 1.5 NaN True # two 2001 Ohio 1.7 -1.2 True # three 2002 Ohio 3.6 NaN True # four 2001 Nevada 2.4 -1.5 False # five 2002 Nevada 2.9 -1.7 False # six 2003 Nevada 3.2 NaN False print(frame2.eastern) # one True # two True # three True # four False # five False # six False # Name: eastern, dtype: bool del \u5173\u952e\u5b57\u53ef\u4ee5\u50cf\u5728\u5b57\u5178\u4e2d\u90a3\u6837\u5bf9DataFrame\u5220\u9664\u5217\u3002 del frame2['eastern'] print(frame2.columns) # Index(['year', 'state', 'pop', 'debt'], dtype='object')","title":"\u7531\u5b57\u5178\u6784\u6210DataFrame"},{"location":"python/DataAnalysis/ch02/#dataframe_2","text":"pandas\u4f1a\u5c06\u5b57\u5178\u7684\u952e\u4f5c\u4e3a\u5217('Nevada', etc.)\uff0c\u5c06\u5185\u90e8\u5b57\u5178\u7684\u952e\u4f5c\u4e3a\u884c\u7d22\u5f15(2001, etc.) pop = { 'Nevada': { 2001: 2.4, 2002: 2.9 }, 'Ohio': { 2000: 1.5, 2001: 1.7, 2002: 3.6 } } # \u4e0d\u6307\u5b9a\u7d22\u5f15\uff0c\u9ed8\u8ba4\u4f7f\u7528\u5b57\u5178\u7d22\u5f15 frame3 = pd.DataFrame(pop) print(frame3) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 # \u6307\u5b9a\u5b57\u5178\u67d0\u5217\u4f5c\u4e3a\u7d22\u5f15 print(pd.DataFrame(pop, index=[2001, 2002, 2003])) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2003 NaN NaN # \u6307\u5b9a\u4e0d\u76f8\u5e72\u7d22\u5f15 print(pd.DataFrame(pop, index=['a', 'b', 'c'])) # Nevada Ohio # a NaN NaN # b NaN NaN # c NaN NaN \u8f6c\u7f6e\u64cd\u4f5c\uff08\u8c03\u6362\u884c\u548c\u5217\uff09 print(frame3.T) # 2001 2002 2000 # Nevada 2.4 2.9 NaN # Ohio 1.7 3.6 1.5","title":"\u4f7f\u7528\u5d4c\u5957\u5b57\u5178\u6784\u5efaDataFrame"},{"location":"python/DataAnalysis/ch02/#seriesdataframe","text":"frame3['Ohio'][:-1] \u662f\u503c\u4e3a Ohio \u7684Series\u76840~\u5012\u6570\u7b2c\u4e00\u4e2a\u5143\u7d20\uff08\u4e0d\u542b\uff09\uff0c\u4e00\u51713\u4e2a\u3002 frame3['Nevada'][:2] \u662f\u503c\u4e3a Nevada \u7684Series\u7684\u524d2\u4e2a\u5143\u7d20\u3002 pdata = { 'Ohio': frame3['Ohio'][:-1], 'Nevada': frame3['Nevada'][:2] } print(pd.DataFrame(pdata)) # Ohio Nevada # 2001 1.7 2.4 # 2002 3.6 2.9 \u6307\u5b9aDataframe frame3 \u7684\u5217\u540d\u3002 frame3.index.name = 'year' frame3.columns.name = 'state' print(frame3) # state Nevada Ohio # year # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 \u53ea\u8f93\u51faDataframe\u7684\u503c frame3.values \uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u3002 print(frame3.values) # [[2.4 1.7] # [2.9 3.6] # [nan 1.5]] \u53ea\u8f93\u51faDataframe\u7684\u503c frame2.values \uff0c\u662f\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\u3002 print(frame2) # year state pop debt # one 2000 Ohio 1.5 NaN # two 2001 Ohio 1.7 -1.2 # three 2002 Ohio 3.6 NaN # four 2001 Nevada 2.4 -1.5 # five 2002 Nevada 2.9 -1.7 # six 2003 Nevada 3.2 NaN print(frame2.values) # [[2000 'Ohio' 1.5 nan] # [2001 'Ohio' 1.7 -1.2] # [2002 'Ohio' 3.6 nan] # [2001 'Nevada' 2.4 -1.5] # [2002 'Nevada' 2.9 -1.7] # [2003 'Nevada' 3.2 nan]]","title":"\u4f7f\u7528\u542bSeries\u7684\u5b57\u5178\u6784\u9020DataFrame"},{"location":"python/DataAnalysis/ch02/#_1","text":"pandas\u4e2d\u7684 \u7d22\u5f15\u5bf9\u8c61 \u662f\u7528\u4e8e\u5b58\u50a8\u8f74\u6807\u7b7e\u548c\u5176\u4ed6\u5143\u6570\u636e\u7684\uff08\u4f8b\u5982\u8f74\u540d\u79f0\u6216\u6807\u7b7e\uff09\u3002 \u5728\u6784\u9020Series\u6216DataFrame\u65f6\uff0c\u4f60\u6240\u4f7f\u7528\u7684\u4efb\u610f\u6570\u7ec4\u6216\u6807\u7b7e\u5e8f\u5217\u90fd\u53ef\u4ee5\u5728\u5185\u90e8\u8f6c\u6362\u4e3a\u7d22\u5f15\u5bf9\u8c61\u3002 \u7d22\u5f15\u5bf9\u8c61\u662f\u4e0d\u53ef\u53d8\u7684\u3002 \u9664\u4e86\u7c7b\u4f3c\u6570\u7ec4\uff0c\u7d22\u5f15\u5bf9\u8c61\u4e5f\u50cf\u4e00\u4e2a\u56fa\u5b9a\u5927\u5c0f\u7684\u96c6\u5408\u3002\u4e0ePython\u96c6\u5408\u4e0d\u540c\uff0c pandas\u7d22\u5f15\u5bf9\u8c61\u53ef\u4ee5\u5305\u542b\u91cd\u590d\u6807\u7b7e \u3002 \u56e0\u4e3a\u4e00\u4e9b\u64cd\u4f5c\u4f1a\u4ea7\u751f\u5305\u542b\u7d22\u5f15\u5316\u6570\u636e\u7684\u7ed3\u679c\uff0c\u7406\u89e3\u7d22\u5f15\u5982\u4f55\u5de5\u4f5c\u8fd8\u662f\u5f88\u91cd\u8981\u7684\u3002 \u4e0b\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u8bfb\u53d6Dataframe\u7684\u7d22\u5f15\u503c\u3002 obj = pd.Series(range(3), index=['a', 'b', 'c']) index = obj.index print(obj) # a 0 # b 1 # c 2 # dtype: int64 print(index) # Index(['a', 'b', 'c'], dtype='object') print(index[1:]) # Index(['b', 'c'], dtype='object') \u4e0b\u4f8b\u6f14\u793a\u4e86\u901a\u8fc7\u4e00\u4e2a\u6307\u5b9a\u7684Dataframe\u7d22\u5f15 labels \u6765\u751f\u6210Dataframe obj2 \u3002 labels = pd.Index(np.arange(3)) print(labels) # Int64Index([0, 1, 2], dtype='int64') obj2 = pd.Series([1.5, -2.5, 0], index=labels) print(obj2) # 0 1.5 # 1 -2.5 # 2 0.0 # dtype: float64 print(obj2.index is labels) # True \u4e0b\u4f8b\u6f14\u793a\u4e86\u4e0d\u6307\u5b9a\u7d22\u5f15\uff0c\u9ed8\u8ba4\u4f7f\u7528\u5b57\u5178\u7d22\u5f15\u6765\u521b\u5efaDataframe\u3002 pop = { 'Nevada': { 2001: 2.4, 2002: 2.9 }, 'Ohio': { 2000: 1.5, 2001: 1.7, 2002: 3.6 } } frame3 = pd.DataFrame(pop) print(frame3) # Nevada Ohio # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 print(frame3) # state Nevada Ohio # year # 2001 2.4 1.7 # 2002 2.9 3.6 # 2000 NaN 1.5 print(frame3.columns) # Index(['Nevada', 'Ohio'], dtype='object', name='state') print(frame3.index) # Int64Index([2001, 2002, 2000], dtype='int64', name='year') print('Ohio' in frame3.columns) # True print(2003 in frame3.index) # False pandas\u7d22\u5f15\u5bf9\u8c61\u5141\u8bb8\u5305\u542b\u91cd\u590d\u6807\u7b7e\u3002\u6839\u636e\u91cd\u590d\u6807\u7b7e\u8fdb\u884c\u7b5b\u9009\uff0c\u4f1a\u9009\u53d6\u6240\u6709\u91cd\u590d\u6807\u7b7e\u5bf9\u5e94\u7684\u6570\u636e\u3002 dup_labels = pd.Index(['foo', 'foo', 'bar', 'bar']) print(dup_labels) # Index(['foo', 'foo', 'bar', 'bar'], dtype='object') \u4e00\u4e9b\u5e38\u7528\u7d22\u5f15\u5bf9\u8c61\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u3002 obj1 = pd.Series(range(3), index=['a', 'b', 'c']) index1 = obj1.index obj2 = pd.Series(range(3), index=['c', 'f', 'g']) index2 = obj2.index print(index1) # Index(['a', 'b', 'c'], dtype='object') print(index2) # Index(['c', 'f', 'g'], dtype='object') append \u65b9\u6cd5\uff1a\u5c06\u5916\u90e8\u7684\u7d22\u5f15\u5bf9\u8c61\u7c98\u8d34\u5230\u539f\u7d22\u5f15\u540e\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684\u7d22\u5f15\u3002 \u63a5\u4e0a\u4f8b\uff0c\u628a index2 \u5bf9\u8c61\u8ffd\u52a0\u5230 index1 \u5bf9\u8c61\u3002 print(index1.append(index2)) # Index(['a', 'b', 'c', 'c', 'f', 'g'], dtype='object') difference \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u5dee\u96c6\u3002 print(index1.difference(index2)) # Index(['a', 'b'], dtype='object') intersection \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u4ea4\u96c6\u3002 print(index1.intersection(index2)) # Index(['c'], dtype='object') union \u65b9\u6cd5: \u8ba1\u7b972\u4e2a\u7d22\u5f15\u7684\u5e76\u96c6\uff08\u53bb\u91cd\uff09\u3002 print(index1.union(index2)) # Index(['a', 'b', 'c', 'f', 'g'], dtype='object') isin \u65b9\u6cd5: \u8ba1\u7b97\u8868\u793a\u6bcf\u4e00\u4e2a\u503c\u662f\u5426\u5728\u4f20\u503c\u5bb9\u5668\u4e2d\uff0c\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5e03\u5c14\u6570\u7ec4\u3002 print(index1.isin(index2)) # [False False True] delete \u65b9\u6cd5: \u5c06\u4f4d\u7f6ei\uff08\u4ece0\u5f00\u59cb\u7f16\u53f7\uff09\u7684\u5143\u7d20\u5220\u9664\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15\u3002 print(index1.delete('b')) # IndexError: arrays used as indices must be of integer (or boolean) type print(index1.delete(1)) # Index(['a', 'c'], dtype='object') print(index1) # Index(['a', 'b', 'c'], dtype='object') drop \u65b9\u6cd5: \u6839\u636e\u4f20\u53c2\u5220\u9664\u6307\u5b9a\u7d22\u5f15\u503c\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15, \u5bf9\u6bd4\u548cdelete\u7684\u533a\u522b\uff0c delete \u65b9\u6cd5\u662f\u8f93\u5165\u4f4d\u7f6e\uff0c drop \u65b9\u6cd5\u662f\u8f93\u5165\u7d22\u5f15\u540d\u79f0\u3002 print(index2.drop(1)) # KeyError: '[1] not found in axis' print(index2.drop('f')) # Index(['c', 'g'], dtype='object') print(index2) # Index(['c', 'f', 'g'], dtype='object') insert \u65b9\u6cd5: \u5728\u4f4d\u7f6e i \u63d2\u5165\u5143\u7d20\uff0c\u5e76\u4ea7\u751f\u65b0\u7684\u7d22\u5f15\u3002 print(index1.insert(1, 'e')) # Index(['a', 'e', 'b', 'c'], dtype='object') print(index1) # Index(['a', 'b', 'c'], dtype='object') is_monotonic \u65b9\u6cd5: \u5982\u679c\u7d22\u5f15\u5e8f\u5217\u9012\u589e\uff0c\u5219\u8fd4\u56de True \u3002 print(index1.is_monotonic) # True print(index1.insert(1, 'e').is_monotonic) # False is_unique \u65b9\u6cd5: \u5982\u679c\u7d22\u5f15\u5e8f\u5217\u552f\u4e00\u5219\u8fd4\u56de True \u3002 print(index1.is_unique) # True print(index1.append(index2).is_unique) # False unique \u65b9\u6cd5: \u8ba1\u7b97\u7d22\u5f15\u7684\u552f\u4e00\u503c\u5e8f\u5217\uff08\u5bf9\u6bd4Union\uff09\u3002 print(index1.unique()) # Index(['a', 'b', 'c'], dtype='object') print(index1.append(index2).unique()) # Index(['a', 'b', 'c', 'f', 'g'], dtype='object')","title":"\u7d22\u5f15\u5bf9\u8c61"},{"location":"python/DataAnalysis/ch02/#pandas_2","text":"","title":"pandas\u57fa\u672c\u529f\u80fd"},{"location":"python/DataAnalysis/ch02/#_2","text":"Series\u8c03\u7528 reindex \u65b9\u6cd5\u65f6\uff0c\u4f1a\u5c06\u6570\u636e\u6309\u7167\u65b0\u7684\u7d22\u5f15\u8fdb\u884c\u6392\u5217\uff0c\u5982\u679c\u67d0\u4e2a\u7d22\u5f15\u503c\u4e4b\u524d\u5e76\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u5f15\u5165\u7f3a\u5931\u503c\u3002 \u4e0b\u4f8b\u4e2d\uff0c\u5bf9 obj1 \u505a reindex \uff0c reindex \u65b9\u6cd5\u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7d22\u5f15\u5bf9\u8c61 obj2 \uff0c\u7d22\u5f15\u503c e \u4e4b\u524d\u5e76\u4e0d\u5b58\u5728\uff0c\u6240\u4ee5\u586b\u5165\u7f3a\u5931\u503c\u3002 \u5982\u679c\u5bf9obj1\u505a reindex \u65f6\u6307\u5b9a method='ffill' \uff0c\u4f1a\u62a5\u9519 index must be monotonic increasing or decreasing \u3002 obj1 = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c']) print(obj1) # d 4.5 # b 7.2 # a -5.3 # c 3.6 # dtype: float64 obj2 = obj1.reindex(['a', 'b', 'c', 'd', 'e']) print(obj2) # a -5.3 # b 7.2 # c 3.6 # d 4.5 # e NaN # dtype: float64 obj2 = obj1.reindex(['a', 'b', 'c', 'd', 'e'], method='ffill') # ValueError: index must be monotonic increasing or decreasing \u5bf9\u4e8e\u987a\u5e8f\u6570\u636e\uff0c\u6bd4\u5982\u65f6\u95f4\u5e8f\u5217\uff0c\u5728\u91cd\u5efa\u7d22\u5f15\u65f6\u53ef\u80fd\u4f1a\u9700\u8981\u8fdb\u884c\u63d2\u503c\u6216\u586b\u503c\u3002 ffill \u65b9\u6cd5\u5728\u91cd\u5efa\u7d22\u5f15\u65f6\u63d2\u503c\uff0c\u5c06\u503c\u524d\u5411\u586b\u5145\u3002 obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4]) print(obj3.reindex(range(6), method='ffill')) # 0 blue # 1 blue # 2 purple # 3 purple # 4 yellow # 5 yellow # dtype: object \u5728DataFrame\u4e2d\uff0c reindex \u53ef\u4ee5\u6539\u53d8\u884c\u7d22\u5f15\u3001\u5217\u7d22\u5f15\uff0c\u4e5f\u53ef\u4ee5\u540c\u65f6\u6539\u53d8\u4e8c\u8005\u3002\u5f53\u4ec5\u4f20\u5165\u4e00\u4e2a\u5e8f\u5217\u65f6\uff0c\u4f1a\u91cd\u5efa\u884c\u7d22\u5f15\u3002 \u4e0b\u4f8b\u4e2d\uff0c\u901a\u8fc7 indexes \u521b\u5efaDataframe frame \u3002 \u901a\u8fc7 frame.reindex(['a', 'b', 'c', 'd'])\u91cd\u5efa\u884c\u7d22\u5f15 \u3002 \u901a\u8fc7 frame2.reindex(columns=['Ohio', 'Uta', 'California']) \u91cd\u5efa\u5217\u7d22\u5f15\u3002 \u7f3a\u5931\u7684\u7d22\u5f15\u5217\u586b\u5165\u7f3a\u5931\u503c\u3002 indexes = index = ['a', 'b', 'c'] states = ['Ohio', 'Texas', 'California'] frame = pd.DataFrame( np.arange(9).reshape(3, 3), index=indexes, columns=states ) print(frame) # Ohio Texas California # a 0 1 2 # b 3 4 5 # c 6 7 8 frame2 = frame.reindex(['a', 'b', 'c', 'd']) # \u91cd\u5efa\u884c\u7d22\u5f15 print(frame2) # Ohio Texas California # a 0.0 1.0 2.0 # b 3.0 4.0 5.0 # c 6.0 7.0 8.0 # d NaN NaN NaN frame3 = frame2.reindex(columns=['Ohio', 'Uta', 'California']) # \u91cd\u5efa\u5217\u7d22\u5f15 print(frame3) # Ohio Uta California # a 0.0 NaN 2.0 # b 3.0 NaN 5.0 # c 6.0 NaN 8.0 # d NaN NaN NaN \u4f7f\u7528 loc \u8fdb\u884c\u66f4\u4e3a\u7b80\u6d01\u7684\u884c\u3001\u5217\u6807\u7b7e\u7d22\u5f15\u3002\u4e0b\u4f8b\u901a\u8fc7\u7b5b\u9009\u884c\u7d22\u5f15\u548c\u5217\u7d22\u5f15\u4ea7\u751f\u65b0\u7684Dataframe\u3002 frame4 = frame.loc[['a', 'b'], states] print(frame4) # Ohio Texas California # a 0 1 2 # b 3 4 5","title":"\u91cd\u5efa\u7d22\u5f15"},{"location":"python/DataAnalysis/ch02/#_3","text":"set_index() , dropna() , fillna() , reset_index() , drop() , replace() \u8fd9\u4e9b\u65b9\u6cd5\u7684 inplace \u5c5e\u6027\u8bbe\u4e3a True \u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f1a\u4fee\u6539Series\u6216DataFrame\u7684\u5c3a\u5bf8\u6216\u5f62\u72b6\uff0c \u76f4\u63a5 \u64cd\u4f5c\u539f\u5bf9\u8c61\u800c\u4e0d\u8fd4\u56de\u65b0\u5bf9\u8c61\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj) # a 0 # b 1 # c 2 # d 3 # e 4 # dtype: int64 obj1 = obj.drop('c') print(obj1) # a 0 # b 1 # d 3 # e 4 # dtype: int64 print(obj1.drop(['d', 'e'])) # a 0 # b 1 # dtype: int64 \u5bf9\u6bd4 inplace=True \u548c False \u7684\u533a\u522b\u3002 inplace=False \u65f6\uff0c obj \u7684\u503c\u6ca1\u6709\u53d8\u5316\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj.drop('c', inplace=False)) # \u8bf4\u660e\u751f\u6210\u4e86\u65b0\u5bf9\u8c61 # a 0 # b 1 # d 3 # e 4 # dtype: int64 print(obj) # a 0 # b 1 # c 2 # d 3 # e 4 # dtype: int64 obj.drop('c', inplace=True) \u8f93\u51fa\u662f None \uff0c\u8bf4\u660e\u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61\uff0c\u53d8\u5316\u76f4\u63a5\u4f5c\u7528\u5230 obj \u4e0a\u3002 obj = pd.Series(np.arange(5), index=['a', 'b', 'c', 'd', 'e']) print(obj) print(obj.drop('c', inplace=True)) # \u8bf4\u660e\u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61 # None print(obj) # a 0 # b 1 # d 3 # e 4 # dtype: int64 \u4e0b\u4f8b\u6f14\u793a\u4e86\u8f74\u5411\u7684\u6548\u679c\u3002 \u5982\u679c\u4e0d\u6307\u5b9a\u8f74\u5411axis\uff0c drop() \u4f1a\u9ed8\u8ba4\u6cbf axis=0 \u8fdb\u884c\uff0c\u6240\u4ee5\uff0c\u57280\u8f74\u4e0a\u6267\u884c data.drop(['one', 'two']) \u4f1a\u62a5\u9519\u3002 axis='columns \u4e0e\u6307\u5b9a axis=1 \u540c\u6837\u6548\u679c\u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'] ) print(data) # one two three four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 # \u6cbf0\u8f74\u64cd\u4f5c\uff0c\u5220\u9664\u7b26\u5408\u6761\u4ef6\u7684\u884c\u8bb0\u5f55 print(data.drop(['Ohio', 'Colorado'])) # one two three four # Utah 8 9 10 11 # New York 12 13 14 15 print(data.drop(['one', 'two'])) # KeyError: \"['one' 'two'] not found in axis\" # \u6cbf1\u8f74\u64cd\u4f5c\uff0c\u5220\u9664\u7b26\u5408\u6761\u4ef6\u7684\u5217\u8bb0\u5f55 print(data.drop(['one', 'two'], axis=1)) # three four # Ohio 2 3 # Colorado 6 7 # Utah 10 11 # New York 14 15 print(data.drop(['one', 'two'], axis='columns')) # three four # Ohio 2 3 # Colorado 6 7 # Utah 10 11 # New York 14 15 \u518d\u901a\u8fc7\u4e0b\u4f8b\u4f53\u4f1a\u4e00\u4e0b inplace \u53c2\u6570\u7684\u4e0d\u540c\u6548\u679c\u3002 data = pd.DataFrame( { 'Name': ['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], 'class': [11, 12, 10, 9], 'Age': [18, 20, 21, 17] } ) print(data) # Name class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data.rename(columns={'Name': 'FirstName'}, inplace=False)) # FirstName class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data) # Name class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17 print(data.rename(columns={'Name': 'FirstName'}, inplace=True)) # \u6ca1\u6709\u751f\u6210\u65b0\u5bf9\u8c61 # None print(data) # FirstName class Age # 0 Shobhit 11 18 # 1 vaibhav 12 20 # 2 vimal 10 21 # 3 Sourabh 9 17","title":"\u8f74\u5411\u7d22\u5f15\u5220\u9664\u6761\u76ee"},{"location":"python/DataAnalysis/ch02/#_4","text":"Series\u7684\u7d22\u5f15 obj[...] \u4e0eNumPy\u6570\u7ec4\u7d22\u5f15\u7684\u529f\u80fd\u7c7b\u4f3c\uff0c\u53ea\u4e0d\u8fc7Series\u7684\u7d22\u5f15\u503c\u53ef\u4ee5\u4e0d\u4ec5\u4ec5\u662f\u6574\u6570\u3002 \u4e0b\u4f8b\u4e2d\uff1a obj[1] \u901a\u8fc7\u7d22\u5f15\u4f4d 1 \u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c\u3002 obj[1] \u901a\u8fc7\u7d22\u5f15\u4f4d [1] \u68c0\u7d22\uff0c\u8f93\u51faSeries\u3002 obj['b'] \u901a\u8fc7\u7d22\u5f15\u503c 'b' \u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c\u3002 obj[['b']] \u901a\u8fc7\u7d22\u5f15\u503c ['b'] \u68c0\u7d22\uff0c\u8f93\u51faSeries\u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) print(obj) # a Shobhit # b vaibhav # c vimal # d Sourabh # dtype: object print(obj[1]) # \u901a\u8fc7\u7d22\u5f15\u4f4d\u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c # vaibhav print(obj[[1]]) # b vaibhav # dtype: object print(obj['b']) # \u901a\u8fc7\u7d22\u5f15\u503c\u68c0\u7d22\uff0c\u8f93\u51fa\u5bf9\u5e94Series\u7684\u503c # vaibhav print(obj[['b']]) # \u901a\u8fc7\u7d22\u5f15\u503c\u68c0\u7d22\uff0c\u8f93\u51faSeries # b vaibhav # dtype: object \u4e0b\u9762\u4e00\u7ec4\u7684\u8f93\u51fa\u4e2d\uff0c\u6ce8\u610f\u5bf9\u6bd4\u666e\u901aPython\u5207\u7247\u4e0eSeries\u7684\u5207\u7247\u7684\u5dee\u5f02\u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) print(obj[1]) # vaibhav print(obj[[1]]) # b vaibhav # dtype: object print(obj[1:3]) # b vaibhav # c vimal # dtype: object print(obj['b':'d']) # b vaibhav # c vimal # d Sourabh # dtype: object Series\u7684\u5207\u7247\u7684\u503c\u66f4\u65b0\u3002 obj['b': 'c'] = 5 \u662f\u901a\u8fc7\u7d22\u5f15\u503c\u8fdb\u884c\u66f4\u65b0\uff0c\u76f4\u63a5\u4f5c\u7528\u5728 obj \u3002 obj[1: 3] = 6 \u662f\u901a\u8fc7\u7d22\u5f15\u4f4d\u7f6e\u6765\u66f4\u65b0 obj \u3002 obj = pd.Series(['Shobhit', 'vaibhav', 'vimal', 'Sourabh'], index=['a', 'b', 'c', 'd']) obj['b': 'c'] = 5 print(obj) # a Shobhit # b 5 # c 5 # d Sourabh # dtype: object obj[1: 3] = 6 print(obj) # a Shobhit # b 6 # c 6 # d Sourabh # dtype: object DataFrame\u7684\u7d22\u5f15\u4e0e\u5207\u7247\u3002 data[['Three', 'Two']] \u9009\u53d6\u6307\u5b9a\u5217\uff0c\u6ce8\u610f\u8f93\u5165\u5217\u6761\u4ef6\u662f\u5217\u8868 ['Three', 'Two'] \u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['One', 'Two', 'Three', 'Four'] ) print(data) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 print(data['Two']) # Ohio 1 # Colorado 5 # Utah 9 # New York 13 # Name: Two, dtype: int64 print(data[['Three', 'Two']]) # Three Two # Ohio 2 1 # Colorado 6 5 # Utah 10 9 # New York 14 13 print(data[:2]) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 \u5d4c\u5957\uff1a\u6839\u636e\u4e00\u4e2a\u5e03\u5c14\u503c\u6570\u7ec4\u5207\u7247\u6216\u9009\u62e9\u6570\u636e\u3002 data['Three'] > 5 \u662f\u4e00\u4e2a\u5e03\u5c14\u503c\u5e8f\u5217\u3002 data[data['Three'] > 5] \u8f93\u51fa\u6761\u4ef6\u4e3aTrue\u7684\u7ed3\u679c\u96c6\u3002 print(data['Three'] > 5) # Ohio False # Colorado True # Utah True # New York True # Name: Three, dtype: bool print(data[data['Three'] > 5]) # One Two Three Four # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4f7f\u7528\u5e03\u5c14\u503cDataFrame\u8fdb\u884c\u7d22\u5f15\uff0c\u5df2\u7ecf\u66f4\u65b0\u3002 \u5728\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u8fd9\u79cd\u7d22\u5f15\u65b9\u5f0f\u4f7f\u5f97DataFrame\u5728\u8bed\u6cd5\u4e0a\u66f4\u50cf\u662fNumPy\u4e8c\u7ef4\u6570\u7ec4\u3002 print(data < 5) # One Two Three Four # Ohio True True True True # Colorado True False False False # Utah False False False False # New York False False False False data[data < 5] = 0 print(data) # One Two Three Four # Ohio 0 0 0 0 # Colorado 0 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4f7f\u7528loc\u548ciloc\u9009\u62e9\u6570\u636e\u3002 \u4f7f\u7528\u6807\u7b7e\u540d loc \u6216\u6807\u7b7e\u4f4d\u7f6e iloc \u4ee5NumPy\u98ce\u683c\u7684\u8bed\u6cd5\u4eceDataFrame\u4e2d\u9009\u51faDataframe\u7684\u884c\u548c\u5217\u7684\u5b50\u96c6\u3002 data = pd.DataFrame( np.arange(16).reshape(4, 4), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['One', 'Two', 'Three', 'Four'] ) print(data) # One Two Three Four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # Utah 8 9 10 11 # New York 12 13 14 15 \u4e0b\u4f8b\u901a\u8fc7loc\u5bf9\u6807\u7b7e\u540d\u7b5b\u9009\u884c\u6216\u5217\u6570\u636e\u3002\u4f8b\u5982\uff0c\u8f93\u51fa Colorado \u884c\u6807\u7b7e\u7684 Two \u548c Three \u8fd9\u4e24\u5217\u7684\u503c\uff0c\u4ee5\u884c\u8bb0\u5f55\u7684\u65b9\u5f0f\u5c55\u73b0\u3002 print(data.loc['Colorado', ['Two', 'Three']]) # \u5207\u7247: # Two 5 # Three 6 # Name: Colorado, dtype: int64 print(data.loc[:'Ohio', :'Two']) # \u5207\u7247: 0\u884c\uff0c0,1\u5217 # One Two # Ohio 0 1 \u4e0b\u4f8b\u901a\u8fc7\u6807\u7b7e\u4f4d\u7f6e iloc \u8fdb\u884c\u7c7b\u4f3c\u7684\u6570\u636e\u9009\u62e9\u3002 data.iloc[:3, :2][data > 4] \u6309\u6307\u5b9a\u6761\u4ef6\u8fdb\u884c\u884c\u3001\u5217\u7b5b\u9009\uff0c\u7b26\u5408\u6761\u4ef6 [data > 4] \u7684\u8f93\u51faDataframe\u503c\uff0c\u4e0d\u7b26\u5408\u6761\u4ef6\u7684\u8f93\u51faNaN\u3002 print(data.iloc[[0]]) # 0\u884c # One Two Three Four # Ohio 0 1 2 3 print(data.iloc[[0], [1]]) # \u5207\u7247: 0\u884c\uff0c1\u5217 # Two # Ohio 1 print(data.iloc[1:2, 1:2]) # \u5207\u7247: 1\u884c\uff0c2\u5217 # Two # Ohio 1 print(data.iloc[2, [3, 0, 1]]) # \u5207\u7247: 2\u884c\uff0c\u4f9d\u6b21\u53d63\uff0c0\uff0c1\u5217 # Four 11 # One 8 # Two 9 # Name: Utah, dtype: int64 print(data.iloc[:3, :2][data > 4]) # One Two # Ohio NaN NaN # Colorado NaN 5.0 # Utah 8.0 9.0","title":"\u7d22\u5f15\u3001\u9009\u62e9\u4e0e\u8fc7\u6ee4"},{"location":"python/DataAnalysis/ch02/#_5","text":"Pandas\u7684Series\u7684\u7d22\u5f15\u503c\u662f\u6574\u6570\u7d22\u5f15\u3002 data = np.arange(3.) ser = pd.Series(data) print(ser) # 0 0.0 # 1 1.0 # 2 2.0 # dtype: float64 print(ser[:1]) # 0 0.0 # dtype: float64 print(ser.loc[:1]) # loc\u7528\u4e8e\u6807\u7b7e\u540d # 0 0.0 # 1 1.0 # dtype: float64 print(ser.iloc[:1]) # iloc\u7528\u4e8e\u6807\u7b7e\u4f4d\u7f6e # 0 0.0 # dtype: float64 data = ['1', 'b', 'e', 3] ser = pd.Series(data) print(ser) # 0 1 # 1 b # 2 e # 3 3 # dtype: object print(ser[:1]) # 0 1 # dtype: object print(ser.loc[:1]) # 0 1 # 1 b # dtype: object print(ser.iloc[:1]) # 0 1 # dtype: object \u5bf9DataFrame\u7684\u66f4\u65b0\u3002 df1 = pd.DataFrame(np.arange(4).reshape((2, 2)), columns=list('ab')) print(df1) # a b # 0 0 1 # 1 2 3 # \u6309\u6807\u7b7e\u540d\u66f4\u65b0 df1.loc[1, :'b'] = np.nan print(df1) # a b # 0 0.0 1.0 # 1 NaN NaN","title":"\u6574\u6570\u7d22\u5f15"},{"location":"python/DataAnalysis/ch02/#_6","text":"Pandas\u652f\u6301\u5728Series\u6216\u8005DataFrame\u5bf9\u8c61\u4e4b\u95f4\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97\u3002 \u4f8b\uff1a\u4e24\u4e2aSeries\u505a\u7b97\u672f\u52a0\u6cd5\u3002 \u8fd4\u56de\u7684\u7ed3\u679c\u4e5f\u662f\u4e00\u4e2aSeries\u3002 \u8fd4\u56de\u7ed3\u679c\u7684\u7d22\u5f15\u662f\u6bcf\u4e2aSeries\u7684\u7d22\u5f15\u7684\u5e76\u96c6\u3002 \u51e1\u662f\u6ca1\u6709\u5728\u4e24\u4e2aSeries\u90fd\u51fa\u73b0\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0c\u5185\u90e8\u6570\u636e\u5bf9\u9f50\u4f1a\u586b\u5145\u7f3a\u5931\u503cNaN\u3002\u7f3a\u5931\u503c\u4f1a\u5728\u540e\u7eed\u7684\u5176\u5b83\u7b97\u672f\u64cd\u4f5c\u4e0a\u4ea7\u751f\u5f71\u54cd\u3002 \u540c\u65f6\u51fa\u73b0\u5728\u4e24\u4e2aSeries\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0cSeries\u7684\u503c\u505a\u7b97\u672f\u76f8\u52a0\u3002 s1 = pd.Series( [7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'] ) s2 = pd.Series( [-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'] ) print(s1) # a 7.3 # c -2.5 # d 3.4 # e 1.5 # dtype: float64 print(s2) # a -2.1 # c 3.6 # e -1.5 # f 4.0 # g 3.1 # dtype: float64 print(s1 + s2) # a 5.2 # c 1.1 # d NaN # e 0.0 # f NaN # g NaN # dtype: float64 \u4f8b\uff1a\u4e24\u4e2aDataframe\u505a\u7b97\u672f\u52a0\u6cd5 \u8fd4\u56de\u7ed3\u679c\u4e5f\u662f\u4e00\u4e2aDataframe\u3002 \u8fd4\u56de\u7ed3\u679c\u7684\u884c\u5217\u7d22\u5f15\u662f\u6bcf\u4e2aDataFrame\u7684\u884c\u5217\u7d22\u5f15\u7684\u5e76\u96c6\u3002 \u51e1\u662f\u6ca1\u6709\u5728\u4e24\u4e2aDataFrame\u90fd\u51fa\u73b0\u7684\u4f4d\u7f6e\u5c31\u4f1a\u88ab\u7f6e\u4e3aNaN\u3002 \u4e24\u4e2aDataFrame\u90fd\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5bf9Dataframe\u7684\u503c\u505a\u7b97\u672f\u52a0\u6cd5\u3002 df1 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'] ) df2 = pd.DataFrame( np.arange(12).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(df1) # b c d # Ohio 0 1 2 # Texas 3 4 5 # Colorado 6 7 8 print(df2) # b d e # Utah 0 1 2 # Ohio 3 4 5 # Texas 6 7 8 # Oregon 9 10 11 print(df1 + df2) # b c d e # Colorado NaN NaN NaN NaN # Ohio 3.0 NaN 6.0 NaN # Oregon NaN NaN NaN NaN # Texas 9.0 NaN 12.0 NaN # Utah NaN NaN NaN NaN \u5728Series\u6216\u8005DataFrame\u5bf9\u8c61\u4e4b\u95f4\u8fdb\u884c\u7b97\u672f\u64cd\u4f5c\u65f6\uff0c\u6709\u65f6\u9700\u8981\u5bf9\u7f3a\u5931\u503c\u6307\u5b9a\u586b\u5145\u503c\uff0c\u6bd4\u5982\u5f53\u8f74\u6807\u7b7e\u5728\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u5b58\u5728\uff0c\u5728\u53e6\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u4e0d\u5b58\u5728\u65f6\uff0c\u5c06\u7f3a\u5931\u503c\u586b\u5145\u4e3a0\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5982\u679c\u5728\u4e24\u4e2aDataFrame\u90fd\u7f3a\u5931\uff0c\u90a3\u4e48\u4f9d\u7136\u8fd8\u4f1a\u662fNaN\u3002 \u4e0b\u4f8b\u4e2da2\u662f\u5728 df1 \u548c df2 \u90fd\u7f3a\u5931\u7684\u4f4d\u7f6e\uff0c\u6240\u4ee5\u5373\u4f7f fill_value=0 \uff0ca2\u4ecd\u7136\u662fNaN\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('bcd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # b c d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 # \u5bf9df1\u548cdf2\u5c31\u7b97\u672f\u548c\uff0c\u5bf9\u5e94\u6ca1\u6709\u884c\u5217\u5171\u540c\u7684\u4ea4\u96c6\u7684\u5730\u65b9\u586b\u5145\u7a7a\u503cNaN\uff0c\u6709\u4ea4\u96c6\u7684\u5730\u65b9\u6c42\u7b97\u672f\u548c\u3002 print(df1.add(df2)) # a b c d # 0 NaN 1.0 NaN NaN # 1 NaN 6.0 NaN NaN # 2 NaN NaN NaN NaN # \u5bf9df1\u548cdf2\u5c31\u7b97\u672f\u548c\uff0c\u5bf9\u5e94\u6ca1\u6709\u884c\u5217\u5171\u540c\u7684\u4ea4\u96c6\u7684\u5730\u65b9\u586b\u5145\u7a7a\u503c0\uff0c\u6709\u4ea4\u96c6\u7684\u5730\u65b9\u6c42\u7b97\u672f\u548c\u3002 print(df1.add(df2, fill_value=0)) # df2.add(df1, fill_value=0) \u8fd4\u56de\u540c\u6837\u7684\u7ed3\u679c # a b c d # 0 0.0 1.0 1.0 2.0 # 1 2.0 6.0 4.0 5.0 # 2 NaN 6.0 7.0 8.0 \u4e0b\u4f8b\u4e2db2\u662f\u5728 df1 \u548c df2 \u90fd\u7f3a\u5931\u7684\u4f4d\u7f6e\uff0c\u6240\u4ee5\u5373\u4f7f fill_value=0 \uff0cb2\u4ecd\u7136\u662fNaN\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('acd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a c d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.add(df2, fill_value=0)) # a b c d # 0 0.0 1.0 1.0 2.0 # 1 5.0 3.0 4.0 5.0 # 2 6.0 NaN 7.0 8.0 \u4e0b\u4f8b\u4e2d\u6ca1\u6709\u4e24\u4e2aDataFrame\u5171\u540c\u7f3a\u5931\u7684\u60c5\u51b5\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('abd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a b d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.add(df2, fill_value=0)) # a b d # 0 0.0 2.0 2.0 # 1 5.0 7.0 5.0 # 2 6.0 7.0 8.0 \u4e0b\u9762\u662fSeries\u548cDataFrame\u7684\u7b97\u672f\u65b9\u6cd5\u3002 add\uff0cradd\uff1a\u52a0\u6cd5(+) sub\uff0crsub\uff1a\u51cf\u6cd5(-) div\uff0crdiv\uff1a\u9664\u6cd5(/) floordiv\uff0crfloordiv\uff1a\u6574\u9664(//) mul\uff0crmul\uff1a\u4e58\u6cd5(*) pow\uff0crpow\uff1a\u5e42\u6b21\u65b9(**) \u4e0a\u8ff0\u6bcf\u4e2a\u65b9\u6cd5\u90fd\u6709\u4e00\u4e2a\u4ee5r\u5f00\u5934\u7684\u526f\u672c\uff0c\u8fd9\u4e9b\u526f\u672c\u65b9\u6cd5\u7684\u53c2\u6570\u662f\u7ffb\u8f6c\u7684\u3002\u6bd4\u5982\uff0c\u6c42DataFrame\u5f53\u4e2d\u6240\u6709\u5143\u7d20\u7684\u5012\u6570 1/df \uff0c\u53ef\u4ee5\u5199\u6210df.rdiv(1)\u3002 df1 = pd.DataFrame( np.arange(4).reshape((2, 2)), columns=list('ab') ) df2 = pd.DataFrame( np.arange(9).reshape((3, 3)), columns=list('abd') ) print(df1) # a b # 0 0 1 # 1 2 3 print(df2) # a b d # 0 0 1 2 # 1 3 4 5 # 2 6 7 8 print(df1.radd(df2, fill_value=0)) # a b d # 0 0.0 2.0 2.0 # 1 5.0 7.0 5.0 # 2 6.0 7.0 8.0 print(df1.sub(df2, fill_value=0)) # a b d # 0 0.0 0.0 -2.0 # 1 -1.0 -1.0 -5.0 # 2 -6.0 -7.0 -8.0 print(df1.div(df2, fill_value=0)) # a b d # 0 NaN 1.00 0.0 # 1 0.666667 0.75 0.0 # 2 0.000000 0.00 0.0 print(df1.floordiv(df2, fill_value=0)) # a b d # 0 NaN 1.0 0.0 # 1 0.0 0.0 0.0 # 2 0.0 0.0 0.0 print(df1.mul(df2, fill_value=0)) # a b d # 0 0.0 1.0 0.0 # 1 6.0 12.0 0.0 # 2 0.0 0.0 0.0 print(df1.pow(df2, fill_value=0)) # a b d # 0 1.0 1.0 0.0 # 1 8.0 81.0 0.0 # 2 0.0 0.0 0.0","title":"\u7b97\u672f\u548c\u6570\u636e\u5bf9\u9f50"},{"location":"python/DataAnalysis/ch02/#dataframeseries","text":"DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c\u4e0eNumPy\u4e2d\u4e0d\u540c\u7ef4\u5ea6\u6570\u7ec4\u95f4\u7684\u64cd\u4f5c\u7c7b\u4f3c\u3002","title":"DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch02/#numpy","text":"\u4ecearr\u4e2d\u51cf\u53bbarr[0]\u65f6\uff0c\u51cf\u6cd5\u6cbf0\u8f74\u5728\u6bcf\u4e00\u884c\u90fd\u8fdb\u884c\u4e86\u64cd\u4f5c\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\u5e7f\u64ad\u673a\u5236\u3002 arr = np.arange(12).reshape((3, 4)) print(arr) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] print(arr[0]) # [0 1 2 3] print(arr - arr[0]) # [[0 0 0 0] # [4 4 4 4] # [8 8 8 8]]","title":"\u4e0d\u540c\u7ef4\u5ea6NumPy\u6570\u7ec4\u95f4\u7684\u7b97\u672f\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch02/#dataframeseries_1","text":"\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cDataFrame\u548cSeries\u7684\u6570\u5b66\u64cd\u4f5c\u4e2d\u4f1a\u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684 \u5217 \u8fdb\u884c\u5339\u914d\uff0c\u5e76 \u5e7f\u64ad\u5230\u5404\u884c . \u5982\u679c\u4e00\u4e2a\u7d22\u5f15\u503c\u4e0d\u5728DataFrame\u7684\u5217\u4e2d\uff0c\u4e5f\u4e0d\u5728Series\u7684\u7d22\u5f15\u4e2d\uff0c\u5219\u65b0\u5bf9\u8c61\u4f1a\u6784\u5efa\u5e76\u96c6\u7d22\u5f15\u3002 frame = pd.DataFrame( np.arange(12).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(frame) # b d e # Utah 0 1 2 # Ohio 3 4 5 # Texas 6 7 8 # Oregon 9 10 11 # \u622a\u53d6frame\u7684\u7b2c0\u884c\uff0c\u5217\u6807\u7b7e\u53d8\u6210\u65b0Serise\u7684\u7d22\u5f15\u3002 series = frame.iloc[0] print(series) # b 0 # d 1 # e 2 # Name: Utah, dtype: int64 series2 = pd.Series( range(3), index=list('bef') ) print(series2) # b 0 # e 1 # f 2 # dtype: int64 # \u622a\u53d6frame\u7684d\u5217\uff0c\u884c\u6807\u7b7e\u53d8\u6210\u65b0Serise\u7684\u7d22\u5f15\u3002 series3 = frame['d'] print(series3) # Utah 1 # Ohio 4 # Texas 7 # Oregon 10 # Name: d, dtype: int64 # \u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684\u5217\u6807\u7b7e\u8fdb\u884c\u5339\u914d\uff0cSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\u3002 print(frame - series) # frame: series Result: # b d e # b 0 # b d e # Utah 0 1 2 # d 1 # Utah 0 0 0 # Ohio 3 4 5 # e 2 # Ohio 3 3 3 # Texas 6 7 8 # Name: Utah, dtype: int64 # Texas 6 6 6 # Oregon 9 10 11 # Oregon 9 9 9 # \u5c06Series\u7684\u7d22\u5f15\u548cDataFrame\u7684\u5217\u6807\u7b7e\u8fdb\u884c\u5339\u914d\uff0cSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\uff0c\u7f3a\u5931\u4f4d\u7f6e\u586b\u5145\u7a7a\u503cNaN\u3002 print(frame - series2) # frame: series2 Result: # b d e # b 0 # b d e f # Utah 0 1 2 # e 1 # Utah 0.0 NaN 1.0 NaN # Ohio 3 4 5 # f 2 # Ohio 3.0 NaN 4.0 NaN # Texas 6 7 8 # dtype: int64 # Texas 6.0 NaN 7.0 NaN # Oregon 9 10 11 # Oregon 9.0 NaN 10.0 NaN # \u6539\u4e3a\u5728\u5217\u4e0a\u8fdb\u884c\u5e7f\u64ad\uff0c\u5728\u884c\u4e0a\u5339\u914d\uff0c\u5fc5\u987b\u4f5c\u7528\u5728\u67d0\u79cd\u7b97\u672f\u65b9\u6cd5\u4e0a\u3002\u4e0b\u4f8b\u4e2dSeries\u7684\u503c\u6cbfDataFrame\u76840\u8f74\u5e7f\u64ad\u5230\u5404\u4e2a\u884c\uff08\u6309index\u5339\u914d\u8fdb\u884c\u884c\u64cd\u4f5c\uff09\u3002 print(frame.sub(series3, axis='index')) # \u6216axis=0 # frame: series3 Result: # b d e # Utah 1 # b d e # Utah 0 1 2 # Ohio 4 # Utah -1 0 1 # Ohio 3 4 5 # Texas 7 # Ohio -1 0 1 # Texas 6 7 8 # Oregon 10 # Texas -1 0 1 # Oregon 9 10 11 # Name: d, dtype: int64 # Oregon -1 0 1","title":"DataFrame\u548cSeries\u95f4\u7684\u7b97\u672f\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch02/#_7","text":"NumPy\u7684\u901a\u7528\u51fd\u6570\uff08\u9010\u5143\u7d20\u6570\u7ec4\u65b9\u6cd5\uff09\u5bf9pandas\u5bf9\u8c61\uff08DataFrame\u548cSeries\uff09\u4e5f\u6709\u6548\u3002 frame = pd.DataFrame( np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'] ) print(frame) # b d e # Utah 2.737734 -0.379977 0.758933 # Ohio 0.847497 0.839583 -2.192021 # Texas -0.907544 -0.457436 -1.907396 # Oregon 0.389362 0.250170 1.065889 # \u5bf9DataFrame\u5bf9\u8c61\u8ba1\u7b97\u7edd\u5bf9\u503c\u3002 print(np.abs(frame)) # b d e # Utah 2.737734 0.379977 0.758933 # Ohio 0.847497 0.839583 2.192021 # Texas 0.907544 0.457436 1.907396 # Oregon 0.389362 0.250170 1.065889 # f\u8fd4\u56de\u4e00\u4e2a\u6807\u91cf\u503c f = lambda x: x.max() - x.min() # \u6cbf0\u8f74\u5e94\u7528f\uff08\u5bf9\u6bcf\u5217\u7684\u6240\u6709\u884c\u5143\u7d20\u8fdb\u884cf\u8ba1\u7b97\uff09, \u9ed8\u8ba4axis=0 print(frame.apply(f)) # b 3.645278 # d 1.297019 # e 3.257911 # dtype: float64 # \u6cbf1\u8f74\u5e94\u7528f\uff08\u5bf9\u6bcf\u884c\u7684\u6240\u6709\u5217\u5143\u7d20\u8fdb\u884cf\u8ba1\u7b97\uff09 print(frame.apply(f, axis=1)) # Utah 3.117711 # Ohio 3.039518 # Texas 1.449961 # Oregon 0.815720 # dtype: float64 # \u5b9a\u4e49\u51fd\u6570f\uff0c\u8fd4\u56de\u5e26\u6709\u591a\u4e2a\u503c\u7684Series\u3002 def f(x): return pd.Series( [x.min(), x.max()], index=['min', 'max'] ) print(frame.apply(f)) # b d e # min -0.907544 -0.457436 -2.192021 # max 2.737734 0.839583 1.065889 # \u5b9a\u4e49\u51fd\u6570f\uff0c\u4f7f\u7528applymap\u65b9\u6cd5\u683c\u5f0f\u5316\u5b57\u7b26\uff0c\u5c06\u4e00\u4e2a\u9010\u5143\u7d20\u7684\u51fd\u6570\u5e94\u7528\u5230Series\u4e0a\u3002 f = lambda x: '%.2f' % x print(frame.applymap(f)) # # b d e # Utah 2.74 -0.38 0.76 # Ohio 0.85 0.84 -2.19 # Texas -0.91 -0.46 -1.91 # Oregon 0.39 0.25 1.07 print(frame['e'].map(f)) # Utah 0.76 # Ohio -2.19 # Texas -1.91 # Oregon 1.07 # Name: e, dtype: object","title":"\u51fd\u6570\u5e94\u7528\u548c\u6620\u5c04"},{"location":"python/DataAnalysis/ch02/#_8","text":"\u4f7f\u7528sort_index\u65b9\u6cd5\uff0c\u6309\u884c\u6216\u5217\u7d22\u5f15\u8fdb\u884c\u5b57\u5178\u578b\u6392\u5e8f\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u6392\u5e8f\u597d\u7684Pandas\u5bf9\u8c61\u3002","title":"\u6392\u5e8f\u548c\u6392\u540d"},{"location":"python/DataAnalysis/ch02/#series_1","text":"\u5bf9Series\u8fdb\u884c\u7d22\u5f15\u6392\u5e8f\u548c\u503c\u6392\u5e8f\u3002 obj = pd.Series( range(4), index=list('dabc') ) print(obj) # d 0 # a 1 # b 2 # c 3 # dtype: int64 print(obj.sort_index()) # a 1 # b 2 # c 3 # d 0 # dtype: int64 # print(obj.sort_values()) # d 0 # a 1 # b 2 # c 3 # dtype: int64 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u7684\u7f3a\u5931\u503c\u90fd\u4f1a\u88ab\u6392\u5e8f\u81f3Series\u7684\u5c3e\u90e8\u3002 obj = pd.Series([4, np.nan, 7, np.nan, -3, 2]) print(obj) # 0 4.0 # 1 NaN # 2 7.0 # 3 NaN # 4 -3.0 # 5 2.0 # dtype: float64 print(obj.sort_values()) # 4 -3.0 # 5 2.0 # 0 4.0 # 2 7.0 # 1 NaN # 3 NaN # dtype: float64","title":"Series\u6392\u5e8f"},{"location":"python/DataAnalysis/ch02/#dataframe_3","text":"frame = pd.DataFrame( [[0, 1, 10, 3], [4, 5, 6, 21], [8, 9, 2, 21]], index=['three', 'one', 'five'], columns=list('dabc') ) print(frame) # d a b c # three 0 1 10 3 # one 4 5 6 21 # five 8 9 2 21 print(frame.index) # Index(['three', 'one', 'five'], dtype='object') # \u9ed8\u8ba40\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index()) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3 # \u6307\u5b9a0\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index(axis=0)) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3 # \u6307\u5b9a0\u8f74\uff0c\u6240\u6709\u884c\u8fdb\u884c\u7d22\u5f15\u9996\u5b57\u6bcd\u964d\u5e8f print(frame.sort_index(axis=0, ascending=False)) # d a b c # three 0 1 10 3 # one 4 5 6 21 # five 8 9 2 21 # \u6307\u5b9a1\u8f74\uff0c\u6240\u6709\u5217\u8fdb\u5217\u7d22\u5f15\u9996\u5b57\u6bcd\u5347\u5e8f print(frame.sort_index(axis=1)) # a b c d # three 1 10 3 0 # one 5 6 21 4 # five 9 2 21 8 # \u6307\u5b9a1\u8f74\uff0c\u6240\u6709\u5217\u8fdb\u5217\u7d22\u5f15\u9996\u5b57\u6bcd\u964d\u5e8f print(frame.sort_index(axis=1, ascending=False)) # d c b a # three 0 3 10 1 # one 4 21 6 5 # five 8 21 2 9 # \u6309\u6307\u5b9a\u5355\u5217\u8fdb\u884c\u503c\u6392\u5e8f\uff08\u964d\u5e8f\uff09 print(frame.sort_values(by=['c'], ascending=False)) # d a b c # one 4 5 6 21 # five 8 9 2 21 # three 0 1 10 3 # \u6309\u6307\u5b9a\u591a\u5217\u8fdb\u884c\u503c\u6392\u5e8f\uff08\u964d\u5e8f\uff09\uff0c\u5148\u5bf9b\u964d\u5e8f\uff0c\u518d\u5bf9d\u964d\u5e8f print(frame.sort_values(by=['c', 'd'], ascending=False)) # d a b c # five 8 9 2 21 # one 4 5 6 21 # three 0 1 10 3","title":"DataFrame\u6392\u5e8f"},{"location":"python/DataAnalysis/ch02/#_9","text":"\u6392\u540d \u662f\u6307\u5bf9\u6570\u7ec4\u4ece1\u5230\u6709\u6548\u6570\u636e\u70b9\u603b\u6570\u5206\u914d\u540d\u6b21\u7684\u64cd\u4f5c\u3002 Series\u548cDataFrame\u7684 rank \u65b9\u6cd5\u662f\u5b9e\u73b0\u6392\u540d\u7684\u65b9\u6cd5\uff0c df.rank(ascending=False, method='max') \u3002 ascending \uff1a\u6392\u540d\u65b9\u5f0f\uff0c\u9ed8\u8ba4\u4ece\u4f4e\u5230\u9ad8\uff0c ascending=False \u8868\u793a\u4ece\u9ad8\u5230\u4f4e\uff1b method \uff1a\u6392\u540d\u65b9\u5f0f\uff0c\u5305\u62ec\uff1a average:\u9ed8\u8ba4\uff0c\u5728\u76f8\u7b49\u5206\u7ec4\u4e2d\uff0c\u4e3a\u5404\u4e2a\u503c\u5206\u914d\u5e73\u5747\u6392\u540d\uff0c\u5373\u76f8\u540c\u503c\u7684\u548c\u9664\u4ee5\u8be5\u503c\u7684\u4e2a\u6570\uff0c\u5373\u4e3a\u8be5\u503c\u7684\u540d\u6b21\u3002 min:\u4f7f\u7528\u6574\u4e2a\u5206\u7ec4\u7684\u6700\u5c0f\u6392\u540d\uff0c\u5373\uff0c\u5bf9\u5e94\u76f8\u540c\u503c\uff0c\u53d6\u5728\u987a\u5e8f\u6392\u540d\u4e2d\u6700\u5c0f\u7684\u90a3\u4e2a\u6392\u540d\u4f5c\u4e3a\u6240\u6709\u8be5\u503c\u7684\u6392\u540d\u3002 max:\u4f7f\u7528\u6574\u4e2a\u5206\u7ec4\u7684\u6700\u5927\u6392\u540d\uff0c\u5373\uff0c\u5bf9\u5e94\u76f8\u540c\u503c\uff0c\u53d6\u5728\u987a\u5e8f\u6392\u540d\u4e2d\u6700\u5927\u7684\u90a3\u4e2a\u6392\u540d\u4f5c\u4e3a\u6240\u6709\u8be5\u503c\u7684\u6392\u540d\u3002 first:\u6309\u503c\u518d\u539f\u59cb\u6570\u636e\u4e2d\u51fa\u73b0\u987a\u5e8f\u5206\u914d\u6392\u540d\uff0c\u8c01\u51fa\u73b0\u7684\u4f4d\u7f6e\u9760\u524d\uff0c\u8c01\u7684\u6392\u540d\u9760\u524d\u3002 dense:\u7c7b\u4f3cmin\u65b9\u6cd5\uff0c\u4f46\u6392\u540d\u603b\u662f\u5728\u7ec4\u95f4\u589e\u52a01\uff0c\u800c\u4e0d\u662f\u7ec4\u4e2d\u76f8\u540c\u7684\u5143\u7d20\u6570\uff0c\u5373\u76f8\u540c\u503c\u7684\u6392\u540d\u76f8\u540c\uff0c\u5176\u4ed6\u4f9d\u6b21\u52a01\u5373\u53ef\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0crank\u662f\u901a\u8fc7\u201c\u4e3a\u5404\u7ec4\u5206\u914d\u4e00\u4e2a\u5e73\u5747\u6392\u540d\u201d\u7684\u65b9\u5f0f\u7834\u574f\u5e73\u7ea7\u5173\u7cfb # \u6309\u7167\u6bcf\u4e2a\u5143\u7d20\u7684\u5927\u5c0f\u987a\u5e8f\u7ed9\u51fa\u4e00\u4e2a\u5e73\u5747\u6392\u540d obj = pd.Series([7, -5, 7, 4, 2, 0, 4]) print(obj) # 0 7 # 1 -5 # 2 7 # 3 4 # 4 2 # 5 0 # 6 4 # dtype: int64 print(obj.rank()) # 0 6.5 # 1 1.0 # 2 6.5 # 3 4.5 # 4 3.0 # 5 2.0 # 6 4.5 # dtype: float64 # index value rank # 2 -5 1 # 6 0 2 # 5 2 3 # 4 4 4.5 # 7 4 4.5 # 1 7 6.5 # 3 7 6.5 # \u6839\u636e\u5143\u7d20\u7684\u89c2\u5bdf\u987a\u5e8f\u8fdb\u884c\u5206\u914d\u3002\u5143\u7d200\u548c2\u6ca1\u6709\u4f7f\u7528\u5e73\u5747\u6392\u540d6.5\uff0c\u5b83\u4eec\u88ab\u8bbe\u6210\u4e866\u548c7\uff0c\u56e0\u4e3a\u6570\u636e\u4e2d\u6807\u7b7e0\u4f4d\u4e8e\u6807\u7b7e2\u7684\u524d\u9762\u3002 print(obj.rank(method='first')) # 0 6.0 # 1 1.0 # 2 7.0 # 3 4.0 # 4 3.0 # 5 2.0 # 6 5.0 # dtype: float64 # \u6309\u7167max\u8fdb\u884c\u5347\u5e8f\u548c\u964d\u5e8f print(obj.rank(ascending=False, method='max')) print(obj.rank(ascending=True, method='max')) # Original Series Max with inc Max with dec # 0 7 # 0 2.0 (\u6700\u5c0f) # 0 7.0 (\u6700\u5927) # 1 -5 # 1 7.0 (\u6700\u5927) # 1 1.0 (\u6700\u5c0f) # 2 7 # 2 2.0 (\u6700\u5c0f) # 2 7.0 (\u6700\u5927) # 3 4 # 3 4.0 # 3 5.0 # 4 2 # 4 5.0 # 4 3.0 # 5 0 # 5 6.0 # 5 2.0 # 6 4 # 6 4.0 # 6 5.0 # dtype: float64 # dtype: float64 # dtype: float64 frame = pd.DataFrame( {'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1], 'c': [-2, 5, 8, -2]} ) print(frame) # b a c # 0 4.3 0 -2 # 1 7.0 1 5 # 2 -3.0 0 8 # 3 2.0 1 -2 # \u6cbf1\u8f74\u5bf9DataFrame\u8fdb\u884crank\u64cd\u4f5c\uff0c\u5373\uff0c\u6bcf\u4e00\u884c\u5404\u5143\u7d20\u8fdb\u884crank\u3002 print(frame.rank(axis='columns')) # axis=1 # b a c # 0 3.0 2.0 1.0 # 1 3.0 1.0 2.0 # 2 1.0 2.0 3.0 # 3 3.0 2.0 1.0","title":"\u6392\u540d"},{"location":"python/DataAnalysis/ch02/#_10","text":"\u5c3d\u7ba1\u5f88\u591apandas\u51fd\u6570\uff08\u6bd4\u5982reindex\uff09\u9700\u8981\u6807\u7b7e\u662f\u552f\u4e00\u7684\uff0c\u4f46\u8fd9\u4e2a\u5e76\u4e0d\u662f\u5f3a\u5236\u6027\u7684\u3002 \u7d22\u5f15\u7684is_unique\u5c5e\u6027\u53ef\u4ee5\u68c0\u67e5\u6807\u7b7e\u662f\u5426\u552f\u4e00\u3002 \u5e26\u6709\u91cd\u590d\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u7d22\u5f15\u6807\u7b7e\u4f1a\u4ee5\u5e8f\u5217\u65b9\u5f0f\u8fd4\u56de\u591a\u4e2a\u6761\u76ee\u3002\u4e0d\u91cd\u590d\u7684\u7d22\u5f15\u5219\u4f1a\u4ee5\u6807\u91cf\u503c\u7684\u5f62\u5f0f\u8fd4\u56de\u5355\u4e2a\u6761\u76ee\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4f7f\u4ee3\u7801\u66f4\u590d\u6742\u3002 obj = pd.Series(range(5), index=['a', 'b', 'a', 'c', 'b']) print(obj) # a 0 # b 1 # a 2 # c 3 # b 4 # dtype: int64 print(obj.is_unique) # True print(obj.index.is_unique) # False # \u8fd4\u56de\u91cd\u590d\u7d22\u5f15\u5bf9\u5e94\u503c\u7684\u5e8f\u5217\u3002 print(obj['a']) # a 0 # a 2 # dtype: int64 df = pd.DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b', 'b']) print(df) # 0 1 2 # a -0.726164 0.531540 -0.521611 # a -1.539807 -0.710880 -0.992789 # b -0.975970 -0.470725 0.121958 # b -0.301495 1.072322 -1.542296 print(df.index.is_unique) # False print(df.loc['b']) # 0 1 2 # b -0.520008 0.052574 0.638529 # b -1.928705 -1.099534 -1.605296","title":"\u542b\u6709\u91cd\u590d\u6807\u7b7e\u7684\u8f74\u7d22\u5f15"},{"location":"python/DataAnalysis/ch02/#_11","text":"pandas\u5305\u542b\u4e86\u4e00\u4e9b\u5e38\u7528\u6570\u5b66\u3001\u7edf\u8ba1\u5b66\u65b9\u6cd5\u3002\u5176\u4e2d\u5927\u90e8\u5206\u5c5e\u4e8e\u5f52\u7ea6\u6216\u6c47\u603b\u7edf\u8ba1\u7684\u7c7b\u522b\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4eceDataFrame\u7684\u884c\u6216\u5217\u4e2d\u62bd\u53d6\u4e00\u4e2aSeries\u6216\u4e00\u7cfb\u5217\u503c\uff08\u5982\u603b\u548c\u6216\u5e73\u5747\u503c\uff09\u3002 \u4e0eNumPy\u6570\u7ec4\u4e2d\u7684\u7c7b\u4f3c\u65b9\u6cd5\u76f8\u6bd4\uff0cpandas\u5185\u5efa\u4e86\u5904\u7406\u7f3a\u5931\u503c\u7684\u529f\u80fd\u3002 \u5f52\u7ea6\u65b9\u6cd5: sum() \u79ef\u7d2f\u578b\u65b9\u6cd5: cumsun() \u65e2\u4e0d\u662f\u5f52\u7ea6\u578b\u65b9\u6cd5\u4e5f\u4e0d\u662f\u79ef\u7d2f\u578b\u65b9\u6cd5: describe() df = pd.DataFrame( [[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=list('abcd'), columns=['one', 'two'] ) print(df) # one two # a 1.40 NaN # b 7.10 -4.5 # c NaN NaN # d 0.75 -1.3 # axis=0, \u8fd4\u56de\u4e00\u4e2a\u6bcf\u5217\u7b97\u672f\u548c\u7684Series print(df.sum()) # one 9.25 # two -5.80 # dtype: float64 # axis=1\u4e14skipna=True, \u8fd4\u56de\u4e00\u4e2a\u6bcf\u884c\u548c\u7684Series, \u5ffd\u7565NA\u503c, \u586b0\u3002 print(df.sum(axis=1)) # a 1.40 # b 2.60 # c 0.00 # d -0.55 # dtype: float64 # \u4e0d\u5ffd\u7565NA\u503c\uff0c\u586bNaN\u3002 print(df.sum(axis=1, skipna=False)) # a NaN # b 2.60 # c NaN # d -0.55 # dtype: float64 # \u53ea\u67091\u7ea7\u7d22\u5f15\uff0c\u6240\u4ee5level=0\u548c\u539f\u7d22\u5f15\u6ca1\u6709\u533a\u522b\uff0cNaN\u586b\u51450\u3002 print(df.groupby(level=0).sum()) # one two # a 1.40 0.0 # b 7.10 -4.5 # c 0.00 0.0 # d 0.75 -1.3 # \u5217one\u7684\u6700\u5927\u503c\u662f\u5728\u7d22\u5f15b, \u5217two\u7684\u6700\u5927\u503c\u662f\u5728\u7d22\u5f15d print(df.idxmax()) # one b # two d # dtype: object print(df.idxmin()) # one d # two b # dtype: object # cumsun\u7684\u610f\u601d\u662f\u7b2cn\u6b21\u7684\u548c\u662fn-1\u6b21\u7684\u548c\u4e0en\u7684\u548c\uff0cone\u5217d\u884c\u7684\u548c\u5c31\u662fone\u5217a\u3001b\u3001c\u3001d\u503c\u7684\u603b\u548c\u3002 print(df.cumsum()) # one two # a 1.40 NaN # b 8.50 -4.5 # c NaN NaN # d 9.25 -5.8 \u901a\u8fc7describe\u4ea7\u751f\u7edf\u8ba1\u4fe1\u606f\uff0c\u6ce8\u610f\uff0c\u6570\u503c\u578b\u548c\u975e\u6570\u503c\u578b\u7684describe\u7684\u4fe1\u606f\u662f\u4e0d\u540c\u7684\u3002 # \u4e00\u6b21\u6027\u4ea7\u751f\u591a\u4e2a\u6c47\u603b\u7edf\u8ba1 print(df.describe()) # one two # count 3.000000 2.000000 # mean 3.083333 -2.900000 # std 3.493685 2.262742 # min 0.750000 -4.500000 # 25% 1.075000 -3.700000 # 50% 1.400000 -2.900000 # 75% 4.250000 -2.100000 # max 7.100000 -1.300000 obj = pd.Series(['a', 'a', 'b', 'c'] * 4) print(obj) # 0 a # 1 a # 2 b # 3 c # 4 a # 5 a # 6 b # 7 c # 8 a # 9 a # 10 b # 11 c # 12 a # 13 a # 14 b # 15 c # dtype: object # \u9488\u5bf9\u975e\u6570\u503c\u578b\u6570\u636e\uff0cdescribe\u4ea7\u751f\u53e6\u4e00\u79cd\u6c47\u603b\u7edf\u8ba1 print(obj.describe()) # count 16 # unique 3 # top a # freq 8 # dtype: object","title":"\u63cf\u8ff0\u6027\u7edf\u8ba1\u6982\u8ff0\u4e0e\u8ba1\u7b97"},{"location":"python/DataAnalysis/ch02/#_12","text":"\u534f\u65b9\u5dee\u4e0e\u76f8\u5173\u7cfb\u6570\u4e5f\u662f\u5728\u65f6\u57df\u5206\u6790\u65f6\u5e38\u89c1\u7684\u4e24\u4e2a\u6982\u5ff5\uff0c\u4ed6\u4eec\u90fd\u662f\u7528\u6765\u63cf\u8ff0\u6570\u636e\u201c\u50cf\u4e0d\u50cf\u201d\u7684\u3002 \u534f\u65b9\u5dee\u7684\u901a\u4fd7\u7406\u89e3\uff1a \u4e24\u4e2a\u53d8\u91cf\u5728\u53d8\u5316\u8fc7\u7a0b\u4e2d\u662f\u540c\u65b9\u5411\u53d8\u5316\u8fd8\u662f\u53cd\u65b9\u5411\u53d8\u5316\uff1f\u76f8\u540c\u6216\u8005\u76f8\u53cd\u7a0b\u5ea6\u5982\u4f55\uff1f \u4f60\u53d8\u5927\uff0c\u540c\u65f6\u6211\u53d8\u5927\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u662f\u540c\u5411\u53d8\u5316\uff0c\u8fd9\u65f6\u534f\u65b9\u5dee\u5c31\u662f\u6b63\u7684\u3002 \u4f60\u53d8\u5927\uff0c\u540c\u65f6\u6211\u53d8\u5c0f\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u662f\u53cd\u5411\u53d8\u5316\uff0c\u8fd9\u65f6\u534f\u65b9\u5dee\u5c31\u662f\u8d1f\u7684\u3002 \u4ece\u6570\u503c\u770b\uff0c\u534f\u65b9\u5dee\u7684\u6570\u503c\u8d8a\u5927\uff0c\u4e24\u4e2a\u53d8\u91cf\u540c\u5411\u7a0b\u5ea6\u4e5f\u5c31\u8d8a\u5927\u3002\u53cd\u4e4b\u4ea6\u7136\u3002 \u76f8\u5173\u7cfb\u6570\u7684\u901a\u4fd7\u7406\u89e3\uff1a \u7528X\uff0cY\u7684\u534f\u65b9\u5dee\u9664\u4ee5X\u7684\u6807\u51c6\u5dee\u548cY\u7684\u6807\u51c6\u5dee\u3002\u76f8\u5173\u7cfb\u6570\u4e5f\u53ef\u4ee5\u770b\u6210\u534f\u65b9\u5dee\uff0c\u4e00\u79cd\u63d0\u51fa\u4e86\u4e24\u4e2a\u53d8\u91cf\u91cf\u7eb2\u5f71\u54cd\u3001\u6807\u51c6\u5316\u540e\u7684\u7279\u6b8a\u534f\u65b9\u5dee\u3002\u6240\u4ee5\uff1a\u4e5f\u53ef\u4ee5\u53cd\u6620\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u662f\u540c\u5411\u8fd8\u662f\u53cd\u5411\uff0c\u5982\u679c\u540c\u5411\u53d8\u5316\u5c31\u4e3a\u6b63\uff0c\u53cd\u5411\u53d8\u5316\u5c31\u4e3a\u8d1f\u3002 \u7531\u4e8e\u662f\u6807\u51c6\u7248\u540e\u7684\u534f\u65b9\u5dee\uff0c\u76f8\u5173\u7cfb\u6570\u6d88\u9664\u4e86\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u5e45\u5ea6\u7684\u5f71\u54cd\uff0c\u800c\u53ea\u662f\u5355\u7eaf\u53cd\u5e94\u4e24\u4e2a\u53d8\u91cf\u6bcf\u5355\u4f4d\u53d8\u5316\u65f6\u7684\u76f8\u4f3c\u7a0b\u5ea6\u3002 \u603b\u7ed3\uff1a \u5bf9\u4e8e\u4e24\u4e2a\u53d8\u91cfX\u3001Y\uff0c \u5f53\u4ed6\u4eec\u7684\u76f8\u5173\u7cfb\u6570\u4e3a1\u65f6\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u7684\u6b63\u5411\u76f8\u4f3c\u5ea6\u6700\u5927\u3002 \u5f53\u4ed6\u4eec\u7684\u76f8\u5173\u7cfb\u6570\u4e3a\uff0d1\u65f6\uff0c\u8bf4\u660e\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u7684\u53cd\u5411\u76f8\u4f3c\u5ea6\u6700\u5927\u3002 \u968f\u7740\u4ed6\u4eec\u76f8\u5173\u7cfb\u6570\u51cf\u5c0f\uff0c\u4e24\u4e2a\u53d8\u91cf\u53d8\u5316\u65f6\u7684\u76f8\u4f3c\u5ea6\u4e5f\u53d8\u5c0f\uff0c\u5f53\u76f8\u5173\u7cfb\u6570\u4e3a0\u65f6\uff0c\u4e24\u4e2a\u53d8\u91cf\u7684\u53d8\u5316\u8fc7\u7a0b\u6ca1\u6709\u4efb\u4f55\u76f8\u4f3c\u5ea6\uff0c\u4e5f\u5373\u4e24\u4e2a\u53d8\u91cf\u65e0\u5173\u3002 \u5f53\u76f8\u5173\u7cfb\u6570\u7ee7\u7eed\u53d8\u5c0f\uff0c\u5c0f\u4e8e0\u65f6\uff0c\u4e24\u4e2a\u53d8\u91cf\u5f00\u59cb\u51fa\u73b0\u53cd\u5411\u7684\u76f8\u4f3c\u5ea6\uff0c\u968f\u7740\u76f8\u5173\u7cfb\u6570\u7ee7\u7eed\u53d8\u5c0f\uff0c\u53cd\u5411\u76f8\u4f3c\u5ea6\u4f1a\u9010\u6e10\u53d8\u5927\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u4f7f\u7528 pandas-datareader\uff1a https://pypi.org/project/pandas-datareader/ https://pydata.github.io/pandas-datareader/) \u5728\u6240\u6709\u4f8b\u5b50\u4e2d\uff0c\u5728\u8ba1\u7b97\u76f8\u5173\u6027\u4e4b\u524d\uff0c\u6570\u636e\u70b9\u5df2\u7ecf\u6309\u6807\u7b7e\u8fdb\u884c\u4e86\u5bf9\u9f50\u3002 \u4e0b\u4f8b\u9700\u8981\u901a\u8fc7pandas-datareader\u5e93\u4eceYahoo! Finance\u4e0a\u83b7\u53d6\u7684\u5305\u542b\u80a1\u4ef7\u548c\u4ea4\u6613\u91cf\u7684DataFrame\u3002 import pandas_datareader.data as web all_data = { ticker: web.get_data_yahoo(ticker) for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG'] } price = pd.DataFrame( { ticker: data['Adj Close'] for ticker, data in all_data.items() } ) volume = pd.DataFrame( { ticker: data['Volume'] for ticker, data in all_data.items() } ) returns = price.pct_change() print(returns.tail()) # AAPL IBM MSFT GOOG # Date # 2021-08-09 -0.000342 -0.008424 -0.003904 0.007049 # 2021-08-10 -0.003354 0.000920 -0.006555 0.000685 # 2021-08-11 0.001786 0.005305 0.001781 -0.002947 # 2021-08-12 0.020773 0.006614 0.009967 0.005084 # 2021-08-13 0.001410 0.000769 0.010490 0.000119 Series\u7684corr\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u91cd\u53e0\u7684\u3001\u975eNA\u7684\u3001\u6309\u7d22\u5f15\u5bf9\u9f50\u7684\u503c\u7684\u76f8\u5173\u6027\u3002\u76f8\u5e94\u5730\uff0ccov\u8ba1\u7b97\u7684\u662f\u534f\u65b9\u5dee print(returns['MSFT']) # Date # 2016-08-15 NaN # 2016-08-16 -0.005540 # 2016-08-17 0.002089 # 2016-08-18 0.000695 # 2016-08-19 0.000347 # ... # 2021-08-09 -0.003904 # 2021-08-10 -0.006555 # 2021-08-11 0.001781 # 2021-08-12 0.009967 # 2021-08-13 0.010490 # Name: MSFT, Length: 1259, dtype: float64 # Series\u7684corr\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u91cd\u53e0\u7684\u3001\u975eNA\u7684\u3001\u6309\u7d22\u5f15\u5bf9\u9f50\u7684\u503c\u7684\u76f8\u5173\u6027\u3002 print(returns['MSFT'].corr(returns['IBM'])) # 0.5175237180581937 # \u7b49\u540c\u5199\u6cd5\uff0cMSFT\u662f\u4e00\u4e2a\u6709\u6548\u7684Python\u5c5e\u6027 print(returns.MSFT.corr(returns.IBM)) # 0.5175237180581937 # Series\u7684cov\u65b9\u6cd5\u8ba1\u7b97\u7684\u662f\u4e24\u4e2aSeries\u4e2d\u503c\u7684\u534f\u65b9\u5dee\u3002 print(returns['MSFT'].cov(returns['IBM'])) # 0.0001452224236764915 DataFrame\u7684corr\u548ccov\u65b9\u6cd5\u4f1a\u5206\u522b\u4ee5DataFrame\u7684\u5f62\u5f0f\u8fd4\u56de\u76f8\u5173\u6027\u548c\u534f\u65b9\u5dee\u77e9\u9635\u3002 print(returns.corr()) # AAPL IBM MSFT GOOG # AAPL 1.000000 0.441111 0.735539 0.661961 # IBM 0.441111 1.000000 0.517524 0.484230 # MSFT 0.735539 0.517524 1.000000 0.775756 # GOOG 0.661961 0.484230 0.775756 1.000000 # \u7ed9corrwith\u65b9\u6cd5\uff0c\u4f20\u5165\u4e00\u4e2aSeries\u65f6\uff0c\u4f1a\u8fd4\u56de\u4e00\u4e2a\u542b\u6709\u4e3a\u6bcf\u5217\u8ba1\u7b97\u76f8\u5173\u6027\u503c\u7684Series print(returns.corrwith(returns['IBM'])) # AAPL 0.441111 # IBM 1.000000 # MSFT 0.517524 # GOOG 0.484230 # dtype: float64 # \u7ed9corrwith\u65b9\u6cd5\uff0c\u4f20\u5165\u4e00\u4e2aDataFrame\u65f6\uff0c\u4f1a\u8ba1\u7b97\u5339\u914d\u5230\u5217\u540d\u7684\u76f8\u5173\u6027\u6570\u503c\u3002\u4e0b\u9762\u662f\u8ba1\u7b97\u4ea4\u6613\u91cf\u767e\u5206\u6bd4\u53d8\u5316\u7684\u76f8\u5173\u6027 print(returns.corrwith(volume)) # AAPL -0.063111 # IBM -0.103721 # MSFT -0.056842 # GOOG -0.119026 # dtype: float64 print(returns.cov()) # AAPL IBM MSFT GOOG # AAPL 0.000361 0.000137 0.000240 0.000211 # IBM 0.000137 0.000268 0.000145 0.000133 # MSFT 0.000240 0.000145 0.000294 0.000224 # GOOG 0.000211 0.000133 0.000224 0.000282","title":"\u76f8\u5173\u6027\u548c\u534f\u65b9\u5dee"},{"location":"python/DataAnalysis/ch02/#_13","text":"obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c']) print(obj) # 0 c # 1 a # 2 d # 3 a # 4 a # 5 a # 6 b # 7 b # 8 c # 9 c # dtype: object \u51fd\u6570 unique \u7ed9\u51faSeries\u4e2d\u7684\u552f\u4e00\u503c\u3002 print(obj.unique()) # ['c' 'a' 'd' 'b'] print(obj.sort_values().unique()) # ['a' 'b' 'c' 'd'] # value_counts\u8ba1\u7b97Series\u5305\u542b\u7684\u503c\u7684\u4e2a\u6570 print(obj.value_counts()) # a 4 # c 3 # b 2 # d 1 # dtype: int64 # \u8fd9\u91ccvalue_counts\u4e0d\u662fSeries\u7684\u65b9\u6cd5\uff0c\u662fpandas\u9876\u5c42\u65b9\u6cd5 print(pd.value_counts(obj.values, sort=True)) # a 4 # c 3 # b 2 # d 1 # dtype: int64 print(obj.isin(['b', 'c'])) # 0 True # 1 False # 2 False # 3 False # 4 False # 5 False # 6 True # 7 True # 8 True # 9 True # dtype: bool # \u5c06\u4e0a\u9762\u7684\u7ed3\u679c\u4f5c\u4e3a\u5217\u8868\u8f93\u5165\u7684\u6761\u4ef6\uff0c\u8f93\u51fa\u4e3aTrue\u7684\u7ed3\u679c print(obj[obj.isin(['b', 'c'])]) # 0 c # 6 b # 7 b # 8 c # 9 c # dtype: object \u53c2\u8003: pandas.Index.get_indexer obj1 = pd.Series(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c']) obj2 = pd.Series(['c', 'a', 'b']) print(pd.Index(obj1)) # Index(['c', 'a', 'd', 'a', 'a', 'a', 'b', 'b', 'c', 'c'], dtype='object') print(pd.Index(obj2)) # Index(['c', 'a', 'b'], dtype='object') # \u8fd9\u91cc0\u5bf9\u5e94obj2\u91cc\u9762\u7684c\u5728job1\u7684\u4f4d\u7f6e\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u751f\u6210\u65b0\u7684\u7d22\u5f15\u5217\u8868 print(pd.Index(obj2).get_indexer(obj1)) # [ 0 1 -1 1 1 1 2 2 0 0] \u8ba1\u7b97DataFrame\u591a\u4e2a\u76f8\u5173\u5217\u7684\u76f4\u65b9\u56fe\u3002 data = pd.DataFrame( { 'Que1': [1, 3, 4, 3, 4], 'Que2': [2, 3, 1, 2, 3], 'Que3': [1, 5, 2, 4, 4], } ) print(data) # Que1 Que2 Que3 # 0 1 2 1 # 1 3 3 5 # 2 4 1 2 # 3 3 2 4 # 4 4 3 4 result = data.apply(pd.value_counts).fillna(0) # \u4e0b\u9762\u7ed3\u679c\u4e2d\u7684\u884c\u6807\u7b7e\u662f\u6240\u6709\u5217\u4e2d\u51fa\u73b0\u7684\u4e0d\u540c\u503c\uff0c\u6570\u503c\u5219\u662f\u8fd9\u4e9b\u4e0d\u540c\u503c\u5728\u6bcf\u4e2a\u5217\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u4f8b\u5982\uff1a\u6570\u5b575\u53ea\u5728Que3\u91cc\u9762\u51fa\u73b0\u4e86\u4e00\u6b21 print(result) # Que1 Que2 Que3 # 1 1.0 1.0 1.0 # 2 0.0 2.0 1.0 # 3 2.0 2.0 0.0 # 4 2.0 0.0 2.0 # 5 0.0 0.0 1.0","title":"\u552f\u4e00\u503c\u3001\u8ba1\u6570\u548c\u6210\u5458\u5c5e\u6027"},{"location":"python/DataAnalysis/ch03/","text":"\u6570\u636e\u8f7d\u5165\u3001\u5b58\u50a8\u53ca\u6587\u4ef6\u683c\u5f0f \u6587\u672c\u683c\u5f0f\u6570\u636e\u7684\u8bfb\u5199 import numpy as np import pandas as pd import sys import csv import json \u5c06\u8868\u683c\u578b\u6570\u636e\u8bfb\u53d6\u4e3aDataFrame\u5bf9\u8c61\u662fpandas\u7684\u91cd\u8981\u7279\u6027\u3002\\ \u4e0b\u9762\u662f\u90e8\u5206\u5b9e\u73b0\u6587\u4ef6\u8bfb\u53d6\u529f\u80fd\u7684\u51fd\u6570\uff0cread_csv\u548cread_table\u53ef\u80fd\u662f\u540e\u671f\u6211\u4eec\u4f7f\u7528\u6700\u591a\u7684\u51fd\u6570\u3002\\ \\ \u8fd9\u4e9b\u51fd\u6570\u7684\u53ef\u9009\u53c2\u6570\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u7c7b\u578b\uff1a * \u7d22\u5f15\uff1a\u53ef\u4ee5\u5c06\u4e00\u5217\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u8fd4\u56de\u7684DataFrame\uff0c\u4ece\u6587\u4ef6\u6216\u7528\u6237\u5904\u83b7\u5f97\u5217\u540d\uff0c\u6216\u8005\u6ca1\u6709\u5217\u540d\u3002 * \u7c7b\u578b\u63a8\u65ad\u548c\u6570\u636e\u8f6c\u6362\uff1a\u5305\u62ec\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u503c\u8f6c\u6362\u548c\u81ea\u5b9a\u4e49\u7684\u7f3a\u5931\u503c\u7b26\u53f7\u5217\u8868\u3002 * \u65e5\u671f\u65f6\u95f4\u89e3\u6790\uff1a\u5305\u62ec\u7ec4\u5408\u529f\u80fd\uff0c\u4e5f\u5305\u62ec\u5c06\u5206\u6563\u5728\u591a\u4e2a\u5217\u4e0a\u7684\u65e5\u671f\u548c\u65f6\u95f4\u4fe1\u606f\u7ec4\u5408\u6210\u7ed3\u679c\u4e2d\u7684\u5355\u4e2a\u5217\u3002 * \u8fed\u4ee3\uff1a\u652f\u6301\u5bf9\u5927\u578b\u6587\u4ef6\u7684\u5206\u5757\u8fed\u4ee3\u3002 * \u672a\u6e05\u6d17\u6570\u636e\u95ee\u9898\uff1a\u8df3\u8fc7\u884c\u3001\u9875\u811a\u3001\u6ce8\u91ca\u4ee5\u53ca\u5176\u4ed6\u6b21\u8981\u6570\u636e\uff0c\u6bd4\u5982\u4f7f\u7528\u9017\u53f7\u5206\u9694\u5343\u4f4d\u7684\u6570\u5b57\u3002 file01 = '../examples/ex1.csv' # \u4f7f\u7528read_csv\u5c06\u6587\u4ef6\u8bfb\u5165\u4e00\u4e2aDataFrame df = pd.read_csv(file01) print(df) # 1 2 3 4 hello # 0 5 6 7 8 world # 1 9 10 11 12 foo df = pd.read_csv(file01, header=None) # \u4f7f\u7528pandas\u81ea\u52a8\u5206\u914d\u9ed8\u8ba4\u5217\u540d print(df) # 0 1 2 3 4 # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo df = pd.read_csv(file01, names=['aa', 'bb', 'cc', 'dd', 'message']) # \u81ea\u5df1\u6307\u5b9a\u5217\u540d print(df) # aa bb cc dd ee # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo # \u4f7f\u7528read_table\uff0c\u5e76\u6307\u5b9a\u5206\u9694\u7b26\uff0c\u5c06\u6587\u4ef6\u8bfb\u5165\u4e00\u4e2aDataFrame df = pd.read_table(file01, sep=',') print(df) # a b c d message # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo \u4ece\u591a\u4e2a\u5217\u4e2d\u5f62\u6210\u4e00\u4e2a\u5206\u5c42\u7d22\u5f15 parased = pd.read_csv('../examples/csv_mindex.csv', index_col=['key1', 'key2']) print(parased) # value1 value2 # key1 key2 # one a 1 2 # b 3 4 # c 5 6 # d 7 8 # two a 9 10 # b 11 12 # c 13 14 # d 15 16 \u4e0b\u4f8b\u4e2d\uff0c\u7531\u4e8e\u5217\u540d\u7684\u6570\u91cf\u6bd4\u6570\u636e\u7684\u5217\u6570\u5c11\u4e00\u4e2a\uff0c\u56e0\u6b64read_table\u63a8\u65ad\u7b2c\u4e00\u5217\u5e94\u5f53\u4f5c\u4e3aDataFrame\u7684\u7d22\u5f15\u3002\\ ex3.txt\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 A B C aaa -0.264438 -1.026059 -0.619500 bbb 0.927272 0.302904 -0.032399 ccc -0.264273 -0.386314 -0.217601 ddd -0.871858 -0.348382 1.100491 result = pd.read_table('../examples/ex3.txt') # \u76f4\u63a5\u8bfb\u53d6 print(result) # A B C # aaa -0.264438 -1.026059 -0.619500 # bbb 0.927272 0.302904 -0.032399 NaN # ccc -0.264273 -0.386314 -0.217601 # ddd -0.871858 -0.348382 1.100491 result = pd.read_table('../examples/ex3.txt', sep='\\s+') # \u5411read_table\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a\\s+\u6765\u683c\u5f0f\u5316\u6587\u4ef6 print(result) # A B C # aaa -0.264438 -1.026059 -0.619500 # bbb 0.927272 0.302904 -0.032399 # ccc -0.264273 -0.386314 -0.217601 # ddd -0.871858 -0.348382 1.100491 \u4e0b\u4f8b\u4e2dex4.csv\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 # hey! a,b,c,d,message # just wanted to make things more difficult for you # who reads CSV files with computers, anyway? 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo result = pd.read_csv('../examples/ex4.csv', skiprows=[0, 2, 3]) # \u4f7f\u7528skiprows\u6765\u8df3\u8fc7\u7b2c\u4e00\u884c\u3001\u7b2c\u4e09\u884c\u548c\u7b2c\u56db\u884c print(result) # a b c d message # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo \u7f3a\u5931\u503c\u5904\u7406 \\ \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cpandas\u4f7f\u7528\u4e00\u4e9b\u5e38\u89c1\u7684\u6807\u8bc6\uff0c\u4f8b\u5982NA\u548cNULL \\ \u4e0b\u4f8b\u4e2dex5.csv\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 something,a,b,c,d,message one,1,2,3,4,NA two,5,6,,8,world three,9,10,11,12,foo result = pd.read_csv('../examples/ex5.csv') print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo print(pd.isnull(result)) # something a b c d message # 0 False False False False False True # 1 False False False True False False # 2 False False False False False False result = pd.read_csv('../examples/ex5.csv', na_values=['NULL']) print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo \u5b9a\u4e49\u66ff\u6362\u89c4\u5219 sentinels = { 'message': ['foo', 'NA'], 'something': ['two'] } result = pd.read_csv('../examples/ex5.csv', na_values=sentinels) \u628amessage\u5217\u6240\u6709\u503c\u4e3afoo\u6216NA\u7684\u66ff\u6362\u4e3aNull \\ \u628asomething\u5217\u6240\u6709\u503c\u4e3atwo\u7684\u66ff\u6362\u4e3aNull print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 NaN 5 6 NaN 8 world # 2 three 9 10 11.0 12 NaN \u5206\u5757\u8bfb\u5165\u6587\u672c\u6587\u4ef6 pd.options.display.max_rows = 10 result = pd.read_csv('../examples/ex6.csv') # \u8bfb\u53d6\u5168\u90e8\u8bb0\u5f55 print(result) result = pd.read_csv('../examples/ex6.csv', nrows=5) # \u8bfb\u53d6\u524d5\u884c\u8bb0\u5f55 print(result) # [10000 rows x 5 columns] # one two three four key # 0 0.467976 -0.038649 -0.295344 -1.824726 L # 1 -0.358893 1.404453 0.704965 -0.200638 B # 2 -0.501840 0.659254 -0.421691 -0.057688 G # 3 0.204886 1.074134 1.388361 -0.982404 R # 4 0.354628 -0.133116 0.283763 -0.837063 Q result = pd.read_csv('../examples/ex6.csv', chunksize=1000) # \u5206\u5757\u8bfb\u5165\u6587\u4ef6\uff0c\u6bcf\u57571000\u884c print(result) # \u8fd4\u56de\u7684\u662f\u4e00\u4e2aTextParser\u5bf9\u8c61, \u5141\u8bb8\u4f60\u6839\u636echunksize\u904d\u5386\u6587\u4ef6\u3002 # <pandas.io.parsers.readers.TextFileReader object at 0x7f2b3cd01730> \u53ef\u4ee5\u904d\u5386ex6.csv\uff0c\u5e76\u5bf9\u2019key\u2019\u5217\u805a\u5408\u83b7\u5f97\u8ba1\u6570\u503c tot = pd.Series([], dtype=float) # \u8fd9\u91cc\u9700\u8981\u663e\u5f0f\u6307\u5b9adtype\uff0c\u540e\u7eedPython\u4f1a\u5c06\u9ed8\u8ba4\u503c\u4ecefloat64\u53d8\u6210object\uff0c\u76ee\u524d\u9ed8\u8ba4\u662ffloat64 for piece in result: tot = tot.add(piece['key'].value_counts(), fill_value=0) tot = tot.sort_values(ascending=False) print(tot[:10]) # E 368.0 # X 364.0 # L 346.0 # O 343.0 # Q 340.0 # M 338.0 # J 337.0 # F 335.0 # K 334.0 # H 330.0 # dtype: float64 \u5c06\u6570\u636e\u5199\u5165\u6587\u672c\u683c\u5f0f data = pd.read_csv('../examples/ex5.csv') print(data) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo \u4f7f\u7528DataFrame\u7684to_csv\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u5bfc\u51fa\u4e3a\u9017\u53f7\u5206\u9694\u7684\u6587\u4ef6 data.to_csv('../examples/out.csv') # \u8f93\u51faout.csv\u7684\u5185\u5bb9 # ,something,a,b,c,d,message # 0,one,1,2,3.0,4, # 1,two,5,6,,8,world # 2,three,9,10,11.0,12,foo \u4f7f\u7528DataFrame\u7684to_csv\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u5bfc\u51fa\u4e3a\u5176\u4ed6\u7684\u5206\u9694\u7b26\u7684\u6587\u4ef6 data.to_csv(sys.stdout, sep='|') # |something|a|b|c|d|message # 0|one|1|2|3.0|4| # 1|two|5|6||8|world # 2|three|9|10|11.0|12|foo data.to_csv(sys.stdout, sep=',') # ,something,a,b,c,d,message # 0,one,1,2,3.0,4, # 1,two,5,6,,8,world # 2,three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL') # \u8bbe\u5b9a\u7f3a\u5931\u503c\u5728\u8f93\u51fa\u65f6\u4ee5\u7a7a\u5b57\u7b26\u4e32\u51fa\u73b0 # ,something,a,b,c,d,message # 0,one,1,2,3.0,4,NULL # 1,two,5,6,NULL,8,world # 2,three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL', index=False, header=False) # \u4e0d\u8f93\u51fa\u884c\u548c\u5217\u7684\u6807\u7b7e\uff08index\uff0cheader\uff09 # one,1,2,3.0,4,NULL # two,5,6,NULL,8,world # three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL', index=False, header=False, columns=['a', 'b', 'c']) # \u6309\u7167\u81ea\u5b9a\u7684\u987a\u5e8f\u8f93\u51fa\u5b50\u96c6 # 1,2,3.0 # 5,6,NULL # 9,10,11.0 Series\u4e5f\u6709to_csv\u65b9\u6cd5 dates = pd.date_range('1/1/2000', periods=7) ts = pd.Series(np.arange(7), index=dates) ts.to_csv('../examples/tseries.csv', header=False) # \u8f93\u51fatseries.csv\u6587\u4ef6\u5185\u5bb9 # 2000-01-01,0 # 2000-01-02,1 # 2000-01-03,2 # 2000-01-04,3 # 2000-01-05,4 # 2000-01-06,5 # 2000-01-07,6 \u4f7f\u7528\u5206\u9694\u683c\u5f0f \u7edd\u5927\u591a\u6570\u7684\u8868\u578b\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u51fd\u6570pandas.read_table\u4ece\u786c\u76d8\u4e2d\u8bfb\u53d6\u3002 \\ \u7136\u800c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u63a5\u6536\u4e00\u4e2a\u5e26\u6709\u4e00\u884c\u6216\u591a\u884c\u9519\u8bef\u7684\u6587\u4ef6\u5e76\u4e0d\u5c11\u89c1\uff0cread_table\u4e5f\u65e0\u6cd5\u89e3\u51b3\u8fd9\u79cd\u60c5\u51b5\u3002 ex7.csv \u6587\u4ef6\u5185\u5bb9 \"a\",\"b\",\"c\" \"1\",\"2\",\"3\" \"1\",\"2\",\"3\" f = open('../examples/ex7.csv') # \u4f7f\u7528Python\u7684\u5185\u5efacsv\u6a21\u5757 reader = csv.reader(f) # \u5c06\u4efb\u4e00\u6253\u5f00\u7684\u6587\u4ef6\u6216\u6587\u4ef6\u578b\u5bf9\u8c61\u4f20\u7ed9csv.reader for line in reader: # # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a', 'b', 'c'] # ['1', '2', '3'] # ['1', '2', '3'] with open('../examples/ex7.csv') as f: lines = list(csv.reader(f)) # \u9996\u5148\uff0c\u5c06\u6587\u4ef6\u8bfb\u53d6\u4e3a\u884c\u7684\u5217\u8868 header, values = lines[0], lines[1:] # \u5176\u6b21\uff0c\u5c06\u6570\u636e\u62c6\u5206\u4e3a\u5217\u540d\u884c\u548c\u6570\u636e\u884c data_dict = { h: v for h, v in zip(header, zip(*values)) # \u518d\u7136\u540e\uff0c\u4f7f\u7528\u5b57\u5178\u63a8\u5bfc\u5f0f\u548c\u8868\u8fbe\u5f0fzip(*values)\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6570\u636e\u5217\u7684\u5b57\u5178\uff0c\u5b57\u5178\u4e2d\u884c\u8f6c\u7f6e\u6210\u5217 } print(data_dict) # \u8f93\u51fa\u7ed3\u679c # {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')} \u5982\u679c\u9700\u6839\u636e\u4e0d\u540c\u7684\u5206\u9694\u7b26\u3001\u5b57\u7b26\u4e32\u5f15\u7528\u7ea6\u5b9a\u6216\u884c\u7ec8\u6b62\u7b26\u5b9a\u4e49\u4e00\u79cd\u65b0\u7684\u683c\u5f0f\u65f6\uff0c\u53ef\u4ee5: \\ \u65b9\u6cd51\uff1a\u4f7f\u7528csv.Dialect\u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684\u5b50\u7c7b class my_dialect(csv.Dialect): lineterminator = '\\n' delimiter = ';' # \u8fd9\u91cc\u53ea\u80fd\u662f\u4e00\u4e2a\u5b57\u7b26 quotechar = '\"' quoting = csv.QUOTE_MINIMAL f = open('../examples/ex7.csv') reader = csv.reader(f, dialect=my_dialect) for line in reader: # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a,\"b\",\"c\"'] # ['1,\"2\",\"3\"'] # ['1,\"2\",\"3\"'] \u65b9\u6cd52\uff1a\u76f4\u63a5\u5c06CSV\u65b9\u8a00\u53c2\u6570(dialect)\u4f20\u5165csv.reader\u7684\u5173\u952e\u5b57\u53c2\u6570 \\ \u6bd4\u8f83\u8be6\u7ec6\u7684\u4ecb\u7ecd\u65b9\u8a00\u548c\u5206\u9694\u7b26\uff1ahttps://blog.csdn.net/tcy23456/article/details/85291994 f = open('../examples/ex7.csv') reader = csv.reader(f, delimiter='|') for line in reader: # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a,\"b\",\"c\"'] # ['1,\"2\",\"3\"'] # ['1,\"2\",\"3\"'] \u5bf9\u4e8e\u5177\u6709\u66f4\u590d\u6742\u6216\u56fa\u5b9a\u7684\u591a\u5b57\u7b26\u5206\u9694\u7b26\u7684\u6587\u4ef6\uff0c\u5c06\u65e0\u6cd5\u4f7f\u7528csv\u6a21\u5757\u3002 \\ \u5728\u6b64\u7c7b\u60c5\u51b5\u4e0b\uff0c\u5c06\u4f7f\u7528\u5b57\u7b26\u4e32\u7684split\u65b9\u6cd5\u6216\u6b63\u5219\u8868\u8fbe\u5f0f\u65b9\u6cd5re.split\u8fdb\u884c\u884c\u62c6\u5206\u548c\u5176\u4ed6\u6e05\u7406\u5de5\u4f5c\u3002 \\ \u9700\u8981\u624b\u52a8\u5199\u5165\u88ab\u5206\u9694\u7684\u6587\u4ef6\u65f6\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528csv.writer\u3002 \\ \u8fd9\u4e2a\u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u5df2\u7ecf\u6253\u5f00\u7684\u53ef\u5199\u5165\u6587\u4ef6\u5bf9\u8c61\u4ee5\u53ca\u548ccsv.reader\u76f8\u540c\u7684CSV\u65b9\u8a00\u3001\u683c\u5f0f\u9009\u9879 with open('../examples/mydata.csv', 'w') as f: writer = csv.writer(f, dialect=my_dialect) writer.writerow(('1', '2', '3')) writer.writerow(('4', '5', '6')) writer.writerow(('7', '8', '9')) writer.writerow(('10', '11', '12')) # mydata.csv \u6587\u4ef6\u5185\u5bb9 # 1;2;3 # 4;5;6 # 7;8;9 # 10;11;12 JSON\u6570\u636e obj = \"\"\" { \"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [ { \"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"] }, { \"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"] } ] } \"\"\" \u5c06JSON\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3aPython\u5f62\u5f0f\u65f6\uff0c\u4f7f\u7528json.loads\u65b9\u6cd5 result = json.loads(obj) print(result) # {'name': 'Wes', 'places_lived': ['United States', 'Spain', 'Germany'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zeus', 'Zuko']}, {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]} \u53e6\u4e00\u65b9\u9762\uff0cjson.dumps\u53ef\u4ee5\u5c06Python\u5bf9\u8c61\u8f6c\u6362\u56deJSON asjson = json.dumps(result) print(asjson) # {\"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]}, {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]} \u5c06JSON\u5bf9\u8c61\u6216\u5bf9\u8c61\u5217\u8868\u8f6c\u6362\u4e3aDataFrame\u6216\u5176\u4ed6\u6570\u636e\u7ed3\u6784 \\ \u6bd4\u8f83\u65b9\u4fbf\u7684\u65b9\u5f0f\u662f\u5c06\u5b57\u5178\u6784\u6210\u7684\u5217\u8868\uff08\u4e4b\u524d\u662fJSON\u5bf9\u8c61\uff09\u4f20\u5165DataFrame\u6784\u9020\u51fd\u6570\uff0c\u5e76\u9009\u51fa\u6570\u636e\u5b57\u6bb5\u7684\u5b50\u96c6 siblings = pd.DataFrame(result['siblings'], columns=['name', 'age']) print(siblings) # name age # 0 Scott 30 # 1 Katie 38 pandas.read_json\u53ef\u4ee5\u81ea\u52a8\u5c06JSON\u6570\u636e\u96c6\u6309\u7167\u6307\u5b9a\u6b21\u5e8f\u8f6c\u6362\u4e3aSeries\u6216DataFrame \\ pandas.read_json\u7684\u9ed8\u8ba4\u9009\u9879\u662f\u5047\u8bbeJSON\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u662f\u8868\u91cc\u7684\u4e00\u884c \\ \u8bfb\u53d6\u3001\u64cd\u4f5cJSON\u6570\u636e\uff08\u5305\u62ec\u5d4c\u5957\u8bb0\u5f55\uff09\u7684\u62d3\u5c55\u793a\u4f8b\uff0c\u8bf7\u53c2\u770b\u7b2c7\u7ae0\u7684USDA\u98df\u54c1\u6570\u636e\u5e93\u793a\u4f8b \\ \u4f8b\u5982\u8bfb\u53d6 data = pd.read_json('../examples/example_new.json') data = pd.read_json('../examples/example.json') print(data) # a b c # 0 1 2 3 # 1 4 5 6 # 2 7 8 9 print(data.to_json()) # {\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}} print(data.to_json(orient='records')) # [{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}] XML\u548cHTML\uff1a\u7f51\u7edc\u6293\u53d6 pandas\u7684\u5185\u5efa\u51fd\u6570read_html\u53ef\u4ee5\u4f7f\u7528lxml\u548cBeautiful Soup\u7b49\u5e93\u5c06HTML\u4e2d\u7684\u8868\u81ea\u52a8\u89e3\u6790\u4e3aDataFrame\u5bf9\u8c61 tables = pd.read_html('../examples/fdic_failed_bank_list.html') print(len(tables)) # 1 failures = tables[0] # //*[@id=\"table\"] print(failures.head()) # \u8bfb\u53d6\u524d5\u884c\u8bb0\u5f55 # Bank Name ... Updated Date # 0 Allied Bank ... November 17, 2016 # 1 The Woodbury Banking Company ... November 17, 2016 # 2 First CornerStone Bank ... September 6, 2016 # 3 Trust Company Bank ... September 6, 2016 # 4 North Milwaukee State Bank ... June 16, 2016 # # [5 rows x 7 columns] close_timestamps = pd.to_datetime(failures['Closing Date']) # \u8ba1\u7b97\u6bcf\u5e74\u94f6\u884c\u5012\u95ed\u7684\u6570\u91cf print(close_timestamps.dt.year.value_counts()) # 2010 157 # 2009 140 # 2011 92 # 2012 51 # 2008 25 # ... # 2004 4 # 2001 4 # 2007 3 # 2003 3 # 2000 2 # Name: Closing Date, Length: 15, dtype: int64 \u4e8c\u8fdb\u5236\u683c\u5f0f \u4e0eWeb API\u4ea4\u4e92 \u4e0e\u6570\u636e\u5e93\u4ea4\u4e92","title":"\u6570\u636e\u8f7d\u5165\u3001\u5b58\u50a8\u53ca\u6587\u4ef6\u683c\u5f0f"},{"location":"python/DataAnalysis/ch03/#_1","text":"","title":"\u6570\u636e\u8f7d\u5165\u3001\u5b58\u50a8\u53ca\u6587\u4ef6\u683c\u5f0f"},{"location":"python/DataAnalysis/ch03/#_2","text":"import numpy as np import pandas as pd import sys import csv import json \u5c06\u8868\u683c\u578b\u6570\u636e\u8bfb\u53d6\u4e3aDataFrame\u5bf9\u8c61\u662fpandas\u7684\u91cd\u8981\u7279\u6027\u3002\\ \u4e0b\u9762\u662f\u90e8\u5206\u5b9e\u73b0\u6587\u4ef6\u8bfb\u53d6\u529f\u80fd\u7684\u51fd\u6570\uff0cread_csv\u548cread_table\u53ef\u80fd\u662f\u540e\u671f\u6211\u4eec\u4f7f\u7528\u6700\u591a\u7684\u51fd\u6570\u3002\\ \\ \u8fd9\u4e9b\u51fd\u6570\u7684\u53ef\u9009\u53c2\u6570\u4e3b\u8981\u6709\u4ee5\u4e0b\u51e0\u79cd\u7c7b\u578b\uff1a * \u7d22\u5f15\uff1a\u53ef\u4ee5\u5c06\u4e00\u5217\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u8fd4\u56de\u7684DataFrame\uff0c\u4ece\u6587\u4ef6\u6216\u7528\u6237\u5904\u83b7\u5f97\u5217\u540d\uff0c\u6216\u8005\u6ca1\u6709\u5217\u540d\u3002 * \u7c7b\u578b\u63a8\u65ad\u548c\u6570\u636e\u8f6c\u6362\uff1a\u5305\u62ec\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u503c\u8f6c\u6362\u548c\u81ea\u5b9a\u4e49\u7684\u7f3a\u5931\u503c\u7b26\u53f7\u5217\u8868\u3002 * \u65e5\u671f\u65f6\u95f4\u89e3\u6790\uff1a\u5305\u62ec\u7ec4\u5408\u529f\u80fd\uff0c\u4e5f\u5305\u62ec\u5c06\u5206\u6563\u5728\u591a\u4e2a\u5217\u4e0a\u7684\u65e5\u671f\u548c\u65f6\u95f4\u4fe1\u606f\u7ec4\u5408\u6210\u7ed3\u679c\u4e2d\u7684\u5355\u4e2a\u5217\u3002 * \u8fed\u4ee3\uff1a\u652f\u6301\u5bf9\u5927\u578b\u6587\u4ef6\u7684\u5206\u5757\u8fed\u4ee3\u3002 * \u672a\u6e05\u6d17\u6570\u636e\u95ee\u9898\uff1a\u8df3\u8fc7\u884c\u3001\u9875\u811a\u3001\u6ce8\u91ca\u4ee5\u53ca\u5176\u4ed6\u6b21\u8981\u6570\u636e\uff0c\u6bd4\u5982\u4f7f\u7528\u9017\u53f7\u5206\u9694\u5343\u4f4d\u7684\u6570\u5b57\u3002 file01 = '../examples/ex1.csv' # \u4f7f\u7528read_csv\u5c06\u6587\u4ef6\u8bfb\u5165\u4e00\u4e2aDataFrame df = pd.read_csv(file01) print(df) # 1 2 3 4 hello # 0 5 6 7 8 world # 1 9 10 11 12 foo df = pd.read_csv(file01, header=None) # \u4f7f\u7528pandas\u81ea\u52a8\u5206\u914d\u9ed8\u8ba4\u5217\u540d print(df) # 0 1 2 3 4 # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo df = pd.read_csv(file01, names=['aa', 'bb', 'cc', 'dd', 'message']) # \u81ea\u5df1\u6307\u5b9a\u5217\u540d print(df) # aa bb cc dd ee # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo # \u4f7f\u7528read_table\uff0c\u5e76\u6307\u5b9a\u5206\u9694\u7b26\uff0c\u5c06\u6587\u4ef6\u8bfb\u5165\u4e00\u4e2aDataFrame df = pd.read_table(file01, sep=',') print(df) # a b c d message # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo \u4ece\u591a\u4e2a\u5217\u4e2d\u5f62\u6210\u4e00\u4e2a\u5206\u5c42\u7d22\u5f15 parased = pd.read_csv('../examples/csv_mindex.csv', index_col=['key1', 'key2']) print(parased) # value1 value2 # key1 key2 # one a 1 2 # b 3 4 # c 5 6 # d 7 8 # two a 9 10 # b 11 12 # c 13 14 # d 15 16 \u4e0b\u4f8b\u4e2d\uff0c\u7531\u4e8e\u5217\u540d\u7684\u6570\u91cf\u6bd4\u6570\u636e\u7684\u5217\u6570\u5c11\u4e00\u4e2a\uff0c\u56e0\u6b64read_table\u63a8\u65ad\u7b2c\u4e00\u5217\u5e94\u5f53\u4f5c\u4e3aDataFrame\u7684\u7d22\u5f15\u3002\\ ex3.txt\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 A B C aaa -0.264438 -1.026059 -0.619500 bbb 0.927272 0.302904 -0.032399 ccc -0.264273 -0.386314 -0.217601 ddd -0.871858 -0.348382 1.100491 result = pd.read_table('../examples/ex3.txt') # \u76f4\u63a5\u8bfb\u53d6 print(result) # A B C # aaa -0.264438 -1.026059 -0.619500 # bbb 0.927272 0.302904 -0.032399 NaN # ccc -0.264273 -0.386314 -0.217601 # ddd -0.871858 -0.348382 1.100491 result = pd.read_table('../examples/ex3.txt', sep='\\s+') # \u5411read_table\u6b63\u5219\u8868\u8fbe\u5f0f\u4e3a\\s+\u6765\u683c\u5f0f\u5316\u6587\u4ef6 print(result) # A B C # aaa -0.264438 -1.026059 -0.619500 # bbb 0.927272 0.302904 -0.032399 # ccc -0.264273 -0.386314 -0.217601 # ddd -0.871858 -0.348382 1.100491 \u4e0b\u4f8b\u4e2dex4.csv\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 # hey! a,b,c,d,message # just wanted to make things more difficult for you # who reads CSV files with computers, anyway? 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo result = pd.read_csv('../examples/ex4.csv', skiprows=[0, 2, 3]) # \u4f7f\u7528skiprows\u6765\u8df3\u8fc7\u7b2c\u4e00\u884c\u3001\u7b2c\u4e09\u884c\u548c\u7b2c\u56db\u884c print(result) # a b c d message # 0 1 2 3 4 hello # 1 5 6 7 8 world # 2 9 10 11 12 foo \u7f3a\u5931\u503c\u5904\u7406 \\ \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cpandas\u4f7f\u7528\u4e00\u4e9b\u5e38\u89c1\u7684\u6807\u8bc6\uff0c\u4f8b\u5982NA\u548cNULL \\ \u4e0b\u4f8b\u4e2dex5.csv\u539f\u59cb\u6587\u4ef6\u5185\u5bb9 something,a,b,c,d,message one,1,2,3,4,NA two,5,6,,8,world three,9,10,11,12,foo result = pd.read_csv('../examples/ex5.csv') print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo print(pd.isnull(result)) # something a b c d message # 0 False False False False False True # 1 False False False True False False # 2 False False False False False False result = pd.read_csv('../examples/ex5.csv', na_values=['NULL']) print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo \u5b9a\u4e49\u66ff\u6362\u89c4\u5219 sentinels = { 'message': ['foo', 'NA'], 'something': ['two'] } result = pd.read_csv('../examples/ex5.csv', na_values=sentinels) \u628amessage\u5217\u6240\u6709\u503c\u4e3afoo\u6216NA\u7684\u66ff\u6362\u4e3aNull \\ \u628asomething\u5217\u6240\u6709\u503c\u4e3atwo\u7684\u66ff\u6362\u4e3aNull print(result) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 NaN 5 6 NaN 8 world # 2 three 9 10 11.0 12 NaN","title":"\u6587\u672c\u683c\u5f0f\u6570\u636e\u7684\u8bfb\u5199"},{"location":"python/DataAnalysis/ch03/#_3","text":"pd.options.display.max_rows = 10 result = pd.read_csv('../examples/ex6.csv') # \u8bfb\u53d6\u5168\u90e8\u8bb0\u5f55 print(result) result = pd.read_csv('../examples/ex6.csv', nrows=5) # \u8bfb\u53d6\u524d5\u884c\u8bb0\u5f55 print(result) # [10000 rows x 5 columns] # one two three four key # 0 0.467976 -0.038649 -0.295344 -1.824726 L # 1 -0.358893 1.404453 0.704965 -0.200638 B # 2 -0.501840 0.659254 -0.421691 -0.057688 G # 3 0.204886 1.074134 1.388361 -0.982404 R # 4 0.354628 -0.133116 0.283763 -0.837063 Q result = pd.read_csv('../examples/ex6.csv', chunksize=1000) # \u5206\u5757\u8bfb\u5165\u6587\u4ef6\uff0c\u6bcf\u57571000\u884c print(result) # \u8fd4\u56de\u7684\u662f\u4e00\u4e2aTextParser\u5bf9\u8c61, \u5141\u8bb8\u4f60\u6839\u636echunksize\u904d\u5386\u6587\u4ef6\u3002 # <pandas.io.parsers.readers.TextFileReader object at 0x7f2b3cd01730> \u53ef\u4ee5\u904d\u5386ex6.csv\uff0c\u5e76\u5bf9\u2019key\u2019\u5217\u805a\u5408\u83b7\u5f97\u8ba1\u6570\u503c tot = pd.Series([], dtype=float) # \u8fd9\u91cc\u9700\u8981\u663e\u5f0f\u6307\u5b9adtype\uff0c\u540e\u7eedPython\u4f1a\u5c06\u9ed8\u8ba4\u503c\u4ecefloat64\u53d8\u6210object\uff0c\u76ee\u524d\u9ed8\u8ba4\u662ffloat64 for piece in result: tot = tot.add(piece['key'].value_counts(), fill_value=0) tot = tot.sort_values(ascending=False) print(tot[:10]) # E 368.0 # X 364.0 # L 346.0 # O 343.0 # Q 340.0 # M 338.0 # J 337.0 # F 335.0 # K 334.0 # H 330.0 # dtype: float64","title":"\u5206\u5757\u8bfb\u5165\u6587\u672c\u6587\u4ef6"},{"location":"python/DataAnalysis/ch03/#_4","text":"data = pd.read_csv('../examples/ex5.csv') print(data) # something a b c d message # 0 one 1 2 3.0 4 NaN # 1 two 5 6 NaN 8 world # 2 three 9 10 11.0 12 foo \u4f7f\u7528DataFrame\u7684to_csv\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u5bfc\u51fa\u4e3a\u9017\u53f7\u5206\u9694\u7684\u6587\u4ef6 data.to_csv('../examples/out.csv') # \u8f93\u51faout.csv\u7684\u5185\u5bb9 # ,something,a,b,c,d,message # 0,one,1,2,3.0,4, # 1,two,5,6,,8,world # 2,three,9,10,11.0,12,foo \u4f7f\u7528DataFrame\u7684to_csv\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u5bfc\u51fa\u4e3a\u5176\u4ed6\u7684\u5206\u9694\u7b26\u7684\u6587\u4ef6 data.to_csv(sys.stdout, sep='|') # |something|a|b|c|d|message # 0|one|1|2|3.0|4| # 1|two|5|6||8|world # 2|three|9|10|11.0|12|foo data.to_csv(sys.stdout, sep=',') # ,something,a,b,c,d,message # 0,one,1,2,3.0,4, # 1,two,5,6,,8,world # 2,three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL') # \u8bbe\u5b9a\u7f3a\u5931\u503c\u5728\u8f93\u51fa\u65f6\u4ee5\u7a7a\u5b57\u7b26\u4e32\u51fa\u73b0 # ,something,a,b,c,d,message # 0,one,1,2,3.0,4,NULL # 1,two,5,6,NULL,8,world # 2,three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL', index=False, header=False) # \u4e0d\u8f93\u51fa\u884c\u548c\u5217\u7684\u6807\u7b7e\uff08index\uff0cheader\uff09 # one,1,2,3.0,4,NULL # two,5,6,NULL,8,world # three,9,10,11.0,12,foo data.to_csv(sys.stdout, sep=',', na_rep='NULL', index=False, header=False, columns=['a', 'b', 'c']) # \u6309\u7167\u81ea\u5b9a\u7684\u987a\u5e8f\u8f93\u51fa\u5b50\u96c6 # 1,2,3.0 # 5,6,NULL # 9,10,11.0 Series\u4e5f\u6709to_csv\u65b9\u6cd5 dates = pd.date_range('1/1/2000', periods=7) ts = pd.Series(np.arange(7), index=dates) ts.to_csv('../examples/tseries.csv', header=False) # \u8f93\u51fatseries.csv\u6587\u4ef6\u5185\u5bb9 # 2000-01-01,0 # 2000-01-02,1 # 2000-01-03,2 # 2000-01-04,3 # 2000-01-05,4 # 2000-01-06,5 # 2000-01-07,6","title":"\u5c06\u6570\u636e\u5199\u5165\u6587\u672c\u683c\u5f0f"},{"location":"python/DataAnalysis/ch03/#_5","text":"\u7edd\u5927\u591a\u6570\u7684\u8868\u578b\u6570\u636e\u90fd\u53ef\u4ee5\u4f7f\u7528\u51fd\u6570pandas.read_table\u4ece\u786c\u76d8\u4e2d\u8bfb\u53d6\u3002 \\ \u7136\u800c\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u63a5\u6536\u4e00\u4e2a\u5e26\u6709\u4e00\u884c\u6216\u591a\u884c\u9519\u8bef\u7684\u6587\u4ef6\u5e76\u4e0d\u5c11\u89c1\uff0cread_table\u4e5f\u65e0\u6cd5\u89e3\u51b3\u8fd9\u79cd\u60c5\u51b5\u3002 ex7.csv \u6587\u4ef6\u5185\u5bb9 \"a\",\"b\",\"c\" \"1\",\"2\",\"3\" \"1\",\"2\",\"3\" f = open('../examples/ex7.csv') # \u4f7f\u7528Python\u7684\u5185\u5efacsv\u6a21\u5757 reader = csv.reader(f) # \u5c06\u4efb\u4e00\u6253\u5f00\u7684\u6587\u4ef6\u6216\u6587\u4ef6\u578b\u5bf9\u8c61\u4f20\u7ed9csv.reader for line in reader: # # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a', 'b', 'c'] # ['1', '2', '3'] # ['1', '2', '3'] with open('../examples/ex7.csv') as f: lines = list(csv.reader(f)) # \u9996\u5148\uff0c\u5c06\u6587\u4ef6\u8bfb\u53d6\u4e3a\u884c\u7684\u5217\u8868 header, values = lines[0], lines[1:] # \u5176\u6b21\uff0c\u5c06\u6570\u636e\u62c6\u5206\u4e3a\u5217\u540d\u884c\u548c\u6570\u636e\u884c data_dict = { h: v for h, v in zip(header, zip(*values)) # \u518d\u7136\u540e\uff0c\u4f7f\u7528\u5b57\u5178\u63a8\u5bfc\u5f0f\u548c\u8868\u8fbe\u5f0fzip(*values)\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6570\u636e\u5217\u7684\u5b57\u5178\uff0c\u5b57\u5178\u4e2d\u884c\u8f6c\u7f6e\u6210\u5217 } print(data_dict) # \u8f93\u51fa\u7ed3\u679c # {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')} \u5982\u679c\u9700\u6839\u636e\u4e0d\u540c\u7684\u5206\u9694\u7b26\u3001\u5b57\u7b26\u4e32\u5f15\u7528\u7ea6\u5b9a\u6216\u884c\u7ec8\u6b62\u7b26\u5b9a\u4e49\u4e00\u79cd\u65b0\u7684\u683c\u5f0f\u65f6\uff0c\u53ef\u4ee5: \\ \u65b9\u6cd51\uff1a\u4f7f\u7528csv.Dialect\u5b9a\u4e49\u4e00\u4e2a\u7b80\u5355\u7684\u5b50\u7c7b class my_dialect(csv.Dialect): lineterminator = '\\n' delimiter = ';' # \u8fd9\u91cc\u53ea\u80fd\u662f\u4e00\u4e2a\u5b57\u7b26 quotechar = '\"' quoting = csv.QUOTE_MINIMAL f = open('../examples/ex7.csv') reader = csv.reader(f, dialect=my_dialect) for line in reader: # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a,\"b\",\"c\"'] # ['1,\"2\",\"3\"'] # ['1,\"2\",\"3\"'] \u65b9\u6cd52\uff1a\u76f4\u63a5\u5c06CSV\u65b9\u8a00\u53c2\u6570(dialect)\u4f20\u5165csv.reader\u7684\u5173\u952e\u5b57\u53c2\u6570 \\ \u6bd4\u8f83\u8be6\u7ec6\u7684\u4ecb\u7ecd\u65b9\u8a00\u548c\u5206\u9694\u7b26\uff1ahttps://blog.csdn.net/tcy23456/article/details/85291994 f = open('../examples/ex7.csv') reader = csv.reader(f, delimiter='|') for line in reader: # \u904d\u5386reader\uff0c\u4ea7\u751f\u5143\u7ec4\uff0c\u5143\u7ec4\u7684\u503c\u4e3a\u5220\u9664\u4e86\u5f15\u53f7\u7684\u5b57\u7b26 print(line) f.close() # ['a,\"b\",\"c\"'] # ['1,\"2\",\"3\"'] # ['1,\"2\",\"3\"'] \u5bf9\u4e8e\u5177\u6709\u66f4\u590d\u6742\u6216\u56fa\u5b9a\u7684\u591a\u5b57\u7b26\u5206\u9694\u7b26\u7684\u6587\u4ef6\uff0c\u5c06\u65e0\u6cd5\u4f7f\u7528csv\u6a21\u5757\u3002 \\ \u5728\u6b64\u7c7b\u60c5\u51b5\u4e0b\uff0c\u5c06\u4f7f\u7528\u5b57\u7b26\u4e32\u7684split\u65b9\u6cd5\u6216\u6b63\u5219\u8868\u8fbe\u5f0f\u65b9\u6cd5re.split\u8fdb\u884c\u884c\u62c6\u5206\u548c\u5176\u4ed6\u6e05\u7406\u5de5\u4f5c\u3002 \\ \u9700\u8981\u624b\u52a8\u5199\u5165\u88ab\u5206\u9694\u7684\u6587\u4ef6\u65f6\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528csv.writer\u3002 \\ \u8fd9\u4e2a\u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u5df2\u7ecf\u6253\u5f00\u7684\u53ef\u5199\u5165\u6587\u4ef6\u5bf9\u8c61\u4ee5\u53ca\u548ccsv.reader\u76f8\u540c\u7684CSV\u65b9\u8a00\u3001\u683c\u5f0f\u9009\u9879 with open('../examples/mydata.csv', 'w') as f: writer = csv.writer(f, dialect=my_dialect) writer.writerow(('1', '2', '3')) writer.writerow(('4', '5', '6')) writer.writerow(('7', '8', '9')) writer.writerow(('10', '11', '12')) # mydata.csv \u6587\u4ef6\u5185\u5bb9 # 1;2;3 # 4;5;6 # 7;8;9 # 10;11;12","title":"\u4f7f\u7528\u5206\u9694\u683c\u5f0f"},{"location":"python/DataAnalysis/ch03/#json","text":"obj = \"\"\" { \"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [ { \"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"] }, { \"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"] } ] } \"\"\" \u5c06JSON\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3aPython\u5f62\u5f0f\u65f6\uff0c\u4f7f\u7528json.loads\u65b9\u6cd5 result = json.loads(obj) print(result) # {'name': 'Wes', 'places_lived': ['United States', 'Spain', 'Germany'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zeus', 'Zuko']}, {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]} \u53e6\u4e00\u65b9\u9762\uff0cjson.dumps\u53ef\u4ee5\u5c06Python\u5bf9\u8c61\u8f6c\u6362\u56deJSON asjson = json.dumps(result) print(asjson) # {\"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]}, {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]} \u5c06JSON\u5bf9\u8c61\u6216\u5bf9\u8c61\u5217\u8868\u8f6c\u6362\u4e3aDataFrame\u6216\u5176\u4ed6\u6570\u636e\u7ed3\u6784 \\ \u6bd4\u8f83\u65b9\u4fbf\u7684\u65b9\u5f0f\u662f\u5c06\u5b57\u5178\u6784\u6210\u7684\u5217\u8868\uff08\u4e4b\u524d\u662fJSON\u5bf9\u8c61\uff09\u4f20\u5165DataFrame\u6784\u9020\u51fd\u6570\uff0c\u5e76\u9009\u51fa\u6570\u636e\u5b57\u6bb5\u7684\u5b50\u96c6 siblings = pd.DataFrame(result['siblings'], columns=['name', 'age']) print(siblings) # name age # 0 Scott 30 # 1 Katie 38 pandas.read_json\u53ef\u4ee5\u81ea\u52a8\u5c06JSON\u6570\u636e\u96c6\u6309\u7167\u6307\u5b9a\u6b21\u5e8f\u8f6c\u6362\u4e3aSeries\u6216DataFrame \\ pandas.read_json\u7684\u9ed8\u8ba4\u9009\u9879\u662f\u5047\u8bbeJSON\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u662f\u8868\u91cc\u7684\u4e00\u884c \\ \u8bfb\u53d6\u3001\u64cd\u4f5cJSON\u6570\u636e\uff08\u5305\u62ec\u5d4c\u5957\u8bb0\u5f55\uff09\u7684\u62d3\u5c55\u793a\u4f8b\uff0c\u8bf7\u53c2\u770b\u7b2c7\u7ae0\u7684USDA\u98df\u54c1\u6570\u636e\u5e93\u793a\u4f8b \\ \u4f8b\u5982\u8bfb\u53d6 data = pd.read_json('../examples/example_new.json') data = pd.read_json('../examples/example.json') print(data) # a b c # 0 1 2 3 # 1 4 5 6 # 2 7 8 9 print(data.to_json()) # {\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}} print(data.to_json(orient='records')) # [{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]","title":"JSON\u6570\u636e"},{"location":"python/DataAnalysis/ch03/#xmlhtml","text":"pandas\u7684\u5185\u5efa\u51fd\u6570read_html\u53ef\u4ee5\u4f7f\u7528lxml\u548cBeautiful Soup\u7b49\u5e93\u5c06HTML\u4e2d\u7684\u8868\u81ea\u52a8\u89e3\u6790\u4e3aDataFrame\u5bf9\u8c61 tables = pd.read_html('../examples/fdic_failed_bank_list.html') print(len(tables)) # 1 failures = tables[0] # //*[@id=\"table\"] print(failures.head()) # \u8bfb\u53d6\u524d5\u884c\u8bb0\u5f55 # Bank Name ... Updated Date # 0 Allied Bank ... November 17, 2016 # 1 The Woodbury Banking Company ... November 17, 2016 # 2 First CornerStone Bank ... September 6, 2016 # 3 Trust Company Bank ... September 6, 2016 # 4 North Milwaukee State Bank ... June 16, 2016 # # [5 rows x 7 columns] close_timestamps = pd.to_datetime(failures['Closing Date']) # \u8ba1\u7b97\u6bcf\u5e74\u94f6\u884c\u5012\u95ed\u7684\u6570\u91cf print(close_timestamps.dt.year.value_counts()) # 2010 157 # 2009 140 # 2011 92 # 2012 51 # 2008 25 # ... # 2004 4 # 2001 4 # 2007 3 # 2003 3 # 2000 2 # Name: Closing Date, Length: 15, dtype: int64","title":"XML\u548cHTML\uff1a\u7f51\u7edc\u6293\u53d6"},{"location":"python/DataAnalysis/ch03/#_6","text":"","title":"\u4e8c\u8fdb\u5236\u683c\u5f0f"},{"location":"python/DataAnalysis/ch03/#web-api","text":"","title":"\u4e0eWeb API\u4ea4\u4e92"},{"location":"python/DataAnalysis/ch03/#_7","text":"","title":"\u4e0e\u6570\u636e\u5e93\u4ea4\u4e92"},{"location":"python/DataAnalysis/ch04/","text":"\u6570\u636e\u6e05\u6d17\u4e0e\u51c6\u5907 \u5904\u7406\u7f3a\u5931\u503c import pandas as pd import numpy as np from numpy import nan as NA \u5bf9\u4e8e\u6570\u503c\u578b\u6570\u636e\uff0cpandas\u4f7f\u7528\u6d6e\u70b9\u503c NaN \uff08Not a Number\u6765\u8868\u793a\u7f3a\u5931\u503c\uff09\u3002 \u5728pandas\u4e2d\uff0c\u91c7\u7528\u4e86R\u8bed\u8a00\u4e2d\u7684\u7f16\u7a0b\u60ef\u4f8b\uff0c\u5c06\u7f3a\u5931\u503c\u6210\u4e3a NA \uff0c\u610f\u601d\u662fnotavailable\uff08\u4e0d\u53ef\u7528\uff09\u3002 Python\u5185\u5efa\u7684 None \u503c\u5728\u5bf9\u8c61\u6570\u7ec4\u4e2d\u4e5f\u88ab\u5f53\u4f5c NA \u5904\u7406\u3002 NA\u5904\u7406\u65b9\u6cd5\uff1a dropna :\u6839\u636e\u6bcf\u4e2a\u6807\u7b7e\u7684\u503c\u662f\u5426\u662f\u786e\u5b9e\u6570\u636e\u6765\u7b5b\u9009\u8f74\u6807\u7b7e\uff0c\u5e76\u6839\u636e\u5141\u8bb8\u4e22\u5931\u7684\u6570\u636e\u91cf\u6765\u786e\u5b9a\u9608\u503c fillna :\u7528\u67d0\u4e9b\u503c\u586b\u5145\u786e\u5b9e\u7684\u6570\u636e\u6216\u4f7f\u7528\u63d2\u503c\u65b9\u6cd5\uff0c\u5982 ffill \u6216 bfill isnull :\u8fd4\u56de\u8868\u660e\u54ea\u4e9b\u503c\u662f\u7f3a\u5931\u503c\u7684\u5e03\u5c14\u503c notnull :\u662f isnull \u7684\u53cd\u51fd\u6570 string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado']) print(string_data) # 0 aardvark # 1 artichoke # 2 NaN # 3 avocado # dtype: object print(string_data.isnull()) # 0 False # 1 False # 2 True # 3 False # dtype: bool string_data[0] = None print(string_data.isnull()) # 0 True # 1 False # 2 True # 3 False # dtype: bool \u8fc7\u6ee4\u7f3a\u5931\u503c \u5904\u7406Series \u5728Series\u4e0a\u4f7f\u7528 dropna \uff0c\u5b83\u4f1a\u8fd4\u56deSeries\u4e2d\u6240\u6709\u7684\u975e\u7a7a\u6570\u636e\u53ca\u5176\u7d22\u5f15\u503c\u3002 data = pd.Series([1, NA, 3.5, NA, 7]) print(data.dropna()) # 0 1.0 # 2 3.5 # 4 7.0 # dtype: float64 print(data[data.notnull()]) # \u4e0e\u4e0a\u9762\u7b49\u4ef7 # 0 1.0 # 2 3.5 # 4 7.0 # dtype: float64 \u5904\u7406DataFrame data = pd.DataFrame( [[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]] ) print(data) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.5 3.0 cleaned = data.dropna() # dropna\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f1a\u5220\u9664\u5305\u542b\u7f3a\u5931\u503c\u7684\u884c print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 cleaned = data.dropna(how='all') # \u4f20\u5165how='all\u2019\u65f6\uff0c\u5c06\u5220\u9664\u6240\u6709\u503c\u5747\u4e3aNA\u7684\u884c print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 3 NaN 6.5 3.0 data[4] = NA print(data) # 0 1 2 4 # 0 1.0 6.5 3.0 NaN # 1 1.0 NaN NaN NaN # 2 NaN NaN NaN NaN # 3 NaN 6.5 3.0 NaN cleaned = data.dropna(axis=1, how='all') # \u5220\u9664\u5168NA\u7684\u5217 print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.5 3.0 df = pd.DataFrame(np.random.randn(7, 3)) print(df) # 0 1 2 # 0 -1.069771 -0.777921 0.181956 # 1 -0.399504 -0.641737 -0.946327 # 2 -1.013920 -0.247588 -0.760146 # 3 1.076946 -1.263203 0.494077 # 4 0.460985 -1.241870 0.283006 # 5 1.168149 1.033752 0.900095 # 6 -1.208514 -1.049546 -0.783680 df.iloc[:4, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[:2, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 -1.069771 NaN NaN # 1 -0.399504 NaN NaN # 2 -1.013920 NaN -0.760146 # 3 1.076946 NaN 0.494077 # 4 0.460985 -1.241870 0.283006 # 5 1.168149 1.033752 0.900095 # 6 -1.208514 -1.049546 -0.783680 cleaned = df.dropna() print(cleaned) # 0 1 2 # 4 0.033663 0.291886 0.736448 # 5 -0.433380 0.397104 1.252005 # 6 -1.999018 0.303866 1.430109 cleaned = df.dropna(thresh=2) # \u4fdd\u75592\u884c\u542bNA\u7684\u89c2\u5bdf\u503c print(cleaned) # 0 1 2 # 2 -1.413976 NaN 0.222274 # 3 -0.644266 NaN 0.324180 # 4 -0.122160 -2.244880 -0.406562 # 5 -0.140326 0.101133 -0.764048 # 6 -1.809141 0.139091 -0.819175 \u8865\u5168\u7f3a\u5931\u503c fillna \u51fd\u6570\u53c2\u6570\uff1a value\uff1a\u6807\u91cf\u503c\u6216\u5b57\u5178\u578b\u5bf9\u8c61\u7528\u4e8e\u586b\u5145\u7f3a\u5931\u503c method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u5982\u679c\u6ca1\u6709\u5176\u4ed6\u53c2\u6570\uff0c\u9ed8\u8ba4\u662f'ffill' axis\uff1a\u9700\u8981\u586b\u5145\u7684\u8f74\uff0c\u9ed8\u8ba4axis=0 inplace\uff1a\u4fee\u6539\u88ab\u8c03\u7528\u5bf9\u8c61\uff0c\u800c\u4e0d\u662f\u751f\u6210\u4e00\u4e2a\u5907\u4efd limit\uff1a\u7528\u4e8e\u524d\u5411\u6216\u540e\u5411\u586b\u5145\u65f6\u6700\u5927\u7684\u586b\u5145\u8303\u56f4 df = pd.DataFrame(np.random.randn(7, 3)) df.iloc[:4, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[:2, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 -0.181196 NaN NaN # 1 -1.657668 NaN NaN # 2 -0.053454 NaN 0.391461 # 3 -0.539307 NaN -0.668400 # 4 -0.433439 0.839713 -0.295273 # 5 0.749930 1.661641 -0.495165 # 6 0.591810 1.017372 0.932367 result = df.fillna(0) # \u8c03\u7528fillna\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5e38\u6570\u6765\u66ff\u4ee3\u7f3a\u5931\u503c print(result) # 0 1 2 # 0 -0.430926 0.000000 0.000000 # 1 0.448061 0.000000 0.000000 # 2 -0.059910 0.000000 -1.532646 # 3 -0.315793 0.000000 -0.196546 # 4 -0.546106 0.135108 -0.332309 # 5 1.083075 0.346070 -0.773104 # 6 -0.186511 1.055337 -1.168303 result = df.fillna({1: 0.5, 2: 0}) # \u8c03\u7528fillna\u65f6\u4f7f\u7528\u5b57\u5178\uff0c\u53ef\u4ee5\u4e3a\u4e0d\u540c\u5217\u8bbe\u5b9a\u4e0d\u540c\u7684\u586b\u5145\u503c print(result) # 0 1 2 # 0 -0.794344 0.500000 0.000000 # 1 -0.960917 0.500000 0.000000 # 2 1.494351 0.500000 0.100878 # 3 -0.554765 0.500000 1.118801 # 4 -0.866117 0.523615 1.217478 # 5 -0.706966 -0.681776 0.797690 # 6 -1.456366 1.205518 -0.402432 fillna \u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u65b0\u7684\u5bf9\u8c61\uff0c\u4f46\u4e5f\u53ef\u4ee5\u4fee\u6539\u5df2\u7ecf\u5b58\u5728\u7684\u5bf9\u8c61 _ = df.fillna(0, inplace=True) # inplace=True\u6307\u5b9a\u5728\u5df2\u6709\u5bf9\u8c61\u4e0a\u76f4\u63a5\u4fee\u6539 print(df) # 0 1 2 # 0 -1.176124 0.000000 0.000000 # 1 0.120458 0.000000 0.000000 # 2 -1.206408 0.000000 0.551693 # 3 0.224563 0.000000 1.145156 # 4 -0.557836 0.081135 -0.075282 # 5 2.378837 -0.876145 1.430386 # 6 -0.152662 1.278364 0.479686 df = pd.DataFrame(np.random.randn(6, 3)) df.iloc[2:, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[4:, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 1.154788 0.033949 -0.122807 # 1 0.258684 -0.580244 1.636514 # 2 1.503756 NaN -1.224203 # 3 0.824049 NaN -0.364345 # 4 -1.247609 NaN NaN # 5 -1.019980 NaN NaN result = df.fillna(method='ffill') # \u5411\u540e\u586b\u5145 print(result) # 0 1 2 # 0 2.082449 0.398874 0.359772 # 1 0.233129 0.385347 1.953533 # 2 0.396555 0.385347 0.592784 # 3 -0.957249 0.385347 0.169815 # 4 0.854452 0.385347 0.169815 # 5 -0.105982 0.385347 0.169815 result = df.fillna(method='ffill', limit=3) # \u6bcf\u5217\u6700\u591a\u586b3\u4e2a print(result) result = df.fillna(df[0].max()) # \u75280\u5217\u7684\u6700\u5927\u503c\u586b\u5145\u6240\u6709\u7684NA print(result) # 0 1 2 # 0 -0.377697 -0.852891 -0.705489 # 1 -0.611759 -0.013237 -0.295764 # 2 -0.389974 1.057881 1.041957 # 3 -0.016845 1.057881 -1.149954 # 4 1.057881 1.057881 1.057881 # 5 -0.463471 1.057881 1.057881 \u6570\u636e\u8f6c\u6362 import pandas as pd import numpy as np from numpy import nan as NA \u5220\u9664\u91cd\u590d\u503c data = pd.DataFrame( { 'k1': ['one', 'two'] * 3 + ['two'], 'k2': [1, 1, 2, 3, 4, 4, 4] } ) print(data) # \u91cd\u590d\u51fa\u73b02\u6b21\u7684\u8bb0\u5f55\uff1atwo 4 # k1 k2 # 0 one 1 # 1 two 1 # 2 one 2 # 3 two 3 # 4 one 4 # 5 two 4 # 6 two 4 DataFrame\u7684 duplicated \u65b9\u6cd5\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5e03\u5c14\u503cSeries\uff0c\u8fd9\u4e2aSeries\u53cd\u6620\u7684\u662f\u6bcf\u4e00\u884c\u662f\u5426\u5b58\u5728\u91cd\u590d\uff08\u4e0e\u4e4b\u524d\u51fa\u73b0\u8fc7\u7684\u884c\u76f8\u540c\uff09\u60c5\u51b5\uff0c\u9ed8\u8ba4\u662f\u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 print(data.duplicated()) # 0 False # 1 False # 2 False # 3 False # 4 False # 5 False # 6 True # dtype: bool drop_duplicates \u8fd4\u56de\u7684\u662fDataFrame\uff0c\u5185\u5bb9\u662f duplicated \u8fd4\u56de\u6570\u7ec4\u4e2d\u4e3a False \u7684\u90e8\u5206\u3002\u9ed8\u8ba4\u662f\u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 print(data.drop_duplicates()) # k1 k2 # 0 one 1 # 1 two 1 # 2 one 2 # 3 two 3 # 4 one 4 # 5 two 4 \u53ef\u4ee5\u6307\u5b9a\u6570\u636e\u7684\u4efb\u4f55\u5b50\u96c6\u6765\u68c0\u6d4b\u662f\u5426\u6709\u91cd\u590d\u3002\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u989d\u5916\u7684\u5217\uff0c\u5e76\u60f3\u57fa\u4e8e\u2019k1\u2019\u5217\u53bb\u9664\u91cd\u590d\u503c\u3002 data['v1'] = range(7) print(data) # k1 k2 v1 # 0 one 1 0 # 1 two 1 1 # 2 one 2 2 # 3 two 3 3 # 4 one 4 4 # 5 two 4 5 # 6 two 4 6 print(data.drop_duplicates(['k1'])) # \u4fdd\u7559\u7b2c\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684one\u548ctwo\uff0c\u5176\u4f59\u4e22\u5f03 # k1 k2 v1 # 0 one 1 0 # 1 two 1 1 duplicated \u548c drop_duplicates \u9ed8\u8ba4\u90fd\u662f\u4fdd\u7559\u7b2c\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684\u503c\u3002\u4f20\u5165\u53c2\u6570keep='last\u2019\u5c06\u4f1a\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u3002 print(data.drop_duplicates(['k1'], keep='last')) # \u4fdd\u7559\u6700\u540e\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684one\u548ctwo # k1 k2 v1 # 4 one 4 4 # 6 two 4 6 \u4f7f\u7528\u51fd\u6570\u6216\u6620\u5c04\u8fdb\u884c\u6570\u636e\u8f6c\u6362 \u4f7f\u7528 map \u662f\u4e00\u79cd\u53ef\u4ee5\u4fbf\u6377\u6267\u884c\u6309\u5143\u7d20\u8f6c\u6362\u53ca\u5176\u4ed6\u6e05\u6d17\u76f8\u5173\u64cd\u4f5c\u7684\u65b9\u6cd5\u3002 data = pd.DataFrame( { 'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6] } ) print(data) # food ounces # 0 bacon 4.0 # 1 pulled pork 3.0 # 2 bacon 12.0 # 3 Pastrami 6.0 # 4 corned beef 7.5 # 5 Bacon 8.0 # 6 pastrami 3.0 # 7 honey ham 5.0 # 8 nova lox 6.0 \u6dfb\u52a0\u4e00\u5217\u7528\u4e8e\u8868\u660e\u6bcf\u79cd\u98df\u7269\u7684\u52a8\u7269\u8089\u7c7b\u578b\u3002 \u5148\u521b\u5efa\u4e00\u4e2a\u98df\u7269\u548c\u8089\u7c7b\u7684\u6620\u5c04\u3002 meat_to_animal = { 'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon' } lowercased = data['food'].str.lower() # \u4f7f\u7528Series\u7684str.lower\u65b9\u6cd5\u5c06food\u7684\u6bcf\u4e2a\u503c\u90fd\u8f6c\u6362\u4e3a\u5c0f\u5199 print(lowercased) # 0 bacon # 1 pulled pork # 2 bacon # 3 pastrami # 4 corned beef # 5 bacon # 6 pastrami # 7 honey ham # 8 nova lox # Name: food, dtype: object data['animal'] = lowercased.map(meat_to_animal) print(data) # food ounces animal # 0 bacon 4.0 pig # 1 pulled pork 3.0 pig # 2 bacon 12.0 pig # 3 Pastrami 6.0 cow # 4 corned beef 7.5 cow # 5 Bacon 8.0 pig # 6 pastrami 3.0 cow # 7 honey ham 5.0 pig # 8 nova lox 6.0 salmon \u4e5f\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u51fd\u6570\uff0c\u5b8c\u6210\u4e0a\u9762\u6240\u6709\u529f\u80fd\u3002 data = pd.DataFrame( { 'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6] } ) result = data['food'].map(lambda x: meat_to_animal[x.lower()]) print(result) # 0 pig # 1 pig # 2 pig # 3 cow # 4 cow # 5 pig # 6 cow # 7 pig # 8 salmon # Name: food, dtype: object \u66ff\u4ee3\u503c \u4f7f\u7528 fillna \u586b\u5145\u7f3a\u5931\u503c\u662f\u901a\u7528\u503c\u66ff\u6362\u7684\u7279\u6b8a\u6848\u4f8b\u3002 map \u53ef\u4ee5\u7528\u6765\u4fee\u6539\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u5b50\u96c6\u7684\u503c\uff0c\u4f46\u662f replace \u63d0\u4f9b\u4e86\u66f4\u4e3a\u7b80\u5355\u7075\u6d3b\u7684\u5b9e\u73b0\u3002 data.replace \u65b9\u6cd5\u4e0e data.str.replace \u65b9\u6cd5\u662f\u4e0d\u540c\u7684\uff0c data.str.replace \u662f\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u6309\u5143\u7d20\u66ff\u4ee3\u7684\u3002 \u4e0b\u9762\u7684Series\uff0c -999 \u53ef\u80fd\u662f\u7f3a\u5931\u503c\u7684\u6807\u8bc6\u3002\u5982\u679c\u8981\u4f7f\u7528 NA \u6765\u66ff\u4ee3\u8fd9\u4e9b\u503c\uff0c\u53ef\u4ee5\u4f7f\u7528 replace \u65b9\u6cd5\u751f\u6210\u65b0\u7684Series\uff08\u9664\u975e\u4f20\u5165\u4e86 inplace=True \uff09 data = pd.Series([1., -999., 2., -999., -1000., 3.]) print(data) # 0 1.0 # 1 -999.0 # 2 2.0 # 3 -999.0 # 4 -1000.0 # 5 3.0 # dtype: float64 result = data.replace(-999, np.nan) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 -1000.0 # 5 3.0 # dtype: float64 \u8981\u5c06\u4e0d\u540c\u7684\u503c\u66ff\u6362\u4e3a\u4e0d\u540c\u7684\u503c\uff0c\u53ef\u4ee5\u4f20\u5165\u66ff\u4ee3\u503c\u7684\u5217\u8868 result = data.replace([-999, -1000], [np.nan, 0]) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 0.0 # 5 3.0 # dtype: float64 \u4e5f\u53ef\u4ee5\u4f20\u5165\u66ff\u4ee3\u503c\u7684\u5b57\u5178 result = data.replace({-999: np.nan, -1000: 0}) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 0.0 # 5 3.0 # dtype: float64 \u91cd\u547d\u540d\u8f74\u7d22\u5f15 \u548cSeries\u4e2d\u503c\u66ff\u6362\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u901a\u8fc7\u51fd\u6570\u6216\u6620\u5c04\u5bf9\u8f74\u6807\u7b7e\u8fdb\u884c\u7c7b\u4f3c\u7684\u8f6c\u6362\uff0c\u751f\u6210\u65b0\u7684\u4e14\u5e26\u6709\u4e0d\u540c\u6807\u7b7e\u7684\u5bf9\u8c61\u3002 data = pd.DataFrame( np.arange(12).reshape((3, 4)), index=['Ohio', 'Colorado', 'New York'], columns=['one', 'two', 'three', 'four'] ) print(data) # one two three four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # New York 8 9 10 11 \u4e0eSeries\u7c7b\u4f3c\uff0c\u8f74\u7d22\u5f15\u4e5f\u6709\u4e00\u4e2a map \u65b9\u6cd5\u3002 transform = lambda x: x[:4].upper() # \u622a\u53d6index\u7684\u524d\u56db\u4f4d\u5e76\u8f6c\u5316\u4e3a\u5927\u5199\u683c\u5f0f result = data.index.map(transform) print(result) # Index(['OHIO', 'COLO', 'NEW '], dtype='object') \u8d4b\u503c\u7ed9 index \uff0c\u4fee\u6539DataFrame\u3002 data.index = data.index.map(transform) print(data) # one two three four # OHIO 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 \u521b\u5efa\u6570\u636e\u96c6\u8f6c\u6362\u540e\u7684\u7248\u672c\uff0c\u5e76\u4e14\u4e0d\u4fee\u6539\u539f\u6709\u7684\u6570\u636e\u96c6\uff0c\u4e00\u4e2a\u6709\u7528\u7684\u65b9\u6cd5\u662f rename \u3002 result = data.rename(index=str.title, columns=str.upper) print(result) # ONE TWO THREE FOUR # Ohio 0 1 2 3 # Colo 4 5 6 7 # New 8 9 10 11 print(data) # \u539f\u6709\u7684\u6570\u636e\u96c6\u672a\u88ab\u4fee\u6539 # one two three four # OHIO 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 rename \u53ef\u4ee5\u7ed3\u5408\u5b57\u5178\u578b\u5bf9\u8c61\u4f7f\u7528\uff0c\u4e3a\u8f74\u6807\u7b7e\u7684\u5b50\u96c6\u63d0\u4f9b\u65b0\u7684\u503c\u3002 result = data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'}) print(result) # one two peekaboo four # INDIANA 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 \u5982\u679c\u8981\u4fee\u6539\u539f\u6709\u7684\u6570\u636e\u96c6\uff0c\u4f20\u5165 inplace=True \u3002 data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'}, inplace=True) print(data) # one two peekaboo four # INDIANA 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 \u79bb\u6563\u5316\u548c\u5206\u7bb1 \u8fde\u7eed\u503c\u7ecf\u5e38\u9700\u8981\u79bb\u6563\u5316\uff0c\u6216\u8005\u5206\u79bb\u6210\u201d\u7bb1\u5b50\u201c\u8fdb\u884c\u5206\u6790\u3002 \u5047\u8bbe\u6709\u4e00\u7ec4\u4eba\u7fa4\u7684\u6570\u636e\uff0c\u60f3\u5c06\u4ed6\u4eec\u8fdb\u884c\u5206\u7ec4\uff0c\u653e\u5165\u79bb\u6563\u7684\u5e74\u9f84\u6846\u4e2d\u3002 ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32] \u5c06\u8fd9\u4e9b\u5e74\u9f84\u5206\u4e3a18\uff5e25\u300126\uff5e35\u300136\uff5e60\u4ee5\u53ca61\u53ca\u4ee5\u4e0a\u7b49\u82e5\u5e72\u7ec4\uff0c\u4f7f\u7528pandas\u4e2d\u7684 cut \u3002 bins = [18, 25, 35, 60, 100] cats = pd.cut(ages, bins) print(cats) # [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]] # Length: 12 # Categories (4, interval[int64, right]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]] pandas\u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u4e00\u4e2a\u7279\u6b8a\u7684 Categorical \u5bf9\u8c61\u3002 \u4f60\u770b\u5230\u7684\u8f93\u51fa\u63cf\u8ff0\u4e86\u7531 pandas.cut \u8ba1\u7b97\u51fa\u7684\u7bb1\u3002 \u4f60\u53ef\u4ee5\u5c06\u5b83\u5f53\u4f5c\u4e00\u4e2a\u8868\u793a\u7bb1\u540d\u7684\u5b57\u7b26\u4e32\u6570\u7ec4\uff1b\u5b83\u5728\u5185\u90e8\u5305\u542b\u4e00\u4e2a categories \uff08\u7c7b\u522b\uff09\u6570\u7ec4\uff0c\u5b83\u6307\u5b9a\u4e86\u4e0d\u540c\u7684\u7c7b\u522b\u540d\u79f0\u4ee5\u53ca codes \u5c5e\u6027\u4e2d\u7684 ages \uff08\u5e74\u9f84\uff09\u6570\u636e\u6807\u7b7e\u3002 print(cats.categories) # \u56db\u4e2a\u533a\u95f4\u7ec4 # IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]], dtype='interval[int64, right]') print(cats.codes) # 61\u5c81\u843d\u5728\u7b2c3\u7ec4\uff08\u7ec4\u7f16\u53f7\u4ece0\u5f00\u59cb\uff09 # [0 0 0 1 0 0 2 1 3 2 2 1] \u6ce8\u610f\uff0c pd.value_counts(cats) \u662f\u5bf9 pandas.cut \u7684\u7ed3\u679c\u4e2d\u7684\u7bb1\u6570\u91cf\u7684\u8ba1\u6570\u3002 result = pd.value_counts(cats) print(result) # (18, 25] 5 # (25, 35] 3 # (35, 60] 3 # (60, 100] 1 # dtype: int64 \u4e0e\u533a\u95f4\u7684\u6570\u5b66\u7b26\u53f7\u4e00\u81f4\uff0c\u5c0f\u62ec\u53f7\u8868\u793a\u8fb9\u662f\u5f00\u653e\u7684\uff0c\u4e2d\u62ec\u53f7\u8868\u793a\u5b83\u662f\u5c01\u95ed\u7684\uff08\u5305\u62ec\u8fb9\uff09\u3002\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012 right=False \u6765\u6539\u53d8\u54ea\u4e00\u8fb9\u662f\u5c01\u95ed\u7684\u3002\u9ed8\u8ba4 right=True \u3002 result = pd.cut(ages, [18, 26, 36, 61, 100], right=False) print(result) # [[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)] # Length: 12 # Categories (4, interval[int64, left]): [[18, 26) < [26, 36) < [36, 61) < [61, 100)] \u901a\u8fc7\u5411 labels \u9009\u9879\u4f20\u9012\u4e00\u4e2a\u5217\u8868\u6216\u6570\u7ec4\u6765\u4f20\u5165\u81ea\u5b9a\u4e49\u7684\u7bb1\u540d\u3002 group_name = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior'] result = pd.cut(ages, bins, labels=group_name) print(result) # ['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult'] # Length: 12 # Categories (4, object): ['Youth' < 'YoungAdult' < 'MiddleAged' < 'Senior'] result = pd.value_counts(pd.cut(ages, bins, labels=group_name)) # \u6807\u7b7e\u8f93\u51fa print(result) # Youth 5 # YoungAdult 3 # MiddleAged 3 # Senior 1 # dtype: int64 result = pd.value_counts(pd.cut(ages, bins)) # \u533a\u95f4\u8f93\u51fa print(result) # (18, 25] 5 # (25, 35] 3 # (35, 60] 3 # (60, 100] 1 # dtype: int64 \u5982\u679c\u4f20\u7ed9 cut \u6574\u6570\u4e2a\u7684\u7bb1\u6765\u4ee3\u66ff\u663e\u5f0f\u7684\u7bb1\u8fb9\uff0cpandas\u5c06\u6839\u636e\u6570\u636e\u4e2d\u7684\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c\u8ba1\u7b97\u51fa\u7b49\u957f\u7684\u7bb1\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u8003\u8651\u4e00\u4e9b\u5747\u5300\u5206\u5e03\u7684\u6570\u636e\u88ab\u5207\u6210\u56db\u4efd\u7684\u60c5\u51b5\u3002 data = np.random.rand(20) result = pd.cut(data, 4, precision=2) # precision=2\u7684\u9009\u9879\u5c06\u5341\u8fdb\u5236\u7cbe\u5ea6\u9650\u5236\u5728\u4e24\u4f4d\u3002 print(result) # [(0.44, 0.66], (0.0063, 0.23], (0.23, 0.44], (0.0063, 0.23], (0.23, 0.44], ..., (0.23, 0.44], (0.0063, 0.23], (0.23, 0.44], (0.66, 0.88], (0.23, 0.44]] # Length: 20 # Categories (4, interval[float64, right]): [(0.0063, 0.23] < (0.23, 0.44] < (0.44, 0.66] < (0.66, 0.88]] qcut \u662f\u4e00\u4e2a\u4e0e\u5206\u7bb1\u5bc6\u5207\u76f8\u5173\u7684\u51fd\u6570\uff0c\u5b83\u57fa\u4e8e\u6837\u672c\u5206\u4f4d\u6570\u8fdb\u884c\u5206\u7bb1\u3002 \u53d6\u51b3\u4e8e\u6570\u636e\u7684\u5206\u5e03\uff0c\u4f7f\u7528 cut \u901a\u5e38\u4e0d\u4f1a\u4f7f\u6bcf\u4e2a\u7bb1\u5177\u6709\u76f8\u540c\u6570\u636e\u91cf\u7684\u6570\u636e\u70b9\u3002 \u7531\u4e8eqcut\u4f7f\u7528\u6837\u672c\u7684\u5206\u4f4d\u6570\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7qcut\u83b7\u5f97\u7b49\u957f\u7684\u7bb1\u3002 data = np.random.randn(1000) # \u6b63\u6001\u5206\u5e03 cats = pd.qcut(data, 4) # \u5207\u62104\u4efd print(cats) # [(-0.00329, 0.644], (-0.00329, 0.644], (-0.659, -0.00329], (-0.659, -0.00329], (0.644, 3.468], ..., (0.644, 3.468], (-3.9619999999999997, -0.659], (-3.9619999999999997, -0.659], (-0.00329, 0.644], (-0.00329, 0.644]] # Length: 1000 # Categories (4, interval[float64, right]): [(-3.9619999999999997, -0.659] < (-0.659, -0.00329] < (-0.00329, 0.644] < (0.644, 3.468]] result = pd.value_counts(cats) print(result) # (-3.9619999999999997, -0.659] 250 # (-0.659, -0.00329] 250 # (-0.00329, 0.644] 250 # (0.644, 3.468] 250 # dtype: int64 \u4e0e cut \u7c7b\u4f3c\uff0c\u53ef\u4ee5\u4f20\u5165\u81ea\u5b9a\u4e49\u7684\u5206\u4f4d\u6570\uff080\u548c1\u4e4b\u95f4\u7684\u6570\u636e\uff0c\u5305\u62ec\u8fb9\uff09\u3002 result = pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]) print(result) # [(-0.00329, 1.234], (-0.00329, 1.234], (-1.321, -0.00329], (-1.321, -0.00329], (-0.00329, 1.234], ..., (-0.00329, 1.234], (-1.321, -0.00329], (-1.321, -0.00329], (-0.00329, 1.234], (-0.00329, 1.234]] # Length: 1000 # Categories (4, interval[float64, right]): [(-3.9619999999999997, -1.321] < (-1.321, -0.00329] < (-0.00329, 1.234] < (1.234, 3.468]] \u68c0\u6d4b\u548c\u8fc7\u6ee4\u5f02\u5e38\u503c \u8fc7\u6ee4\u6216\u8f6c\u6362\u5f02\u5e38\u503c\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u5e94\u7528\u6570\u7ec4\u64cd\u4f5c\u7684\u4e8b\u60c5\u3002 \u8003\u8651\u4e00\u4e2a\u5177\u6709\u6b63\u6001\u5206\u5e03\u6570\u636e\u7684DataFrame\u3002 data = pd.DataFrame(np.random.randn(1000, 4)) print(data.describe()) # 0 1 2 3 # count 1000.000000 1000.000000 1000.000000 1000.000000 # mean 0.008124 -0.008050 -0.013403 -0.008261 # std 0.979236 0.992982 0.998819 1.038760 # min -3.231914 -3.441270 -3.345210 -4.320565 # 25% -0.634801 -0.599852 -0.656481 -0.677611 # 50% -0.033252 0.000060 -0.040634 -0.015463 # 75% 0.649340 0.644312 0.678101 0.683849 # max 3.292099 2.758754 2.911447 3.371729 \u627e\u51fa\u4e00\u5217\u4e2d\u7edd\u5bf9\u503c\u5927\u4e8e\u4e09\u7684\u503c\u3002 col = data[2] result = col[np.abs(col) > 3] print(result) # 519 -3.035355 # 536 -3.345210 # Name: 2, dtype: float64 \u9009\u51fa\u6240\u6709\u503c\u5927\u4e8e3\u6216\u5c0f\u4e8e-3\u7684\u884c\uff0c\u53ef\u4ee5\u5bf9\u5e03\u5c14\u503cDataFrame\u4f7f\u7528 any \u65b9\u6cd5\u3002 result = data[(np.abs(data) > 3).any(1)] print(result) # 0 1 2 3 # 116 -0.080907 -3.441270 -0.163263 0.392800 # 139 -1.294440 1.828397 1.178897 -3.469466 # 241 -0.486292 0.150443 0.264172 -3.013440 # 295 3.292099 -0.339284 0.732829 -0.475202 # 355 0.307577 -3.053322 0.967497 0.896363 # 359 3.264981 -1.172096 0.207622 -0.281803 # 519 -0.448987 1.623843 -3.035355 -0.436833 # 533 -1.022616 -0.212597 1.030969 3.371729 # 536 1.067598 -1.306839 -3.345210 0.620834 # 541 -0.952760 -2.157970 -0.403199 -4.320565 # 690 0.006821 -3.104117 0.484881 -0.132613 # 750 -3.231914 1.017712 0.070430 0.631447 # 771 -3.007622 0.257960 -0.118179 -1.283365 # 976 1.684760 -0.003295 -0.249843 3.169371 \u6839\u636e\u8fd9\u4e9b\u6807\u51c6\u6765\u8bbe\u7f6e\u6765\u9650\u5b9a\u503c\uff0c\u4e0b\u9762\u4ee3\u7801\u9650\u5236\u4e86-3\u52303\u4e4b\u95f4\u7684\u6570\u503c\u3002 \u8bed\u53e5 np.sign(data) \u6839\u636e\u6570\u636e\u4e2d\u7684\u503c\u7684\u6b63\u8d1f\u5206\u522b\u751f\u62101\u548c-1\u7684\u6570\u503c\u3002 result = data[(np.abs(data) > 3)] = np.sign(data) * 3 print(result.describe()) # 0 1 2 3 # count 1000.000000 1000.000000 1000.000000 1000.000000 # mean -0.036000 0.000000 -0.084000 -0.048000 # std 3.001285 3.001501 3.000324 3.001117 # min -3.000000 -3.000000 -3.000000 -3.000000 # 25% -3.000000 -3.000000 -3.000000 -3.000000 # 50% -3.000000 0.000000 -3.000000 -3.000000 # 75% 3.000000 3.000000 3.000000 3.000000 # max 3.000000 3.000000 3.000000 3.000000 print(result.head()) # 0 1 2 3 # 0 -3.0 3.0 -3.0 -3.0 # 1 -3.0 -3.0 -3.0 -3.0 # 2 3.0 3.0 -3.0 3.0 # 3 3.0 -3.0 3.0 -3.0 # 4 3.0 -3.0 -3.0 -3.0 \u7f6e\u6362\u548c\u968f\u673a\u62bd\u6837 \u4f7f\u7528 numpy.random.permutation \u5bf9DataFrame\u4e2d\u7684Series\u6216\u884c\u8fdb\u884c\u7f6e\u6362\uff08\u968f\u673a\u91cd\u6392\u5e8f\uff09\u3002 \u5728\u8c03\u7528 permutation \u65f6\u6839\u636e\u4f60\u60f3\u8981\u7684\u8f74\u957f\u5ea6\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u8868\u793a\u65b0\u987a\u5e8f\u7684\u6574\u6570\u6570\u7ec4\u3002 df = pd.DataFrame(np.arange(5 * 4).reshape((5, 4))) sampler = np.random.permutation(5) print(sampler) # \u8fd4\u56dearray # [1 4 3 0 2] print(df) # 0 1 2 3 # 0 0 1 2 3 # 1 4 5 6 7 # 2 8 9 10 11 # 3 12 13 14 15 # 4 16 17 18 19 \u4e0a\u9762\u8fd4\u56de\u7684 sampler \u6574\u6570\u6570\u7ec4 [1 4 3 0 2] \u7528\u5728\u57fa\u4e8e iloc \u7684\u7d22\u5f15\u6216\u7b49\u4ef7\u7684 take \u51fd\u6570\u4e2d\uff0c\u91cd\u65b0\u6392\u5217\u884c\u987a\u5e8f\u3002 print(df.take(sampler)) # 0 1 2 3 # 1 4 5 6 7 # 4 16 17 18 19 # 3 12 13 14 15 # 0 0 1 2 3 # 2 8 9 10 11 \u9009\u51fa\u4e00\u4e2a\u4e0d\u542b\u6709\u66ff\u4ee3\u503c\u7684\u968f\u673a\u5b50\u96c6\uff0c\u53ef\u4ee5\u4f7f\u7528Series\u548cDataFrame\u7684 sample \u65b9\u6cd5\u3002 result = df.sample(n=3) print(result) # 0 1 2 3 # 0 0 1 2 3 # 2 8 9 10 11 # 1 4 5 6 7 \u8981\u751f\u6210\u4e00\u4e2a\u5e26\u6709\u66ff\u4ee3\u503c\u7684\u6837\u672c\uff08\u5141\u8bb8\u6709\u91cd\u590d\u9009\u62e9\uff09\uff0c\u5c06 replace=True \u4f20\u5165 sample \u65b9\u6cd5\u3002 choice = pd.Series([5, 7, -1, 6, 4]) draws = choice.sample(n=10, replace=True) print(choice) # 0 5 # 1 7 # 2 -1 # 3 6 # 4 4 # dtype: int64 print(draws) # 4 4 # 0 5 # 0 5 # 3 6 # 4 4 # 0 5 # 1 7 # 3 6 # 2 -1 # 0 5 # dtype: int64 \u8ba1\u7b97\u6307\u6807/\u865a\u62df\u53d8\u91cf \u5c06\u5206\u7c7b\u53d8\u91cf\u8f6c\u6362\u4e3a\u201c\u865a\u62df\u201d\u6216\u201c\u6307\u6807\u201d\u77e9\u9635\u662f\u53e6\u4e00\u79cd\u7528\u4e8e\u7edf\u8ba1\u5efa\u6a21\u6216\u673a\u5668\u5b66\u4e60\u7684\u8f6c\u6362\u64cd\u4f5c\u3002 \u5982\u679cDataFrame\u4e2d\u7684\u4e00\u5217\u6709 k \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u5219\u53ef\u4ee5\u884d\u751f\u4e00\u4e2a k \u5217\u7684\u503c\u4e3a 1 \u548c 0 \u7684\u77e9\u9635\u6216DataFrame\u3002 pandas\u6709\u4e00\u4e2aget_dummies\u51fd\u6570\u7528\u4e8e\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 df = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6) } ) print(df) # key data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 b 5 \u5728\u6307\u6807DataFrame\u7684\u5217\u4e0a\u52a0\u5165\u524d\u7f00\uff0c\u7136\u540e\u4e0e\u5176\u4ed6\u6570\u636e\u5408\u5e76\u3002\u5728 get_dummies \u65b9\u6cd5\u4e2d\u6709\u4e00\u4e2a\u524d\u7f00\u53c2\u6570\u7528\u4e8e\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 \u901a\u8fc7 get_dummies \u65b9\u6cd5\uff0c\u628a\u4e0a\u9762 df \u6570\u636e\u6309\u7167 key \u8fdb\u884c\u4e86\u5206\u7ec4\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u5217\u6765\u5c55\u73b0\u5206\u7ec4\u540e\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u4f8b\u5982\uff0c key \u5217\u7684 a \uff0c\u5bf9\u5e94\u503c 2 \u548c 4 \u3002 dummies = pd.get_dummies(df['key'], prefix='key') print(dummies) # key_a key_b key_c # 0 0 1 0 # 1 0 1 0 # 2 1 0 0 # 3 0 0 1 # 4 1 0 0 # 5 0 1 0 df_with_dummy = df[['data1']].join(dummies) print(df_with_dummy) # data1 key_a key_b key_c # 0 0 0 1 0 # 1 1 0 1 0 # 2 2 1 0 0 # 3 3 0 0 1 # 4 4 1 0 0 # 5 5 0 1 0 \u66f4\u4e3a\u590d\u6742\u7684\u60c5\u51b5\uff0cDataFrame\u4e2d\u7684\u4e00\u884c\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b\u3002 \u4ee5MovieLens\u76841M\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\u589e\u52a0\u53c2\u6570 encoding='unicode_escape' \u907f\u514d\u51fa\u73b0\u4e0b\u9762\u7684\u9519\u8bef\uff1a UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 3114: invalid continuation byte \u589e\u52a0\u53c2\u6570 engine='python' \u907f\u514d\u51fa\u73b0\u4e0b\u9762\u7684\u9519\u8bef\uff1a ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'. mnames = ['movie_id', 'title', 'genres'] movies = pd.read_table( '../datasets/movielens/movies.dat', sep='::', header=None, names=mnames, encoding='unicode_escape', engine='python' ) print(movies[:10]) # movie_id title genres # 0 1 Toy Story (1995) Animation|Children's|Comedy # 1 2 Jumanji (1995) Adventure|Children's|Fantasy # 2 3 Grumpier Old Men (1995) Comedy|Romance # 3 4 Waiting to Exhale (1995) Comedy|Drama # 4 5 Father of the Bride Part II (1995) Comedy # 5 6 Heat (1995) Action|Crime|Thriller # 6 7 Sabrina (1995) Comedy|Romance # 7 8 Tom and Huck (1995) Adventure|Children's # 8 9 Sudden Death (1995) Action # 9 10 GoldenEye (1995) Action|Adventure|Thriller \u4e3a\u6bcf\u4e2a\u7535\u5f71\u6d41\u6d3e\u6dfb\u52a0\u6307\u6807\u53d8\u91cf\u9700\u8981\u8fdb\u884c\u4e00\u4e9b\u6570\u636e\u5904\u7406\u3002 \u9996\u5148\uff0c\u6211\u4eec\u4ece\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u51fa\u6240\u6709\u4e0d\u540c\u7684\u6d41\u6d3e\u7684\u5217\u8868\u3002 all_genres = [] for x in movies.genres: all_genres.extend(x.split('|')) genres = pd.unique(all_genres) print(genres) # ['Animation' \"Children's\" 'Comedy' 'Adventure' 'Fantasy' 'Romance' 'Drama' # 'Action' 'Crime' 'Thriller' 'Horror' 'Sci-Fi' 'Documentary' 'War' # 'Musical' 'Mystery' 'Film-Noir' 'Western'] \u4f7f\u7528\u51680\u7684DataFrame\u662f\u6784\u5efa\u6307\u6807DataFrame\u7684\u4e00\u79cd\u65b9\u5f0f\u3002 zero_matrix = np.zeros((len(movies), len(genres))) dummies = pd.DataFrame(zero_matrix, columns=genres) print(zero_matrix) # [[0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # ... # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.]] print(dummies.head(n=10)) # Animation Children's Comedy ... Mystery Film-Noir Western # 0 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 1 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 2 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 3 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 4 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 5 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 6 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 7 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 8 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 9 0.0 0.0 0.0 ... 0.0 0.0 0.0 # # [10 rows x 18 columns] \u904d\u5386\u6bcf\u4e00\u90e8\u7535\u5f71\uff0c\u5c06 dummies \u6bcf\u4e00\u884c\u7684\u6761\u76ee\u8bbe\u7f6e\u4e3a 1 \u3002\u4f7f\u7528 dummies.columns \u6765\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u6d41\u6d3e\u7684\u5217\u6307\u6807\u3002 gen = movies.genres[0] print(gen.split('|')) # ['Animation', \"Children's\", 'Comedy'] result = dummies.columns.get_indexer(gen.split('|')) print(result) # [0 1 2] \u4f7f\u7528 .loc \u6839\u636e\u8fd9\u4e9b\u6307\u6807\u6765\u8bbe\u7f6e\u503c\u3002 for i, gen in enumerate(movies.genres): indices = dummies.columns.get_indexer(gen.split('|')) dummies.iloc[i, indices] = 1 \u5c06\u7ed3\u679c\u4e0e movies \u8fdb\u884c\u5408\u5e76\u3002 movies_windic = movies.join(dummies.add_prefix('Genre_')) print(movies_windic.iloc[0]) # movie_id 1 # title Toy Story (1995) # genres Animation|Children's|Comedy # Genre_Animation 1.0 # Genre_Children's 1.0 # Genre_Comedy 1.0 # Genre_Adventure 0.0 # Genre_Fantasy 0.0 # Genre_Romance 0.0 # Genre_Drama 0.0 # Genre_Action 0.0 # Genre_Crime 0.0 # Genre_Thriller 0.0 # Genre_Horror 0.0 # Genre_Sci-Fi 0.0 # Genre_Documentary 0.0 # Genre_War 0.0 # Genre_Musical 0.0 # Genre_Mystery 0.0 # Genre_Film-Noir 0.0 # Genre_Western 0.0 # Name: 0, dtype: object \u5bf9\u4e8e\u66f4\u5927\u7684\u6570\u636e\uff0c\u4e0a\u9762\u8fd9\u79cd\u4f7f\u7528\u591a\u6210\u5458\u6784\u5efa\u6307\u6807\u53d8\u91cf\u5e76\u4e0d\u662f\u7279\u522b\u5feb\u901f\u3002 \u66f4\u597d\u7684\u65b9\u6cd5\u662f\u5199\u4e00\u4e2a\u76f4\u63a5\u5c06\u6570\u636e\u5199\u4e3aNumPy\u6570\u7ec4\u7684\u5e95\u5c42\u51fd\u6570\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u5c01\u88c5\u8fdbDataFrame\u3002 \u5c06 get_dummies \u4e0e cut \u7b49\u79bb\u6563\u5316\u51fd\u6570\u7ed3\u5408\u4f7f\u7528\u662f\u7edf\u8ba1\u5e94\u7528\u7684\u4e00\u4e2a\u6709\u7528\u65b9\u6cd5\u3002 np.random.seed(12345) # \u4f7f\u7528numpy.random.seed\u6765\u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\u4ee5\u786e\u4fdd\u793a\u4f8b\u7684\u786e\u5b9a\u6027 values = np.random.rand(10) print(values) # [0.92961609 0.31637555 0.18391881 0.20456028 0.56772503 0.5955447 # 0.96451452 0.6531771 0.74890664 0.65356987] bins = [0, 0.2, 0.4, 0.6, 0.8, 1] result = pd.get_dummies(pd.cut(values, bins)) print(result) # (0.0, 0.2] (0.2, 0.4] (0.4, 0.6] (0.6, 0.8] (0.8, 1.0] # 0 0 0 0 0 1 # 1 0 1 0 0 0 # 2 1 0 0 0 0 # 3 0 1 0 0 0 # 4 0 0 1 0 0 # 5 0 0 1 0 0 # 6 0 0 0 0 1 # 7 0 0 0 1 0 # 8 0 0 0 1 0 # 9 0 0 0 1 0 \u5b57\u7b26\u4e32\u64cd\u4f5c import re pandas\u5141\u8bb8\u5c06\u5b57\u7b26\u4e32\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u7b80\u6d01\u5730\u5e94\u7528\u5230\u6574\u4e2a\u6570\u636e\u6570\u7ec4\u4e0a\uff0c\u6b64\u5916\u8fd8\u80fd\u5904\u7406\u6570\u636e\u7f3a\u5931\u3002 \u5b57\u7b26\u4e32\u5bf9\u8c61\u65b9\u6cd5 \u5b57\u4e32\u62c6\u5206\u5408\u5e76\u65b9\u6cd5\u3002\u5728\u5f88\u591a\u5b57\u7b26\u4e32\u5904\u7406\u548c\u811a\u672c\u5e94\u7528\u4e2d\uff0c\u5185\u5efa\u7684\u5b57\u7b26\u4e32\u65b9\u6cd5\u662f\u8db3\u591f\u7684\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u9017\u53f7\u5206\u9694\u7684\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f7f\u7528split\u65b9\u6cd5\u62c6\u5206\u6210\u591a\u5757\u3002 import numpy as np import pandas as pd val = 'a, b, guido' result = val.split(',') print(result) # ['a', ' b', ' guido'] count \uff1a\u8fd4\u56de\u5b50\u5b57\u7b26\u4e32\u5728\u5b57\u7b26\u4e32\u4e2d\u7684\u975e\u91cd\u53e0\u51fa\u73b0\u6b21\u6570\u3002 result = val.count(',') print(result) # 2 endswith \uff1a\u5982\u679c\u5b57\u7b26\u4e32\u4ee5\u540e\u7f00\u7ed3\u5c3e\u5219\u8fd4\u56de True \u3002 startswith \uff1a\u5982\u679c\u5b57\u7b26\u4e32\u4ee5\u540e\u7f00\u7ed3\u5c3e\u5219\u8fd4\u56de True \u3002 result = val.endswith('b') print(result) # False result = val.endswith('o') print(result) # True result = val.startswith('a') print(result) # True split \u5e38\u548c strip \u4e00\u8d77\u4f7f\u7528\uff0c\u7528\u4e8e\u6e05\u9664\u7a7a\u683c\uff08\u5305\u62ec\u6362\u884c\uff09\u3002 split \uff1a\u4f7f\u7528\u5206\u9694\u7b26\u8bb2\u5b57\u7b26\u4e32\u62c6\u5206\u6210\u5b50\u5b57\u7b26\u4e32\u7684\u5217\u8868\u3002 strip \uff0c rstrip \uff0c lstrip \uff1a\u4fee\u526a\u7a7a\u767d\uff0c\u5305\u62ec\u6362\u884c\u7b26\uff1b\u76f8\u5f53\u4e8e\u5bf9\u6bcf\u4e2a\u5143\u7d20\u8fdb\u884c x.strip() (\u4ee5\u53ca rstrip \uff0c lstrip )\u3002 pieces = [x.strip() for x in val.split(',')] print(pieces) # ['a', 'b', 'guido'] \u8fd9\u4e9b\u5b50\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f7f\u7528\u52a0\u6cd5\u4e0e\u4e24\u4e2a\u5192\u53f7\u5206\u9694\u7b26\u8fde\u63a5\u5728\u4e00\u8d77\u3002 first, second, third = pieces result = first + '::' + second + '::' + third print(result) # a::b::guido \u4f46\u662f\u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u901a\u7528\u65b9\u6cd5\u3002 \u5728\u5b57\u7b26\u4e32 ': :' \u7684 join \u65b9\u6cd5\u4e2d\u4f20\u5165\u4e00\u4e2a\u5217\u8868\u6216\u5143\u7ec4\u662f\u4e00\u79cd\u66f4\u5feb\u4e14\u66f4\u52a0Pythonic\uff08Python\u98ce\u683c\u5316\uff09\u7684\u65b9\u6cd5\u3002 join : \u4f7f\u7528\u5b57\u7b26\u4e32\u5ea7\u4f4d\u95f4\u9694\u7b26\uff0c\u7528\u4e8e\u7c98\u5408\u5176\u4ed6\u5b57\u7b26\u4e32\u7684\u5e8f\u5217\u3002 result = '::'.join(pieces) print(result) # a::b::guido \u5b9a\u4f4d\u5b50\u5b57\u7b26\u4e32\u7684\u65b9\u6cd5\u3002 \u4f7f\u7528Python\u7684 in \u5173\u952e\u5b57\u662f\u68c0\u6d4b\u5b50\u5b57\u7b26\u4e32\u7684\u6700\u4f73\u65b9\u6cd5\uff0c\u5c3d\u7ba1 index \u548c find \u4e5f\u80fd\u5b9e\u73b0\u540c\u6837\u7684\u529f\u80fd\u3002 result = 'guido' in val print(result) # True index \uff1a\u5982\u679c\u5728\u5b57\u7b26\u4e32\u4e2d\u627e\u5230\uff0c\u5219\u8fd4\u56de\u5b50\u5b57\u7b26\u4e32\u4e2d\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u627e\u4e0d\u5230\u5219\u89e6\u53d1\u4e00\u4e2a ValueError \u3002 find \uff1a\u8fd4\u56de\u5b57\u7b26\u4e32\u4e2d\u7b2c\u4e00\u4e2a\u51fa\u73b0\u5b50\u5b57\u7b26\u7684\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u7c7b\u4f3c index \uff0c\u5982\u679c\u6ca1\u6709\u627e\u5230\uff0c\u5219\u8fd4\u56de -1 \u3002 rfind \uff1a\u8fd4\u56de\u5b57\u7b26\u4e32\u4e2d\u5b50\u5b57\u7b26\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u65f6\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u627e\u5230\uff0c\u5219\u8fd4\u56de -1 \u3002 result = val.index(',') print(result) # 1 result = val.find(',') print(result) # 1 # result = val.index(':') print(result) # ValueError: substring not found result = val.find(':') print(result) # -1 result = val.rfind(',') print(result) # 4 replace \u5c06\u7528\u4e00\u79cd\u6a21\u5f0f\u66ff\u4ee3\u53e6\u4e00\u79cd\u6a21\u5f0f\u3002\u5b83\u4e5f\u7528\u4e8e\u4f20\u5165\u7a7a\u5b57\u7b26\u4e32\u6765\u5220\u9664\u67d0\u4e2a\u6a21\u5f0f\u3002 result = val.replace(',', '::') print(result) # a:: b:: guido result = val.replace(', ', '') print(result) # abguido result = val.replace(',', '') print(result) # a b guido lower \uff1a\u5c06\u5927\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 upper \uff1a\u5c06\u5c0f\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 uppers = val.upper() print(uppers) # A, B, GUIDO casefold \uff1a\u548c lower \u7c7b\u4f3c\uff0c\u5c06\u5b57\u7b26\u4e32\u4e2d\u7684\u5143\u7d20\u53d8\u6210\u5c0f\u5199\uff0c lower \u51fd\u6570\u53ea\u652f\u6301 ascill \u8868\u4e2d\u7684\u5b57\u7b26\uff0c casefold \u652f\u6301\u5f88\u591a\u4e0d\u540c\u79cd\u7c7b\u7684\u8bed\u8a00\u3002 str1 = \"Jan Wei\u03b2@cN\u4e0a\u6d77\" result = str1.casefold() print(result) # jan wei\u03b2@cn\u4e0a\u6d77 result = str1.lower() print(result) # jan wei\u03b2@cn\u4e0a\u6d77 ljust \uff0c rjust \uff1a\u5de6\u5bf9\u9f50\u6216\u8005\u53f3\u5bf9\u9f50\uff1b\u7528\u7a7a\u683c\u6216\u8005\u5176\u5b83\u4e00\u4e9b\u5b57\u7b26\u586b\u5145\u5b57\u7b26\u4e32\u7684\u76f8\u53cd\u4fa7\uff0c\u4ee5\u8fd4\u56de\u5177\u6709\u6700\u5c0f\u5bbd\u5ea6\u7684\u5b57\u7b26\u4e32 str1 = 'https://docs.python.org/3/' str2 = 'https://packagehub.suse.com/package-categories/python/' print(str1.ljust(60, '*')) print(str2.ljust(60, '*')) # https://docs.python.org/3/********************************** # https://packagehub.suse.com/package-categories/python/****** print(str1.rjust(60, '*')) print(str2.rjust(60, '*')) # **********************************https://docs.python.org/3/ # ******https://packagehub.suse.com/package-categories/python/ print(str1.rjust(60)) print(str2.rjust(60)) \u6b63\u5219\u8868\u8fbe\u5f0f Python\u5185\u5efa\u7684 re \u6a21\u5757\u662f\u7528\u4e8e\u5c06\u6b63\u5219\u8868\u8fbe\u5f0f\u5e94\u7528\u5230\u5b57\u7b26\u4e32\u4e0a\u7684\u5e93\u3002 re \u6a21\u5757\u4e3b\u8981\u6709\u4e09\u4e2a\u4e3b\u9898\uff1a\u6a21\u5f0f\u5339\u914d\u3001\u66ff\u4ee3\u3001\u62c6\u5206\u3002 \u770b\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u5c06\u542b\u6709\u591a\u79cd\u7a7a\u767d\u5b57\u7b26\uff08\u5236\u8868\u7b26\u3001\u7a7a\u683c\u3001\u6362\u884c\u7b26\uff09\u7684\u5b57\u7b26\u4e32\u62c6\u5206\u5f00\u3002 \u63cf\u8ff0\u4e00\u4e2a\u6216\u591a\u4e2a\u7a7a\u767d\u5b57\u7b26\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u662f \\s+ \u3002 \u5f53\u8c03\u7528 re.split('\\s+', text) \uff0c\u6b63\u5219\u8868\u8fbe\u5f0f\u9996\u5148\u4f1a\u88ab\u7f16\u8bd1\uff0c\u7136\u540e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684 split \u65b9\u6cd5\u5728\u4f20\u5165\u6587\u672c\u4e0a\u88ab\u8c03\u7528\u3002 text = \"foo bar\\t baz \\tqux\" result = re.split('\\s+', text) print(result) # ['foo', 'bar', 'baz', 'qux'] \u53ef\u4ee5\u4f7f\u7528 re.compile \u81ea\u884c\u7f16\u8bd1\uff0c\u5f62\u6210\u4e00\u4e2a\u53ef\u590d\u7528\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u8c61\u3002 regex = re.compile('\\s+') result = regex.split(text) print(result) # ['foo', 'bar', 'baz', 'qux'] \u5982\u679c\u60f3\u83b7\u5f97\u7684\u662f\u4e00\u4e2a\u6240\u6709\u5339\u914d\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6a21\u5f0f\u7684\u5217\u8868\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 findall \u65b9\u6cd5\u3002 result = regex.findall(text) print(result) # [' ', '\\t ', ' \\t'] \u4e3a\u4e86\u5728\u6b63\u5219\u8868\u8fbe\u5f0f\u4e2d\u907f\u514d\u8f6c\u4e49\u7b26 \\ \u7684\u5f71\u54cd\uff0c\u53ef\u4ee5\u4f7f\u7528\u539f\u751f\u5b57\u7b26\u4e32\u8bed\u6cd5\uff0c\u6bd4\u5982 r'C:\\x' \u6216\u8005\u7528\u7b49\u4ef7\u7684 'C:\\\\x'\\ \u3002 \u5982\u679c\u9700\u8981\u5c06\u76f8\u540c\u7684\u8868\u8fbe\u5f0f\u5e94\u7528\u5230\u591a\u4e2a\u5b57\u7b26\u4e32\u4e0a\uff0c\u63a8\u8350\u4f7f\u7528 re.compile \u521b\u5efa\u4e00\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u8c61\uff0c\u8fd9\u6837\u505a\u6709\u5229\u4e8e\u8282\u7ea6CPU\u5468\u671f\u3002 match \u548c search \u4e0e findall \u76f8\u5173\u6027\u5f88\u5927\u3002 findall \u8fd4\u56de\u7684\u662f\u5b57\u7b26\u4e32\u4e2d\u6240\u6709\u7684\u5339\u914d\u9879\uff0c\u800c search \u8fd4\u56de\u7684\u4ec5\u4ec5\u662f\u7b2c\u4e00\u4e2a\u5339\u914d\u9879\u3002 match \u66f4\u4e3a\u4e25\u683c\uff0c\u5b83\u53ea\u5728\u5b57\u7b26\u4e32\u7684\u8d77\u59cb\u4f4d\u7f6e\u8fdb\u884c\u5339\u914d\u3002 text = \"\"\"Dave dave@google.com Steve steve@gmail.com Rob rob@gmail.com Ryan ryan@yahoo.com \"\"\" pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}' regex = re.compile(pattern, flags=re.IGNORECASE) # flags=re.IGNORECASE \u4f7f\u6b63\u5219\u8868\u8fbe\u5f0f\u4e0d\u533a\u5206\u5927\u5c0f\u5199 m = regex.findall(text) # findall\u4f1a\u751f\u6210\u4e00\u4e2a\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u7684\u5217\u8868 print(m) # ['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com'] search \u8fd4\u56de\u7684\u662f\u6587\u672c\u4e2d\u7b2c\u4e00\u4e2a\u5339\u914d\u5230\u7684\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u3002 \u5bf9\u4e8e\u524d\u9762\u63d0\u5230\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u5339\u914d\u5bf9\u8c61\u53ea\u80fd\u544a\u8bc9\u6211\u4eec\u6a21\u5f0f\u5728\u5b57\u7b26\u4e32\u4e2d\u8d77\u59cb\u548c\u7ed3\u675f\u7684\u4f4d\u7f6e\u3002 m = regex.search(text) print(m) # <re.Match object; span=(5, 20), match='dave@google.com'> print(text[m.start():m.end()]) # dave@google.com regex.match \u53ea\u5728\u6a21\u5f0f\u51fa\u73b0\u4e8e\u5b57\u7b26\u4e32\u8d77\u59cb\u4f4d\u7f6e\u65f6\u8fdb\u884c\u5339\u914d\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u5230\uff0c\u8fd4\u56de None \u3002 m = regex.match(text) print(m) # None m = regex.match('rob@gmail.com') print(m) # <re.Match object; span=(0, 13), match='rob@gmail.com'> print(m.group()) # rob@gmail.com print(m.groups()) # () regex.sub \u4f1a\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5b57\u7b26\u4e32\uff0c\u539f\u5b57\u7b26\u4e32\u4e2d\u7684\u6a21\u5f0f\u4f1a\u88ab\u4e00\u4e2a\u65b0\u7684\u5b57\u7b26\u4e32\u66ff\u4ee3\u3002 m = regex.sub('REDACTED', text) print(m) # Dave REDACTED # Steve REDACTED # Rob REDACTED # Ryan REDACTED \u67e5\u627e\u7535\u5b50\u90ae\u4ef6\u5730\u5740\uff0c\u5e76\u5c06\u6bcf\u4e2a\u5730\u5740\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u7528\u6237\u540d\uff0c\u57df\u540d\u548c\u57df\u540d\u540e\u7f00\u3002\u8981\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u53ef\u4ee5\u7528\u62ec\u53f7\u5c06 pattern \u5305\u8d77\u6765\u3002 \u4fee\u6539\u540e\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u4ea7\u751f\u7684\u5339\u914d\u5bf9\u8c61\u7684 groups \u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u6a21\u5f0f\u7ec4\u4ef6\u7684\u5143\u7ec4\u3002 text = \"\"\"Dave dave@google.com Steve steve@gmail.com Rob rob@gmail.com Ryan ryan@yahoo.com \"\"\" pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})' regex = re.compile(pattern, flags=re.IGNORECASE) m = regex.findall(text) # \u5f53pattern\u53ef\u4ee5\u5206\u7ec4\u65f6\uff0cfindall\u8fd4\u56de\u7684\u662f\u5305\u542b\u5143\u7ec4\u7684\u5217\u8868 print(m) # [('dave', 'google', 'com'), ('steve', 'gmail', 'com'), ('rob', 'gmail', 'com'), ('ryan', 'yahoo', 'com')] m = regex.search(text) print(m) # <re.Match object; span=(5, 20), match='dave@google.com'> print(text[m.start():m.end()]) # dave@google.com m = regex.match('rob@gmail.com') print(m) # <re.Match object; span=(0, 13), match='rob@gmail.com'> print(m.group()) # rob@gmail.com print(m.groups()) # ('rob', 'gmail', 'com') m = regex.sub('REDACTED', text) print(m) # Dave REDACTED # Steve REDACTED # Rob REDACTED # Ryan REDACTED m = regex.sub(r'Username: \\1, Domain: \\2, Suffix: \\3', text) print(m) # Dave Username: dave, Domain: google, Suffix: com # Steve Username: steve, Domain: gmail, Suffix: com # Rob Username: rob, Domain: gmail, Suffix: com # Ryan Username: ryan, Domain: yahoo, Suffix: com pandas\u4e2d\u7684\u5411\u91cf\u5316\u5b57\u7b26\u4e32\u51fd\u6570 \u6e05\u7406\u6742\u4e71\u7684\u6570\u636e\u96c6\u7528\u4e8e\u5206\u6790\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u5b57\u7b26\u4e32\u5904\u7406\u548c\u6b63\u5219\u5316\u3002 data = { 'Dave': 'dave@gmail.com', 'Steve': 'steve@gmail.com', 'Rob': 'rob@gmail.com', 'Wes': np.nan } data = pd.Series(data) print(data) # Dave dave@gmail.com # Steve steve@gmail.com # Rob rob@gmail.com # Wes NaN # dtype: object print(data.isnull()) # Dave False # Steve False # Rob False # Wes True # dtype: bool \u53ef\u4ee5\u4f7f\u7528 data.map \u5c06\u5b57\u7b26\u4e32\u548c\u6709\u6548\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u65b9\u6cd5\uff08\u4ee5 lambda \u6216\u5176\u4ed6\u51fd\u6570\u7684\u65b9\u5f0f\u4f20\u9012\uff09\u5e94\u7528\u5230\u6bcf\u4e2a\u503c\u4e0a\uff0c\u4f46\u662f\u5728 NA \uff08 null \uff09\u503c\u4e0a\u4f1a\u5931\u8d25\u3002 \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0cSeries\u6709\u9762\u5411\u6570\u7ec4\u7684\u65b9\u6cd5\u7528\u4e8e\u8df3\u8fc7 NA \u503c\u7684\u5b57\u7b26\u4e32\u64cd\u4f5c\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u8fc7Series\u7684 str \u5c5e\u6027\u8fdb\u884c\u8c03\u7528\u3002 \u4f8b\u5982\uff0c\u53ef\u4ee5\u901a\u8fc7 str.contains \u6765\u68c0\u67e5\u6bcf\u4e2a\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u662f\u5426\u542b\u6709 'gmail' \u3002 m = data.str.contains('gmail') print(m) # Dave True # Steve True # Rob True # Wes NaN # dtype: object \u6b63\u5219\u8868\u8fbe\u5f0f\u4e5f\u53ef\u4ee5\u7ed3\u5408\u4efb\u610f\u7684 re \u6a21\u5757\u9009\u9879\u4f7f\u7528\uff0c\u4f8b\u5982 IGNORECASE \u3002 print(pattern) # ([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4}) m = data.str.findall(pattern, flags=re.IGNORECASE) print(m) # Dave [(dave, gmail, com)] # Steve [(steve, gmail, com)] # Rob [(rob, gmail, com)] # Wes NaN # dtype: object \u4f7f\u7528 str.get \u6216\u5728 str \u5c5e\u6027\u5185\u90e8\u7d22\u5f15\uff0c\u8fdb\u884c\u5411\u91cf\u5316\u7684\u5143\u7d20\u68c0\u7d22\u3002 m = data.str.match(pattern, flags=re.IGNORECASE) print(m) # Dave True # Steve True # Rob True # Wes NaN # dtype: object m = data.str.findall(pattern, flags=re.IGNORECASE) print(m.str.get(1)) # Dave NaN # Steve NaN # Rob NaN # Wes NaN # dtype: float64 print(m.str[0]) # Dave (dave, gmail, com) # Steve (steve, gmail, com) # Rob (rob, gmail, com) # Wes NaN # dtype: object \u4f7f\u7528\u5b57\u7b26\u4e32\u5207\u7247\u7684\u7c7b\u4f3c\u8bed\u6cd5\u8fdb\u884c\u5411\u91cf\u5316\u5207\u7247\u3002 print(data.str[:]) # Dave dave@gmail.com # Steve steve@gmail.com # Rob rob@gmail.com # Wes NaN # dtype: object print(data.str[:5]) # Dave dave@ # Steve steve # Rob rob@g # Wes NaN # dtype: object","title":"\u6570\u636e\u6e05\u6d17\u4e0e\u51c6\u5907"},{"location":"python/DataAnalysis/ch04/#_1","text":"","title":"\u6570\u636e\u6e05\u6d17\u4e0e\u51c6\u5907"},{"location":"python/DataAnalysis/ch04/#_2","text":"import pandas as pd import numpy as np from numpy import nan as NA \u5bf9\u4e8e\u6570\u503c\u578b\u6570\u636e\uff0cpandas\u4f7f\u7528\u6d6e\u70b9\u503c NaN \uff08Not a Number\u6765\u8868\u793a\u7f3a\u5931\u503c\uff09\u3002 \u5728pandas\u4e2d\uff0c\u91c7\u7528\u4e86R\u8bed\u8a00\u4e2d\u7684\u7f16\u7a0b\u60ef\u4f8b\uff0c\u5c06\u7f3a\u5931\u503c\u6210\u4e3a NA \uff0c\u610f\u601d\u662fnotavailable\uff08\u4e0d\u53ef\u7528\uff09\u3002 Python\u5185\u5efa\u7684 None \u503c\u5728\u5bf9\u8c61\u6570\u7ec4\u4e2d\u4e5f\u88ab\u5f53\u4f5c NA \u5904\u7406\u3002 NA\u5904\u7406\u65b9\u6cd5\uff1a dropna :\u6839\u636e\u6bcf\u4e2a\u6807\u7b7e\u7684\u503c\u662f\u5426\u662f\u786e\u5b9e\u6570\u636e\u6765\u7b5b\u9009\u8f74\u6807\u7b7e\uff0c\u5e76\u6839\u636e\u5141\u8bb8\u4e22\u5931\u7684\u6570\u636e\u91cf\u6765\u786e\u5b9a\u9608\u503c fillna :\u7528\u67d0\u4e9b\u503c\u586b\u5145\u786e\u5b9e\u7684\u6570\u636e\u6216\u4f7f\u7528\u63d2\u503c\u65b9\u6cd5\uff0c\u5982 ffill \u6216 bfill isnull :\u8fd4\u56de\u8868\u660e\u54ea\u4e9b\u503c\u662f\u7f3a\u5931\u503c\u7684\u5e03\u5c14\u503c notnull :\u662f isnull \u7684\u53cd\u51fd\u6570 string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado']) print(string_data) # 0 aardvark # 1 artichoke # 2 NaN # 3 avocado # dtype: object print(string_data.isnull()) # 0 False # 1 False # 2 True # 3 False # dtype: bool string_data[0] = None print(string_data.isnull()) # 0 True # 1 False # 2 True # 3 False # dtype: bool","title":"\u5904\u7406\u7f3a\u5931\u503c"},{"location":"python/DataAnalysis/ch04/#_3","text":"","title":"\u8fc7\u6ee4\u7f3a\u5931\u503c"},{"location":"python/DataAnalysis/ch04/#series","text":"\u5728Series\u4e0a\u4f7f\u7528 dropna \uff0c\u5b83\u4f1a\u8fd4\u56deSeries\u4e2d\u6240\u6709\u7684\u975e\u7a7a\u6570\u636e\u53ca\u5176\u7d22\u5f15\u503c\u3002 data = pd.Series([1, NA, 3.5, NA, 7]) print(data.dropna()) # 0 1.0 # 2 3.5 # 4 7.0 # dtype: float64 print(data[data.notnull()]) # \u4e0e\u4e0a\u9762\u7b49\u4ef7 # 0 1.0 # 2 3.5 # 4 7.0 # dtype: float64","title":"\u5904\u7406Series"},{"location":"python/DataAnalysis/ch04/#dataframe","text":"data = pd.DataFrame( [[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]] ) print(data) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.5 3.0 cleaned = data.dropna() # dropna\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4f1a\u5220\u9664\u5305\u542b\u7f3a\u5931\u503c\u7684\u884c print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 cleaned = data.dropna(how='all') # \u4f20\u5165how='all\u2019\u65f6\uff0c\u5c06\u5220\u9664\u6240\u6709\u503c\u5747\u4e3aNA\u7684\u884c print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 3 NaN 6.5 3.0 data[4] = NA print(data) # 0 1 2 4 # 0 1.0 6.5 3.0 NaN # 1 1.0 NaN NaN NaN # 2 NaN NaN NaN NaN # 3 NaN 6.5 3.0 NaN cleaned = data.dropna(axis=1, how='all') # \u5220\u9664\u5168NA\u7684\u5217 print(cleaned) # 0 1 2 # 0 1.0 6.5 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.5 3.0 df = pd.DataFrame(np.random.randn(7, 3)) print(df) # 0 1 2 # 0 -1.069771 -0.777921 0.181956 # 1 -0.399504 -0.641737 -0.946327 # 2 -1.013920 -0.247588 -0.760146 # 3 1.076946 -1.263203 0.494077 # 4 0.460985 -1.241870 0.283006 # 5 1.168149 1.033752 0.900095 # 6 -1.208514 -1.049546 -0.783680 df.iloc[:4, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[:2, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 -1.069771 NaN NaN # 1 -0.399504 NaN NaN # 2 -1.013920 NaN -0.760146 # 3 1.076946 NaN 0.494077 # 4 0.460985 -1.241870 0.283006 # 5 1.168149 1.033752 0.900095 # 6 -1.208514 -1.049546 -0.783680 cleaned = df.dropna() print(cleaned) # 0 1 2 # 4 0.033663 0.291886 0.736448 # 5 -0.433380 0.397104 1.252005 # 6 -1.999018 0.303866 1.430109 cleaned = df.dropna(thresh=2) # \u4fdd\u75592\u884c\u542bNA\u7684\u89c2\u5bdf\u503c print(cleaned) # 0 1 2 # 2 -1.413976 NaN 0.222274 # 3 -0.644266 NaN 0.324180 # 4 -0.122160 -2.244880 -0.406562 # 5 -0.140326 0.101133 -0.764048 # 6 -1.809141 0.139091 -0.819175","title":"\u5904\u7406DataFrame"},{"location":"python/DataAnalysis/ch04/#_4","text":"fillna \u51fd\u6570\u53c2\u6570\uff1a value\uff1a\u6807\u91cf\u503c\u6216\u5b57\u5178\u578b\u5bf9\u8c61\u7528\u4e8e\u586b\u5145\u7f3a\u5931\u503c method\uff1a\u63d2\u503c\u65b9\u6cd5\uff0c\u5982\u679c\u6ca1\u6709\u5176\u4ed6\u53c2\u6570\uff0c\u9ed8\u8ba4\u662f'ffill' axis\uff1a\u9700\u8981\u586b\u5145\u7684\u8f74\uff0c\u9ed8\u8ba4axis=0 inplace\uff1a\u4fee\u6539\u88ab\u8c03\u7528\u5bf9\u8c61\uff0c\u800c\u4e0d\u662f\u751f\u6210\u4e00\u4e2a\u5907\u4efd limit\uff1a\u7528\u4e8e\u524d\u5411\u6216\u540e\u5411\u586b\u5145\u65f6\u6700\u5927\u7684\u586b\u5145\u8303\u56f4 df = pd.DataFrame(np.random.randn(7, 3)) df.iloc[:4, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[:2, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 -0.181196 NaN NaN # 1 -1.657668 NaN NaN # 2 -0.053454 NaN 0.391461 # 3 -0.539307 NaN -0.668400 # 4 -0.433439 0.839713 -0.295273 # 5 0.749930 1.661641 -0.495165 # 6 0.591810 1.017372 0.932367 result = df.fillna(0) # \u8c03\u7528fillna\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5e38\u6570\u6765\u66ff\u4ee3\u7f3a\u5931\u503c print(result) # 0 1 2 # 0 -0.430926 0.000000 0.000000 # 1 0.448061 0.000000 0.000000 # 2 -0.059910 0.000000 -1.532646 # 3 -0.315793 0.000000 -0.196546 # 4 -0.546106 0.135108 -0.332309 # 5 1.083075 0.346070 -0.773104 # 6 -0.186511 1.055337 -1.168303 result = df.fillna({1: 0.5, 2: 0}) # \u8c03\u7528fillna\u65f6\u4f7f\u7528\u5b57\u5178\uff0c\u53ef\u4ee5\u4e3a\u4e0d\u540c\u5217\u8bbe\u5b9a\u4e0d\u540c\u7684\u586b\u5145\u503c print(result) # 0 1 2 # 0 -0.794344 0.500000 0.000000 # 1 -0.960917 0.500000 0.000000 # 2 1.494351 0.500000 0.100878 # 3 -0.554765 0.500000 1.118801 # 4 -0.866117 0.523615 1.217478 # 5 -0.706966 -0.681776 0.797690 # 6 -1.456366 1.205518 -0.402432 fillna \u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u65b0\u7684\u5bf9\u8c61\uff0c\u4f46\u4e5f\u53ef\u4ee5\u4fee\u6539\u5df2\u7ecf\u5b58\u5728\u7684\u5bf9\u8c61 _ = df.fillna(0, inplace=True) # inplace=True\u6307\u5b9a\u5728\u5df2\u6709\u5bf9\u8c61\u4e0a\u76f4\u63a5\u4fee\u6539 print(df) # 0 1 2 # 0 -1.176124 0.000000 0.000000 # 1 0.120458 0.000000 0.000000 # 2 -1.206408 0.000000 0.551693 # 3 0.224563 0.000000 1.145156 # 4 -0.557836 0.081135 -0.075282 # 5 2.378837 -0.876145 1.430386 # 6 -0.152662 1.278364 0.479686 df = pd.DataFrame(np.random.randn(6, 3)) df.iloc[2:, 1] = NA # \u6807\u7b7e1\uff0c\u524d4\u4e2a\u5143\u7d20 df.iloc[4:, 2] = NA # \u6807\u7b7e2\uff0c\u524d2\u4e2a\u5143\u7d20 print(df) # 0 1 2 # 0 1.154788 0.033949 -0.122807 # 1 0.258684 -0.580244 1.636514 # 2 1.503756 NaN -1.224203 # 3 0.824049 NaN -0.364345 # 4 -1.247609 NaN NaN # 5 -1.019980 NaN NaN result = df.fillna(method='ffill') # \u5411\u540e\u586b\u5145 print(result) # 0 1 2 # 0 2.082449 0.398874 0.359772 # 1 0.233129 0.385347 1.953533 # 2 0.396555 0.385347 0.592784 # 3 -0.957249 0.385347 0.169815 # 4 0.854452 0.385347 0.169815 # 5 -0.105982 0.385347 0.169815 result = df.fillna(method='ffill', limit=3) # \u6bcf\u5217\u6700\u591a\u586b3\u4e2a print(result) result = df.fillna(df[0].max()) # \u75280\u5217\u7684\u6700\u5927\u503c\u586b\u5145\u6240\u6709\u7684NA print(result) # 0 1 2 # 0 -0.377697 -0.852891 -0.705489 # 1 -0.611759 -0.013237 -0.295764 # 2 -0.389974 1.057881 1.041957 # 3 -0.016845 1.057881 -1.149954 # 4 1.057881 1.057881 1.057881 # 5 -0.463471 1.057881 1.057881","title":"\u8865\u5168\u7f3a\u5931\u503c"},{"location":"python/DataAnalysis/ch04/#_5","text":"import pandas as pd import numpy as np from numpy import nan as NA","title":"\u6570\u636e\u8f6c\u6362"},{"location":"python/DataAnalysis/ch04/#_6","text":"data = pd.DataFrame( { 'k1': ['one', 'two'] * 3 + ['two'], 'k2': [1, 1, 2, 3, 4, 4, 4] } ) print(data) # \u91cd\u590d\u51fa\u73b02\u6b21\u7684\u8bb0\u5f55\uff1atwo 4 # k1 k2 # 0 one 1 # 1 two 1 # 2 one 2 # 3 two 3 # 4 one 4 # 5 two 4 # 6 two 4 DataFrame\u7684 duplicated \u65b9\u6cd5\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5e03\u5c14\u503cSeries\uff0c\u8fd9\u4e2aSeries\u53cd\u6620\u7684\u662f\u6bcf\u4e00\u884c\u662f\u5426\u5b58\u5728\u91cd\u590d\uff08\u4e0e\u4e4b\u524d\u51fa\u73b0\u8fc7\u7684\u884c\u76f8\u540c\uff09\u60c5\u51b5\uff0c\u9ed8\u8ba4\u662f\u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 print(data.duplicated()) # 0 False # 1 False # 2 False # 3 False # 4 False # 5 False # 6 True # dtype: bool drop_duplicates \u8fd4\u56de\u7684\u662fDataFrame\uff0c\u5185\u5bb9\u662f duplicated \u8fd4\u56de\u6570\u7ec4\u4e2d\u4e3a False \u7684\u90e8\u5206\u3002\u9ed8\u8ba4\u662f\u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 print(data.drop_duplicates()) # k1 k2 # 0 one 1 # 1 two 1 # 2 one 2 # 3 two 3 # 4 one 4 # 5 two 4 \u53ef\u4ee5\u6307\u5b9a\u6570\u636e\u7684\u4efb\u4f55\u5b50\u96c6\u6765\u68c0\u6d4b\u662f\u5426\u6709\u91cd\u590d\u3002\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u989d\u5916\u7684\u5217\uff0c\u5e76\u60f3\u57fa\u4e8e\u2019k1\u2019\u5217\u53bb\u9664\u91cd\u590d\u503c\u3002 data['v1'] = range(7) print(data) # k1 k2 v1 # 0 one 1 0 # 1 two 1 1 # 2 one 2 2 # 3 two 3 3 # 4 one 4 4 # 5 two 4 5 # 6 two 4 6 print(data.drop_duplicates(['k1'])) # \u4fdd\u7559\u7b2c\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684one\u548ctwo\uff0c\u5176\u4f59\u4e22\u5f03 # k1 k2 v1 # 0 one 1 0 # 1 two 1 1 duplicated \u548c drop_duplicates \u9ed8\u8ba4\u90fd\u662f\u4fdd\u7559\u7b2c\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684\u503c\u3002\u4f20\u5165\u53c2\u6570keep='last\u2019\u5c06\u4f1a\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u3002 print(data.drop_duplicates(['k1'], keep='last')) # \u4fdd\u7559\u6700\u540e\u4e00\u4e2a\u89c2\u6d4b\u5230\u7684one\u548ctwo # k1 k2 v1 # 4 one 4 4 # 6 two 4 6","title":"\u5220\u9664\u91cd\u590d\u503c"},{"location":"python/DataAnalysis/ch04/#_7","text":"\u4f7f\u7528 map \u662f\u4e00\u79cd\u53ef\u4ee5\u4fbf\u6377\u6267\u884c\u6309\u5143\u7d20\u8f6c\u6362\u53ca\u5176\u4ed6\u6e05\u6d17\u76f8\u5173\u64cd\u4f5c\u7684\u65b9\u6cd5\u3002 data = pd.DataFrame( { 'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6] } ) print(data) # food ounces # 0 bacon 4.0 # 1 pulled pork 3.0 # 2 bacon 12.0 # 3 Pastrami 6.0 # 4 corned beef 7.5 # 5 Bacon 8.0 # 6 pastrami 3.0 # 7 honey ham 5.0 # 8 nova lox 6.0 \u6dfb\u52a0\u4e00\u5217\u7528\u4e8e\u8868\u660e\u6bcf\u79cd\u98df\u7269\u7684\u52a8\u7269\u8089\u7c7b\u578b\u3002 \u5148\u521b\u5efa\u4e00\u4e2a\u98df\u7269\u548c\u8089\u7c7b\u7684\u6620\u5c04\u3002 meat_to_animal = { 'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon' } lowercased = data['food'].str.lower() # \u4f7f\u7528Series\u7684str.lower\u65b9\u6cd5\u5c06food\u7684\u6bcf\u4e2a\u503c\u90fd\u8f6c\u6362\u4e3a\u5c0f\u5199 print(lowercased) # 0 bacon # 1 pulled pork # 2 bacon # 3 pastrami # 4 corned beef # 5 bacon # 6 pastrami # 7 honey ham # 8 nova lox # Name: food, dtype: object data['animal'] = lowercased.map(meat_to_animal) print(data) # food ounces animal # 0 bacon 4.0 pig # 1 pulled pork 3.0 pig # 2 bacon 12.0 pig # 3 Pastrami 6.0 cow # 4 corned beef 7.5 cow # 5 Bacon 8.0 pig # 6 pastrami 3.0 cow # 7 honey ham 5.0 pig # 8 nova lox 6.0 salmon \u4e5f\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u51fd\u6570\uff0c\u5b8c\u6210\u4e0a\u9762\u6240\u6709\u529f\u80fd\u3002 data = pd.DataFrame( { 'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6] } ) result = data['food'].map(lambda x: meat_to_animal[x.lower()]) print(result) # 0 pig # 1 pig # 2 pig # 3 cow # 4 cow # 5 pig # 6 cow # 7 pig # 8 salmon # Name: food, dtype: object","title":"\u4f7f\u7528\u51fd\u6570\u6216\u6620\u5c04\u8fdb\u884c\u6570\u636e\u8f6c\u6362"},{"location":"python/DataAnalysis/ch04/#_8","text":"\u4f7f\u7528 fillna \u586b\u5145\u7f3a\u5931\u503c\u662f\u901a\u7528\u503c\u66ff\u6362\u7684\u7279\u6b8a\u6848\u4f8b\u3002 map \u53ef\u4ee5\u7528\u6765\u4fee\u6539\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u5b50\u96c6\u7684\u503c\uff0c\u4f46\u662f replace \u63d0\u4f9b\u4e86\u66f4\u4e3a\u7b80\u5355\u7075\u6d3b\u7684\u5b9e\u73b0\u3002 data.replace \u65b9\u6cd5\u4e0e data.str.replace \u65b9\u6cd5\u662f\u4e0d\u540c\u7684\uff0c data.str.replace \u662f\u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u6309\u5143\u7d20\u66ff\u4ee3\u7684\u3002 \u4e0b\u9762\u7684Series\uff0c -999 \u53ef\u80fd\u662f\u7f3a\u5931\u503c\u7684\u6807\u8bc6\u3002\u5982\u679c\u8981\u4f7f\u7528 NA \u6765\u66ff\u4ee3\u8fd9\u4e9b\u503c\uff0c\u53ef\u4ee5\u4f7f\u7528 replace \u65b9\u6cd5\u751f\u6210\u65b0\u7684Series\uff08\u9664\u975e\u4f20\u5165\u4e86 inplace=True \uff09 data = pd.Series([1., -999., 2., -999., -1000., 3.]) print(data) # 0 1.0 # 1 -999.0 # 2 2.0 # 3 -999.0 # 4 -1000.0 # 5 3.0 # dtype: float64 result = data.replace(-999, np.nan) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 -1000.0 # 5 3.0 # dtype: float64 \u8981\u5c06\u4e0d\u540c\u7684\u503c\u66ff\u6362\u4e3a\u4e0d\u540c\u7684\u503c\uff0c\u53ef\u4ee5\u4f20\u5165\u66ff\u4ee3\u503c\u7684\u5217\u8868 result = data.replace([-999, -1000], [np.nan, 0]) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 0.0 # 5 3.0 # dtype: float64 \u4e5f\u53ef\u4ee5\u4f20\u5165\u66ff\u4ee3\u503c\u7684\u5b57\u5178 result = data.replace({-999: np.nan, -1000: 0}) print(result) # 0 1.0 # 1 NaN # 2 2.0 # 3 NaN # 4 0.0 # 5 3.0 # dtype: float64","title":"\u66ff\u4ee3\u503c"},{"location":"python/DataAnalysis/ch04/#_9","text":"\u548cSeries\u4e2d\u503c\u66ff\u6362\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u901a\u8fc7\u51fd\u6570\u6216\u6620\u5c04\u5bf9\u8f74\u6807\u7b7e\u8fdb\u884c\u7c7b\u4f3c\u7684\u8f6c\u6362\uff0c\u751f\u6210\u65b0\u7684\u4e14\u5e26\u6709\u4e0d\u540c\u6807\u7b7e\u7684\u5bf9\u8c61\u3002 data = pd.DataFrame( np.arange(12).reshape((3, 4)), index=['Ohio', 'Colorado', 'New York'], columns=['one', 'two', 'three', 'four'] ) print(data) # one two three four # Ohio 0 1 2 3 # Colorado 4 5 6 7 # New York 8 9 10 11 \u4e0eSeries\u7c7b\u4f3c\uff0c\u8f74\u7d22\u5f15\u4e5f\u6709\u4e00\u4e2a map \u65b9\u6cd5\u3002 transform = lambda x: x[:4].upper() # \u622a\u53d6index\u7684\u524d\u56db\u4f4d\u5e76\u8f6c\u5316\u4e3a\u5927\u5199\u683c\u5f0f result = data.index.map(transform) print(result) # Index(['OHIO', 'COLO', 'NEW '], dtype='object') \u8d4b\u503c\u7ed9 index \uff0c\u4fee\u6539DataFrame\u3002 data.index = data.index.map(transform) print(data) # one two three four # OHIO 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 \u521b\u5efa\u6570\u636e\u96c6\u8f6c\u6362\u540e\u7684\u7248\u672c\uff0c\u5e76\u4e14\u4e0d\u4fee\u6539\u539f\u6709\u7684\u6570\u636e\u96c6\uff0c\u4e00\u4e2a\u6709\u7528\u7684\u65b9\u6cd5\u662f rename \u3002 result = data.rename(index=str.title, columns=str.upper) print(result) # ONE TWO THREE FOUR # Ohio 0 1 2 3 # Colo 4 5 6 7 # New 8 9 10 11 print(data) # \u539f\u6709\u7684\u6570\u636e\u96c6\u672a\u88ab\u4fee\u6539 # one two three four # OHIO 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 rename \u53ef\u4ee5\u7ed3\u5408\u5b57\u5178\u578b\u5bf9\u8c61\u4f7f\u7528\uff0c\u4e3a\u8f74\u6807\u7b7e\u7684\u5b50\u96c6\u63d0\u4f9b\u65b0\u7684\u503c\u3002 result = data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'}) print(result) # one two peekaboo four # INDIANA 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11 \u5982\u679c\u8981\u4fee\u6539\u539f\u6709\u7684\u6570\u636e\u96c6\uff0c\u4f20\u5165 inplace=True \u3002 data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'}, inplace=True) print(data) # one two peekaboo four # INDIANA 0 1 2 3 # COLO 4 5 6 7 # NEW 8 9 10 11","title":"\u91cd\u547d\u540d\u8f74\u7d22\u5f15"},{"location":"python/DataAnalysis/ch04/#_10","text":"\u8fde\u7eed\u503c\u7ecf\u5e38\u9700\u8981\u79bb\u6563\u5316\uff0c\u6216\u8005\u5206\u79bb\u6210\u201d\u7bb1\u5b50\u201c\u8fdb\u884c\u5206\u6790\u3002 \u5047\u8bbe\u6709\u4e00\u7ec4\u4eba\u7fa4\u7684\u6570\u636e\uff0c\u60f3\u5c06\u4ed6\u4eec\u8fdb\u884c\u5206\u7ec4\uff0c\u653e\u5165\u79bb\u6563\u7684\u5e74\u9f84\u6846\u4e2d\u3002 ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32] \u5c06\u8fd9\u4e9b\u5e74\u9f84\u5206\u4e3a18\uff5e25\u300126\uff5e35\u300136\uff5e60\u4ee5\u53ca61\u53ca\u4ee5\u4e0a\u7b49\u82e5\u5e72\u7ec4\uff0c\u4f7f\u7528pandas\u4e2d\u7684 cut \u3002 bins = [18, 25, 35, 60, 100] cats = pd.cut(ages, bins) print(cats) # [(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]] # Length: 12 # Categories (4, interval[int64, right]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]] pandas\u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u4e00\u4e2a\u7279\u6b8a\u7684 Categorical \u5bf9\u8c61\u3002 \u4f60\u770b\u5230\u7684\u8f93\u51fa\u63cf\u8ff0\u4e86\u7531 pandas.cut \u8ba1\u7b97\u51fa\u7684\u7bb1\u3002 \u4f60\u53ef\u4ee5\u5c06\u5b83\u5f53\u4f5c\u4e00\u4e2a\u8868\u793a\u7bb1\u540d\u7684\u5b57\u7b26\u4e32\u6570\u7ec4\uff1b\u5b83\u5728\u5185\u90e8\u5305\u542b\u4e00\u4e2a categories \uff08\u7c7b\u522b\uff09\u6570\u7ec4\uff0c\u5b83\u6307\u5b9a\u4e86\u4e0d\u540c\u7684\u7c7b\u522b\u540d\u79f0\u4ee5\u53ca codes \u5c5e\u6027\u4e2d\u7684 ages \uff08\u5e74\u9f84\uff09\u6570\u636e\u6807\u7b7e\u3002 print(cats.categories) # \u56db\u4e2a\u533a\u95f4\u7ec4 # IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]], dtype='interval[int64, right]') print(cats.codes) # 61\u5c81\u843d\u5728\u7b2c3\u7ec4\uff08\u7ec4\u7f16\u53f7\u4ece0\u5f00\u59cb\uff09 # [0 0 0 1 0 0 2 1 3 2 2 1] \u6ce8\u610f\uff0c pd.value_counts(cats) \u662f\u5bf9 pandas.cut \u7684\u7ed3\u679c\u4e2d\u7684\u7bb1\u6570\u91cf\u7684\u8ba1\u6570\u3002 result = pd.value_counts(cats) print(result) # (18, 25] 5 # (25, 35] 3 # (35, 60] 3 # (60, 100] 1 # dtype: int64 \u4e0e\u533a\u95f4\u7684\u6570\u5b66\u7b26\u53f7\u4e00\u81f4\uff0c\u5c0f\u62ec\u53f7\u8868\u793a\u8fb9\u662f\u5f00\u653e\u7684\uff0c\u4e2d\u62ec\u53f7\u8868\u793a\u5b83\u662f\u5c01\u95ed\u7684\uff08\u5305\u62ec\u8fb9\uff09\u3002\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012 right=False \u6765\u6539\u53d8\u54ea\u4e00\u8fb9\u662f\u5c01\u95ed\u7684\u3002\u9ed8\u8ba4 right=True \u3002 result = pd.cut(ages, [18, 26, 36, 61, 100], right=False) print(result) # [[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)] # Length: 12 # Categories (4, interval[int64, left]): [[18, 26) < [26, 36) < [36, 61) < [61, 100)] \u901a\u8fc7\u5411 labels \u9009\u9879\u4f20\u9012\u4e00\u4e2a\u5217\u8868\u6216\u6570\u7ec4\u6765\u4f20\u5165\u81ea\u5b9a\u4e49\u7684\u7bb1\u540d\u3002 group_name = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior'] result = pd.cut(ages, bins, labels=group_name) print(result) # ['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult'] # Length: 12 # Categories (4, object): ['Youth' < 'YoungAdult' < 'MiddleAged' < 'Senior'] result = pd.value_counts(pd.cut(ages, bins, labels=group_name)) # \u6807\u7b7e\u8f93\u51fa print(result) # Youth 5 # YoungAdult 3 # MiddleAged 3 # Senior 1 # dtype: int64 result = pd.value_counts(pd.cut(ages, bins)) # \u533a\u95f4\u8f93\u51fa print(result) # (18, 25] 5 # (25, 35] 3 # (35, 60] 3 # (60, 100] 1 # dtype: int64 \u5982\u679c\u4f20\u7ed9 cut \u6574\u6570\u4e2a\u7684\u7bb1\u6765\u4ee3\u66ff\u663e\u5f0f\u7684\u7bb1\u8fb9\uff0cpandas\u5c06\u6839\u636e\u6570\u636e\u4e2d\u7684\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c\u8ba1\u7b97\u51fa\u7b49\u957f\u7684\u7bb1\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u8003\u8651\u4e00\u4e9b\u5747\u5300\u5206\u5e03\u7684\u6570\u636e\u88ab\u5207\u6210\u56db\u4efd\u7684\u60c5\u51b5\u3002 data = np.random.rand(20) result = pd.cut(data, 4, precision=2) # precision=2\u7684\u9009\u9879\u5c06\u5341\u8fdb\u5236\u7cbe\u5ea6\u9650\u5236\u5728\u4e24\u4f4d\u3002 print(result) # [(0.44, 0.66], (0.0063, 0.23], (0.23, 0.44], (0.0063, 0.23], (0.23, 0.44], ..., (0.23, 0.44], (0.0063, 0.23], (0.23, 0.44], (0.66, 0.88], (0.23, 0.44]] # Length: 20 # Categories (4, interval[float64, right]): [(0.0063, 0.23] < (0.23, 0.44] < (0.44, 0.66] < (0.66, 0.88]] qcut \u662f\u4e00\u4e2a\u4e0e\u5206\u7bb1\u5bc6\u5207\u76f8\u5173\u7684\u51fd\u6570\uff0c\u5b83\u57fa\u4e8e\u6837\u672c\u5206\u4f4d\u6570\u8fdb\u884c\u5206\u7bb1\u3002 \u53d6\u51b3\u4e8e\u6570\u636e\u7684\u5206\u5e03\uff0c\u4f7f\u7528 cut \u901a\u5e38\u4e0d\u4f1a\u4f7f\u6bcf\u4e2a\u7bb1\u5177\u6709\u76f8\u540c\u6570\u636e\u91cf\u7684\u6570\u636e\u70b9\u3002 \u7531\u4e8eqcut\u4f7f\u7528\u6837\u672c\u7684\u5206\u4f4d\u6570\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7qcut\u83b7\u5f97\u7b49\u957f\u7684\u7bb1\u3002 data = np.random.randn(1000) # \u6b63\u6001\u5206\u5e03 cats = pd.qcut(data, 4) # \u5207\u62104\u4efd print(cats) # [(-0.00329, 0.644], (-0.00329, 0.644], (-0.659, -0.00329], (-0.659, -0.00329], (0.644, 3.468], ..., (0.644, 3.468], (-3.9619999999999997, -0.659], (-3.9619999999999997, -0.659], (-0.00329, 0.644], (-0.00329, 0.644]] # Length: 1000 # Categories (4, interval[float64, right]): [(-3.9619999999999997, -0.659] < (-0.659, -0.00329] < (-0.00329, 0.644] < (0.644, 3.468]] result = pd.value_counts(cats) print(result) # (-3.9619999999999997, -0.659] 250 # (-0.659, -0.00329] 250 # (-0.00329, 0.644] 250 # (0.644, 3.468] 250 # dtype: int64 \u4e0e cut \u7c7b\u4f3c\uff0c\u53ef\u4ee5\u4f20\u5165\u81ea\u5b9a\u4e49\u7684\u5206\u4f4d\u6570\uff080\u548c1\u4e4b\u95f4\u7684\u6570\u636e\uff0c\u5305\u62ec\u8fb9\uff09\u3002 result = pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.]) print(result) # [(-0.00329, 1.234], (-0.00329, 1.234], (-1.321, -0.00329], (-1.321, -0.00329], (-0.00329, 1.234], ..., (-0.00329, 1.234], (-1.321, -0.00329], (-1.321, -0.00329], (-0.00329, 1.234], (-0.00329, 1.234]] # Length: 1000 # Categories (4, interval[float64, right]): [(-3.9619999999999997, -1.321] < (-1.321, -0.00329] < (-0.00329, 1.234] < (1.234, 3.468]]","title":"\u79bb\u6563\u5316\u548c\u5206\u7bb1"},{"location":"python/DataAnalysis/ch04/#_11","text":"\u8fc7\u6ee4\u6216\u8f6c\u6362\u5f02\u5e38\u503c\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u662f\u5e94\u7528\u6570\u7ec4\u64cd\u4f5c\u7684\u4e8b\u60c5\u3002 \u8003\u8651\u4e00\u4e2a\u5177\u6709\u6b63\u6001\u5206\u5e03\u6570\u636e\u7684DataFrame\u3002 data = pd.DataFrame(np.random.randn(1000, 4)) print(data.describe()) # 0 1 2 3 # count 1000.000000 1000.000000 1000.000000 1000.000000 # mean 0.008124 -0.008050 -0.013403 -0.008261 # std 0.979236 0.992982 0.998819 1.038760 # min -3.231914 -3.441270 -3.345210 -4.320565 # 25% -0.634801 -0.599852 -0.656481 -0.677611 # 50% -0.033252 0.000060 -0.040634 -0.015463 # 75% 0.649340 0.644312 0.678101 0.683849 # max 3.292099 2.758754 2.911447 3.371729 \u627e\u51fa\u4e00\u5217\u4e2d\u7edd\u5bf9\u503c\u5927\u4e8e\u4e09\u7684\u503c\u3002 col = data[2] result = col[np.abs(col) > 3] print(result) # 519 -3.035355 # 536 -3.345210 # Name: 2, dtype: float64 \u9009\u51fa\u6240\u6709\u503c\u5927\u4e8e3\u6216\u5c0f\u4e8e-3\u7684\u884c\uff0c\u53ef\u4ee5\u5bf9\u5e03\u5c14\u503cDataFrame\u4f7f\u7528 any \u65b9\u6cd5\u3002 result = data[(np.abs(data) > 3).any(1)] print(result) # 0 1 2 3 # 116 -0.080907 -3.441270 -0.163263 0.392800 # 139 -1.294440 1.828397 1.178897 -3.469466 # 241 -0.486292 0.150443 0.264172 -3.013440 # 295 3.292099 -0.339284 0.732829 -0.475202 # 355 0.307577 -3.053322 0.967497 0.896363 # 359 3.264981 -1.172096 0.207622 -0.281803 # 519 -0.448987 1.623843 -3.035355 -0.436833 # 533 -1.022616 -0.212597 1.030969 3.371729 # 536 1.067598 -1.306839 -3.345210 0.620834 # 541 -0.952760 -2.157970 -0.403199 -4.320565 # 690 0.006821 -3.104117 0.484881 -0.132613 # 750 -3.231914 1.017712 0.070430 0.631447 # 771 -3.007622 0.257960 -0.118179 -1.283365 # 976 1.684760 -0.003295 -0.249843 3.169371 \u6839\u636e\u8fd9\u4e9b\u6807\u51c6\u6765\u8bbe\u7f6e\u6765\u9650\u5b9a\u503c\uff0c\u4e0b\u9762\u4ee3\u7801\u9650\u5236\u4e86-3\u52303\u4e4b\u95f4\u7684\u6570\u503c\u3002 \u8bed\u53e5 np.sign(data) \u6839\u636e\u6570\u636e\u4e2d\u7684\u503c\u7684\u6b63\u8d1f\u5206\u522b\u751f\u62101\u548c-1\u7684\u6570\u503c\u3002 result = data[(np.abs(data) > 3)] = np.sign(data) * 3 print(result.describe()) # 0 1 2 3 # count 1000.000000 1000.000000 1000.000000 1000.000000 # mean -0.036000 0.000000 -0.084000 -0.048000 # std 3.001285 3.001501 3.000324 3.001117 # min -3.000000 -3.000000 -3.000000 -3.000000 # 25% -3.000000 -3.000000 -3.000000 -3.000000 # 50% -3.000000 0.000000 -3.000000 -3.000000 # 75% 3.000000 3.000000 3.000000 3.000000 # max 3.000000 3.000000 3.000000 3.000000 print(result.head()) # 0 1 2 3 # 0 -3.0 3.0 -3.0 -3.0 # 1 -3.0 -3.0 -3.0 -3.0 # 2 3.0 3.0 -3.0 3.0 # 3 3.0 -3.0 3.0 -3.0 # 4 3.0 -3.0 -3.0 -3.0","title":"\u68c0\u6d4b\u548c\u8fc7\u6ee4\u5f02\u5e38\u503c"},{"location":"python/DataAnalysis/ch04/#_12","text":"\u4f7f\u7528 numpy.random.permutation \u5bf9DataFrame\u4e2d\u7684Series\u6216\u884c\u8fdb\u884c\u7f6e\u6362\uff08\u968f\u673a\u91cd\u6392\u5e8f\uff09\u3002 \u5728\u8c03\u7528 permutation \u65f6\u6839\u636e\u4f60\u60f3\u8981\u7684\u8f74\u957f\u5ea6\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u8868\u793a\u65b0\u987a\u5e8f\u7684\u6574\u6570\u6570\u7ec4\u3002 df = pd.DataFrame(np.arange(5 * 4).reshape((5, 4))) sampler = np.random.permutation(5) print(sampler) # \u8fd4\u56dearray # [1 4 3 0 2] print(df) # 0 1 2 3 # 0 0 1 2 3 # 1 4 5 6 7 # 2 8 9 10 11 # 3 12 13 14 15 # 4 16 17 18 19 \u4e0a\u9762\u8fd4\u56de\u7684 sampler \u6574\u6570\u6570\u7ec4 [1 4 3 0 2] \u7528\u5728\u57fa\u4e8e iloc \u7684\u7d22\u5f15\u6216\u7b49\u4ef7\u7684 take \u51fd\u6570\u4e2d\uff0c\u91cd\u65b0\u6392\u5217\u884c\u987a\u5e8f\u3002 print(df.take(sampler)) # 0 1 2 3 # 1 4 5 6 7 # 4 16 17 18 19 # 3 12 13 14 15 # 0 0 1 2 3 # 2 8 9 10 11 \u9009\u51fa\u4e00\u4e2a\u4e0d\u542b\u6709\u66ff\u4ee3\u503c\u7684\u968f\u673a\u5b50\u96c6\uff0c\u53ef\u4ee5\u4f7f\u7528Series\u548cDataFrame\u7684 sample \u65b9\u6cd5\u3002 result = df.sample(n=3) print(result) # 0 1 2 3 # 0 0 1 2 3 # 2 8 9 10 11 # 1 4 5 6 7 \u8981\u751f\u6210\u4e00\u4e2a\u5e26\u6709\u66ff\u4ee3\u503c\u7684\u6837\u672c\uff08\u5141\u8bb8\u6709\u91cd\u590d\u9009\u62e9\uff09\uff0c\u5c06 replace=True \u4f20\u5165 sample \u65b9\u6cd5\u3002 choice = pd.Series([5, 7, -1, 6, 4]) draws = choice.sample(n=10, replace=True) print(choice) # 0 5 # 1 7 # 2 -1 # 3 6 # 4 4 # dtype: int64 print(draws) # 4 4 # 0 5 # 0 5 # 3 6 # 4 4 # 0 5 # 1 7 # 3 6 # 2 -1 # 0 5 # dtype: int64","title":"\u7f6e\u6362\u548c\u968f\u673a\u62bd\u6837"},{"location":"python/DataAnalysis/ch04/#_13","text":"\u5c06\u5206\u7c7b\u53d8\u91cf\u8f6c\u6362\u4e3a\u201c\u865a\u62df\u201d\u6216\u201c\u6307\u6807\u201d\u77e9\u9635\u662f\u53e6\u4e00\u79cd\u7528\u4e8e\u7edf\u8ba1\u5efa\u6a21\u6216\u673a\u5668\u5b66\u4e60\u7684\u8f6c\u6362\u64cd\u4f5c\u3002 \u5982\u679cDataFrame\u4e2d\u7684\u4e00\u5217\u6709 k \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u5219\u53ef\u4ee5\u884d\u751f\u4e00\u4e2a k \u5217\u7684\u503c\u4e3a 1 \u548c 0 \u7684\u77e9\u9635\u6216DataFrame\u3002 pandas\u6709\u4e00\u4e2aget_dummies\u51fd\u6570\u7528\u4e8e\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 df = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6) } ) print(df) # key data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 b 5 \u5728\u6307\u6807DataFrame\u7684\u5217\u4e0a\u52a0\u5165\u524d\u7f00\uff0c\u7136\u540e\u4e0e\u5176\u4ed6\u6570\u636e\u5408\u5e76\u3002\u5728 get_dummies \u65b9\u6cd5\u4e2d\u6709\u4e00\u4e2a\u524d\u7f00\u53c2\u6570\u7528\u4e8e\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 \u901a\u8fc7 get_dummies \u65b9\u6cd5\uff0c\u628a\u4e0a\u9762 df \u6570\u636e\u6309\u7167 key \u8fdb\u884c\u4e86\u5206\u7ec4\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u5217\u6765\u5c55\u73b0\u5206\u7ec4\u540e\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u4f8b\u5982\uff0c key \u5217\u7684 a \uff0c\u5bf9\u5e94\u503c 2 \u548c 4 \u3002 dummies = pd.get_dummies(df['key'], prefix='key') print(dummies) # key_a key_b key_c # 0 0 1 0 # 1 0 1 0 # 2 1 0 0 # 3 0 0 1 # 4 1 0 0 # 5 0 1 0 df_with_dummy = df[['data1']].join(dummies) print(df_with_dummy) # data1 key_a key_b key_c # 0 0 0 1 0 # 1 1 0 1 0 # 2 2 1 0 0 # 3 3 0 0 1 # 4 4 1 0 0 # 5 5 0 1 0 \u66f4\u4e3a\u590d\u6742\u7684\u60c5\u51b5\uff0cDataFrame\u4e2d\u7684\u4e00\u884c\u5c5e\u4e8e\u591a\u4e2a\u7c7b\u522b\u3002 \u4ee5MovieLens\u76841M\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\u589e\u52a0\u53c2\u6570 encoding='unicode_escape' \u907f\u514d\u51fa\u73b0\u4e0b\u9762\u7684\u9519\u8bef\uff1a UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 3114: invalid continuation byte \u589e\u52a0\u53c2\u6570 engine='python' \u907f\u514d\u51fa\u73b0\u4e0b\u9762\u7684\u9519\u8bef\uff1a ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'. mnames = ['movie_id', 'title', 'genres'] movies = pd.read_table( '../datasets/movielens/movies.dat', sep='::', header=None, names=mnames, encoding='unicode_escape', engine='python' ) print(movies[:10]) # movie_id title genres # 0 1 Toy Story (1995) Animation|Children's|Comedy # 1 2 Jumanji (1995) Adventure|Children's|Fantasy # 2 3 Grumpier Old Men (1995) Comedy|Romance # 3 4 Waiting to Exhale (1995) Comedy|Drama # 4 5 Father of the Bride Part II (1995) Comedy # 5 6 Heat (1995) Action|Crime|Thriller # 6 7 Sabrina (1995) Comedy|Romance # 7 8 Tom and Huck (1995) Adventure|Children's # 8 9 Sudden Death (1995) Action # 9 10 GoldenEye (1995) Action|Adventure|Thriller \u4e3a\u6bcf\u4e2a\u7535\u5f71\u6d41\u6d3e\u6dfb\u52a0\u6307\u6807\u53d8\u91cf\u9700\u8981\u8fdb\u884c\u4e00\u4e9b\u6570\u636e\u5904\u7406\u3002 \u9996\u5148\uff0c\u6211\u4eec\u4ece\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u51fa\u6240\u6709\u4e0d\u540c\u7684\u6d41\u6d3e\u7684\u5217\u8868\u3002 all_genres = [] for x in movies.genres: all_genres.extend(x.split('|')) genres = pd.unique(all_genres) print(genres) # ['Animation' \"Children's\" 'Comedy' 'Adventure' 'Fantasy' 'Romance' 'Drama' # 'Action' 'Crime' 'Thriller' 'Horror' 'Sci-Fi' 'Documentary' 'War' # 'Musical' 'Mystery' 'Film-Noir' 'Western'] \u4f7f\u7528\u51680\u7684DataFrame\u662f\u6784\u5efa\u6307\u6807DataFrame\u7684\u4e00\u79cd\u65b9\u5f0f\u3002 zero_matrix = np.zeros((len(movies), len(genres))) dummies = pd.DataFrame(zero_matrix, columns=genres) print(zero_matrix) # [[0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # ... # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.] # [0. 0. 0. ... 0. 0. 0.]] print(dummies.head(n=10)) # Animation Children's Comedy ... Mystery Film-Noir Western # 0 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 1 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 2 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 3 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 4 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 5 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 6 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 7 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 8 0.0 0.0 0.0 ... 0.0 0.0 0.0 # 9 0.0 0.0 0.0 ... 0.0 0.0 0.0 # # [10 rows x 18 columns] \u904d\u5386\u6bcf\u4e00\u90e8\u7535\u5f71\uff0c\u5c06 dummies \u6bcf\u4e00\u884c\u7684\u6761\u76ee\u8bbe\u7f6e\u4e3a 1 \u3002\u4f7f\u7528 dummies.columns \u6765\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u6d41\u6d3e\u7684\u5217\u6307\u6807\u3002 gen = movies.genres[0] print(gen.split('|')) # ['Animation', \"Children's\", 'Comedy'] result = dummies.columns.get_indexer(gen.split('|')) print(result) # [0 1 2] \u4f7f\u7528 .loc \u6839\u636e\u8fd9\u4e9b\u6307\u6807\u6765\u8bbe\u7f6e\u503c\u3002 for i, gen in enumerate(movies.genres): indices = dummies.columns.get_indexer(gen.split('|')) dummies.iloc[i, indices] = 1 \u5c06\u7ed3\u679c\u4e0e movies \u8fdb\u884c\u5408\u5e76\u3002 movies_windic = movies.join(dummies.add_prefix('Genre_')) print(movies_windic.iloc[0]) # movie_id 1 # title Toy Story (1995) # genres Animation|Children's|Comedy # Genre_Animation 1.0 # Genre_Children's 1.0 # Genre_Comedy 1.0 # Genre_Adventure 0.0 # Genre_Fantasy 0.0 # Genre_Romance 0.0 # Genre_Drama 0.0 # Genre_Action 0.0 # Genre_Crime 0.0 # Genre_Thriller 0.0 # Genre_Horror 0.0 # Genre_Sci-Fi 0.0 # Genre_Documentary 0.0 # Genre_War 0.0 # Genre_Musical 0.0 # Genre_Mystery 0.0 # Genre_Film-Noir 0.0 # Genre_Western 0.0 # Name: 0, dtype: object \u5bf9\u4e8e\u66f4\u5927\u7684\u6570\u636e\uff0c\u4e0a\u9762\u8fd9\u79cd\u4f7f\u7528\u591a\u6210\u5458\u6784\u5efa\u6307\u6807\u53d8\u91cf\u5e76\u4e0d\u662f\u7279\u522b\u5feb\u901f\u3002 \u66f4\u597d\u7684\u65b9\u6cd5\u662f\u5199\u4e00\u4e2a\u76f4\u63a5\u5c06\u6570\u636e\u5199\u4e3aNumPy\u6570\u7ec4\u7684\u5e95\u5c42\u51fd\u6570\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u5c01\u88c5\u8fdbDataFrame\u3002 \u5c06 get_dummies \u4e0e cut \u7b49\u79bb\u6563\u5316\u51fd\u6570\u7ed3\u5408\u4f7f\u7528\u662f\u7edf\u8ba1\u5e94\u7528\u7684\u4e00\u4e2a\u6709\u7528\u65b9\u6cd5\u3002 np.random.seed(12345) # \u4f7f\u7528numpy.random.seed\u6765\u8bbe\u7f6e\u968f\u673a\u79cd\u5b50\u4ee5\u786e\u4fdd\u793a\u4f8b\u7684\u786e\u5b9a\u6027 values = np.random.rand(10) print(values) # [0.92961609 0.31637555 0.18391881 0.20456028 0.56772503 0.5955447 # 0.96451452 0.6531771 0.74890664 0.65356987] bins = [0, 0.2, 0.4, 0.6, 0.8, 1] result = pd.get_dummies(pd.cut(values, bins)) print(result) # (0.0, 0.2] (0.2, 0.4] (0.4, 0.6] (0.6, 0.8] (0.8, 1.0] # 0 0 0 0 0 1 # 1 0 1 0 0 0 # 2 1 0 0 0 0 # 3 0 1 0 0 0 # 4 0 0 1 0 0 # 5 0 0 1 0 0 # 6 0 0 0 0 1 # 7 0 0 0 1 0 # 8 0 0 0 1 0 # 9 0 0 0 1 0","title":"\u8ba1\u7b97\u6307\u6807/\u865a\u62df\u53d8\u91cf"},{"location":"python/DataAnalysis/ch04/#_14","text":"import re pandas\u5141\u8bb8\u5c06\u5b57\u7b26\u4e32\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u7b80\u6d01\u5730\u5e94\u7528\u5230\u6574\u4e2a\u6570\u636e\u6570\u7ec4\u4e0a\uff0c\u6b64\u5916\u8fd8\u80fd\u5904\u7406\u6570\u636e\u7f3a\u5931\u3002","title":"\u5b57\u7b26\u4e32\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch04/#_15","text":"\u5b57\u4e32\u62c6\u5206\u5408\u5e76\u65b9\u6cd5\u3002\u5728\u5f88\u591a\u5b57\u7b26\u4e32\u5904\u7406\u548c\u811a\u672c\u5e94\u7528\u4e2d\uff0c\u5185\u5efa\u7684\u5b57\u7b26\u4e32\u65b9\u6cd5\u662f\u8db3\u591f\u7684\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u9017\u53f7\u5206\u9694\u7684\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f7f\u7528split\u65b9\u6cd5\u62c6\u5206\u6210\u591a\u5757\u3002 import numpy as np import pandas as pd val = 'a, b, guido' result = val.split(',') print(result) # ['a', ' b', ' guido'] count \uff1a\u8fd4\u56de\u5b50\u5b57\u7b26\u4e32\u5728\u5b57\u7b26\u4e32\u4e2d\u7684\u975e\u91cd\u53e0\u51fa\u73b0\u6b21\u6570\u3002 result = val.count(',') print(result) # 2 endswith \uff1a\u5982\u679c\u5b57\u7b26\u4e32\u4ee5\u540e\u7f00\u7ed3\u5c3e\u5219\u8fd4\u56de True \u3002 startswith \uff1a\u5982\u679c\u5b57\u7b26\u4e32\u4ee5\u540e\u7f00\u7ed3\u5c3e\u5219\u8fd4\u56de True \u3002 result = val.endswith('b') print(result) # False result = val.endswith('o') print(result) # True result = val.startswith('a') print(result) # True split \u5e38\u548c strip \u4e00\u8d77\u4f7f\u7528\uff0c\u7528\u4e8e\u6e05\u9664\u7a7a\u683c\uff08\u5305\u62ec\u6362\u884c\uff09\u3002 split \uff1a\u4f7f\u7528\u5206\u9694\u7b26\u8bb2\u5b57\u7b26\u4e32\u62c6\u5206\u6210\u5b50\u5b57\u7b26\u4e32\u7684\u5217\u8868\u3002 strip \uff0c rstrip \uff0c lstrip \uff1a\u4fee\u526a\u7a7a\u767d\uff0c\u5305\u62ec\u6362\u884c\u7b26\uff1b\u76f8\u5f53\u4e8e\u5bf9\u6bcf\u4e2a\u5143\u7d20\u8fdb\u884c x.strip() (\u4ee5\u53ca rstrip \uff0c lstrip )\u3002 pieces = [x.strip() for x in val.split(',')] print(pieces) # ['a', 'b', 'guido'] \u8fd9\u4e9b\u5b50\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f7f\u7528\u52a0\u6cd5\u4e0e\u4e24\u4e2a\u5192\u53f7\u5206\u9694\u7b26\u8fde\u63a5\u5728\u4e00\u8d77\u3002 first, second, third = pieces result = first + '::' + second + '::' + third print(result) # a::b::guido \u4f46\u662f\u8fd9\u5e76\u4e0d\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u901a\u7528\u65b9\u6cd5\u3002 \u5728\u5b57\u7b26\u4e32 ': :' \u7684 join \u65b9\u6cd5\u4e2d\u4f20\u5165\u4e00\u4e2a\u5217\u8868\u6216\u5143\u7ec4\u662f\u4e00\u79cd\u66f4\u5feb\u4e14\u66f4\u52a0Pythonic\uff08Python\u98ce\u683c\u5316\uff09\u7684\u65b9\u6cd5\u3002 join : \u4f7f\u7528\u5b57\u7b26\u4e32\u5ea7\u4f4d\u95f4\u9694\u7b26\uff0c\u7528\u4e8e\u7c98\u5408\u5176\u4ed6\u5b57\u7b26\u4e32\u7684\u5e8f\u5217\u3002 result = '::'.join(pieces) print(result) # a::b::guido \u5b9a\u4f4d\u5b50\u5b57\u7b26\u4e32\u7684\u65b9\u6cd5\u3002 \u4f7f\u7528Python\u7684 in \u5173\u952e\u5b57\u662f\u68c0\u6d4b\u5b50\u5b57\u7b26\u4e32\u7684\u6700\u4f73\u65b9\u6cd5\uff0c\u5c3d\u7ba1 index \u548c find \u4e5f\u80fd\u5b9e\u73b0\u540c\u6837\u7684\u529f\u80fd\u3002 result = 'guido' in val print(result) # True index \uff1a\u5982\u679c\u5728\u5b57\u7b26\u4e32\u4e2d\u627e\u5230\uff0c\u5219\u8fd4\u56de\u5b50\u5b57\u7b26\u4e32\u4e2d\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u627e\u4e0d\u5230\u5219\u89e6\u53d1\u4e00\u4e2a ValueError \u3002 find \uff1a\u8fd4\u56de\u5b57\u7b26\u4e32\u4e2d\u7b2c\u4e00\u4e2a\u51fa\u73b0\u5b50\u5b57\u7b26\u7684\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u7c7b\u4f3c index \uff0c\u5982\u679c\u6ca1\u6709\u627e\u5230\uff0c\u5219\u8fd4\u56de -1 \u3002 rfind \uff1a\u8fd4\u56de\u5b57\u7b26\u4e32\u4e2d\u5b50\u5b57\u7b26\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u65f6\u7b2c\u4e00\u4e2a\u5b57\u7b26\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u627e\u5230\uff0c\u5219\u8fd4\u56de -1 \u3002 result = val.index(',') print(result) # 1 result = val.find(',') print(result) # 1 # result = val.index(':') print(result) # ValueError: substring not found result = val.find(':') print(result) # -1 result = val.rfind(',') print(result) # 4 replace \u5c06\u7528\u4e00\u79cd\u6a21\u5f0f\u66ff\u4ee3\u53e6\u4e00\u79cd\u6a21\u5f0f\u3002\u5b83\u4e5f\u7528\u4e8e\u4f20\u5165\u7a7a\u5b57\u7b26\u4e32\u6765\u5220\u9664\u67d0\u4e2a\u6a21\u5f0f\u3002 result = val.replace(',', '::') print(result) # a:: b:: guido result = val.replace(', ', '') print(result) # abguido result = val.replace(',', '') print(result) # a b guido lower \uff1a\u5c06\u5927\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a\u5c0f\u5199\u5b57\u6bcd\u3002 upper \uff1a\u5c06\u5c0f\u5199\u5b57\u6bcd\u8f6c\u6362\u4e3a\u5927\u5199\u5b57\u6bcd\u3002 uppers = val.upper() print(uppers) # A, B, GUIDO casefold \uff1a\u548c lower \u7c7b\u4f3c\uff0c\u5c06\u5b57\u7b26\u4e32\u4e2d\u7684\u5143\u7d20\u53d8\u6210\u5c0f\u5199\uff0c lower \u51fd\u6570\u53ea\u652f\u6301 ascill \u8868\u4e2d\u7684\u5b57\u7b26\uff0c casefold \u652f\u6301\u5f88\u591a\u4e0d\u540c\u79cd\u7c7b\u7684\u8bed\u8a00\u3002 str1 = \"Jan Wei\u03b2@cN\u4e0a\u6d77\" result = str1.casefold() print(result) # jan wei\u03b2@cn\u4e0a\u6d77 result = str1.lower() print(result) # jan wei\u03b2@cn\u4e0a\u6d77 ljust \uff0c rjust \uff1a\u5de6\u5bf9\u9f50\u6216\u8005\u53f3\u5bf9\u9f50\uff1b\u7528\u7a7a\u683c\u6216\u8005\u5176\u5b83\u4e00\u4e9b\u5b57\u7b26\u586b\u5145\u5b57\u7b26\u4e32\u7684\u76f8\u53cd\u4fa7\uff0c\u4ee5\u8fd4\u56de\u5177\u6709\u6700\u5c0f\u5bbd\u5ea6\u7684\u5b57\u7b26\u4e32 str1 = 'https://docs.python.org/3/' str2 = 'https://packagehub.suse.com/package-categories/python/' print(str1.ljust(60, '*')) print(str2.ljust(60, '*')) # https://docs.python.org/3/********************************** # https://packagehub.suse.com/package-categories/python/****** print(str1.rjust(60, '*')) print(str2.rjust(60, '*')) # **********************************https://docs.python.org/3/ # ******https://packagehub.suse.com/package-categories/python/ print(str1.rjust(60)) print(str2.rjust(60))","title":"\u5b57\u7b26\u4e32\u5bf9\u8c61\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch04/#_16","text":"Python\u5185\u5efa\u7684 re \u6a21\u5757\u662f\u7528\u4e8e\u5c06\u6b63\u5219\u8868\u8fbe\u5f0f\u5e94\u7528\u5230\u5b57\u7b26\u4e32\u4e0a\u7684\u5e93\u3002 re \u6a21\u5757\u4e3b\u8981\u6709\u4e09\u4e2a\u4e3b\u9898\uff1a\u6a21\u5f0f\u5339\u914d\u3001\u66ff\u4ee3\u3001\u62c6\u5206\u3002 \u770b\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u5c06\u542b\u6709\u591a\u79cd\u7a7a\u767d\u5b57\u7b26\uff08\u5236\u8868\u7b26\u3001\u7a7a\u683c\u3001\u6362\u884c\u7b26\uff09\u7684\u5b57\u7b26\u4e32\u62c6\u5206\u5f00\u3002 \u63cf\u8ff0\u4e00\u4e2a\u6216\u591a\u4e2a\u7a7a\u767d\u5b57\u7b26\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u662f \\s+ \u3002 \u5f53\u8c03\u7528 re.split('\\s+', text) \uff0c\u6b63\u5219\u8868\u8fbe\u5f0f\u9996\u5148\u4f1a\u88ab\u7f16\u8bd1\uff0c\u7136\u540e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684 split \u65b9\u6cd5\u5728\u4f20\u5165\u6587\u672c\u4e0a\u88ab\u8c03\u7528\u3002 text = \"foo bar\\t baz \\tqux\" result = re.split('\\s+', text) print(result) # ['foo', 'bar', 'baz', 'qux'] \u53ef\u4ee5\u4f7f\u7528 re.compile \u81ea\u884c\u7f16\u8bd1\uff0c\u5f62\u6210\u4e00\u4e2a\u53ef\u590d\u7528\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u8c61\u3002 regex = re.compile('\\s+') result = regex.split(text) print(result) # ['foo', 'bar', 'baz', 'qux'] \u5982\u679c\u60f3\u83b7\u5f97\u7684\u662f\u4e00\u4e2a\u6240\u6709\u5339\u914d\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6a21\u5f0f\u7684\u5217\u8868\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 findall \u65b9\u6cd5\u3002 result = regex.findall(text) print(result) # [' ', '\\t ', ' \\t'] \u4e3a\u4e86\u5728\u6b63\u5219\u8868\u8fbe\u5f0f\u4e2d\u907f\u514d\u8f6c\u4e49\u7b26 \\ \u7684\u5f71\u54cd\uff0c\u53ef\u4ee5\u4f7f\u7528\u539f\u751f\u5b57\u7b26\u4e32\u8bed\u6cd5\uff0c\u6bd4\u5982 r'C:\\x' \u6216\u8005\u7528\u7b49\u4ef7\u7684 'C:\\\\x'\\ \u3002 \u5982\u679c\u9700\u8981\u5c06\u76f8\u540c\u7684\u8868\u8fbe\u5f0f\u5e94\u7528\u5230\u591a\u4e2a\u5b57\u7b26\u4e32\u4e0a\uff0c\u63a8\u8350\u4f7f\u7528 re.compile \u521b\u5efa\u4e00\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u8c61\uff0c\u8fd9\u6837\u505a\u6709\u5229\u4e8e\u8282\u7ea6CPU\u5468\u671f\u3002 match \u548c search \u4e0e findall \u76f8\u5173\u6027\u5f88\u5927\u3002 findall \u8fd4\u56de\u7684\u662f\u5b57\u7b26\u4e32\u4e2d\u6240\u6709\u7684\u5339\u914d\u9879\uff0c\u800c search \u8fd4\u56de\u7684\u4ec5\u4ec5\u662f\u7b2c\u4e00\u4e2a\u5339\u914d\u9879\u3002 match \u66f4\u4e3a\u4e25\u683c\uff0c\u5b83\u53ea\u5728\u5b57\u7b26\u4e32\u7684\u8d77\u59cb\u4f4d\u7f6e\u8fdb\u884c\u5339\u914d\u3002 text = \"\"\"Dave dave@google.com Steve steve@gmail.com Rob rob@gmail.com Ryan ryan@yahoo.com \"\"\" pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}' regex = re.compile(pattern, flags=re.IGNORECASE) # flags=re.IGNORECASE \u4f7f\u6b63\u5219\u8868\u8fbe\u5f0f\u4e0d\u533a\u5206\u5927\u5c0f\u5199 m = regex.findall(text) # findall\u4f1a\u751f\u6210\u4e00\u4e2a\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u7684\u5217\u8868 print(m) # ['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com'] search \u8fd4\u56de\u7684\u662f\u6587\u672c\u4e2d\u7b2c\u4e00\u4e2a\u5339\u914d\u5230\u7684\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u3002 \u5bf9\u4e8e\u524d\u9762\u63d0\u5230\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u5339\u914d\u5bf9\u8c61\u53ea\u80fd\u544a\u8bc9\u6211\u4eec\u6a21\u5f0f\u5728\u5b57\u7b26\u4e32\u4e2d\u8d77\u59cb\u548c\u7ed3\u675f\u7684\u4f4d\u7f6e\u3002 m = regex.search(text) print(m) # <re.Match object; span=(5, 20), match='dave@google.com'> print(text[m.start():m.end()]) # dave@google.com regex.match \u53ea\u5728\u6a21\u5f0f\u51fa\u73b0\u4e8e\u5b57\u7b26\u4e32\u8d77\u59cb\u4f4d\u7f6e\u65f6\u8fdb\u884c\u5339\u914d\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u5230\uff0c\u8fd4\u56de None \u3002 m = regex.match(text) print(m) # None m = regex.match('rob@gmail.com') print(m) # <re.Match object; span=(0, 13), match='rob@gmail.com'> print(m.group()) # rob@gmail.com print(m.groups()) # () regex.sub \u4f1a\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u5b57\u7b26\u4e32\uff0c\u539f\u5b57\u7b26\u4e32\u4e2d\u7684\u6a21\u5f0f\u4f1a\u88ab\u4e00\u4e2a\u65b0\u7684\u5b57\u7b26\u4e32\u66ff\u4ee3\u3002 m = regex.sub('REDACTED', text) print(m) # Dave REDACTED # Steve REDACTED # Rob REDACTED # Ryan REDACTED \u67e5\u627e\u7535\u5b50\u90ae\u4ef6\u5730\u5740\uff0c\u5e76\u5c06\u6bcf\u4e2a\u5730\u5740\u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a\u7528\u6237\u540d\uff0c\u57df\u540d\u548c\u57df\u540d\u540e\u7f00\u3002\u8981\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u53ef\u4ee5\u7528\u62ec\u53f7\u5c06 pattern \u5305\u8d77\u6765\u3002 \u4fee\u6539\u540e\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u4ea7\u751f\u7684\u5339\u914d\u5bf9\u8c61\u7684 groups \u65b9\u6cd5\uff0c\u8fd4\u56de\u7684\u662f\u6a21\u5f0f\u7ec4\u4ef6\u7684\u5143\u7ec4\u3002 text = \"\"\"Dave dave@google.com Steve steve@gmail.com Rob rob@gmail.com Ryan ryan@yahoo.com \"\"\" pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})' regex = re.compile(pattern, flags=re.IGNORECASE) m = regex.findall(text) # \u5f53pattern\u53ef\u4ee5\u5206\u7ec4\u65f6\uff0cfindall\u8fd4\u56de\u7684\u662f\u5305\u542b\u5143\u7ec4\u7684\u5217\u8868 print(m) # [('dave', 'google', 'com'), ('steve', 'gmail', 'com'), ('rob', 'gmail', 'com'), ('ryan', 'yahoo', 'com')] m = regex.search(text) print(m) # <re.Match object; span=(5, 20), match='dave@google.com'> print(text[m.start():m.end()]) # dave@google.com m = regex.match('rob@gmail.com') print(m) # <re.Match object; span=(0, 13), match='rob@gmail.com'> print(m.group()) # rob@gmail.com print(m.groups()) # ('rob', 'gmail', 'com') m = regex.sub('REDACTED', text) print(m) # Dave REDACTED # Steve REDACTED # Rob REDACTED # Ryan REDACTED m = regex.sub(r'Username: \\1, Domain: \\2, Suffix: \\3', text) print(m) # Dave Username: dave, Domain: google, Suffix: com # Steve Username: steve, Domain: gmail, Suffix: com # Rob Username: rob, Domain: gmail, Suffix: com # Ryan Username: ryan, Domain: yahoo, Suffix: com","title":"\u6b63\u5219\u8868\u8fbe\u5f0f"},{"location":"python/DataAnalysis/ch04/#pandas","text":"\u6e05\u7406\u6742\u4e71\u7684\u6570\u636e\u96c6\u7528\u4e8e\u5206\u6790\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u5b57\u7b26\u4e32\u5904\u7406\u548c\u6b63\u5219\u5316\u3002 data = { 'Dave': 'dave@gmail.com', 'Steve': 'steve@gmail.com', 'Rob': 'rob@gmail.com', 'Wes': np.nan } data = pd.Series(data) print(data) # Dave dave@gmail.com # Steve steve@gmail.com # Rob rob@gmail.com # Wes NaN # dtype: object print(data.isnull()) # Dave False # Steve False # Rob False # Wes True # dtype: bool \u53ef\u4ee5\u4f7f\u7528 data.map \u5c06\u5b57\u7b26\u4e32\u548c\u6709\u6548\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u65b9\u6cd5\uff08\u4ee5 lambda \u6216\u5176\u4ed6\u51fd\u6570\u7684\u65b9\u5f0f\u4f20\u9012\uff09\u5e94\u7528\u5230\u6bcf\u4e2a\u503c\u4e0a\uff0c\u4f46\u662f\u5728 NA \uff08 null \uff09\u503c\u4e0a\u4f1a\u5931\u8d25\u3002 \u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0cSeries\u6709\u9762\u5411\u6570\u7ec4\u7684\u65b9\u6cd5\u7528\u4e8e\u8df3\u8fc7 NA \u503c\u7684\u5b57\u7b26\u4e32\u64cd\u4f5c\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u8fc7Series\u7684 str \u5c5e\u6027\u8fdb\u884c\u8c03\u7528\u3002 \u4f8b\u5982\uff0c\u53ef\u4ee5\u901a\u8fc7 str.contains \u6765\u68c0\u67e5\u6bcf\u4e2a\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u662f\u5426\u542b\u6709 'gmail' \u3002 m = data.str.contains('gmail') print(m) # Dave True # Steve True # Rob True # Wes NaN # dtype: object \u6b63\u5219\u8868\u8fbe\u5f0f\u4e5f\u53ef\u4ee5\u7ed3\u5408\u4efb\u610f\u7684 re \u6a21\u5757\u9009\u9879\u4f7f\u7528\uff0c\u4f8b\u5982 IGNORECASE \u3002 print(pattern) # ([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4}) m = data.str.findall(pattern, flags=re.IGNORECASE) print(m) # Dave [(dave, gmail, com)] # Steve [(steve, gmail, com)] # Rob [(rob, gmail, com)] # Wes NaN # dtype: object \u4f7f\u7528 str.get \u6216\u5728 str \u5c5e\u6027\u5185\u90e8\u7d22\u5f15\uff0c\u8fdb\u884c\u5411\u91cf\u5316\u7684\u5143\u7d20\u68c0\u7d22\u3002 m = data.str.match(pattern, flags=re.IGNORECASE) print(m) # Dave True # Steve True # Rob True # Wes NaN # dtype: object m = data.str.findall(pattern, flags=re.IGNORECASE) print(m.str.get(1)) # Dave NaN # Steve NaN # Rob NaN # Wes NaN # dtype: float64 print(m.str[0]) # Dave (dave, gmail, com) # Steve (steve, gmail, com) # Rob (rob, gmail, com) # Wes NaN # dtype: object \u4f7f\u7528\u5b57\u7b26\u4e32\u5207\u7247\u7684\u7c7b\u4f3c\u8bed\u6cd5\u8fdb\u884c\u5411\u91cf\u5316\u5207\u7247\u3002 print(data.str[:]) # Dave dave@gmail.com # Steve steve@gmail.com # Rob rob@gmail.com # Wes NaN # dtype: object print(data.str[:5]) # Dave dave@ # Steve steve # Rob rob@g # Wes NaN # dtype: object","title":"pandas\u4e2d\u7684\u5411\u91cf\u5316\u5b57\u7b26\u4e32\u51fd\u6570"},{"location":"python/DataAnalysis/ch05/","text":"\u6570\u636e\u89c4\u6574\uff1a\u8fde\u63a5\u3001\u8054\u5408\u4e0e\u91cd\u5851 \u5206\u5c42\u7d22\u5f15 import pandas as pd import numpy as np import re \u5206\u5c42\u7d22\u5f15\u662fpandas\u7684\u91cd\u8981\u7279\u6027\uff0c\u5141\u8bb8\u4f60\u5728\u4e00\u4e2a\u8f74\u5411\u4e0a\u62e5\u6709\u591a\u4e2a\uff08\u4e24\u4e2a\u6216\u4e24\u4e2a\u4ee5\u4e0a\uff09\u7d22\u5f15\u5c42\u7ea7\u3002 \u5206\u5c42\u7d22 import re \u5f15\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u66f4\u4f4e\u7ef4\u5ea6\u7684\u5f62\u5f0f\u4e2d\u5904\u7406\u66f4\u9ad8\u7ef4\u5ea6\u6570\u636e\u7684\u65b9\u5f0f\u3002 Series\u7d22\u5f15\u5206\u5c42 data = pd.Series( np.random.randn(9), index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 3, 1, 2, 2, 3]] ) \u8f93\u51fa\u662f\u4e00\u4e2a\u4ee5 MultiIndex \u4f5c\u4e3a\u7d22\u5f15\u7684Series\u7684\u7f8e\u5316\u89c6\u56fe\u3002 \u7d22\u5f15\u4e2d\u7684\"\u95f4\u9699\"\u8868\u793a\"\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u6807\u7b7e\"\u3002 print(data) # a 1 0.163468 # 2 -1.525926 # 3 -0.210247 # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # d 2 0.034305 # 3 -0.896078 # dtype: float64 print(data.index) # MultiIndex([('a', 1), # ('a', 2), # ('a', 3), # ('b', 1), # ('b', 3), # ('c', 1), # ('c', 2), # ('d', 2), # ('d', 3)], # ) \u901a\u8fc7\u5206\u5c42\u7d22\u5f15\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u79f0\u4e3a\u90e8\u5206\u7d22\u5f15\uff0c\u53ef\u4ee5\u7b80\u6d01\u5730\u9009\u62e9\u51fa\u6570\u636e\u7684\u5b50\u96c6\u3002 m = data['b'] print(m) # 1 -0.956063 # 3 -1.839111 # dtype: float64 m = data['b': 'c'] print(m) # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # dtype: float64 m = data.loc[['b', 'c']] print(m) # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # dtype: float64 m = data.loc[:, 2] print(m) # a -1.525926 # c 0.595279 # d 0.034305 # dtype: float64 \u5206\u5c42\u7d22\u5f15\u5728\u91cd\u5851\u6570\u636e\u548c\u6570\u7ec4\u900f\u89c6\u8868\u7b49\u5206\u7ec4\u64cd\u4f5c\u4e2d\u626e\u6f14\u4e86\u91cd\u8981\u89d2\u8272\u3002 \u4f8b\u5982\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 unstack \u65b9\u6cd5\u5c06\u6570\u636e\u5728DataFrame\u4e2d\u91cd\u65b0\u6392\u5217\u3002 m = data.unstack() print(m) # 1 2 3 # a 0.163468 -1.525926 -0.210247 # b -0.956063 NaN -1.839111 # c -0.398905 0.595279 NaN # d NaN 0.034305 -0.896078 n = m.stack() print(n) # \u6216\u8005 print(data.unstack().stack()) # a 1 0.163468 # 2 -1.525926 # 3 -0.210247 # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # d 2 0.034305 # 3 -0.896078 # dtype: float64 DataFrame\u7d22\u5f15\u5206\u5c42 \u5728DataFrame\u4e2d\uff0c\u6bcf\u4e2a\u8f74\u90fd\u53ef\u4ee5\u62e5\u6709\u5206\u5c42\u7d22\u5f15\u3002 \u53c2\u8003 \u65b9\u6cd51\uff1a\u76f4\u63a5\u521b\u5efa \u76f4\u63a5\u901a\u8fc7\u7ed9 index \uff08columns\uff09\u53c2\u6570\u4f20\u9012\u591a\u7ef4\u6570\u7ec4\uff0c\u8fdb\u800c\u6784\u5efa\u591a\u7ef4\u7d22\u5f15\u3002 \u6570\u7ec4\u4e2d\u6bcf\u4e2a\u7ef4\u5ea6\u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c\u7ec4\u6210\u6bcf\u4e2a\u7d22\u5f15\u503c\u3002 frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) print(frame) # Ohio Colorado # Green Red Green # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 \u4e0a\u9762\u8f93\u51fa\u4e2d\u76842\u4e2a\u5c42\u7ea7\u662f\u6ca1\u6709\u540d\u5b57\u3002 \u5206\u5c42\u7684\u5c42\u7ea7\u53ef\u4ee5\u6709\u540d\u79f0\uff08\u53ef\u4ee5\u662f\u5b57\u7b26\u4e32\u6216Python\u5bf9\u8c61\uff09\u3002 \u5982\u679c\u5c42\u7ea7\u6709\u540d\u79f0\uff0c\u8fd9\u4e9b\u540d\u79f0\u4f1a\u5728\u63a7\u5236\u53f0\u8f93\u51fa\u4e2d\u663e\u793a\u3002 print(frame.index.names) # [None, None] print(frame.columns.names) # [None, None] \u7ed9\u5c42\u7ea7\u8d4b\u4e88\u540d\u79f0\u3002\u6ce8\u610f\u533a\u5206\u884c\u6807\u7b7e\u4e2d\u7684\u7d22\u5f15\u540d\u79f0 state \u548c color \u3002 frame.index.names = ['key1', 'key2'] frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 print(frame['Ohio']) # color Green Red # key1 key2 # a 1 0 1 # 2 3 4 # b 1 6 7 # 2 9 10 print(frame.index) # MultiIndex([('a', 1), # ('a', 2), # ('b', 1), # ('b', 2)], # names=['key1', 'key2']) \u901a\u8fc7 MultiIndex \u7c7b\u7684\u76f8\u5173\u65b9\u6cd5\uff0c\u9884\u5148\u521b\u5efa\u4e00\u4e2a MultiIndex \u5bf9\u8c61\uff0c\u7136\u540e\u4f5c\u4e3aSeries\u4e0eDataFrame\u4e2d\u7684 index \uff08\u6216columns\uff09\u53c2\u6570\u503c\u3002\u540c\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7 names \u53c2\u6570\u6307\u5b9a\u591a\u5c42\u7d22\u5f15\u7684\u540d\u79f0\u3002 \u65b9\u6cd52\uff1afrom_arrays from_arrays \uff1a\u63a5\u6536\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u53c2\u6570\uff0c\u9ad8\u7ef4\u6307\u5b9a\u9ad8\u5c42\u7d22\u5f15\uff0c\u4f4e\u7ef4\u6307\u5b9a\u5e95\u5c42\u7d22\u5f15\u3002 mindex = pd.MultiIndex.from_arrays( [['a', 'a', 'b', 'b'], [1, 2, 1, 2]], names=['key1', 'key2'] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 \u65b9\u6cd53\uff1afrom_tuples from_tuples \uff1a\u63a5\u6536\u4e00\u4e2a\u5143\u7ec4\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7ec4\u6307\u5b9a\u6bcf\u4e2a\u7d22\u5f15\uff08\u9ad8\u7ef4\u7d22\u5f15\uff0c\u4f4e\u7ef4\u7d22\u5f15\uff09\u3002 mindex = pd.MultiIndex.from_tuples( [('a', 1), ('a', 2), ('b', 1), ('b', 2)] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.index.names = ['key1', 'key2'] frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 \u65b9\u6cd54\uff1afrom_product from_product \uff1a\u63a5\u6536\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u5217\u8868\uff0c\u6839\u636e\u591a\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5143\u7d20\u7684\u7b1b\u5361\u5c14\u79ef\u8fdb\u884c\u521b\u5efa\u7d22\u5f15\u3002 \u4f7f\u7528\u7b1b\u5361\u5c14\u79ef\u7684\u65b9\u5f0f\u6765\u521b\u5efa\u591a\u5c42\u7d22\u5f15\u3002\u53c2\u6570\u4e3a\u5d4c\u5957\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u3002\u7ed3\u679c\u4e3a\u4f7f\u7528\u6bcf\u4e2a\u4e00\u7ef4\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\u4e0e\u5176\u4ed6\u4e00\u7ef4\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\u6765\u751f\u6210\u3002 \u7b1b\u5361\u5c14\u79ef\u7684\u65b9\u5f0f\u7684\u5c40\u9650\uff1a\u4e24\u4e24\u7ec4\u5408\u5fc5\u987b\u90fd\u5b58\u5728\uff0c\u5426\u5219\uff0c\u5c31\u4e0d\u80fd\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u3002 mindex = pd.MultiIndex.from_product( [['a', 'b'], ['1', '2']], names=['key1', 'key2'] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 \u91cd\u6392\u5e8f\u548c\u5c42\u7ea7\u6392\u5e8f \u5982\u679c\u9700\u8981\u91cd\u65b0\u6392\u5217\u8f74\u4e0a\u7684\u5c42\u7ea7\u987a\u5e8f\uff0c\u6216\u8005\u6309\u7167\u7279\u5b9a\u5c42\u7ea7\u7684\u503c\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\uff0c \u53ef\u4ee5\u901a\u8fc7swaplevel\u63a5\u6536\u4e24\u4e2a\u5c42\u7ea7\u5e8f\u53f7\u6216\u5c42\u7ea7\u540d\u79f0\uff0c\u8fd4\u56de\u4e00\u4e2a\u8fdb\u884c\u4e86\u5c42\u7ea7\u53d8\u66f4\u7684\u65b0\u5bf9\u8c61\uff08\u4f46\u662f\u6570\u636e\u662f\u4e0d\u53d8\u7684\uff09\u3002 print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.swaplevel('key1', 'key2') print(m) # state Ohio Colorado # color Green Red Green # key2 key1 # 1 a 0 1 2 # 2 a 3 4 5 # 1 b 6 7 8 # 2 b 9 10 11 sort_index \u53ea\u80fd\u5728\u5355\u4e00\u5c42\u7ea7\u4e0a\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\u3002 \u5728\u8fdb\u884c\u5c42\u7ea7\u53d8\u6362\u65f6\uff0c\u4f7f\u7528 sort_index \u4ee5\u4f7f\u5f97\u7ed3\u679c\u6309\u7167\u5c42\u7ea7\u8fdb\u884c\u5b57\u5178\u6392\u5e8f\u3002 m = frame.sort_index(level=1) # \u5bf9key2\u6392\u5e8f\uff0c\u5e95\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # b 1 6 7 8 # a 2 3 4 5 # b 2 9 10 11 m = frame.sort_index(level=0) # \u5bf9key1\u6392\u5e8f\uff0c\u9ad8\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.swaplevel(0, 1).sort_index(level=1) # swaplevel(0, 1)\u7b49\u540c\u4e8eswaplevel(key1, key2)\uff0c\u4ea4\u6362\u540ekey1\u53d8\u6210\u4e86\u5e95\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key2 key1 # 1 a 0 1 2 # 2 a 3 4 5 # 1 b 6 7 8 # 2 b 9 10 11 \u6309\u5c42\u7ea7\u8fdb\u884c\u6c47\u603b\u7edf\u8ba1 DataFrame\u548cSeries\u4e2d\u5f88\u591a\u63cf\u8ff0\u6027\u548c\u6c47\u603b\u6027\u7edf\u8ba1\u6709\u4e00\u4e2a level \u9009\u9879\uff0c\u901a\u8fc7 level \u9009\u9879\u4f60\u53ef\u4ee5\u6307\u5b9a\u4f60\u60f3\u8981\u5728\u67d0\u4e2a\u7279\u5b9a\u7684\u8f74\u4e0a\u8fdb\u884c\u805a\u5408\u3002 print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.groupby(level='key2').sum() print(m) # state Ohio Colorado # color Green Red Green # key2 # 1 6 8 10 # 2 12 14 16 m = frame.groupby(level='color', axis=1).sum() print(m) # color Green Red # key1 key2 # a 1 2 1 # 2 8 4 # b 1 14 7 # 2 20 10 \u4f7f\u7528DataFrame\u7684\u5217\u8fdb\u884c\u7d22\u5f15 \u901a\u5e38\u6211\u4eec\u4e0d\u4f1a\u4f7f\u7528DataFrame\u4e2d\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u884c\u7d22\u5f15\uff1b\u53cd\u800c\u4f60\u53ef\u80fd\u60f3\u8981\u5c06\u884c\u7d22\u5f15\u79fb\u52a8\u5230DataFrame\u7684\u5217\u4e2d\u3002 frame = pd.DataFrame( {'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': [0, 1, 2, 0, 1, 2, 3] } ) print(frame) # a b c d # 0 0 7 one 0 # 1 1 6 one 1 # 2 2 5 one 2 # 3 3 4 two 0 # 4 4 3 two 1 # 5 5 2 two 2 # 6 6 1 two 3 DataFrame\u7684 set_index \u51fd\u6570\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684DataFrame\uff0c\u65b0\u7684DataFrame\u4f7f\u7528\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u7d22\u5f15\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\u8fd9\u4e9b\u7d22\u5f15\u5217\u4f1a\u4eceDataFrame\u4e2d\u79fb\u9664\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5b83\u4eec\u7559\u5728DataFrame\u4e2d\u3002 frame2 = frame.set_index(['c', 'd'], drop=False) print(frame2) # a b c d # c d # one 0 0 7 one 0 # 1 1 6 one 1 # 2 2 5 one 2 # two 0 3 4 two 0 # 1 4 3 two 1 # 2 5 2 two 2 # 3 6 1 two 3 frame2 = frame.set_index(['c', 'd']) print(frame2) # a b # c d # one 0 0 7 # 1 1 6 # 2 2 5 # two 0 3 4 # 1 4 3 # 2 5 2 # 3 6 1 reset_index \u662f set_index \u7684\u53cd\u64cd\u4f5c\uff0c\u5206\u5c42\u7d22\u5f15\u7684\u7d22\u5f15\u5c42\u7ea7\u4f1a\u88ab\u79fb\u52a8\u5230\u5217\u4e2d\u3002 \u6ce8\u610f\uff1a\u5982\u679c\u5728 set_index \u65f6\u4f7f\u7528\u4e86 drop=False \uff0c\u5728\u4f7f\u7528 reset_index \u4f1a\u62a5\u9519\u3002 m = frame2.reset_index() print(m) # c d a b # 0 one 0 0 7 # 1 one 1 1 6 # 2 one 2 2 5 # 3 two 0 3 4 # 4 two 1 4 3 # 5 two 2 5 2 # 6 two 3 6 1 \u8054\u5408\u4e0e\u5408\u5e76\u6570\u636e\u96c6 \u5305\u542b\u5728pandas\u5bf9\u8c61\u7684\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u591a\u79cd\u65b9\u5f0f\u8054\u5408\u5728\u4e00\u8d77\uff1a pandas.merge \u6839\u636e\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u5c06\u884c\u8fdb\u884c\u8fde\u63a5\u3002\u5bf9\u4e8eSQL\u6216\u5176\u4ed6\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u7528\u6237\u6765\u8bf4\uff0c\u8fd9\u79cd\u65b9\u5f0f\u6bd4\u8f83\u719f\u6089\uff0c\u5b83\u5b9e\u73b0\u7684\u662f\u6570\u636e\u5e93\u7684\u8fde\u63a5\u64cd\u4f5c\u3002 pandas.concat \u4f7f\u5bf9\u8c61\u5728\u8f74\u5411\u4e0a\u8fdb\u884c\u9ecf\u5408\u6216\u201c\u5806\u53e0\u201d\u3002 combine_first \u5b9e\u4f8b\u65b9\u6cd5\u5141\u8bb8\u5c06\u91cd\u53e0\u7684\u6570\u636e\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u503c\u586b\u5145\u53e6\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u7f3a\u5931\u503c\u3002 \u6570\u636e\u5e93\u98ce\u683c\u7684DataFrame\u8fde\u63a5 \u5408\u5e76\u6216\u8fde\u63a5\u64cd\u4f5c\u901a\u8fc7\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u8fde\u63a5\u884c\u6765\u8054\u5408\u6570\u636e\u96c6\u3002 \u8fd9\u4e9b\u64cd\u4f5c\u662f\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u6838\u5fc3\u5185\u5bb9\uff08\u4f8b\u5982\u57fa\u4e8eSQL\u7684\u6570\u636e\u5e93\uff09\u3002 pandas\u4e2d\u7684 merge \u51fd\u6570\u4e3b\u8981\u7528\u4e8e\u5c06\u5404\u79cd join \u64cd\u4f5c\u7b97\u6cd5\u8fd0\u7528\u5728\u6570\u636e\u4e0a\u3002 \u5728\u8fdb\u884c\u5217-\u5217\u8fde\u63a5\u65f6\uff0c\u4f20\u9012\u7684DataFrame\u7d22\u5f15\u5bf9\u8c61\u4f1a\u88ab\u4e22\u5f03\u3002 \u5408\u5e76\u64cd\u4f5c\u4e5f\u8981\u8003\u8651\u5982\u4f55\u5904\u7406\u91cd\u53e0\u7684\u5217\u540d( suffixes \u540e\u7f00\u9009\u9879)\u3002 \u4e0b\u9762\u662f\u4e00\u4e2a\u591a\u5bf9\u4e00\u8fde\u63a5\u7684\u4f8b\u5b50\u3002 df1 \u7684\u6570\u636e\u6709\u591a\u4e2a\u884c\u7684\u6807\u7b7e\u4e3a a \u548c b \uff0c\u800c df2 \u5728 key \u5217\u4e2d\u6bcf\u4e2a\u503c\u4ec5\u6709\u4e00\u884c\u3002 df1 = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7) } ) df2 = pd.DataFrame( { 'key': ['a', 'b', 'd'], 'data1': range(3) } ) print(df1) # key data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 a 5 # 6 b 6 print(df2) # key data1 # 0 a 0 # 1 b 1 # 2 d 2 \u8c03\u7528 merge \u5904\u7406\uff0c\u63a8\u8350\u663e\u5f0f\u5730\u6307\u5b9a\u8fde\u63a5\u952e\u3002 result = pd.merge(df1, df2) print(result) # key data1 # 0 b 1 result = pd.merge(df1, df2, on=['key', 'data1']) print(result) # key data1 # 0 b 1 result = pd.merge(df1, df2, on='key') print(result) # key data1_x data1_y # 0 b 0 1 # 1 b 1 1 # 2 b 6 1 # 3 a 2 0 # 4 a 4 0 # 5 a 5 0 \u5982\u679c\u6bcf\u4e2a\u5bf9\u8c61\u7684\u5217\u540d\u662f\u4e0d\u540c\u7684\uff0c\u53ef\u4ee5\u5206\u522b\u4e3a\u5b83\u4eec\u6307\u5b9a\u5217\u540d\u3002 df3 = pd.DataFrame( { 'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7) } ) df4 = pd.DataFrame( { 'rkey': ['a', 'b', 'd'], 'data2': range(3) } ) print(df3) # lkey data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 a 5 # 6 b 6 print(df4) # rkey data2 # 0 a 0 # 1 b 1 # 2 d 2 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c merge \u505a\u7684\u662f\u5185\u8fde\u63a5\uff08'inner' join\uff09\uff0c\u7ed3\u679c\u4e2d\u7684\u952e\u662f\u4e24\u5f20\u8868\u7684\u4ea4\u96c6\u3002 result = pd.merge(df3, df4, left_on='lkey', right_on='rkey') # df4\u7684[a,0]\u5bf9\u5e94df3\u7684\u6240\u6709[a,?]\u8bb0\u5f55\uff08\u901a\u8fc7\u91cd\u590d\u6765\u586b\u5145\u4e0d\u8db3\uff09 print(result) # lkey data1 rkey data2 # 0 b 0 b 1 # 1 b 1 b 1 # 2 b 6 b 1 # 3 a 2 a 0 # 4 a 4 a 0 # 5 a 5 a 0 \u5916\u8fde\u63a5\uff08outer join\uff09\u662f\u952e\u7684\u5e76\u96c6\uff0c\u8054\u5408\u4e86\u5de6\u8fde\u63a5\u548c\u53f3\u8fde\u63a5\u7684\u6548\u679c\u3002 \u591a\u5bf9\u591a\u8fde\u63a5\u662f\u884c\u7684\u7b1b\u5361\u5c14\u79ef\u3002 df1 = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6) } ) df2 = pd.DataFrame( { 'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5) } ) print(df1.sort_values(by='key')) # key data1 # 2 a 2 # 4 a 4 # 0 b 0 # 1 b 1 # 5 b 5 # 3 c 3 print(df2.sort_values(by='key')) # key data2 # 0 a 0 # 2 a 2 # 1 b 1 # 3 b 3 # 4 d 4 result = pd.merge(df1, df2, on='key', how='left') print(result.sort_values(by='key')) # key data1 data2 # 4 a 2 0.0 # 5 a 2 2.0 # 7 a 4 0.0 # 8 a 4 2.0 # 0 b 0 1.0 # 1 b 0 3.0 # 2 b 1 1.0 # 3 b 1 3.0 # 9 b 5 1.0 # 10 b 5 3.0 # 6 c 3 NaN result = pd.merge(df1, df2, on='key', how='outer') # \u591a\u5bf9\u591a\u8fde\u63a5 print(result.sort_values(by='key')) # key data1 data2 # 6 a 2.0 0.0 # 7 a 2.0 2.0 # 8 a 4.0 0.0 # 9 a 4.0 2.0 # 0 b 0.0 1.0 # 1 b 0.0 3.0 # 2 b 1.0 1.0 # 3 b 1.0 3.0 # 4 b 5.0 1.0 # 5 b 5.0 3.0 # 10 c 3.0 NaN # 11 d NaN 4.0 \u591a\u952e\u5408\u5e76\u3002 df1 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3] } ) df2 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7] } ) print(df1.sort_values(by=['key1', 'key2'])) # key1 key2 lval # 2 bar one 3 # 0 foo one 1 # 1 foo two 2 print(df2.sort_values(by=['key1', 'key2'])) # key1 key2 rval # 2 bar one 6 # 3 bar two 7 # 0 foo one 4 # 1 foo one 5 result = pd.merge(df1, df2, on=['key1', 'key2'], how='outer') print(result.sort_values(by=['key1', 'key2'])) # key1 key2 lval rval # 3 bar one 3.0 6.0 # 4 bar two NaN 7.0 # 0 foo one 1.0 4.0 # \u91cd\u590d\u586b\u5145 # 1 foo one 1.0 5.0 # \u91cd\u590d\u586b\u5145 # 2 foo two 2.0 NaN \u5904\u7406\u91cd\u53e0\u5217\u540d\u3002 result = pd.merge(df1, df2, on='key1') print(result.sort_values(by='key1')) # key1 key2_x lval key2_y rval # 4 bar one 3 one 6 # 5 bar one 3 two 7 # 0 foo one 1 one 4 # 1 foo one 1 one 5 # 2 foo two 2 one 4 # 3 foo two 2 one 5 result = pd.merge(df1, df2, on='key1', suffixes=('_left', '_right')) print(result.sort_values(by='key1')) # key1 key2_left lval key2_right rval # 4 bar one 3 one 6 # 5 bar one 3 two 7 # 0 foo one 1 one 4 # 1 foo one 1 one 5 # 2 foo two 2 one 4 # 3 foo two 2 one 5 \u6839\u636e\u7d22\u5f15\u5408\u5e76 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0cDataFrame\u4e2d\u7528\u4e8e\u5408\u5e76\u7684\u952e\u662f\u5b83\u7684\u7d22\u5f15\u3002\u53ef\u4ee5\u4f20\u9012 left_index=True \u6216 right_index=True \uff08\u6216\u8005\u90fd\u4f20\uff09\u6765\u8868\u793a\u7d22\u5f15\u9700\u8981\u7528\u6765\u4f5c\u4e3a\u5408\u5e76\u7684\u952e\u3002 df1 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3] } ) df2 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7] }, index=['foo', 'foo', 'bar', 'bar'] ) print(df1) # key1 key2 lval # 0 foo one 1 # 1 foo two 2 # 2 bar one 3 print(df2) # key1 key2 rval # foo foo one 4 # foo foo one 5 # bar bar one 6 # bar bar two 7 result = pd.merge(df1, df2, left_on='key1', right_index=True, suffixes=('_left', '_right')) print(result.sort_index()) # key1 key1_left key2_left lval key1_right key2_right rval # 0 foo foo one 1 foo one 4 # 0 foo foo one 1 foo one 5 # 1 foo foo two 2 foo one 4 # 1 foo foo two 2 foo one 5 # 2 bar bar one 3 bar one 6 # 2 bar bar one 3 bar two 7 result = pd.merge(df1, df2, left_on='key1', right_index=True, how='outer', suffixes=('_left', '_right')) # \u548c\u4e0a\u8ff0\u7ed3\u679c\u4e00\u6837 print(result.sort_index()) # key1 key1_left key2_left lval key1_right key2_right rval # 0 foo foo one 1 foo one 4 # 0 foo foo one 1 foo one 5 # 1 foo foo two 2 foo one 4 # 1 foo foo two 2 foo one 5 # 2 bar bar one 3 bar one 6 # 2 bar bar one 3 bar two 7 \u5728\u66f4\u590d\u6742\u591a\u5c42\u7d22\u5f15\u6570\u636e\u7684\u591a\u952e\u5408\u5e76\uff0c\u5728\u7d22\u5f15\u4e0a\u8fde\u63a5\u662f\u4e00\u4e2a\u9690\u5f0f\u7684\u591a\u952e\u5408\u5e76\u3002 \u5fc5\u987b\u4ee5\u5217\u8868\u7684\u65b9\u5f0f\u6307\u660e\u5408\u5e76\u6240\u9700\u591a\u4e2a\u5217\uff08\u6ce8\u610f\u4f7f\u7528 how='outer' \u5904\u7406\u91cd\u590d\u7684\u7d22\u5f15\u503c\uff09\u3002 df1 = pd.DataFrame( { 'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'key2': [2000, 2001, 2002, 2001, 2002], 'data': np.arange(5.) } ) df2 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'], [2001, 2000, 2000, 2000, 2001, 2002] ], columns=['event1', 'event2'] ) print(df1) # key1 key2 data # 0 Ohio 2000 0.0 # 1 Ohio 2001 1.0 # 2 Ohio 2002 2.0 # 3 Nevada 2001 3.0 # 4 Nevada 2002 4.0 print(df2) # event1 event2 # Nevada 2001 0 1 # 2000 2 3 # Ohio 2000 4 5 # 2000 6 7 # 2001 8 9 # 2002 10 11 result = pd.merge(df1, df2, left_on=['key1', 'key2'], right_index=True) print(result) # key1 key2 data event1 event2 # 0 Ohio 2000 0.0 4 5 # 0 Ohio 2000 0.0 6 7 # 1 Ohio 2001 1.0 8 9 # 2 Ohio 2002 2.0 10 11 # 3 Nevada 2001 3.0 0 1 result = pd.merge(df1, df2, left_on=['key1', 'key2'], right_index=True, how='outer') print(result) # key1 key2 data event1 event2 # 0 Ohio 2000 0.0 4.0 5.0 # 0 Ohio 2000 0.0 6.0 7.0 # 1 Ohio 2001 1.0 8.0 9.0 # 2 Ohio 2002 2.0 10.0 11.0 # 3 Nevada 2001 3.0 0.0 1.0 # 4 Nevada 2002 4.0 NaN NaN # 4 Nevada 2000 NaN 2.0 3.0 \u4f7f\u7528\u4e24\u8fb9\u7684\u7d22\u5f15\u8fdb\u884c\u5408\u5e76\u4e5f\u662f\u53ef\u4ee5\u7684\uff0c\u524d\u63d0\u662f\u7528\u4e24\u8fb9\u7528\u6765\u5408\u5e76\u7684\u7d22\u5f15\u6709\u4ea4\u96c6\uff08\u516c\u5171\u90e8\u5206\uff09\u3002 \u5728\u4f7f\u7528 merge \u65f6\uff0c\u53c2\u6570 on=['key1', 'key2'] \u4e0d\u80fd\u548c left_index=True , right_index=True \u540c\u65f6\u5b58\u5728\u3002 \u5bf9\u4e8e\u91cd\u590d\u7d22\u5f15\uff0c\u5982\u679c\u503c\u4e0d\u540c\uff0c\u5219\u591a\u884c\u663e\u793a\uff0c\u548c\u6570\u636e\u5e93SQL\u7684 full join \u7c7b\u4f3c\u6982\u5ff5\u3002 \u5982\u679c\u51fa\u73b0\u76f8\u540c\u5217\u540d\uff0c\u5219\u4f1a\u81ea\u52a8\u6dfb\u52a0\u540e\u7f00\u5b57\u7b26\u4ee5\u793a\u533a\u522b\u3002 df1 = pd.DataFrame( [[1, 2], [3, 4], [5, 6]], index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'] ) print(df1) # Ohio Nevada # a 1 2 # c 3 4 # e 5 6 df2 = pd.DataFrame( [[7, 8], [9, 10], [11, 12], [13, 14]], index=['b', 'c', 'c', 'e'], columns=['Missouri', 'Alabama'] ) print(df2) # Missouri Alabama # b 7 8 # c 9 10 # c 11 12 # e 13 14 df3 = pd.DataFrame( [[7, 8], [9, 10], [11, 12], [13, 14]], index=['a', 'c', 'e', 'f'], columns=['Nevada', 'Alabama'] ) print(df3) # Nevada Alabama # a 7 8 # c 9 10 # e 11 12 # f 13 14 result = pd.merge(df1, df2, left_index=True, right_index=True, how='outer') print(result) # Ohio Nevada Missouri Alabama # a 1.0 2.0 NaN NaN # b NaN NaN 7.0 8.0 # c 3.0 4.0 9.0 10.0 # c 3.0 4.0 11.0 12.0 # e 5.0 6.0 13.0 14.0 result = pd.merge(df1, df3, left_index=True, right_index=True, how='outer') print(result) # Ohio Nevada_x Nevada_y Alabama # a 1.0 2.0 7 8 # c 3.0 4.0 9 10 # e 5.0 6.0 11 12 # f NaN NaN 13 14 \u53e6\u4e00\u79cd\u5199\u6cd5\uff1a result = df1.join(df2, how='outer') print(result) # Ohio Nevada Missouri Alabama # a 1.0 2.0 NaN NaN # b NaN NaN 7.0 8.0 # c 3.0 4.0 9.0 10.0 # c 3.0 4.0 11.0 12.0 # e 5.0 6.0 13.0 14.0 \u4e5f\u53ef\u4ee5\u5411 join \u65b9\u6cd5\u4f20\u5165\u4e00\u4e2aDataFrame\u5217\u8868\uff0c\u7c7b\u4f3c\u4e8e\u5bf9\u4e09\u4e2a\u6570\u636e\u96c6\u8fdb\u884c join \u64cd\u4f5c\u3002 result = df1.join([df2, df3]) print(result) # Ohio Nevada_x Missouri Alabama_x Nevada_y Alabama_y # a 1 2 NaN NaN 7 8 # c 3 4 9.0 10.0 9 10 # c 3 4 11.0 12.0 9 10 # e 5 6 13.0 14.0 11 12 \u6cbf\u8f74\u5411\u8fde\u63a5 \u53e6\u4e00\u79cd\u6570\u636e\u7ec4\u5408\u64cd\u4f5c\u53ef\u79f0\u4e3a\u62fc\u63a5\u3001\u7ed1\u5b9a\u6216\u5806\u53e0\u3002NumPy\u7684 concatenate \u51fd\u6570\u53ef\u4ee5\u5728NumPy\u6570\u7ec4\u4e0a\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 \u57fa\u4e8eSeries\u7684pandas\u7684 concat \u51fd\u6570\u7684\u5de5\u4f5c\u673a\u5236\u5206\u6790\u3002 \u4e0b\u9762\u4e09\u4e2a\u7d22\u5f15\u4e0d\u91cd\u53e0\u7684Series\u3002 s1 = pd.Series([0, 1], index=['a', 'b']) s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e']) s3 = pd.Series([5, 6], index=['f', 'g']) \u7528\u5217\u8868\u4e2d\u7684\u8fd9\u4e9b\u5bf9\u8c61\u8c03\u7528 concat \u65b9\u6cd5\u4f1a\u5c06\u503c\u548c\u7d22\u5f15\u7c98\u5728\u4e00\u8d77\uff1a \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c concat \u65b9\u6cd5\u662f\u6cbf\u7740 axis=0 \u7684\u8f74\u5411\u751f\u6548\u7684\uff0c\u751f\u6210\u53e6\u4e00\u4e2aSeries\u3002 \u5982\u679c\u4f20\u9012 axis=1 \uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u5219\u662f\u4e00\u4e2aDataFrame\uff08 axis=1 \u65f6\u662f\u5217\uff09\u3002 result = pd.concat([s1, s2, s3]) print(result) # a 0 # b 1 # c 2 # d 3 # e 4 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s2, s3], keys=['one', 'two', 'three']) # \u901a\u8fc7keys\u53c2\u6570\uff0c\u5728\u8fde\u63a5\u8f74\u5411\u4e0a\u521b\u5efa\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15\uff0c\u4ee5\u4fbf\u5728\u7ed3\u679c\u4e2d\u533a\u5206\u5404\u90e8\u5206 print(result) # one a 0 # b 1 # two c 2 # d 3 # e 4 # three f 5 # g 6 # dtype: int64 print(result.unstack()) # \u628a\u539f\u7d22\u5f15\u4f5c\u4e3a\u5217\u6807\u7b7e\u5c55\u5f00 # a b c d e f g # one 0.0 1.0 NaN NaN NaN NaN NaN # two NaN NaN 2.0 3.0 4.0 NaN NaN # three NaN NaN NaN NaN NaN 5.0 6.0 result = pd.concat([s1, s2, s3], axis=1) # \u5728\u8fd9\u4e2a\u6848\u4f8b\u4e2daxis=1\u8f74\u5411\u4e0a\u5e76\u6ca1\u6709\u91cd\u53e0 print(result) # 0 1 2 # a 0.0 NaN NaN # b 1.0 NaN NaN # c NaN 2.0 NaN # d NaN 3.0 NaN # e NaN 4.0 NaN # f NaN NaN 5.0 # g NaN NaN 6.0 result = pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three']) # \u5728\u8fd9\u4e2a\u6848\u4f8b\u4e2daxis=1\u8f74\u5411\u4e0a\u5e76\u6ca1\u6709\u91cd\u53e0 print(result) # one two three # a 0.0 NaN NaN # b 1.0 NaN NaN # c NaN 2.0 NaN # d NaN 3.0 NaN # e NaN 4.0 NaN # f NaN NaN 5.0 # g NaN NaN 6.0 print(result.unstack()) # \u5bf9\u6bd4axis=0\u7684\u591a\u5c42\u7d22\u5f15\uff0c\u5f53axis=1\u65f6\u5bf9\u8f93\u51fa\u5404index\u7684\u5e76\u96c6\u505a\u4e86\u5206\u7ec4\u3002 # one a 0.0 # b 1.0 # c NaN # d NaN # e NaN # f NaN # g NaN # two a NaN # b NaN # c 2.0 # d 3.0 # e 4.0 # f NaN # g NaN # three a NaN # b NaN # c NaN # d NaN # e NaN # f 5.0 # g 6.0 # dtype: float64 s4 = pd.concat([s1, s3]) print(s4) # a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4]) print(result) # a 0 # b 1 # a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4], axis=1) # \u73b0\u5728\u5728\u4e2daxis=1\u8f74\u5411\u4e0a\u6709\u91cd\u53e0 print(result) # 0 1 # a 0.0 0 # b 1.0 1 # f NaN 5 # g NaN 6 result = pd.concat([s1, s4], axis=1, keys=['one', 'two', 'three']) print(result) # one two # a 0.0 0 # b 1.0 1 # f NaN 5 # g NaN 6 result = pd.concat([s1, s4], axis=0, keys=['one', 'two', 'three']) # \u901a\u8fc7keys\u53c2\u6570\uff0c\u5728\u8fde\u63a5\u8f74\u5411\u4e0a\u521b\u5efa\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15 print(result) # one a 0 # b 1 # two a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4], axis=1, join='inner') # \u5185\u8fde\u63a5\u65b9\u5f0f\u5408\u5e76\u7d22\u5f15\uff08\u7d22\u5f15\u4ea4\u96c6\uff09 print(result) # 0 1 # a 0 0 # b 1 1 result = pd.concat([s1, s4], axis=1).reindex(['a', 'c', 'b', 'e']) # \u4f7f\u7528join_axes(\u5df2\u88ab\u66ff\u6362\u6210reindex)\u6765\u6307\u5b9a\u7528\u4e8e\u8fde\u63a5\u5176\u4ed6\u8f74\u5411\u7684\u8f74 print(result) # 0 1 # a 0.0 0.0 # c NaN NaN # b 1.0 1.0 # e NaN NaN \u57fa\u4e8eDataFrame\u7684pandas\u7684 concat \u51fd\u6570\u7684\u5de5\u4f5c\u673a\u5236\u5206\u6790\u3002 df1 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], [2000, 2001, 2002, 2000, 2001, 2002] ], columns=['event1', 'event2'] ) df2 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], [2000, 2001, 2002, 2000, 2001, 2002] ], columns=['event3', 'event4'] ) print(df1) # event1 event2 # Ohio 2000 0 1 # 2001 2 3 # 2002 4 5 # Nevada 2000 6 7 # 2001 8 9 # 2002 10 11 print(df2) # event3 event4 # Ohio 2000 0 1 # 2001 2 3 # 2002 4 5 # Nevada 2000 6 7 # 2001 8 9 # 2002 10 11 result = np.concatenate([df1, df2], axis=0) # \u6cbf0\u8f74\u62fc\u63a5 print(result) # [[ 0 1] # [ 2 3] # [ 4 5] # [ 6 7] # [ 8 9] # [10 11] # [ 0 1] # [ 2 3] # [ 4 5] # [ 6 7] # [ 8 9] # [10 11]] result = np.concatenate([df1, df2], axis=1) # \u6cbf1\u8f74\u62fc\u63a5 print(result) # [[ 0 1 0 1] # [ 2 3 2 3] # [ 4 5 4 5] # [ 6 7 6 7] # [ 8 9 8 9] # [10 11 10 11]] result = np.concatenate([df1, df2], axis=None) # \u5c06\u6570\u7ec4\u5c55\u5e73 print(result) # [ 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11] \u8054\u5408\u91cd\u53e0\u6570\u636e \u53e6\u4e00\u4e2a\u6570\u636e\u8054\u5408\u573a\u666f\uff0c\u65e2\u4e0d\u662f\u5408\u5e76\u64cd\u4f5c\uff0c\u4e5f\u4e0d\u662f\u8fde\u63a5\u64cd\u4f5c\u3002 \u5047\u5982\u6709\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u8fd9\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u7d22\u5f15\u5168\u90e8\u6216\u90e8\u5206\u91cd\u53e0\uff0c\u901a\u8fc7NumPy\u7684 where \u51fd\u6570\u53ef\u4ee5\u8fdb\u884c\u9762\u5411\u6570\u7ec4\u7684if-else\u7b49\u4ef7\u64cd\u4f5c\u3002 s1 = pd.Series( [np.nan, 2.5, 0.0, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'] ) s2 = pd.Series( [0.0, np.nan, 2.0, np.nan, np.nan, 5.0], index=['a', 'b', 'c', 'd', 'e', 'f'] ) print(s1) # f NaN # e 2.5 # d 0.0 # c 3.5 # b 4.5 # a NaN # dtype: float64 print(s2) # a 0.0 # b NaN # c 2.0 # d NaN # e NaN # f 5.0 # dtype: float64 \u65b9\u6cd51\uff0c\u901a\u8fc7Numpy\u7684 where \u51fd\u6570\u3002 result = np.where(pd.isnull(s1), s2, s1) # An array with elements from 'x'(s2) where 'condition'(isnull(s1)) is True, and elements from 'y'(s1) elsewhere. print(result) # [0. 2.5 0. 3.5 4.5 5. ] # s1 # s2 # result # f NaN # a 0.0 0. \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94x(s2)\u7684\u5143\u7d20\uff08\u6ce8\u610f\uff0c\u4e0e\u7d22\u5f15\u987a\u5e8f\u65e0\u5173\uff09 # e 2.5 # b NaN 2.5 \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e0d\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94y(s1)\u7684\u5143\u7d20 # d 0.0 # c 2.0 0. # c 3.5 # d NaN 3.5 # b 4.5 # e NaN 4.5 # a NaN # f 5.0 5.0 \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94x(s2)\u7684\u5143\u7d20 result = np.where(pd.isnull(s2), s1, s2) print(result) # [0. 2.5 2. 3.5 4.5 5. ] \u65b9\u6cd52\uff0c\u901a\u8fc7Series\u7684 combine_first \u65b9\u6cd5\u3002 result = s2.combine_first(s1) # \u6ce8\u610f\uff0ccombine_first\u662f\u6309\u7167s2\u7684\u7d22\u5f15\u987a\u5e8f\u68c0\u7d22\u7684\uff0c\u76f8\u540c\u7d22\u5f15\u7684s1\u7684\u503c\u4f1a\u586b\u5145\u5bf9\u5e94s2\u7684null print(result) # a 0.0 # b 4.5 # c 2.0 # d 0.0 # e 2.5 # f 5.0 # dtype: float64 \u65b9\u6cd53\uff1aPandas\u7684 combine_first \u65b9\u6cd5\u3002 df1 = pd.DataFrame( { 'a': [1.0, np.nan, 5.0, np.nan], 'b': [np.nan, 2.0, np.nan, 6.0], 'c': [2.0, 6.0, 10.0, 15.0] } ) df2 = pd.DataFrame( { 'a': [5.0, 4.0, np.nan, 3.0, 7.0], 'b': [np.nan, 3.0, 4.0, 6.0, 8.0] } ) print(df1) # a b c # 0 1.0 NaN 2.0 # 1 NaN 2.0 6.0 # 2 5.0 NaN 10.0 # 3 NaN 6.0 15.0 print(df2) # a b # 0 5.0 NaN # 1 4.0 3.0 # 2 NaN 4.0 # 3 3.0 6.0 # 4 7.0 8.0 result = df2.combine_first(df1) # \u7528df1\u7684\u503c\u53bb\u586b\u5145df2\u5bf9\u5e94\u7d22\u5f15\u4f4d\u7f6e\u7684null\u503c print(result) # a b c # 0 5.0 NaN 2.0 # 1 4.0 3.0 6.0 # 2 5.0 4.0 10.0 # 3 3.0 6.0 15.0 # 4 7.0 8.0 NaN \u91cd\u5851\u548c\u900f\u89c6 \u91cd\u65b0\u6392\u5217\u8868\u683c\u578b\u6570\u636e\u6709\u591a\u79cd\u57fa\u7840\u64cd\u4f5c\u3002\u8fd9\u4e9b\u64cd\u4f5c\u88ab\u79f0\u4e3a\u91cd\u5851\u6216\u900f\u89c6\u3002 import numpy as np import pandas as pd \u4f7f\u7528\u591a\u5c42\u7d22\u5f15\u8fdb\u884c\u91cd\u5851 \u591a\u5c42\u7d22\u5f15\u5728DataFrame\u4e2d\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e00\u81f4\u6027\u65b9\u5f0f\u7528\u4e8e\u91cd\u6392\u5217\u6570\u636e\u3002\u4ee5\u4e0b\u662f\u4e24\u4e2a\u57fa\u7840\u64cd\u4f5c\uff1a statck\uff08\u5806\u53e0\uff09\u8be5\u64cd\u4f5c\u4f1a\u201c\u65cb\u8f6c\u201d\u6216\u5c06\u5217\u4e2d\u7684\u6570\u636e\u900f\u89c6\u5230\u884c\u3002 unstack\uff08\u62c6\u5806\uff09\u8be5\u64cd\u4f5c\u4f1a\u5c06\u884c\u4e2d\u7684\u6570\u636e\u900f\u89c6\u5230\u5217\u3002 df = pd.DataFrame( np.arange(6).reshape((2, 3)), index=pd.Index(['Ohio', 'Colorado'], name='state'), columns=pd.Index(['one', 'two', 'three'], name='number') ) print(df) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 \u5728\u8fd9\u4efd\u6570\u636e\u4e0a\u4f7f\u7528stack\u65b9\u6cd5\u4f1a\u5c06\u5217\u900f\u89c6\u5230\u884c\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684Series\uff1a result = df.stack() print(result) # state number # Ohio one 0 # two 1 # three 2 # Colorado one 3 # two 4 # three 5 # dtype: int64 \u4ece\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15\u5e8f\u5217\u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 unstack \u65b9\u6cd5\u5c06\u6570\u636e\u91cd\u6392\u5217\u540e\u653e\u5165\u4e00\u4e2aDataFrame\u4e2d\uff1a print(result.unstack()) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 print(result.unstack(0)) # \u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5c42\u7ea7\u5e8f\u53f7\u6216\u540d\u79f0\u6765\u62c6\u5206\u4e00\u4e2a\u4e0d\u540c\u7684\u5c42\u7ea7 # state Ohio Colorado # number # one 0 3 # two 1 4 # three 2 5 print(result.unstack(1)) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 print(result.unstack('state')) # \u8f93\u51fa\u7ed3\u679c\u548c\u4f20\u5165\u5c42\u7ea70\u4e00\u6837 # state Ohio Colorado # number # one 0 3 # two 1 4 # three 2 5 print(result.unstack('number')) # \u8f93\u51fa\u7ed3\u679c\u548c\u4f20\u5165\u5c42\u7ea71\u4e00\u6837 # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 \u5982\u679c\u5c42\u7ea7\u4e2d\u7684\u6240\u6709\u503c\u5e76\u672a\u5305\u542b\u4e8e\u6bcf\u4e2a\u5b50\u5206\u7ec4\u4e2d\u65f6\uff0c\u62c6\u5206\u53ef\u80fd\u4f1a\u5f15\u5165\u7f3a\u5931\u503c\uff1a s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd']) s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e']) s3 = pd.concat([s1, s2], keys=['one', 'two']) print(s3) # one a 0 # b 1 # c 2 # d 3 # two c 4 # d 5 # e 6 # dtype: int64 print(s3.unstack(0)) # one two # a 0.0 NaN # b 1.0 NaN # c 2.0 4.0 # d 3.0 5.0 # e NaN 6.0 print(s3.unstack(1)) print(s3.unstack()) # a b c d e # one 0.0 1.0 2.0 3.0 NaN # two NaN NaN 4.0 5.0 6.0 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5806\u53e0\u4f1a\u8fc7\u6ee4\u51fa\u7f3a\u5931\u503c\uff0c\u56e0\u6b64\u5806\u53e0\u62c6\u5806\u7684\u64cd\u4f5c\u662f\u53ef\u9006\u7684\u3002 print(s3.unstack().stack()) # one a 0.0 # b 1.0 # c 2.0 # d 3.0 # two c 4.0 # d 5.0 # e 6.0 # dtype: float64 print(s3.unstack().stack(dropna=False)) # one a 0.0 # b 1.0 # c 2.0 # d 3.0 # e NaN # two a NaN # b NaN # c 4.0 # d 5.0 # e 6.0 # dtype: float64 \u5728DataFrame\u4e2d\u62c6\u5806\u65f6\uff0c\u88ab\u62c6\u5806\u7684\u5c42\u7ea7\u4f1a\u53d8\u4e3a\u7ed3\u679c\u4e2d\u6700\u4f4e\u7684\u5c42\u7ea7\u3002 \u5728\u8c03\u7528 stack \u65b9\u6cd5\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u6307\u660e\u9700\u8981\u5806\u53e0\u7684\u8f74\u5411\u540d\u79f0\u3002 df = pd.DataFrame( {'left': result, 'right': result + 5}, columns=pd.Index(['left', 'right'], name='side') ) print(df) # side left right # state number # Ohio one 0 5 # two 1 6 # three 2 7 # Colorado one 3 8 # two 4 9 # three 5 10 print(df.unstack()) # side left right # number one two three one two three # state # Ohio 0 1 2 5 6 7 # Colorado 3 4 5 8 9 10 print(df.unstack('state')) # \u88ab\u62c6\u5806\u7684\u5c42\u7ea7(state)\u4f1a\u53d8\u4e3a\u7ed3\u679c\u4e2d\u6700\u4f4e\u7684\u5c42\u7ea7 # side left right # state Ohio Colorado Ohio Colorado # number # one 0 3 5 8 # two 1 4 6 9 # three 2 5 7 10 \u5728\u8c03\u7528 stack \u65b9\u6cd5\u65f6\uff0c\u53ef\u4ee5\u6307\u660e\u9700\u8981\u5806\u53e0\u7684\u8f74\u5411\u540d\u79f0\uff1a print(df.unstack('state').stack('side')) # state Colorado Ohio # number side # one left 3 0 # right 8 5 # two left 4 1 # right 9 6 # three left 5 2 # right 10 7 \u5c06\u201c\u957f\u201d\u900f\u89c6\u4e3a\u201c\u5bbd\u201d \u5728\u6570\u636e\u5e93\u548cCSV\u4e2d\u5b58\u50a8\u591a\u65f6\u95f4\u5e8f\u5217\u7684\u65b9\u5f0f\u5c31\u662f\u6240\u8c13\u7684\u957f\u683c\u5f0f\u6216\u5806\u53e0\u683c\u5f0f\u3002 data = pd.read_csv('../examples/macrodata.csv') print(data.head(3)) # year quarter realgdp realcons ... unemp pop infl realint # 0 1959.0 1.0 2710.349 1707.4 ... 5.8 177.146 0.00 0.00 # 1 1959.0 2.0 2778.801 1733.7 ... 5.1 177.830 2.34 0.74 # 2 1959.0 3.0 2775.488 1751.8 ... 5.3 178.657 2.74 1.09 # ...... # [3 rows x 14 columns] # PeriodIndex\u5c06year\u548cquarter\u7b49\u5217\u8fdb\u884c\u8054\u5408\u5e76\u751f\u6210\u4e86\u4e00\u79cd\u65f6\u95f4\u95f4\u9694\u7c7b\u578b periods = pd.PeriodIndex( year=data.year, quarter=data.quarter, name='date' ) columns = pd.Index( ['realgdp', 'infl', 'unemp'], name='item' ) data = data.reindex(columns=columns) print(data) # item realgdp infl unemp # 0 2710.349 0.00 5.8 # 1 2778.801 2.34 5.1 # 2 2775.488 2.74 5.3 # ...... # [203 rows x 3 columns] data.index = periods.to_timestamp('D', 'end') print(data.index) # DatetimeIndex(['1959-03-31 23:59:59.999999999', # '1959-06-30 23:59:59.999999999', # ... # '2009-06-30 23:59:59.999999999', # '2009-09-30 23:59:59.999999999'], # dtype='datetime64[ns]', name='date', length=203, freq=None) \u4e0b\u9762\u662fldata\u7684\u6570\u636e\u6837\u672c\u3002 \u8fd9\u79cd\u6570\u636e\u5373\u6240\u8c13\u7684\u591a\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u683c\u5f0f\uff0c\u6216\u79f0\u4e3a\u5177\u6709\u4e24\u4e2a\u6216\u66f4\u591a\u4e2a\u952e\u7684\u5176\u4ed6\u89c2\u6d4b\u6570\u636e\uff08\u8fd9\u91cc\uff0c\u6211\u4eec\u7684\u952e\u662fdate\u548citem\uff09\u3002 \u8868\u4e2d\u7684\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2a\u65f6\u95f4\u70b9\u4e0a\u7684\u5355\u4e2a\u89c2\u6d4b\u503c\u3002 ldata = data.stack().reset_index().rename(columns={0: 'value'}) print(ldata) # date item value # 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 # 1 1959-03-31 23:59:59.999999999 infl 0.000 # 2 1959-03-31 23:59:59.999999999 unemp 5.800 # 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 # 4 1959-06-30 23:59:59.999999999 infl 2.340 # .. ... ... ... # 604 2009-06-30 23:59:59.999999999 infl 3.370 # 605 2009-06-30 23:59:59.999999999 unemp 9.200 # 606 2009-09-30 23:59:59.999999999 realgdp 12990.341 # 607 2009-09-30 23:59:59.999999999 infl 3.560 # 608 2009-09-30 23:59:59.999999999 unemp 9.600 # [609 rows x 3 columns] \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff1a \u6570\u636e\u901a\u5e38\u4ee5\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5728\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\uff0c\u6bd4\u5982MySQL\uff0c\u56e0\u4e3a\u56fa\u5b9a\u6a21\u5f0f\uff08\u5217\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\uff09\u5141\u8bb8 item \u5217\u4e2d\u4e0d\u540c\u503c\u7684\u6570\u91cf\u968f\u7740\u6570\u636e\u88ab\u6dfb\u52a0\u5230\u8868\u4e2d\u800c\u6539\u53d8\u3002 date \u548c item \u901a\u5e38\u662f\u4e3b\u952e\uff08\u4f7f\u7528\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u8bf4\u6cd5\uff09\uff0c\u63d0\u4f9b\u4e86\u5173\u7cfb\u5b8c\u6574\u6027\u548c\u66f4\u7b80\u5355\u7684\u8fde\u63a5\u3002 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5904\u7406\u8fd9\u79cd\u683c\u5f0f\u7684\u6570\u636e\u66f4\u4e3a\u56f0\u96be\u3002\u53ef\u80fd\u66f4\u503e\u5411\u4e8e\u83b7\u53d6\u4e00\u4e2a\u6309 date \u5217\u65f6\u95f4\u6233\u7d22\u5f15\u7684\u4e14\u6bcf\u4e2a\u4e0d\u540c\u7684 item \u72ec\u7acb\u4e00\u5217\u7684DataFrame\u3002 DataFrame\u7684pivot\u65b9\u6cd5\u5c31\u662f\u8fdb\u884c\u8fd9\u79cd\u8f6c\u6362\u7684\uff1a \u4e0b\u9762\u4f8b\u5b50\u4e2d\uff0c\u4f20\u9012\u7684\u524d\u4e24\u4e2a\u503c\u662f\u5206\u522b\u7528\u4f5c\u884c\u548c\u5217\u7d22\u5f15\u7684\u5217\uff0c\u7136\u540e\u662f\u53ef\u9009\u7684\u6570\u503c\u5217\u4ee5\u586b\u5145DataFrame\u3002 \u6ce8\u610f\uff0c pivot \u65b9\u6cd5\u7b49\u4ef7\u4e8e\u4f7f\u7528 set_index \u521b\u5efa\u5206\u5c42\u7d22\u5f15\uff0c\u7136\u540e\u8c03\u7528unstack\u3002 pivoted = ldata.pivot('date', 'item', 'value') print(pivoted) # item infl realgdp unemp # date # 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 # 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 # ... ... ... ... # 2009-06-30 23:59:59.999999999 3.37 12901.504 9.2 # 2009-09-30 23:59:59.999999999 3.56 12990.341 9.6 # [203 rows x 3 columns] ldata['value2'] = np.random.randn(len(ldata)) print(ldata[:5]) # date item value value2 # 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 -1.268405 # 1 1959-03-31 23:59:59.999999999 infl 0.000 0.377691 # 2 1959-03-31 23:59:59.999999999 unemp 5.800 -0.342492 # 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 0.132797 # 4 1959-06-30 23:59:59.999999999 infl 2.340 0.180290 \u6b64\u65f6 ldata \u5df2\u7ecf\u6dfb\u52a0\u4e86\u4e00\u5217\u3002\u5982\u679c\u9057\u6f0f\u6700\u540e\u4e00\u4e2a\u53c2\u6570\uff0c\u4f1a\u5f97\u5230\u4e00\u4e2a\u542b\u6709\u591a\u5c42\u5217\u7684DataFrame\uff0c\u5982\u4e0b\uff1a pivoted = ldata.pivot('date', 'item') print(pivoted) # value ... value2 # item infl realgdp ... realgdp unemp # date ... # 1959-03-31 23:59:59.999999999 0.00 2710.349 ... 0.157467 -0.222464 # 1959-06-30 23:59:59.999999999 2.34 2778.801 ... 0.861501 0.368855 # ... ... ... ... ... ... # 2009-06-30 23:59:59.999999999 3.37 12901.504 ... 0.279988 0.934972 # 2009-09-30 23:59:59.999999999 3.56 12990.341 ... 0.547914 1.842967 # [203 rows x 6 columns] \u6ce8\u610f\uff0c pivot \u65b9\u6cd5\u7b49\u4ef7\u4e8e\u4f7f\u7528 set_index \u521b\u5efa\u5206\u5c42\u7d22\u5f15\uff0c\u7136\u540e\u8c03\u7528 unstack \u3002 unstacked = ldata.set_index(['date', 'item']).unstack('item') print(unstacked[:5]) # value ... value2 # item infl realgdp ... realgdp unemp # date ... # 1959-03-31 23:59:59.999999999 0.00 2710.349 ... 0.213120 -0.248004 # 1959-06-30 23:59:59.999999999 2.34 2778.801 ... 0.697763 0.112388 # 1959-09-30 23:59:59.999999999 2.74 2775.488 ... 1.291884 -1.046142 # 1959-12-31 23:59:59.999999999 0.27 2785.204 ... 0.363339 -0.307364 # 1960-03-31 23:59:59.999999999 2.31 2847.699 ... 0.377330 2.272980 # [5 rows x 6 columns] \u5c06\u201c\u5bbd\u201d\u900f\u89c6\u4e3a\u201c\u957f\u201d \u5728DataFrame\u4e2d\uff0cpivot\u65b9\u6cd5\u7684\u53cd\u64cd\u4f5c\u662f pandas.melt \u3002 \u4e0e\u5c06\u4e00\u5217\u53d8\u6362\u4e3a\u65b0\u7684DataFrame\u4e2d\u7684\u591a\u5217\u4e0d\u540c\uff0c\u5b83\u5c06\u591a\u5217\u5408\u5e76\u6210\u4e00\u5217\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684DataFrame\uff0c\u5176\u957f\u5ea6\u6bd4\u8f93\u5165\u66f4\u957f\u3002 df = pd.DataFrame( { 'key': ['foo', 'bar', 'baz'], 'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9] } ) print(df) # key A B C # 0 foo 1 4 7 # 1 bar 2 5 8 # 2 baz 3 6 9 key \u5217\u53ef\u4ee5\u4f5c\u4e3a\u5206\u7ec4\u6307\u6807\uff0c\u5176\u4ed6\u5217\u5747\u4e3a\u6570\u636e\u503c\u3002 \u5f53\u4f7f\u7528 pandas.melt \u65f6\uff0c\u6211\u4eec\u5fc5\u987b\u6307\u660e\u54ea\u4e9b\u5217\u662f\u5206\u7ec4\u6307\u6807\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\u3002 \u6b64\u5904\uff0c\u8ba9\u6211\u4eec\u4f7f\u7528 key \u4f5c\u4e3a\u552f\u4e00\u7684\u5206\u7ec4\u6307\u6807\uff1a melted = pd.melt(df, ['key']) print(melted) # key variable value # 0 foo A 1 # 1 bar A 2 # 2 baz A 3 # 3 foo B 4 # 4 bar B 5 # 5 baz B 6 # 6 foo C 7 # 7 bar C 8 # 8 baz C 9 \u4f7f\u7528 pivot \u65b9\u6cd5\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u6570\u636e\u91cd\u5851\u56de\u539f\u5148\u7684\u5e03\u5c40\u3002 reshaped = melted.pivot('key', 'variable', 'value') print(reshaped) # variable A B C # key # bar 2 5 8 # baz 3 6 9 # foo 1 4 7 \u7531\u4e8e pivot \u7684\u7ed3\u679c\u6839\u636e\u4f5c\u4e3a\u884c\u6807\u7b7e\u7684\u5217\u751f\u6210\u4e86\u7d22\u5f15\uff0c\u53ef\u4f7f\u7528 reset_index \u6765\u5c06\u6570\u636e\u56de\u79fb\u4e00\u5217\uff1a print(reshaped.reset_index()) # variable key A B C # 0 bar 2 5 8 # 1 baz 3 6 9 # 2 foo 1 4 7 pandas.melt \u7684\u4f7f\u7528\u4e5f\u53ef\u4ee5\u65e0\u987b\u4efb\u4f55\u5206\u7ec4\u6307\u6807\u3002 result = pd.melt(df, value_vars=['A', 'B', 'C']) print(result) # variable value # 0 A 1 # 1 A 2 # 2 A 3 # 3 B 4 # 4 B 5 # 5 B 6 # 6 C 7 # 7 C 8 # 8 C 9 result = pd.melt(df, value_vars=['key', 'B', 'C']) print(result) # variable value # 0 key foo # 1 key bar # 2 key baz # 3 B 4 # 4 B 5 # 5 B 6 # 6 C 7 # 7 C 8 # 8 C 9","title":"\u6570\u636e\u89c4\u6574\uff1a\u8fde\u63a5\u3001\u8054\u5408\u4e0e\u91cd\u5851"},{"location":"python/DataAnalysis/ch05/#_1","text":"","title":"\u6570\u636e\u89c4\u6574\uff1a\u8fde\u63a5\u3001\u8054\u5408\u4e0e\u91cd\u5851"},{"location":"python/DataAnalysis/ch05/#_2","text":"import pandas as pd import numpy as np import re \u5206\u5c42\u7d22\u5f15\u662fpandas\u7684\u91cd\u8981\u7279\u6027\uff0c\u5141\u8bb8\u4f60\u5728\u4e00\u4e2a\u8f74\u5411\u4e0a\u62e5\u6709\u591a\u4e2a\uff08\u4e24\u4e2a\u6216\u4e24\u4e2a\u4ee5\u4e0a\uff09\u7d22\u5f15\u5c42\u7ea7\u3002 \u5206\u5c42\u7d22 import re \u5f15\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u66f4\u4f4e\u7ef4\u5ea6\u7684\u5f62\u5f0f\u4e2d\u5904\u7406\u66f4\u9ad8\u7ef4\u5ea6\u6570\u636e\u7684\u65b9\u5f0f\u3002","title":"\u5206\u5c42\u7d22\u5f15"},{"location":"python/DataAnalysis/ch05/#series","text":"data = pd.Series( np.random.randn(9), index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 3, 1, 2, 2, 3]] ) \u8f93\u51fa\u662f\u4e00\u4e2a\u4ee5 MultiIndex \u4f5c\u4e3a\u7d22\u5f15\u7684Series\u7684\u7f8e\u5316\u89c6\u56fe\u3002 \u7d22\u5f15\u4e2d\u7684\"\u95f4\u9699\"\u8868\u793a\"\u76f4\u63a5\u4f7f\u7528\u4e0a\u9762\u7684\u6807\u7b7e\"\u3002 print(data) # a 1 0.163468 # 2 -1.525926 # 3 -0.210247 # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # d 2 0.034305 # 3 -0.896078 # dtype: float64 print(data.index) # MultiIndex([('a', 1), # ('a', 2), # ('a', 3), # ('b', 1), # ('b', 3), # ('c', 1), # ('c', 2), # ('d', 2), # ('d', 3)], # ) \u901a\u8fc7\u5206\u5c42\u7d22\u5f15\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u79f0\u4e3a\u90e8\u5206\u7d22\u5f15\uff0c\u53ef\u4ee5\u7b80\u6d01\u5730\u9009\u62e9\u51fa\u6570\u636e\u7684\u5b50\u96c6\u3002 m = data['b'] print(m) # 1 -0.956063 # 3 -1.839111 # dtype: float64 m = data['b': 'c'] print(m) # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # dtype: float64 m = data.loc[['b', 'c']] print(m) # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # dtype: float64 m = data.loc[:, 2] print(m) # a -1.525926 # c 0.595279 # d 0.034305 # dtype: float64 \u5206\u5c42\u7d22\u5f15\u5728\u91cd\u5851\u6570\u636e\u548c\u6570\u7ec4\u900f\u89c6\u8868\u7b49\u5206\u7ec4\u64cd\u4f5c\u4e2d\u626e\u6f14\u4e86\u91cd\u8981\u89d2\u8272\u3002 \u4f8b\u5982\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 unstack \u65b9\u6cd5\u5c06\u6570\u636e\u5728DataFrame\u4e2d\u91cd\u65b0\u6392\u5217\u3002 m = data.unstack() print(m) # 1 2 3 # a 0.163468 -1.525926 -0.210247 # b -0.956063 NaN -1.839111 # c -0.398905 0.595279 NaN # d NaN 0.034305 -0.896078 n = m.stack() print(n) # \u6216\u8005 print(data.unstack().stack()) # a 1 0.163468 # 2 -1.525926 # 3 -0.210247 # b 1 -0.956063 # 3 -1.839111 # c 1 -0.398905 # 2 0.595279 # d 2 0.034305 # 3 -0.896078 # dtype: float64","title":"Series\u7d22\u5f15\u5206\u5c42"},{"location":"python/DataAnalysis/ch05/#dataframe","text":"\u5728DataFrame\u4e2d\uff0c\u6bcf\u4e2a\u8f74\u90fd\u53ef\u4ee5\u62e5\u6709\u5206\u5c42\u7d22\u5f15\u3002 \u53c2\u8003","title":"DataFrame\u7d22\u5f15\u5206\u5c42"},{"location":"python/DataAnalysis/ch05/#1","text":"\u76f4\u63a5\u901a\u8fc7\u7ed9 index \uff08columns\uff09\u53c2\u6570\u4f20\u9012\u591a\u7ef4\u6570\u7ec4\uff0c\u8fdb\u800c\u6784\u5efa\u591a\u7ef4\u7d22\u5f15\u3002 \u6570\u7ec4\u4e2d\u6bcf\u4e2a\u7ef4\u5ea6\u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c\u7ec4\u6210\u6bcf\u4e2a\u7d22\u5f15\u503c\u3002 frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) print(frame) # Ohio Colorado # Green Red Green # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 \u4e0a\u9762\u8f93\u51fa\u4e2d\u76842\u4e2a\u5c42\u7ea7\u662f\u6ca1\u6709\u540d\u5b57\u3002 \u5206\u5c42\u7684\u5c42\u7ea7\u53ef\u4ee5\u6709\u540d\u79f0\uff08\u53ef\u4ee5\u662f\u5b57\u7b26\u4e32\u6216Python\u5bf9\u8c61\uff09\u3002 \u5982\u679c\u5c42\u7ea7\u6709\u540d\u79f0\uff0c\u8fd9\u4e9b\u540d\u79f0\u4f1a\u5728\u63a7\u5236\u53f0\u8f93\u51fa\u4e2d\u663e\u793a\u3002 print(frame.index.names) # [None, None] print(frame.columns.names) # [None, None] \u7ed9\u5c42\u7ea7\u8d4b\u4e88\u540d\u79f0\u3002\u6ce8\u610f\u533a\u5206\u884c\u6807\u7b7e\u4e2d\u7684\u7d22\u5f15\u540d\u79f0 state \u548c color \u3002 frame.index.names = ['key1', 'key2'] frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 print(frame['Ohio']) # color Green Red # key1 key2 # a 1 0 1 # 2 3 4 # b 1 6 7 # 2 9 10 print(frame.index) # MultiIndex([('a', 1), # ('a', 2), # ('b', 1), # ('b', 2)], # names=['key1', 'key2']) \u901a\u8fc7 MultiIndex \u7c7b\u7684\u76f8\u5173\u65b9\u6cd5\uff0c\u9884\u5148\u521b\u5efa\u4e00\u4e2a MultiIndex \u5bf9\u8c61\uff0c\u7136\u540e\u4f5c\u4e3aSeries\u4e0eDataFrame\u4e2d\u7684 index \uff08\u6216columns\uff09\u53c2\u6570\u503c\u3002\u540c\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7 names \u53c2\u6570\u6307\u5b9a\u591a\u5c42\u7d22\u5f15\u7684\u540d\u79f0\u3002","title":"\u65b9\u6cd51\uff1a\u76f4\u63a5\u521b\u5efa"},{"location":"python/DataAnalysis/ch05/#2from_arrays","text":"from_arrays \uff1a\u63a5\u6536\u4e00\u4e2a\u591a\u7ef4\u6570\u7ec4\u53c2\u6570\uff0c\u9ad8\u7ef4\u6307\u5b9a\u9ad8\u5c42\u7d22\u5f15\uff0c\u4f4e\u7ef4\u6307\u5b9a\u5e95\u5c42\u7d22\u5f15\u3002 mindex = pd.MultiIndex.from_arrays( [['a', 'a', 'b', 'b'], [1, 2, 1, 2]], names=['key1', 'key2'] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11","title":"\u65b9\u6cd52\uff1afrom_arrays"},{"location":"python/DataAnalysis/ch05/#3from_tuples","text":"from_tuples \uff1a\u63a5\u6536\u4e00\u4e2a\u5143\u7ec4\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7ec4\u6307\u5b9a\u6bcf\u4e2a\u7d22\u5f15\uff08\u9ad8\u7ef4\u7d22\u5f15\uff0c\u4f4e\u7ef4\u7d22\u5f15\uff09\u3002 mindex = pd.MultiIndex.from_tuples( [('a', 1), ('a', 2), ('b', 1), ('b', 2)] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.index.names = ['key1', 'key2'] frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11","title":"\u65b9\u6cd53\uff1afrom_tuples"},{"location":"python/DataAnalysis/ch05/#4from_product","text":"from_product \uff1a\u63a5\u6536\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u5217\u8868\uff0c\u6839\u636e\u591a\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5143\u7d20\u7684\u7b1b\u5361\u5c14\u79ef\u8fdb\u884c\u521b\u5efa\u7d22\u5f15\u3002 \u4f7f\u7528\u7b1b\u5361\u5c14\u79ef\u7684\u65b9\u5f0f\u6765\u521b\u5efa\u591a\u5c42\u7d22\u5f15\u3002\u53c2\u6570\u4e3a\u5d4c\u5957\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u3002\u7ed3\u679c\u4e3a\u4f7f\u7528\u6bcf\u4e2a\u4e00\u7ef4\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\u4e0e\u5176\u4ed6\u4e00\u7ef4\u6570\u7ec4\u4e2d\u7684\u5143\u7d20\u6765\u751f\u6210\u3002 \u7b1b\u5361\u5c14\u79ef\u7684\u65b9\u5f0f\u7684\u5c40\u9650\uff1a\u4e24\u4e24\u7ec4\u5408\u5fc5\u987b\u90fd\u5b58\u5728\uff0c\u5426\u5219\uff0c\u5c31\u4e0d\u80fd\u4f7f\u7528\u8fd9\u79cd\u65b9\u5f0f\u3002 mindex = pd.MultiIndex.from_product( [['a', 'b'], ['1', '2']], names=['key1', 'key2'] ) frame = pd.DataFrame( np.arange(12).reshape((4, 3)), index=mindex, columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']] ) frame.columns.names = ['state', 'color'] print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11","title":"\u65b9\u6cd54\uff1afrom_product"},{"location":"python/DataAnalysis/ch05/#_3","text":"\u5982\u679c\u9700\u8981\u91cd\u65b0\u6392\u5217\u8f74\u4e0a\u7684\u5c42\u7ea7\u987a\u5e8f\uff0c\u6216\u8005\u6309\u7167\u7279\u5b9a\u5c42\u7ea7\u7684\u503c\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\uff0c \u53ef\u4ee5\u901a\u8fc7swaplevel\u63a5\u6536\u4e24\u4e2a\u5c42\u7ea7\u5e8f\u53f7\u6216\u5c42\u7ea7\u540d\u79f0\uff0c\u8fd4\u56de\u4e00\u4e2a\u8fdb\u884c\u4e86\u5c42\u7ea7\u53d8\u66f4\u7684\u65b0\u5bf9\u8c61\uff08\u4f46\u662f\u6570\u636e\u662f\u4e0d\u53d8\u7684\uff09\u3002 print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.swaplevel('key1', 'key2') print(m) # state Ohio Colorado # color Green Red Green # key2 key1 # 1 a 0 1 2 # 2 a 3 4 5 # 1 b 6 7 8 # 2 b 9 10 11 sort_index \u53ea\u80fd\u5728\u5355\u4e00\u5c42\u7ea7\u4e0a\u5bf9\u6570\u636e\u8fdb\u884c\u6392\u5e8f\u3002 \u5728\u8fdb\u884c\u5c42\u7ea7\u53d8\u6362\u65f6\uff0c\u4f7f\u7528 sort_index \u4ee5\u4f7f\u5f97\u7ed3\u679c\u6309\u7167\u5c42\u7ea7\u8fdb\u884c\u5b57\u5178\u6392\u5e8f\u3002 m = frame.sort_index(level=1) # \u5bf9key2\u6392\u5e8f\uff0c\u5e95\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # b 1 6 7 8 # a 2 3 4 5 # b 2 9 10 11 m = frame.sort_index(level=0) # \u5bf9key1\u6392\u5e8f\uff0c\u9ad8\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.swaplevel(0, 1).sort_index(level=1) # swaplevel(0, 1)\u7b49\u540c\u4e8eswaplevel(key1, key2)\uff0c\u4ea4\u6362\u540ekey1\u53d8\u6210\u4e86\u5e95\u5c42\u7d22\u5f15 print(m) # state Ohio Colorado # color Green Red Green # key2 key1 # 1 a 0 1 2 # 2 a 3 4 5 # 1 b 6 7 8 # 2 b 9 10 11","title":"\u91cd\u6392\u5e8f\u548c\u5c42\u7ea7\u6392\u5e8f"},{"location":"python/DataAnalysis/ch05/#_4","text":"DataFrame\u548cSeries\u4e2d\u5f88\u591a\u63cf\u8ff0\u6027\u548c\u6c47\u603b\u6027\u7edf\u8ba1\u6709\u4e00\u4e2a level \u9009\u9879\uff0c\u901a\u8fc7 level \u9009\u9879\u4f60\u53ef\u4ee5\u6307\u5b9a\u4f60\u60f3\u8981\u5728\u67d0\u4e2a\u7279\u5b9a\u7684\u8f74\u4e0a\u8fdb\u884c\u805a\u5408\u3002 print(frame) # state Ohio Colorado # color Green Red Green # key1 key2 # a 1 0 1 2 # 2 3 4 5 # b 1 6 7 8 # 2 9 10 11 m = frame.groupby(level='key2').sum() print(m) # state Ohio Colorado # color Green Red Green # key2 # 1 6 8 10 # 2 12 14 16 m = frame.groupby(level='color', axis=1).sum() print(m) # color Green Red # key1 key2 # a 1 2 1 # 2 8 4 # b 1 14 7 # 2 20 10","title":"\u6309\u5c42\u7ea7\u8fdb\u884c\u6c47\u603b\u7edf\u8ba1"},{"location":"python/DataAnalysis/ch05/#dataframe_1","text":"\u901a\u5e38\u6211\u4eec\u4e0d\u4f1a\u4f7f\u7528DataFrame\u4e2d\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u884c\u7d22\u5f15\uff1b\u53cd\u800c\u4f60\u53ef\u80fd\u60f3\u8981\u5c06\u884c\u7d22\u5f15\u79fb\u52a8\u5230DataFrame\u7684\u5217\u4e2d\u3002 frame = pd.DataFrame( {'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': [0, 1, 2, 0, 1, 2, 3] } ) print(frame) # a b c d # 0 0 7 one 0 # 1 1 6 one 1 # 2 2 5 one 2 # 3 3 4 two 0 # 4 4 3 two 1 # 5 5 2 two 2 # 6 6 1 two 3 DataFrame\u7684 set_index \u51fd\u6570\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684DataFrame\uff0c\u65b0\u7684DataFrame\u4f7f\u7528\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4f5c\u4e3a\u7d22\u5f15\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\u8fd9\u4e9b\u7d22\u5f15\u5217\u4f1a\u4eceDataFrame\u4e2d\u79fb\u9664\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5b83\u4eec\u7559\u5728DataFrame\u4e2d\u3002 frame2 = frame.set_index(['c', 'd'], drop=False) print(frame2) # a b c d # c d # one 0 0 7 one 0 # 1 1 6 one 1 # 2 2 5 one 2 # two 0 3 4 two 0 # 1 4 3 two 1 # 2 5 2 two 2 # 3 6 1 two 3 frame2 = frame.set_index(['c', 'd']) print(frame2) # a b # c d # one 0 0 7 # 1 1 6 # 2 2 5 # two 0 3 4 # 1 4 3 # 2 5 2 # 3 6 1 reset_index \u662f set_index \u7684\u53cd\u64cd\u4f5c\uff0c\u5206\u5c42\u7d22\u5f15\u7684\u7d22\u5f15\u5c42\u7ea7\u4f1a\u88ab\u79fb\u52a8\u5230\u5217\u4e2d\u3002 \u6ce8\u610f\uff1a\u5982\u679c\u5728 set_index \u65f6\u4f7f\u7528\u4e86 drop=False \uff0c\u5728\u4f7f\u7528 reset_index \u4f1a\u62a5\u9519\u3002 m = frame2.reset_index() print(m) # c d a b # 0 one 0 0 7 # 1 one 1 1 6 # 2 one 2 2 5 # 3 two 0 3 4 # 4 two 1 4 3 # 5 two 2 5 2 # 6 two 3 6 1","title":"\u4f7f\u7528DataFrame\u7684\u5217\u8fdb\u884c\u7d22\u5f15"},{"location":"python/DataAnalysis/ch05/#_5","text":"\u5305\u542b\u5728pandas\u5bf9\u8c61\u7684\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u591a\u79cd\u65b9\u5f0f\u8054\u5408\u5728\u4e00\u8d77\uff1a pandas.merge \u6839\u636e\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u5c06\u884c\u8fdb\u884c\u8fde\u63a5\u3002\u5bf9\u4e8eSQL\u6216\u5176\u4ed6\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u7528\u6237\u6765\u8bf4\uff0c\u8fd9\u79cd\u65b9\u5f0f\u6bd4\u8f83\u719f\u6089\uff0c\u5b83\u5b9e\u73b0\u7684\u662f\u6570\u636e\u5e93\u7684\u8fde\u63a5\u64cd\u4f5c\u3002 pandas.concat \u4f7f\u5bf9\u8c61\u5728\u8f74\u5411\u4e0a\u8fdb\u884c\u9ecf\u5408\u6216\u201c\u5806\u53e0\u201d\u3002 combine_first \u5b9e\u4f8b\u65b9\u6cd5\u5141\u8bb8\u5c06\u91cd\u53e0\u7684\u6570\u636e\u62fc\u63a5\u5728\u4e00\u8d77\uff0c\u4ee5\u4f7f\u7528\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u503c\u586b\u5145\u53e6\u4e00\u4e2a\u5bf9\u8c61\u4e2d\u7684\u7f3a\u5931\u503c\u3002","title":"\u8054\u5408\u4e0e\u5408\u5e76\u6570\u636e\u96c6"},{"location":"python/DataAnalysis/ch05/#dataframe_2","text":"\u5408\u5e76\u6216\u8fde\u63a5\u64cd\u4f5c\u901a\u8fc7\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u8fde\u63a5\u884c\u6765\u8054\u5408\u6570\u636e\u96c6\u3002 \u8fd9\u4e9b\u64cd\u4f5c\u662f\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u6838\u5fc3\u5185\u5bb9\uff08\u4f8b\u5982\u57fa\u4e8eSQL\u7684\u6570\u636e\u5e93\uff09\u3002 pandas\u4e2d\u7684 merge \u51fd\u6570\u4e3b\u8981\u7528\u4e8e\u5c06\u5404\u79cd join \u64cd\u4f5c\u7b97\u6cd5\u8fd0\u7528\u5728\u6570\u636e\u4e0a\u3002 \u5728\u8fdb\u884c\u5217-\u5217\u8fde\u63a5\u65f6\uff0c\u4f20\u9012\u7684DataFrame\u7d22\u5f15\u5bf9\u8c61\u4f1a\u88ab\u4e22\u5f03\u3002 \u5408\u5e76\u64cd\u4f5c\u4e5f\u8981\u8003\u8651\u5982\u4f55\u5904\u7406\u91cd\u53e0\u7684\u5217\u540d( suffixes \u540e\u7f00\u9009\u9879)\u3002 \u4e0b\u9762\u662f\u4e00\u4e2a\u591a\u5bf9\u4e00\u8fde\u63a5\u7684\u4f8b\u5b50\u3002 df1 \u7684\u6570\u636e\u6709\u591a\u4e2a\u884c\u7684\u6807\u7b7e\u4e3a a \u548c b \uff0c\u800c df2 \u5728 key \u5217\u4e2d\u6bcf\u4e2a\u503c\u4ec5\u6709\u4e00\u884c\u3002 df1 = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7) } ) df2 = pd.DataFrame( { 'key': ['a', 'b', 'd'], 'data1': range(3) } ) print(df1) # key data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 a 5 # 6 b 6 print(df2) # key data1 # 0 a 0 # 1 b 1 # 2 d 2 \u8c03\u7528 merge \u5904\u7406\uff0c\u63a8\u8350\u663e\u5f0f\u5730\u6307\u5b9a\u8fde\u63a5\u952e\u3002 result = pd.merge(df1, df2) print(result) # key data1 # 0 b 1 result = pd.merge(df1, df2, on=['key', 'data1']) print(result) # key data1 # 0 b 1 result = pd.merge(df1, df2, on='key') print(result) # key data1_x data1_y # 0 b 0 1 # 1 b 1 1 # 2 b 6 1 # 3 a 2 0 # 4 a 4 0 # 5 a 5 0 \u5982\u679c\u6bcf\u4e2a\u5bf9\u8c61\u7684\u5217\u540d\u662f\u4e0d\u540c\u7684\uff0c\u53ef\u4ee5\u5206\u522b\u4e3a\u5b83\u4eec\u6307\u5b9a\u5217\u540d\u3002 df3 = pd.DataFrame( { 'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7) } ) df4 = pd.DataFrame( { 'rkey': ['a', 'b', 'd'], 'data2': range(3) } ) print(df3) # lkey data1 # 0 b 0 # 1 b 1 # 2 a 2 # 3 c 3 # 4 a 4 # 5 a 5 # 6 b 6 print(df4) # rkey data2 # 0 a 0 # 1 b 1 # 2 d 2 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c merge \u505a\u7684\u662f\u5185\u8fde\u63a5\uff08'inner' join\uff09\uff0c\u7ed3\u679c\u4e2d\u7684\u952e\u662f\u4e24\u5f20\u8868\u7684\u4ea4\u96c6\u3002 result = pd.merge(df3, df4, left_on='lkey', right_on='rkey') # df4\u7684[a,0]\u5bf9\u5e94df3\u7684\u6240\u6709[a,?]\u8bb0\u5f55\uff08\u901a\u8fc7\u91cd\u590d\u6765\u586b\u5145\u4e0d\u8db3\uff09 print(result) # lkey data1 rkey data2 # 0 b 0 b 1 # 1 b 1 b 1 # 2 b 6 b 1 # 3 a 2 a 0 # 4 a 4 a 0 # 5 a 5 a 0 \u5916\u8fde\u63a5\uff08outer join\uff09\u662f\u952e\u7684\u5e76\u96c6\uff0c\u8054\u5408\u4e86\u5de6\u8fde\u63a5\u548c\u53f3\u8fde\u63a5\u7684\u6548\u679c\u3002 \u591a\u5bf9\u591a\u8fde\u63a5\u662f\u884c\u7684\u7b1b\u5361\u5c14\u79ef\u3002 df1 = pd.DataFrame( { 'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6) } ) df2 = pd.DataFrame( { 'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5) } ) print(df1.sort_values(by='key')) # key data1 # 2 a 2 # 4 a 4 # 0 b 0 # 1 b 1 # 5 b 5 # 3 c 3 print(df2.sort_values(by='key')) # key data2 # 0 a 0 # 2 a 2 # 1 b 1 # 3 b 3 # 4 d 4 result = pd.merge(df1, df2, on='key', how='left') print(result.sort_values(by='key')) # key data1 data2 # 4 a 2 0.0 # 5 a 2 2.0 # 7 a 4 0.0 # 8 a 4 2.0 # 0 b 0 1.0 # 1 b 0 3.0 # 2 b 1 1.0 # 3 b 1 3.0 # 9 b 5 1.0 # 10 b 5 3.0 # 6 c 3 NaN result = pd.merge(df1, df2, on='key', how='outer') # \u591a\u5bf9\u591a\u8fde\u63a5 print(result.sort_values(by='key')) # key data1 data2 # 6 a 2.0 0.0 # 7 a 2.0 2.0 # 8 a 4.0 0.0 # 9 a 4.0 2.0 # 0 b 0.0 1.0 # 1 b 0.0 3.0 # 2 b 1.0 1.0 # 3 b 1.0 3.0 # 4 b 5.0 1.0 # 5 b 5.0 3.0 # 10 c 3.0 NaN # 11 d NaN 4.0 \u591a\u952e\u5408\u5e76\u3002 df1 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3] } ) df2 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7] } ) print(df1.sort_values(by=['key1', 'key2'])) # key1 key2 lval # 2 bar one 3 # 0 foo one 1 # 1 foo two 2 print(df2.sort_values(by=['key1', 'key2'])) # key1 key2 rval # 2 bar one 6 # 3 bar two 7 # 0 foo one 4 # 1 foo one 5 result = pd.merge(df1, df2, on=['key1', 'key2'], how='outer') print(result.sort_values(by=['key1', 'key2'])) # key1 key2 lval rval # 3 bar one 3.0 6.0 # 4 bar two NaN 7.0 # 0 foo one 1.0 4.0 # \u91cd\u590d\u586b\u5145 # 1 foo one 1.0 5.0 # \u91cd\u590d\u586b\u5145 # 2 foo two 2.0 NaN \u5904\u7406\u91cd\u53e0\u5217\u540d\u3002 result = pd.merge(df1, df2, on='key1') print(result.sort_values(by='key1')) # key1 key2_x lval key2_y rval # 4 bar one 3 one 6 # 5 bar one 3 two 7 # 0 foo one 1 one 4 # 1 foo one 1 one 5 # 2 foo two 2 one 4 # 3 foo two 2 one 5 result = pd.merge(df1, df2, on='key1', suffixes=('_left', '_right')) print(result.sort_values(by='key1')) # key1 key2_left lval key2_right rval # 4 bar one 3 one 6 # 5 bar one 3 two 7 # 0 foo one 1 one 4 # 1 foo one 1 one 5 # 2 foo two 2 one 4 # 3 foo two 2 one 5","title":"\u6570\u636e\u5e93\u98ce\u683c\u7684DataFrame\u8fde\u63a5"},{"location":"python/DataAnalysis/ch05/#_6","text":"\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0cDataFrame\u4e2d\u7528\u4e8e\u5408\u5e76\u7684\u952e\u662f\u5b83\u7684\u7d22\u5f15\u3002\u53ef\u4ee5\u4f20\u9012 left_index=True \u6216 right_index=True \uff08\u6216\u8005\u90fd\u4f20\uff09\u6765\u8868\u793a\u7d22\u5f15\u9700\u8981\u7528\u6765\u4f5c\u4e3a\u5408\u5e76\u7684\u952e\u3002 df1 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3] } ) df2 = pd.DataFrame( { 'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7] }, index=['foo', 'foo', 'bar', 'bar'] ) print(df1) # key1 key2 lval # 0 foo one 1 # 1 foo two 2 # 2 bar one 3 print(df2) # key1 key2 rval # foo foo one 4 # foo foo one 5 # bar bar one 6 # bar bar two 7 result = pd.merge(df1, df2, left_on='key1', right_index=True, suffixes=('_left', '_right')) print(result.sort_index()) # key1 key1_left key2_left lval key1_right key2_right rval # 0 foo foo one 1 foo one 4 # 0 foo foo one 1 foo one 5 # 1 foo foo two 2 foo one 4 # 1 foo foo two 2 foo one 5 # 2 bar bar one 3 bar one 6 # 2 bar bar one 3 bar two 7 result = pd.merge(df1, df2, left_on='key1', right_index=True, how='outer', suffixes=('_left', '_right')) # \u548c\u4e0a\u8ff0\u7ed3\u679c\u4e00\u6837 print(result.sort_index()) # key1 key1_left key2_left lval key1_right key2_right rval # 0 foo foo one 1 foo one 4 # 0 foo foo one 1 foo one 5 # 1 foo foo two 2 foo one 4 # 1 foo foo two 2 foo one 5 # 2 bar bar one 3 bar one 6 # 2 bar bar one 3 bar two 7 \u5728\u66f4\u590d\u6742\u591a\u5c42\u7d22\u5f15\u6570\u636e\u7684\u591a\u952e\u5408\u5e76\uff0c\u5728\u7d22\u5f15\u4e0a\u8fde\u63a5\u662f\u4e00\u4e2a\u9690\u5f0f\u7684\u591a\u952e\u5408\u5e76\u3002 \u5fc5\u987b\u4ee5\u5217\u8868\u7684\u65b9\u5f0f\u6307\u660e\u5408\u5e76\u6240\u9700\u591a\u4e2a\u5217\uff08\u6ce8\u610f\u4f7f\u7528 how='outer' \u5904\u7406\u91cd\u590d\u7684\u7d22\u5f15\u503c\uff09\u3002 df1 = pd.DataFrame( { 'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'key2': [2000, 2001, 2002, 2001, 2002], 'data': np.arange(5.) } ) df2 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'], [2001, 2000, 2000, 2000, 2001, 2002] ], columns=['event1', 'event2'] ) print(df1) # key1 key2 data # 0 Ohio 2000 0.0 # 1 Ohio 2001 1.0 # 2 Ohio 2002 2.0 # 3 Nevada 2001 3.0 # 4 Nevada 2002 4.0 print(df2) # event1 event2 # Nevada 2001 0 1 # 2000 2 3 # Ohio 2000 4 5 # 2000 6 7 # 2001 8 9 # 2002 10 11 result = pd.merge(df1, df2, left_on=['key1', 'key2'], right_index=True) print(result) # key1 key2 data event1 event2 # 0 Ohio 2000 0.0 4 5 # 0 Ohio 2000 0.0 6 7 # 1 Ohio 2001 1.0 8 9 # 2 Ohio 2002 2.0 10 11 # 3 Nevada 2001 3.0 0 1 result = pd.merge(df1, df2, left_on=['key1', 'key2'], right_index=True, how='outer') print(result) # key1 key2 data event1 event2 # 0 Ohio 2000 0.0 4.0 5.0 # 0 Ohio 2000 0.0 6.0 7.0 # 1 Ohio 2001 1.0 8.0 9.0 # 2 Ohio 2002 2.0 10.0 11.0 # 3 Nevada 2001 3.0 0.0 1.0 # 4 Nevada 2002 4.0 NaN NaN # 4 Nevada 2000 NaN 2.0 3.0 \u4f7f\u7528\u4e24\u8fb9\u7684\u7d22\u5f15\u8fdb\u884c\u5408\u5e76\u4e5f\u662f\u53ef\u4ee5\u7684\uff0c\u524d\u63d0\u662f\u7528\u4e24\u8fb9\u7528\u6765\u5408\u5e76\u7684\u7d22\u5f15\u6709\u4ea4\u96c6\uff08\u516c\u5171\u90e8\u5206\uff09\u3002 \u5728\u4f7f\u7528 merge \u65f6\uff0c\u53c2\u6570 on=['key1', 'key2'] \u4e0d\u80fd\u548c left_index=True , right_index=True \u540c\u65f6\u5b58\u5728\u3002 \u5bf9\u4e8e\u91cd\u590d\u7d22\u5f15\uff0c\u5982\u679c\u503c\u4e0d\u540c\uff0c\u5219\u591a\u884c\u663e\u793a\uff0c\u548c\u6570\u636e\u5e93SQL\u7684 full join \u7c7b\u4f3c\u6982\u5ff5\u3002 \u5982\u679c\u51fa\u73b0\u76f8\u540c\u5217\u540d\uff0c\u5219\u4f1a\u81ea\u52a8\u6dfb\u52a0\u540e\u7f00\u5b57\u7b26\u4ee5\u793a\u533a\u522b\u3002 df1 = pd.DataFrame( [[1, 2], [3, 4], [5, 6]], index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'] ) print(df1) # Ohio Nevada # a 1 2 # c 3 4 # e 5 6 df2 = pd.DataFrame( [[7, 8], [9, 10], [11, 12], [13, 14]], index=['b', 'c', 'c', 'e'], columns=['Missouri', 'Alabama'] ) print(df2) # Missouri Alabama # b 7 8 # c 9 10 # c 11 12 # e 13 14 df3 = pd.DataFrame( [[7, 8], [9, 10], [11, 12], [13, 14]], index=['a', 'c', 'e', 'f'], columns=['Nevada', 'Alabama'] ) print(df3) # Nevada Alabama # a 7 8 # c 9 10 # e 11 12 # f 13 14 result = pd.merge(df1, df2, left_index=True, right_index=True, how='outer') print(result) # Ohio Nevada Missouri Alabama # a 1.0 2.0 NaN NaN # b NaN NaN 7.0 8.0 # c 3.0 4.0 9.0 10.0 # c 3.0 4.0 11.0 12.0 # e 5.0 6.0 13.0 14.0 result = pd.merge(df1, df3, left_index=True, right_index=True, how='outer') print(result) # Ohio Nevada_x Nevada_y Alabama # a 1.0 2.0 7 8 # c 3.0 4.0 9 10 # e 5.0 6.0 11 12 # f NaN NaN 13 14 \u53e6\u4e00\u79cd\u5199\u6cd5\uff1a result = df1.join(df2, how='outer') print(result) # Ohio Nevada Missouri Alabama # a 1.0 2.0 NaN NaN # b NaN NaN 7.0 8.0 # c 3.0 4.0 9.0 10.0 # c 3.0 4.0 11.0 12.0 # e 5.0 6.0 13.0 14.0 \u4e5f\u53ef\u4ee5\u5411 join \u65b9\u6cd5\u4f20\u5165\u4e00\u4e2aDataFrame\u5217\u8868\uff0c\u7c7b\u4f3c\u4e8e\u5bf9\u4e09\u4e2a\u6570\u636e\u96c6\u8fdb\u884c join \u64cd\u4f5c\u3002 result = df1.join([df2, df3]) print(result) # Ohio Nevada_x Missouri Alabama_x Nevada_y Alabama_y # a 1 2 NaN NaN 7 8 # c 3 4 9.0 10.0 9 10 # c 3 4 11.0 12.0 9 10 # e 5 6 13.0 14.0 11 12","title":"\u6839\u636e\u7d22\u5f15\u5408\u5e76"},{"location":"python/DataAnalysis/ch05/#_7","text":"\u53e6\u4e00\u79cd\u6570\u636e\u7ec4\u5408\u64cd\u4f5c\u53ef\u79f0\u4e3a\u62fc\u63a5\u3001\u7ed1\u5b9a\u6216\u5806\u53e0\u3002NumPy\u7684 concatenate \u51fd\u6570\u53ef\u4ee5\u5728NumPy\u6570\u7ec4\u4e0a\u5b9e\u73b0\u8be5\u529f\u80fd\u3002 \u57fa\u4e8eSeries\u7684pandas\u7684 concat \u51fd\u6570\u7684\u5de5\u4f5c\u673a\u5236\u5206\u6790\u3002 \u4e0b\u9762\u4e09\u4e2a\u7d22\u5f15\u4e0d\u91cd\u53e0\u7684Series\u3002 s1 = pd.Series([0, 1], index=['a', 'b']) s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e']) s3 = pd.Series([5, 6], index=['f', 'g']) \u7528\u5217\u8868\u4e2d\u7684\u8fd9\u4e9b\u5bf9\u8c61\u8c03\u7528 concat \u65b9\u6cd5\u4f1a\u5c06\u503c\u548c\u7d22\u5f15\u7c98\u5728\u4e00\u8d77\uff1a \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c concat \u65b9\u6cd5\u662f\u6cbf\u7740 axis=0 \u7684\u8f74\u5411\u751f\u6548\u7684\uff0c\u751f\u6210\u53e6\u4e00\u4e2aSeries\u3002 \u5982\u679c\u4f20\u9012 axis=1 \uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u5219\u662f\u4e00\u4e2aDataFrame\uff08 axis=1 \u65f6\u662f\u5217\uff09\u3002 result = pd.concat([s1, s2, s3]) print(result) # a 0 # b 1 # c 2 # d 3 # e 4 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s2, s3], keys=['one', 'two', 'three']) # \u901a\u8fc7keys\u53c2\u6570\uff0c\u5728\u8fde\u63a5\u8f74\u5411\u4e0a\u521b\u5efa\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15\uff0c\u4ee5\u4fbf\u5728\u7ed3\u679c\u4e2d\u533a\u5206\u5404\u90e8\u5206 print(result) # one a 0 # b 1 # two c 2 # d 3 # e 4 # three f 5 # g 6 # dtype: int64 print(result.unstack()) # \u628a\u539f\u7d22\u5f15\u4f5c\u4e3a\u5217\u6807\u7b7e\u5c55\u5f00 # a b c d e f g # one 0.0 1.0 NaN NaN NaN NaN NaN # two NaN NaN 2.0 3.0 4.0 NaN NaN # three NaN NaN NaN NaN NaN 5.0 6.0 result = pd.concat([s1, s2, s3], axis=1) # \u5728\u8fd9\u4e2a\u6848\u4f8b\u4e2daxis=1\u8f74\u5411\u4e0a\u5e76\u6ca1\u6709\u91cd\u53e0 print(result) # 0 1 2 # a 0.0 NaN NaN # b 1.0 NaN NaN # c NaN 2.0 NaN # d NaN 3.0 NaN # e NaN 4.0 NaN # f NaN NaN 5.0 # g NaN NaN 6.0 result = pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three']) # \u5728\u8fd9\u4e2a\u6848\u4f8b\u4e2daxis=1\u8f74\u5411\u4e0a\u5e76\u6ca1\u6709\u91cd\u53e0 print(result) # one two three # a 0.0 NaN NaN # b 1.0 NaN NaN # c NaN 2.0 NaN # d NaN 3.0 NaN # e NaN 4.0 NaN # f NaN NaN 5.0 # g NaN NaN 6.0 print(result.unstack()) # \u5bf9\u6bd4axis=0\u7684\u591a\u5c42\u7d22\u5f15\uff0c\u5f53axis=1\u65f6\u5bf9\u8f93\u51fa\u5404index\u7684\u5e76\u96c6\u505a\u4e86\u5206\u7ec4\u3002 # one a 0.0 # b 1.0 # c NaN # d NaN # e NaN # f NaN # g NaN # two a NaN # b NaN # c 2.0 # d 3.0 # e 4.0 # f NaN # g NaN # three a NaN # b NaN # c NaN # d NaN # e NaN # f 5.0 # g 6.0 # dtype: float64 s4 = pd.concat([s1, s3]) print(s4) # a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4]) print(result) # a 0 # b 1 # a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4], axis=1) # \u73b0\u5728\u5728\u4e2daxis=1\u8f74\u5411\u4e0a\u6709\u91cd\u53e0 print(result) # 0 1 # a 0.0 0 # b 1.0 1 # f NaN 5 # g NaN 6 result = pd.concat([s1, s4], axis=1, keys=['one', 'two', 'three']) print(result) # one two # a 0.0 0 # b 1.0 1 # f NaN 5 # g NaN 6 result = pd.concat([s1, s4], axis=0, keys=['one', 'two', 'three']) # \u901a\u8fc7keys\u53c2\u6570\uff0c\u5728\u8fde\u63a5\u8f74\u5411\u4e0a\u521b\u5efa\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15 print(result) # one a 0 # b 1 # two a 0 # b 1 # f 5 # g 6 # dtype: int64 result = pd.concat([s1, s4], axis=1, join='inner') # \u5185\u8fde\u63a5\u65b9\u5f0f\u5408\u5e76\u7d22\u5f15\uff08\u7d22\u5f15\u4ea4\u96c6\uff09 print(result) # 0 1 # a 0 0 # b 1 1 result = pd.concat([s1, s4], axis=1).reindex(['a', 'c', 'b', 'e']) # \u4f7f\u7528join_axes(\u5df2\u88ab\u66ff\u6362\u6210reindex)\u6765\u6307\u5b9a\u7528\u4e8e\u8fde\u63a5\u5176\u4ed6\u8f74\u5411\u7684\u8f74 print(result) # 0 1 # a 0.0 0.0 # c NaN NaN # b 1.0 1.0 # e NaN NaN \u57fa\u4e8eDataFrame\u7684pandas\u7684 concat \u51fd\u6570\u7684\u5de5\u4f5c\u673a\u5236\u5206\u6790\u3002 df1 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], [2000, 2001, 2002, 2000, 2001, 2002] ], columns=['event1', 'event2'] ) df2 = pd.DataFrame( np.arange(12).reshape((6, 2)), index=[ ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], [2000, 2001, 2002, 2000, 2001, 2002] ], columns=['event3', 'event4'] ) print(df1) # event1 event2 # Ohio 2000 0 1 # 2001 2 3 # 2002 4 5 # Nevada 2000 6 7 # 2001 8 9 # 2002 10 11 print(df2) # event3 event4 # Ohio 2000 0 1 # 2001 2 3 # 2002 4 5 # Nevada 2000 6 7 # 2001 8 9 # 2002 10 11 result = np.concatenate([df1, df2], axis=0) # \u6cbf0\u8f74\u62fc\u63a5 print(result) # [[ 0 1] # [ 2 3] # [ 4 5] # [ 6 7] # [ 8 9] # [10 11] # [ 0 1] # [ 2 3] # [ 4 5] # [ 6 7] # [ 8 9] # [10 11]] result = np.concatenate([df1, df2], axis=1) # \u6cbf1\u8f74\u62fc\u63a5 print(result) # [[ 0 1 0 1] # [ 2 3 2 3] # [ 4 5 4 5] # [ 6 7 6 7] # [ 8 9 8 9] # [10 11 10 11]] result = np.concatenate([df1, df2], axis=None) # \u5c06\u6570\u7ec4\u5c55\u5e73 print(result) # [ 0 1 2 3 4 5 6 7 8 9 10 11 0 1 2 3 4 5 6 7 8 9 10 11]","title":"\u6cbf\u8f74\u5411\u8fde\u63a5"},{"location":"python/DataAnalysis/ch05/#_8","text":"\u53e6\u4e00\u4e2a\u6570\u636e\u8054\u5408\u573a\u666f\uff0c\u65e2\u4e0d\u662f\u5408\u5e76\u64cd\u4f5c\uff0c\u4e5f\u4e0d\u662f\u8fde\u63a5\u64cd\u4f5c\u3002 \u5047\u5982\u6709\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u8fd9\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u7d22\u5f15\u5168\u90e8\u6216\u90e8\u5206\u91cd\u53e0\uff0c\u901a\u8fc7NumPy\u7684 where \u51fd\u6570\u53ef\u4ee5\u8fdb\u884c\u9762\u5411\u6570\u7ec4\u7684if-else\u7b49\u4ef7\u64cd\u4f5c\u3002 s1 = pd.Series( [np.nan, 2.5, 0.0, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'] ) s2 = pd.Series( [0.0, np.nan, 2.0, np.nan, np.nan, 5.0], index=['a', 'b', 'c', 'd', 'e', 'f'] ) print(s1) # f NaN # e 2.5 # d 0.0 # c 3.5 # b 4.5 # a NaN # dtype: float64 print(s2) # a 0.0 # b NaN # c 2.0 # d NaN # e NaN # f 5.0 # dtype: float64 \u65b9\u6cd51\uff0c\u901a\u8fc7Numpy\u7684 where \u51fd\u6570\u3002 result = np.where(pd.isnull(s1), s2, s1) # An array with elements from 'x'(s2) where 'condition'(isnull(s1)) is True, and elements from 'y'(s1) elsewhere. print(result) # [0. 2.5 0. 3.5 4.5 5. ] # s1 # s2 # result # f NaN # a 0.0 0. \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94x(s2)\u7684\u5143\u7d20\uff08\u6ce8\u610f\uff0c\u4e0e\u7d22\u5f15\u987a\u5e8f\u65e0\u5173\uff09 # e 2.5 # b NaN 2.5 \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e0d\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94y(s1)\u7684\u5143\u7d20 # d 0.0 # c 2.0 0. # c 3.5 # d NaN 3.5 # b 4.5 # e NaN 4.5 # a NaN # f 5.0 5.0 \u6761\u4ef6\u4e2ds1\u8be5\u5143\u7d20\u4e3anull\uff0c\u6240\u4ee5where\u51fd\u6570\u53d6\u5bf9\u5e94x(s2)\u7684\u5143\u7d20 result = np.where(pd.isnull(s2), s1, s2) print(result) # [0. 2.5 2. 3.5 4.5 5. ] \u65b9\u6cd52\uff0c\u901a\u8fc7Series\u7684 combine_first \u65b9\u6cd5\u3002 result = s2.combine_first(s1) # \u6ce8\u610f\uff0ccombine_first\u662f\u6309\u7167s2\u7684\u7d22\u5f15\u987a\u5e8f\u68c0\u7d22\u7684\uff0c\u76f8\u540c\u7d22\u5f15\u7684s1\u7684\u503c\u4f1a\u586b\u5145\u5bf9\u5e94s2\u7684null print(result) # a 0.0 # b 4.5 # c 2.0 # d 0.0 # e 2.5 # f 5.0 # dtype: float64 \u65b9\u6cd53\uff1aPandas\u7684 combine_first \u65b9\u6cd5\u3002 df1 = pd.DataFrame( { 'a': [1.0, np.nan, 5.0, np.nan], 'b': [np.nan, 2.0, np.nan, 6.0], 'c': [2.0, 6.0, 10.0, 15.0] } ) df2 = pd.DataFrame( { 'a': [5.0, 4.0, np.nan, 3.0, 7.0], 'b': [np.nan, 3.0, 4.0, 6.0, 8.0] } ) print(df1) # a b c # 0 1.0 NaN 2.0 # 1 NaN 2.0 6.0 # 2 5.0 NaN 10.0 # 3 NaN 6.0 15.0 print(df2) # a b # 0 5.0 NaN # 1 4.0 3.0 # 2 NaN 4.0 # 3 3.0 6.0 # 4 7.0 8.0 result = df2.combine_first(df1) # \u7528df1\u7684\u503c\u53bb\u586b\u5145df2\u5bf9\u5e94\u7d22\u5f15\u4f4d\u7f6e\u7684null\u503c print(result) # a b c # 0 5.0 NaN 2.0 # 1 4.0 3.0 6.0 # 2 5.0 4.0 10.0 # 3 3.0 6.0 15.0 # 4 7.0 8.0 NaN","title":"\u8054\u5408\u91cd\u53e0\u6570\u636e"},{"location":"python/DataAnalysis/ch05/#_9","text":"\u91cd\u65b0\u6392\u5217\u8868\u683c\u578b\u6570\u636e\u6709\u591a\u79cd\u57fa\u7840\u64cd\u4f5c\u3002\u8fd9\u4e9b\u64cd\u4f5c\u88ab\u79f0\u4e3a\u91cd\u5851\u6216\u900f\u89c6\u3002 import numpy as np import pandas as pd","title":"\u91cd\u5851\u548c\u900f\u89c6"},{"location":"python/DataAnalysis/ch05/#_10","text":"\u591a\u5c42\u7d22\u5f15\u5728DataFrame\u4e2d\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e00\u81f4\u6027\u65b9\u5f0f\u7528\u4e8e\u91cd\u6392\u5217\u6570\u636e\u3002\u4ee5\u4e0b\u662f\u4e24\u4e2a\u57fa\u7840\u64cd\u4f5c\uff1a statck\uff08\u5806\u53e0\uff09\u8be5\u64cd\u4f5c\u4f1a\u201c\u65cb\u8f6c\u201d\u6216\u5c06\u5217\u4e2d\u7684\u6570\u636e\u900f\u89c6\u5230\u884c\u3002 unstack\uff08\u62c6\u5806\uff09\u8be5\u64cd\u4f5c\u4f1a\u5c06\u884c\u4e2d\u7684\u6570\u636e\u900f\u89c6\u5230\u5217\u3002 df = pd.DataFrame( np.arange(6).reshape((2, 3)), index=pd.Index(['Ohio', 'Colorado'], name='state'), columns=pd.Index(['one', 'two', 'three'], name='number') ) print(df) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 \u5728\u8fd9\u4efd\u6570\u636e\u4e0a\u4f7f\u7528stack\u65b9\u6cd5\u4f1a\u5c06\u5217\u900f\u89c6\u5230\u884c\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684Series\uff1a result = df.stack() print(result) # state number # Ohio one 0 # two 1 # three 2 # Colorado one 3 # two 4 # three 5 # dtype: int64 \u4ece\u4e00\u4e2a\u591a\u5c42\u7d22\u5f15\u5e8f\u5217\u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 unstack \u65b9\u6cd5\u5c06\u6570\u636e\u91cd\u6392\u5217\u540e\u653e\u5165\u4e00\u4e2aDataFrame\u4e2d\uff1a print(result.unstack()) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 print(result.unstack(0)) # \u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5c42\u7ea7\u5e8f\u53f7\u6216\u540d\u79f0\u6765\u62c6\u5206\u4e00\u4e2a\u4e0d\u540c\u7684\u5c42\u7ea7 # state Ohio Colorado # number # one 0 3 # two 1 4 # three 2 5 print(result.unstack(1)) # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 print(result.unstack('state')) # \u8f93\u51fa\u7ed3\u679c\u548c\u4f20\u5165\u5c42\u7ea70\u4e00\u6837 # state Ohio Colorado # number # one 0 3 # two 1 4 # three 2 5 print(result.unstack('number')) # \u8f93\u51fa\u7ed3\u679c\u548c\u4f20\u5165\u5c42\u7ea71\u4e00\u6837 # number one two three # state # Ohio 0 1 2 # Colorado 3 4 5 \u5982\u679c\u5c42\u7ea7\u4e2d\u7684\u6240\u6709\u503c\u5e76\u672a\u5305\u542b\u4e8e\u6bcf\u4e2a\u5b50\u5206\u7ec4\u4e2d\u65f6\uff0c\u62c6\u5206\u53ef\u80fd\u4f1a\u5f15\u5165\u7f3a\u5931\u503c\uff1a s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd']) s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e']) s3 = pd.concat([s1, s2], keys=['one', 'two']) print(s3) # one a 0 # b 1 # c 2 # d 3 # two c 4 # d 5 # e 6 # dtype: int64 print(s3.unstack(0)) # one two # a 0.0 NaN # b 1.0 NaN # c 2.0 4.0 # d 3.0 5.0 # e NaN 6.0 print(s3.unstack(1)) print(s3.unstack()) # a b c d e # one 0.0 1.0 2.0 3.0 NaN # two NaN NaN 4.0 5.0 6.0 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5806\u53e0\u4f1a\u8fc7\u6ee4\u51fa\u7f3a\u5931\u503c\uff0c\u56e0\u6b64\u5806\u53e0\u62c6\u5806\u7684\u64cd\u4f5c\u662f\u53ef\u9006\u7684\u3002 print(s3.unstack().stack()) # one a 0.0 # b 1.0 # c 2.0 # d 3.0 # two c 4.0 # d 5.0 # e 6.0 # dtype: float64 print(s3.unstack().stack(dropna=False)) # one a 0.0 # b 1.0 # c 2.0 # d 3.0 # e NaN # two a NaN # b NaN # c 4.0 # d 5.0 # e 6.0 # dtype: float64 \u5728DataFrame\u4e2d\u62c6\u5806\u65f6\uff0c\u88ab\u62c6\u5806\u7684\u5c42\u7ea7\u4f1a\u53d8\u4e3a\u7ed3\u679c\u4e2d\u6700\u4f4e\u7684\u5c42\u7ea7\u3002 \u5728\u8c03\u7528 stack \u65b9\u6cd5\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u6307\u660e\u9700\u8981\u5806\u53e0\u7684\u8f74\u5411\u540d\u79f0\u3002 df = pd.DataFrame( {'left': result, 'right': result + 5}, columns=pd.Index(['left', 'right'], name='side') ) print(df) # side left right # state number # Ohio one 0 5 # two 1 6 # three 2 7 # Colorado one 3 8 # two 4 9 # three 5 10 print(df.unstack()) # side left right # number one two three one two three # state # Ohio 0 1 2 5 6 7 # Colorado 3 4 5 8 9 10 print(df.unstack('state')) # \u88ab\u62c6\u5806\u7684\u5c42\u7ea7(state)\u4f1a\u53d8\u4e3a\u7ed3\u679c\u4e2d\u6700\u4f4e\u7684\u5c42\u7ea7 # side left right # state Ohio Colorado Ohio Colorado # number # one 0 3 5 8 # two 1 4 6 9 # three 2 5 7 10 \u5728\u8c03\u7528 stack \u65b9\u6cd5\u65f6\uff0c\u53ef\u4ee5\u6307\u660e\u9700\u8981\u5806\u53e0\u7684\u8f74\u5411\u540d\u79f0\uff1a print(df.unstack('state').stack('side')) # state Colorado Ohio # number side # one left 3 0 # right 8 5 # two left 4 1 # right 9 6 # three left 5 2 # right 10 7","title":"\u4f7f\u7528\u591a\u5c42\u7d22\u5f15\u8fdb\u884c\u91cd\u5851"},{"location":"python/DataAnalysis/ch05/#_11","text":"\u5728\u6570\u636e\u5e93\u548cCSV\u4e2d\u5b58\u50a8\u591a\u65f6\u95f4\u5e8f\u5217\u7684\u65b9\u5f0f\u5c31\u662f\u6240\u8c13\u7684\u957f\u683c\u5f0f\u6216\u5806\u53e0\u683c\u5f0f\u3002 data = pd.read_csv('../examples/macrodata.csv') print(data.head(3)) # year quarter realgdp realcons ... unemp pop infl realint # 0 1959.0 1.0 2710.349 1707.4 ... 5.8 177.146 0.00 0.00 # 1 1959.0 2.0 2778.801 1733.7 ... 5.1 177.830 2.34 0.74 # 2 1959.0 3.0 2775.488 1751.8 ... 5.3 178.657 2.74 1.09 # ...... # [3 rows x 14 columns] # PeriodIndex\u5c06year\u548cquarter\u7b49\u5217\u8fdb\u884c\u8054\u5408\u5e76\u751f\u6210\u4e86\u4e00\u79cd\u65f6\u95f4\u95f4\u9694\u7c7b\u578b periods = pd.PeriodIndex( year=data.year, quarter=data.quarter, name='date' ) columns = pd.Index( ['realgdp', 'infl', 'unemp'], name='item' ) data = data.reindex(columns=columns) print(data) # item realgdp infl unemp # 0 2710.349 0.00 5.8 # 1 2778.801 2.34 5.1 # 2 2775.488 2.74 5.3 # ...... # [203 rows x 3 columns] data.index = periods.to_timestamp('D', 'end') print(data.index) # DatetimeIndex(['1959-03-31 23:59:59.999999999', # '1959-06-30 23:59:59.999999999', # ... # '2009-06-30 23:59:59.999999999', # '2009-09-30 23:59:59.999999999'], # dtype='datetime64[ns]', name='date', length=203, freq=None) \u4e0b\u9762\u662fldata\u7684\u6570\u636e\u6837\u672c\u3002 \u8fd9\u79cd\u6570\u636e\u5373\u6240\u8c13\u7684\u591a\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u683c\u5f0f\uff0c\u6216\u79f0\u4e3a\u5177\u6709\u4e24\u4e2a\u6216\u66f4\u591a\u4e2a\u952e\u7684\u5176\u4ed6\u89c2\u6d4b\u6570\u636e\uff08\u8fd9\u91cc\uff0c\u6211\u4eec\u7684\u952e\u662fdate\u548citem\uff09\u3002 \u8868\u4e2d\u7684\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2a\u65f6\u95f4\u70b9\u4e0a\u7684\u5355\u4e2a\u89c2\u6d4b\u503c\u3002 ldata = data.stack().reset_index().rename(columns={0: 'value'}) print(ldata) # date item value # 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 # 1 1959-03-31 23:59:59.999999999 infl 0.000 # 2 1959-03-31 23:59:59.999999999 unemp 5.800 # 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 # 4 1959-06-30 23:59:59.999999999 infl 2.340 # .. ... ... ... # 604 2009-06-30 23:59:59.999999999 infl 3.370 # 605 2009-06-30 23:59:59.999999999 unemp 9.200 # 606 2009-09-30 23:59:59.999999999 realgdp 12990.341 # 607 2009-09-30 23:59:59.999999999 infl 3.560 # 608 2009-09-30 23:59:59.999999999 unemp 9.600 # [609 rows x 3 columns] \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff1a \u6570\u636e\u901a\u5e38\u4ee5\u8fd9\u79cd\u65b9\u5f0f\u5b58\u50a8\u5728\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\uff0c\u6bd4\u5982MySQL\uff0c\u56e0\u4e3a\u56fa\u5b9a\u6a21\u5f0f\uff08\u5217\u540d\u79f0\u548c\u6570\u636e\u7c7b\u578b\uff09\u5141\u8bb8 item \u5217\u4e2d\u4e0d\u540c\u503c\u7684\u6570\u91cf\u968f\u7740\u6570\u636e\u88ab\u6dfb\u52a0\u5230\u8868\u4e2d\u800c\u6539\u53d8\u3002 date \u548c item \u901a\u5e38\u662f\u4e3b\u952e\uff08\u4f7f\u7528\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u8bf4\u6cd5\uff09\uff0c\u63d0\u4f9b\u4e86\u5173\u7cfb\u5b8c\u6574\u6027\u548c\u66f4\u7b80\u5355\u7684\u8fde\u63a5\u3002 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5904\u7406\u8fd9\u79cd\u683c\u5f0f\u7684\u6570\u636e\u66f4\u4e3a\u56f0\u96be\u3002\u53ef\u80fd\u66f4\u503e\u5411\u4e8e\u83b7\u53d6\u4e00\u4e2a\u6309 date \u5217\u65f6\u95f4\u6233\u7d22\u5f15\u7684\u4e14\u6bcf\u4e2a\u4e0d\u540c\u7684 item \u72ec\u7acb\u4e00\u5217\u7684DataFrame\u3002 DataFrame\u7684pivot\u65b9\u6cd5\u5c31\u662f\u8fdb\u884c\u8fd9\u79cd\u8f6c\u6362\u7684\uff1a \u4e0b\u9762\u4f8b\u5b50\u4e2d\uff0c\u4f20\u9012\u7684\u524d\u4e24\u4e2a\u503c\u662f\u5206\u522b\u7528\u4f5c\u884c\u548c\u5217\u7d22\u5f15\u7684\u5217\uff0c\u7136\u540e\u662f\u53ef\u9009\u7684\u6570\u503c\u5217\u4ee5\u586b\u5145DataFrame\u3002 \u6ce8\u610f\uff0c pivot \u65b9\u6cd5\u7b49\u4ef7\u4e8e\u4f7f\u7528 set_index \u521b\u5efa\u5206\u5c42\u7d22\u5f15\uff0c\u7136\u540e\u8c03\u7528unstack\u3002 pivoted = ldata.pivot('date', 'item', 'value') print(pivoted) # item infl realgdp unemp # date # 1959-03-31 23:59:59.999999999 0.00 2710.349 5.8 # 1959-06-30 23:59:59.999999999 2.34 2778.801 5.1 # ... ... ... ... # 2009-06-30 23:59:59.999999999 3.37 12901.504 9.2 # 2009-09-30 23:59:59.999999999 3.56 12990.341 9.6 # [203 rows x 3 columns] ldata['value2'] = np.random.randn(len(ldata)) print(ldata[:5]) # date item value value2 # 0 1959-03-31 23:59:59.999999999 realgdp 2710.349 -1.268405 # 1 1959-03-31 23:59:59.999999999 infl 0.000 0.377691 # 2 1959-03-31 23:59:59.999999999 unemp 5.800 -0.342492 # 3 1959-06-30 23:59:59.999999999 realgdp 2778.801 0.132797 # 4 1959-06-30 23:59:59.999999999 infl 2.340 0.180290 \u6b64\u65f6 ldata \u5df2\u7ecf\u6dfb\u52a0\u4e86\u4e00\u5217\u3002\u5982\u679c\u9057\u6f0f\u6700\u540e\u4e00\u4e2a\u53c2\u6570\uff0c\u4f1a\u5f97\u5230\u4e00\u4e2a\u542b\u6709\u591a\u5c42\u5217\u7684DataFrame\uff0c\u5982\u4e0b\uff1a pivoted = ldata.pivot('date', 'item') print(pivoted) # value ... value2 # item infl realgdp ... realgdp unemp # date ... # 1959-03-31 23:59:59.999999999 0.00 2710.349 ... 0.157467 -0.222464 # 1959-06-30 23:59:59.999999999 2.34 2778.801 ... 0.861501 0.368855 # ... ... ... ... ... ... # 2009-06-30 23:59:59.999999999 3.37 12901.504 ... 0.279988 0.934972 # 2009-09-30 23:59:59.999999999 3.56 12990.341 ... 0.547914 1.842967 # [203 rows x 6 columns] \u6ce8\u610f\uff0c pivot \u65b9\u6cd5\u7b49\u4ef7\u4e8e\u4f7f\u7528 set_index \u521b\u5efa\u5206\u5c42\u7d22\u5f15\uff0c\u7136\u540e\u8c03\u7528 unstack \u3002 unstacked = ldata.set_index(['date', 'item']).unstack('item') print(unstacked[:5]) # value ... value2 # item infl realgdp ... realgdp unemp # date ... # 1959-03-31 23:59:59.999999999 0.00 2710.349 ... 0.213120 -0.248004 # 1959-06-30 23:59:59.999999999 2.34 2778.801 ... 0.697763 0.112388 # 1959-09-30 23:59:59.999999999 2.74 2775.488 ... 1.291884 -1.046142 # 1959-12-31 23:59:59.999999999 0.27 2785.204 ... 0.363339 -0.307364 # 1960-03-31 23:59:59.999999999 2.31 2847.699 ... 0.377330 2.272980 # [5 rows x 6 columns]","title":"\u5c06\u201c\u957f\u201d\u900f\u89c6\u4e3a\u201c\u5bbd\u201d"},{"location":"python/DataAnalysis/ch05/#_12","text":"\u5728DataFrame\u4e2d\uff0cpivot\u65b9\u6cd5\u7684\u53cd\u64cd\u4f5c\u662f pandas.melt \u3002 \u4e0e\u5c06\u4e00\u5217\u53d8\u6362\u4e3a\u65b0\u7684DataFrame\u4e2d\u7684\u591a\u5217\u4e0d\u540c\uff0c\u5b83\u5c06\u591a\u5217\u5408\u5e76\u6210\u4e00\u5217\uff0c\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684DataFrame\uff0c\u5176\u957f\u5ea6\u6bd4\u8f93\u5165\u66f4\u957f\u3002 df = pd.DataFrame( { 'key': ['foo', 'bar', 'baz'], 'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9] } ) print(df) # key A B C # 0 foo 1 4 7 # 1 bar 2 5 8 # 2 baz 3 6 9 key \u5217\u53ef\u4ee5\u4f5c\u4e3a\u5206\u7ec4\u6307\u6807\uff0c\u5176\u4ed6\u5217\u5747\u4e3a\u6570\u636e\u503c\u3002 \u5f53\u4f7f\u7528 pandas.melt \u65f6\uff0c\u6211\u4eec\u5fc5\u987b\u6307\u660e\u54ea\u4e9b\u5217\u662f\u5206\u7ec4\u6307\u6807\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\u3002 \u6b64\u5904\uff0c\u8ba9\u6211\u4eec\u4f7f\u7528 key \u4f5c\u4e3a\u552f\u4e00\u7684\u5206\u7ec4\u6307\u6807\uff1a melted = pd.melt(df, ['key']) print(melted) # key variable value # 0 foo A 1 # 1 bar A 2 # 2 baz A 3 # 3 foo B 4 # 4 bar B 5 # 5 baz B 6 # 6 foo C 7 # 7 bar C 8 # 8 baz C 9 \u4f7f\u7528 pivot \u65b9\u6cd5\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u6570\u636e\u91cd\u5851\u56de\u539f\u5148\u7684\u5e03\u5c40\u3002 reshaped = melted.pivot('key', 'variable', 'value') print(reshaped) # variable A B C # key # bar 2 5 8 # baz 3 6 9 # foo 1 4 7 \u7531\u4e8e pivot \u7684\u7ed3\u679c\u6839\u636e\u4f5c\u4e3a\u884c\u6807\u7b7e\u7684\u5217\u751f\u6210\u4e86\u7d22\u5f15\uff0c\u53ef\u4f7f\u7528 reset_index \u6765\u5c06\u6570\u636e\u56de\u79fb\u4e00\u5217\uff1a print(reshaped.reset_index()) # variable key A B C # 0 bar 2 5 8 # 1 baz 3 6 9 # 2 foo 1 4 7 pandas.melt \u7684\u4f7f\u7528\u4e5f\u53ef\u4ee5\u65e0\u987b\u4efb\u4f55\u5206\u7ec4\u6307\u6807\u3002 result = pd.melt(df, value_vars=['A', 'B', 'C']) print(result) # variable value # 0 A 1 # 1 A 2 # 2 A 3 # 3 B 4 # 4 B 5 # 5 B 6 # 6 C 7 # 7 C 8 # 8 C 9 result = pd.melt(df, value_vars=['key', 'B', 'C']) print(result) # variable value # 0 key foo # 1 key bar # 2 key baz # 3 B 4 # 4 B 5 # 5 B 6 # 6 C 7 # 7 C 8 # 8 C 9","title":"\u5c06\u201c\u5bbd\u201d\u900f\u89c6\u4e3a\u201c\u957f\u201d"},{"location":"python/DataAnalysis/ch06/","text":"\u7ed8\u56fe\u4e0e\u53ef\u89c6\u5316 \u7b80\u660ematplotlib API\u5165\u95e8 import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd from io import BytesIO \u6267\u884c plt.show() \u65f6\u62a5\u9519\uff1a UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. \u6267\u884c\u4e0b\u9762\u547d\u4ee4\uff0c\u5f97\u5230 plt \u7684 backend \u662f\u7528 agg \u3002 plt.get_backend() \u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') Out[6]: 'agg' \u5b89\u88c5\u4e0b\u9762\u51e0\u4e2a\u5305\uff1a sudo zypper in python-tk python3-tk sudo zypper in plplot-tcltk-devel plplot-tcltk-libs pip install tk \u6dfb\u52a0\u4e0b\u9762\u5230python\u4ee3\u7801\u4e2d\u3002 import matplotlib.pyplot as plt mpl.use('TkAgg') \u6267\u884c\u540e\u62a5\u4e0b\u9762\u9519\u8bef\uff1a your Python may not be configured for Tk \u8fdb\u5165python\u6e90\u7801\u76ee\u5f55\uff0c\u91cd\u65b0\u7f16\u8bd1\u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') james@lizard:/opt/Python-3.9.6> sudo make james@lizard:/opt/Python-3.9.6> sudo make install \u95ee\u9898\u89e3\u51b3\uff0c\u5373\u4f7f\u4e0d\u52a0\u5165 mpl.use('TkAgg') \uff0c\u6267\u884c plt.show() \u4e5f\u662f\u53ef\u4ee5\u8f93\u51fa\u56fe\u50cf\u3002 \u56fe\u7247\u4e0e\u5b50\u56fe matplotlib \u6240\u7ed8\u5236\u7684\u56fe\u4f4d\u4e8e\u56fe\u7247\uff08Figure\uff09\u5bf9\u8c61\u4e2d\u3002\u53ef\u4ee5\u4f7f\u7528 plt.figure \u751f\u6210\u4e00\u4e2a\u65b0\u7684\u56fe\u7247\u3002 \u4f7f\u7528 add_subplot \u521b\u5efa\u4e00\u4e2a\u6216\u591a\u4e2a\u5b50\u56fe\uff08subplot\uff09\u3002 plt \u4e0e ax \u7ed8\u56fe\u3002 fig = plt.figure() # plt: \u5148\u751f\u6210\u4e86\u4e00\u4e2a\u753b\u5e03\uff0c\u7136\u540e\u5728\u8fd9\u4e2a\u753b\u5e03\u4e0a\u9690\u5f0f\u7684\u751f\u6210\u4e00\u4e2a\u753b\u56fe\u533a\u57df\u6765\u8fdb\u884c\u753b\u56fe # plt.plot([1, 2, 3, 4]) # plt.show() # ax: \u5148\u751f\u6210\u4e00\u4e2a\u753b\u5e03\uff082\u00d72\u7684\u533a\u57df\uff0c\u6700\u591a\u653e\u56db\u4e2a\u56fe\u5f62\uff09\uff0c\u7136\u540e\u5728\u6b64\u753b\u5e03\u4e0a\uff0c\u9009\u5b9a\u4e00\u4e2a\u5b50\u533a\u57df\u753b\u4e86\u4e00\u4e2a\u5b50\u56fe\uff08\u5e8f\u53f71\u4ee3\u8868\u7b2c\u4e00\u4e2a\u533a\u57df\uff09 ax1 = fig.add_subplot(2, 2, 1) # \u4e5f\u53ef\u4ee5\u5199\u6210fig.add_subplot(221) ax1.plot([1, 2, 3, 4], [1, 4, 3, 2]) # \u8f93\u51fa\u56fe\u7247\u5230\u7b2c\u4e00\u4e2a\u533a\u57df\u3002 # \u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u6570\u636e\u96c6\u91cc\u5404\u4e2a\u6570\u636e\u70b9\u7684X\u503c\u7684\u96c6\u5408 # \u7b2c\u4e8c\u4e2a\u53c2\u6570\u6570\u636e\u96c6\u91cc\u5404\u4e2a\u6570\u636e\u70b9\u7684Y\u503c\u7684\u96c6\u5408\u3002 # \u4e0d\u662f\u6570\u5b66\u4e0a\u5e38\u89c1\u7684\u6210\u5bf9\u5750\u6807\u70b9\u5982(x1,y1)\u3001(x2,y2)\u3001...\u3001(xn,yn)\u7684\u683c\u5f0f\uff0c\u800c\u662f (x1,x2,...,xn)\u548c(y1,y2,...,yn) \u3002 plt.show() \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u589e\u52a0\u5b50\u56fe\u540e\u7684\u6570\u636e\u53ef\u89c6\u5316\u6548\u679c\u3002 fig = plt.figure() ax1 = fig.add_subplot(2, 2, 1) ax2 = fig.add_subplot(2, 2, 2) ax3 = fig.add_subplot(2, 2, 3) ax1.plot(np.random.randn(50).cumsum(), 'k--') # \u5728\u7b2c\u4e09\u4e2a\u533a\u57df\u8f93\u51fa\u56fe\u50cf\u3002'k--\u2019\u662f\u7528\u4e8e\u7ed8\u5236\u9ed1\u8272\u5206\u6bb5\u7ebf\u7684style\u9009\u9879\u3002 ax2.hist(np.random.randn(100), bins=20, color='k', alpha=0.3) ax3.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30)) plt.show() plt.subplots \u901a\u8fc7 matplotlib \u7684 subplots \u65b9\u6cd5\uff0c\u4f7f\u7528\u5b50\u56fe\u7f51\u683c\u521b\u5efa\u56fe\u7247\uff0c\u7136\u540e\u8fd4\u56de\u5305\u542b\u4e86\u5df2\u751f\u6210\u5b50\u56fe\u5bf9\u8c61\u7684NumPy\u6570\u7ec4\u3002 \u6570\u7ec4 axes \u53ef\u4ee5\u50cf\u4e8c\u7ef4\u6570\u7ec4\u90a3\u6837\u65b9\u4fbf\u5730\u8fdb\u884c\u7d22\u5f15\uff0c\u4f8b\u5982\uff0c axes[0, 1] \u3002 plt.subplots \u53c2\u6570\u9009\u9879\uff1a nrows\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\uff0c\u9ed8\u8ba4\u4e3a1\u3002\u5b50\u56fe\u7f51\u683c\u7684\u884c\u6570\u3002 ncols\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\uff0c\u9ed8\u8ba4\u4e3a1\u3002\u5b50\u56fe\u7f51\u683c\u7684\u5217\u6570\u3002 sharex\uff1a\u53ef\u9009\u7684\uff0c\u9ed8\u8ba4\u4e3aFalse\u3002\u53ef\u9009\u503c\u5982\u4e0b\uff1a True\u6216all\uff0c\u6240\u6709\u5b50\u56fe\u5171\u4eabx\u8f74 False\u6216none\uff0c\u6bcf\u4e2a\u5b50\u56fe\u7684x\u8f74\u90fd\u662f\u72ec\u7acb\u7684 row\uff0c\u6bcf\u884c\u5b50\u56fe\u5171\u4eab\u4e00\u4e2ax\u8f74 col\uff0c\u6bcf\u5217\u5b50\u56fe\u5171\u4eab\u4e00\u4e2ax\u8f74 sharey\uff1a\u7c7b\u4f3c\u4e8esharex\uff0c\u8bbe\u7f6ey\u8f74\u7684\u5171\u4eab\u65b9\u5f0f\u3002\u5f53\u67d0\u5217\u5171\u4eab\u4e00\u4e2ax\u8f74\u65f6\uff0c\u53ea\u6709\u5e95\u90e8\u7684\u5b50\u56fe\u4f1a\u521b\u5efax\u8f74\u6807\u8bb0\u3002\u540c\u6837\u7684\uff0c\u5982\u679c\u67d0\u884c\u5171\u4eab\u4e00\u4e2ay\u8f74\u65f6\uff0c\u53ea\u6709\u884c\u7684\u7b2c\u4e00\u5217\u5b50\u56fe\u4f1a\u521b\u5efay\u8f74\u6807\u8bb0\u3002 squeeze \uff1a\u53ef\u9009\u7684\uff0c\u5e03\u5c14\u578b\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002\u662f\u5426\u538b\u7f29\u8fd4\u56de\u7684Axes\u6570\u7ec4\u3002\u5982\u679c\u4e3aTrue\uff0c\u5f53\u53ea\u6709\u4e00\u4e2a\u5b50\u56fe\uff0c\u5373nrows\u548cncols\u5747\u4e3a1\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u5355\u72ec\u7684Axes\u5bf9\u8c61\uff0c\u5f53\u6709N 1\u548c1 M\u4e2a\u5b50\u56fe\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u4e00\u7ef4Axes\u5bf9\u8c61\u6570\u7ec4\u3002\u5f53\u6709N*M\u4e2a\u5b50\u56fe\uff08N>1\uff0cM>1\uff09\u65f6\uff0c\u8fd4\u56de\u4e8c\u7ef4\u6570\u7ec4\u3002\u5982\u679c\u4e3aFalse\uff0c\u5219\u603b\u662f\u8fd4\u56de\u4e8c\u7ef4\u6570\u7ec4\u3002 num\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\u6216\u5b57\u7b26\u4e32\uff0c\u9ed8\u8ba4\u4e3aNone\u3002\u662fmatplotlib.pyplot.figure\u7684\u5173\u952e\u5b57\uff0c\u7528\u4e8e\u8bbe\u7f6e\u56fe\u50cf\u6570\u5b57\u6216\u6807\u7b7e\u3002\u5982\u679c\u672a\u8bbe\u7f6e\u6b64\u53c2\u6570\uff0c\u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\uff0c\u5e76\u9012\u589e\u56fe\u50cf\u7f16\u53f7\uff0cfigure\u5bf9\u8c61\u4f1a\u5c06\u7f16\u53f7\u4fdd\u5b58\u5728number\u5c5e\u6027\u4e2d\u3002\u5982\u679c\u8bbe\u7f6e\u4e86\u6b64\u53c2\u6570\uff0c\u5e76\u4e14\u5b58\u5728\u53c2\u6570\u6307\u5b9a\u7684\u56fe\u50cf\uff0c\u5219\u4f1a\u8fd4\u56de\u6b64\u56fe\u50cf\u7684\u5f15\u7528\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u4f1a\u521b\u5efa\u65b0\u7684\u56fe\u50cf\u5e76\u8fd4\u56de\u5b83\u7684\u5f15\u7528\u3002\u5982\u679c\u662f\u5b57\u7b26\u4e32\uff0c\u5219\u7a97\u53e3\u6807\u9898\u4f1a\u88ab\u8bbe\u7f6e\u4e3a\u6b64\u5b57\u7b26\u4e32\u7684\u503c\u3002 subplot_kw\uff1a\u53ef\u9009\u7684\uff0c\u5b57\u5178\u7c7b\u578b\u3002\u5305\u542b\u4f20\u9012\u7ed9\u7528\u4e8e\u521b\u5efa\u5b50\u56fe\u7684\u8c03\u7528add_subplot\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 gridspec_kw\uff1a\u53ef\u9009\u7684\uff0c\u5b57\u5178\u7c7b\u578b\u3002\u5305\u542b\u4f20\u9012\u7ed9\u7528\u4e8e\u521b\u5efa\u5b50\u56fe\u7f51\u683c\u7684GridSpec\u6784\u9020\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 fig, axes = plt.subplots(2, 3) print(axes) # \u5c06\u751f\u6210\u7684axes\u5bf9\u8c61\u653e\u5165NumPy\u6570\u7ec4\u3002 # [[<AxesSubplot:> <AxesSubplot:> <AxesSubplot:>] # [<AxesSubplot:> <AxesSubplot:> <AxesSubplot:>]] \u8c03\u6574\u5b50\u56fe\u5468\u56f4\u7684\u95f4\u8ddd\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c matplotlib \u4f1a\u5728\u5b50\u56fe\u7684\u5916\u90e8\u548c\u5b50\u56fe\u4e4b\u95f4\u7559\u51fa\u4e00\u5b9a\u7684\u95f4\u8ddd\u3002 \u8fd9\u4e2a\u95f4\u8ddd\u90fd\u662f\u76f8\u5bf9\u4e8e\u56fe\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u6765\u6307\u5b9a\u7684\uff0c\u624b\u52a8\u8c03\u6574\u56fe\u7684\u5927\u5c0f\uff0c\u90a3\u4e48\u95f4\u8ddd\u4f1a\u81ea\u52a8\u8c03\u6574\u3002 \u4e5f\u53ef\u4ee5\u4f7f\u7528\u56fe\u5bf9\u8c61\u4e0a\u7684 subplots_adjust \u65b9\u6cd5\u66f4\u6539\u95f4\u8ddd\uff0c\u4e5f\u53ef\u4ee5\u7528\u4f5c\u9876\u5c42\u51fd\u6570\u3002 fig, axes = plt.subplots(2, 2, sharex=True, sharey=True) for i in range(2): for j in range(2): axes[i, j].hist(np.random.randn(500), bins=50, color='k', alpha=0.5) plt.subplots_adjust(wspace=0, hspace=0) plt.show() \u4e0a\u9762\u8f93\u51fa\u56fe\u50cf\u7684\u8f74\u6807\u7b7e\u662f\u5b58\u5728\u91cd\u53e0\u7684\u3002 matplotlib \u5e76\u4e0d\u68c0\u67e5\u6807\u7b7e\u662f\u5426\u91cd\u53e0\uff0c\u56e0\u6b64\u5728\u7c7b\u4f3c\u60c5\u51b5\u4e0b\u4f60\u9700\u8981\u901a\u8fc7\u663e\u5f0f\u6307\u5b9a\u523b\u5ea6\u4f4d\u7f6e\u548c\u523b\u5ea6\u6807\u7b7e\u7684\u65b9\u6cd5\u6765\u4fee\u590d\u8f74\u6807\u7b7e\u3002 \u989c\u8272\u3001\u6807\u8bb0\u548c\u7ebf\u7c7b\u578b matplotlib \u7684\u4e3b\u51fd\u6570 plot \u63a5\u6536\u5e26\u6709 x \u548c y \u8f74\u7684\u6570\u7ec4\u4ee5\u53ca\u4e00\u4e9b\u53ef\u9009\u7684\u5b57\u7b26\u4e32\u7f29\u5199\u53c2\u6570\u6765\u6307\u660e\u989c\u8272\u548c\u7ebf\u7c7b\u578b\u3002 \u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') data = np.random.randn(30).cumsum() plt.plot(data, 'ko--') plt.show() # \u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u5199\u5f97\u66f4\u4e3a\u663e\u5f0f\uff1a plt.plot(data, color='k', linestyle='dashed', marker='o') plt.show() plt.plot(data, color='k', linestyle='dashed', marker='o', label='Default') plt.show() plt.plot(data, color='k', linestyle='dashed', marker='o', label='steps-post', drawstyle='steps-post') plt.show() \u523b\u5ea6\u3001\u6807\u7b7e\u548c\u56fe\u4f8b \u5bf9\u4e8e\u5927\u591a\u6570\u56fe\u8868\u4fee\u9970\u5de5\u4f5c\uff0c\u6709\u4e24\u79cd\u4e3b\u8981\u7684\u65b9\u5f0f\uff1a\u4f7f\u7528\u7a0b\u5e8f\u6027\u7684pyplot\u63a5\u53e3\uff08\u5373matplotlib.pyplot\uff09\u548c\u66f4\u591a\u9762\u5411\u5bf9\u8c61\u7684\u539f\u751fmatplotlib API\u3002 pyplot \u63a5\u53e3\u8bbe\u8ba1\u4e3a\u4ea4\u4e92\u5f0f\u4f7f\u7528\uff0c\u5305\u542b\u4e86\u50cf xlim \u3001 xticks \u548c xticklabels \u7b49\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5206\u522b\u63a7\u5236\u4e86\u7ed8\u56fe\u8303\u56f4\u3001\u523b\u5ea6\u4f4d\u7f6e\u4ee5\u53ca\u523b\u5ea6\u6807\u7b7e\u3002 \u5728\u6ca1\u6709\u51fd\u6570\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8c03\u7528\uff0c\u8fd4\u56de\u5f53\u524d\u7684\u53c2\u6570\u503c\uff08\u4f8b\u5982 plt.xlim() \u8fd4\u56de\u5f53\u524d\u7684x\u8f74\u7ed8\u56fe\u8303\u56f4\uff09\u3002 \u4f20\u5165\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8c03\u7528\uff0c\u5e76\u8bbe\u7f6e\u53c2\u6570\u503c\uff08\u4f8b\u5982 plt.xlim\uff08[0, 10]\uff09 \u4f1a\u5c06 x \u8f74\u7684\u8303\u56f4\u8bbe\u7f6e\u4e3a0\u523010\uff09\u3002 \u6240\u6709\u7684\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u4f1a\u5728\u5f53\u524d\u6d3b\u52a8\u7684\u6216\u6700\u8fd1\u521b\u5efa\u7684 AxesSubplot \u4e0a\u751f\u6548\u3002 \u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5bf9\u5e94\u4e8e\u5b50\u56fe\u81ea\u8eab\u7684\u4e24\u4e2a\u65b9\u6cd5\u3002\u6bd4\u5982 xlim \u5bf9\u5e94\u4e8e ax.get_lim \u548c ax.set_lim \u3002 \u63a8\u8350\u4f7f\u7528 subplot \u7684\u5b9e\u4f8b\u65b9\u6cd5\uff0c\u56e0\u4e3a\u8fd9\u6837\u66f4\u4e3a\u663e\u5f0f\uff08\u5c24\u5176\u662f\u5728\u5904\u7406\u591a\u4e2a\u5b50\u56fe\u65f6\uff09\u3002 data = np.random.randn(1000).cumsum() fig = plt.figure() # \u8bbe\u5b9a\u5b50\u56fe ax = fig.add_subplot(1, 1, 1) # \u8bbe\u5b9ax\u8f74\u5bf9\u5e94\u53c2\u6570\uff1a # \u8bbe\u5b9ax\u8f74\u523b\u5ea6 ax.set_xticks([0, 250, 500, 750, 1000]) # \u8bbe\u5b9ax\u8f74\u6807\u7b7e ax.set_xticklabels(['one(0)', 'two(250)', 'three(500)', 'four(750)', 'five(1000)'], rotation=30, fontsize='small') # \u7ed9x\u8f74\u4e00\u4e2a\u540d\u79f0 ax.set_xlabel('Stages') # \u8bbe\u5b9ay\u8f74\u5bf9\u5e94\u53c2\u6570\uff1a # \u672a\u6307\u5b9a\u7684\u53c2\u6570\u7531\u7cfb\u7edf\u9ed8\u8ba4\u4ea7\u751f\u3002 ax.set_ylabel('Steps') # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e2a\u6807\u9898 ax.set_title('My first matplotlib plot') # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e2a\u56fe\u4f8b\uff08\u5982\uff1a\u7ed9\u5b50\u56fe\u5185\u4e00\u4e2a\u56fe\u5f62\u66f2\u7ebf\u6dfb\u52a0\u4e00\u4e2alabel\uff09 ax.plot(data, 'k--', label='Label One') # loc\u53c2\u6570\u544a\u8bc9matplotlib\u5728\u54ea\u91cc\u653e\u7f6e\u56fe\u8868\u3002legend\u65b9\u6cd5\u6709\u591a\u4e2a\u5176\u4ed6\u7684\u4f4d\u7f6e\u53c2\u6570loc\u3002 ax.legend(loc='best') # \u6216\u8005plt.legend(loc='best') \u3002 # \u5728\u56fe\u5f62\u5750\u6807\u4e3a(0, 0)\u7684\u4f4d\u7f6e\u6dfb\u52a0\u4e00\u4e2alable ax.text(0, 0, 'Hello World1', family='monospace', fontsize=10) # \u7ed9\u5b50\u56fe\u6dfb\u52a0annotate\u3002\u7528\u4e00\u4e2a\u7bad\u5934\u6307\u5411\u8981\u6ce8\u91ca\u7684\u5730\u65b9\uff0c\u518d\u5199\u4e0a\u4e00\u6bb5\u8bdd\u7684\u884c\u4e3a\uff0c\u53eb\u505aannotate\u3002 # * s: \u6ce8\u91ca\u7684\u5185\u5bb9\uff0c\u4e00\u6bb5\u6587\u5b57\uff1b # * xytext: \u8fd9\u6bb5\u6587\u5b57\u6240\u5904\u7684\u4f4d\u7f6e; # * xy: \u7bad\u5934\u6307\u5411\u7684\u4f4d\u7f6e\uff1b # * arrowprops: \u901a\u8fc7arrowstyle\u8868\u660e\u7bad\u5934\u7684\u98ce\u683c\u6216\u79cd\u7c7b\u3002 ax.annotate('Zero is here!', xytext=(20, 20), xy=(1, 1), arrowprops=dict(arrowstyle='->')) # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e9b\u56fe\u5f62 # matplotlib\u542b\u6709\u8868\u793a\u591a\u79cd\u5e38\u89c1\u56fe\u5f62\u7684\u5bf9\u8c61\uff0c\u8fd9\u4e9b\u5bf9\u8c61\u7684\u5f15\u7528\u662fpatches\u3002 # \u4e00\u4e9b\u56fe\u5f62\uff0c\u6bd4\u5982Rectangle\uff08\u77e9\u5f62\uff09\u548cCircle\uff08\u5706\u5f62\uff09\uff0c\u53ef\u4ee5\u5728matplotlib.pyplot\u4e2d\u627e\u5230\uff0c\u4f46\u56fe\u5f62\u7684\u5168\u96c6\u4f4d\u4e8ematplotlib.patches\u3002 rect = plt.Rectangle((10, 5), 100, 15, color='k', alpha=0.3) circ = plt.Circle((200, 9), 95, color='b', alpha=0.3) pgon = plt.Polygon([[500, 5], [600, -5], [700, 30]], color='g', alpha=0.5) ax.add_patch(rect) ax.add_patch(circ) ax.add_patch(pgon) # \u5c06\u56fe\u7247\u4fdd\u5b58\u5230\u6587\u4ef6 # \u6587\u4ef6\u7c7b\u578b\u662f\u4ece\u6587\u4ef6\u6269\u5c55\u540d\u4e2d\u63a8\u65ad\u51fa\u6765\u7684\u3002\u6240\u4ee5\u5982\u679c\u4f60\u4f7f\u7528\uff0epdf\uff0c\u5219\u4f1a\u5f97\u5230\u4e00\u4e2aPDF\u3002 # \u51e0\u4e2a\u91cd\u8981\u7684\u9009\u9879\uff1adpi\uff0c\u5b83\u63a7\u5236\u6bcf\u82f1\u5bf8\u70b9\u6570\u7684\u5206\u8fa8\u7387\uff1bbbox_inches\uff0c\u53ef\u4ee5\u4fee\u526a\u5b9e\u9645\u56fe\u5f62\u7684\u7a7a\u767d\u3002 plt.savefig('../examples/figpath.png', dpi=400, bbox_inches='tight') # saveifg\u5e76\u975e\u4e00\u5b9a\u662f\u5199\u5230\u786c\u76d8\u7684\uff0c\u5b83\u53ef\u4ee5\u5c06\u56fe\u7247\u5199\u5165\u5230\u6240\u6709\u7684\u6587\u4ef6\u578b\u5bf9\u8c61\u4e2d\uff0c\u4f8b\u5982BytesIO buffer = BytesIO() plt.savefig(buffer) plot_data = buffer.getvalue() plt.show() matplotlib\u8bbe\u7f6e matplotlib \u914d\u7f6e\u4e86\u914d\u8272\u65b9\u6848\u548c\u9ed8\u8ba4\u8bbe\u7f6e\uff0c\u901a\u8fc7\u5168\u5c40\u53c2\u6570\u6765\u5b9a\u5236\uff0c\u5305\u62ec\u56fe\u5f62\u5927\u5c0f\u3001\u5b50\u56fe\u95f4\u8ddd\u3001\u989c\u8272\u3001\u5b57\u4f53\u5927\u5c0f\u548c\u7f51\u683c\u6837\u5f0f\u7b49\u7b49\u3002 \u4f7f\u7528 rc \u65b9\u6cd5\u662f\u4f7f\u7528Python\u7f16\u7a0b\u4fee\u6539\u914d\u7f6e\u7684\u4e00\u79cd\u65b9\u5f0f\u3002 rc \u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u4f60\u60f3\u8981\u81ea\u5b9a\u4e49\u7684\u7ec4\u4ef6\uff0c\u6bd4\u5982 'figure'\u3001'axes'\u3001'xtick'\u3001'ytick'\u3001'grid'\u3001'legend' \u7b49\u7b49\u3002 \u4e4b\u540e\uff0c\u53ef\u4ee5\u6309\u7167\u5173\u952e\u5b57\u53c2\u6570\u7684\u5e8f\u5217\u6307\u5b9a\u65b0\u53c2\u6570\u3002 \u5b57\u5178\u662f\u4e00\u79cd\u5728\u7a0b\u5e8f\u4e2d\u8bbe\u7f6e\u9009\u9879\u7684\u7b80\u5355\u65b9\u5f0f\u3002\u6bd4\u5982\uff1a plt.rc('figure', figsize=(10, 10)) font_options = { 'family': 'monospace', 'weight': 'bold', 'size': 'small' } plt.rc('font', **font_options) \u4f7f\u7528pandas\u548cseaborn\u7ed8\u56fe pandas\u81ea\u8eab\u6709\u5f88\u591a\u5185\u5efa\u65b9\u6cd5\u53ef\u4ee5\u7b80\u5316\u4eceDataFrame\u548cSeries\u5bf9\u8c61\u751f\u6210\u53ef\u89c6\u5316\u7684\u8fc7\u7a0b\u3002 \u53e6\u4e00\u4e2a\u5e93\u662f seaborn \u3002 seaborn \u7b80\u5316\u4e86\u5f88\u591a\u5e38\u7528\u53ef\u89c6\u5316\u7c7b\u578b\u7684\u751f\u6210\u3002 \u5bfc\u5165 seaborn \u4f1a\u4fee\u6539\u9ed8\u8ba4\u7684matplotlib\u914d\u8272\u65b9\u6848\u548c\u7ed8\u56fe\u6837\u5f0f\uff0c\u8fd9\u4f1a\u63d0\u9ad8\u56fe\u8868\u7684\u53ef\u8bfb\u6027\u548c\u7f8e\u89c2\u6027\u3002 \u5373\u4f7f\u4e0d\u4f7f\u7528seaborn\u7684API\uff0c\u4e5f\u53ef\u4ee5\u5bfc\u5165seaborn\u6765\u4e3a\u901a\u7528matplotlib\u56fe\u8868\u63d0\u4f9b\u66f4\u597d\u7684\u89c6\u89c9\u7f8e\u89c2\u5ea6\u3002 import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns \u6298\u7ebf\u56fe Series\u548cDataFrame\u90fd\u6709\u4e00\u4e2a plot \u5c5e\u6027\uff0c\u7528\u4e8e\u7ed8\u5236\u57fa\u672c\u7684\u56fe\u5f62\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c plot() \u7ed8\u5236\u7684\u662f\u6298\u7ebf\u56fe\u3002 Series\u7684 plot \u53c2\u6570\uff1a ax: matplotlib\u5b50\u56fe\u5bf9\u8c61axes\uff0c\u5982\u679c\u6ca1\u6709\u4f20\u503c\uff0c\u5219\u4f7f\u7528\u5f53\u524d\u6d3b\u52a8\u7684\u5b50\u56fe\u9ed8\u8ba4\u4f7f\u7528gca() alpha: \u56fe\u7247\u4e0d\u900f\u660e\u5ea6\uff080\u52301\uff09 data: \u6570\u636e\u5e8f\u5217Series figsize: \u56fe\u50cf\u5c3a\u5bf8\uff0ctuple(\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c\u6ce8\u610f\u8fd9\u91cc\u7684\u5355\u4f4d\u662f\u82f1\u5bf8 fontsize: \u8bbe\u7f6e\u523b\u5ea6\u6807\u7b7e\uff08xticks, yticks\uff09\u7684\u5927\u5c0f grid: \u7f51\u683c\u7ebf\uff08\u9ed8\u8ba4\u662f\u6253\u5f00\u7684\uff09 kind: \u56fe\u7c7b\u578b\uff1a\u6298\u7ebf\u56fe\uff0c\u67f1\u5f62\u56fe\uff0c\u6a2a\u5411\u67f1\u5f62\u56fe\uff0c\u76f4\u65b9\u56fe\uff0c\u7bb1\u7ebf\u56fe\uff0c\u5bc6\u5ea6\u56fe\uff0c\u9762\u79ef\u56fe\uff0c\u997c\u56fe label: \u5217\u7684\u522b\u540d\uff0c\u4f5c\u7528\u5728\u56fe\u4f8b\u4e0a legend: \u56fe\u4f8b loglog: x,y\u8f74\u90fd\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 logx: x\u8f74\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 logy: y\u8f74\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 mark_right: \u53cc y \u8f74\u65f6\uff0c\u5728\u56fe\u4f8b\u4e2d\u7684\u5217\u6807\u7b7e\u65c1\u589e\u52a0\u663e\u793a (right) \u6807\u8bc6 position: \u67f1\u5f62\u56fe\u7684\u67f1\u5b50\u7684\u4f4d\u7f6e\u8bbe\u7f6e rot: \u6539\u53d8\u523b\u5ea6\u6807\u7b7e\uff08xticks, yticks\uff09\u7684\u65cb\u8f6c\u5ea6\uff080\u5230360\uff09 secondary_y: \u53cc y \u8f74\uff0c\u5728\u53f3\u8fb9\u7684\u7b2c\u4e8c\u4e2a y \u8f74 style: \u7ebf\u7684\u6837\u5f0f\uff0c\u6bd4\u5982'ko--' table: \u5c06\u6570\u636e\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\u5c55\u793a\u51fa\u6765 title: \u6807\u9898 use_index: \u662f\u5426\u4f7f\u7528\u7d22\u5f15\u4f5c\u4e3ax\u523b\u5ea6\u6807\u7b7e xerr: \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe xlim: \u6a2a\u8f74\u5750\u6807\u523b\u5ea6\u7684\u53d6\u503c\u8303\u56f4 xticks: x\u8f74\u523b\u5ea6\u6807\u7b7e yerr: \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe ylim: \u7eb5\u8f74\u5750\u6807\u523b\u5ea6\u7684\u53d6\u503c\u8303\u56f4 yticks: y\u8f74\u523b\u5ea6\u6807\u7b7e **kwds: matplotlib plot\u65b9\u6cd5\u7684\u5176\u4ed6\u53c2\u6570 DataFrame\u7684 plot \u53c2\u6570\uff1a x : \u6307\u6570\u636e\u6846\u5217\u7684\u6807\u7b7e\u6216\u4f4d\u7f6e\u53c2\u6570 y : \u6307\u6570\u636e\u6846\u5217\u7684\u6807\u7b7e\u6216\u4f4d\u7f6e\u53c2\u6570 kind : 'line' : \u6298\u7ebf\u56fe 'bar' : \u6761\u5f62\u56fe 'barh' : \u6a2a\u5411\u6761\u5f62\u56fe 'hist' : \u67f1\u72b6\u56fe 'box' : \u7bb1\u7ebf\u56fe 'kde' : Kernel\u7684\u5bc6\u5ea6\u4f30\u8ba1\u56fe\uff0c\u4e3b\u8981\u5bf9\u67f1\u72b6\u56fe\u6dfb\u52a0Kernel \u6982\u7387\u5bc6\u5ea6\u7ebf 'density' : 'kde' 'area' : area plot 'pie' : \u997c\u56fe 'scatter' : \u6563\u70b9\u56fe \u9700\u8981\u4f20\u5165columns\u65b9\u5411\u7684\u7d22\u5f15 'hexbin' : hexbin plot ax : \u5b50\u56fe(axes, \u4e5f\u53ef\u4ee5\u7406\u89e3\u6210\u5750\u6807\u8f74) \u8981\u5728\u5176\u4e0a\u8fdb\u884c\u7ed8\u5236\u7684matplotlib subplot\u5bf9\u8c61\u3002\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\uff0c\u5219\u4f7f\u7528\u5f53\u524dmatplotlib subplot\u3002\u5176\u4e2d\uff0c\u53d8\u91cf\u548c\u51fd\u6570\u901a\u8fc7\u6539\u53d8figure\u548caxes\u4e2d\u7684\u5143\u7d20\uff08\u4f8b\u5982\uff1atitle,label,\u70b9\u548c\u7ebf\u7b49\u7b49\uff09\u4e00\u8d77\u63cf\u8ff0figure\u548caxes\uff0c\u4e5f\u5c31\u662f\u5728\u753b\u5e03\u4e0a\u7ed8\u56fe\u3002 subplots : \u5224\u65ad\u56fe\u7247\u4e2d\u662f\u5426\u6709\u5b50\u56fe sharex : \u5982\u679c\u6709\u5b50\u56fe\uff0c\u5b50\u56fe\u5171x\u8f74\u523b\u5ea6\uff0c\u6807\u7b7e sharey : \u5982\u679c\u6709\u5b50\u56fe\uff0c\u5b50\u56fe\u5171y\u8f74\u523b\u5ea6\uff0c\u6807\u7b7e layout : \u5b50\u56fe\u7684\u884c\u5217\u5e03\u5c40 figsize : \u56fe\u7247\u5c3a\u5bf8\u5927\u5c0f use_index : \u9ed8\u8ba4\u7528\u7d22\u5f15\u505ax\u8f74 title : \u56fe\u7247\u7684\u6807\u9898\u7528\u5b57\u7b26\u4e32 grid : \u56fe\u7247\u662f\u5426\u6709\u7f51\u683c legend : \u5b50\u56fe\u7684\u56fe\u4f8b\uff0c\u6dfb\u52a0\u4e00\u4e2asubplot\u56fe\u4f8b(\u9ed8\u8ba4\u4e3aTrue) style : \u5bf9\u6bcf\u5217\u6298\u7ebf\u56fe\u8bbe\u7f6e\u7ebf\u7684\u7c7b\u578b logx : \u8bbe\u7f6ex\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 logy : \u8bbe\u7f6ey\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 loglog : \u540c\u65f6\u8bbe\u7f6ex\uff0cy\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 xticks : \u8bbe\u7f6ex\u8f74\u523b\u5ea6\u503c\uff0c\u5e8f\u5217\u5f62\u5f0f\uff08\u6bd4\u5982\u5217\u8868\uff09 yticks : \u8bbe\u7f6ey\u8f74\u523b\u5ea6\uff0c\u5e8f\u5217\u5f62\u5f0f\uff08\u6bd4\u5982\u5217\u8868\uff09 xlim : \u8bbe\u7f6e\u5750\u6807\u8f74x\u7684\u8303\u56f4\uff0c\u5217\u8868\u6216\u5143\u7ec4\u5f62\u5f0f ylim : \u8bbe\u7f6e\u5750\u6807\u8f74y\u7684\u8303\u56f4\uff0c\u5217\u8868\u6216\u5143\u7ec4\u5f62\u5f0f rot : \u8bbe\u7f6e\u8f74\u6807\u7b7e\uff08\u8f74\u523b\u5ea6\uff09\u7684\u663e\u793a\u65cb\u8f6c\u5ea6\u6570 fontsize : \u8bbe\u7f6e\u8f74\u523b\u5ea6\u7684\u5b57\u4f53\u5927\u5c0f colormap : \u8bbe\u7f6e\u56fe\u7684\u533a\u57df\u989c\u8272 colorbar : \u56fe\u7247\u67f1\u5b50 position : Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center) layout : \u5e03\u5c40(rows, columns) for the layout of the plot table : \u5982\u679c\u4e3a\u6b63\uff0c\u5219\u9009\u62e9DataFrame\u7c7b\u578b\u7684\u6570\u636e\u5e76\u4e14\u8f6c\u6362\u5339\u914dmatplotlib\u7684\u5e03\u5c40 yerr : \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe xerr : \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe stacked : \u751f\u6210\u5806\u79ef\u67f1\u72b6\u56fe sort_columns : \u4ee5\u5b57\u6bcd\u8868\u987a\u5e8f\u7ed8\u5236\u5404\u5217\uff0c\u9ed8\u8ba4\u4f7f\u7528\u524d\u5217\u987a\u5e8f secondary_y : \u8bbe\u7f6e\u7b2c\u4e8c\u4e2ay\u8f74\uff08\u53f3y\u8f74\uff09 mark_right : When using a secondary_y axis, automatically mark the column labels with \u201c(right)\u201d in the legend kwds : Options to pass to matplotlib plotting method Series data1 = np.random.randn(10).cumsum(0) s1 = pd.Series( data1, index=np.arange(0, 100, 10), ) print(s1) fig, axes = plt.subplots(3, 1) # 3\u4e2a\u5b50\u56fe s1.plot.bar(ax=axes[0], color='k', alpha=0.7) # \u6761\u5f62\u56fe(\u5b50\u56fe0)\uff0ccolor='k\u2019(\u67f1\u5b50\u7684\u989c\u8272\u8bbe\u7f6e\u4e3a\u9ed1\u8272)\uff0calpha=0.7(\u56fe\u50cf\u7684\u586b\u5145\u8272\u8bbe\u7f6e\u4e3a\u90e8\u5206\u900f\u660e) s1.plot.barh(ax=axes[1], color='k', alpha=0.7) # \u6a2a\u5411\u6761\u5f62\u56fe(\u5b50\u56fe1) s1.value_counts().plot.pie(ax=axes[2]) # \u901a\u8fc7value_counts()\u5bf9Series\u503c\u9891\u7387\u8fdb\u884c\u53ef\u89c6\u5316 plt.show() DataFrame data2 = np.random.randn(10, 4).cumsum(0) df1 = pd.DataFrame( data2, columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'), index=np.arange(0, 100, 10) ) print(df1) fig, axes = plt.subplots(2, 1) # 2\u4e2a\u5b50\u56fe df1.plot.kde(ax=axes[0], alpha=0.7, grid='True', title='KDE Figure', sharex=True) df1.plot.bar(ax=axes[1], grid='True', title='Line Figure', sharex=True, use_index=False, stacked=True) # \u56e0\u4e3a\u5171\u4eabx\u8f74\uff0c\u6240\u4ee5\u5728KDE\u5b50\u56fe\u4e2d\u6307\u5b9ause_index=False\u770b\u4e0d\u51fa\u6548\u679c\u3002 # DataFrame\u7684\u5217\u540d\u79f0\"Genus\"\u88ab\u7528\u4f5c\u4e86\u56fe\u4f8b\u6807\u9898 # stacked=True\u6765\u751f\u6210\u5806\u79ef\u67f1\u72b6\u56fe plt.show() \u5b9e\u4f8b\uff1a\u7ed8\u5236\u4e00\u4e2a\u5806\u79ef\u67f1\u72b6\u56fe\uff0c\u7528\u4e8e\u5c55\u793a\u6bcf\u4e2a\u6d3e\u5bf9\u5728\u6bcf\u5929\u7684\u6570\u636e\u70b9\u5360\u6bd4\u3002 \u4ea4\u53c9\u8868 \u662f\u4e00\u79cd\u5e38\u7528\u7684\u5206\u7c7b\u6c47\u603b\u8868\u683c\uff0c\u7528\u4e8e\u9891\u6570\u5206\u5e03\u7edf\u8ba1\uff0c\u4e3b\u8981\u4ef7\u503c\u5728\u4e8e\u63cf\u8ff0\u4e86\u53d8\u91cf\u95f4\u5173\u7cfb\u7684\u6df1\u523b\u542b\u4e49\u3002 \u867d\u7136\u4e24\u4e2a\uff08\u6216\u4ee5\u4e0a\uff09\u53d8\u91cf\u53ef\u4ee5\u662f\u5206\u7c7b\u7684\u6216\u6570\u91cf\u7684\uff0c\u4f46\u662f\u4ee5\u90fd\u662f\u5206\u7c7b\u7684\u60c5\u5f62\u6700\u4e3a\u5e38\u89c1\u3002 Pandas\u7684 crosstab() \u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u6784\u5efa\u4ea4\u53c9\u8868\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u52a0\u4ee5\u4e2a\u6027\u5316\u7684\u8bbe\u7f6e\u3002\u5176\u4e2d\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u5c06\u6784\u6210\u4ea4\u53c9\u8868\u7684\u884c\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u5c06\u6784\u6210\u4ea4\u53c9\u8868\u7684\u5217\u3002 tips = pd.read_csv('../examples/tips.csv') print(tips) # total_bill tip smoker day time size # 0 16.99 1.01 No Sun Dinner 2 # 1 10.34 1.66 No Sun Dinner 3 # 2 21.01 3.50 No Sun Dinner 3 # 3 23.68 3.31 No Sun Dinner 2 # 4 24.59 3.61 No Sun Dinner 4 # .. ... ... ... ... ... ... # 239 29.03 5.92 No Sat Dinner 3 # 240 27.18 2.00 Yes Sat Dinner 2 # 241 22.67 2.00 Yes Sat Dinner 2 # 242 17.82 1.75 No Sat Dinner 2 # 243 18.78 3.00 No Thur Dinner 2 # [244 rows x 6 columns] party_counts = pd.crosstab(tips['day'], tips['size']) # \u5bf9\u539f\u59cb\u6570\u636e\u7684day\u548csize\u8fdb\u884c\u805a\u5408\uff0c\u5e76\u6784\u5efa\u4ea4\u53c9\u8868\uff0cday\u4f5c\u4e3a\u884c\uff0csize\u4f5c\u4e3a\u5217\u3002 print(party_counts) # size 1 2 3 4 5 6 # day # Fri 1 16 1 1 0 0 # Sat 2 53 18 13 1 0 # Sun 0 39 15 18 3 1 # Thur 1 48 4 5 1 3 # \u6ca1\u6709\u592a\u591a\u76841\u4eba\u548c6\u4eba\u6d3e\u5bf9\uff0c\u820d\u5f03\u8fd9\u4e9b\u6570\u636e party_counts = party_counts.loc[:, 2:5] print(party_counts) # size 2 3 4 5 # day # Fri 16 1 1 0 # Sat 53 18 13 1 # Sun 39 15 18 3 # Thur 48 4 5 1 # \u6807\u51c6\u5316\u81f3\u548c\u4e3a1\uff1a\u6cbf0\u8f74\uff08\u884c\uff09\u5bf9\u6bcf\u5217\u6c42\u548c\uff0c\u6bcf\u884c\u5404\u503c\u9664\u4ee5\u548c\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e00\u884c\u7684\u503c\u548c\u4e3a1\uff0c\u7136\u540e\u8fdb\u884c\u7ed8\u56fe party_pcts = party_counts.div(party_counts.sum(1), axis=0) print(party_pcts) # size 2 3 4 5 # day # Fri 0.888889 0.055556 0.055556 0.000000 # Sat 0.623529 0.211765 0.152941 0.011765 # Sun 0.520000 0.200000 0.240000 0.040000 # Thur 0.827586 0.068966 0.086207 0.017241 party_counts.plot.bar() plt.show() \u53ef\u4ee5\u770b\u5230\u672c\u6570\u636e\u96c6\u4e2d\u7684\u6d3e\u5bf9\u6570\u91cf\u5728\u5468\u672b\u4f1a\u589e\u52a0\u3002 \u5b9e\u4f8b\uff1a\u4f7f\u7528seaborn\u8fdb\u884c\u6309\u661f\u671f\u65e5\u671f\u8ba1\u7b97\u5c0f\u8d39\u767e\u5206\u6bd4\u3002 Seaborn\u8981\u6c42\u6570\u636e\u7684\u8f93\u5165\u7c7b\u578b\u4e3apandas\u7684Dataframe\u6216Numpy\u6570\u7ec4\u3002 tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) print(tips) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 # .. ... ... ... ... ... ... ... # 239 29.03 5.92 No Sat Dinner 3 0.256166 # 240 27.18 2.00 Yes Sat Dinner 2 0.079428 # 241 22.67 2.00 Yes Sat Dinner 2 0.096759 # 242 17.82 1.75 No Sat Dinner 2 0.108899 # 243 18.78 3.00 No Thur Dinner 2 0.190114 # [244 rows x 7 columns] # barplot: \u5c06\u70b9\u4f30\u8ba1\u548c\u7f6e\u4fe1\u533a\u95f4\u663e\u793a\u4e3a\u77e9\u5f62\u6761\u3002\u6761\u5f62\u56fe\u8868\u793a\u5177\u6709\u6bcf\u4e2a\u77e9\u5f62\u7684\u9ad8\u5ea6\u7684\u6570\u503c\u53d8\u91cf\u7684\u96c6\u4e2d\u8d8b\u52bf\u7684\u4f30\u8ba1\uff0c\u5e76\u4e14\u4f7f\u7528\u8bef\u5dee\u6761\u63d0\u4f9b\u56f4\u7ed5\u8be5\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4e00\u4e9b\u6307\u793a # \u67f1\u5b50\u7684\u503c\u662ftip_pct\u7684\u5e73\u5747\u503c # \u67f1\u5b50\u4e0a\u753b\u51fa\u7684\u9ed1\u7ebf\u4ee3\u8868\u7684\u662f95%\u7684\u7f6e\u4fe1\u533a\u95f4\uff08\u7f6e\u4fe1\u533a\u95f4\u53ef\u4ee5\u901a\u8fc7\u53ef\u9009\u53c2\u6570\u8fdb\u884c\u8bbe\u7f6e\uff09 # hue\u9009\u9879\uff0c\u5141\u8bb8\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u989d\u5916\u7684\u5206\u7c7b\u503c\u5c06\u6570\u636e\u5206\u79bb # \u5e26\u53c2\u6570hue='time'\u65f6\uff0c\u56db\u4e2a\u4e0d\u540c\u989c\u8272\u7684\u67f1\u5b50\uff0c\u6bcf\u4e2a\u67f1\u5b50\u4e0a\u6709\u7f6e\u4fe1\u533a\u95f4\u7684\u9ed1\u7ebf\uff0c\u523b\u5ea60.00~0.30\uff0c\u6b65\u957f0.05 # \u4e0d\u5e26\u53c2\u6570hue='time'\u65f6\uff0c\u4e24\u4e2a\u4e0d\u540c\u989c\u8272\u7684\u67f1\u5b50\uff0c\u5206\u522b\u4ee3\u8868Dinner\u548cLunch\uff0c\u4e0d\u662f\u6bcf\u4e2a\u67f1\u5b50\u4e0a\u90fd\u6709\u7f6e\u4fe1\u533a\u95f4\u7684\u9ed1\u7ebf\uff0c\u523b\u5ea60.00~0.30\uff0c\u6b65\u957f0.05 sns.barplot(x='tip_pct', y='day', data=tips, hue='time', orient='h') # \u6839\u636e\u661f\u671f\u65e5\u671f\u548c\u65f6\u95f4\u8ba1\u7b97\u7684\u5c0f\u8d39\u767e\u5206\u6bd4 # sns.barplot(x='tip_pct', y='day', data=tips, orient='h') sns.set(style=\"darkgrid\", palette=\"deep\") # style=\"whitegrid\" plt.show() \u76f4\u65b9\u56fe\u548c\u5bc6\u5ea6\u56fe \u76f4\u65b9\u56fe\u662f\u4e00\u79cd\u6761\u5f62\u56fe\uff0c\u7528\u4e8e\u7ed9\u51fa\u503c\u9891\u7387\u7684\u79bb\u6563\u663e\u793a\u3002\u6570\u636e\u70b9\u88ab\u5206\u6210\u79bb\u6563\u7684\uff0c\u5747\u5300\u95f4\u9694\u7684\u7bb1\uff0c\u5e76\u4e14\u7ed8\u5236\u6bcf\u4e2a\u7bb1\u4e2d\u6570\u636e\u70b9\u7684\u6570\u91cf\u3002 tips['tip_pct'].plot.hist(bins=50) # \u5c0f\u8d39\u767e\u5206\u6bd4\u7684\u76f4\u65b9\u56fe plt.show() \u5bc6\u5ea6\u56fe\u662f\u4e00\u79cd\u4e0e\u76f4\u65b9\u56fe\u76f8\u5173\u7684\u56fe\u8868\u7c7b\u578b\uff0c\u5b83\u901a\u8fc7\u8ba1\u7b97\u53ef\u80fd\u4ea7\u751f\u89c2\u6d4b\u6570\u636e\u7684\u8fde\u7eed\u6982\u7387\u5206\u5e03\u4f30\u8ba1\u800c\u4ea7\u751f\u3002 \u901a\u5e38\u7684\u505a\u6cd5\u662f\u5c06\u8fd9\u79cd\u5206\u5e03\u8fd1\u4f3c\u4e3a\u201c\u5185\u6838\u201d\u7684\u6df7\u5408\uff0c\u4e5f\u5c31\u662f\u50cf\u6b63\u6001\u5206\u5e03\u90a3\u6837\u7b80\u5355\u7684\u5206\u5e03\u3002 \u56e0\u6b64\uff0c\u5bc6\u5ea6\u56fe\u4e5f\u88ab\u79f0\u4e3a\u5185\u6838\u5bc6\u5ea6\u4f30\u8ba1\u56fe\uff08KDE\uff09\u3002 tips['tip_pct'].plot.density() # \u5c0f\u8d39\u767e\u5206\u6bd4\u5bc6\u5ea6\u56fe plt.show() \u7ed8\u5236\u76f4\u65b9\u56fe\u548c\u8fde\u7eed\u5bc6\u5ea6\u4f30\u8ba1 sns.displot() \u3002 sns.distplot(tips['tip_pct'], bins=100, color='k') plt.show() # FutureWarning: `distplot` is a deprecated function and will be removed in a future version. # Please adapt your code to use either `displot` (a figure-level function with similar flexibility) # or `histplot` (an axes-level function for histograms). \u6563\u70b9\u56fe\u6216\u70b9\u56fe \u70b9\u56fe\u6216\u6563\u70b9\u56fe\u53ef\u4ee5\u7528\u4e8e\u68c0\u9a8c\u4e24\u4e2a\u4e00\u7ef4\u6570\u636e\u5e8f\u5217\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b9e\u4f8b\uff1a\u4ece statsmodels \u9879\u76ee\u4e2d\u8f7d\u5165\u4e86macrodata\u6570\u636e\u96c6\uff0c\u5e76\u9009\u62e9\u4e86\u4e00\u4e9b\u53d8\u91cf\uff0c\u4e4b\u540e\u8ba1\u7b97\u5bf9\u6570\u5dee\u3002 macro = pd.read_csv('../examples/macrodata.csv') print(macro.head(5)) # year quarter realgdp realcons ... unemp pop infl realint # 0 1959.0 1.0 2710.349 1707.4 ... 5.8 177.146 0.00 0.00 # 1 1959.0 2.0 2778.801 1733.7 ... 5.1 177.830 2.34 0.74 # 2 1959.0 3.0 2775.488 1751.8 ... 5.3 178.657 2.74 1.09 # 3 1959.0 4.0 2785.204 1753.7 ... 5.6 179.386 0.27 4.06 # 4 1960.0 1.0 2847.699 1770.5 ... 5.2 180.007 2.31 1.19 # [5 rows x 14 columns] data = macro[['cpi', 'm1', 'tbilrate', 'unemp']] print(data.head(5)) # cpi m1 tbilrate unemp # 0 28.98 139.7 2.82 5.8 # 1 29.15 141.7 3.08 5.1 # 2 29.35 140.5 3.82 5.3 # 3 29.37 140.0 4.33 5.6 # 4 29.54 139.6 3.50 5.2 trans_data = np.log(data).diff().dropna() print(trans_data[-5:]) # cpi m1 tbilrate unemp # 198 -0.007904 0.045361 -0.396881 0.105361 # 199 -0.021979 0.066753 -2.277267 0.139762 # 200 0.002340 0.010286 0.606136 0.160343 # 201 0.008419 0.037461 -0.200671 0.127339 # 202 0.008894 0.012202 -0.405465 0.042560 \u7528 seaborn \u7684 regplot \u65b9\u6cd5\u7ed8\u5236\u6563\u70b9\u56fe\uff0c\u5e76\u62df\u5408\u51fa\u4e00\u4e2a\u6761\u7ebf\u6027\u56de\u5f52\u7ebf\u3002( seaborn\u6587\u6863 ) sns.regplot('m1', 'unemp', data=trans_data) plt.title('Changes in log %s versus log %s ' % ('m1', 'unemp')) plt.show() \u5728\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u4e2d\uff0c\u80fd\u591f\u67e5\u770b\u4e00\u7ec4\u53d8\u91cf\u4e2d\u7684\u6240\u6709\u6563\u70b9\u56fe\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u8fd9\u88ab\u79f0\u4e3a\u6210\u5bf9\u56fe\u6216\u6563\u70b9\u56fe\u77e9\u9635\u3002 Seaborn\u6709\u4e00\u4e2a\u65b9\u4fbf\u7684 pairplot \u51fd\u6570\uff0c\u5b83\u652f\u6301\u5728\u5bf9\u89d2\u7ebf\u4e0a\u653e\u7f6e\u6bcf\u4e2a\u53d8\u91cf\u7684\u76f4\u65b9\u56fe\u6216\u5bc6\u5ea6\u4f30\u8ba1\u503c\u3002 plot_ksw \u53c2\u6570\u80fd\u591f\u5c06\u914d\u7f6e\u9009\u9879\u4f20\u9012\u7ed9\u975e\u5bf9\u89d2\u5143\u7d20\u4e0a\u7684\u5404\u4e2a\u7ed8\u56fe\u8c03\u7528\u3002 sns.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2}) plt.show() \u5206\u9762\u7f51\u683c\u548c\u5206\u7c7b\u6570\u636e \u5982\u679c\u6570\u636e\u96c6\u6709\u989d\u5916\u7684\u5206\u7ec4\u7ef4\u5ea6\u600e\u4e48\u529e\uff1f\u4f7f\u7528\u5206\u9762\u7f51\u683c\u662f\u5229\u7528\u591a\u79cd\u5206\u7ec4\u53d8\u91cf\u5bf9\u6570\u636e\u8fdb\u884c\u53ef\u89c6\u5316\u7684\u65b9\u5f0f\u3002 seaborn\u62e5\u6709\u4e00\u4e2a\u6709\u6548\u7684\u5185\u5efa\u51fd\u6570 factorplot \uff0c\u5b83\u53ef\u4ee5\u7b80\u5316\u591a\u79cd\u5206\u9762\u7ed8\u56fe\u3002 sns.factorplot(x='day', y='tip_pct', hue='time', col='smoker', kind='bar', data=tips[tips.tip_pct < 1]) plt.show() # UserWarning: The `factorplot` function has been renamed to `catplot`. # The original name will be removed in a future release. Please update your code. # Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`. sns.catplot(x='day', y='tip_pct', hue='time', col='smoker', kind='box', data=tips[tips.tip_pct < 0.5]) plt.show() \u5176\u4ed6Python\u53ef\u89c6\u5316\u5de5\u5177 \u81ea2010\u5e74\u4ee5\u6765\uff0c\u5f88\u591a\u5f00\u53d1\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u521b\u5efaweb\u4ea4\u4e92\u5f0f\u56fe\u5f62\u4e0a\u3002 \u501f\u52a9\u50cf Bokeh \u548c Plotly \u8fd9\u6837\u7684\u5de5\u5177\uff0c\u5728web\u6d4f\u89c8\u5668\u4e2d\u521b\u5efa\u52a8\u6001\u7684\u3001\u4ea4\u4e92\u5f0f\u56fe\u50cf\u7684\u5de5\u4f5c\u73b0\u5728\u5df2\u7ecf\u53ef\u4ee5\u5b9e\u73b0\u3002 \u53ef\u89c6\u5316\u662f\u4e00\u4e2a\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df\u3002","title":"\u7ed8\u56fe\u4e0e\u53ef\u89c6\u5316"},{"location":"python/DataAnalysis/ch06/#_1","text":"","title":"\u7ed8\u56fe\u4e0e\u53ef\u89c6\u5316"},{"location":"python/DataAnalysis/ch06/#matplotlib-api","text":"import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np import pandas as pd from io import BytesIO \u6267\u884c plt.show() \u65f6\u62a5\u9519\uff1a UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. \u6267\u884c\u4e0b\u9762\u547d\u4ee4\uff0c\u5f97\u5230 plt \u7684 backend \u662f\u7528 agg \u3002 plt.get_backend() \u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') Out[6]: 'agg' \u5b89\u88c5\u4e0b\u9762\u51e0\u4e2a\u5305\uff1a sudo zypper in python-tk python3-tk sudo zypper in plplot-tcltk-devel plplot-tcltk-libs pip install tk \u6dfb\u52a0\u4e0b\u9762\u5230python\u4ee3\u7801\u4e2d\u3002 import matplotlib.pyplot as plt mpl.use('TkAgg') \u6267\u884c\u540e\u62a5\u4e0b\u9762\u9519\u8bef\uff1a your Python may not be configured for Tk \u8fdb\u5165python\u6e90\u7801\u76ee\u5f55\uff0c\u91cd\u65b0\u7f16\u8bd1\u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') james@lizard:/opt/Python-3.9.6> sudo make james@lizard:/opt/Python-3.9.6> sudo make install \u95ee\u9898\u89e3\u51b3\uff0c\u5373\u4f7f\u4e0d\u52a0\u5165 mpl.use('TkAgg') \uff0c\u6267\u884c plt.show() \u4e5f\u662f\u53ef\u4ee5\u8f93\u51fa\u56fe\u50cf\u3002","title":"\u7b80\u660ematplotlib API\u5165\u95e8"},{"location":"python/DataAnalysis/ch06/#_2","text":"matplotlib \u6240\u7ed8\u5236\u7684\u56fe\u4f4d\u4e8e\u56fe\u7247\uff08Figure\uff09\u5bf9\u8c61\u4e2d\u3002\u53ef\u4ee5\u4f7f\u7528 plt.figure \u751f\u6210\u4e00\u4e2a\u65b0\u7684\u56fe\u7247\u3002 \u4f7f\u7528 add_subplot \u521b\u5efa\u4e00\u4e2a\u6216\u591a\u4e2a\u5b50\u56fe\uff08subplot\uff09\u3002 plt \u4e0e ax \u7ed8\u56fe\u3002 fig = plt.figure() # plt: \u5148\u751f\u6210\u4e86\u4e00\u4e2a\u753b\u5e03\uff0c\u7136\u540e\u5728\u8fd9\u4e2a\u753b\u5e03\u4e0a\u9690\u5f0f\u7684\u751f\u6210\u4e00\u4e2a\u753b\u56fe\u533a\u57df\u6765\u8fdb\u884c\u753b\u56fe # plt.plot([1, 2, 3, 4]) # plt.show() # ax: \u5148\u751f\u6210\u4e00\u4e2a\u753b\u5e03\uff082\u00d72\u7684\u533a\u57df\uff0c\u6700\u591a\u653e\u56db\u4e2a\u56fe\u5f62\uff09\uff0c\u7136\u540e\u5728\u6b64\u753b\u5e03\u4e0a\uff0c\u9009\u5b9a\u4e00\u4e2a\u5b50\u533a\u57df\u753b\u4e86\u4e00\u4e2a\u5b50\u56fe\uff08\u5e8f\u53f71\u4ee3\u8868\u7b2c\u4e00\u4e2a\u533a\u57df\uff09 ax1 = fig.add_subplot(2, 2, 1) # \u4e5f\u53ef\u4ee5\u5199\u6210fig.add_subplot(221) ax1.plot([1, 2, 3, 4], [1, 4, 3, 2]) # \u8f93\u51fa\u56fe\u7247\u5230\u7b2c\u4e00\u4e2a\u533a\u57df\u3002 # \u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u6570\u636e\u96c6\u91cc\u5404\u4e2a\u6570\u636e\u70b9\u7684X\u503c\u7684\u96c6\u5408 # \u7b2c\u4e8c\u4e2a\u53c2\u6570\u6570\u636e\u96c6\u91cc\u5404\u4e2a\u6570\u636e\u70b9\u7684Y\u503c\u7684\u96c6\u5408\u3002 # \u4e0d\u662f\u6570\u5b66\u4e0a\u5e38\u89c1\u7684\u6210\u5bf9\u5750\u6807\u70b9\u5982(x1,y1)\u3001(x2,y2)\u3001...\u3001(xn,yn)\u7684\u683c\u5f0f\uff0c\u800c\u662f (x1,x2,...,xn)\u548c(y1,y2,...,yn) \u3002 plt.show() \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u589e\u52a0\u5b50\u56fe\u540e\u7684\u6570\u636e\u53ef\u89c6\u5316\u6548\u679c\u3002 fig = plt.figure() ax1 = fig.add_subplot(2, 2, 1) ax2 = fig.add_subplot(2, 2, 2) ax3 = fig.add_subplot(2, 2, 3) ax1.plot(np.random.randn(50).cumsum(), 'k--') # \u5728\u7b2c\u4e09\u4e2a\u533a\u57df\u8f93\u51fa\u56fe\u50cf\u3002'k--\u2019\u662f\u7528\u4e8e\u7ed8\u5236\u9ed1\u8272\u5206\u6bb5\u7ebf\u7684style\u9009\u9879\u3002 ax2.hist(np.random.randn(100), bins=20, color='k', alpha=0.3) ax3.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30)) plt.show() plt.subplots \u901a\u8fc7 matplotlib \u7684 subplots \u65b9\u6cd5\uff0c\u4f7f\u7528\u5b50\u56fe\u7f51\u683c\u521b\u5efa\u56fe\u7247\uff0c\u7136\u540e\u8fd4\u56de\u5305\u542b\u4e86\u5df2\u751f\u6210\u5b50\u56fe\u5bf9\u8c61\u7684NumPy\u6570\u7ec4\u3002 \u6570\u7ec4 axes \u53ef\u4ee5\u50cf\u4e8c\u7ef4\u6570\u7ec4\u90a3\u6837\u65b9\u4fbf\u5730\u8fdb\u884c\u7d22\u5f15\uff0c\u4f8b\u5982\uff0c axes[0, 1] \u3002 plt.subplots \u53c2\u6570\u9009\u9879\uff1a nrows\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\uff0c\u9ed8\u8ba4\u4e3a1\u3002\u5b50\u56fe\u7f51\u683c\u7684\u884c\u6570\u3002 ncols\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\uff0c\u9ed8\u8ba4\u4e3a1\u3002\u5b50\u56fe\u7f51\u683c\u7684\u5217\u6570\u3002 sharex\uff1a\u53ef\u9009\u7684\uff0c\u9ed8\u8ba4\u4e3aFalse\u3002\u53ef\u9009\u503c\u5982\u4e0b\uff1a True\u6216all\uff0c\u6240\u6709\u5b50\u56fe\u5171\u4eabx\u8f74 False\u6216none\uff0c\u6bcf\u4e2a\u5b50\u56fe\u7684x\u8f74\u90fd\u662f\u72ec\u7acb\u7684 row\uff0c\u6bcf\u884c\u5b50\u56fe\u5171\u4eab\u4e00\u4e2ax\u8f74 col\uff0c\u6bcf\u5217\u5b50\u56fe\u5171\u4eab\u4e00\u4e2ax\u8f74 sharey\uff1a\u7c7b\u4f3c\u4e8esharex\uff0c\u8bbe\u7f6ey\u8f74\u7684\u5171\u4eab\u65b9\u5f0f\u3002\u5f53\u67d0\u5217\u5171\u4eab\u4e00\u4e2ax\u8f74\u65f6\uff0c\u53ea\u6709\u5e95\u90e8\u7684\u5b50\u56fe\u4f1a\u521b\u5efax\u8f74\u6807\u8bb0\u3002\u540c\u6837\u7684\uff0c\u5982\u679c\u67d0\u884c\u5171\u4eab\u4e00\u4e2ay\u8f74\u65f6\uff0c\u53ea\u6709\u884c\u7684\u7b2c\u4e00\u5217\u5b50\u56fe\u4f1a\u521b\u5efay\u8f74\u6807\u8bb0\u3002 squeeze \uff1a\u53ef\u9009\u7684\uff0c\u5e03\u5c14\u578b\uff0c\u9ed8\u8ba4\u4e3aTrue\u3002\u662f\u5426\u538b\u7f29\u8fd4\u56de\u7684Axes\u6570\u7ec4\u3002\u5982\u679c\u4e3aTrue\uff0c\u5f53\u53ea\u6709\u4e00\u4e2a\u5b50\u56fe\uff0c\u5373nrows\u548cncols\u5747\u4e3a1\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u5355\u72ec\u7684Axes\u5bf9\u8c61\uff0c\u5f53\u6709N 1\u548c1 M\u4e2a\u5b50\u56fe\u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a\u4e00\u7ef4Axes\u5bf9\u8c61\u6570\u7ec4\u3002\u5f53\u6709N*M\u4e2a\u5b50\u56fe\uff08N>1\uff0cM>1\uff09\u65f6\uff0c\u8fd4\u56de\u4e8c\u7ef4\u6570\u7ec4\u3002\u5982\u679c\u4e3aFalse\uff0c\u5219\u603b\u662f\u8fd4\u56de\u4e8c\u7ef4\u6570\u7ec4\u3002 num\uff1a\u53ef\u9009\u7684\uff0c\u6574\u578b\u6216\u5b57\u7b26\u4e32\uff0c\u9ed8\u8ba4\u4e3aNone\u3002\u662fmatplotlib.pyplot.figure\u7684\u5173\u952e\u5b57\uff0c\u7528\u4e8e\u8bbe\u7f6e\u56fe\u50cf\u6570\u5b57\u6216\u6807\u7b7e\u3002\u5982\u679c\u672a\u8bbe\u7f6e\u6b64\u53c2\u6570\uff0c\u4f1a\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\uff0c\u5e76\u9012\u589e\u56fe\u50cf\u7f16\u53f7\uff0cfigure\u5bf9\u8c61\u4f1a\u5c06\u7f16\u53f7\u4fdd\u5b58\u5728number\u5c5e\u6027\u4e2d\u3002\u5982\u679c\u8bbe\u7f6e\u4e86\u6b64\u53c2\u6570\uff0c\u5e76\u4e14\u5b58\u5728\u53c2\u6570\u6307\u5b9a\u7684\u56fe\u50cf\uff0c\u5219\u4f1a\u8fd4\u56de\u6b64\u56fe\u50cf\u7684\u5f15\u7528\uff0c\u5982\u679c\u4e0d\u5b58\u5728\u5219\u4f1a\u521b\u5efa\u65b0\u7684\u56fe\u50cf\u5e76\u8fd4\u56de\u5b83\u7684\u5f15\u7528\u3002\u5982\u679c\u662f\u5b57\u7b26\u4e32\uff0c\u5219\u7a97\u53e3\u6807\u9898\u4f1a\u88ab\u8bbe\u7f6e\u4e3a\u6b64\u5b57\u7b26\u4e32\u7684\u503c\u3002 subplot_kw\uff1a\u53ef\u9009\u7684\uff0c\u5b57\u5178\u7c7b\u578b\u3002\u5305\u542b\u4f20\u9012\u7ed9\u7528\u4e8e\u521b\u5efa\u5b50\u56fe\u7684\u8c03\u7528add_subplot\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 gridspec_kw\uff1a\u53ef\u9009\u7684\uff0c\u5b57\u5178\u7c7b\u578b\u3002\u5305\u542b\u4f20\u9012\u7ed9\u7528\u4e8e\u521b\u5efa\u5b50\u56fe\u7f51\u683c\u7684GridSpec\u6784\u9020\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 fig, axes = plt.subplots(2, 3) print(axes) # \u5c06\u751f\u6210\u7684axes\u5bf9\u8c61\u653e\u5165NumPy\u6570\u7ec4\u3002 # [[<AxesSubplot:> <AxesSubplot:> <AxesSubplot:>] # [<AxesSubplot:> <AxesSubplot:> <AxesSubplot:>]] \u8c03\u6574\u5b50\u56fe\u5468\u56f4\u7684\u95f4\u8ddd\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c matplotlib \u4f1a\u5728\u5b50\u56fe\u7684\u5916\u90e8\u548c\u5b50\u56fe\u4e4b\u95f4\u7559\u51fa\u4e00\u5b9a\u7684\u95f4\u8ddd\u3002 \u8fd9\u4e2a\u95f4\u8ddd\u90fd\u662f\u76f8\u5bf9\u4e8e\u56fe\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u6765\u6307\u5b9a\u7684\uff0c\u624b\u52a8\u8c03\u6574\u56fe\u7684\u5927\u5c0f\uff0c\u90a3\u4e48\u95f4\u8ddd\u4f1a\u81ea\u52a8\u8c03\u6574\u3002 \u4e5f\u53ef\u4ee5\u4f7f\u7528\u56fe\u5bf9\u8c61\u4e0a\u7684 subplots_adjust \u65b9\u6cd5\u66f4\u6539\u95f4\u8ddd\uff0c\u4e5f\u53ef\u4ee5\u7528\u4f5c\u9876\u5c42\u51fd\u6570\u3002 fig, axes = plt.subplots(2, 2, sharex=True, sharey=True) for i in range(2): for j in range(2): axes[i, j].hist(np.random.randn(500), bins=50, color='k', alpha=0.5) plt.subplots_adjust(wspace=0, hspace=0) plt.show() \u4e0a\u9762\u8f93\u51fa\u56fe\u50cf\u7684\u8f74\u6807\u7b7e\u662f\u5b58\u5728\u91cd\u53e0\u7684\u3002 matplotlib \u5e76\u4e0d\u68c0\u67e5\u6807\u7b7e\u662f\u5426\u91cd\u53e0\uff0c\u56e0\u6b64\u5728\u7c7b\u4f3c\u60c5\u51b5\u4e0b\u4f60\u9700\u8981\u901a\u8fc7\u663e\u5f0f\u6307\u5b9a\u523b\u5ea6\u4f4d\u7f6e\u548c\u523b\u5ea6\u6807\u7b7e\u7684\u65b9\u6cd5\u6765\u4fee\u590d\u8f74\u6807\u7b7e\u3002","title":"\u56fe\u7247\u4e0e\u5b50\u56fe"},{"location":"python/DataAnalysis/ch06/#_3","text":"matplotlib \u7684\u4e3b\u51fd\u6570 plot \u63a5\u6536\u5e26\u6709 x \u548c y \u8f74\u7684\u6570\u7ec4\u4ee5\u53ca\u4e00\u4e9b\u53ef\u9009\u7684\u5b57\u7b26\u4e32\u7f29\u5199\u53c2\u6570\u6765\u6307\u660e\u989c\u8272\u548c\u7ebf\u7c7b\u578b\u3002 \u4f8b\u5982\uff1a\u4e0b\u9762\u4e24\u79cd\u8868\u8fbe\u65b9\u5f0f\u6548\u679c\u4e00\u6837\u3002 ax.plot(x, y, 'g--') ax.plot(x, y, linestyle='--', color='g') data = np.random.randn(30).cumsum() plt.plot(data, 'ko--') plt.show() # \u4e0a\u9762\u7684\u4ee3\u7801\u53ef\u4ee5\u5199\u5f97\u66f4\u4e3a\u663e\u5f0f\uff1a plt.plot(data, color='k', linestyle='dashed', marker='o') plt.show() plt.plot(data, color='k', linestyle='dashed', marker='o', label='Default') plt.show() plt.plot(data, color='k', linestyle='dashed', marker='o', label='steps-post', drawstyle='steps-post') plt.show()","title":"\u989c\u8272\u3001\u6807\u8bb0\u548c\u7ebf\u7c7b\u578b"},{"location":"python/DataAnalysis/ch06/#_4","text":"\u5bf9\u4e8e\u5927\u591a\u6570\u56fe\u8868\u4fee\u9970\u5de5\u4f5c\uff0c\u6709\u4e24\u79cd\u4e3b\u8981\u7684\u65b9\u5f0f\uff1a\u4f7f\u7528\u7a0b\u5e8f\u6027\u7684pyplot\u63a5\u53e3\uff08\u5373matplotlib.pyplot\uff09\u548c\u66f4\u591a\u9762\u5411\u5bf9\u8c61\u7684\u539f\u751fmatplotlib API\u3002 pyplot \u63a5\u53e3\u8bbe\u8ba1\u4e3a\u4ea4\u4e92\u5f0f\u4f7f\u7528\uff0c\u5305\u542b\u4e86\u50cf xlim \u3001 xticks \u548c xticklabels \u7b49\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5206\u522b\u63a7\u5236\u4e86\u7ed8\u56fe\u8303\u56f4\u3001\u523b\u5ea6\u4f4d\u7f6e\u4ee5\u53ca\u523b\u5ea6\u6807\u7b7e\u3002 \u5728\u6ca1\u6709\u51fd\u6570\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8c03\u7528\uff0c\u8fd4\u56de\u5f53\u524d\u7684\u53c2\u6570\u503c\uff08\u4f8b\u5982 plt.xlim() \u8fd4\u56de\u5f53\u524d\u7684x\u8f74\u7ed8\u56fe\u8303\u56f4\uff09\u3002 \u4f20\u5165\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8c03\u7528\uff0c\u5e76\u8bbe\u7f6e\u53c2\u6570\u503c\uff08\u4f8b\u5982 plt.xlim\uff08[0, 10]\uff09 \u4f1a\u5c06 x \u8f74\u7684\u8303\u56f4\u8bbe\u7f6e\u4e3a0\u523010\uff09\u3002 \u6240\u6709\u7684\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u4f1a\u5728\u5f53\u524d\u6d3b\u52a8\u7684\u6216\u6700\u8fd1\u521b\u5efa\u7684 AxesSubplot \u4e0a\u751f\u6548\u3002 \u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5bf9\u5e94\u4e8e\u5b50\u56fe\u81ea\u8eab\u7684\u4e24\u4e2a\u65b9\u6cd5\u3002\u6bd4\u5982 xlim \u5bf9\u5e94\u4e8e ax.get_lim \u548c ax.set_lim \u3002 \u63a8\u8350\u4f7f\u7528 subplot \u7684\u5b9e\u4f8b\u65b9\u6cd5\uff0c\u56e0\u4e3a\u8fd9\u6837\u66f4\u4e3a\u663e\u5f0f\uff08\u5c24\u5176\u662f\u5728\u5904\u7406\u591a\u4e2a\u5b50\u56fe\u65f6\uff09\u3002 data = np.random.randn(1000).cumsum() fig = plt.figure() # \u8bbe\u5b9a\u5b50\u56fe ax = fig.add_subplot(1, 1, 1) # \u8bbe\u5b9ax\u8f74\u5bf9\u5e94\u53c2\u6570\uff1a # \u8bbe\u5b9ax\u8f74\u523b\u5ea6 ax.set_xticks([0, 250, 500, 750, 1000]) # \u8bbe\u5b9ax\u8f74\u6807\u7b7e ax.set_xticklabels(['one(0)', 'two(250)', 'three(500)', 'four(750)', 'five(1000)'], rotation=30, fontsize='small') # \u7ed9x\u8f74\u4e00\u4e2a\u540d\u79f0 ax.set_xlabel('Stages') # \u8bbe\u5b9ay\u8f74\u5bf9\u5e94\u53c2\u6570\uff1a # \u672a\u6307\u5b9a\u7684\u53c2\u6570\u7531\u7cfb\u7edf\u9ed8\u8ba4\u4ea7\u751f\u3002 ax.set_ylabel('Steps') # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e2a\u6807\u9898 ax.set_title('My first matplotlib plot') # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e2a\u56fe\u4f8b\uff08\u5982\uff1a\u7ed9\u5b50\u56fe\u5185\u4e00\u4e2a\u56fe\u5f62\u66f2\u7ebf\u6dfb\u52a0\u4e00\u4e2alabel\uff09 ax.plot(data, 'k--', label='Label One') # loc\u53c2\u6570\u544a\u8bc9matplotlib\u5728\u54ea\u91cc\u653e\u7f6e\u56fe\u8868\u3002legend\u65b9\u6cd5\u6709\u591a\u4e2a\u5176\u4ed6\u7684\u4f4d\u7f6e\u53c2\u6570loc\u3002 ax.legend(loc='best') # \u6216\u8005plt.legend(loc='best') \u3002 # \u5728\u56fe\u5f62\u5750\u6807\u4e3a(0, 0)\u7684\u4f4d\u7f6e\u6dfb\u52a0\u4e00\u4e2alable ax.text(0, 0, 'Hello World1', family='monospace', fontsize=10) # \u7ed9\u5b50\u56fe\u6dfb\u52a0annotate\u3002\u7528\u4e00\u4e2a\u7bad\u5934\u6307\u5411\u8981\u6ce8\u91ca\u7684\u5730\u65b9\uff0c\u518d\u5199\u4e0a\u4e00\u6bb5\u8bdd\u7684\u884c\u4e3a\uff0c\u53eb\u505aannotate\u3002 # * s: \u6ce8\u91ca\u7684\u5185\u5bb9\uff0c\u4e00\u6bb5\u6587\u5b57\uff1b # * xytext: \u8fd9\u6bb5\u6587\u5b57\u6240\u5904\u7684\u4f4d\u7f6e; # * xy: \u7bad\u5934\u6307\u5411\u7684\u4f4d\u7f6e\uff1b # * arrowprops: \u901a\u8fc7arrowstyle\u8868\u660e\u7bad\u5934\u7684\u98ce\u683c\u6216\u79cd\u7c7b\u3002 ax.annotate('Zero is here!', xytext=(20, 20), xy=(1, 1), arrowprops=dict(arrowstyle='->')) # \u7ed9\u5b50\u56fe\u6dfb\u52a0\u4e00\u4e9b\u56fe\u5f62 # matplotlib\u542b\u6709\u8868\u793a\u591a\u79cd\u5e38\u89c1\u56fe\u5f62\u7684\u5bf9\u8c61\uff0c\u8fd9\u4e9b\u5bf9\u8c61\u7684\u5f15\u7528\u662fpatches\u3002 # \u4e00\u4e9b\u56fe\u5f62\uff0c\u6bd4\u5982Rectangle\uff08\u77e9\u5f62\uff09\u548cCircle\uff08\u5706\u5f62\uff09\uff0c\u53ef\u4ee5\u5728matplotlib.pyplot\u4e2d\u627e\u5230\uff0c\u4f46\u56fe\u5f62\u7684\u5168\u96c6\u4f4d\u4e8ematplotlib.patches\u3002 rect = plt.Rectangle((10, 5), 100, 15, color='k', alpha=0.3) circ = plt.Circle((200, 9), 95, color='b', alpha=0.3) pgon = plt.Polygon([[500, 5], [600, -5], [700, 30]], color='g', alpha=0.5) ax.add_patch(rect) ax.add_patch(circ) ax.add_patch(pgon) # \u5c06\u56fe\u7247\u4fdd\u5b58\u5230\u6587\u4ef6 # \u6587\u4ef6\u7c7b\u578b\u662f\u4ece\u6587\u4ef6\u6269\u5c55\u540d\u4e2d\u63a8\u65ad\u51fa\u6765\u7684\u3002\u6240\u4ee5\u5982\u679c\u4f60\u4f7f\u7528\uff0epdf\uff0c\u5219\u4f1a\u5f97\u5230\u4e00\u4e2aPDF\u3002 # \u51e0\u4e2a\u91cd\u8981\u7684\u9009\u9879\uff1adpi\uff0c\u5b83\u63a7\u5236\u6bcf\u82f1\u5bf8\u70b9\u6570\u7684\u5206\u8fa8\u7387\uff1bbbox_inches\uff0c\u53ef\u4ee5\u4fee\u526a\u5b9e\u9645\u56fe\u5f62\u7684\u7a7a\u767d\u3002 plt.savefig('../examples/figpath.png', dpi=400, bbox_inches='tight') # saveifg\u5e76\u975e\u4e00\u5b9a\u662f\u5199\u5230\u786c\u76d8\u7684\uff0c\u5b83\u53ef\u4ee5\u5c06\u56fe\u7247\u5199\u5165\u5230\u6240\u6709\u7684\u6587\u4ef6\u578b\u5bf9\u8c61\u4e2d\uff0c\u4f8b\u5982BytesIO buffer = BytesIO() plt.savefig(buffer) plot_data = buffer.getvalue() plt.show()","title":"\u523b\u5ea6\u3001\u6807\u7b7e\u548c\u56fe\u4f8b"},{"location":"python/DataAnalysis/ch06/#matplotlib","text":"matplotlib \u914d\u7f6e\u4e86\u914d\u8272\u65b9\u6848\u548c\u9ed8\u8ba4\u8bbe\u7f6e\uff0c\u901a\u8fc7\u5168\u5c40\u53c2\u6570\u6765\u5b9a\u5236\uff0c\u5305\u62ec\u56fe\u5f62\u5927\u5c0f\u3001\u5b50\u56fe\u95f4\u8ddd\u3001\u989c\u8272\u3001\u5b57\u4f53\u5927\u5c0f\u548c\u7f51\u683c\u6837\u5f0f\u7b49\u7b49\u3002 \u4f7f\u7528 rc \u65b9\u6cd5\u662f\u4f7f\u7528Python\u7f16\u7a0b\u4fee\u6539\u914d\u7f6e\u7684\u4e00\u79cd\u65b9\u5f0f\u3002 rc \u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u4f60\u60f3\u8981\u81ea\u5b9a\u4e49\u7684\u7ec4\u4ef6\uff0c\u6bd4\u5982 'figure'\u3001'axes'\u3001'xtick'\u3001'ytick'\u3001'grid'\u3001'legend' \u7b49\u7b49\u3002 \u4e4b\u540e\uff0c\u53ef\u4ee5\u6309\u7167\u5173\u952e\u5b57\u53c2\u6570\u7684\u5e8f\u5217\u6307\u5b9a\u65b0\u53c2\u6570\u3002 \u5b57\u5178\u662f\u4e00\u79cd\u5728\u7a0b\u5e8f\u4e2d\u8bbe\u7f6e\u9009\u9879\u7684\u7b80\u5355\u65b9\u5f0f\u3002\u6bd4\u5982\uff1a plt.rc('figure', figsize=(10, 10)) font_options = { 'family': 'monospace', 'weight': 'bold', 'size': 'small' } plt.rc('font', **font_options)","title":"matplotlib\u8bbe\u7f6e"},{"location":"python/DataAnalysis/ch06/#pandasseaborn","text":"pandas\u81ea\u8eab\u6709\u5f88\u591a\u5185\u5efa\u65b9\u6cd5\u53ef\u4ee5\u7b80\u5316\u4eceDataFrame\u548cSeries\u5bf9\u8c61\u751f\u6210\u53ef\u89c6\u5316\u7684\u8fc7\u7a0b\u3002 \u53e6\u4e00\u4e2a\u5e93\u662f seaborn \u3002 seaborn \u7b80\u5316\u4e86\u5f88\u591a\u5e38\u7528\u53ef\u89c6\u5316\u7c7b\u578b\u7684\u751f\u6210\u3002 \u5bfc\u5165 seaborn \u4f1a\u4fee\u6539\u9ed8\u8ba4\u7684matplotlib\u914d\u8272\u65b9\u6848\u548c\u7ed8\u56fe\u6837\u5f0f\uff0c\u8fd9\u4f1a\u63d0\u9ad8\u56fe\u8868\u7684\u53ef\u8bfb\u6027\u548c\u7f8e\u89c2\u6027\u3002 \u5373\u4f7f\u4e0d\u4f7f\u7528seaborn\u7684API\uff0c\u4e5f\u53ef\u4ee5\u5bfc\u5165seaborn\u6765\u4e3a\u901a\u7528matplotlib\u56fe\u8868\u63d0\u4f9b\u66f4\u597d\u7684\u89c6\u89c9\u7f8e\u89c2\u5ea6\u3002 import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns","title":"\u4f7f\u7528pandas\u548cseaborn\u7ed8\u56fe"},{"location":"python/DataAnalysis/ch06/#_5","text":"Series\u548cDataFrame\u90fd\u6709\u4e00\u4e2a plot \u5c5e\u6027\uff0c\u7528\u4e8e\u7ed8\u5236\u57fa\u672c\u7684\u56fe\u5f62\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c plot() \u7ed8\u5236\u7684\u662f\u6298\u7ebf\u56fe\u3002 Series\u7684 plot \u53c2\u6570\uff1a ax: matplotlib\u5b50\u56fe\u5bf9\u8c61axes\uff0c\u5982\u679c\u6ca1\u6709\u4f20\u503c\uff0c\u5219\u4f7f\u7528\u5f53\u524d\u6d3b\u52a8\u7684\u5b50\u56fe\u9ed8\u8ba4\u4f7f\u7528gca() alpha: \u56fe\u7247\u4e0d\u900f\u660e\u5ea6\uff080\u52301\uff09 data: \u6570\u636e\u5e8f\u5217Series figsize: \u56fe\u50cf\u5c3a\u5bf8\uff0ctuple(\u5bbd\u5ea6\uff0c\u9ad8\u5ea6)\uff0c\u6ce8\u610f\u8fd9\u91cc\u7684\u5355\u4f4d\u662f\u82f1\u5bf8 fontsize: \u8bbe\u7f6e\u523b\u5ea6\u6807\u7b7e\uff08xticks, yticks\uff09\u7684\u5927\u5c0f grid: \u7f51\u683c\u7ebf\uff08\u9ed8\u8ba4\u662f\u6253\u5f00\u7684\uff09 kind: \u56fe\u7c7b\u578b\uff1a\u6298\u7ebf\u56fe\uff0c\u67f1\u5f62\u56fe\uff0c\u6a2a\u5411\u67f1\u5f62\u56fe\uff0c\u76f4\u65b9\u56fe\uff0c\u7bb1\u7ebf\u56fe\uff0c\u5bc6\u5ea6\u56fe\uff0c\u9762\u79ef\u56fe\uff0c\u997c\u56fe label: \u5217\u7684\u522b\u540d\uff0c\u4f5c\u7528\u5728\u56fe\u4f8b\u4e0a legend: \u56fe\u4f8b loglog: x,y\u8f74\u90fd\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 logx: x\u8f74\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 logy: y\u8f74\u4f7f\u7528\u5bf9\u6570\u523b\u5ea6 mark_right: \u53cc y \u8f74\u65f6\uff0c\u5728\u56fe\u4f8b\u4e2d\u7684\u5217\u6807\u7b7e\u65c1\u589e\u52a0\u663e\u793a (right) \u6807\u8bc6 position: \u67f1\u5f62\u56fe\u7684\u67f1\u5b50\u7684\u4f4d\u7f6e\u8bbe\u7f6e rot: \u6539\u53d8\u523b\u5ea6\u6807\u7b7e\uff08xticks, yticks\uff09\u7684\u65cb\u8f6c\u5ea6\uff080\u5230360\uff09 secondary_y: \u53cc y \u8f74\uff0c\u5728\u53f3\u8fb9\u7684\u7b2c\u4e8c\u4e2a y \u8f74 style: \u7ebf\u7684\u6837\u5f0f\uff0c\u6bd4\u5982'ko--' table: \u5c06\u6570\u636e\u4ee5\u8868\u683c\u7684\u5f62\u5f0f\u5c55\u793a\u51fa\u6765 title: \u6807\u9898 use_index: \u662f\u5426\u4f7f\u7528\u7d22\u5f15\u4f5c\u4e3ax\u523b\u5ea6\u6807\u7b7e xerr: \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe xlim: \u6a2a\u8f74\u5750\u6807\u523b\u5ea6\u7684\u53d6\u503c\u8303\u56f4 xticks: x\u8f74\u523b\u5ea6\u6807\u7b7e yerr: \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe ylim: \u7eb5\u8f74\u5750\u6807\u523b\u5ea6\u7684\u53d6\u503c\u8303\u56f4 yticks: y\u8f74\u523b\u5ea6\u6807\u7b7e **kwds: matplotlib plot\u65b9\u6cd5\u7684\u5176\u4ed6\u53c2\u6570 DataFrame\u7684 plot \u53c2\u6570\uff1a x : \u6307\u6570\u636e\u6846\u5217\u7684\u6807\u7b7e\u6216\u4f4d\u7f6e\u53c2\u6570 y : \u6307\u6570\u636e\u6846\u5217\u7684\u6807\u7b7e\u6216\u4f4d\u7f6e\u53c2\u6570 kind : 'line' : \u6298\u7ebf\u56fe 'bar' : \u6761\u5f62\u56fe 'barh' : \u6a2a\u5411\u6761\u5f62\u56fe 'hist' : \u67f1\u72b6\u56fe 'box' : \u7bb1\u7ebf\u56fe 'kde' : Kernel\u7684\u5bc6\u5ea6\u4f30\u8ba1\u56fe\uff0c\u4e3b\u8981\u5bf9\u67f1\u72b6\u56fe\u6dfb\u52a0Kernel \u6982\u7387\u5bc6\u5ea6\u7ebf 'density' : 'kde' 'area' : area plot 'pie' : \u997c\u56fe 'scatter' : \u6563\u70b9\u56fe \u9700\u8981\u4f20\u5165columns\u65b9\u5411\u7684\u7d22\u5f15 'hexbin' : hexbin plot ax : \u5b50\u56fe(axes, \u4e5f\u53ef\u4ee5\u7406\u89e3\u6210\u5750\u6807\u8f74) \u8981\u5728\u5176\u4e0a\u8fdb\u884c\u7ed8\u5236\u7684matplotlib subplot\u5bf9\u8c61\u3002\u5982\u679c\u6ca1\u6709\u8bbe\u7f6e\uff0c\u5219\u4f7f\u7528\u5f53\u524dmatplotlib subplot\u3002\u5176\u4e2d\uff0c\u53d8\u91cf\u548c\u51fd\u6570\u901a\u8fc7\u6539\u53d8figure\u548caxes\u4e2d\u7684\u5143\u7d20\uff08\u4f8b\u5982\uff1atitle,label,\u70b9\u548c\u7ebf\u7b49\u7b49\uff09\u4e00\u8d77\u63cf\u8ff0figure\u548caxes\uff0c\u4e5f\u5c31\u662f\u5728\u753b\u5e03\u4e0a\u7ed8\u56fe\u3002 subplots : \u5224\u65ad\u56fe\u7247\u4e2d\u662f\u5426\u6709\u5b50\u56fe sharex : \u5982\u679c\u6709\u5b50\u56fe\uff0c\u5b50\u56fe\u5171x\u8f74\u523b\u5ea6\uff0c\u6807\u7b7e sharey : \u5982\u679c\u6709\u5b50\u56fe\uff0c\u5b50\u56fe\u5171y\u8f74\u523b\u5ea6\uff0c\u6807\u7b7e layout : \u5b50\u56fe\u7684\u884c\u5217\u5e03\u5c40 figsize : \u56fe\u7247\u5c3a\u5bf8\u5927\u5c0f use_index : \u9ed8\u8ba4\u7528\u7d22\u5f15\u505ax\u8f74 title : \u56fe\u7247\u7684\u6807\u9898\u7528\u5b57\u7b26\u4e32 grid : \u56fe\u7247\u662f\u5426\u6709\u7f51\u683c legend : \u5b50\u56fe\u7684\u56fe\u4f8b\uff0c\u6dfb\u52a0\u4e00\u4e2asubplot\u56fe\u4f8b(\u9ed8\u8ba4\u4e3aTrue) style : \u5bf9\u6bcf\u5217\u6298\u7ebf\u56fe\u8bbe\u7f6e\u7ebf\u7684\u7c7b\u578b logx : \u8bbe\u7f6ex\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 logy : \u8bbe\u7f6ey\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 loglog : \u540c\u65f6\u8bbe\u7f6ex\uff0cy\u8f74\u523b\u5ea6\u662f\u5426\u53d6\u5bf9\u6570 xticks : \u8bbe\u7f6ex\u8f74\u523b\u5ea6\u503c\uff0c\u5e8f\u5217\u5f62\u5f0f\uff08\u6bd4\u5982\u5217\u8868\uff09 yticks : \u8bbe\u7f6ey\u8f74\u523b\u5ea6\uff0c\u5e8f\u5217\u5f62\u5f0f\uff08\u6bd4\u5982\u5217\u8868\uff09 xlim : \u8bbe\u7f6e\u5750\u6807\u8f74x\u7684\u8303\u56f4\uff0c\u5217\u8868\u6216\u5143\u7ec4\u5f62\u5f0f ylim : \u8bbe\u7f6e\u5750\u6807\u8f74y\u7684\u8303\u56f4\uff0c\u5217\u8868\u6216\u5143\u7ec4\u5f62\u5f0f rot : \u8bbe\u7f6e\u8f74\u6807\u7b7e\uff08\u8f74\u523b\u5ea6\uff09\u7684\u663e\u793a\u65cb\u8f6c\u5ea6\u6570 fontsize : \u8bbe\u7f6e\u8f74\u523b\u5ea6\u7684\u5b57\u4f53\u5927\u5c0f colormap : \u8bbe\u7f6e\u56fe\u7684\u533a\u57df\u989c\u8272 colorbar : \u56fe\u7247\u67f1\u5b50 position : Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center) layout : \u5e03\u5c40(rows, columns) for the layout of the plot table : \u5982\u679c\u4e3a\u6b63\uff0c\u5219\u9009\u62e9DataFrame\u7c7b\u578b\u7684\u6570\u636e\u5e76\u4e14\u8f6c\u6362\u5339\u914dmatplotlib\u7684\u5e03\u5c40 yerr : \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe xerr : \u5e26\u8bef\u5dee\u7ebf\u7684\u67f1\u5f62\u56fe stacked : \u751f\u6210\u5806\u79ef\u67f1\u72b6\u56fe sort_columns : \u4ee5\u5b57\u6bcd\u8868\u987a\u5e8f\u7ed8\u5236\u5404\u5217\uff0c\u9ed8\u8ba4\u4f7f\u7528\u524d\u5217\u987a\u5e8f secondary_y : \u8bbe\u7f6e\u7b2c\u4e8c\u4e2ay\u8f74\uff08\u53f3y\u8f74\uff09 mark_right : When using a secondary_y axis, automatically mark the column labels with \u201c(right)\u201d in the legend kwds : Options to pass to matplotlib plotting method Series data1 = np.random.randn(10).cumsum(0) s1 = pd.Series( data1, index=np.arange(0, 100, 10), ) print(s1) fig, axes = plt.subplots(3, 1) # 3\u4e2a\u5b50\u56fe s1.plot.bar(ax=axes[0], color='k', alpha=0.7) # \u6761\u5f62\u56fe(\u5b50\u56fe0)\uff0ccolor='k\u2019(\u67f1\u5b50\u7684\u989c\u8272\u8bbe\u7f6e\u4e3a\u9ed1\u8272)\uff0calpha=0.7(\u56fe\u50cf\u7684\u586b\u5145\u8272\u8bbe\u7f6e\u4e3a\u90e8\u5206\u900f\u660e) s1.plot.barh(ax=axes[1], color='k', alpha=0.7) # \u6a2a\u5411\u6761\u5f62\u56fe(\u5b50\u56fe1) s1.value_counts().plot.pie(ax=axes[2]) # \u901a\u8fc7value_counts()\u5bf9Series\u503c\u9891\u7387\u8fdb\u884c\u53ef\u89c6\u5316 plt.show() DataFrame data2 = np.random.randn(10, 4).cumsum(0) df1 = pd.DataFrame( data2, columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'), index=np.arange(0, 100, 10) ) print(df1) fig, axes = plt.subplots(2, 1) # 2\u4e2a\u5b50\u56fe df1.plot.kde(ax=axes[0], alpha=0.7, grid='True', title='KDE Figure', sharex=True) df1.plot.bar(ax=axes[1], grid='True', title='Line Figure', sharex=True, use_index=False, stacked=True) # \u56e0\u4e3a\u5171\u4eabx\u8f74\uff0c\u6240\u4ee5\u5728KDE\u5b50\u56fe\u4e2d\u6307\u5b9ause_index=False\u770b\u4e0d\u51fa\u6548\u679c\u3002 # DataFrame\u7684\u5217\u540d\u79f0\"Genus\"\u88ab\u7528\u4f5c\u4e86\u56fe\u4f8b\u6807\u9898 # stacked=True\u6765\u751f\u6210\u5806\u79ef\u67f1\u72b6\u56fe plt.show() \u5b9e\u4f8b\uff1a\u7ed8\u5236\u4e00\u4e2a\u5806\u79ef\u67f1\u72b6\u56fe\uff0c\u7528\u4e8e\u5c55\u793a\u6bcf\u4e2a\u6d3e\u5bf9\u5728\u6bcf\u5929\u7684\u6570\u636e\u70b9\u5360\u6bd4\u3002 \u4ea4\u53c9\u8868 \u662f\u4e00\u79cd\u5e38\u7528\u7684\u5206\u7c7b\u6c47\u603b\u8868\u683c\uff0c\u7528\u4e8e\u9891\u6570\u5206\u5e03\u7edf\u8ba1\uff0c\u4e3b\u8981\u4ef7\u503c\u5728\u4e8e\u63cf\u8ff0\u4e86\u53d8\u91cf\u95f4\u5173\u7cfb\u7684\u6df1\u523b\u542b\u4e49\u3002 \u867d\u7136\u4e24\u4e2a\uff08\u6216\u4ee5\u4e0a\uff09\u53d8\u91cf\u53ef\u4ee5\u662f\u5206\u7c7b\u7684\u6216\u6570\u91cf\u7684\uff0c\u4f46\u662f\u4ee5\u90fd\u662f\u5206\u7c7b\u7684\u60c5\u5f62\u6700\u4e3a\u5e38\u89c1\u3002 Pandas\u7684 crosstab() \u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u6784\u5efa\u4ea4\u53c9\u8868\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u53c2\u6570\u52a0\u4ee5\u4e2a\u6027\u5316\u7684\u8bbe\u7f6e\u3002\u5176\u4e2d\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u5c06\u6784\u6210\u4ea4\u53c9\u8868\u7684\u884c\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u5c06\u6784\u6210\u4ea4\u53c9\u8868\u7684\u5217\u3002 tips = pd.read_csv('../examples/tips.csv') print(tips) # total_bill tip smoker day time size # 0 16.99 1.01 No Sun Dinner 2 # 1 10.34 1.66 No Sun Dinner 3 # 2 21.01 3.50 No Sun Dinner 3 # 3 23.68 3.31 No Sun Dinner 2 # 4 24.59 3.61 No Sun Dinner 4 # .. ... ... ... ... ... ... # 239 29.03 5.92 No Sat Dinner 3 # 240 27.18 2.00 Yes Sat Dinner 2 # 241 22.67 2.00 Yes Sat Dinner 2 # 242 17.82 1.75 No Sat Dinner 2 # 243 18.78 3.00 No Thur Dinner 2 # [244 rows x 6 columns] party_counts = pd.crosstab(tips['day'], tips['size']) # \u5bf9\u539f\u59cb\u6570\u636e\u7684day\u548csize\u8fdb\u884c\u805a\u5408\uff0c\u5e76\u6784\u5efa\u4ea4\u53c9\u8868\uff0cday\u4f5c\u4e3a\u884c\uff0csize\u4f5c\u4e3a\u5217\u3002 print(party_counts) # size 1 2 3 4 5 6 # day # Fri 1 16 1 1 0 0 # Sat 2 53 18 13 1 0 # Sun 0 39 15 18 3 1 # Thur 1 48 4 5 1 3 # \u6ca1\u6709\u592a\u591a\u76841\u4eba\u548c6\u4eba\u6d3e\u5bf9\uff0c\u820d\u5f03\u8fd9\u4e9b\u6570\u636e party_counts = party_counts.loc[:, 2:5] print(party_counts) # size 2 3 4 5 # day # Fri 16 1 1 0 # Sat 53 18 13 1 # Sun 39 15 18 3 # Thur 48 4 5 1 # \u6807\u51c6\u5316\u81f3\u548c\u4e3a1\uff1a\u6cbf0\u8f74\uff08\u884c\uff09\u5bf9\u6bcf\u5217\u6c42\u548c\uff0c\u6bcf\u884c\u5404\u503c\u9664\u4ee5\u548c\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e00\u884c\u7684\u503c\u548c\u4e3a1\uff0c\u7136\u540e\u8fdb\u884c\u7ed8\u56fe party_pcts = party_counts.div(party_counts.sum(1), axis=0) print(party_pcts) # size 2 3 4 5 # day # Fri 0.888889 0.055556 0.055556 0.000000 # Sat 0.623529 0.211765 0.152941 0.011765 # Sun 0.520000 0.200000 0.240000 0.040000 # Thur 0.827586 0.068966 0.086207 0.017241 party_counts.plot.bar() plt.show() \u53ef\u4ee5\u770b\u5230\u672c\u6570\u636e\u96c6\u4e2d\u7684\u6d3e\u5bf9\u6570\u91cf\u5728\u5468\u672b\u4f1a\u589e\u52a0\u3002 \u5b9e\u4f8b\uff1a\u4f7f\u7528seaborn\u8fdb\u884c\u6309\u661f\u671f\u65e5\u671f\u8ba1\u7b97\u5c0f\u8d39\u767e\u5206\u6bd4\u3002 Seaborn\u8981\u6c42\u6570\u636e\u7684\u8f93\u5165\u7c7b\u578b\u4e3apandas\u7684Dataframe\u6216Numpy\u6570\u7ec4\u3002 tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) print(tips) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 # .. ... ... ... ... ... ... ... # 239 29.03 5.92 No Sat Dinner 3 0.256166 # 240 27.18 2.00 Yes Sat Dinner 2 0.079428 # 241 22.67 2.00 Yes Sat Dinner 2 0.096759 # 242 17.82 1.75 No Sat Dinner 2 0.108899 # 243 18.78 3.00 No Thur Dinner 2 0.190114 # [244 rows x 7 columns] # barplot: \u5c06\u70b9\u4f30\u8ba1\u548c\u7f6e\u4fe1\u533a\u95f4\u663e\u793a\u4e3a\u77e9\u5f62\u6761\u3002\u6761\u5f62\u56fe\u8868\u793a\u5177\u6709\u6bcf\u4e2a\u77e9\u5f62\u7684\u9ad8\u5ea6\u7684\u6570\u503c\u53d8\u91cf\u7684\u96c6\u4e2d\u8d8b\u52bf\u7684\u4f30\u8ba1\uff0c\u5e76\u4e14\u4f7f\u7528\u8bef\u5dee\u6761\u63d0\u4f9b\u56f4\u7ed5\u8be5\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u4e00\u4e9b\u6307\u793a # \u67f1\u5b50\u7684\u503c\u662ftip_pct\u7684\u5e73\u5747\u503c # \u67f1\u5b50\u4e0a\u753b\u51fa\u7684\u9ed1\u7ebf\u4ee3\u8868\u7684\u662f95%\u7684\u7f6e\u4fe1\u533a\u95f4\uff08\u7f6e\u4fe1\u533a\u95f4\u53ef\u4ee5\u901a\u8fc7\u53ef\u9009\u53c2\u6570\u8fdb\u884c\u8bbe\u7f6e\uff09 # hue\u9009\u9879\uff0c\u5141\u8bb8\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u989d\u5916\u7684\u5206\u7c7b\u503c\u5c06\u6570\u636e\u5206\u79bb # \u5e26\u53c2\u6570hue='time'\u65f6\uff0c\u56db\u4e2a\u4e0d\u540c\u989c\u8272\u7684\u67f1\u5b50\uff0c\u6bcf\u4e2a\u67f1\u5b50\u4e0a\u6709\u7f6e\u4fe1\u533a\u95f4\u7684\u9ed1\u7ebf\uff0c\u523b\u5ea60.00~0.30\uff0c\u6b65\u957f0.05 # \u4e0d\u5e26\u53c2\u6570hue='time'\u65f6\uff0c\u4e24\u4e2a\u4e0d\u540c\u989c\u8272\u7684\u67f1\u5b50\uff0c\u5206\u522b\u4ee3\u8868Dinner\u548cLunch\uff0c\u4e0d\u662f\u6bcf\u4e2a\u67f1\u5b50\u4e0a\u90fd\u6709\u7f6e\u4fe1\u533a\u95f4\u7684\u9ed1\u7ebf\uff0c\u523b\u5ea60.00~0.30\uff0c\u6b65\u957f0.05 sns.barplot(x='tip_pct', y='day', data=tips, hue='time', orient='h') # \u6839\u636e\u661f\u671f\u65e5\u671f\u548c\u65f6\u95f4\u8ba1\u7b97\u7684\u5c0f\u8d39\u767e\u5206\u6bd4 # sns.barplot(x='tip_pct', y='day', data=tips, orient='h') sns.set(style=\"darkgrid\", palette=\"deep\") # style=\"whitegrid\" plt.show()","title":"\u6298\u7ebf\u56fe"},{"location":"python/DataAnalysis/ch06/#_6","text":"\u76f4\u65b9\u56fe\u662f\u4e00\u79cd\u6761\u5f62\u56fe\uff0c\u7528\u4e8e\u7ed9\u51fa\u503c\u9891\u7387\u7684\u79bb\u6563\u663e\u793a\u3002\u6570\u636e\u70b9\u88ab\u5206\u6210\u79bb\u6563\u7684\uff0c\u5747\u5300\u95f4\u9694\u7684\u7bb1\uff0c\u5e76\u4e14\u7ed8\u5236\u6bcf\u4e2a\u7bb1\u4e2d\u6570\u636e\u70b9\u7684\u6570\u91cf\u3002 tips['tip_pct'].plot.hist(bins=50) # \u5c0f\u8d39\u767e\u5206\u6bd4\u7684\u76f4\u65b9\u56fe plt.show() \u5bc6\u5ea6\u56fe\u662f\u4e00\u79cd\u4e0e\u76f4\u65b9\u56fe\u76f8\u5173\u7684\u56fe\u8868\u7c7b\u578b\uff0c\u5b83\u901a\u8fc7\u8ba1\u7b97\u53ef\u80fd\u4ea7\u751f\u89c2\u6d4b\u6570\u636e\u7684\u8fde\u7eed\u6982\u7387\u5206\u5e03\u4f30\u8ba1\u800c\u4ea7\u751f\u3002 \u901a\u5e38\u7684\u505a\u6cd5\u662f\u5c06\u8fd9\u79cd\u5206\u5e03\u8fd1\u4f3c\u4e3a\u201c\u5185\u6838\u201d\u7684\u6df7\u5408\uff0c\u4e5f\u5c31\u662f\u50cf\u6b63\u6001\u5206\u5e03\u90a3\u6837\u7b80\u5355\u7684\u5206\u5e03\u3002 \u56e0\u6b64\uff0c\u5bc6\u5ea6\u56fe\u4e5f\u88ab\u79f0\u4e3a\u5185\u6838\u5bc6\u5ea6\u4f30\u8ba1\u56fe\uff08KDE\uff09\u3002 tips['tip_pct'].plot.density() # \u5c0f\u8d39\u767e\u5206\u6bd4\u5bc6\u5ea6\u56fe plt.show() \u7ed8\u5236\u76f4\u65b9\u56fe\u548c\u8fde\u7eed\u5bc6\u5ea6\u4f30\u8ba1 sns.displot() \u3002 sns.distplot(tips['tip_pct'], bins=100, color='k') plt.show() # FutureWarning: `distplot` is a deprecated function and will be removed in a future version. # Please adapt your code to use either `displot` (a figure-level function with similar flexibility) # or `histplot` (an axes-level function for histograms).","title":"\u76f4\u65b9\u56fe\u548c\u5bc6\u5ea6\u56fe"},{"location":"python/DataAnalysis/ch06/#_7","text":"\u70b9\u56fe\u6216\u6563\u70b9\u56fe\u53ef\u4ee5\u7528\u4e8e\u68c0\u9a8c\u4e24\u4e2a\u4e00\u7ef4\u6570\u636e\u5e8f\u5217\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u5b9e\u4f8b\uff1a\u4ece statsmodels \u9879\u76ee\u4e2d\u8f7d\u5165\u4e86macrodata\u6570\u636e\u96c6\uff0c\u5e76\u9009\u62e9\u4e86\u4e00\u4e9b\u53d8\u91cf\uff0c\u4e4b\u540e\u8ba1\u7b97\u5bf9\u6570\u5dee\u3002 macro = pd.read_csv('../examples/macrodata.csv') print(macro.head(5)) # year quarter realgdp realcons ... unemp pop infl realint # 0 1959.0 1.0 2710.349 1707.4 ... 5.8 177.146 0.00 0.00 # 1 1959.0 2.0 2778.801 1733.7 ... 5.1 177.830 2.34 0.74 # 2 1959.0 3.0 2775.488 1751.8 ... 5.3 178.657 2.74 1.09 # 3 1959.0 4.0 2785.204 1753.7 ... 5.6 179.386 0.27 4.06 # 4 1960.0 1.0 2847.699 1770.5 ... 5.2 180.007 2.31 1.19 # [5 rows x 14 columns] data = macro[['cpi', 'm1', 'tbilrate', 'unemp']] print(data.head(5)) # cpi m1 tbilrate unemp # 0 28.98 139.7 2.82 5.8 # 1 29.15 141.7 3.08 5.1 # 2 29.35 140.5 3.82 5.3 # 3 29.37 140.0 4.33 5.6 # 4 29.54 139.6 3.50 5.2 trans_data = np.log(data).diff().dropna() print(trans_data[-5:]) # cpi m1 tbilrate unemp # 198 -0.007904 0.045361 -0.396881 0.105361 # 199 -0.021979 0.066753 -2.277267 0.139762 # 200 0.002340 0.010286 0.606136 0.160343 # 201 0.008419 0.037461 -0.200671 0.127339 # 202 0.008894 0.012202 -0.405465 0.042560 \u7528 seaborn \u7684 regplot \u65b9\u6cd5\u7ed8\u5236\u6563\u70b9\u56fe\uff0c\u5e76\u62df\u5408\u51fa\u4e00\u4e2a\u6761\u7ebf\u6027\u56de\u5f52\u7ebf\u3002( seaborn\u6587\u6863 ) sns.regplot('m1', 'unemp', data=trans_data) plt.title('Changes in log %s versus log %s ' % ('m1', 'unemp')) plt.show() \u5728\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u4e2d\uff0c\u80fd\u591f\u67e5\u770b\u4e00\u7ec4\u53d8\u91cf\u4e2d\u7684\u6240\u6709\u6563\u70b9\u56fe\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u8fd9\u88ab\u79f0\u4e3a\u6210\u5bf9\u56fe\u6216\u6563\u70b9\u56fe\u77e9\u9635\u3002 Seaborn\u6709\u4e00\u4e2a\u65b9\u4fbf\u7684 pairplot \u51fd\u6570\uff0c\u5b83\u652f\u6301\u5728\u5bf9\u89d2\u7ebf\u4e0a\u653e\u7f6e\u6bcf\u4e2a\u53d8\u91cf\u7684\u76f4\u65b9\u56fe\u6216\u5bc6\u5ea6\u4f30\u8ba1\u503c\u3002 plot_ksw \u53c2\u6570\u80fd\u591f\u5c06\u914d\u7f6e\u9009\u9879\u4f20\u9012\u7ed9\u975e\u5bf9\u89d2\u5143\u7d20\u4e0a\u7684\u5404\u4e2a\u7ed8\u56fe\u8c03\u7528\u3002 sns.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2}) plt.show()","title":"\u6563\u70b9\u56fe\u6216\u70b9\u56fe"},{"location":"python/DataAnalysis/ch06/#_8","text":"\u5982\u679c\u6570\u636e\u96c6\u6709\u989d\u5916\u7684\u5206\u7ec4\u7ef4\u5ea6\u600e\u4e48\u529e\uff1f\u4f7f\u7528\u5206\u9762\u7f51\u683c\u662f\u5229\u7528\u591a\u79cd\u5206\u7ec4\u53d8\u91cf\u5bf9\u6570\u636e\u8fdb\u884c\u53ef\u89c6\u5316\u7684\u65b9\u5f0f\u3002 seaborn\u62e5\u6709\u4e00\u4e2a\u6709\u6548\u7684\u5185\u5efa\u51fd\u6570 factorplot \uff0c\u5b83\u53ef\u4ee5\u7b80\u5316\u591a\u79cd\u5206\u9762\u7ed8\u56fe\u3002 sns.factorplot(x='day', y='tip_pct', hue='time', col='smoker', kind='bar', data=tips[tips.tip_pct < 1]) plt.show() # UserWarning: The `factorplot` function has been renamed to `catplot`. # The original name will be removed in a future release. Please update your code. # Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`. sns.catplot(x='day', y='tip_pct', hue='time', col='smoker', kind='box', data=tips[tips.tip_pct < 0.5]) plt.show()","title":"\u5206\u9762\u7f51\u683c\u548c\u5206\u7c7b\u6570\u636e"},{"location":"python/DataAnalysis/ch06/#python","text":"\u81ea2010\u5e74\u4ee5\u6765\uff0c\u5f88\u591a\u5f00\u53d1\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u521b\u5efaweb\u4ea4\u4e92\u5f0f\u56fe\u5f62\u4e0a\u3002 \u501f\u52a9\u50cf Bokeh \u548c Plotly \u8fd9\u6837\u7684\u5de5\u5177\uff0c\u5728web\u6d4f\u89c8\u5668\u4e2d\u521b\u5efa\u52a8\u6001\u7684\u3001\u4ea4\u4e92\u5f0f\u56fe\u50cf\u7684\u5de5\u4f5c\u73b0\u5728\u5df2\u7ecf\u53ef\u4ee5\u5b9e\u73b0\u3002 \u53ef\u89c6\u5316\u662f\u4e00\u4e2a\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df\u3002","title":"\u5176\u4ed6Python\u53ef\u89c6\u5316\u5de5\u5177"},{"location":"python/DataAnalysis/ch07/","text":"\u6570\u636e\u805a\u5408\u4e0e\u5206\u7ec4\u64cd\u4f5c GroupBy\u673a\u5236 import pandas as pd import numpy as np \u5206\u7ec4\u673a\u5236 \u5206\u7ec4\u64cd\u4f5c\u7b2c\u4e00\u6b65\uff0c\u6570\u636e\u5305\u542b\u5728pandas\u5bf9\u8c61\u4e2d\uff0c\u53ef\u4ee5\u662fSeries\u3001DataFrame\u6216\u5176\u4ed6\u6570\u636e\u7ed3\u6784\u3002\u4e4b\u540e\u6839\u636e\u63d0\u4f9b\u7684\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u5206\u79bb\u5230\u5404\u4e2a\u7ec4\u4e2d\u3002 \u5206\u7ec4\u952e\u53ef\u662f\u591a\u79cd\u5f62\u5f0f\u7684\uff0c\u5e76\u4e14\u952e\u4e0d\u4e00\u5b9a\u662f\u5b8c\u5168\u76f8\u540c\u7684\u7c7b\u578b(\u6ce8\u610f\u540e\u9762\u4ecb\u7ecd\u7684\u4e09\u4e2a\u65b9\u6cd5\u662f\u53ef\u4ee5\u4ea7\u751f\u7528\u4e8e\u5206\u9694\u5bf9\u8c61\u7684\u503c\u6570\u7ec4\u7684\u5feb\u6377\u65b9\u5f0f)\uff1a \u4e0e\u9700\u8981\u5206\u7ec4\u7684\u8f74\u5411\u957f\u5ea6\u4e00\u81f4\u7684\u503c\u5217\u8868\u6216\u503c\u6570\u7ec4\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cgroupby\u5728axis=0\u7684\u8f74\u5411\u4e0a\u5206\u7ec4\u3002 DataFrame\u7684\u5217\u540d\u7684\u503c\u3002 \u53ef\u4ee5\u5c06\u5206\u7ec4\u8f74\u5411\u4e0a\u7684\u503c\u548c\u5206\u7ec4\u540d\u79f0\u76f8\u5339\u914d\u7684\u5b57\u5178\u6216Series\u3002 \u53ef\u4ee5\u5728\u8f74\u7d22\u5f15\u6216\u7d22\u5f15\u4e2d\u7684\u5355\u4e2a\u6807\u7b7e\u4e0a\u8c03\u7528\u7684\u51fd\u6570\u3002 \u8bf7\u6ce8\u610f\uff0c\u5206\u7ec4\u952e\u4e2d\u7684\u4efb\u4f55\u7f3a\u5931\u503c\u5c06\u88ab\u6392\u9664\u5728\u7ed3\u679c\u4e4b\u5916\u3002 \u5206\u79bb\u64cd\u4f5c\u662f\u5728\u6570\u636e\u5bf9\u8c61\u7684\u7279\u5b9a\u8f74\u5411\u4e0a\u8fdb\u884c\u7684\u3002\u4f8b\u5982\uff0cDataFrame\u53ef\u4ee5\u5728\u5b83\u7684\u884c\u65b9\u5411\uff08axis=0\uff09\u6216\u5217\u65b9\u5411\uff08axis=1\uff09\u8fdb\u884c\u5206\u7ec4\u3002 \u5206\u7ec4\u64cd\u4f5c\u540e\uff0c\u4e00\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u5e94\u7528\u5230\u5404\u4e2a\u7ec4\u4e2d\uff0c\u4ea7\u751f\u65b0\u7684\u503c\u3002\u6700\u7ec8\uff0c\u6240\u6709\u51fd\u6570\u7684\u5e94\u7528\u7ed3\u679c\u4f1a\u8054\u5408\u4e3a\u4e00\u4e2a\u7ed3\u679c\u5bf9\u8c61\u3002 df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) \u6839\u636ekey1\u6807\u7b7e\u8ba1\u7b97data1\u5217\u7684\u5747\u503c\uff0c\u65b9\u6cd5\u4e00\uff0c\u8bbf\u95ee data1 \u5e76\u4f7f\u7528 key1 \u5217\uff08\u5b83\u662f\u4e00\u4e2aSeries\uff09\u8c03\u7528 groupby \u65b9\u6cd5\uff1a grouped = df['data1'].groupby(df['key1']) print(grouped) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fdd2cb01430> grouped \u53d8\u91cf\u73b0\u5728\u662f\u4e00\u4e2a GroupBy \u5bf9\u8c61\uff0c\u5b83\u5b9e\u9645\u4e0a\u8fd8\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u8ba1\u7b97\uff0c\u62e5\u6709\u4e00\u4e9b\u5173\u4e8e\u5206\u7ec4\u952edf['key1']\u7684\u4e00\u4e9b\u4e2d\u95f4\u6570\u636e\u7684\u4fe1\u606f\u3002 \u4e0b\u9762\u5bf9 grouped \u5bf9\u8c61\u505a\u4e00\u4e9b\u64cd\u4f5c\uff1a result = grouped.mean() # \u8ba1\u7b97\u5e73\u5747\u503c print(result) # key1 # a 4.333333 # b 6.000000 # Name: data1, dtype: float64 grouped_means = df['data1'].groupby([df['key1'], df['key2']]).mean() print(grouped_means) # key1 key2 # a one 5.0 # two 3.0 # b one 5.0 # two 7.0 # Name: data1, dtype: float64 \u4e0a\u9762\u4f8b\u5b50\u4f7f\u7528\u4e86\u4e24\u4e2a\u952e\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u4e14\u7ed3\u679cSeries\u73b0\u5728\u62e5\u6709\u4e00\u4e2a\u5305\u542b\u552f\u4e00\u952e\u5bf9\u7684\u591a\u5c42\u7d22\u5f15\u3002 \u4e0b\u9762\u5bf9\u8ba1\u7b97\u7684\u5e73\u5747\u503c\uff08mean\uff09\u8fdb\u884c\u91cd\u5851\uff08unstack\uff09\u3002 print(grouped_means.unstack()) # key2 one two # key1 # a 5.0 3.0 # b 5.0 7.0 \u5206\u7ec4\u4fe1\u606f\u901a\u5e38\u5305\u542b\u5728\u540c\u4e00\u4e2aDataFrame\u4e2d\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u4f20\u9012\u5217\u540d\uff08\u65e0\u8bba\u90a3\u4e9b\u5217\u540d\u662f\u5b57\u7b26\u4e32\u3001\u6570\u5b57\u6216\u5176\u4ed6Python\u5bf9\u8c61\uff09\u4f5c\u4e3a\u5206\u7ec4\u952e\uff1a \u4e0b\u9762\u4f8b\u5b50\u4e2d df.groupby('key1').mean() \u7684\u7ed3\u679c\u91cc\u5e76\u6ca1\u6709 key2 \u5217\u3002\u8fd9\u662f\u56e0\u4e3a df['key2'] \u5e76\u4e0d\u662f\u6570\u503c\u6570\u636e\uff0c\u5373 df['key2'] \u662f\u4e00\u4e2a\u5197\u4f59\u5217\uff0c\u56e0\u6b64\u88ab\u6392\u9664\u5728\u7ed3\u679c\u4e4b\u5916\u3002 result = df.groupby('key1').mean() print(result) # data1 data2 # key1 # a 4.333333 5.333333 # b 6.000000 7.000000 result = df.groupby(['key1', 'key2']).mean() print(result) # data1 data2 # key1 key2 # a one 5.0 6.0 # two 3.0 4.0 # b one 5.0 6.0 # two 7.0 8.0 result = df.groupby(['key1', 'key2']).size() print(result) # key1 key # a one 2 # two 1 # b one 1 # two 1 # dtype: int64 \u904d\u5386\u5404\u5206\u7ec4 GroupBy \u5bf9\u8c61\u652f\u6301\u8fed\u4ee3\uff0c\u4f1a\u751f\u6210\u4e00\u4e2a\u5305\u542b\u7ec4\u540d\u548c\u6570\u636e\u5757\u76842\u7ef4\u5143\u7ec4\u5e8f\u5217\u3002 df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) \u5355\u4e2a\u5206\u7ec4\u952e\u7684\u60c5\u51b5: for name, group in df.groupby('key1'): print(name) print(group) # a # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10 # b # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 \u591a\u4e2a\u5206\u7ec4\u952e\u7684\u60c5\u51b5: \u5143\u7ec4\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u662f\u952e\u503c\u7684\u5143\u7ec4\u3002 for (k1, k2), group in df.groupby(['key1', 'key2']): print((k1, k2)) print(group) # ('a', 'one') # key1 key2 data1 data2 # 0 a one 1 2 # 4 a one 9 10 # ('a', 'two') # key1 key2 data1 data2 # 1 a two 3 4 # ('b', 'one') # key1 key2 data1 data2 # 2 b one 5 6 # ('b', 'two') # key1 key2 data1 data2 # 3 b two 7 8 result = dict(list(df.groupby('key1'))) print(result) # df.groupby('key1')\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5bf9\u8c61 # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f240fe058b0> # list(df.groupby('key1'))\u7684\u7ed3\u679c\u662f\u5305\u542bFrameData\u7684\u7ed3\u6784\u7684\u5217\u8868list: # [ # ('a', key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10), # ('b', key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8) # ] # dict(list(df.groupby('key1')))\u7684\u7ed3\u679c\u662f\u5305\u542bFrameData\u7684\u7ed3\u6784\u7684\u5b57\u5178dict # { # 'a': key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10, # 'b': key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 # } print(result['b']) # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c groupby \u5728 axis=0 \u7684\u8f74\u5411\u4e0a\u5206\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u5728\u5176\u4ed6\u4efb\u610f\u8f74\u5411\u4e0a\u8fdb\u884c\u5206\u7ec4\u3002 print(df.dtypes) # key1 object # key2 object # data1 int64 # data2 int64 # dtype: object grouped = df.groupby(df.dtypes, axis=1) print(grouped) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f4f6636df70> print(list(grouped)) # [ # (dtype('int64'), data1 data2 # 0 1 2 # 1 3 4 # 2 5 6 # 3 7 8 # 4 9 10), # (dtype('O'), key1 key2 # 0 a one # 1 a two # 2 b one # 3 b two # 4 a one) # ] \u6253\u5370\u5404\u5206\u7ec4\u5982\u4e0b\uff1a for dtype, group in grouped: print(dtype) print(group) # int64 # data1 data2 # 0 1 2 # 1 3 4 # 2 5 6 # 3 7 8 # 4 9 10 # object # key1 key2 # 0 a one # 1 a two # 2 b one # 3 b two # 4 a one \u9009\u62e9\u4e00\u5217\u6216\u6240\u6709\u5217\u7684\u5b50\u96c6 \u5bf9\u4e8e\u4eceDataFrame\u521b\u5efa\u7684 GroupBy \u5bf9\u8c61\uff0c\u7528\u5217\u540d\u79f0\u6216\u5217\u540d\u79f0\u6570\u7ec4\u8fdb\u884c\u7d22\u5f15\u65f6\uff0c\u4f1a\u4ea7\u751f\u7528\u4e8e\u805a\u5408\u7684\u5217\u5b50\u96c6\u7684\u6548\u679c\u3002 \u5982\u679c\u4f20\u9012\u7684\u662f\u5217\u8868\u6216\u6570\u7ec4\uff0c\u5219\u6b64\u7d22\u5f15\u64cd\u4f5c\u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u5206\u7ec4\u7684DataFrame\uff1b\u5982\u679c\u53ea\u6709\u5355\u4e2a\u5217\u540d\u4f5c\u4e3a\u6807\u91cf\u4f20\u9012\uff0c\u5219\u4e3a\u5206\u7ec4\u7684Series\uff1b \u5bf9\u6bd4\u4e0b\u97624\u53e5\uff1a result = df.groupby('key1')['data1'] # \u5355\u4e2a\u5217\u540d print(result) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fa988609040> for key, data in result: print(key) print(data) result = df['data1'].groupby(df['key1']) # \u5355\u4e2a\u5217\u540d print(result) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fa988609910> for key, data in result: print(key) print(data) # a # 0 1 # 1 3 # 4 9 # Name: data1, dtype: int64 # b # 2 5 # 3 7 # Name: data1, dtype: int64 result = df.groupby('key1')[['data1']] # \u5217\u8868\u6216\u6570\u7ec4 print(result) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f32666176a0> for key, data in result: print(key) print(data) # a # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10 # b # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 result = df[['data1']].groupby(df['key1']) # \u5217\u8868\u6216\u6570\u7ec4 print(result) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f32666171f0> for key, data in result: print(key) print(data) # a # data1 # 0 1 # 1 3 # 4 9 # b # data1 # 2 5 # 3 7 \u4f7f\u7528\u5b57\u5178\u548cSeries\u5206\u7ec4 \u5206\u7ec4\u4fe1\u606f\u53ef\u80fd\u4f1a\u4ee5\u975e\u6570\u7ec4\u5f62\u5f0f\u5b58\u5728\u3002 \u751f\u6210\u4e00\u4e2a\u793a\u4f8bDataFrame\u3002 people = pd.DataFrame( [[1, 3, 5, 7, 9], [0, 2, 4, 6, 8], [0, 2, 4, 6, 8], [1, 3, 5, 7, 9], [1, 2, 3, 4, 5]], columns=['a', 'b', 'c', 'd', 'e'], index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'] ) \u6dfb\u52a0\u4e00\u4e9bNA\u503c\u3002 people.iloc[2:3, [1, 2]] = np.nan print(people) # a b c d e # Joe 1 3.0 5.0 7 9 # Steve 0 2.0 4.0 6 8 # Wes 0 NaN NaN 6 8 # Jim 1 3.0 5.0 7 9 # Travis 1 2.0 3.0 4 5 \u5047\u8bbe\u6709\u5982\u4e0b\u5404\u5217\u7684\u5206\u7ec4\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u4e14\u60f3\u628a\u5404\u5217\u6309\u7ec4\u7d2f\u52a0\u3002 mapping = { 'a': 'red', 'b': 'red', 'c': 'blue', 'd': 'blue', 'e': 'red', 'f': 'orange' # \u6ce8\u610f\uff1a\u5065f\u867d\u7136\u6ca1\u6709\u88ab\u7528\u5230\uff0c\u4f46\u4e0d\u5f71\u54cd\u5728\u8fd9\u91cc\u5b9a\u4e49\u3002 } \u628a mapping \u8fd9\u4e2a\u5b57\u5178\u4f20\u7ed9 groupby() \u3002 by_column = people.groupby(mapping, axis=1) print(by_column.sum()) # blue red # Joe 12.0 13.0 # Steve 10.0 10.0 # Wes 6.0 8.0 # Jim 12.0 13.0 # Travis 7.0 8.0 Series\u4e5f\u6709\u76f8\u540c\u7684\u529f\u80fd\uff0c\u53ef\u4ee5\u89c6\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u6620\u5c04\u3002 map_services = pd.Series(mapping) print(map_services) # a red # b red # c blue # d blue # e red # f orange # dtype: object result = people.groupby(map_services, axis=1).count() print(result) # blue red # Joe 2 3 # Steve 2 3 # Wes 1 2 # Jim 2 3 # Travis 2 3 \u4f7f\u7528\u51fd\u6570\u5206\u7ec4 \u4e0e\u4f7f\u7528\u5b57\u5178\u6216Series\u5206\u7ec4\u76f8\u6bd4\uff0c\u4f7f\u7528Python\u51fd\u6570\u662f\u5b9a\u4e49\u5206\u7ec4\u5173\u7cfb\u7684\u4e00\u79cd\u66f4\u4e3a\u901a\u7528\u7684\u65b9\u5f0f\u3002 \u4f5c\u4e3a\u5206\u7ec4\u952e\u4f20\u9012\u7684\u51fd\u6570\u5c06\u4f1a\u6309\u7167\u6bcf\u4e2a\u7d22\u5f15\u503c\u8c03\u7528\u4e00\u6b21\uff0c\u540c\u65f6\u8fd4\u56de\u503c\u4f1a\u88ab\u7528\u4f5c\u5206\u7ec4\u540d\u79f0\u3002\u6ce8\u610f\uff1a\u51fd\u6570\u662f\u4f5c\u7528\u5728\u7d22\u5f15\u4e0a\u3002 result = people.groupby(len).sum() # \u4eba\u7684\u540d\u5b57\u662f\u7d22\u5f15\u503c\uff0c\u6839\u636e\u540d\u5b57\u7684\u957f\u5ea6\u6765\u8fdb\u884c\u5206\u7ec4 print(result) # a b c d e # 3 2 6.0 10.0 20 26 # 5 0 2.0 4.0 6 8 # 6 1 2.0 3.0 4 5 \u53ef\u4ee5\u5c06\u51fd\u6570\u4e0e\u6570\u7ec4\u3001\u5b57\u5178\u6216Series\u8fdb\u884c\u6df7\u5408\uff0c\u6240\u6709\u7684\u5bf9\u8c61\u90fd\u4f1a\u5728\u5185\u90e8\u8f6c\u6362\u4e3a\u6570\u7ec4\u3002 key_list = ['one', 'one', 'one', 'two', 'two'] result = people.groupby([len, key_list]).min() print(result) # a b c d e # 3 one 0 3.0 5.0 6 8 # two 1 3.0 5.0 7 9 # 5 one 0 2.0 4.0 6 8 # 6 two 1 2.0 3.0 4 5 \u6839\u636e\u7d22\u5f15\u5c42\u7ea7\u5206\u7ec4 \u6839\u636e\u5c42\u7ea7\u5206\u7ec4\u65f6\uff0c\u5c06\u5c42\u7ea7\u6570\u503c\u6216\u5c42\u7ea7\u540d\u79f0\u4f20\u9012\u7ed9 level \u5173\u952e\u5b57\u3002 columns = pd.MultiIndex.from_arrays( [['US', 'US', 'US', 'JP', 'JP'], [1, 3, 5, 1, 3]], names=['cty', 'tenor'] ) hier_df = pd.DataFrame( [[1, 3, 5, 7, 9], [0, 2, 4, 6, 8], [1, 3, 5, 7, 9], [1, 2, 3, 4, 5]], columns=columns ) print(hier_df) # cty US JP # tenor 1 3 5 1 3 # 0 1 3 5 7 9 # 1 0 2 4 6 8 # 2 1 3 5 7 9 # 3 1 2 3 4 5 result = hier_df.groupby(level='cty', axis=1).count() print(result) # cty JP US # 0 2 3 # 1 2 3 # 2 2 3 # 3 2 3 \u6570\u636e\u805a\u5408 \u805a\u5408\u662f\u6307\u6240\u6709\u6839\u636e\u6570\u7ec4\u4ea7\u751f\u6807\u91cf\u503c\u7684\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\uff0c\u6bd4\u5982\uff1a mean \u3001 count \u3001 min \u548c sum \u7b49\u4e00\u4e9b\u805a\u5408\u64cd\u4f5c\u3002 import pandas as pd import numpy as np \u9884\u5907\u77e5\u8bc6\uff1a \u5206\u4f4d\u6570\uff08Quantile\uff09\uff0c\u4e5f\u79f0\u5206\u4f4d\u70b9\uff0c\u662f\u6307\u5c06\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\u7684\u6982\u7387\u5206\u5e03\u8303\u56f4\u5206\u4e3a\u51e0\u4e2a\u7b49\u4efd\u7684\u6570\u503c\u70b9\uff0c\u5206\u6790\u5176\u6570\u636e\u53d8\u91cf\u7684\u8d8b\u52bf\u3002 \u5e38\u7528\u7684\u5206\u4f4d\u6570\u6709 \u4e2d\u4f4d\u6570\u3001\u56db\u5206\u4f4d\u6570\u3001\u767e\u5206\u4f4d\u6570\u7b49\u3002 \u4e2d\u4f4d\u6570\uff08Medians\uff09\u662f\u4e00\u4e2a\u7edf\u8ba1\u5b66\u7684\u4e13\u6709\u540d\u8bcd\uff0c\u4ee3\u8868\u4e00\u4e2a\u6837\u672c\u3001\u79cd\u7fa4\u6216\u6982\u7387\u5206\u5e03\u4e2d\u7684\u4e00\u4e2a\u6570\u503c\uff0c\u53ef\u4ee5\u5c06\u6570\u503c\u96c6\u5408\u5212\u5206\u4e3a\u76f8\u7b49\u7684\u4e24\u90e8\u5206\u3002 \u5229\u7528pandas\u5e93\u8ba1\u7b97 data = [6, 47, 49, 15, 42, 41, 7, 39, 43, 40, 36] \u7684\u5206\u4f4d\u6570\u3002 \u786e\u5b9a p \u5206\u4f4d\u6570\u4f4d\u7f6e\u7684\u4e24\u79cd\u65b9\u6cd5( n \u4e3a\u6570\u636e\u7684\u603b\u4e2a\u6570\uff0c p \u4e3a 0-1 \u4e4b\u95f4\u7684\u503c)\u3002\u5728python\u4e2d\u8ba1\u7b97\u5206\u4f4d\u6570\u4f4d\u7f6e\u7684\u65b9\u6848\u91c7\u7528 position=1+(n-1)*p \uff1a position = (n+1)*p position = 1 + (n-1)*p \u6848\u4f8b1 data = pd.Series(np.array([6, 47, 49, 15, 42, 41, 7, 39, 43, 40, 36])) print(\"\u6570\u636e\u683c\u5f0f\uff1a\") print(np.sort(data)) # \u5fc5\u987b\u8981\u6392\u5e8f print('Q1:', data.quantile(.25)) print('Q2:', data.quantile(.5)) print('Q3:', data.quantile(.75)) # \u6570\u636e\u683c\u5f0f\uff1a # [ 6 7 15 36 39 40 41 42 43 47 49] # Q1: 25.5 # Q2: 40.0 # Q3: 42.5 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # Q1\u7684p\u5206\u4f4d\u6570(0.25)\u4f4d\u7f6eposition = 1+(11-1)*0.25 = 3.5(\u53d6\u7b2c3\u4f4d) (p=0.25) Q1=15+(36-15)*0.5=25.5 (\u7b2c3\u30014\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.5) # Q2\u7684p\u5206\u4f4d\u6570(0.5)\u4f4d\u7f6eposition = 1+(11-1)*0.5 = 6 (p=0.5) Q2=40 # Q3\u7684p\u5206\u4f4d\u6570(0.75)\u4f4d\u7f6eposition = 1+(11-1)*0.75 = 9 (p=0.75) Q3=42+(43-42)*0.5=42.5 # IQR = Q3 - Q1 = 17 \u6848\u4f8b2 df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]), columns=['a', 'b']) print(\"\u6570\u636e\u539f\u59cb\u683c\u5f0f\uff1a\") print(df) print(\"\u8ba1\u7b97p=0.1\u65f6\uff0ca\u5217\u548cb\u5217\u7684\u5206\u4f4d\u6570\") print(df.quantile(.1)) # \u6570\u636e\u539f\u59cb\u683c\u5f0f\uff1a # a b # 0 1 1 # 1 2 10 # 2 3 100 # 3 4 100 # \u8ba1\u7b97p=0.1\u65f6\uff0ca\u5217\u548cb\u5217\u7684\u5206\u4f4d\u6570 # a 1.3 # b 3.7 # Name: 0.1, dtype: float64 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # \u8ba1\u7b97a\u5217 # position=1+(4-1)*0.1=1.3 (\u53d6\u7b2c1\u4f4d) # Q1=1+(2-1)*0.3=1.3 (\u7b2c1\u30012\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.3) # \u8ba1\u7b97b\u5217 # position=1+(4-1)*0.1=1.3 (\u53d6\u7b2c1\u4f4d) # Q1=1+(10-1)*0.3=3.7 (\u7b2c1\u30012\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.3) \u4f18\u5316\u7684 groupby \u65b9\u6cd5\uff1a count: \u5206\u7ec4\u4e2d\u975eNA\u503c\u7684\u6570\u91cf sum: \u975eNA\u503c\u7684\u7d2f\u52a0\u548c mean: \u975eNA\u503c\u7684\u5e73\u5747\u503c median: \u975eNA\u503c\u7684\u7b97\u672f\u4e2d\u4f4d\u6570 std, var: \u65e0\u504f\u7684(n-1\u5206\u6bcd)\u6807\u51c6\u5dee\u548c\u65b9\u5dee min, max: \u975eNA\u503c\u7684\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c prod: \u975eNA\u503c\u7684\u4e58\u79ef first, last: \u975eNA\u503c\u7684\u7b2c\u4e00\u4e2a\u3001\u6700\u540e\u4e00\u4e2a\u503c df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) print(df) # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 2 b one 5 6 # 3 b two 7 8 # 4 a one 9 10 grouped = df.groupby('key1') result = grouped['data1'] for i in result: print(i) # ('a', 0 1 # 1 3 # 4 9 # Name: data1, dtype: int64) # ('b', 2 5 # 3 7 # Name: data1, dtype: int64) result = grouped['data1'].quantile(0.9) # quantile\u5206\u4f4d\u6570 print(result) # key1 # a 7.8 # b 6.8 # Name: data1, dtype: float64 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # \u8ba1\u7b97a\u5217 # position=1+(3-1)*0.9=2.8 # Q1=3+(9-3)*0.8=7.8 # \u8ba1\u7b97b\u5217 # position=1+(2-1)*0.9=1.9 # Q1=5+(7-5)*0.9=6.8 \u4f7f\u7528\u81ea\u884c\u5236\u5b9a\u7684\u805a\u5408\uff0c\u5e76\u518d\u8c03\u7528\u5df2\u7ecf\u5728\u5206\u7ec4\u5bf9\u8c61\u4e0a\u5b9a\u4e49\u597d\u7684\u65b9\u6cd5\u3002 def peak_to_peak(arr): return arr.max() - arr.min() result = grouped.agg(peak_to_peak) print(result) # data1 data2 # key1 # a 8 8 # b 2 2 result = grouped.describe() print(result) # data1 ... data2 # count mean std min 25% ... min 25% 50% 75% max # key1 ... # a 3.0 4.333333 4.163332 1.0 2.0 ... 2.0 3.0 4.0 7.0 10.0 # b 2.0 6.000000 1.414214 5.0 5.5 ... 6.0 6.5 7.0 7.5 8.0 \u9010\u5217\u53ca\u591a\u51fd\u6570\u5e94\u7528 tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u6839\u636e\u5404\u5217\u540c\u65f6\u4f7f\u7528\u591a\u4e2a\u51fd\u6570\u8fdb\u884c\u805a\u5408 grouped = tips.groupby(['day', 'smoker']) # for i in grouped: # print(i) # (('Fri', 'No'), total_bill tip smoker day time size tip_pct # 91 22.49 3.50 No Fri Dinner 2 0.184308 # ...... # 223 15.98 3.00 No Fri Lunch 3 0.231125) # (('Fri', 'Yes'), total_bill tip smoker day time size tip_pct # 90 28.97 3.00 Yes Fri Dinner 2 0.115518 # ...... # 226 10.09 2.00 Yes Fri Lunch 2 0.247219) # ...... grouped_pct = grouped['tip_pct'] for i in grouped_pct: print(i) # (('Fri', 'No'), 91 0.184308 # 94 0.166667 # ...... # Name: tip_pct, dtype: float64) # (('Fri', 'Yes'), 90 0.115518 # 92 0.210526 # ...... # Name: tip_pct, dtype: float64) # ...... \u5c06\u51fd\u6570\u540d\u4ee5\u5b57\u7b26\u4e32\u5f62\u5f0f\u4f20\u9012\u3002 result = grouped_pct.agg('mean') print(result) # day smoker # Fri No 0.179740 # Yes 0.216293 # Sat No 0.190412 # Yes 0.179833 # Sun No 0.193617 # Yes 0.322021 # Thur No 0.193424 # Yes 0.198508 # Name: tip_pct, dtype: float64 \u5982\u679c\u4f20\u9012\u7684\u662f\u51fd\u6570\u6216\u8005\u51fd\u6570\u540d\u7684\u5217\u8868\uff0c\u4f1a\u5f97\u5230\u4e00\u4e2a\u5217\u540d\u662f\u8fd9\u4e9b\u51fd\u6570\u540d\u7684DataFrame\u3002 \u4e0b\u9762\u4f20\u9012\u4e86\u805a\u5408\u51fd\u6570\u7684\u5217\u8868\u7ed9agg\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u51fd\u6570\u4f1a\u5404\u81ea\u8fd0\u7528\u4e8e\u6570\u636e\u5206\u7ec4\u3002 result = grouped_pct.agg(['mean', 'std', peak_to_peak]) print(result) # mean std peak_to_peak # day smoker # Fri No 0.179740 0.039458 0.094263 # Yes 0.216293 0.077530 0.242219 # Sat No 0.190412 0.058626 0.352192 # Yes 0.179833 0.089496 0.446137 # Sun No 0.193617 0.060302 0.274897 # Yes 0.322021 0.538061 2.382107 # Thur No 0.193424 0.056065 0.284273 # Yes 0.198508 0.057170 0.219047 \u5982\u679c\u4f20\u9012\u7684\u662f (name, function) \u5143\u7ec4\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7ec4\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u5c06\u4f5c\u4e3aDataFrame\u7684\u5217\u540d\uff08\u53ef\u4ee5\u8ba4\u4e3a\u4e8c\u5143\u5143\u7ec4\u7684\u5217\u8868\u662f\u4e00\u79cd\u6709\u5e8f\u7684\u5bf9\u5e94\u5173\u7cfb\uff09\uff1a result = grouped_pct.agg([('foo', 'mean'), ('bar', np.std)]) # foo\u662fmean\u503c\u7684\u5217\u540d print(result) # foo bar # day smoker # Fri No 0.179740 0.039458 # Yes 0.216293 0.077530 # Sat No 0.190412 0.058626 # Yes 0.179833 0.089496 # Sun No 0.193617 0.060302 # Yes 0.322021 0.538061 # Thur No 0.193424 0.056065 # Yes 0.198508 0.057170 \u53ef\u4ee5\u6307\u5b9a\u5e94\u7528\u5230\u6240\u6709\u5217\u4e0a\u7684\u51fd\u6570\u5217\u8868\u6216\u6bcf\u4e00\u5217\u4e0a\u8981\u5e94\u7528\u7684\u4e0d\u540c\u51fd\u6570\u3002 \u4e0b\u9762\u4ea7\u751f\u7684DataFrame\u62e5\u6709\u5206\u5c42\u5217\uff0c\u4e0e\u5206\u522b\u805a\u5408\u6bcf\u4e00\u5217\uff0c\u518d\u4ee5\u5217\u540d\u4f5c\u4e3a keys \u53c2\u6570\u4f7f\u7528 concat \u5c06\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\u7684\u7ed3\u679c\u76f8\u540c\u3002 functions = ['count', 'mean', 'max'] result = grouped[['tip_pct', 'total_bill']].agg(functions) print(result) # tip_pct total_bill # count mean max count mean max # day smoker # Fri No 4 0.179740 0.231125 4 18.420000 22.75 # Yes 15 0.216293 0.357737 15 16.813333 40.17 # Sat No 45 0.190412 0.412409 45 19.661778 48.33 # Yes 42 0.179833 0.483092 42 21.276667 50.81 # Sun No 57 0.193617 0.338101 57 20.506667 48.17 # Yes 19 0.322021 2.452381 19 24.120000 45.35 # Thur No 45 0.193424 0.362976 45 17.113111 41.19 # Yes 17 0.198508 0.317965 17 19.190588 43.11 # \u628a['tip_pct', 'total_bill']\u6539\u6210[['tip_pct', 'total_bill']]\uff0c\u5c31\u53ef\u4ee5\u907f\u514d\u62a5\u9519 # FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead. # result = grouped['tip_pct', 'total_bill'].agg(functions) print(result['tip_pct']) # count mean max # day smoker # Fri No 4 0.179740 0.231125 # Yes 15 0.216293 0.357737 # Sat No 45 0.190412 0.412409 # Yes 42 0.179833 0.483092 # Sun No 57 0.193617 0.338101 # Yes 19 0.322021 2.452381 # Thur No 45 0.193424 0.362976 # Yes 17 0.198508 0.317965 \u4e5f\u540c\u6837\u53ef\u4ee5\u4f20\u9012\u5177\u6709\u81ea\u5b9a\u4e49\u540d\u79f0\u7684\u5143\u7ec4\u5217\u8868\uff1a ftuples = [('Durchschnitt', 'mean'), ('Abweichung', np.var)] result = grouped[['tip_pct', 'total_bill']].agg(ftuples) print(result) # tip_pct total_bill # Durchschnitt Abweichung Durchschnitt Abweichung # day smoker # Fri No 0.179740 0.001557 18.420000 25.596333 # Yes 0.216293 0.006011 16.813333 82.562438 # Sat No 0.190412 0.003437 19.661778 79.908965 # Yes 0.179833 0.008010 21.276667 101.387535 # Sun No 0.193617 0.003636 20.506667 66.099980 # Yes 0.322021 0.289509 24.120000 109.046044 # Thur No 0.193424 0.003143 17.113111 59.625081 # Yes 0.198508 0.003268 19.190588 69.808518 \u8981\u5c06\u4e0d\u540c\u7684\u51fd\u6570\u5e94\u7528\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4e0a\uff0c\u9700\u8981\u5c06\u542b\u6709\u5217\u540d\u4e0e\u51fd\u6570\u5bf9\u5e94\u5173\u7cfb\u7684\u5b57\u5178\u4f20\u9012\u7ed9 agg \uff1a result = grouped.agg({'tip': np.max, 'size': 'sum'}) print(result) # tip size # day smoker # Fri No 3.50 9 # Yes 4.73 31 # Sat No 9.00 115 # Yes 10.00 104 # Sun No 6.00 167 # Yes 6.50 49 # Thur No 6.70 112 # Yes 5.00 40 result = grouped.agg({'tip_pct': ['min', 'max', 'mean', 'std']}) print(result) # tip_pct # min max mean std # day smoker # Fri No 0.136861 0.231125 0.179740 0.039458 # Yes 0.115518 0.357737 0.216293 0.077530 # Sat No 0.060217 0.412409 0.190412 0.058626 # Yes 0.036955 0.483092 0.179833 0.089496 # Sun No 0.063204 0.338101 0.193617 0.060302 # Yes 0.070274 2.452381 0.322021 0.538061 # Thur No 0.078704 0.362976 0.193424 0.056065 # Yes 0.098918 0.317965 0.198508 0.057170 \u53ea\u6709\u591a\u4e2a\u51fd\u6570\u5e94\u7528\u4e8e\u81f3\u5c11\u4e00\u4e2a\u5217\u65f6\uff0cDataFrame\u624d\u5177\u6709\u5206\u5c42\u5217\u3002 \u8fd4\u56de\u4e0d\u542b\u884c\u7d22\u5f15\u7684\u805a\u5408\u6570\u636e \u5728\u524d\u9762\u6240\u6709\u7684\u4f8b\u5b50\u4e2d\uff0c\u805a\u5408\u6570\u636e\u8fd4\u56de\u65f6\u90fd\u662f\u5e26\u6709\u7d22\u5f15\u7684\uff0c\u6709\u65f6\u7d22\u5f15\u662f\u5206\u5c42\u7684\uff0c\u7531\u552f\u4e00\u7684\u5206\u7ec4\u952e\u8054\u5408\u5f62\u6210\u3002 \u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u60c5\u51b5\u4e0b\u90fd\u9700\u8981\u7d22\u5f15\uff0c\u6240\u4ee5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u53ef\u4ee5\u901a\u8fc7\u5411groupby\u4f20\u9012as_index=False\u6765\u7981\u7528\u5206\u7ec4\u952e\u4f5c\u4e3a\u7d22\u5f15\u7684\u884c\u4e3a\uff1a result = tips.groupby(['day', 'smoker'], as_index=False).mean() print(result) # day smoker total_bill tip size tip_pct # 0 Fri No 18.420000 2.812500 2.250000 0.179740 # 1 Fri Yes 16.813333 2.714000 2.066667 0.216293 # 2 Sat No 19.661778 3.102889 2.555556 0.190412 # 3 Sat Yes 21.276667 2.875476 2.476190 0.179833 # 4 Sun No 20.506667 3.167895 2.929825 0.193617 # 5 Sun Yes 24.120000 3.516842 2.578947 0.322021 # 6 Thur No 17.113111 2.673778 2.488889 0.193424 # 7 Thur Yes 19.190588 3.030000 2.352941 0.198508 \u901a\u8fc7\u5728\u7ed3\u679c\u4e0a\u8c03\u7528reset_index\u4e5f\u53ef\u4ee5\u83b7\u5f97\u540c\u6837\u7684\u7ed3\u679c\u3002\u4f7f\u7528as_index=False\u53ef\u4ee5\u907f\u514d\u4e00\u4e9b\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u3002 result = tips.groupby(['day', 'smoker']).mean() print(result.reset_index()) # day smoker total_bill tip size tip_pct # 0 Fri No 18.420000 2.812500 2.250000 0.179740 # 1 Fri Yes 16.813333 2.714000 2.066667 0.216293 # 2 Sat No 19.661778 3.102889 2.555556 0.190412 # 3 Sat Yes 21.276667 2.875476 2.476190 0.179833 # 4 Sun No 20.506667 3.167895 2.929825 0.193617 # 5 Sun Yes 24.120000 3.516842 2.578947 0.322021 # 6 Thur No 17.113111 2.673778 2.488889 0.193424 # 7 Thur Yes 19.190588 3.030000 2.352941 0.198508 print(result) # total_bill tip size tip_pct # day smoker # Fri No 18.420000 2.812500 2.250000 0.179740 # Yes 16.813333 2.714000 2.066667 0.216293 # Sat No 19.661778 3.102889 2.555556 0.190412 # Yes 21.276667 2.875476 2.476190 0.179833 # Sun No 20.506667 3.167895 2.929825 0.193617 # Yes 24.120000 3.516842 2.578947 0.322021 # Thur No 17.113111 2.673778 2.488889 0.193424 # Yes 19.190588 3.030000 2.352941 0.198508 \u5e94\u7528\uff1a\u901a\u7528\u62c6\u5206-\u5e94\u7528-\u8054\u5408 import pandas as pd import numpy as np import statsmodels.api as sm GroupBy \u65b9\u6cd5\u6700\u5e38\u89c1\u7684\u76ee\u7684\u662f apply \uff08\u5e94\u7528\uff09\u3002 apply \u5c06\u5bf9\u8c61\u62c6\u5206\u6210\u591a\u5757\uff0c\u7136\u540e\u5728\u6bcf\u4e00\u5757\u4e0a\u8c03\u7528\u4f20\u9012\u7684\u51fd\u6570\uff0c\u4e4b\u540e\u5c1d\u8bd5\u5c06\u6bcf\u4e00\u5757\u62fc\u63a5\u5230\u4e00\u8d77\u3002 \u6839\u636e\u4e0b\u9762\u7684\u5c0f\u8d39\u6570\u636e\u96c6\uff0c\u6309\u7ec4\u9009\u51fa\u5c0f\u8d39\u767e\u5206\u6bd4\uff08tip-pct\uff09\u6700\u9ad8\u7684\u4e94\u7ec4\u3002 tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) \u6837\u672c\u6570\u636e print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u9996\u5148\uff0c\u5199\u4e00\u4e2a\u53ef\u4ee5\u5728\u7279\u5b9a\u5217\u4e2d\u9009\u51fa\u6700\u5927\u503c\u6240\u5728\u884c\u7684\u51fd\u6570\uff1a \u6dfb\u52a0\u4e86\u5347\u5e8f\uff0c\u7ed3\u679c\u8f93\u51fa\u6700\u540e5\u884c\uff08\u6700\u540e\u76845\u884c\u4e5f\u662f\u6700\u5927\u76845\u4e2a tip_tcp \u8bb0\u5f55\uff09\u3002 def top(df, n=5, column='tip_pct'): return df.sort_values(by=column, ascending=True)[-n:] result = top(tips, n=6) print(result) # \u7b49\u4ef7\u65b9\u5f0f\uff1a # result = tips.sort_values('tip_pct')[-6:] # print(result) # total_bill tip smoker day time size tip_pct # 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 \u5982\u679c\u6309\u7167 smoker \u8fdb\u884c\u5206\u7ec4\uff0c\u4e4b\u540e\u8c03\u7528 apply \uff0c\u4f1a\u5f97\u5230\u4ee5\u4e0b\u7ed3\u679c\uff1a top \u51fd\u6570\u5728DataFrame\u7684\u6bcf\u4e00\u884c\u5206\u7ec4\u4e0a\u88ab\u8c03\u7528\uff0c\u4e4b\u540e\u4f7f\u7528 pandas.concat \u5c06\u51fd\u6570\u7ed3\u679c\u7c98\u8d34\u5728\u4e00\u8d77\uff0c\u5e76\u4f7f\u7528\u5206\u7ec4\u540d\u4f5c\u4e3a\u5404\u7ec4\u7684\u6807\u7b7e\u3002 \u56e0\u6b64\u7ed3\u679c\u5305\u542b\u4e00\u4e2a\u5206\u5c42\u7d22\u5f15\uff0c\u8be5\u5206\u5c42\u7d22\u5f15\u7684\u5185\u90e8\u5c42\u7ea7\u5305\u542b\u539fDataFrame\u7684\u7d22\u5f15\u503c\u3002 result = tips.groupby('smoker').apply(top) print(result) # total_bill tip smoker day time size tip_pct # smoker # No 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # Yes 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 \u5982\u679c\u9664\u4e86\u5411 apply \u4f20\u9012\u51fd\u6570\uff0c\u8fd8\u4f20\u9012\u5176\u4ed6\u53c2\u6570\u6216\u5173\u952e\u5b57\u7684\u8bdd\uff0c\u4f60\u53ef\u4ee5\u628a\u8fd9\u4e9b\u653e\u5728\u51fd\u6570\u540e\u8fdb\u884c\u4f20\u9012\u3002 result = tips.groupby('smoker').apply(top, n=1, column='total_bill') print(result) # \u8fd92\u884c\u90fd\u662fsmoker\u662fyes\u548cno\u65f6\u6700\u5927total_bill\u503c\u6240\u5728\u884c\u3002 # total_bill tip smoker day time size tip_pct # smoker # No 212 48.33 9.0 No Sat Dinner 4 0.228833 # Yes 170 50.81 10.0 Yes Sat Dinner 3 0.245038 \u5728 GroupBy \u5bf9\u8c61\u4e0a\u8c03\u7528 describe \u65b9\u6cd5\u3002 result = tips.groupby('smoker')['tip_pct'].describe() print(result) # count mean std ... 50% 75% max # smoker ... # No 151.0 0.192237 0.057665 ... 0.184308 0.227015 0.412409 # Yes 93.0 0.218176 0.254295 ... 0.181818 0.242326 2.452381 # [2 rows x 8 columns] print(result.unstack('smoker')) # \u7c7b\u4f3c\u4e8e\u8f6c\u7f6e # smoker # count No 151.000000 # Yes 93.000000 # mean No 0.192237 # Yes 0.218176 # std No 0.057665 # Yes 0.254295 # min No 0.060217 # Yes 0.036955 # 25% No 0.158622 # Yes 0.119534 # 50% No 0.184308 # Yes 0.181818 # 75% No 0.227015 # Yes 0.242326 # max No 0.412409 # Yes 2.452381 # dtype: float64 \u5728 GroupBy \u5bf9\u8c61\u7684\u5185\u90e8\uff0c\u5f53\u8c03\u7528\u50cf describe \u8fd9\u6837\u7684\u65b9\u6cd5\u65f6\uff0c\u5b9e\u9645\u4e0a\u662f\u4ee5\u4e0b\u4ee3\u7801\u7684\u7b80\u5199\uff1a grouped = tips.groupby(['smoker']) f = lambda x: x.describe() result = grouped.apply(f) print(result) # total_bill tip size tip_pct # smoker # No count 151.000000 151.000000 151.000000 151.000000 # mean 19.188278 2.991854 2.668874 0.192237 # std 8.255582 1.377190 1.017984 0.057665 # min 7.250000 1.000000 1.000000 0.060217 # 25% 13.325000 2.000000 2.000000 0.158622 # 50% 17.590000 2.740000 2.000000 0.184308 # 75% 22.755000 3.505000 3.000000 0.227015 # max 48.330000 9.000000 6.000000 0.412409 # Yes count 93.000000 93.000000 93.000000 93.000000 # mean 20.756344 3.008710 2.408602 0.218176 # std 9.832154 1.401468 0.810751 0.254295 # min 3.070000 1.000000 1.000000 0.036955 # 25% 13.420000 2.000000 2.000000 0.119534 # 50% 17.920000 3.000000 2.000000 0.181818 # 75% 26.860000 3.680000 3.000000 0.242326 # max 50.810000 10.000000 5.000000 2.452381 \u538b\u7f29\u5206\u7ec4\u952e \u5728\u524d\u9762\u7684\u4f8b\u5b50\u4e2d\u6240\u5f97\u5230\u7684\u5bf9\u8c61\uff0c\u90fd\u5177\u6709\u5206\u7ec4\u952e\u6240\u5f62\u6210\u7684\u5206\u5c42\u7d22\u5f15\u4ee5\u53ca\u6bcf\u4e2a\u539f\u59cb\u5bf9\u8c61\u7684\u7d22\u5f15\u3002 \u4e5f\u53ef\u4ee5\u901a\u8fc7\u5411 groupby \u4f20\u9012 group_keys=False \u6765\u7981\u7528\u8fd9\u4e2a\u529f\u80fd\u3002 result = tips.groupby('smoker', group_keys=True).apply(top) print(result) # total_bill tip smoker day time size tip_pct # smoker # No 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # Yes 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 result = tips.groupby('smoker', group_keys=False).apply(top) print(result) # total_bill tip smoker day time size tip_pct # 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 \u5206\u4f4d\u6570\u4e0e\u6876\u5206\u6790 \u7b2c8\u7ae0\u4e2d\uff0cpandas\u6709\u4e00\u4e9b\u5de5\u5177\uff0c\u5c24\u5176\u662f cut \u548c qcut \uff0c\u7528\u4e8e\u5c06\u6570\u636e\u6309\u7167\u4f60\u9009\u62e9\u7684\u7bb1\u4f4d\u6216\u6837\u672c\u5206\u4f4d\u6570\u8fdb\u884c\u5206\u6876\u3002 \u4e0e groupby \u65b9\u6cd5\u4e00\u8d77\u4f7f\u7528\u8fd9\u4e9b\u51fd\u6570\u53ef\u4ee5\u5bf9\u6570\u636e\u96c6\u66f4\u65b9\u4fbf\u5730\u8fdb\u884c\u5206\u6876\u6216\u5206\u4f4d\u5206\u6790\u3002 \u590d\u4e60\uff1a\u673a\u68b0\u5b66\u4e60\u4e2d\u7684\u5206\u7bb1\u5904\u7406\u3002 \u5728\u673a\u68b0\u5b66\u4e60\u4e2d\u7ecf\u5e38\u4f1a\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7bb1\u5904\u7406\u7684\u64cd\u4f5c\uff0c \u4e5f\u5c31\u662f\u628a\u4e00\u6bb5\u8fde\u7eed\u7684\u503c\u5207\u5206\u6210\u82e5\u5e72\u6bb5\uff0c\u6bcf\u4e00\u6bb5\u7684\u503c\u770b\u6210\u4e00\u4e2a\u5206\u7c7b\u3002\u8fd9\u4e2a\u628a\u8fde\u7eed\u503c\u8f6c\u6362\u6210\u79bb\u6563\u503c\u7684\u8fc7\u7a0b\uff0c\u6211\u4eec\u53eb\u505a\u5206\u7bb1\u5904\u7406\u3002 \u6bd4\u5982\uff0c\u628a\u5e74\u9f84\u630915\u5c81\u5212\u5206\u6210\u4e00\u7ec4\uff0c0-15\u5c81\u53eb\u505a\u5c11\u5e74\uff0c16-30\u5c81\u53eb\u505a\u9752\u5e74\uff0c31-45\u5c81\u53eb\u505a\u58ee\u5e74\u3002\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u628a\u8fde\u7eed\u7684\u5e74\u9f84\u5206\u6210\u4e86\u4e09\u4e2a\u7c7b\u522b\uff0c\u201c\u5c11\u5e74\u201d\uff0c\u201c\u9752\u5e74\u201d\u548c\u201c\u58ee\u5e74\u201d\u5c31\u662f\u5404\u4e2a\u7c7b\u522b\u7684\u540d\u79f0\uff0c\u6216\u8005\u53eb\u505a\u6807\u7b7e\u3002 \u5728pandas\u4e2d\uff0c cut \u548c qcut \u51fd\u6570\u90fd\u53ef\u4ee5\u8fdb\u884c\u5206\u7bb1\u5904\u7406\u64cd\u4f5c\u3002 cut() \u6309\u7167\u53d8\u91cf\u7684\u503c\u5bf9\u53d8\u91cf\u8fdb\u884c\u5206\u5272\uff0c\u6bcf\u4e2a\u5206\u7ec4\u91cc\u6570\u636e\u7684\u4e2a\u6570\u5e76\u4e0d\u4e00\u6837\u3002 qcut() \u662f\u6309\u53d8\u91cf\u7684\u6570\u91cf\u6765\u5bf9\u53d8\u91cf\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u5c3d\u91cf\u4fdd\u8bc1\u6bcf\u4e2a\u5206\u7ec4\u91cc\u53d8\u91cf\u7684\u4e2a\u6570\u76f8\u540c\u3002 \u8003\u8651\u4e0b\u9762\u4e00\u4e2a\u7b80\u5355\u7684\u968f\u673a\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u4f7f\u7528 cut \u7684\u7b49\u957f\u6876\u5206\u7c7b\uff1a df = pd.DataFrame( { 'data1': np.random.randn(1000), 'data2': np.random.randn(1000) } ) quartiles = pd.cut(df.data1, 4) # \u6309\u7167data1\u503c\u7531\u5c0f\u5230\u5927\u7684\u987a\u5e8f\u5c06\u6570\u636e\u5206\u62104\u4efd\uff0c\u5e76\u4e14\u4f7f\u6bcf\u7ec4\u503c\u7684\u8303\u56f4\u5927\u81f4\u76f8\u7b49\u3002 print(quartiles[:10]) # 0 (-0.0743, 1.729] # 1 (-0.0743, 1.729] # 2 (-0.0743, 1.729] # 3 (-0.0743, 1.729] # 4 (-1.877, -0.0743] # 5 (-0.0743, 1.729] # 6 (-0.0743, 1.729] # 7 (-0.0743, 1.729] # 8 (-1.877, -0.0743] # 9 (-0.0743, 1.729] # Name: data1, dtype: category # Categories ( # 4, # interval[float64, right]): [ # (-3.687, -1.877] < (-1.877, -0.0743] < (-0.0743, 1.729] < (1.729, 3.531] # ] \u4e0a\u9762 cut \u8fd4\u56de\u7684 Categorical \u5bf9\u8c61\u53ef\u4ee5\u76f4\u63a5\u4f20\u9012\u7ed9 groupby \u3002\u5229\u7528\u5b83\u8ba1\u7b97\u51fa data2 \u5217\u7684\u4e00\u4e2a\u7edf\u8ba1\u503c\u96c6\u5408\uff0c\u5982\u4e0b\uff1a def get_stats(group): return { 'min': group.min(), 'max': group.max(), 'count': group.count(), 'mean': group.mean() } grouped = df.data2.groupby(quartiles) for i in grouped: print(i) result = grouped.apply(get_stats).unstack() print(result) # min max count mean # data1 # (-3.145, -1.424] -1.759377 2.484321 77.0 -0.127900 # (-1.424, 0.29] -3.142344 2.830654 524.0 -0.081931 # (0.29, 2.005] -3.557136 3.261635 376.0 0.015715 # (2.005, 3.719] -2.829458 1.766352 23.0 -0.198780 \u4f7f\u7528 qcut \uff0c\u6839\u636e\u6837\u672c\u5206\u4f4d\u6570\u8ba1\u7b97\u51fa\u7b49\u5927\u5c0f\u7684\u6876\uff0c\u5c31\u662f\u7b49\u957f\u6876\u3002\u901a\u8fc7\u4f20\u9012 labels=False \u6765\u83b7\u5f97\u5206\u4f4d\u6570\u6570\u503c\u3002 grouping = pd.qcut(df.data1, 10, labels=False) grouped = df.data2.groupby(grouping) result = grouped.apply(get_stats).unstack() print(result) # min max count mean # data1 # 0 -3.678934 3.022862 100.0 0.029658 # 1 -2.319813 2.646502 100.0 0.094035 # 2 -2.873727 2.470840 100.0 0.023866 # 3 -2.196701 2.042251 100.0 0.021232 # 4 -2.154161 2.020809 100.0 0.110834 # 5 -2.723061 2.415626 100.0 0.057365 # 6 -2.291470 2.536159 100.0 0.020866 # 7 -2.064083 1.799356 100.0 -0.081025 # 8 -3.405679 1.792581 100.0 -0.009705 # 9 -2.469285 2.600849 100.0 -0.061721 \u793a\u4f8b\uff1a\u4f7f\u7528\u6307\u5b9a\u5206\u7ec4\u503c\u586b\u5145\u7f3a\u5931\u503c \u5728\u6e05\u9664\u7f3a\u5931\u503c\u65f6\uff0c\u6709\u65f6\u4f1a\u4f7f\u7528 dropna \u6765\u53bb\u9664\u7f3a\u5931\u503c\uff0c\u6709\u65f6\u4f7f\u7528\u4fee\u6b63\u503c\u6216\u6765\u81ea\u4e8e\u5176\u4ed6\u6570\u636e\u7684\u503c\u6765\u8f93\u5165\uff08\u586b\u5145\uff09\u5230 null \u503c\uff08 NA \uff09\u3002 fillna \u662f\u4e00\u4e2a\u53ef\u4ee5\u4f7f\u7528\u7684\u6b63\u786e\u5de5\u5177\u3002 \u4f8b\u5982\u4e0b\u9762\u4f8b\u5b50\u4e2d\u4f7f\u7528\u4f7f\u7528\u5e73\u5747\u503c\u6765\u586b\u5145NA\u503c\uff1a data = (100, 110, 120, 130, 140, 150) s = pd.Series(data) print(s) # 0 100 # 1 110 # 2 120 # 3 130 # 4 140 # 5 150 # dtype: float64 \u5c06\u6570\u636e\u4e2d\u7684\u4e00\u4e9b\u503c\u8bbe\u7f6e\u4e3a\u7f3a\u5931\u503c\uff1a s[::2] = np.nan print(s) # 0 NaN # 1 110.0 # 2 NaN # 3 130.0 # 4 NaN # 5 150.0 # dtype: float64 result = s.fillna(s.mean()) # 110, 130, 150\u7684\u5e73\u5747\u503c\u662f130 print(result) # 0 130.0 # 1 110.0 # 2 130.0 # 3 130.0 # 4 130.0 # 5 150.0 # dtype: float64 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u6309\u7ec4\u586b\u5145NA\u503c\uff1a \u65b9\u6cd51,\u5bf9\u6570\u636e\u5206\u7ec4\u540e\u4f7f\u7528 apply \u3002 \u65b9\u6cd52,\u5728\u6bcf\u4e2a\u6570\u636e\u5757\u4e0a\u90fd\u8c03\u7528 fillna \u7684\u51fd\u6570\u3002 data = (100, 110, 120, 130, 140, 150, 160, 170) states = ['Ohio', 'New York', 'Vermont', 'Florida', 'Oregon', 'Nevada', 'California', 'Idaho'] group_key = ['East'] * 4 + ['West'] * 4 # 4\u4e2aEast\u548c4\u4e2aWest\u62fc\u63a5\u7684\u5217\u8868list s = pd.Series(data, index=states) print(s) # Ohio 100 # New York 110 # Vermont 120 # Florida 130 # Oregon 140 # Nevada 150 # California 160 # Idaho 170 # dtype: int64 \u5c06\u6570\u636e\u4e2d\u7684\u4e00\u4e9b\u503c\u8bbe\u7f6e\u4e3a\u7f3a\u5931\u503c\uff1a s[['Vermont', 'Nevada', 'Idaho']] = np.nan print(s) # Ohio 100.0 # New York 110.0 # Vermont NaN # Florida 130.0 # Oregon 140.0 # Nevada NaN # California 160.0 # Idaho NaN # dtype: float64 result = s.groupby(group_key).mean() print(result) # East 113.333333 # West 150.000000 # dtype: float64 \u7528\u4e0a\u9762\u5f97\u51fa\u7684\u5206\u7ec4\u5e73\u5747\u503c\u6765\u586b\u5145NA\u3002 fill_mean = lambda g: g.fillna(g.mean()) result = s.groupby(group_key).apply(fill_mean) print(result) # Ohio 100.000000 # New York 110.000000 # Vermont 113.333333 # Florida 130.000000 # Oregon 140.000000 # Nevada 150.000000 # California 160.000000 # Idaho 150.000000 # dtype: float64 \u5982\u679c\u5df2\u7ecf\u5728\u4ee3\u7801\u4e2d\u4e3a\u6bcf\u4e2a\u5206\u7ec4\u9884\u5b9a\u4e49\u4e86\u586b\u5145\u503c\uff0c\u53ef\u4ee5\u5229\u7528\u6bcf\u4e2a\u5206\u7ec4\u90fd\u6709\u7684\u5185\u7f6e\u7684 name \u5c5e\u6027\uff0c\u5b9e\u73b0\u586b\u5145 NA \u3002 fill_value = {'East': 0.5, 'West': -1} fill_func = lambda g: g.fillna(fill_value[g.name]) result = s.groupby(group_key).apply(fill_func) print(result) # Ohio 100.0 # New York 110.0 # Vermont 0.5 # Florida 130.0 # Oregon 140.0 # Nevada -1.0 # California 160.0 # Idaho -1.0 # dtype: float64 \u793a\u4f8b\uff1a\u968f\u673a\u91c7\u6837\u4e0e\u6392\u5217 \u5047\u8bbe\u60f3\u4ece\u5927\u6570\u636e\u96c6\u4e2d\u62bd\u53d6\u968f\u673a\u6837\u672c\uff08\u6709\u6216\u6ca1\u6709\u66ff\u6362\uff09\u4ee5\u7528\u4e8e\u8499\u7279\u5361\u7f57\u6a21\u62df\u76ee\u7684\u6216\u67d0\u4e9b\u5176\u4ed6\u5e94\u7528\u7a0b\u5e8f\u3002 \u6709\u5f88\u591a\u65b9\u6cd5\u6765\u6267\u884c\u201c\u62bd\u53d6\u201d\uff0c\u8fd9\u91cc\u4f7f\u7528Series\u7684sample\u65b9\u6cd5\u3002 \u4e3a\u4e86\u6f14\u793a\uff0c\u8fd9\u91cc\u4ecb\u7ecd\u4e00\u79cd\u6784\u9020\u4e00\u526f\u82f1\u5f0f\u6251\u514b\u724c\u7684\u65b9\u6cd5\uff1a # \u6885\u82b1clubs\u3001\u65b9\u5757diamonds\u3001\u7ea2\u6843hearts\u3001\u9ed1\u6843spades\u3002 suits = ['H', 'S', 'C', 'D'] card_val = (list(range(1, 11)) + [10] * 3) * 4 # card_val [ # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10 # ] base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q'] # base_names\uff1a ['A', 2, 3, 4, 5, 6, 7, 8, 9, 10, 'J', 'K', 'Q'] \u751f\u6210\u4e86\u4e00\u4e2a\u957f\u5ea6\u4e3a 52 \u7684Series, Series\u7684\u7d22\u5f15\u5305\u542b\u4e86\u724c\u540d\uff0cSeries\u7684\u503c\u53ef\u4ee5\u7528\u6e38\u620f\uff08\u4e3a\u4e86\u4fdd\u6301\u7b80\u5355\uff0c\u8ba9\u2019A\u2019\u4e3a1 \uff09\uff1a cards = [] for suit in ['H', 'S', 'C', 'D']: cards.extend(str(num) + suit for num in base_names) deck = pd.Series(card_val, index=cards) print(deck) # AH 1 # 2H 2 # 3H 3 # 4H 4 # 5H 5 # 6H 6 # 7H 7 # 8H 8 # 9H 9 # 10H 10 # JH 10 # KH 10 # QH 10 # AS 1 # 2S 2 # 3S 3 # 4S 4 # 5S 5 # 6S 6 # 7S 7 # 8S 8 # 9S 9 # 10S 10 # JS 10 # KS 10 # QS 10 # AC 1 # 2C 2 # 3C 3 # 4C 4 # 5C 5 # 6C 6 # 7C 7 # 8C 8 # 9C 9 # 10C 10 # JC 10 # KC 10 # QC 10 # AD 1 # 2D 2 # 3D 3 # 4D 4 # 5D 5 # 6D 6 # 7D 7 # 8D 8 # 9D 9 # 10D 10 # JD 10 # KD 10 # QD 10 # dtype: int64 \u4ece\u8fd9\u526f\u724c\u4e2d\u62ff\u51fa\u4e94\u5f20\u724c\u53ef\u4ee5\u5199\u6210\uff1a def draw(_deck, n=5): return _deck.sample(n) print(draw(deck)) # KD 10 # 2S 2 # 5C 5 # 6C 6 # QD 10 # dtype: int64 \u5047\u8bbe\u8981\u4ece\u6bcf\u4e2a\u82b1\u8272\u4e2d\u968f\u673a\u62bd\u53d6\u4e24\u5f20\u724c\u3002\u7531\u4e8e\u82b1\u8272\u662f\u724c\u540d\u7684\u6700\u540e\u4e24\u4e2a\u5b57\u7b26\uff0c\u53ef\u4ee5\u57fa\u4e8e\u8fd9\u70b9\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u4f7f\u7528 apply \uff1a get_suit = lambda card: card[-1] # \u6700\u540e\u4e00\u4e2a\u5b57\u6bcd\u662f\u82b1\u8272 result = deck.groupby(get_suit).apply(draw, n=2) print(result) # C 10C 10 # 3C 3 # D KD 10 # AD 1 # H 5H 5 # 7H 7 # S 3S 3 # 5S 5 # dtype: int64 \u6216\u8005\u4e5f\u53ef\u4ee5\u5199\u6210\uff1a result = deck.groupby(get_suit, group_keys=False).apply(draw, n=2) print(result) # JC 10 # 8C 8 # QD 10 # 4D 4 # 10H 10 # 6H 6 # 7S 7 # KS 10 # dtype: int64 \u793a\u4f8b\uff1a\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u548c\u76f8\u5173\u6027 \u5728 groupby \u7684\u62c6\u5206-\u5e94\u7528-\u8054\u5408\u7684\u8303\u5f0f\u4e0b\uff0cDataFrame\u7684\u5217\u95f4\u64cd\u4f5c\u6216\u4e24\u4e2aSeriese\u4e4b\u95f4\u7684\u64cd\u4f5c\uff0c\u4f8b\u5982\u5b9e\u73b0\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u3002 \u4e0b\u9762\u4f8b\u5b50\uff0c\u4f7f\u7528\u4e00\u4e2a\u5305\u542b\u5206\u7ec4\u952e\u548c\u6743\u91cd\u503c\u7684\u6570\u636e\u96c6\uff1a dt = np.random.randn(8) wt = np.random.randn(8) df = pd.DataFrame( { 'category': ['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'], 'data': dt, 'weight': wt } ) print(df) # category data weight # 0 a -0.250764 -0.085285 # 1 a 0.167155 -1.361254 # 2 a 0.399306 1.755542 # 3 a -0.514477 0.270124 # 4 b -0.005558 0.886514 # 5 b 0.607596 -1.384315 # 6 b -1.029627 -0.845340 # 7 b -0.294204 1.253965 \u901a\u8fc7 category \u8fdb\u884c\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u5982\u4e0b\uff1a grouped = df.groupby('category') get_wavg = lambda g: np.average(g['data'], weights=g['weight']) result = grouped.apply(get_wavg) print(result) # category # a 0.614499 # b 3.863947 # dtype: float64 \u53e6\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e00\u4e2a\u4ece\u96c5\u864e\u8d22\u7ecf\u4e0a\u83b7\u5f97\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e00\u4e9b\u6807\u666e500 \uff08SPX\u7b26\u53f7\uff09\u548c\u80a1\u7968\u7684\u6536\u76d8\u4ef7\uff1a close_px = pd.read_csv('../examples/stock_px_2.csv', parse_dates=True, index_col=0) print(close_px.info()) # <class 'pandas.core.frame.DataFrame'> # DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14 # Data columns (total 4 columns): # # Column Non-Null Count Dtype # --- ------ -------------- ----- # 0 AAPL 2214 non-null float64 # 1 MSFT 2214 non-null float64 # 2 XOM 2214 non-null float64 # 3 SPX 2214 non-null float64 # dtypes: float64(4) # memory usage: 86.5 KB # None print(close_px[-4:]) # AAPL MSFT XOM SPX # 2011-10-11 400.29 27.00 76.27 1195.54 # 2011-10-12 402.19 26.96 77.16 1207.25 # 2011-10-13 408.43 27.18 76.37 1203.66 # 2011-10-14 422.00 27.27 78.11 1224.58 \u76ee\u6807\u4efb\u52a1\uff1a\u8ba1\u7b97\u4e00\u4e2aDataFrame\uff0c\u5b83\u5305\u542b\u6807\u666e\u6307\u6570\uff08SPX\uff09\u6bcf\u65e5\u6536\u76ca\u7684\u5e74\u5ea6\u76f8\u5173\u6027\uff08\u901a\u8fc7\u767e\u5206\u6bd4\u53d8\u5316\u8ba1\u7b97\uff09\u3002 \u9996\u5148\u521b\u5efa\u4e00\u4e2a\u8ba1\u7b97\u6bcf\u5217\u4e0e\u2019SPX\u2019\u5217\u6210\u5bf9\u5173\u8054\u7684\u51fd\u6570\uff1a spx_corr = lambda x: x.corrwith(x['SPX']) \u4e4b\u540e\uff0c\u4f7f\u7528 pct_change \u8ba1\u7b97 close-px \u767e\u5206\u6bd4\u7684\u53d8\u5316\uff1a rets = close_px.pct_change().dropna() # Percentage change between the current and a prior element. print(rets) # AAPL MSFT XOM SPX # 2003-01-03 0.006757 0.001421 0.000684 -0.000484 # 2003-01-06 0.000000 0.017975 0.024624 0.022474 # ... ... ... ... ... # 2011-10-14 0.033225 0.003311 0.022784 0.017380 # [2213 rows x 4 columns] \u6700\u540e\uff0c\u6309\u5e74\u5bf9\u767e\u5206\u6bd4\u53d8\u5316\u8fdb\u884c\u5206\u7ec4\uff0c\u53ef\u4ee5\u4f7f\u7528\u5355\u884c\u51fd\u6570\u4ece\u6bcf\u4e2a\u884c\u6807\u7b7e\u4e2d\u63d0\u53d6\u6bcf\u4e2a datetime \u6807\u7b7e\u7684 year \u5c5e\u6027\uff1a get_year = lambda x: x.year by_year = rets.groupby(get_year) result = by_year.apply(spx_corr) print(result) # AAPL MSFT XOM SPX # 2003 0.541124 0.745174 0.661265 1.0 # 2004 0.374283 0.588531 0.557742 1.0 # 2005 0.467540 0.562374 0.631010 1.0 # 2006 0.428267 0.406126 0.518514 1.0 # 2007 0.508118 0.658770 0.786264 1.0 # 2008 0.681434 0.804626 0.828303 1.0 # 2009 0.707103 0.654902 0.797921 1.0 # 2010 0.710105 0.730118 0.839057 1.0 # 2011 0.691931 0.800996 0.859975 1.0 \u53ef\u4ee5\u8ba1\u7b97\u5185\u90e8\u5217\u76f8\u5173\u6027\u3002\u8fd9\u91cc\u8ba1\u7b97\u4e86\u82f9\u679c\u548c\u5fae\u8f6f\u7684\u5e74\u5ea6\u76f8\u5173\u6027\uff1a result = by_year.apply(lambda g: g['AAPL'].corr(g['MSFT'])) print(result) # 2003 0.480868 # 2004 0.259024 # 2005 0.300093 # 2006 0.161735 # 2007 0.417738 # 2008 0.611901 # 2009 0.432738 # 2010 0.571946 # 2011 0.581987 # dtype: float64 \u793a\u4f8b\uff1a\u9010\u7ec4\u7ebf\u6027\u56de\u5f52 \u5b9a\u4e49\u4ee5\u4e0b regress \uff08\u56de\u5f52\uff09\u51fd\u6570\uff08\u4f7f\u7528 statsmodels \u8ba1\u91cf\u7ecf\u6d4e\u5b66\u5e93\uff09\uff0c\u8be5\u51fd\u6570\u5bf9\u6bcf\u4e2a\u6570\u636e\u5757\u6267\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\uff08OLS\uff09\u56de\u5f52\uff1a def regress(data, yvar, xvars): Y = data[yvar] X = data[xvars] X['intercept'] = 1. result = sm.OLS(Y, X).fit() return result.params \u73b0\u5728\u8981\u8ba1\u7b97AAPL\u5728SPX\u56de\u62a5\u4e0a\u7684\u5e74\u5ea6\u7ebf\u6027\u56de\u5f52\uff1a result = by_year.apply(regress, 'AAPL', ['SPX']) print(result) # SPX intercept # 2003 1.195406 0.000710 # 2004 1.363463 0.004201 # 2005 1.766415 0.003246 # 2006 1.645496 0.000080 # 2007 1.198761 0.003438 # 2008 0.968016 -0.001110 # 2009 0.879103 0.002954 # 2010 1.052608 0.001261 # 2011 0.806605 0.001514 \u6570\u636e\u900f\u89c6\u8868\u4e0e\u4ea4\u53c9\u8868 \u6570\u636e\u900f\u89c6\u8868 \u6570\u636e\u900f\u89c6\u8868\u662f\u7535\u5b50\u8868\u683c\u7a0b\u5e8f\u548c\u5176\u4ed6\u6570\u636e\u5206\u6790\u8f6f\u4ef6\u4e2d\u5e38\u89c1\u7684\u6570\u636e\u6c47\u603b\u5de5\u5177\u3002 \u5b83\u6839\u636e\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u805a\u5408\u4e00\u5f20\u8868\u7684\u6570\u636e\uff0c\u5c06\u6570\u636e\u5728\u77e9\u5f62\u683c\u5f0f\u4e2d\u6392\u5217\uff0c\u5176\u4e2d\u4e00\u4e9b\u5206\u7ec4\u952e\u662f\u6cbf\u7740\u884c\u7684\uff0c\u53e6\u4e00\u4e9b\u662f\u6cbf\u7740\u5217\u7684\u3002 Python\u4e2d\u7684pandas\u900f\u89c6\u8868\u662f\u901a\u8fc7\u8fd9\u91cc\u6240\u4ecb\u7ecd\u7684groupby\u5de5\u5177\u4ee5\u53ca\u4f7f\u7528\u5206\u5c42\u7d22\u5f15\u7684\u91cd\u5851\u64cd\u4f5c\u5b9e\u73b0\u7684\u3002 DataFrame\u62e5\u6709\u4e00\u4e2a pivot_table \u65b9\u6cd5\uff0c\u5e76\u4e14\u8fd8\u6709\u8fd8\u4e00\u4e2a\u9876\u5c42\u7684 pandas.pivot_table \u51fd\u6570\u3002 \u9664\u4e86\u4e3a groupby \u63d0\u4f9b\u4e00\u4e2a\u65b9\u4fbf\u63a5\u53e3\uff0c pivot_table \u8fd8\u53ef\u4ee5\u6dfb\u52a0\u90e8\u5206\u603b\u8ba1\uff0c\u4e5f\u79f0\u4f5c\u8fb9\u8ddd\u3002 import pandas as pd import numpy as np \u6839\u636e\u4e0b\u9762\u7684\u5c0f\u8d39\u6570\u636e\u96c6\uff0c\u8ba1\u7b97\u4e00\u5f20\u5728\u884c\u65b9\u5411\u4e0a\u6309 day \u548c smoker \u6392\u5217\u7684\u5206\u7ec4\u5e73\u5747\u503c\uff08\u9ed8\u8ba4\u7684 pivot_table \u805a\u5408\u7c7b\u578b\uff09\u7684\u8868\u3002 pivot_table \u9009\u9879\uff1a values: \u9700\u8981\u805a\u5408\u7684\u5217\u540d\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u805a\u5408\u6240\u6709\u6570\u503c\u578b\u7684\u5217\u3002 index: \u5728\u7ed3\u679c\u900f\u89c6\u8868\u7684\u884c\u4e0a\u8fdb\u884c\u5206\u7ec4\u7684\u5217\u540d\u6216\u8005\u5176\u4ed6\u5206\u7ec4\u952e\u3002 tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) \u6837\u672c\u6570\u636e\u3002 print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u8ba1\u7b97\u5728\u884c\u65b9\u5411\u4e0a\u6309 day \u548c smoker \u6392\u5217\u7684\u5206\u7ec4\u5e73\u5747\u503c\u3002\u4e5f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 groupby \u5b9e\u73b0\u3002 result = tips.pivot_table(index=['day', 'smoker']) print(result) # size tip tip_pct total_bill # day smoker # Fri No 2.250000 2.812500 0.179740 18.420000 # Yes 2.066667 2.714000 0.216293 16.813333 # Sat No 2.555556 3.102889 0.190412 19.661778 # Yes 2.476190 2.875476 0.179833 21.276667 # Sun No 2.929825 3.167895 0.193617 20.506667 # Yes 2.578947 3.516842 0.322021 24.120000 # Thur No 2.488889 2.673778 0.193424 17.113111 # Yes 2.352941 3.030000 0.198508 19.190588 \u5728 tip_pct \u548c size \u4e0a\u8fdb\u884c\u805a\u5408\uff0c\u5e76\u6839\u636e time \u5206\u7ec4\u3002\u5c06\u628a smoker \u653e\u5165\u8868\u7684\u5217\uff0c\u800c\u5c06 day \u653e\u5165\u8868\u7684\u884c\uff1a result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker' ) print(result) # size tip_pct # smoker No Yes No Yes # time day # Dinner Fri 2.000000 2.222222 0.162612 0.202545 # Sat 2.555556 2.476190 0.190412 0.179833 # Sun 2.929825 2.578947 0.193617 0.322021 # Thur 2.000000 NaN 0.190114 NaN # Lunch Fri 3.000000 1.833333 0.231125 0.236915 # Thur 2.500000 2.352941 0.193499 0.198508 \u901a\u8fc7\u4f20\u9012 margins=True \u6765\u6269\u5145\u8fd9\u4e2a\u8868\u6765\u5305\u542b\u90e8\u5206\u603b\u8ba1\u3002\u8fd9\u4f1a\u6dfb\u52a0 All \u884c\u548c\u5217\u6807\u7b7e\uff0c\u5176\u4e2d\u76f8\u5e94\u7684\u503c\u662f\u5355\u5c42\u4e2d\u6240\u6709\u6570\u636e\u7684\u5206\u7ec4\u7edf\u8ba1\u503c\u3002 \u8fd9\u91cc All \u7684\u503c\u662f\u5747\u503c\uff0c\u4e14\u8be5\u5747\u503c\u662f\u4e0d\u8003\u8651\u5438\u70df\u8005\u4e0e\u975e\u5438\u70df\u8005\uff08 All \u5217\uff09\u6216\u884c\u5206\u7ec4\u4e2d\u4efb\u4f55\u4e24\u7ea7\u7684\uff08 All \u884c\uff09\u3002 result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 2.000000 2.222222 2.166667 0.162612 0.202545 0.192562 # Sat 2.555556 2.476190 2.517241 0.190412 0.179833 0.185305 # Sun 2.929825 2.578947 2.842105 0.193617 0.322021 0.225718 # Thur 2.000000 NaN 2.000000 0.190114 NaN 0.190114 # Lunch Fri 3.000000 1.833333 2.000000 0.231125 0.236915 0.236088 # Thur 2.500000 2.352941 2.459016 0.193499 0.198508 0.194895 # All 2.668874 2.408602 2.569672 0.192237 0.218176 0.202123 \u8981\u4f7f\u7528\u4e0d\u540c\u7684\u805a\u5408\u51fd\u6570\u65f6\uff0c\u5c06\u51fd\u6570\u4f20\u9012\u7ed9 aggfunc \u3002\u4f8b\u5982\uff0c count \u6216\u8005 len \u5c06\u7ed9\u51fa\u4e00\u5f20\u5206\u7ec4\u5927\u5c0f\u7684\u4ea4\u53c9\u8868\uff08\u8ba1\u6570\u6216\u51fa\u73b0\u9891\u7387\uff09\uff1a result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', aggfunc=len, margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 3.0 9.0 12 3.0 9.0 12 # Sat 45.0 42.0 87 45.0 42.0 87 # Sun 57.0 19.0 76 57.0 19.0 76 # Thur 1.0 NaN 1 1.0 NaN 1 # Lunch Fri 1.0 6.0 7 1.0 6.0 7 # Thur 44.0 17.0 61 44.0 17.0 61 # All 151.0 93.0 244 151.0 93.0 244 \u5bf9\u4e8e\u7a7a\u503c NA \uff0c\u4f20\u9012\u4e00\u4e2a fill_value \u3002 result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', aggfunc='mean', fill_value=0, margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 2.000000 2.222222 2.166667 0.162612 0.202545 0.192562 # Sat 2.555556 2.476190 2.517241 0.190412 0.179833 0.185305 # Sun 2.929825 2.578947 2.842105 0.193617 0.322021 0.225718 # Thur 2.000000 0.000000 2.000000 0.190114 0.000000 0.190114 # Lunch Fri 3.000000 1.833333 2.000000 0.231125 0.236915 0.236088 # Thur 2.500000 2.352941 2.459016 0.193499 0.198508 0.194895 # All 2.668874 2.408602 2.569672 0.192237 0.218176 0.202123 \u4ea4\u53c9\u8868\uff1acrosstab \u4ea4\u53c9\u8868\uff08\u7b80\u5199\u4e3acrosstab\uff09\u662f\u6570\u636e\u900f\u89c6\u8868\u7684\u4e00\u4e2a\u7279\u6b8a\u60c5\u51b5\uff0c\u8ba1\u7b97\u7684\u662f\u5206\u7ec4\u4e2d\u7684\u9891\u7387\u3002 crosstab \u7684\u524d\u4e24\u4e2a\u53c2\u6570\u53ef\u662f\u6570\u7ec4\u3001Series\u6216\u6570\u7ec4\u7684\u5217\u8868\u3002 sample = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] nationality = ['USA', 'Japan', 'USA', 'Japan', 'Japan', 'Japan', 'USA', 'USA', 'Japan', 'USA'] handedness = ['Right-handed', 'Left-handed', 'Right-handed', 'Right-handed', 'Left-handed', 'Right-handed', 'Right-handed', 'Left-handed', 'Right-handed', 'Right-handed'] df = pd.DataFrame( { 'sample': sample, 'nationality': nationality, 'handedness': handedness } ) print(df) # sample nationality handedness # 0 1 USA Right-handed # 1 2 Japan Left-handed # 2 3 USA Right-handed # 3 4 Japan Right-handed # 4 5 Japan Left-handed # 5 6 Japan Right-handed # 6 7 USA Right-handed # 7 8 USA Left-handed # 8 9 Japan Right-handed # 9 10 USA Right-handed \u6309\u7167\u56fd\u7c4d\u548c\u60ef\u7528\u6027\u6765\u603b\u7ed3\u8fd9\u4e9b\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528 pivot_table \u6765\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u4f46\u662f pandas.crosstable \u51fd\u6570\u66f4\u4e3a\u65b9\u4fbf\uff1a result = pd.crosstab(df.nationality, df.handedness, margins=True) print(result) # handedness Left-handed Right-handed All # nationality # Japan 2 3 5 # USA 1 4 5 # All 3 7 10 \u5728\u5c0f\u8d39\u6570\u636e\u4e2d\u53ef\u4ee5\u8fd9\u4e48\u505a\uff1a result = pd.crosstab(['tips.time', tips.day], tips.smoker, margins=True) print(result) # smoker No Yes All # row_0 day # tips.time Fri 4 15 19 # Sat 45 42 87 # Sun 57 19 76 # Thur 45 17 62 # All 151 93 244","title":"\u6570\u636e\u805a\u5408\u4e0e\u5206\u7ec4\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch07/#_1","text":"","title":"\u6570\u636e\u805a\u5408\u4e0e\u5206\u7ec4\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch07/#groupby","text":"import pandas as pd import numpy as np","title":"GroupBy\u673a\u5236"},{"location":"python/DataAnalysis/ch07/#_2","text":"\u5206\u7ec4\u64cd\u4f5c\u7b2c\u4e00\u6b65\uff0c\u6570\u636e\u5305\u542b\u5728pandas\u5bf9\u8c61\u4e2d\uff0c\u53ef\u4ee5\u662fSeries\u3001DataFrame\u6216\u5176\u4ed6\u6570\u636e\u7ed3\u6784\u3002\u4e4b\u540e\u6839\u636e\u63d0\u4f9b\u7684\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u5206\u79bb\u5230\u5404\u4e2a\u7ec4\u4e2d\u3002 \u5206\u7ec4\u952e\u53ef\u662f\u591a\u79cd\u5f62\u5f0f\u7684\uff0c\u5e76\u4e14\u952e\u4e0d\u4e00\u5b9a\u662f\u5b8c\u5168\u76f8\u540c\u7684\u7c7b\u578b(\u6ce8\u610f\u540e\u9762\u4ecb\u7ecd\u7684\u4e09\u4e2a\u65b9\u6cd5\u662f\u53ef\u4ee5\u4ea7\u751f\u7528\u4e8e\u5206\u9694\u5bf9\u8c61\u7684\u503c\u6570\u7ec4\u7684\u5feb\u6377\u65b9\u5f0f)\uff1a \u4e0e\u9700\u8981\u5206\u7ec4\u7684\u8f74\u5411\u957f\u5ea6\u4e00\u81f4\u7684\u503c\u5217\u8868\u6216\u503c\u6570\u7ec4\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cgroupby\u5728axis=0\u7684\u8f74\u5411\u4e0a\u5206\u7ec4\u3002 DataFrame\u7684\u5217\u540d\u7684\u503c\u3002 \u53ef\u4ee5\u5c06\u5206\u7ec4\u8f74\u5411\u4e0a\u7684\u503c\u548c\u5206\u7ec4\u540d\u79f0\u76f8\u5339\u914d\u7684\u5b57\u5178\u6216Series\u3002 \u53ef\u4ee5\u5728\u8f74\u7d22\u5f15\u6216\u7d22\u5f15\u4e2d\u7684\u5355\u4e2a\u6807\u7b7e\u4e0a\u8c03\u7528\u7684\u51fd\u6570\u3002 \u8bf7\u6ce8\u610f\uff0c\u5206\u7ec4\u952e\u4e2d\u7684\u4efb\u4f55\u7f3a\u5931\u503c\u5c06\u88ab\u6392\u9664\u5728\u7ed3\u679c\u4e4b\u5916\u3002 \u5206\u79bb\u64cd\u4f5c\u662f\u5728\u6570\u636e\u5bf9\u8c61\u7684\u7279\u5b9a\u8f74\u5411\u4e0a\u8fdb\u884c\u7684\u3002\u4f8b\u5982\uff0cDataFrame\u53ef\u4ee5\u5728\u5b83\u7684\u884c\u65b9\u5411\uff08axis=0\uff09\u6216\u5217\u65b9\u5411\uff08axis=1\uff09\u8fdb\u884c\u5206\u7ec4\u3002 \u5206\u7ec4\u64cd\u4f5c\u540e\uff0c\u4e00\u4e2a\u51fd\u6570\u5c31\u53ef\u4ee5\u5e94\u7528\u5230\u5404\u4e2a\u7ec4\u4e2d\uff0c\u4ea7\u751f\u65b0\u7684\u503c\u3002\u6700\u7ec8\uff0c\u6240\u6709\u51fd\u6570\u7684\u5e94\u7528\u7ed3\u679c\u4f1a\u8054\u5408\u4e3a\u4e00\u4e2a\u7ed3\u679c\u5bf9\u8c61\u3002 df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) \u6839\u636ekey1\u6807\u7b7e\u8ba1\u7b97data1\u5217\u7684\u5747\u503c\uff0c\u65b9\u6cd5\u4e00\uff0c\u8bbf\u95ee data1 \u5e76\u4f7f\u7528 key1 \u5217\uff08\u5b83\u662f\u4e00\u4e2aSeries\uff09\u8c03\u7528 groupby \u65b9\u6cd5\uff1a grouped = df['data1'].groupby(df['key1']) print(grouped) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fdd2cb01430> grouped \u53d8\u91cf\u73b0\u5728\u662f\u4e00\u4e2a GroupBy \u5bf9\u8c61\uff0c\u5b83\u5b9e\u9645\u4e0a\u8fd8\u6ca1\u6709\u8fdb\u884c\u4efb\u4f55\u8ba1\u7b97\uff0c\u62e5\u6709\u4e00\u4e9b\u5173\u4e8e\u5206\u7ec4\u952edf['key1']\u7684\u4e00\u4e9b\u4e2d\u95f4\u6570\u636e\u7684\u4fe1\u606f\u3002 \u4e0b\u9762\u5bf9 grouped \u5bf9\u8c61\u505a\u4e00\u4e9b\u64cd\u4f5c\uff1a result = grouped.mean() # \u8ba1\u7b97\u5e73\u5747\u503c print(result) # key1 # a 4.333333 # b 6.000000 # Name: data1, dtype: float64 grouped_means = df['data1'].groupby([df['key1'], df['key2']]).mean() print(grouped_means) # key1 key2 # a one 5.0 # two 3.0 # b one 5.0 # two 7.0 # Name: data1, dtype: float64 \u4e0a\u9762\u4f8b\u5b50\u4f7f\u7528\u4e86\u4e24\u4e2a\u952e\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u4e14\u7ed3\u679cSeries\u73b0\u5728\u62e5\u6709\u4e00\u4e2a\u5305\u542b\u552f\u4e00\u952e\u5bf9\u7684\u591a\u5c42\u7d22\u5f15\u3002 \u4e0b\u9762\u5bf9\u8ba1\u7b97\u7684\u5e73\u5747\u503c\uff08mean\uff09\u8fdb\u884c\u91cd\u5851\uff08unstack\uff09\u3002 print(grouped_means.unstack()) # key2 one two # key1 # a 5.0 3.0 # b 5.0 7.0 \u5206\u7ec4\u4fe1\u606f\u901a\u5e38\u5305\u542b\u5728\u540c\u4e00\u4e2aDataFrame\u4e2d\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u4f20\u9012\u5217\u540d\uff08\u65e0\u8bba\u90a3\u4e9b\u5217\u540d\u662f\u5b57\u7b26\u4e32\u3001\u6570\u5b57\u6216\u5176\u4ed6Python\u5bf9\u8c61\uff09\u4f5c\u4e3a\u5206\u7ec4\u952e\uff1a \u4e0b\u9762\u4f8b\u5b50\u4e2d df.groupby('key1').mean() \u7684\u7ed3\u679c\u91cc\u5e76\u6ca1\u6709 key2 \u5217\u3002\u8fd9\u662f\u56e0\u4e3a df['key2'] \u5e76\u4e0d\u662f\u6570\u503c\u6570\u636e\uff0c\u5373 df['key2'] \u662f\u4e00\u4e2a\u5197\u4f59\u5217\uff0c\u56e0\u6b64\u88ab\u6392\u9664\u5728\u7ed3\u679c\u4e4b\u5916\u3002 result = df.groupby('key1').mean() print(result) # data1 data2 # key1 # a 4.333333 5.333333 # b 6.000000 7.000000 result = df.groupby(['key1', 'key2']).mean() print(result) # data1 data2 # key1 key2 # a one 5.0 6.0 # two 3.0 4.0 # b one 5.0 6.0 # two 7.0 8.0 result = df.groupby(['key1', 'key2']).size() print(result) # key1 key # a one 2 # two 1 # b one 1 # two 1 # dtype: int64","title":"\u5206\u7ec4\u673a\u5236"},{"location":"python/DataAnalysis/ch07/#_3","text":"GroupBy \u5bf9\u8c61\u652f\u6301\u8fed\u4ee3\uff0c\u4f1a\u751f\u6210\u4e00\u4e2a\u5305\u542b\u7ec4\u540d\u548c\u6570\u636e\u5757\u76842\u7ef4\u5143\u7ec4\u5e8f\u5217\u3002 df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) \u5355\u4e2a\u5206\u7ec4\u952e\u7684\u60c5\u51b5: for name, group in df.groupby('key1'): print(name) print(group) # a # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10 # b # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 \u591a\u4e2a\u5206\u7ec4\u952e\u7684\u60c5\u51b5: \u5143\u7ec4\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u662f\u952e\u503c\u7684\u5143\u7ec4\u3002 for (k1, k2), group in df.groupby(['key1', 'key2']): print((k1, k2)) print(group) # ('a', 'one') # key1 key2 data1 data2 # 0 a one 1 2 # 4 a one 9 10 # ('a', 'two') # key1 key2 data1 data2 # 1 a two 3 4 # ('b', 'one') # key1 key2 data1 data2 # 2 b one 5 6 # ('b', 'two') # key1 key2 data1 data2 # 3 b two 7 8 result = dict(list(df.groupby('key1'))) print(result) # df.groupby('key1')\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u5bf9\u8c61 # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f240fe058b0> # list(df.groupby('key1'))\u7684\u7ed3\u679c\u662f\u5305\u542bFrameData\u7684\u7ed3\u6784\u7684\u5217\u8868list: # [ # ('a', key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10), # ('b', key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8) # ] # dict(list(df.groupby('key1')))\u7684\u7ed3\u679c\u662f\u5305\u542bFrameData\u7684\u7ed3\u6784\u7684\u5b57\u5178dict # { # 'a': key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10, # 'b': key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 # } print(result['b']) # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c groupby \u5728 axis=0 \u7684\u8f74\u5411\u4e0a\u5206\u7ec4\uff0c\u4e5f\u53ef\u4ee5\u5728\u5176\u4ed6\u4efb\u610f\u8f74\u5411\u4e0a\u8fdb\u884c\u5206\u7ec4\u3002 print(df.dtypes) # key1 object # key2 object # data1 int64 # data2 int64 # dtype: object grouped = df.groupby(df.dtypes, axis=1) print(grouped) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f4f6636df70> print(list(grouped)) # [ # (dtype('int64'), data1 data2 # 0 1 2 # 1 3 4 # 2 5 6 # 3 7 8 # 4 9 10), # (dtype('O'), key1 key2 # 0 a one # 1 a two # 2 b one # 3 b two # 4 a one) # ] \u6253\u5370\u5404\u5206\u7ec4\u5982\u4e0b\uff1a for dtype, group in grouped: print(dtype) print(group) # int64 # data1 data2 # 0 1 2 # 1 3 4 # 2 5 6 # 3 7 8 # 4 9 10 # object # key1 key2 # 0 a one # 1 a two # 2 b one # 3 b two # 4 a one","title":"\u904d\u5386\u5404\u5206\u7ec4"},{"location":"python/DataAnalysis/ch07/#_4","text":"\u5bf9\u4e8e\u4eceDataFrame\u521b\u5efa\u7684 GroupBy \u5bf9\u8c61\uff0c\u7528\u5217\u540d\u79f0\u6216\u5217\u540d\u79f0\u6570\u7ec4\u8fdb\u884c\u7d22\u5f15\u65f6\uff0c\u4f1a\u4ea7\u751f\u7528\u4e8e\u805a\u5408\u7684\u5217\u5b50\u96c6\u7684\u6548\u679c\u3002 \u5982\u679c\u4f20\u9012\u7684\u662f\u5217\u8868\u6216\u6570\u7ec4\uff0c\u5219\u6b64\u7d22\u5f15\u64cd\u4f5c\u8fd4\u56de\u7684\u5bf9\u8c61\u662f\u5206\u7ec4\u7684DataFrame\uff1b\u5982\u679c\u53ea\u6709\u5355\u4e2a\u5217\u540d\u4f5c\u4e3a\u6807\u91cf\u4f20\u9012\uff0c\u5219\u4e3a\u5206\u7ec4\u7684Series\uff1b \u5bf9\u6bd4\u4e0b\u97624\u53e5\uff1a result = df.groupby('key1')['data1'] # \u5355\u4e2a\u5217\u540d print(result) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fa988609040> for key, data in result: print(key) print(data) result = df['data1'].groupby(df['key1']) # \u5355\u4e2a\u5217\u540d print(result) # <pandas.core.groupby.generic.SeriesGroupBy object at 0x7fa988609910> for key, data in result: print(key) print(data) # a # 0 1 # 1 3 # 4 9 # Name: data1, dtype: int64 # b # 2 5 # 3 7 # Name: data1, dtype: int64 result = df.groupby('key1')[['data1']] # \u5217\u8868\u6216\u6570\u7ec4 print(result) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f32666176a0> for key, data in result: print(key) print(data) # a # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 4 a one 9 10 # b # key1 key2 data1 data2 # 2 b one 5 6 # 3 b two 7 8 result = df[['data1']].groupby(df['key1']) # \u5217\u8868\u6216\u6570\u7ec4 print(result) # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f32666171f0> for key, data in result: print(key) print(data) # a # data1 # 0 1 # 1 3 # 4 9 # b # data1 # 2 5 # 3 7","title":"\u9009\u62e9\u4e00\u5217\u6216\u6240\u6709\u5217\u7684\u5b50\u96c6"},{"location":"python/DataAnalysis/ch07/#series","text":"\u5206\u7ec4\u4fe1\u606f\u53ef\u80fd\u4f1a\u4ee5\u975e\u6570\u7ec4\u5f62\u5f0f\u5b58\u5728\u3002 \u751f\u6210\u4e00\u4e2a\u793a\u4f8bDataFrame\u3002 people = pd.DataFrame( [[1, 3, 5, 7, 9], [0, 2, 4, 6, 8], [0, 2, 4, 6, 8], [1, 3, 5, 7, 9], [1, 2, 3, 4, 5]], columns=['a', 'b', 'c', 'd', 'e'], index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'] ) \u6dfb\u52a0\u4e00\u4e9bNA\u503c\u3002 people.iloc[2:3, [1, 2]] = np.nan print(people) # a b c d e # Joe 1 3.0 5.0 7 9 # Steve 0 2.0 4.0 6 8 # Wes 0 NaN NaN 6 8 # Jim 1 3.0 5.0 7 9 # Travis 1 2.0 3.0 4 5 \u5047\u8bbe\u6709\u5982\u4e0b\u5404\u5217\u7684\u5206\u7ec4\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u4e14\u60f3\u628a\u5404\u5217\u6309\u7ec4\u7d2f\u52a0\u3002 mapping = { 'a': 'red', 'b': 'red', 'c': 'blue', 'd': 'blue', 'e': 'red', 'f': 'orange' # \u6ce8\u610f\uff1a\u5065f\u867d\u7136\u6ca1\u6709\u88ab\u7528\u5230\uff0c\u4f46\u4e0d\u5f71\u54cd\u5728\u8fd9\u91cc\u5b9a\u4e49\u3002 } \u628a mapping \u8fd9\u4e2a\u5b57\u5178\u4f20\u7ed9 groupby() \u3002 by_column = people.groupby(mapping, axis=1) print(by_column.sum()) # blue red # Joe 12.0 13.0 # Steve 10.0 10.0 # Wes 6.0 8.0 # Jim 12.0 13.0 # Travis 7.0 8.0 Series\u4e5f\u6709\u76f8\u540c\u7684\u529f\u80fd\uff0c\u53ef\u4ee5\u89c6\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u6620\u5c04\u3002 map_services = pd.Series(mapping) print(map_services) # a red # b red # c blue # d blue # e red # f orange # dtype: object result = people.groupby(map_services, axis=1).count() print(result) # blue red # Joe 2 3 # Steve 2 3 # Wes 1 2 # Jim 2 3 # Travis 2 3","title":"\u4f7f\u7528\u5b57\u5178\u548cSeries\u5206\u7ec4"},{"location":"python/DataAnalysis/ch07/#_5","text":"\u4e0e\u4f7f\u7528\u5b57\u5178\u6216Series\u5206\u7ec4\u76f8\u6bd4\uff0c\u4f7f\u7528Python\u51fd\u6570\u662f\u5b9a\u4e49\u5206\u7ec4\u5173\u7cfb\u7684\u4e00\u79cd\u66f4\u4e3a\u901a\u7528\u7684\u65b9\u5f0f\u3002 \u4f5c\u4e3a\u5206\u7ec4\u952e\u4f20\u9012\u7684\u51fd\u6570\u5c06\u4f1a\u6309\u7167\u6bcf\u4e2a\u7d22\u5f15\u503c\u8c03\u7528\u4e00\u6b21\uff0c\u540c\u65f6\u8fd4\u56de\u503c\u4f1a\u88ab\u7528\u4f5c\u5206\u7ec4\u540d\u79f0\u3002\u6ce8\u610f\uff1a\u51fd\u6570\u662f\u4f5c\u7528\u5728\u7d22\u5f15\u4e0a\u3002 result = people.groupby(len).sum() # \u4eba\u7684\u540d\u5b57\u662f\u7d22\u5f15\u503c\uff0c\u6839\u636e\u540d\u5b57\u7684\u957f\u5ea6\u6765\u8fdb\u884c\u5206\u7ec4 print(result) # a b c d e # 3 2 6.0 10.0 20 26 # 5 0 2.0 4.0 6 8 # 6 1 2.0 3.0 4 5 \u53ef\u4ee5\u5c06\u51fd\u6570\u4e0e\u6570\u7ec4\u3001\u5b57\u5178\u6216Series\u8fdb\u884c\u6df7\u5408\uff0c\u6240\u6709\u7684\u5bf9\u8c61\u90fd\u4f1a\u5728\u5185\u90e8\u8f6c\u6362\u4e3a\u6570\u7ec4\u3002 key_list = ['one', 'one', 'one', 'two', 'two'] result = people.groupby([len, key_list]).min() print(result) # a b c d e # 3 one 0 3.0 5.0 6 8 # two 1 3.0 5.0 7 9 # 5 one 0 2.0 4.0 6 8 # 6 two 1 2.0 3.0 4 5","title":"\u4f7f\u7528\u51fd\u6570\u5206\u7ec4"},{"location":"python/DataAnalysis/ch07/#_6","text":"\u6839\u636e\u5c42\u7ea7\u5206\u7ec4\u65f6\uff0c\u5c06\u5c42\u7ea7\u6570\u503c\u6216\u5c42\u7ea7\u540d\u79f0\u4f20\u9012\u7ed9 level \u5173\u952e\u5b57\u3002 columns = pd.MultiIndex.from_arrays( [['US', 'US', 'US', 'JP', 'JP'], [1, 3, 5, 1, 3]], names=['cty', 'tenor'] ) hier_df = pd.DataFrame( [[1, 3, 5, 7, 9], [0, 2, 4, 6, 8], [1, 3, 5, 7, 9], [1, 2, 3, 4, 5]], columns=columns ) print(hier_df) # cty US JP # tenor 1 3 5 1 3 # 0 1 3 5 7 9 # 1 0 2 4 6 8 # 2 1 3 5 7 9 # 3 1 2 3 4 5 result = hier_df.groupby(level='cty', axis=1).count() print(result) # cty JP US # 0 2 3 # 1 2 3 # 2 2 3 # 3 2 3","title":"\u6839\u636e\u7d22\u5f15\u5c42\u7ea7\u5206\u7ec4"},{"location":"python/DataAnalysis/ch07/#_7","text":"\u805a\u5408\u662f\u6307\u6240\u6709\u6839\u636e\u6570\u7ec4\u4ea7\u751f\u6807\u91cf\u503c\u7684\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\uff0c\u6bd4\u5982\uff1a mean \u3001 count \u3001 min \u548c sum \u7b49\u4e00\u4e9b\u805a\u5408\u64cd\u4f5c\u3002 import pandas as pd import numpy as np \u9884\u5907\u77e5\u8bc6\uff1a \u5206\u4f4d\u6570\uff08Quantile\uff09\uff0c\u4e5f\u79f0\u5206\u4f4d\u70b9\uff0c\u662f\u6307\u5c06\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\u7684\u6982\u7387\u5206\u5e03\u8303\u56f4\u5206\u4e3a\u51e0\u4e2a\u7b49\u4efd\u7684\u6570\u503c\u70b9\uff0c\u5206\u6790\u5176\u6570\u636e\u53d8\u91cf\u7684\u8d8b\u52bf\u3002 \u5e38\u7528\u7684\u5206\u4f4d\u6570\u6709 \u4e2d\u4f4d\u6570\u3001\u56db\u5206\u4f4d\u6570\u3001\u767e\u5206\u4f4d\u6570\u7b49\u3002 \u4e2d\u4f4d\u6570\uff08Medians\uff09\u662f\u4e00\u4e2a\u7edf\u8ba1\u5b66\u7684\u4e13\u6709\u540d\u8bcd\uff0c\u4ee3\u8868\u4e00\u4e2a\u6837\u672c\u3001\u79cd\u7fa4\u6216\u6982\u7387\u5206\u5e03\u4e2d\u7684\u4e00\u4e2a\u6570\u503c\uff0c\u53ef\u4ee5\u5c06\u6570\u503c\u96c6\u5408\u5212\u5206\u4e3a\u76f8\u7b49\u7684\u4e24\u90e8\u5206\u3002 \u5229\u7528pandas\u5e93\u8ba1\u7b97 data = [6, 47, 49, 15, 42, 41, 7, 39, 43, 40, 36] \u7684\u5206\u4f4d\u6570\u3002 \u786e\u5b9a p \u5206\u4f4d\u6570\u4f4d\u7f6e\u7684\u4e24\u79cd\u65b9\u6cd5( n \u4e3a\u6570\u636e\u7684\u603b\u4e2a\u6570\uff0c p \u4e3a 0-1 \u4e4b\u95f4\u7684\u503c)\u3002\u5728python\u4e2d\u8ba1\u7b97\u5206\u4f4d\u6570\u4f4d\u7f6e\u7684\u65b9\u6848\u91c7\u7528 position=1+(n-1)*p \uff1a position = (n+1)*p position = 1 + (n-1)*p \u6848\u4f8b1 data = pd.Series(np.array([6, 47, 49, 15, 42, 41, 7, 39, 43, 40, 36])) print(\"\u6570\u636e\u683c\u5f0f\uff1a\") print(np.sort(data)) # \u5fc5\u987b\u8981\u6392\u5e8f print('Q1:', data.quantile(.25)) print('Q2:', data.quantile(.5)) print('Q3:', data.quantile(.75)) # \u6570\u636e\u683c\u5f0f\uff1a # [ 6 7 15 36 39 40 41 42 43 47 49] # Q1: 25.5 # Q2: 40.0 # Q3: 42.5 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # Q1\u7684p\u5206\u4f4d\u6570(0.25)\u4f4d\u7f6eposition = 1+(11-1)*0.25 = 3.5(\u53d6\u7b2c3\u4f4d) (p=0.25) Q1=15+(36-15)*0.5=25.5 (\u7b2c3\u30014\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.5) # Q2\u7684p\u5206\u4f4d\u6570(0.5)\u4f4d\u7f6eposition = 1+(11-1)*0.5 = 6 (p=0.5) Q2=40 # Q3\u7684p\u5206\u4f4d\u6570(0.75)\u4f4d\u7f6eposition = 1+(11-1)*0.75 = 9 (p=0.75) Q3=42+(43-42)*0.5=42.5 # IQR = Q3 - Q1 = 17 \u6848\u4f8b2 df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]), columns=['a', 'b']) print(\"\u6570\u636e\u539f\u59cb\u683c\u5f0f\uff1a\") print(df) print(\"\u8ba1\u7b97p=0.1\u65f6\uff0ca\u5217\u548cb\u5217\u7684\u5206\u4f4d\u6570\") print(df.quantile(.1)) # \u6570\u636e\u539f\u59cb\u683c\u5f0f\uff1a # a b # 0 1 1 # 1 2 10 # 2 3 100 # 3 4 100 # \u8ba1\u7b97p=0.1\u65f6\uff0ca\u5217\u548cb\u5217\u7684\u5206\u4f4d\u6570 # a 1.3 # b 3.7 # Name: 0.1, dtype: float64 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # \u8ba1\u7b97a\u5217 # position=1+(4-1)*0.1=1.3 (\u53d6\u7b2c1\u4f4d) # Q1=1+(2-1)*0.3=1.3 (\u7b2c1\u30012\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.3) # \u8ba1\u7b97b\u5217 # position=1+(4-1)*0.1=1.3 (\u53d6\u7b2c1\u4f4d) # Q1=1+(10-1)*0.3=3.7 (\u7b2c1\u30012\u4f4d\u7684\u5dee\u4e58\u4ee5\u4f59\u65700.3) \u4f18\u5316\u7684 groupby \u65b9\u6cd5\uff1a count: \u5206\u7ec4\u4e2d\u975eNA\u503c\u7684\u6570\u91cf sum: \u975eNA\u503c\u7684\u7d2f\u52a0\u548c mean: \u975eNA\u503c\u7684\u5e73\u5747\u503c median: \u975eNA\u503c\u7684\u7b97\u672f\u4e2d\u4f4d\u6570 std, var: \u65e0\u504f\u7684(n-1\u5206\u6bcd)\u6807\u51c6\u5dee\u548c\u65b9\u5dee min, max: \u975eNA\u503c\u7684\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c prod: \u975eNA\u503c\u7684\u4e58\u79ef first, last: \u975eNA\u503c\u7684\u7b2c\u4e00\u4e2a\u3001\u6700\u540e\u4e00\u4e2a\u503c df = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a'], 'key2': ['one', 'two', 'one', 'two', 'one'], 'data1': [1, 3, 5, 7, 9], 'data2': [2, 4, 6, 8, 10] } ) print(df) # key1 key2 data1 data2 # 0 a one 1 2 # 1 a two 3 4 # 2 b one 5 6 # 3 b two 7 8 # 4 a one 9 10 grouped = df.groupby('key1') result = grouped['data1'] for i in result: print(i) # ('a', 0 1 # 1 3 # 4 9 # Name: data1, dtype: int64) # ('b', 2 5 # 3 7 # Name: data1, dtype: int64) result = grouped['data1'].quantile(0.9) # quantile\u5206\u4f4d\u6570 print(result) # key1 # a 7.8 # b 6.8 # Name: data1, dtype: float64 # \u624b\u7b97\u8ba1\u7b97\u7ed3\u679c\uff1a # \u8ba1\u7b97a\u5217 # position=1+(3-1)*0.9=2.8 # Q1=3+(9-3)*0.8=7.8 # \u8ba1\u7b97b\u5217 # position=1+(2-1)*0.9=1.9 # Q1=5+(7-5)*0.9=6.8 \u4f7f\u7528\u81ea\u884c\u5236\u5b9a\u7684\u805a\u5408\uff0c\u5e76\u518d\u8c03\u7528\u5df2\u7ecf\u5728\u5206\u7ec4\u5bf9\u8c61\u4e0a\u5b9a\u4e49\u597d\u7684\u65b9\u6cd5\u3002 def peak_to_peak(arr): return arr.max() - arr.min() result = grouped.agg(peak_to_peak) print(result) # data1 data2 # key1 # a 8 8 # b 2 2 result = grouped.describe() print(result) # data1 ... data2 # count mean std min 25% ... min 25% 50% 75% max # key1 ... # a 3.0 4.333333 4.163332 1.0 2.0 ... 2.0 3.0 4.0 7.0 10.0 # b 2.0 6.000000 1.414214 5.0 5.5 ... 6.0 6.5 7.0 7.5 8.0","title":"\u6570\u636e\u805a\u5408"},{"location":"python/DataAnalysis/ch07/#_8","text":"tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u6839\u636e\u5404\u5217\u540c\u65f6\u4f7f\u7528\u591a\u4e2a\u51fd\u6570\u8fdb\u884c\u805a\u5408 grouped = tips.groupby(['day', 'smoker']) # for i in grouped: # print(i) # (('Fri', 'No'), total_bill tip smoker day time size tip_pct # 91 22.49 3.50 No Fri Dinner 2 0.184308 # ...... # 223 15.98 3.00 No Fri Lunch 3 0.231125) # (('Fri', 'Yes'), total_bill tip smoker day time size tip_pct # 90 28.97 3.00 Yes Fri Dinner 2 0.115518 # ...... # 226 10.09 2.00 Yes Fri Lunch 2 0.247219) # ...... grouped_pct = grouped['tip_pct'] for i in grouped_pct: print(i) # (('Fri', 'No'), 91 0.184308 # 94 0.166667 # ...... # Name: tip_pct, dtype: float64) # (('Fri', 'Yes'), 90 0.115518 # 92 0.210526 # ...... # Name: tip_pct, dtype: float64) # ...... \u5c06\u51fd\u6570\u540d\u4ee5\u5b57\u7b26\u4e32\u5f62\u5f0f\u4f20\u9012\u3002 result = grouped_pct.agg('mean') print(result) # day smoker # Fri No 0.179740 # Yes 0.216293 # Sat No 0.190412 # Yes 0.179833 # Sun No 0.193617 # Yes 0.322021 # Thur No 0.193424 # Yes 0.198508 # Name: tip_pct, dtype: float64 \u5982\u679c\u4f20\u9012\u7684\u662f\u51fd\u6570\u6216\u8005\u51fd\u6570\u540d\u7684\u5217\u8868\uff0c\u4f1a\u5f97\u5230\u4e00\u4e2a\u5217\u540d\u662f\u8fd9\u4e9b\u51fd\u6570\u540d\u7684DataFrame\u3002 \u4e0b\u9762\u4f20\u9012\u4e86\u805a\u5408\u51fd\u6570\u7684\u5217\u8868\u7ed9agg\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u51fd\u6570\u4f1a\u5404\u81ea\u8fd0\u7528\u4e8e\u6570\u636e\u5206\u7ec4\u3002 result = grouped_pct.agg(['mean', 'std', peak_to_peak]) print(result) # mean std peak_to_peak # day smoker # Fri No 0.179740 0.039458 0.094263 # Yes 0.216293 0.077530 0.242219 # Sat No 0.190412 0.058626 0.352192 # Yes 0.179833 0.089496 0.446137 # Sun No 0.193617 0.060302 0.274897 # Yes 0.322021 0.538061 2.382107 # Thur No 0.193424 0.056065 0.284273 # Yes 0.198508 0.057170 0.219047 \u5982\u679c\u4f20\u9012\u7684\u662f (name, function) \u5143\u7ec4\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7ec4\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u5c06\u4f5c\u4e3aDataFrame\u7684\u5217\u540d\uff08\u53ef\u4ee5\u8ba4\u4e3a\u4e8c\u5143\u5143\u7ec4\u7684\u5217\u8868\u662f\u4e00\u79cd\u6709\u5e8f\u7684\u5bf9\u5e94\u5173\u7cfb\uff09\uff1a result = grouped_pct.agg([('foo', 'mean'), ('bar', np.std)]) # foo\u662fmean\u503c\u7684\u5217\u540d print(result) # foo bar # day smoker # Fri No 0.179740 0.039458 # Yes 0.216293 0.077530 # Sat No 0.190412 0.058626 # Yes 0.179833 0.089496 # Sun No 0.193617 0.060302 # Yes 0.322021 0.538061 # Thur No 0.193424 0.056065 # Yes 0.198508 0.057170 \u53ef\u4ee5\u6307\u5b9a\u5e94\u7528\u5230\u6240\u6709\u5217\u4e0a\u7684\u51fd\u6570\u5217\u8868\u6216\u6bcf\u4e00\u5217\u4e0a\u8981\u5e94\u7528\u7684\u4e0d\u540c\u51fd\u6570\u3002 \u4e0b\u9762\u4ea7\u751f\u7684DataFrame\u62e5\u6709\u5206\u5c42\u5217\uff0c\u4e0e\u5206\u522b\u805a\u5408\u6bcf\u4e00\u5217\uff0c\u518d\u4ee5\u5217\u540d\u4f5c\u4e3a keys \u53c2\u6570\u4f7f\u7528 concat \u5c06\u7ed3\u679c\u62fc\u63a5\u5728\u4e00\u8d77\u7684\u7ed3\u679c\u76f8\u540c\u3002 functions = ['count', 'mean', 'max'] result = grouped[['tip_pct', 'total_bill']].agg(functions) print(result) # tip_pct total_bill # count mean max count mean max # day smoker # Fri No 4 0.179740 0.231125 4 18.420000 22.75 # Yes 15 0.216293 0.357737 15 16.813333 40.17 # Sat No 45 0.190412 0.412409 45 19.661778 48.33 # Yes 42 0.179833 0.483092 42 21.276667 50.81 # Sun No 57 0.193617 0.338101 57 20.506667 48.17 # Yes 19 0.322021 2.452381 19 24.120000 45.35 # Thur No 45 0.193424 0.362976 45 17.113111 41.19 # Yes 17 0.198508 0.317965 17 19.190588 43.11 # \u628a['tip_pct', 'total_bill']\u6539\u6210[['tip_pct', 'total_bill']]\uff0c\u5c31\u53ef\u4ee5\u907f\u514d\u62a5\u9519 # FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead. # result = grouped['tip_pct', 'total_bill'].agg(functions) print(result['tip_pct']) # count mean max # day smoker # Fri No 4 0.179740 0.231125 # Yes 15 0.216293 0.357737 # Sat No 45 0.190412 0.412409 # Yes 42 0.179833 0.483092 # Sun No 57 0.193617 0.338101 # Yes 19 0.322021 2.452381 # Thur No 45 0.193424 0.362976 # Yes 17 0.198508 0.317965 \u4e5f\u540c\u6837\u53ef\u4ee5\u4f20\u9012\u5177\u6709\u81ea\u5b9a\u4e49\u540d\u79f0\u7684\u5143\u7ec4\u5217\u8868\uff1a ftuples = [('Durchschnitt', 'mean'), ('Abweichung', np.var)] result = grouped[['tip_pct', 'total_bill']].agg(ftuples) print(result) # tip_pct total_bill # Durchschnitt Abweichung Durchschnitt Abweichung # day smoker # Fri No 0.179740 0.001557 18.420000 25.596333 # Yes 0.216293 0.006011 16.813333 82.562438 # Sat No 0.190412 0.003437 19.661778 79.908965 # Yes 0.179833 0.008010 21.276667 101.387535 # Sun No 0.193617 0.003636 20.506667 66.099980 # Yes 0.322021 0.289509 24.120000 109.046044 # Thur No 0.193424 0.003143 17.113111 59.625081 # Yes 0.198508 0.003268 19.190588 69.808518 \u8981\u5c06\u4e0d\u540c\u7684\u51fd\u6570\u5e94\u7528\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u5217\u4e0a\uff0c\u9700\u8981\u5c06\u542b\u6709\u5217\u540d\u4e0e\u51fd\u6570\u5bf9\u5e94\u5173\u7cfb\u7684\u5b57\u5178\u4f20\u9012\u7ed9 agg \uff1a result = grouped.agg({'tip': np.max, 'size': 'sum'}) print(result) # tip size # day smoker # Fri No 3.50 9 # Yes 4.73 31 # Sat No 9.00 115 # Yes 10.00 104 # Sun No 6.00 167 # Yes 6.50 49 # Thur No 6.70 112 # Yes 5.00 40 result = grouped.agg({'tip_pct': ['min', 'max', 'mean', 'std']}) print(result) # tip_pct # min max mean std # day smoker # Fri No 0.136861 0.231125 0.179740 0.039458 # Yes 0.115518 0.357737 0.216293 0.077530 # Sat No 0.060217 0.412409 0.190412 0.058626 # Yes 0.036955 0.483092 0.179833 0.089496 # Sun No 0.063204 0.338101 0.193617 0.060302 # Yes 0.070274 2.452381 0.322021 0.538061 # Thur No 0.078704 0.362976 0.193424 0.056065 # Yes 0.098918 0.317965 0.198508 0.057170 \u53ea\u6709\u591a\u4e2a\u51fd\u6570\u5e94\u7528\u4e8e\u81f3\u5c11\u4e00\u4e2a\u5217\u65f6\uff0cDataFrame\u624d\u5177\u6709\u5206\u5c42\u5217\u3002","title":"\u9010\u5217\u53ca\u591a\u51fd\u6570\u5e94\u7528"},{"location":"python/DataAnalysis/ch07/#_9","text":"\u5728\u524d\u9762\u6240\u6709\u7684\u4f8b\u5b50\u4e2d\uff0c\u805a\u5408\u6570\u636e\u8fd4\u56de\u65f6\u90fd\u662f\u5e26\u6709\u7d22\u5f15\u7684\uff0c\u6709\u65f6\u7d22\u5f15\u662f\u5206\u5c42\u7684\uff0c\u7531\u552f\u4e00\u7684\u5206\u7ec4\u952e\u8054\u5408\u5f62\u6210\u3002 \u56e0\u4e3a\u4e0d\u662f\u6240\u6709\u7684\u60c5\u51b5\u4e0b\u90fd\u9700\u8981\u7d22\u5f15\uff0c\u6240\u4ee5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u53ef\u4ee5\u901a\u8fc7\u5411groupby\u4f20\u9012as_index=False\u6765\u7981\u7528\u5206\u7ec4\u952e\u4f5c\u4e3a\u7d22\u5f15\u7684\u884c\u4e3a\uff1a result = tips.groupby(['day', 'smoker'], as_index=False).mean() print(result) # day smoker total_bill tip size tip_pct # 0 Fri No 18.420000 2.812500 2.250000 0.179740 # 1 Fri Yes 16.813333 2.714000 2.066667 0.216293 # 2 Sat No 19.661778 3.102889 2.555556 0.190412 # 3 Sat Yes 21.276667 2.875476 2.476190 0.179833 # 4 Sun No 20.506667 3.167895 2.929825 0.193617 # 5 Sun Yes 24.120000 3.516842 2.578947 0.322021 # 6 Thur No 17.113111 2.673778 2.488889 0.193424 # 7 Thur Yes 19.190588 3.030000 2.352941 0.198508 \u901a\u8fc7\u5728\u7ed3\u679c\u4e0a\u8c03\u7528reset_index\u4e5f\u53ef\u4ee5\u83b7\u5f97\u540c\u6837\u7684\u7ed3\u679c\u3002\u4f7f\u7528as_index=False\u53ef\u4ee5\u907f\u514d\u4e00\u4e9b\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u3002 result = tips.groupby(['day', 'smoker']).mean() print(result.reset_index()) # day smoker total_bill tip size tip_pct # 0 Fri No 18.420000 2.812500 2.250000 0.179740 # 1 Fri Yes 16.813333 2.714000 2.066667 0.216293 # 2 Sat No 19.661778 3.102889 2.555556 0.190412 # 3 Sat Yes 21.276667 2.875476 2.476190 0.179833 # 4 Sun No 20.506667 3.167895 2.929825 0.193617 # 5 Sun Yes 24.120000 3.516842 2.578947 0.322021 # 6 Thur No 17.113111 2.673778 2.488889 0.193424 # 7 Thur Yes 19.190588 3.030000 2.352941 0.198508 print(result) # total_bill tip size tip_pct # day smoker # Fri No 18.420000 2.812500 2.250000 0.179740 # Yes 16.813333 2.714000 2.066667 0.216293 # Sat No 19.661778 3.102889 2.555556 0.190412 # Yes 21.276667 2.875476 2.476190 0.179833 # Sun No 20.506667 3.167895 2.929825 0.193617 # Yes 24.120000 3.516842 2.578947 0.322021 # Thur No 17.113111 2.673778 2.488889 0.193424 # Yes 19.190588 3.030000 2.352941 0.198508","title":"\u8fd4\u56de\u4e0d\u542b\u884c\u7d22\u5f15\u7684\u805a\u5408\u6570\u636e"},{"location":"python/DataAnalysis/ch07/#-","text":"import pandas as pd import numpy as np import statsmodels.api as sm GroupBy \u65b9\u6cd5\u6700\u5e38\u89c1\u7684\u76ee\u7684\u662f apply \uff08\u5e94\u7528\uff09\u3002 apply \u5c06\u5bf9\u8c61\u62c6\u5206\u6210\u591a\u5757\uff0c\u7136\u540e\u5728\u6bcf\u4e00\u5757\u4e0a\u8c03\u7528\u4f20\u9012\u7684\u51fd\u6570\uff0c\u4e4b\u540e\u5c1d\u8bd5\u5c06\u6bcf\u4e00\u5757\u62fc\u63a5\u5230\u4e00\u8d77\u3002 \u6839\u636e\u4e0b\u9762\u7684\u5c0f\u8d39\u6570\u636e\u96c6\uff0c\u6309\u7ec4\u9009\u51fa\u5c0f\u8d39\u767e\u5206\u6bd4\uff08tip-pct\uff09\u6700\u9ad8\u7684\u4e94\u7ec4\u3002 tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) \u6837\u672c\u6570\u636e print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u9996\u5148\uff0c\u5199\u4e00\u4e2a\u53ef\u4ee5\u5728\u7279\u5b9a\u5217\u4e2d\u9009\u51fa\u6700\u5927\u503c\u6240\u5728\u884c\u7684\u51fd\u6570\uff1a \u6dfb\u52a0\u4e86\u5347\u5e8f\uff0c\u7ed3\u679c\u8f93\u51fa\u6700\u540e5\u884c\uff08\u6700\u540e\u76845\u884c\u4e5f\u662f\u6700\u5927\u76845\u4e2a tip_tcp \u8bb0\u5f55\uff09\u3002 def top(df, n=5, column='tip_pct'): return df.sort_values(by=column, ascending=True)[-n:] result = top(tips, n=6) print(result) # \u7b49\u4ef7\u65b9\u5f0f\uff1a # result = tips.sort_values('tip_pct')[-6:] # print(result) # total_bill tip smoker day time size tip_pct # 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 \u5982\u679c\u6309\u7167 smoker \u8fdb\u884c\u5206\u7ec4\uff0c\u4e4b\u540e\u8c03\u7528 apply \uff0c\u4f1a\u5f97\u5230\u4ee5\u4e0b\u7ed3\u679c\uff1a top \u51fd\u6570\u5728DataFrame\u7684\u6bcf\u4e00\u884c\u5206\u7ec4\u4e0a\u88ab\u8c03\u7528\uff0c\u4e4b\u540e\u4f7f\u7528 pandas.concat \u5c06\u51fd\u6570\u7ed3\u679c\u7c98\u8d34\u5728\u4e00\u8d77\uff0c\u5e76\u4f7f\u7528\u5206\u7ec4\u540d\u4f5c\u4e3a\u5404\u7ec4\u7684\u6807\u7b7e\u3002 \u56e0\u6b64\u7ed3\u679c\u5305\u542b\u4e00\u4e2a\u5206\u5c42\u7d22\u5f15\uff0c\u8be5\u5206\u5c42\u7d22\u5f15\u7684\u5185\u90e8\u5c42\u7ea7\u5305\u542b\u539fDataFrame\u7684\u7d22\u5f15\u503c\u3002 result = tips.groupby('smoker').apply(top) print(result) # total_bill tip smoker day time size tip_pct # smoker # No 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # Yes 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 \u5982\u679c\u9664\u4e86\u5411 apply \u4f20\u9012\u51fd\u6570\uff0c\u8fd8\u4f20\u9012\u5176\u4ed6\u53c2\u6570\u6216\u5173\u952e\u5b57\u7684\u8bdd\uff0c\u4f60\u53ef\u4ee5\u628a\u8fd9\u4e9b\u653e\u5728\u51fd\u6570\u540e\u8fdb\u884c\u4f20\u9012\u3002 result = tips.groupby('smoker').apply(top, n=1, column='total_bill') print(result) # \u8fd92\u884c\u90fd\u662fsmoker\u662fyes\u548cno\u65f6\u6700\u5927total_bill\u503c\u6240\u5728\u884c\u3002 # total_bill tip smoker day time size tip_pct # smoker # No 212 48.33 9.0 No Sat Dinner 4 0.228833 # Yes 170 50.81 10.0 Yes Sat Dinner 3 0.245038 \u5728 GroupBy \u5bf9\u8c61\u4e0a\u8c03\u7528 describe \u65b9\u6cd5\u3002 result = tips.groupby('smoker')['tip_pct'].describe() print(result) # count mean std ... 50% 75% max # smoker ... # No 151.0 0.192237 0.057665 ... 0.184308 0.227015 0.412409 # Yes 93.0 0.218176 0.254295 ... 0.181818 0.242326 2.452381 # [2 rows x 8 columns] print(result.unstack('smoker')) # \u7c7b\u4f3c\u4e8e\u8f6c\u7f6e # smoker # count No 151.000000 # Yes 93.000000 # mean No 0.192237 # Yes 0.218176 # std No 0.057665 # Yes 0.254295 # min No 0.060217 # Yes 0.036955 # 25% No 0.158622 # Yes 0.119534 # 50% No 0.184308 # Yes 0.181818 # 75% No 0.227015 # Yes 0.242326 # max No 0.412409 # Yes 2.452381 # dtype: float64 \u5728 GroupBy \u5bf9\u8c61\u7684\u5185\u90e8\uff0c\u5f53\u8c03\u7528\u50cf describe \u8fd9\u6837\u7684\u65b9\u6cd5\u65f6\uff0c\u5b9e\u9645\u4e0a\u662f\u4ee5\u4e0b\u4ee3\u7801\u7684\u7b80\u5199\uff1a grouped = tips.groupby(['smoker']) f = lambda x: x.describe() result = grouped.apply(f) print(result) # total_bill tip size tip_pct # smoker # No count 151.000000 151.000000 151.000000 151.000000 # mean 19.188278 2.991854 2.668874 0.192237 # std 8.255582 1.377190 1.017984 0.057665 # min 7.250000 1.000000 1.000000 0.060217 # 25% 13.325000 2.000000 2.000000 0.158622 # 50% 17.590000 2.740000 2.000000 0.184308 # 75% 22.755000 3.505000 3.000000 0.227015 # max 48.330000 9.000000 6.000000 0.412409 # Yes count 93.000000 93.000000 93.000000 93.000000 # mean 20.756344 3.008710 2.408602 0.218176 # std 9.832154 1.401468 0.810751 0.254295 # min 3.070000 1.000000 1.000000 0.036955 # 25% 13.420000 2.000000 2.000000 0.119534 # 50% 17.920000 3.000000 2.000000 0.181818 # 75% 26.860000 3.680000 3.000000 0.242326 # max 50.810000 10.000000 5.000000 2.452381","title":"\u5e94\u7528\uff1a\u901a\u7528\u62c6\u5206-\u5e94\u7528-\u8054\u5408"},{"location":"python/DataAnalysis/ch07/#_10","text":"\u5728\u524d\u9762\u7684\u4f8b\u5b50\u4e2d\u6240\u5f97\u5230\u7684\u5bf9\u8c61\uff0c\u90fd\u5177\u6709\u5206\u7ec4\u952e\u6240\u5f62\u6210\u7684\u5206\u5c42\u7d22\u5f15\u4ee5\u53ca\u6bcf\u4e2a\u539f\u59cb\u5bf9\u8c61\u7684\u7d22\u5f15\u3002 \u4e5f\u53ef\u4ee5\u901a\u8fc7\u5411 groupby \u4f20\u9012 group_keys=False \u6765\u7981\u7528\u8fd9\u4e2a\u529f\u80fd\u3002 result = tips.groupby('smoker', group_keys=True).apply(top) print(result) # total_bill tip smoker day time size tip_pct # smoker # No 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # Yes 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381 result = tips.groupby('smoker', group_keys=False).apply(top) print(result) # total_bill tip smoker day time size tip_pct # 88 24.71 5.85 No Thur Lunch 2 0.310180 # 185 20.69 5.00 No Sun Dinner 5 0.318674 # 51 10.29 2.60 No Sun Dinner 2 0.338101 # 149 7.51 2.00 No Thur Lunch 2 0.362976 # 232 11.61 3.39 No Sat Dinner 2 0.412409 # 109 14.31 4.00 Yes Sat Dinner 2 0.387973 # 183 23.17 6.50 Yes Sun Dinner 4 0.389922 # 67 3.07 1.00 Yes Sat Dinner 1 0.483092 # 178 9.60 4.00 Yes Sun Dinner 2 0.714286 # 172 7.25 5.15 Yes Sun Dinner 2 2.452381","title":"\u538b\u7f29\u5206\u7ec4\u952e"},{"location":"python/DataAnalysis/ch07/#_11","text":"\u7b2c8\u7ae0\u4e2d\uff0cpandas\u6709\u4e00\u4e9b\u5de5\u5177\uff0c\u5c24\u5176\u662f cut \u548c qcut \uff0c\u7528\u4e8e\u5c06\u6570\u636e\u6309\u7167\u4f60\u9009\u62e9\u7684\u7bb1\u4f4d\u6216\u6837\u672c\u5206\u4f4d\u6570\u8fdb\u884c\u5206\u6876\u3002 \u4e0e groupby \u65b9\u6cd5\u4e00\u8d77\u4f7f\u7528\u8fd9\u4e9b\u51fd\u6570\u53ef\u4ee5\u5bf9\u6570\u636e\u96c6\u66f4\u65b9\u4fbf\u5730\u8fdb\u884c\u5206\u6876\u6216\u5206\u4f4d\u5206\u6790\u3002 \u590d\u4e60\uff1a\u673a\u68b0\u5b66\u4e60\u4e2d\u7684\u5206\u7bb1\u5904\u7406\u3002 \u5728\u673a\u68b0\u5b66\u4e60\u4e2d\u7ecf\u5e38\u4f1a\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7bb1\u5904\u7406\u7684\u64cd\u4f5c\uff0c \u4e5f\u5c31\u662f\u628a\u4e00\u6bb5\u8fde\u7eed\u7684\u503c\u5207\u5206\u6210\u82e5\u5e72\u6bb5\uff0c\u6bcf\u4e00\u6bb5\u7684\u503c\u770b\u6210\u4e00\u4e2a\u5206\u7c7b\u3002\u8fd9\u4e2a\u628a\u8fde\u7eed\u503c\u8f6c\u6362\u6210\u79bb\u6563\u503c\u7684\u8fc7\u7a0b\uff0c\u6211\u4eec\u53eb\u505a\u5206\u7bb1\u5904\u7406\u3002 \u6bd4\u5982\uff0c\u628a\u5e74\u9f84\u630915\u5c81\u5212\u5206\u6210\u4e00\u7ec4\uff0c0-15\u5c81\u53eb\u505a\u5c11\u5e74\uff0c16-30\u5c81\u53eb\u505a\u9752\u5e74\uff0c31-45\u5c81\u53eb\u505a\u58ee\u5e74\u3002\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u628a\u8fde\u7eed\u7684\u5e74\u9f84\u5206\u6210\u4e86\u4e09\u4e2a\u7c7b\u522b\uff0c\u201c\u5c11\u5e74\u201d\uff0c\u201c\u9752\u5e74\u201d\u548c\u201c\u58ee\u5e74\u201d\u5c31\u662f\u5404\u4e2a\u7c7b\u522b\u7684\u540d\u79f0\uff0c\u6216\u8005\u53eb\u505a\u6807\u7b7e\u3002 \u5728pandas\u4e2d\uff0c cut \u548c qcut \u51fd\u6570\u90fd\u53ef\u4ee5\u8fdb\u884c\u5206\u7bb1\u5904\u7406\u64cd\u4f5c\u3002 cut() \u6309\u7167\u53d8\u91cf\u7684\u503c\u5bf9\u53d8\u91cf\u8fdb\u884c\u5206\u5272\uff0c\u6bcf\u4e2a\u5206\u7ec4\u91cc\u6570\u636e\u7684\u4e2a\u6570\u5e76\u4e0d\u4e00\u6837\u3002 qcut() \u662f\u6309\u53d8\u91cf\u7684\u6570\u91cf\u6765\u5bf9\u53d8\u91cf\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u5c3d\u91cf\u4fdd\u8bc1\u6bcf\u4e2a\u5206\u7ec4\u91cc\u53d8\u91cf\u7684\u4e2a\u6570\u76f8\u540c\u3002 \u8003\u8651\u4e0b\u9762\u4e00\u4e2a\u7b80\u5355\u7684\u968f\u673a\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u4f7f\u7528 cut \u7684\u7b49\u957f\u6876\u5206\u7c7b\uff1a df = pd.DataFrame( { 'data1': np.random.randn(1000), 'data2': np.random.randn(1000) } ) quartiles = pd.cut(df.data1, 4) # \u6309\u7167data1\u503c\u7531\u5c0f\u5230\u5927\u7684\u987a\u5e8f\u5c06\u6570\u636e\u5206\u62104\u4efd\uff0c\u5e76\u4e14\u4f7f\u6bcf\u7ec4\u503c\u7684\u8303\u56f4\u5927\u81f4\u76f8\u7b49\u3002 print(quartiles[:10]) # 0 (-0.0743, 1.729] # 1 (-0.0743, 1.729] # 2 (-0.0743, 1.729] # 3 (-0.0743, 1.729] # 4 (-1.877, -0.0743] # 5 (-0.0743, 1.729] # 6 (-0.0743, 1.729] # 7 (-0.0743, 1.729] # 8 (-1.877, -0.0743] # 9 (-0.0743, 1.729] # Name: data1, dtype: category # Categories ( # 4, # interval[float64, right]): [ # (-3.687, -1.877] < (-1.877, -0.0743] < (-0.0743, 1.729] < (1.729, 3.531] # ] \u4e0a\u9762 cut \u8fd4\u56de\u7684 Categorical \u5bf9\u8c61\u53ef\u4ee5\u76f4\u63a5\u4f20\u9012\u7ed9 groupby \u3002\u5229\u7528\u5b83\u8ba1\u7b97\u51fa data2 \u5217\u7684\u4e00\u4e2a\u7edf\u8ba1\u503c\u96c6\u5408\uff0c\u5982\u4e0b\uff1a def get_stats(group): return { 'min': group.min(), 'max': group.max(), 'count': group.count(), 'mean': group.mean() } grouped = df.data2.groupby(quartiles) for i in grouped: print(i) result = grouped.apply(get_stats).unstack() print(result) # min max count mean # data1 # (-3.145, -1.424] -1.759377 2.484321 77.0 -0.127900 # (-1.424, 0.29] -3.142344 2.830654 524.0 -0.081931 # (0.29, 2.005] -3.557136 3.261635 376.0 0.015715 # (2.005, 3.719] -2.829458 1.766352 23.0 -0.198780 \u4f7f\u7528 qcut \uff0c\u6839\u636e\u6837\u672c\u5206\u4f4d\u6570\u8ba1\u7b97\u51fa\u7b49\u5927\u5c0f\u7684\u6876\uff0c\u5c31\u662f\u7b49\u957f\u6876\u3002\u901a\u8fc7\u4f20\u9012 labels=False \u6765\u83b7\u5f97\u5206\u4f4d\u6570\u6570\u503c\u3002 grouping = pd.qcut(df.data1, 10, labels=False) grouped = df.data2.groupby(grouping) result = grouped.apply(get_stats).unstack() print(result) # min max count mean # data1 # 0 -3.678934 3.022862 100.0 0.029658 # 1 -2.319813 2.646502 100.0 0.094035 # 2 -2.873727 2.470840 100.0 0.023866 # 3 -2.196701 2.042251 100.0 0.021232 # 4 -2.154161 2.020809 100.0 0.110834 # 5 -2.723061 2.415626 100.0 0.057365 # 6 -2.291470 2.536159 100.0 0.020866 # 7 -2.064083 1.799356 100.0 -0.081025 # 8 -3.405679 1.792581 100.0 -0.009705 # 9 -2.469285 2.600849 100.0 -0.061721","title":"\u5206\u4f4d\u6570\u4e0e\u6876\u5206\u6790"},{"location":"python/DataAnalysis/ch07/#_12","text":"\u5728\u6e05\u9664\u7f3a\u5931\u503c\u65f6\uff0c\u6709\u65f6\u4f1a\u4f7f\u7528 dropna \u6765\u53bb\u9664\u7f3a\u5931\u503c\uff0c\u6709\u65f6\u4f7f\u7528\u4fee\u6b63\u503c\u6216\u6765\u81ea\u4e8e\u5176\u4ed6\u6570\u636e\u7684\u503c\u6765\u8f93\u5165\uff08\u586b\u5145\uff09\u5230 null \u503c\uff08 NA \uff09\u3002 fillna \u662f\u4e00\u4e2a\u53ef\u4ee5\u4f7f\u7528\u7684\u6b63\u786e\u5de5\u5177\u3002 \u4f8b\u5982\u4e0b\u9762\u4f8b\u5b50\u4e2d\u4f7f\u7528\u4f7f\u7528\u5e73\u5747\u503c\u6765\u586b\u5145NA\u503c\uff1a data = (100, 110, 120, 130, 140, 150) s = pd.Series(data) print(s) # 0 100 # 1 110 # 2 120 # 3 130 # 4 140 # 5 150 # dtype: float64 \u5c06\u6570\u636e\u4e2d\u7684\u4e00\u4e9b\u503c\u8bbe\u7f6e\u4e3a\u7f3a\u5931\u503c\uff1a s[::2] = np.nan print(s) # 0 NaN # 1 110.0 # 2 NaN # 3 130.0 # 4 NaN # 5 150.0 # dtype: float64 result = s.fillna(s.mean()) # 110, 130, 150\u7684\u5e73\u5747\u503c\u662f130 print(result) # 0 130.0 # 1 110.0 # 2 130.0 # 3 130.0 # 4 130.0 # 5 150.0 # dtype: float64 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u6309\u7ec4\u586b\u5145NA\u503c\uff1a \u65b9\u6cd51,\u5bf9\u6570\u636e\u5206\u7ec4\u540e\u4f7f\u7528 apply \u3002 \u65b9\u6cd52,\u5728\u6bcf\u4e2a\u6570\u636e\u5757\u4e0a\u90fd\u8c03\u7528 fillna \u7684\u51fd\u6570\u3002 data = (100, 110, 120, 130, 140, 150, 160, 170) states = ['Ohio', 'New York', 'Vermont', 'Florida', 'Oregon', 'Nevada', 'California', 'Idaho'] group_key = ['East'] * 4 + ['West'] * 4 # 4\u4e2aEast\u548c4\u4e2aWest\u62fc\u63a5\u7684\u5217\u8868list s = pd.Series(data, index=states) print(s) # Ohio 100 # New York 110 # Vermont 120 # Florida 130 # Oregon 140 # Nevada 150 # California 160 # Idaho 170 # dtype: int64 \u5c06\u6570\u636e\u4e2d\u7684\u4e00\u4e9b\u503c\u8bbe\u7f6e\u4e3a\u7f3a\u5931\u503c\uff1a s[['Vermont', 'Nevada', 'Idaho']] = np.nan print(s) # Ohio 100.0 # New York 110.0 # Vermont NaN # Florida 130.0 # Oregon 140.0 # Nevada NaN # California 160.0 # Idaho NaN # dtype: float64 result = s.groupby(group_key).mean() print(result) # East 113.333333 # West 150.000000 # dtype: float64 \u7528\u4e0a\u9762\u5f97\u51fa\u7684\u5206\u7ec4\u5e73\u5747\u503c\u6765\u586b\u5145NA\u3002 fill_mean = lambda g: g.fillna(g.mean()) result = s.groupby(group_key).apply(fill_mean) print(result) # Ohio 100.000000 # New York 110.000000 # Vermont 113.333333 # Florida 130.000000 # Oregon 140.000000 # Nevada 150.000000 # California 160.000000 # Idaho 150.000000 # dtype: float64 \u5982\u679c\u5df2\u7ecf\u5728\u4ee3\u7801\u4e2d\u4e3a\u6bcf\u4e2a\u5206\u7ec4\u9884\u5b9a\u4e49\u4e86\u586b\u5145\u503c\uff0c\u53ef\u4ee5\u5229\u7528\u6bcf\u4e2a\u5206\u7ec4\u90fd\u6709\u7684\u5185\u7f6e\u7684 name \u5c5e\u6027\uff0c\u5b9e\u73b0\u586b\u5145 NA \u3002 fill_value = {'East': 0.5, 'West': -1} fill_func = lambda g: g.fillna(fill_value[g.name]) result = s.groupby(group_key).apply(fill_func) print(result) # Ohio 100.0 # New York 110.0 # Vermont 0.5 # Florida 130.0 # Oregon 140.0 # Nevada -1.0 # California 160.0 # Idaho -1.0 # dtype: float64","title":"\u793a\u4f8b\uff1a\u4f7f\u7528\u6307\u5b9a\u5206\u7ec4\u503c\u586b\u5145\u7f3a\u5931\u503c"},{"location":"python/DataAnalysis/ch07/#_13","text":"\u5047\u8bbe\u60f3\u4ece\u5927\u6570\u636e\u96c6\u4e2d\u62bd\u53d6\u968f\u673a\u6837\u672c\uff08\u6709\u6216\u6ca1\u6709\u66ff\u6362\uff09\u4ee5\u7528\u4e8e\u8499\u7279\u5361\u7f57\u6a21\u62df\u76ee\u7684\u6216\u67d0\u4e9b\u5176\u4ed6\u5e94\u7528\u7a0b\u5e8f\u3002 \u6709\u5f88\u591a\u65b9\u6cd5\u6765\u6267\u884c\u201c\u62bd\u53d6\u201d\uff0c\u8fd9\u91cc\u4f7f\u7528Series\u7684sample\u65b9\u6cd5\u3002 \u4e3a\u4e86\u6f14\u793a\uff0c\u8fd9\u91cc\u4ecb\u7ecd\u4e00\u79cd\u6784\u9020\u4e00\u526f\u82f1\u5f0f\u6251\u514b\u724c\u7684\u65b9\u6cd5\uff1a # \u6885\u82b1clubs\u3001\u65b9\u5757diamonds\u3001\u7ea2\u6843hearts\u3001\u9ed1\u6843spades\u3002 suits = ['H', 'S', 'C', 'D'] card_val = (list(range(1, 11)) + [10] * 3) * 4 # card_val [ # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, # 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10 # ] base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q'] # base_names\uff1a ['A', 2, 3, 4, 5, 6, 7, 8, 9, 10, 'J', 'K', 'Q'] \u751f\u6210\u4e86\u4e00\u4e2a\u957f\u5ea6\u4e3a 52 \u7684Series, Series\u7684\u7d22\u5f15\u5305\u542b\u4e86\u724c\u540d\uff0cSeries\u7684\u503c\u53ef\u4ee5\u7528\u6e38\u620f\uff08\u4e3a\u4e86\u4fdd\u6301\u7b80\u5355\uff0c\u8ba9\u2019A\u2019\u4e3a1 \uff09\uff1a cards = [] for suit in ['H', 'S', 'C', 'D']: cards.extend(str(num) + suit for num in base_names) deck = pd.Series(card_val, index=cards) print(deck) # AH 1 # 2H 2 # 3H 3 # 4H 4 # 5H 5 # 6H 6 # 7H 7 # 8H 8 # 9H 9 # 10H 10 # JH 10 # KH 10 # QH 10 # AS 1 # 2S 2 # 3S 3 # 4S 4 # 5S 5 # 6S 6 # 7S 7 # 8S 8 # 9S 9 # 10S 10 # JS 10 # KS 10 # QS 10 # AC 1 # 2C 2 # 3C 3 # 4C 4 # 5C 5 # 6C 6 # 7C 7 # 8C 8 # 9C 9 # 10C 10 # JC 10 # KC 10 # QC 10 # AD 1 # 2D 2 # 3D 3 # 4D 4 # 5D 5 # 6D 6 # 7D 7 # 8D 8 # 9D 9 # 10D 10 # JD 10 # KD 10 # QD 10 # dtype: int64 \u4ece\u8fd9\u526f\u724c\u4e2d\u62ff\u51fa\u4e94\u5f20\u724c\u53ef\u4ee5\u5199\u6210\uff1a def draw(_deck, n=5): return _deck.sample(n) print(draw(deck)) # KD 10 # 2S 2 # 5C 5 # 6C 6 # QD 10 # dtype: int64 \u5047\u8bbe\u8981\u4ece\u6bcf\u4e2a\u82b1\u8272\u4e2d\u968f\u673a\u62bd\u53d6\u4e24\u5f20\u724c\u3002\u7531\u4e8e\u82b1\u8272\u662f\u724c\u540d\u7684\u6700\u540e\u4e24\u4e2a\u5b57\u7b26\uff0c\u53ef\u4ee5\u57fa\u4e8e\u8fd9\u70b9\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u4f7f\u7528 apply \uff1a get_suit = lambda card: card[-1] # \u6700\u540e\u4e00\u4e2a\u5b57\u6bcd\u662f\u82b1\u8272 result = deck.groupby(get_suit).apply(draw, n=2) print(result) # C 10C 10 # 3C 3 # D KD 10 # AD 1 # H 5H 5 # 7H 7 # S 3S 3 # 5S 5 # dtype: int64 \u6216\u8005\u4e5f\u53ef\u4ee5\u5199\u6210\uff1a result = deck.groupby(get_suit, group_keys=False).apply(draw, n=2) print(result) # JC 10 # 8C 8 # QD 10 # 4D 4 # 10H 10 # 6H 6 # 7S 7 # KS 10 # dtype: int64","title":"\u793a\u4f8b\uff1a\u968f\u673a\u91c7\u6837\u4e0e\u6392\u5217"},{"location":"python/DataAnalysis/ch07/#_14","text":"\u5728 groupby \u7684\u62c6\u5206-\u5e94\u7528-\u8054\u5408\u7684\u8303\u5f0f\u4e0b\uff0cDataFrame\u7684\u5217\u95f4\u64cd\u4f5c\u6216\u4e24\u4e2aSeriese\u4e4b\u95f4\u7684\u64cd\u4f5c\uff0c\u4f8b\u5982\u5b9e\u73b0\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u3002 \u4e0b\u9762\u4f8b\u5b50\uff0c\u4f7f\u7528\u4e00\u4e2a\u5305\u542b\u5206\u7ec4\u952e\u548c\u6743\u91cd\u503c\u7684\u6570\u636e\u96c6\uff1a dt = np.random.randn(8) wt = np.random.randn(8) df = pd.DataFrame( { 'category': ['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'], 'data': dt, 'weight': wt } ) print(df) # category data weight # 0 a -0.250764 -0.085285 # 1 a 0.167155 -1.361254 # 2 a 0.399306 1.755542 # 3 a -0.514477 0.270124 # 4 b -0.005558 0.886514 # 5 b 0.607596 -1.384315 # 6 b -1.029627 -0.845340 # 7 b -0.294204 1.253965 \u901a\u8fc7 category \u8fdb\u884c\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u5982\u4e0b\uff1a grouped = df.groupby('category') get_wavg = lambda g: np.average(g['data'], weights=g['weight']) result = grouped.apply(get_wavg) print(result) # category # a 0.614499 # b 3.863947 # dtype: float64 \u53e6\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e00\u4e2a\u4ece\u96c5\u864e\u8d22\u7ecf\u4e0a\u83b7\u5f97\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e00\u4e9b\u6807\u666e500 \uff08SPX\u7b26\u53f7\uff09\u548c\u80a1\u7968\u7684\u6536\u76d8\u4ef7\uff1a close_px = pd.read_csv('../examples/stock_px_2.csv', parse_dates=True, index_col=0) print(close_px.info()) # <class 'pandas.core.frame.DataFrame'> # DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14 # Data columns (total 4 columns): # # Column Non-Null Count Dtype # --- ------ -------------- ----- # 0 AAPL 2214 non-null float64 # 1 MSFT 2214 non-null float64 # 2 XOM 2214 non-null float64 # 3 SPX 2214 non-null float64 # dtypes: float64(4) # memory usage: 86.5 KB # None print(close_px[-4:]) # AAPL MSFT XOM SPX # 2011-10-11 400.29 27.00 76.27 1195.54 # 2011-10-12 402.19 26.96 77.16 1207.25 # 2011-10-13 408.43 27.18 76.37 1203.66 # 2011-10-14 422.00 27.27 78.11 1224.58 \u76ee\u6807\u4efb\u52a1\uff1a\u8ba1\u7b97\u4e00\u4e2aDataFrame\uff0c\u5b83\u5305\u542b\u6807\u666e\u6307\u6570\uff08SPX\uff09\u6bcf\u65e5\u6536\u76ca\u7684\u5e74\u5ea6\u76f8\u5173\u6027\uff08\u901a\u8fc7\u767e\u5206\u6bd4\u53d8\u5316\u8ba1\u7b97\uff09\u3002 \u9996\u5148\u521b\u5efa\u4e00\u4e2a\u8ba1\u7b97\u6bcf\u5217\u4e0e\u2019SPX\u2019\u5217\u6210\u5bf9\u5173\u8054\u7684\u51fd\u6570\uff1a spx_corr = lambda x: x.corrwith(x['SPX']) \u4e4b\u540e\uff0c\u4f7f\u7528 pct_change \u8ba1\u7b97 close-px \u767e\u5206\u6bd4\u7684\u53d8\u5316\uff1a rets = close_px.pct_change().dropna() # Percentage change between the current and a prior element. print(rets) # AAPL MSFT XOM SPX # 2003-01-03 0.006757 0.001421 0.000684 -0.000484 # 2003-01-06 0.000000 0.017975 0.024624 0.022474 # ... ... ... ... ... # 2011-10-14 0.033225 0.003311 0.022784 0.017380 # [2213 rows x 4 columns] \u6700\u540e\uff0c\u6309\u5e74\u5bf9\u767e\u5206\u6bd4\u53d8\u5316\u8fdb\u884c\u5206\u7ec4\uff0c\u53ef\u4ee5\u4f7f\u7528\u5355\u884c\u51fd\u6570\u4ece\u6bcf\u4e2a\u884c\u6807\u7b7e\u4e2d\u63d0\u53d6\u6bcf\u4e2a datetime \u6807\u7b7e\u7684 year \u5c5e\u6027\uff1a get_year = lambda x: x.year by_year = rets.groupby(get_year) result = by_year.apply(spx_corr) print(result) # AAPL MSFT XOM SPX # 2003 0.541124 0.745174 0.661265 1.0 # 2004 0.374283 0.588531 0.557742 1.0 # 2005 0.467540 0.562374 0.631010 1.0 # 2006 0.428267 0.406126 0.518514 1.0 # 2007 0.508118 0.658770 0.786264 1.0 # 2008 0.681434 0.804626 0.828303 1.0 # 2009 0.707103 0.654902 0.797921 1.0 # 2010 0.710105 0.730118 0.839057 1.0 # 2011 0.691931 0.800996 0.859975 1.0 \u53ef\u4ee5\u8ba1\u7b97\u5185\u90e8\u5217\u76f8\u5173\u6027\u3002\u8fd9\u91cc\u8ba1\u7b97\u4e86\u82f9\u679c\u548c\u5fae\u8f6f\u7684\u5e74\u5ea6\u76f8\u5173\u6027\uff1a result = by_year.apply(lambda g: g['AAPL'].corr(g['MSFT'])) print(result) # 2003 0.480868 # 2004 0.259024 # 2005 0.300093 # 2006 0.161735 # 2007 0.417738 # 2008 0.611901 # 2009 0.432738 # 2010 0.571946 # 2011 0.581987 # dtype: float64","title":"\u793a\u4f8b\uff1a\u5206\u7ec4\u52a0\u6743\u5e73\u5747\u548c\u76f8\u5173\u6027"},{"location":"python/DataAnalysis/ch07/#_15","text":"\u5b9a\u4e49\u4ee5\u4e0b regress \uff08\u56de\u5f52\uff09\u51fd\u6570\uff08\u4f7f\u7528 statsmodels \u8ba1\u91cf\u7ecf\u6d4e\u5b66\u5e93\uff09\uff0c\u8be5\u51fd\u6570\u5bf9\u6bcf\u4e2a\u6570\u636e\u5757\u6267\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\uff08OLS\uff09\u56de\u5f52\uff1a def regress(data, yvar, xvars): Y = data[yvar] X = data[xvars] X['intercept'] = 1. result = sm.OLS(Y, X).fit() return result.params \u73b0\u5728\u8981\u8ba1\u7b97AAPL\u5728SPX\u56de\u62a5\u4e0a\u7684\u5e74\u5ea6\u7ebf\u6027\u56de\u5f52\uff1a result = by_year.apply(regress, 'AAPL', ['SPX']) print(result) # SPX intercept # 2003 1.195406 0.000710 # 2004 1.363463 0.004201 # 2005 1.766415 0.003246 # 2006 1.645496 0.000080 # 2007 1.198761 0.003438 # 2008 0.968016 -0.001110 # 2009 0.879103 0.002954 # 2010 1.052608 0.001261 # 2011 0.806605 0.001514","title":"\u793a\u4f8b\uff1a\u9010\u7ec4\u7ebf\u6027\u56de\u5f52"},{"location":"python/DataAnalysis/ch07/#_16","text":"","title":"\u6570\u636e\u900f\u89c6\u8868\u4e0e\u4ea4\u53c9\u8868"},{"location":"python/DataAnalysis/ch07/#_17","text":"\u6570\u636e\u900f\u89c6\u8868\u662f\u7535\u5b50\u8868\u683c\u7a0b\u5e8f\u548c\u5176\u4ed6\u6570\u636e\u5206\u6790\u8f6f\u4ef6\u4e2d\u5e38\u89c1\u7684\u6570\u636e\u6c47\u603b\u5de5\u5177\u3002 \u5b83\u6839\u636e\u4e00\u4e2a\u6216\u591a\u4e2a\u952e\u805a\u5408\u4e00\u5f20\u8868\u7684\u6570\u636e\uff0c\u5c06\u6570\u636e\u5728\u77e9\u5f62\u683c\u5f0f\u4e2d\u6392\u5217\uff0c\u5176\u4e2d\u4e00\u4e9b\u5206\u7ec4\u952e\u662f\u6cbf\u7740\u884c\u7684\uff0c\u53e6\u4e00\u4e9b\u662f\u6cbf\u7740\u5217\u7684\u3002 Python\u4e2d\u7684pandas\u900f\u89c6\u8868\u662f\u901a\u8fc7\u8fd9\u91cc\u6240\u4ecb\u7ecd\u7684groupby\u5de5\u5177\u4ee5\u53ca\u4f7f\u7528\u5206\u5c42\u7d22\u5f15\u7684\u91cd\u5851\u64cd\u4f5c\u5b9e\u73b0\u7684\u3002 DataFrame\u62e5\u6709\u4e00\u4e2a pivot_table \u65b9\u6cd5\uff0c\u5e76\u4e14\u8fd8\u6709\u8fd8\u4e00\u4e2a\u9876\u5c42\u7684 pandas.pivot_table \u51fd\u6570\u3002 \u9664\u4e86\u4e3a groupby \u63d0\u4f9b\u4e00\u4e2a\u65b9\u4fbf\u63a5\u53e3\uff0c pivot_table \u8fd8\u53ef\u4ee5\u6dfb\u52a0\u90e8\u5206\u603b\u8ba1\uff0c\u4e5f\u79f0\u4f5c\u8fb9\u8ddd\u3002 import pandas as pd import numpy as np \u6839\u636e\u4e0b\u9762\u7684\u5c0f\u8d39\u6570\u636e\u96c6\uff0c\u8ba1\u7b97\u4e00\u5f20\u5728\u884c\u65b9\u5411\u4e0a\u6309 day \u548c smoker \u6392\u5217\u7684\u5206\u7ec4\u5e73\u5747\u503c\uff08\u9ed8\u8ba4\u7684 pivot_table \u805a\u5408\u7c7b\u578b\uff09\u7684\u8868\u3002 pivot_table \u9009\u9879\uff1a values: \u9700\u8981\u805a\u5408\u7684\u5217\u540d\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u805a\u5408\u6240\u6709\u6570\u503c\u578b\u7684\u5217\u3002 index: \u5728\u7ed3\u679c\u900f\u89c6\u8868\u7684\u884c\u4e0a\u8fdb\u884c\u5206\u7ec4\u7684\u5217\u540d\u6216\u8005\u5176\u4ed6\u5206\u7ec4\u952e\u3002 tips = pd.read_csv('../examples/tips.csv') tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip']) \u6837\u672c\u6570\u636e\u3002 print(tips.head(5)) # total_bill tip smoker day time size tip_pct # 0 16.99 1.01 No Sun Dinner 2 0.063204 # 1 10.34 1.66 No Sun Dinner 3 0.191244 # 2 21.01 3.50 No Sun Dinner 3 0.199886 # 3 23.68 3.31 No Sun Dinner 2 0.162494 # 4 24.59 3.61 No Sun Dinner 4 0.172069 \u8ba1\u7b97\u5728\u884c\u65b9\u5411\u4e0a\u6309 day \u548c smoker \u6392\u5217\u7684\u5206\u7ec4\u5e73\u5747\u503c\u3002\u4e5f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 groupby \u5b9e\u73b0\u3002 result = tips.pivot_table(index=['day', 'smoker']) print(result) # size tip tip_pct total_bill # day smoker # Fri No 2.250000 2.812500 0.179740 18.420000 # Yes 2.066667 2.714000 0.216293 16.813333 # Sat No 2.555556 3.102889 0.190412 19.661778 # Yes 2.476190 2.875476 0.179833 21.276667 # Sun No 2.929825 3.167895 0.193617 20.506667 # Yes 2.578947 3.516842 0.322021 24.120000 # Thur No 2.488889 2.673778 0.193424 17.113111 # Yes 2.352941 3.030000 0.198508 19.190588 \u5728 tip_pct \u548c size \u4e0a\u8fdb\u884c\u805a\u5408\uff0c\u5e76\u6839\u636e time \u5206\u7ec4\u3002\u5c06\u628a smoker \u653e\u5165\u8868\u7684\u5217\uff0c\u800c\u5c06 day \u653e\u5165\u8868\u7684\u884c\uff1a result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker' ) print(result) # size tip_pct # smoker No Yes No Yes # time day # Dinner Fri 2.000000 2.222222 0.162612 0.202545 # Sat 2.555556 2.476190 0.190412 0.179833 # Sun 2.929825 2.578947 0.193617 0.322021 # Thur 2.000000 NaN 0.190114 NaN # Lunch Fri 3.000000 1.833333 0.231125 0.236915 # Thur 2.500000 2.352941 0.193499 0.198508 \u901a\u8fc7\u4f20\u9012 margins=True \u6765\u6269\u5145\u8fd9\u4e2a\u8868\u6765\u5305\u542b\u90e8\u5206\u603b\u8ba1\u3002\u8fd9\u4f1a\u6dfb\u52a0 All \u884c\u548c\u5217\u6807\u7b7e\uff0c\u5176\u4e2d\u76f8\u5e94\u7684\u503c\u662f\u5355\u5c42\u4e2d\u6240\u6709\u6570\u636e\u7684\u5206\u7ec4\u7edf\u8ba1\u503c\u3002 \u8fd9\u91cc All \u7684\u503c\u662f\u5747\u503c\uff0c\u4e14\u8be5\u5747\u503c\u662f\u4e0d\u8003\u8651\u5438\u70df\u8005\u4e0e\u975e\u5438\u70df\u8005\uff08 All \u5217\uff09\u6216\u884c\u5206\u7ec4\u4e2d\u4efb\u4f55\u4e24\u7ea7\u7684\uff08 All \u884c\uff09\u3002 result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 2.000000 2.222222 2.166667 0.162612 0.202545 0.192562 # Sat 2.555556 2.476190 2.517241 0.190412 0.179833 0.185305 # Sun 2.929825 2.578947 2.842105 0.193617 0.322021 0.225718 # Thur 2.000000 NaN 2.000000 0.190114 NaN 0.190114 # Lunch Fri 3.000000 1.833333 2.000000 0.231125 0.236915 0.236088 # Thur 2.500000 2.352941 2.459016 0.193499 0.198508 0.194895 # All 2.668874 2.408602 2.569672 0.192237 0.218176 0.202123 \u8981\u4f7f\u7528\u4e0d\u540c\u7684\u805a\u5408\u51fd\u6570\u65f6\uff0c\u5c06\u51fd\u6570\u4f20\u9012\u7ed9 aggfunc \u3002\u4f8b\u5982\uff0c count \u6216\u8005 len \u5c06\u7ed9\u51fa\u4e00\u5f20\u5206\u7ec4\u5927\u5c0f\u7684\u4ea4\u53c9\u8868\uff08\u8ba1\u6570\u6216\u51fa\u73b0\u9891\u7387\uff09\uff1a result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', aggfunc=len, margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 3.0 9.0 12 3.0 9.0 12 # Sat 45.0 42.0 87 45.0 42.0 87 # Sun 57.0 19.0 76 57.0 19.0 76 # Thur 1.0 NaN 1 1.0 NaN 1 # Lunch Fri 1.0 6.0 7 1.0 6.0 7 # Thur 44.0 17.0 61 44.0 17.0 61 # All 151.0 93.0 244 151.0 93.0 244 \u5bf9\u4e8e\u7a7a\u503c NA \uff0c\u4f20\u9012\u4e00\u4e2a fill_value \u3002 result = tips.pivot_table( ['tip_pct', 'size'], index=['time', 'day'], columns='smoker', aggfunc='mean', fill_value=0, margins=True ) print(result) # size tip_pct # smoker No Yes All No Yes All # time day # Dinner Fri 2.000000 2.222222 2.166667 0.162612 0.202545 0.192562 # Sat 2.555556 2.476190 2.517241 0.190412 0.179833 0.185305 # Sun 2.929825 2.578947 2.842105 0.193617 0.322021 0.225718 # Thur 2.000000 0.000000 2.000000 0.190114 0.000000 0.190114 # Lunch Fri 3.000000 1.833333 2.000000 0.231125 0.236915 0.236088 # Thur 2.500000 2.352941 2.459016 0.193499 0.198508 0.194895 # All 2.668874 2.408602 2.569672 0.192237 0.218176 0.202123","title":"\u6570\u636e\u900f\u89c6\u8868"},{"location":"python/DataAnalysis/ch07/#crosstab","text":"\u4ea4\u53c9\u8868\uff08\u7b80\u5199\u4e3acrosstab\uff09\u662f\u6570\u636e\u900f\u89c6\u8868\u7684\u4e00\u4e2a\u7279\u6b8a\u60c5\u51b5\uff0c\u8ba1\u7b97\u7684\u662f\u5206\u7ec4\u4e2d\u7684\u9891\u7387\u3002 crosstab \u7684\u524d\u4e24\u4e2a\u53c2\u6570\u53ef\u662f\u6570\u7ec4\u3001Series\u6216\u6570\u7ec4\u7684\u5217\u8868\u3002 sample = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] nationality = ['USA', 'Japan', 'USA', 'Japan', 'Japan', 'Japan', 'USA', 'USA', 'Japan', 'USA'] handedness = ['Right-handed', 'Left-handed', 'Right-handed', 'Right-handed', 'Left-handed', 'Right-handed', 'Right-handed', 'Left-handed', 'Right-handed', 'Right-handed'] df = pd.DataFrame( { 'sample': sample, 'nationality': nationality, 'handedness': handedness } ) print(df) # sample nationality handedness # 0 1 USA Right-handed # 1 2 Japan Left-handed # 2 3 USA Right-handed # 3 4 Japan Right-handed # 4 5 Japan Left-handed # 5 6 Japan Right-handed # 6 7 USA Right-handed # 7 8 USA Left-handed # 8 9 Japan Right-handed # 9 10 USA Right-handed \u6309\u7167\u56fd\u7c4d\u548c\u60ef\u7528\u6027\u6765\u603b\u7ed3\u8fd9\u4e9b\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528 pivot_table \u6765\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u4f46\u662f pandas.crosstable \u51fd\u6570\u66f4\u4e3a\u65b9\u4fbf\uff1a result = pd.crosstab(df.nationality, df.handedness, margins=True) print(result) # handedness Left-handed Right-handed All # nationality # Japan 2 3 5 # USA 1 4 5 # All 3 7 10 \u5728\u5c0f\u8d39\u6570\u636e\u4e2d\u53ef\u4ee5\u8fd9\u4e48\u505a\uff1a result = pd.crosstab(['tips.time', tips.day], tips.smoker, margins=True) print(result) # smoker No Yes All # row_0 day # tips.time Fri 4 15 19 # Sat 45 42 87 # Sun 57 19 76 # Thur 45 17 62 # All 151 93 244","title":"\u4ea4\u53c9\u8868\uff1acrosstab"},{"location":"python/DataAnalysis/ch08/","text":"\u65f6\u95f4\u5e8f\u5217 \u65e5\u671f\u548c\u65f6\u95f4\u6570\u636e\u7684\u7c7b\u578b\u53ca\u5de5\u5177 \u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5f88\u591a\u9886\u57df\u90fd\u662f\u91cd\u8981\u7684\u7ed3\u6784\u5316\u6570\u636e\u5f62\u5f0f\u3002\u5728\u591a\u4e2a\u65f6\u95f4\u70b9\u89c2\u6d4b\u6216\u6d4b\u91cf\u7684\u6570\u636e\u5f62\u6210\u4e86\u65f6\u95f4\u5e8f\u5217\u3002 \u8bb8\u591a\u65f6\u95f4\u5e8f\u5217\u662f\u56fa\u5b9a\u9891\u7387\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u6570\u636e\u662f\u6839\u636e\u76f8\u540c\u7684\u89c4\u5219\u5b9a\u671f\u51fa\u73b0\u7684\uff0c\u4f8b\u5982\u6bcf15\u79d2\u3001\u6bcf5\u5206\u949f\u6216\u6bcf\u67081\u6b21\u3002 \u65f6\u95f4\u5e8f\u5217\u4e5f\u53ef\u4ee5\u662f\u4e0d\u89c4\u5219\u7684\uff0c\u6ca1\u6709\u56fa\u5b9a\u7684\u65f6\u95f4\u5355\u4f4d\u6216\u5355\u4f4d\u95f4\u7684\u504f\u79fb\u91cf\u3002 \u5982\u4f55\u6807\u8bb0\u548c\u5f15\u7528\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53d6\u51b3\u4e8e\u5e94\u7528\u7a0b\u5e8f\uff0c\u65f6\u95f4\u5e8f\u5217\u5305\u62ec\uff1a \u65f6\u95f4\u6233\uff0c\u5177\u4f53\u7684\u65f6\u523b\u3002 \u56fa\u5b9a\u7684\u65f6\u95f4\u533a\u95f4\uff0c\u4f8b\u59822007\u76841\u6708\u6216\u6574\u4e2a2010\u5e74\u3002 \u65f6\u95f4\u95f4\u9694\uff0c\u7531\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u6233\u8868\u793a\u3002\u65f6\u95f4\u533a\u95f4\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u95f4\u9694\u7684\u7279\u6b8a\u60c5\u51b5\u3002 \u5b9e\u9a8c\u65f6\u95f4\u6216\u6d88\u8017\u65f6\u95f4\u3002\u6bcf\u4e2a\u65f6\u95f4\u6233\u662f\u76f8\u5bf9\u4e8e\u7279\u5b9a\u5f00\u59cb\u65f6\u95f4\u7684\u65f6\u95f4\u7684\u91cf\u5ea6\uff08\u4f8b\u5982\uff0c\u81ea\u4ece\u88ab\u653e\u7f6e\u5728\u70e4\u7bb1\u4e2d\u6bcf\u79d2\u70d8\u70e4\u7684\u997c\u5e72\u7684\u76f4\u5f84\uff09\u3002 \u76ee\u524d\u4e3b\u8981\u5173\u6ce8\u524d\u4e09\u7c7b\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u3002 from datetime import datetime, timedelta import datetime as dt from dateutil.parser import parse import pandas as pd datetime datetime\u683c\u5f0f\u7b26\uff1a %a \u661f\u671f\u7684\u82f1\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u661f\u671f\u4e00\uff0c \u5219\u8fd4\u56de Mon %A \u661f\u671f\u7684\u82f1\u6587\u5355\u8bcd\u7684\u5168\u62fc\uff1a\u5982\u661f\u671f\u4e00\uff0c\u8fd4\u56de Monday %b \u6708\u4efd\u7684\u82f1\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u4e00\u6708\uff0c \u5219\u8fd4\u56de Jan %B \u6708\u4efd\u7684\u5f15\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u4e00\u6708\uff0c \u5219\u8fd4\u56de January %c \u8fd4\u56dedatetime\u7684\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u598203/08/15 23:01:26 %d \u8fd4\u56de\u7684\u662f\u5f53\u524d\u65f6\u95f4\u662f\u5f53\u524d\u6708\u7684\u7b2c\u51e0\u5929 %f \u5fae\u79d2\u7684\u8868\u793a\uff1a \u8303\u56f4: [0,999999] %H \u4ee524\u5c0f\u65f6\u5236\u8868\u793a\u5f53\u524d\u5c0f\u65f6 %I \u4ee512\u5c0f\u65f6\u5236\u8868\u793a\u5f53\u524d\u5c0f\u65f6 %m \u8fd4\u56de\u6708\u4efd \u8303\u56f4[0,12] %M \u8fd4\u56de\u5206\u949f\u6570 \u8303\u56f4 [0,59] %P \u8fd4\u56de\u662f\u4e0a\u5348\u8fd8\u662f\u4e0b\u5348\u2013AM or PM %S \u8fd4\u56de\u79d2\u6570 \u8303\u56f4 [0,61]\u3002\u3002\u3002\u624b\u518c\u8bf4\u660e\u7684 %U \u8fd4\u56de\u5f53\u5468\u662f\u5f53\u5e74\u7684\u7b2c\u51e0\u5468 \u4ee5\u5468\u65e5\u4e3a\u7b2c\u4e00\u5929 %W \u8fd4\u56de\u5f53\u5468\u662f\u5f53\u5e74\u7684\u7b2c\u51e0\u5468 \u4ee5\u5468\u4e00\u4e3a\u7b2c\u4e00\u5929 %w \u5f53\u5929\u5728\u5f53\u5468\u7684\u5929\u6570\uff0c\u8303\u56f4\u4e3a[0, 6]\uff0c6\u8868\u793a\u661f\u671f\u5929 %x \u65e5\u671f\u7684\u5b57\u7b26\u4e32\u8868\u793a \uff1a03/08/15 %X \u65f6\u95f4\u7684\u5b57\u7b26\u4e32\u8868\u793a \uff1a23:22:08 %y \u4e24\u4e2a\u6570\u5b57\u8868\u793a\u7684\u5e74\u4efd 15 %Y \u56db\u4e2a\u6570\u5b57\u8868\u793a\u7684\u5e74\u4efd 2015 %z \u4e0eutc\u65f6\u95f4\u7684\u95f4\u9694 \uff08\u5982\u679c\u662f\u672c\u5730\u65f6\u95f4\uff0c\u8fd4\u56de\u7a7a\u5b57\u7b26\u4e32\uff09 %Z \u65f6\u533a\u540d\u79f0\uff08\u5982\u679c\u662f\u672c\u5730\u65f6\u95f4\uff0c\u8fd4\u56de\u7a7a\u5b57\u7b26\u4e32\uff09 datestrs = ['2020/5/6', '2021/10/1'] # \u6ce8\u610f\u533a\u5206datetime\u6a21\u5757\u548cdatetime\u7c7b\uff0c\u540d\u5b57\u76f8\u540c\uff0c\u5bb9\u6613\u5f15\u8d77\u9519\u8bef\u3002 # \u6bd4\u5982datetime.datetime\u5c31\u62a5\u9519type object 'datetime.datetime' has no attribute 'datetime' print(datetime) # <class 'datetime.datetime'> print(dt) # <module 'datetime' from '/opt/Python-3.9.6/Lib/datetime.py'> Python\u6807\u51c6\u5e93\u5305\u542b\u4e86\u65e5\u671f\u548c\u65f6\u95f4\u6570\u636e\u7684\u7c7b\u578b\u3002 datetime \u3001 time \u548c calendar \u6a21\u5757\u662f\u5f00\u59cb\u5904\u7406\u65f6\u95f4\u6570\u636e\u7684\u4e3b\u8981\u5185\u5bb9\u3002 datetime.datetime \u7c7b\u578b\uff0c\u6216\u7b80\u5199\u4e3a datetime \uff0c\u662f\u5e7f\u6cdb\u4f7f\u7528\u7684\u3002 now = datetime.now() print(now) # 2021-10-07 20:24:43.834293 result = dt.datetime(2021, 10, 7, 20, 26, 00, 72973) print(result) # 2021-10-07 20:26:00.072973 datetime \u65e2\u5b58\u50a8\u4e86\u65e5\u671f\uff0c\u4e5f\u5b58\u50a8\u4e86\u7ec6\u5316\u5230\u5fae\u79d2\u7684\u65f6\u95f4\u3002 timedelta \u8868\u793a\u4e24\u4e2a datetime \u5bf9\u8c61\u7684\u65f6\u95f4\u5dee\u3002 delta = datetime(2021, 10, 7) - datetime(2021, 9, 7) print(delta) # 30 days, 0:00:00 print(delta.days) # 30 print(delta.seconds) # 0 result = dt.timedelta(926, 56700) print(result) # 926 days, 15:45:00 \u53ef\u4ee5\u4e3a\u4e00\u4e2a datetime \u5bf9\u8c61\u52a0\u4e0a\uff08\u6216\u51cf\u53bb\uff09\u4e00\u4e2a timedelta \u6216\u5176\u6574\u6570\u500d\u6765\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684 datetime \u5bf9\u8c61\u3002 start = datetime(2021, 10, 7) result = start + timedelta(12) print(result) # 2021-10-19 00:00:00 result = start - 2 * timedelta(5) print(result) # 2021-09-27 00:00:00 \u5b57\u7b26\u4e32\u4e0edatetime\u4e92\u76f8\u8f6c\u6362 \u4f7f\u7528 str \u65b9\u6cd5\u6216\u4f20\u9012\u4e00\u4e2a\u6307\u5b9a\u7684\u683c\u5f0f\u7ed9 strftime \u65b9\u6cd5\u6765\u5bf9 datetime \u5bf9\u8c61\u548cpandas\u7684 Timestamp \u5bf9\u8c61\u8fdb\u884c\u683c\u5f0f\u5316\u3002 stamp = datetime(2021, 10, 7) result = str(stamp) print(result) # 2021-10-07 00:00:00 \u4f7f\u7528 datetime.srtptime \u548c datetime \u683c\u5f0f\u7b26\uff0c\u628a\u5b57\u7b26\u4e32\u8f6c\u6362\u65e5\u671f\u3002 datetime.strptime \u662f\u5728\u5df2\u77e5\u683c\u5f0f\u7684\u60c5\u51b5\u4e0b\u8f6c\u6362\u65e5\u671f\u7684\u597d\u65b9\u5f0f\u3002 value = '2021-10-7' result = datetime.strptime(value, '%Y-%m-%d') print(result) # 2021-10-07 00:00:00 datestrs = ['2020/5/6', '2021/10/1'] result = [datetime.strptime(x, '%Y/%m/%d') for x in datestrs] print(result) # [datetime.datetime(2020, 5, 6, 0, 0), datetime.datetime(2021, 10, 1, 0, 0)] dateutil \u89e3\u6790\u901a\u7528\u65e5\u671f\u683c\u5f0f\uff1a print(parse('2020/5/6')) # 2020-05-06 00:00:00 print(parse('Jan 31, 2021 10:25 AM')) # 2021-01-31 10:25:00 print(parse('5/6/2021', dayfirst=True)) # \u65e5\u671f\u51fa\u73b0\u5728\u6708\u4efd\u4e4b\u524d # 2021-06-05 00:00:00 pandas\u4e3b\u8981\u662f\u9762\u5411\u5904\u7406\u65e5\u671f\u6570\u7ec4\u7684\uff0c\u65e0\u8bba\u662f\u7528\u4f5c\u8f74\u7d22\u5f15\u8fd8\u662f\u7528\u4f5cDataFrame\u4e2d\u7684\u5217\u3002 to_datetime \u65b9\u6cd5\u53ef\u4ee5\u8f6c\u6362\u5f88\u591a\u4e0d\u540c\u7684\u65e5\u671f\u8868\u793a\u683c\u5f0f\u3002 to_datetime \u65b9\u6cd5\u8fd8\u53ef\u4ee5\u5904\u7406\u90a3\u4e9b\u88ab\u8ba4\u4e3a\u662f\u7f3a\u5931\u503c\u7684\u503c\uff08None\u3001\u7a7a\u5b57\u7b26\u4e32\u7b49\uff09\u3002 NaT \uff08Not a time\uff09\u662fpandas\u4e2d\u65f6\u95f4\u6233\u6570\u636e\u7684\u662fnull\u503c\u3002 datestrs = ['2020/5/6 12:00:00', '2021/10/1 09:00:00'] result = pd.to_datetime(datestrs) print(result) # DatetimeIndex(['2020-05-06 12:00:00', '2021-10-01 09:00:00'], dtype='datetime64[ns]', freq=None) idx = pd.to_datetime(datestrs + [None]) print(idx) # DatetimeIndex(['2020-05-06 12:00:00', '2021-10-01 09:00:00', 'NaT'], dtype='datetime64[ns]', freq=None) print(idx[2]) # NaT print(pd.isnull(idx)) # [False False True] \u65f6\u95f4\u5e8f\u5217\u57fa\u7840 from datetime import datetime import pandas as pd import numpy as np DatetimeIndex pandas\u4e2d\u7684\u57fa\u7840\u65f6\u95f4\u5e8f\u5217\u79cd\u7c7b\u662f\u7531\u65f6\u95f4\u6233\u7d22\u5f15\u7684Series\uff0c\u5728pandas\u5916\u90e8\u5219\u901a\u5e38\u8868\u793a\u4e3aPython\u5b57\u7b26\u4e32\u6216 datetime \u5bf9\u8c61\u3002 \u6240\u6709\u4f7f\u7528 datetime \u5bf9\u8c61\u7684\u5730\u65b9\u90fd\u53ef\u4ee5\u7528 Timestamp \u3002 dates = [ datetime(2021, 10, 1), datetime(2021, 10, 3), datetime(2021, 10, 5), datetime(2021, 10, 7), datetime(2021, 10, 9), datetime(2021, 10, 11) ] data = np.random.rand(6) ts = pd.Series(data, index=dates) print(ts) # 2021-10-01 0.678297 # 2021-10-03 0.538631 # 2021-10-05 0.934413 # 2021-10-07 0.018534 # 2021-10-09 0.938441 # 2021-10-11 0.173329 # dtype: float64 \u8fd9\u4e9b datetime \u5bf9\u8c61\u88ab\u653e\u5165 DatetimeIndex \u4e2d\u3002 print(ts.index) # DatetimeIndex(['2021-10-01', '2021-10-03', '2021-10-05', '2021-10-07', # '2021-10-09', '2021-10-11'], # dtype='datetime64[ns]', freq=None) DatetimeIndex \u4e2d\u7684\u6807\u91cf\u503c\u662f pandas \u7684 Timestamp \u5bf9\u8c61\uff1a stamp = ts.index[0] print(stamp) # 2021-10-01 00:00:00 \u548c\u5176\u4ed6Series\u7c7b\u4f3c\uff0c\u4e0d\u540c\u7d22\u5f15\u7684\u65f6\u95f4\u5e8f\u5217\u4e4b\u95f4\u7684\u7b97\u672f\u8fd0\u7b97\u5728\u65e5\u671f\u4e0a\u81ea\u52a8\u5bf9\u9f50\uff1a print(ts + ts[::2]) # ts[::2]\u4f1a\u5c06ts\u4e2d\u6bcf\u9694\u4e00\u4e2a\u7684\u5143\u7d20\u9009\u62e9\u51fa # 2021-10-01 1.356595 # 2021-10-03 NaN # 2021-10-05 1.868825 # 2021-10-07 NaN # 2021-10-09 1.876883 # 2021-10-11 NaN # dtype: float64 pandas\u4f7f\u7528NumPy\u7684 datetime64 \u6570\u636e\u7c7b\u578b\u5728\u7eb3\u79d2\u7ea7\u7684\u5206\u8fa8\u7387\u4e0b\u5b58\u50a8\u65f6\u95f4\u6233 print(ts.index.dtype) # datetime64[ns] \u7d22\u5f15\u3001\u9009\u62e9\u3001\u5b50\u96c6 \u5f53\u57fa\u4e8e\u6807\u7b7e\u8fdb\u884c\u7d22\u5f15\u548c\u9009\u62e9\u65f6\uff0c\u65f6\u95f4\u5e8f\u5217\u7684\u884c\u4e3a\u548c\u5176\u4ed6\u7684pandas.Series\u7c7b\u4f3c\uff1a stamp = ts.index[2] print(ts[stamp]) # 0.9344125159374457 \u5bf9\u5e942021-10-05 \u4e5f\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u80fd\u89e3\u91ca\u4e3a\u65e5\u671f\u7684\u5b57\u7b26\u4e32\uff1a print(ts['10/9/2021']) print(ts['20211003']) \u5bf9\u4e00\u4e2a\u957f\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u5e74\u4efd\u6216\u4e00\u4e2a\u5e74\u4efd\u548c\u6708\u4efd\u6765\u9009\u62e9\u6570\u636e\u5207\u7247\uff1a data = np.random.randn(1000) longer_ts = pd.Series( data, index=pd.date_range('1/1/2021', periods=1000) ) print(longer_ts) # 2021-01-01 -0.009192 # 2021-01-02 -1.079068 # 2021-01-03 -1.851176 # 2021-01-04 1.347109 # 2021-01-05 -0.236394 # ... # 2023-09-23 -1.317943 # 2023-09-24 0.201741 # 2023-09-25 0.442282 # 2023-09-26 0.176137 # 2023-09-27 1.146437 # Freq: D, Length: 1000, dtype: float64 \u5b57\u7b26\u4e32\u20192001\u2019\u88ab\u89e3\u91ca\u4e3a\u4e00\u4e2a\u5e74\u4efd\uff0c\u5e76\u9009\u62e9\u4e86\u76f8\u5e94\u7684\u65f6\u95f4\u533a\u95f4\u3002 print(longer_ts['2021']) # 2021-01-01 2.170411 # 2021-01-02 1.186933 # 2021-01-03 0.399262 # 2021-01-04 -1.042606 # 2021-01-05 2.082112 # ... # 2021-12-27 -0.988282 # 2021-12-28 0.598683 # 2021-12-29 2.770580 # 2021-12-30 -1.463262 # 2021-12-31 -1.642846 # Freq: D, Length: 365, dtype: float64 \u6307\u5b9a\u4e86\u5e74\u4efd\u548c\u6708\u4efd\u4e5f\u662f\u6709\u6548\u7684\u3002 print(longer_ts['2021-10']) # 2021-10-01 0.712265 # 2021-10-02 1.195221 # 2021-10-03 -1.930220 # 2021-10-04 -0.720816 # 2021-10-05 0.081777 # 2021-10-06 -0.037466 # 2021-10-07 3.737303 # 2021-10-08 1.620383 # 2021-10-09 0.990797 # 2021-10-10 0.507850 # 2021-10-11 0.846935 # 2021-10-12 0.996947 # 2021-10-13 -1.078558 # 2021-10-14 0.871832 # 2021-10-15 -0.591698 # 2021-10-16 -0.805463 # 2021-10-17 0.160528 # 2021-10-18 -0.028474 # 2021-10-19 2.305579 # 2021-10-20 -1.132288 # 2021-10-21 0.649980 # 2021-10-22 0.615327 # 2021-10-23 0.185108 # 2021-10-24 0.857199 # 2021-10-25 -1.473752 # 2021-10-26 -0.895161 # 2021-10-27 -0.432717 # 2021-10-28 0.734504 # 2021-10-29 1.892493 # 2021-10-30 0.456619 # 2021-10-31 -0.255288 # Freq: D, dtype: float64 \u4f7f\u7528 datetime \u5bf9\u8c61\u8fdb\u884c\u5207\u7247\u4e5f\u662f\u53ef\u4ee5\u7684\uff1a print(longer_ts[datetime(2023, 1, 6):]) # 2023-01-06 0.952591 # 2023-01-07 -0.900259 # 2023-01-08 0.925332 # 2023-01-09 0.173215 # 2023-01-10 -0.507791 # ... # 2023-09-23 -0.319989 # 2023-09-24 -1.105417 # 2023-09-25 -2.118769 # 2023-09-26 0.009420 # 2023-09-27 -0.310281 # Freq: D, Length: 265, dtype: float64 \u56e0\u4e3a\u5927\u90e8\u5206\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f\u6309\u65f6\u95f4\u987a\u5e8f\u6392\u5e8f\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0d\u5305\u542b\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u6233\u8fdb\u884c\u5207\u7247\uff0c\u4ee5\u6267\u884c\u8303\u56f4\u67e5\u8be2\uff1a print(longer_ts['2021/10/1':'2021/10/5']) # 2021-10-01 -0.591853 # 2021-10-02 -1.554564 # 2021-10-03 -0.712585 # 2021-10-04 -0.326657 # 2021-10-05 1.044887 # Freq: D, dtype: float64 \u4f7f\u7528 truncate \u5728\u4e24\u4e2a\u65e5\u671f\u95f4\u5bf9Series\u8fdb\u884c\u5207\u7247\uff1a print(longer_ts.truncate(after='2021/10/1')) # 2021-01-01 -0.906685 # 2021-01-02 -0.470732 # 2021-01-03 -0.041316 # 2021-01-04 -0.287356 # 2021-01-05 0.104268 # ... # 2021-09-27 -0.669198 # 2021-09-28 -2.222169 # 2021-09-29 -0.653814 # 2021-09-30 -0.625868 # 2021-10-01 0.872684 # Freq: D, Length: 274, dtype: float64 \u4e0a\u9762\u8fd9\u4e9b\u64cd\u4f5c\u4e5f\u90fd\u9002\u7528\u4e8eDataFrame\uff0c\u5e76\u5728\u5176\u884c\u4e0a\u8fdb\u884c\u7d22\u5f15\uff1a dates = pd.date_range('10/1/2020', periods=100, freq='W-WED') data = np.random.randn(100, 4) long_df = pd.DataFrame( data, index=dates, columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(long_df) # Colorado Texas New York Ohio # 2020-10-07 -1.186789 2.020634 0.300076 -0.955234 # 2020-10-14 1.502838 0.965368 -0.797539 -0.292833 # ... ... ... ... ... # 2022-08-24 -0.253116 -0.263307 0.602425 0.370599 # 2022-08-31 0.907918 0.091939 0.789694 2.781535 # [100 rows x 4 columns] print(long_df.loc['10-2020']) # Colorado Texas New York Ohio # 2020-10-07 1.031616 -1.812038 -0.446577 0.395656 # 2020-10-14 -0.673167 0.198804 -0.439141 0.086004 # 2020-10-21 -1.139786 0.716820 0.006516 -0.284335 # 2020-10-28 -0.637939 1.647810 -0.750786 0.140637 \u542b\u6709\u91cd\u590d\u7d22\u5f15\u7684\u65f6\u95f4\u5e8f\u5217 \u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\uff0c\u53ef\u80fd\u4f1a\u6709\u591a\u4e2a\u6570\u636e\u89c2\u5bdf\u503c\u843d\u5728\u7279\u5b9a\u7684\u65f6\u95f4\u6233\u4e0a\u3002\u4e0b\u9762\u662f\u4e2a\u4f8b\u5b50\uff1a dates = pd.DatetimeIndex( ['2021/1/1', '2021/1/2', '2021/1/2', '2021/1/2', '2021/1/3'] ) dup_ts = pd.Series( np.arange(5), index=dates ) print(dup_ts) # 2021-01-01 0 # 2021-01-02 1 # 2021-01-02 2 # 2021-01-02 3 # 2021-01-03 4 # dtype: int64 \u901a\u8fc7\u68c0\u67e5\u7d22\u5f15\u7684 is_unique \u5c5e\u6027\uff0c\u53ef\u4ee5\u770b\u51fa\u7d22\u5f15\u5e76\u4e0d\u662f\u552f\u4e00\u7684\uff1a print(dup_ts.index.is_unique) # False \u5bf9\u4e0a\u9762\u7684Series\u8fdb\u884c\u7d22\u5f15\uff0c\u7ed3\u679c\u662f\u6807\u91cf\u503c\u8fd8\u662fSeries\u5207\u7247\u53d6\u51b3\u4e8e\u662f\u5426\u6709\u65f6\u95f4\u6233\u662f\u91cd\u590d\u7684\uff1a result = dup_ts['2021/1/3'] print(result) # 4 result = dup_ts['2021/1/2'] print(result) # 2021-01-02 1 # 2021-01-02 2 # 2021-01-02 3 # dtype: int64 \u5047\u8bbe\u60f3\u8981\u805a\u5408\u542b\u6709\u975e\u552f\u4e00\u65f6\u95f4\u6233\u7684\u6570\u636e\u3002\u4e00\u79cd\u65b9\u5f0f\u5c31\u662f\u4f7f\u7528 groupby \u5e76\u4f20\u9012 level=0 \uff1a grouped = dup_ts.groupby(level=0) result = grouped.mean() print(result) # 2021-01-01 0.0 # 2021-01-02 2.0 # 2021-01-03 4.0 # dtype: float64 result = grouped.count() print(result) # 2021-01-01 1 # 2021-01-02 3 # 2021-01-03 1 # dtype: int64 \u65e5\u671f\u8303\u56f4\u3001\u9891\u7387\u548c\u79fb\u4f4d from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd pandas\u7684\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u662f\u4e0d\u89c4\u5219\u7684\uff0c\u5373\u65f6\u95f4\u5e8f\u5217\u7684\u9891\u7387\u4e0d\u662f\u56fa\u5b9a\u7684\u3002 \u4f46\u6709\u65f6\u9700\u8981\u5904\u7406\u56fa\u5b9a\u9891\u7387\u7684\u573a\u666f\uff0c\u4f8b\u5982\u6bcf\u65e5\u7684\u3001\u6bcf\u6708\u7684\u6216\u6bcf15\u5206\u949f\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u53ef\u4ee5\u901a\u8fc7\u8c03\u7528resample\u65b9\u6cd5\u5c06\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fa\u5b9a\u7684\u6bcf\u65e5\u9891\u7387\u6570\u636e\u3002 \u5728\u9891\u7387\u95f4\u8f6c\u6362\uff0c\u53c8\u79f0\u4e3a\u91cd\u65b0\u91c7\u6837\u3002 dates = [ datetime(2021, 10, 1), datetime(2021, 10, 3), datetime(2021, 10, 5), datetime(2021, 10, 7), datetime(2021, 10, 9), datetime(2021, 10, 11) ] data = np.random.rand(6) ts = pd.Series(data, index=dates) print(ts) # 2021-10-01 0.956685 # 2021-10-03 0.817168 # 2021-10-05 0.275543 # 2021-10-07 0.614226 # 2021-10-09 0.061377 # 2021-10-11 0.357080 # dtype: float64 resampler = ts.resample('D') # \u5b57\u7b26\u4e32\u2019D\u2019\u88ab\u89e3\u91ca\u4e3a\u6bcf\u65e5\u9891\u7387 print(resampler) # DatetimeIndexResampler [freq=<Day>, axis=0, closed=left, label=left, convention=start, origin=start_day] \u751f\u6210\u65e5\u671f\u8303\u56f4 pandas.date_range \u662f\u7528\u4e8e\u6839\u636e\u7279\u5b9a\u9891\u7387\u751f\u6210\u6307\u5b9a\u957f\u5ea6\u7684 DatetimeIndex \u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c date_range \u751f\u6210\u7684\u662f\u6bcf\u65e5\u7684\u65f6\u95f4\u6233\u3002\u5982\u679c\u53ea\u4f20\u9012\u4e00\u4e2a\u8d77\u59cb\u6216\u7ed3\u5c3e\u65e5\u671f\uff0c\u4f60\u5fc5\u987b\u4f20\u9012\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u8303\u56f4\u7684\u6570\u5b57\u3002 \u5f00\u59cb\u65e5\u671f\u548c\u7ed3\u675f\u65e5\u671f\u4e25\u683c\u5b9a\u4e49\u4e86\u751f\u6210\u65e5\u671f\u7d22\u5f15\u7684\u8fb9\u754c\u3002 index = pd.date_range('2021/1/1', '2021/1/30') print(index) index = pd.date_range(start='2021/1/1', periods=30) print(index) index = pd.date_range(end='2021/1/30', periods=30) print(index) # DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', # '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', # '2021-01-09', '2021-01-10', '2021-01-11', '2021-01-12', # '2021-01-13', '2021-01-14', '2021-01-15', '2021-01-16', # '2021-01-17', '2021-01-18', '2021-01-19', '2021-01-20', # '2021-01-21', '2021-01-22', '2021-01-23', '2021-01-24', # '2021-01-25', '2021-01-26', '2021-01-27', '2021-01-28', # '2021-01-29', '2021-01-30'], # dtype='datetime64[ns]', freq='D') \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c date_range \u4fdd\u7559\u5f00\u59cb\u6216\u7ed3\u675f\u65f6\u95f4\u6233\u7684\u65f6\u95f4\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\u3002 normalize \u9009\u9879\u53ef\u4ee5\u5b9e\u73b0\u751f\u6210\u7684\u662f\u6807\u51c6\u5316\u4e3a\u96f6\u70b9\u7684\u65f6\u95f4\u6233\u3002 index = pd.date_range('2021/1/1 12:56:30', periods=5) print(index) # DatetimeIndex(['2021-01-01 12:56:30', '2021-01-02 12:56:30', # '2021-01-03 12:56:30', '2021-01-04 12:56:30', # '2021-01-05 12:56:30'], # dtype='datetime64[ns]', freq='D') index = pd.date_range('2021/1/1 12:56:30', periods=5, normalize=True) print(index) # DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', # '2021-01-05'], # dtype='datetime64[ns]', freq='D') Pandas\u65f6\u95f4\u5e8f\u5217\uff1a\u9891\u7387\u548c\u65e5\u671f\u504f\u79fb\u91cf\u3002 pandas\u4e2d\u7684\u9891\u7387\u662f\u7531\u4e00\u4e2a\u57fa\u7840\u9891\u7387(\u4f8b\u5982\u201c\u65e5\u201d\u3001\u201c\u6708\u201d)\u548c\u4e00\u4e2a\u4e58\u6570\u7ec4\u6210\u3002 \u57fa\u7840\u9891\u7387\u901a\u5e38\u4ee5\u4e00\u4e2a\u5b57\u7b26\u4e32\u522b\u540d\u8868\u793a\uff0c\u6bd4\u5982\u201cD\u201d\u8868\u793a\u65e5\uff0c\u201cM\u201d\u8868\u793a\u6708\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u57fa\u7840\u9891\u7387\uff0c\u90fd\u6709\u4e00\u4e2a\u88ab\u79f0\u4e3a\u65e5\u671f\u504f\u79fb\u91cf(dateoffset)\u7684\u5bf9\u8c61\u4e0e\u4e4b\u5bf9\u5e94\uff0c\u6bd4\u5982\u65e5\u671f\u504f\u79fb\u91cf Hour \u5bf9\u5e94\u7684\u9891\u7387\u662f H \u3002 \u5e38\u7528\u9891\u7387\u4e0e\u65e5\u671f\u504f\u79fb\u91cf\u3002 \u9891\u7387 \u65e5\u671f\u504f\u79fb\u91cf \u8bf4\u660e D Day \u65e5\u5386\u65e5 B BusinessDay \u5de5\u4f5c\u65e5 H Hour \u5c0f\u65f6 T/min Minute \u5206 S Second \u79d2 L/ms Milli \u6beb\u79d2 U Micro \u5fae\u79d2 M MonthEnd \u6bcf\u6708\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BM BusinessMonthEnd \u6bcf\u6708\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 MS MonthBegin \u6bcf\u6708\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BMS BussinessMonthBegin \u6bcf\u6708\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5 W-MON, W-TUE, ... Week \u6307\u5b9a\u661f\u671f\u51e0(MON,TUE,WED,THU,FRI,SAT,SUN) WOM-1MON,WOM-2MON, ... WeekOfMonth \u4ea7\u751f\u6bcf\u6708\u7b2c\u4e00,\u7b2c\u4e8c,\u7b2c\u4e09\u6216\u7b2c\u56db\u5468\u7684\u661f\u671f\u51e0\u3002\u4f8b\u5982WOM-3FRI\u8868\u793a\u6bcf\u6708\u7b2c3\u4e2a\u661f\u671f\u4e94 Q-JAN,Q-FEB, ... QuarterEnd \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BQ-JAN,BQ-FEB, ... BusinessQuarterEnd \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 QS-JAN,QS-FEB, ... QuarterBegin \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BQS-JAN,BQS-FEB, ... BusinessQuarterBegin \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5 A-JAN,A-FEB, ... YearEnd \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BA-JAN,BA-FEB, ... BusinessYearEnd \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 AS-JAN,AS-FEB, ... YearBegin \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BAS-JAN,BAS-FEB, ... BusinessYearBegin \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5 \u9891\u7387\u548c\u65e5\u671f\u504f\u7f6e pandas\u4e2d\u7684\u9891\u7387\u662f\u7531\u57fa\u7840\u9891\u7387\u548c\u500d\u6570\u7ec4\u6210\u7684\u3002 \u57fa\u7840\u9891\u7387\u901a\u5e38\u4f1a\u6709\u5b57\u7b26\u4e32\u522b\u540d\uff0c\u4f8b\u5982 M \u4ee3\u8868\u6bcf\u6708\uff0c H \u4ee3\u8868\u6bcf\u5c0f\u65f6\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u57fa\u7840\u9891\u7387\uff0c\u90fd\u6709\u4e00\u4e2a\u5bf9\u8c61\u53ef\u4ee5\u88ab\u7528\u4e8e\u5b9a\u4e49\u65e5\u671f\u504f\u7f6e\u3002 \u4f8b\u5982\uff0c\u6bcf\u5c0f\u65f6\u7684\u9891\u7387\u53ef\u4ee5\u4f7f\u7528 Hour \u7c7b\u6765\u8868\u793a\uff1a ```hour = Hour() print(hour) \u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u6574\u6570\u6765\u5b9a\u4e49\u504f\u7f6e\u91cf\u7684\u500d\u6570\uff1a four_hours = Hour(4) print(four_hours) <4 * Hours> \u5728\u5927\u591a\u6570\u5e94\u7528\u4e2d\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u5730\u521b\u5efa\u8fd9\u4e9b\u5bf9\u8c61\uff0c\u800c\u662f\u4f7f\u7528\u5b57\u7b26\u4e32\u522b\u540d\uff0c\u5982`H`\u6216`4H`\u3002\u5728\u57fa\u7840\u9891\u7387\u524d\u653e\u4e00\u4e2a\u6574\u6570\u5c31\u53ef\u4ee5\u751f\u6210\u500d\u6570\uff1a ts = pd.date_range('2021/1/1', '2021/1/2 23:59', freq='4h') print(ts) DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 04:00:00', '2021-01-01 08:00:00', '2021-01-01 12:00:00', '2021-01-01 16:00:00', '2021-01-01 20:00:00', '2021-01-02 00:00:00', '2021-01-02 04:00:00', '2021-01-02 08:00:00', '2021-01-02 12:00:00', '2021-01-02 16:00:00', '2021-01-02 20:00:00'], dtype='datetime64[ns]', freq='4H') \u591a\u4e2a\u504f\u7f6e\u53ef\u4ee5\u901a\u8fc7\u52a0\u6cd5\u8fdb\u884c\u8054\u5408\uff1a print(Hour(2) + Minute(30)) <150 * Minutes> \u7c7b\u4f3c\u5730\uff0c\u53ef\u4ee5\u4f20\u9012\u9891\u7387\u5b57\u7b26\u4e32\uff1a ts = pd.date_range('2021/1/1', '2021/1/1 23:59', freq='4h30min') print(ts) DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 04:30:00', '2021-01-01 09:00:00', '2021-01-01 13:30:00', '2021-01-01 18:00:00', '2021-01-01 22:30:00'], dtype='datetime64[ns]', freq='270T') \u6709\u4e9b\u9891\u7387\u63cf\u8ff0\u70b9\u7684\u65f6\u95f4\u5e76\u4e0d\u662f\u5747\u5300\u5206\u9694\u7684\u3002\u4f8b\u5982\uff0c`M`\uff08\u65e5\u5386\u6708\u672b\uff09\u548c`BM`\uff08\u6708\u5185\u6700\u540e\u5de5\u4f5c\u65e5\uff09\u53d6\u51b3\u4e8e\u5f53\u6708\u5929\u6570\uff0c\u6708\u672b\u662f\u5426\u662f\u5468\u672b\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u65e5\u671f\u79f0\u4e3a\u951a\u5b9a\u504f\u7f6e\u91cf\u3002 #### \u6708\u4e2d\u67d0\u661f\u671f\u7684\u65e5\u671f \"\u6708\u4e2d\u67d0\u661f\u671f\"\uff08week of month \uff09\u7684\u65e5\u671f\u662f\u4e00\u4e2a\u6709\u7528\u7684\u9891\u7387\u7c7b\uff0c\u4ee5`WOM`\u5f00\u59cb\u3002 rng = pd.date_range('2021-1-1', '2021-9-1', freq='WOM-3FRI') # \u6bcf\u6708\u7b2c\u4e09\u4e2a\u661f\u671f\u4e94 print(rng) DatetimeIndex(['2021-01-15', '2021-02-19', '2021-03-19', '2021-04-16', '2021-05-21', '2021-06-18', '2021-07-16', '2021-08-20'], dtype='datetime64[ns]', freq='WOM-3FRI') ### \u79fb\u4f4d\uff08\u524d\u5411\u548c\u540e\u5411\uff09\u65e5\u671f \"\u79fb\u4f4d\"\u662f\u6307\u5c06\u65e5\u671f\u6309\u65f6\u95f4\u5411\u524d\u79fb\u52a8\u6216\u5411\u540e\u79fb\u52a8\u3002 Series\u548cDataFrame\u90fd\u6709\u4e00\u4e2a`shift`\u65b9\u6cd5\u7528\u4e8e\u8fdb\u884c\u7b80\u5355\u7684\u524d\u5411\u6216\u540e\u5411\u79fb\u4f4d\uff0c\u800c\u4e0d\u6539\u53d8\u7d22\u5f15\u3002 \u8fdb\u884c\u79fb\u4f4d\u65f6\uff0c\u4f1a\u5728\u65f6\u95f4\u5e8f\u5217\u7684\u8d77\u59cb\u4f4d\u6216\u7ed3\u675f\u4f4d\u5f15\u5165\u7f3a\u5931\u503c\u3002 data = [0.882972, 1.363282, -0.687750, -0.048117] ts = pd.Series(data, index=pd.date_range('2021-1-1', periods=4, freq='M')) print(ts) 2021-01-31 0.882972 2021-02-28 1.363282 2021-03-31 -0.687750 2021-04-30 -0.048117 Freq: M, dtype: float64 print(ts.shift(2)) 2021-01-31 NaN 2021-02-28 NaN 2021-03-31 0.882972 2021-04-30 1.363282 Freq: M, dtype: float64 print(ts.shift(-2)) 2021-01-31 -0.687750 2021-02-28 -0.048117 2021-03-31 NaN 2021-04-30 NaN Freq: M, dtype: float64 `shift`\u5e38\u7528\u4e8e\u8ba1\u7b97\u65f6\u95f4\u5e8f\u5217\u6216DataFrame\u591a\u5217\u65f6\u95f4\u5e8f\u5217\u7684\u767e\u5206\u6bd4\u53d8\u5316\uff1a print(ts/ts.shift(1)) 2021-01-31 NaN 2021-02-28 1.543970 2021-03-31 -0.504481 2021-04-30 0.069963 Freq: M, dtype: float64 print(ts/ts.shift(1) - 1) 2021-01-31 NaN 2021-02-28 0.543970 2021-03-31 -1.504481 2021-04-30 -0.930037 Freq: M, dtype: float64 \u5982\u679c\u9891\u7387\u662f\u5df2\u77e5\u7684\uff0c\u5219\u53ef\u4ee5\u5c06\u9891\u7387\u4f20\u9012\u7ed9`shift`\u6765\u63a8\u79fb\u65f6\u95f4\u6233\uff1a print(ts.shift(2, freq='M')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u6708\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c 2021-03-31 0.882972 2022021-10-31 00:00:001-04-30 1.363282 2021-05-31 -0.687750 2021-06-30 -0.048117 Freq: M, dtype: float64 print(ts.shift(2, freq='D')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u65e5\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c 2021-02-02 0.882972 2021-03-02 1.363282 2021-04-02 -0.687750 2021-05-02 -0.048117 dtype: float64 print(ts.shift(2, freq='90T')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u5c0f\u65f6\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c 2021-01-31 03:00:00 0.882972 2021-02-28 03:00:00 1.363282 2021-03-31 03:00:00 -0.687750 2021-04-30 03:00:00 -0.048117 dtype: float64 #### \u4f7f\u7528\u504f\u7f6e\u8fdb\u884c\u79fb\u4f4d\u65e5\u671f pandas\u65e5\u671f\u504f\u7f6e\u4e5f\u53ef\u4ee5\u4f7f\u7528`datetime`\u6216`Timestamp`\u5bf9\u8c61\u5b8c\u6210\uff1a now = datetime(2021, 10, 9) print(now) 2021-10-09 00:00:00 print(now + 3 * Day()) 2021-10-12 00:00:00 \u951a\u5b9a\u504f\u7f6e\u53ef\u4ee5\u4f7f\u7528`rollforward`\u548c`rollback`\u5206\u522b\u663e\u5f0f\u5730\u5c06\u65e5\u671f\u5411\u524d\u6216\u5411\u540e\"\u6eda\u52a8\"\u3002 \u5982\u679c\u6dfb\u52a0\u4e86\u4e00\u4e2a\u951a\u5b9a\u504f\u7f6e\u91cf\uff0c\u6bd4\u5982`MonthEnd`\uff0c\u6839\u636e\u9891\u7387\u89c4\u5219\uff0c\u7b2c\u4e00\u4e2a\u589e\u91cf\u4f1a\u5c06\u65e5\u671f\u201c\u524d\u6eda\u201d\u5230\u4e0b\u4e00\u4e2a\u65e5\u671f\uff1a print(now + MonthEnd()) # \u201c\u524d\u6eda\u201d\u5230\u5f53\u524d\u6708\u7684\u6708\u5e95 2021-10-31 00:00:00 print(now + MonthEnd(2)) # \u6ce8\u610f\u8fd9\u91cc\u7684\u5e8f\u5217\u53f7\uff0c\u5f53\u524d\u6708\u662f1,\u4e0b\u4e2a\u6708\u662f2 2021-11-30 00:00:00 offset = MonthEnd() print(offset.rollback(now)) 2021-09-30 00:00:00 print(offset.rollforward(now)) 2021-10-31 00:00:00 \u5c06\u79fb\u4f4d\u65b9\u6cd5\u4e0e`groupby`\u4e00\u8d77\u4f7f\u7528\u662f\u65e5\u671f\u504f\u7f6e\u7684\u4e00\u79cd\u521b\u9020\u6027\u7528\u6cd5\uff1a ts = pd.Series( np.random.randn(20), index=pd.date_range('2021/1/1', periods=20, freq='4d') ) print(ts) 2021-01-01 0.674348 2021-01-05 -1.437803 2021-01-09 -0.079218 2021-01-13 -1.444890 2021-01-17 0.643279 2021-01-21 1.089965 2021-01-25 0.021876 2021-01-29 0.692138 2021-02-02 0.833496 2021-02-06 1.082616 2021-02-10 -0.729415 2021-02-14 0.271186 2021-02-18 -1.416218 2021-02-22 -0.780402 2021-02-26 -0.113773 2021-03-02 2.095338 2021-03-06 -0.302612 2021-03-10 1.113632 2021-03-14 -1.314581 2021-03-18 0.947746 Freq: 4D, dtype: float64 print(ts.groupby(offset.rollforward).mean()) # \u524d\u6eda\u81f3\u5f53\u6708\u6708\u5e95\uff0c\u8ba1\u7b97\u5f53\u6708\u5e73\u5747\u503c 2021-01-31 0.019962 2021-02-28 -0.121787 2021-03-31 0.507905 dtype: float64 \u4f7f\u7528resample\u662f\u66f4\u7b80\u5355\u66f4\u5feb\u6377\u7684\u65b9\u6cd5 print(ts.resample('M').mean()) 2021-01-31 0.019962 2021-02-28 -0.121787 2021-03-31 0.507905 Freq: M, dtype: float64 ## \u65f6\u533a\u5904\u7406 \u65f6\u533a\u901a\u5e38\u88ab\u8868\u793a\u4e3aUTC\u7684\u504f\u7f6e\u3002 \u5728Python\u8bed\u8a00\u4e2d\uff0c\u65f6\u533a\u4fe1\u606f\u6765\u6e90\u4e8e\u7b2c\u4e09\u65b9\u5e93pytz\uff08\u53ef\u4ee5\u4f7f\u7528pip\u6216conda\u5b89\u88c5\uff09\uff0c\u5176\u4e2d\u516c\u5f00\u4e86Olson\u6570\u636e\u5e93\uff0c\u8fd9\u662f\u4e16\u754c\u65f6\u533a\u4fe1\u606f\u7684\u6c47\u7f16\u3002 pandas\u5c01\u88c5\u4e86pytz\u7684\u529f\u80fd\u3002 from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz #### common_timezones tz = pytz.common_timezones[-5:] # \u8bfb\u53d6common_timezones\u8fd9\u4e2a\u5217\u8868\u7684\u6700\u540e5\u4e2a\u5143\u7d20 print(tz) ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC'] \u8981\u83b7\u5f97pytz\u7684\u65f6\u533a\u5bf9\u8c61\uff0c\u53ef\u4f7f\u7528pytz.timezone\uff1a tz = pytz.timezone('Asia/Shanghai') print(tz) #### \u65f6\u533a\u7684\u672c\u5730\u5316\u548c\u8f6c\u6362 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cpandas\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u662f\u65f6\u533a\u7b80\u5355\u578b\u7684\u3002 rng = pd.date_range('2021/1/1 9:30', periods=6, freq='D') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(rng) DatetimeIndex(['2021-01-01 09:30:00', '2021-01-02 09:30:00', '2021-01-03 09:30:00', '2021-01-04 09:30:00', '2021-01-05 09:30:00', '2021-01-06 09:30:00'], dtype='datetime64[ns]', freq='D') print(ts) 2021-01-01 09:30:00 0.339822 2021-01-02 09:30:00 1.356382 2021-01-03 09:30:00 0.475429 2021-01-04 09:30:00 1.826654 2021-01-05 09:30:00 -0.245510 2021-01-06 09:30:00 0.705274 Freq: D, dtype: float64 print(ts.index.tz) # \u7d22\u5f15\u7684tz\u5c5e\u6027\u662fNone None \u65e5\u671f\u8303\u56f4\u53ef\u4ee5\u901a\u8fc7\u65f6\u533a\u96c6\u5408\u6765\u751f\u6210\uff1a rng = pd.date_range('2021/3/1', periods=10, freq='D', tz='UTC') print(rng) DatetimeIndex(['2021-03-01 00:00:00+00:00', '2021-03-02 00:00:00+00:00', '2021-03-03 00:00:00+00:00', '2021-03-04 00:00:00+00:00', '2021-03-05 00:00:00+00:00', '2021-03-06 00:00:00+00:00', '2021-03-07 00:00:00+00:00', '2021-03-08 00:00:00+00:00', '2021-03-09 00:00:00+00:00', '2021-03-10 00:00:00+00:00'], dtype='datetime64[ns, UTC]', freq='D') \u4f7f\u7528`tz_localize`\u65b9\u6cd5\u53ef\u4ee5\u4ece\u7b80\u5355\u65f6\u533a\u8f6c\u6362\u5230\u672c\u5730\u5316\u65f6\u533a\uff1a print(ts) 2021-01-01 09:30:00 0.294647 2021-01-02 09:30:00 0.958414 2021-01-03 09:30:00 0.424235 2021-01-04 09:30:00 -1.714333 2021-01-05 09:30:00 -0.030319 2021-01-06 09:30:00 -0.744940 Freq: D, dtype: float64 print(ts.tz_localize('UTC')) 2021-01-01 09:30:00+00:00 0.294647 2021-01-02 09:30:00+00:00 0.958414 2021-01-03 09:30:00+00:00 0.424235 2021-01-04 09:30:00+00:00 -1.714333 2021-01-05 09:30:00+00:00 -0.030319 2021-01-06 09:30:00+00:00 -0.744940 Freq: D, dtype: float64 print(ts.tz_localize('Asia/Shanghai')) 2021-01-01 09:30:00+08:00 0.052521 2021-01-02 09:30:00+08:00 -0.305417 2021-01-03 09:30:00+08:00 0.150215 2021-01-04 09:30:00+08:00 -0.953715 2021-01-05 09:30:00+08:00 0.543622 2021-01-06 09:30:00+08:00 0.222422 dtype: float64 print(ts.tz_localize('Asia/Shanghai').index) DatetimeIndex(['2021-01-01 09:30:00+08:00', '2021-01-02 09:30:00+08:00', '2021-01-03 09:30:00+08:00', '2021-01-04 09:30:00+08:00', '2021-01-05 09:30:00+08:00', '2021-01-06 09:30:00+08:00'], dtype='datetime64[ns, Asia/Shanghai]', freq=None) \u4e00\u65e6\u65f6\u95f4\u5e8f\u5217\u88ab\u672c\u5730\u5316\u4e3a\u67d0\u4e2a\u7279\u5b9a\u7684\u65f6\u533a\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7`tz_convert`\u5c06\u5176\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u65f6\u533a\uff1a tz_sha = ts.tz_localize('Asia/Shanghai') tz_utc = tz_sha.tz_convert('UTC') print(tz_sha) 2021-01-01 09:30:00+08:00 0.095689 2021-01-02 09:30:00+08:00 -0.392730 2021-01-03 09:30:00+08:00 0.151468 2021-01-04 09:30:00+08:00 0.027467 2021-01-05 09:30:00+08:00 0.393709 2021-01-06 09:30:00+08:00 0.872914 dtype: float64 print(tz_utc) 2021-01-01 01:30:00+00:00 0.095689 2021-01-02 01:30:00+00:00 -0.392730 2021-01-03 01:30:00+00:00 0.151468 2021-01-04 01:30:00+00:00 0.027467 2021-01-05 01:30:00+00:00 0.393709 2021-01-06 01:30:00+00:00 0.872914 dtype: float64 tz_localize\u548ctz_convert\u4e5f\u662fDatetimeIndex\u7684\u5b9e\u4f8b\u65b9\u6cd5\uff1a print(ts.index.tz_localize('Asia/Shanghai')) DatetimeIndex(['2021-01-01 09:30:00+08:00', '2021-01-02 09:30:00+08:00', '2021-01-03 09:30:00+08:00', '2021-01-04 09:30:00+08:00', '2021-01-05 09:30:00+08:00', '2021-01-06 09:30:00+08:00'], dtype='datetime64[ns, Asia/Shanghai]', freq=None) ### \u65f6\u533a\u611f\u77e5\u65f6\u95f4\u6233\u5bf9\u8c61\u7684\u64cd\u4f5c \u4e0e\u65f6\u95f4\u5e8f\u5217\u548c\u65e5\u671f\u8303\u56f4\u7c7b\u4f3c\uff0c\u5355\u72ec\u7684`Timestamp`\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u4ece\u7b80\u5355\u65f6\u95f4\u6233\u672c\u5730\u5316\u4e3a\u65f6\u533a\u611f\u77e5\u65f6\u95f4\u6233\uff0c\u5e76\u4ece\u4e00\u4e2a\u65f6\u533a\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u65f6\u533a\uff1a stamp = pd.Timestamp('2021-5-1 05:30') print(stamp) 2021-05-01 05:30:00 stamp_utc = stamp.tz_localize('utc') print(stamp_utc) 2021-05-01 05:30:00+00:00 stamp_sha = stamp_utc.tz_convert('Asia/Shanghai') print(stamp_sha) 2021-05-01 13:30:00+08:00 \u4e5f\u53ef\u4ee5\u5728\u521b\u5efa`Timestamp`\u7684\u65f6\u5019\u4f20\u9012\u4e00\u4e2a\u65f6\u533a\uff1a stamp_sha = pd.Timestamp('2021-5-1 05:30', tz='Asia/Shanghai') print(stamp_sha) 2021-05-01 05:30:00+08:00 `Timestamp`\u5bf9\u8c61\u5185\u90e8\u5b58\u50a8\u4e86\u4e00\u4e2aUnix\u7eaa\u5143(1970\u5e741\u67081\u65e5)\u81f3\u4eca\u7684\u7eb3\u79d2\u6570\u91cfUTC\u65f6\u95f4\u6233\u6570\u503c\uff0c\u8be5\u6570\u503c\u5728\u65f6\u533a\u8f6c\u6362\u4e2d\u662f\u4e0d\u53d8\u7684\uff1a print(stamp_utc.value) 1619847000000000000 print(stamp_utc.tz_convert('Asia/Shanghai').value) 1619847000000000000 \u5728\u4f7f\u7528pandas\u7684`DateOffset`\u8fdb\u884c\u65f6\u95f4\u7b97\u672f\u65f6\uff0cpandas\u5c3d\u53ef\u80fd\u9075\u4ece\u590f\u65f6\u5236\u3002 \u9996\u5148\uff0c\u6784\u9020\u8f6c\u6362\u5230DST\u4e4b\u524d\u768430\u5206\u949f\u7684\u65f6\u95f4\uff1a stamp = pd.Timestamp('2012-3-12 1:30', tz='US/Eastern') print(stamp) 2012-03-12 01:30:00-04:00 print(stamp + Hour()) 2012-03-12 02:30:00-04:00 \u4e4b\u540e\uff0c\u6784\u5efa\u4eceDST\u8fdb\u884c\u8f6c\u6362\u524d\u768490\u5206\u949f\uff1a stamp = pd.Timestamp('2012-11-04 0:30-04:00', tz='US/Eastern') print(stamp) 2012-11-04 00:30:00-04:00 print(stamp + 2 * Hour()) # \u53ea\u589e\u52a0\u4e86\u4e00\u5c0f\u65f6 2012-11-04 01:30:00-05:00 ### \u4e0d\u540c\u65f6\u533a\u95f4\u7684\u64cd\u4f5c \u5982\u679c\u4e24\u4e2a\u65f6\u533a\u4e0d\u540c\u7684\u65f6\u95f4\u5e8f\u5217\u9700\u8981\u8054\u5408\uff0c\u90a3\u4e48\u7ed3\u679c\u5c06\u662fUTC\u65f6\u95f4\u7684\uff0c\u56e0\u4e3a\u65f6\u95f4\u6233\u4ee5UTC\u683c\u5f0f\u5b58\u50a8\u3002 rng = pd.date_range('2021/1/1 9:30', periods=9, freq='B') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(ts) 2021-01-01 09:30:00 0.715681 2021-01-04 09:30:00 0.524563 2021-01-05 09:30:00 -0.482199 2021-01-06 09:30:00 -0.661303 2021-01-07 09:30:00 1.750010 2021-01-08 09:30:00 0.251478 2021-01-11 09:30:00 -1.487268 2021-01-12 09:30:00 -0.224024 2021-01-13 09:30:00 -1.621853 Freq: B, dtype: float64 ts1 = ts[:7].tz_localize('Europe/London') ts2 = ts1[2:].tz_convert('Europe/Moscow') result = ts1 + ts2 print(ts1) 2021-01-01 09:30:00+00:00 -1.393445 2021-01-04 09:30:00+00:00 -1.179614 2021-01-05 09:30:00+00:00 0.716669 2021-01-06 09:30:00+00:00 -0.485656 2021-01-07 09:30:00+00:00 0.433000 2021-01-08 09:30:00+00:00 1.540745 2021-01-11 09:30:00+00:00 0.343751 dtype: float64 print(ts2) 2021-01-05 12:30:00+03:00 0.716669 2021-01-06 12:30:00+03:00 -0.485656 2021-01-07 12:30:00+03:00 0.433000 2021-01-08 12:30:00+03:00 1.540745 2021-01-11 12:30:00+03:00 0.343751 dtype: float64 print(result) 2021-01-01 09:30:00+00:00 NaN 2021-01-04 09:30:00+00:00 NaN 2021-01-05 09:30:00+00:00 1.433337 2021-01-06 09:30:00+00:00 -0.971312 2021-01-07 09:30:00+00:00 0.866000 2021-01-08 09:30:00+00:00 3.081489 2021-01-11 09:30:00+00:00 0.687502 dtype: float64 ## \u65f6\u95f4\u533a\u95f4\u548c\u533a\u95f4\u7b97\u672f from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz \u65f6\u95f4\u533a\u95f4\u8868\u793a\u7684\u662f\u65f6\u95f4\u8303\u56f4\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628a`year`\u548c`quarter`\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15\uff0c\u6bd4\u5982\u4e00\u4e9b\u5929\u3001\u4e00\u4e9b\u6708\u3001\u4e00\u4e9b\u5b63\u5ea6\u6216\u8005\u662f\u4e00\u4e9b\u5e74\u3002 `Period`\u7c7b\u8868\u793a\u7684\u6b63\u662f\u8fd9\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u9700\u8981\u4e00\u4e2a\u5b57\u7b26\u4e32\u6216\u6570\u5b57\u4ee5\u53ca\u9891\u7387\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c`Period`\u5bf9\u8c61\u8868\u793a\u7684\u662f\u4ece2007\u5e741\u67081\u65e5\u52302007\u5e7412\u670831\u65e5\uff08\u5305\u542b\u5728\u5185\uff09\u7684\u65f6\u95f4\u6bb5\u3002 \u5728\u65f6\u95f4\u6bb5\u4e0a\u589e\u52a0\u6216\u51cf\u53bb\u6574\u6570\u53ef\u4ee5\u65b9\u4fbf\u5730\u6839\u636e\u5b83\u4eec\u7684\u9891\u7387\u8fdb\u884c\u79fb\u4f4d\u3002 p = pd.Period(2020, freq='A-DEC') print(p) 2020 print(p + 5) 2025 print(p - 5) 2015 \u5982\u679c\u4e24\u4e2a\u533a\u95f4\u62e5\u6709\u76f8\u540c\u7684\u9891\u7387\uff0c\u5219\u5b83\u4eec\u7684\u5dee\u662f\u5b83\u4eec\u4e4b\u95f4\u7684\u5355\u4f4d\u6570\u3002 p1 = pd.Period(2020, freq='A-DEC') p2 = pd.Period(2010, freq='A-DEC') print(p1 - p2) <10 * YearEnds: month=12> p1 = pd.Period(2020, freq='Q-DEC') p2 = pd.Period(2010, freq='Q-DEC') print(p1 - p2) <40 * QuarterEnds: startingMonth=12> \u4f7f\u7528`period_range`\u51fd\u6570\u53ef\u4ee5\u6784\u9020\u89c4\u5219\u533a\u95f4\u5e8f\u5217\u3002`PeriodIndex`\u7c7b\u5b58\u50a8\u7684\u662f\u533a\u95f4\u7684\u5e8f\u5217\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u4efb\u610fpandas\u6570\u636e\u7ed3\u6784\u7684\u8f74\u7d22\u5f15\u3002 data = np.random.randn(6) strings = ['2021Q1', '2021Q2', '2021Q3', '2021Q4', '2022Q1', '2022Q2'] rng = pd.period_range('2001-1-1', '2001-6-30', freq='M') ts = pd.Series(data, index=rng) print(ts) 2001-01 -0.481408 2001-02 -0.297590 2001-03 -0.860354 2001-04 1.281540 2001-05 1.036551 2001-06 -0.522592 Freq: M, dtype: float64 rng = pd.PeriodIndex(strings, freq='Q-DEC') # \u5b57\u7b26\u4e32\u6570\u7ec4\u4e5f\u53ef\u4ee5\u4f7f\u7528PeriodIndex\u7c7b ts = pd.Series(data, index=rng) print(ts) 2021Q1 -2.077200 2021Q2 -0.948796 2021Q3 -1.104737 2021Q4 0.090281 2022Q1 0.431517 2022Q2 1.537045 Freq: Q-DEC, dtype: float64 ### \u533a\u95f4\u9891\u7387\u8f6c\u6362 \u4f7f\u7528`asfreq`\u53ef\u4ee5\u5c06\u533a\u95f4\u548c`PeriodIndex`\u5bf9\u8c61\u8f6c\u6362\u4e3a\u5176\u4ed6\u7684\u9891\u7387\u3002 \u4f8b\u5982\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5e74\u5ea6\u533a\u95f4\uff0c\u5e76\u4e14\u60f3\u8981\u5728\u4e00\u5e74\u7684\u5f00\u59cb\u6216\u7ed3\u675f\u65f6\u5c06\u5176\u8f6c\u6362\u4e3a\u6708\u5ea6\u533a\u95f4\u3002 \u53ef\u4ee5\u5c06`Period('2020', 'A-DEC')`\u770b\u4f5c\u4e00\u6bb5\u65f6\u95f4\u4e2d\u7684\u4e00\u79cd\u6e38\u6807\uff0c\u5c06\u65f6\u95f4\u6309\u6708\u4efd\u5212\u5206\u3002 p = pd.Period(2020, freq='A-DEC') print(p.asfreq('M', how='start')) 2020-01 print(p.asfreq('M', how='end')) 2020-12 \u5982\u679c\u8d22\u5e74\u7ed3\u675f\u4e0d\u572812\u6708\uff0c\u5219\u6bcf\u6708\u5206\u671f\u4f1a\u81ea\u52a8\u8c03\u6574\u3002 \u6309\u5f53\u5e74\u8d22\u5e74\u7ed3\u675f\u8ba1\u7b97\uff0c\u8d77\u59cb\u5e74\u4efd\u5c31\u662f\u4e0a\u4e00\u5e74\u4e86\u3002 p = pd.Period(2020, freq='A-JUN') print(p.asfreq('M', how='start')) 2019-07 print(p.asfreq('M', how='end')) 2020-06 \u5f53\u4ece\u9ad8\u9891\u7387\u5411\u4f4e\u9891\u7387\u8f6c\u6362\u65f6\uff0cpandas\u6839\u636e\u5b50\u533a\u95f4\u7684\"\u6240\u5c5e\"\u6765\u51b3\u5b9a\u7236\u533a\u95f4\u3002 \u4f8b\u5982\uff0c\u5728A-JUN\u9891\u7387\u4e2d\uff0cAug-2020\u662f2020\u533a\u95f4\u7684\u4e00\u90e8\u5206\uff1a print(p.asfreq('A-JUN')) 2020\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628a`year`\u548c`quarter`\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15\u3002 \u5b8c\u6574\u7684`PeriodIndex`\u5bf9\u8c61\u6216\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u6309\u7167\u76f8\u540c\u7684\u8bed\u4e49\u8fdb\u884c\u8f6c\u6362\uff1a rng = pd.period_range('2018', '2021', freq='A-DEC') data = np.random.randn(len(rng)) ts = pd.Series(data, index=rng) print(ts) 2018 0.221634 2019 -0.392724 2020 -0.355022 2021 0.114000 Freq: A-DEC, dtype: float64 \u4e0b\u9762\u5e74\u5ea6\u533a\u95f4\u5c06\u901a\u8fc7`asfreq`\u88ab\u66ff\u6362\u4e3a\u5bf9\u5e94\u4e8e\u6bcf\u4e2a\u5e74\u5ea6\u533a\u95f4\u5185\u7684\u7b2c\u4e00\u4e2a\u6708\u7684\u6708\u5ea6\u533a\u95f4\u3002 print(ts.asfreq('M', how='start')) 2018-01 0.681874 2019-01 -1.006585 2020-01 -0.619142 2021-01 1.445820 Freq: M, dtype: float64 \u5982\u679c\u6211\u4eec\u60f3\u8981\u6bcf\u5e74\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`B`\u9891\u7387\u6765\u8868\u793a\u6211\u4eec\u60f3\u8981\u7684\u662f\u533a\u95f4\u7684\u672b\u7aef\u3002 print(ts.asfreq('B', how='end')) 2018-12-31 -1.520316 2019-12-31 -0.425544 2020-12-31 -0.658073 2021-12-31 1.206881 Freq: B, dtype: float64 ### \u5b63\u5ea6\u533a\u95f4\u9891\u7387 \u5b63\u5ea6\u6570\u636e\u662f\u4f1a\u8ba1\u3001\u91d1\u878d\u548c\u5176\u4ed6\u9886\u57df\u7684\u6807\u51c6\u3002 \u5f88\u591a\u5b63\u5ea6\u6570\u636e\u662f\u5728\u8d22\u5e74\u7ed3\u5c3e\u62a5\u544a\u7684\uff0c\u901a\u5e38\u662f\u4e00\u5e7412\u4e2a\u6708\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5\u6216\u5de5\u4f5c\u65e5\u3002 pandas\u652f\u6301\u6240\u6709\u7684\u53ef\u80fd\u768412\u4e2a\u5b63\u5ea6\u9891\u7387\u4eceQ-JAN\u5230Q-DEC\uff1a \u4e0b\u4f8b\u4e2d\uff0c\u8d22\u5e74\u7ed3\u675f\u4e8e1\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7411\u6708\u81f3\u5f53\u5e741\u6708\u3002\u53ef\u4ee5\u901a\u8fc7\u8f6c\u6362\u4e3a\u6bcf\u65e5\u9891\u7387\uff08asfreq\uff09\u8fdb\u884c\u68c0\u67e5\u3002 p = pd.Period('2020Q4', freq='Q-JAN') print(p) 2020Q4 print(p.asfreq('D', 'start')) 2019-11-01 print(p.asfreq('D', 'end')) 2020-01-31 \u5047\u5982\u8d22\u5e74\u7ed3\u675f\u4e8e2\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7412\u6708\u81f3\u5f53\u5e742\u6708\u3002 p = pd.Period('2020Q4', freq='Q-FEB') print(p) 2020Q4 print(p.asfreq('D', 'start')) 2019-11-01 print(p.asfreq('D', 'end')) 2020-01-31 \u5047\u5982\u8d22\u5e74\u7ed3\u675f\u4e8e4\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7412\u6708\u81f3\u5f53\u5e742\u6708\u3002 p = pd.Period('2020Q4', freq='Q-APR') print(p) 2020Q4 print(p.asfreq('D', 'start')) 2020-02-01 print(p.asfreq('D', 'end')) 2020-04-30 \u53ef\u4ee5\u5bf9\u533a\u95f4\u6570\u636e\u505a\u7b97\u672f\u64cd\u4f5c\u3002\u4f8b\u5982\uff0c\u8981\u83b7\u53d6\u5728\u5b63\u5ea6\u5012\u6570\u7b2c\u4e8c\u4e2a\u5de5\u4f5c\u65e5\u4e0b\u53484\u70b9\u7684\u65f6\u95f4\u6233\uff0c\u53ef\u4ee5\u8fd9\u4e48\u505a\uff1a(\u7591\u95ee\uff1a\u8fd9\u91cc\u7684\u53c2\u6570e\u4ee3\u8868\u4ec0\u4e48 ???) p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60 print(p4pm) 2020-04-29 16:00 print(p4pm.to_timestamp()) 2020-04-29 16:00:00 \u53ef\u4ee5\u4f7f\u7528`peroid_range`\u751f\u6210\u5b63\u5ea6\u5e8f\u5217\u3002\u5b83\u7684\u7b97\u672f\u4e5f\u662f\u4e00\u6837\u7684\uff1a rng = pd.period_range('2000Q3', '2001Q4', freq='Q-JAN') ts = pd.Series(np.arange(len(rng)), index=rng) print(ts) 2000Q3 0 2000Q4 1 2001Q1 2 2001Q2 3 2001Q3 4 2001Q4 5 Freq: Q-JAN, dtype: int64 new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60 ts.index = new_rng.to_timestamp() print(ts) 1999-10-28 16:00:00 0 2000-01-28 16:00:00 1 2000-04-27 16:00:00 2 2000-07-28 16:00:00 3 2000-10-30 16:00:00 4 2001-01-30 16:00:00 5 dtype: int64 ### \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u533a\u95f4\uff08\u4ee5\u53ca\u9006\u8f6c\u6362\uff09 \u901a\u8fc7\u65f6\u95f4\u6233\u7d22\u5f15\u7684Series\u548cDataFrame\u53ef\u4ee5\u88ab`to_period`\u65b9\u6cd5\u8f6c\u6362\u4e3a\u533a\u95f4\uff1a rng = pd.date_range('2020-01-01', periods=3, freq='M') ts = pd.Series(np.random.randn(3), index=rng) print(ts) 2020-01-31 -0.567097 2020-02-29 0.63452\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628ayear\u548cquarter\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f152 2020-03-31 0.297777 Freq: M, dtype: float64 pts = ts.to_period() print(pts) 2020-01 -0.567097 2020-02 0.634522 2020-03 0.297777 Freq: M, dtype: float64 \u7531\u4e8e\u533a\u95f4\u662f\u975e\u91cd\u53e0\u65f6\u95f4\u8303\u56f4\uff0c\u4e00\u4e2a\u65f6\u95f4\u6233\u53ea\u80fd\u5c5e\u4e8e\u7ed9\u5b9a\u9891\u7387\u7684\u5355\u4e2a\u533a\u95f4\u3002 \u5c3d\u7ba1\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u6839\u636e\u65f6\u95f4\u6233\u63a8\u65ad\u51fa\u65b0`PeriodIndex`\u7684\u9891\u7387\uff0c\u4f46\u53ef\u4ee5\u6307\u5b9a\u4efb\u4f55\u60f3\u8981\u7684\u9891\u7387\u3002 \u5728\u7ed3\u679c\u4e2d\u5305\u542b\u91cd\u590d\u7684\u533a\u95f4\u4e5f\u662f\u6ca1\u6709\u95ee\u9898\u7684\u3002 rng = pd.date_range('2020-01-01', periods=6, freq='D') ts = pd.Series(np.random.randn(6), index=rng) print(ts) 2020-01-01 -0.111287 2020-01-02 1.442234 2020-01-03 -0.767553 2020-01-04 -0.265064 2020-01-05 1.200312 2020-01-06 -1.782557 Freq: D, dtype: float64 ts_m = ts.to_period('M') # \u6307\u5b9aperiod\u7684\u9891\u7387\uff08M\uff09,\u8f93\u51fa\u7ed3\u679c\u5305\u542b\u91cd\u590dperiod print(ts_m) 2020-01 -0.111287 2020-01 1.442234 2020-01 -0.767553 2020-01 -0.265064 2020-01 1.200312 2020-01 -1.782557 Freq: M, dtype: float64 \u4f7f\u7528`to_timestamp`\u53ef\u4ee5\u5c06\u533a\u95f4\u518d\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233\uff1a print(ts_m.to_timestamp(how='end')) 2020-01-31 23:59:59.999999999 -0.111287 2020-01-31 23:59:59.999999999 1.442234 2020-01-31 23:59:59.999999999 -0.767553 2020-01-31 23:59:59.999999999 -0.265064 2020-01-31 23:59:59.999999999 1.200312 2020-01-31 23:59:59.999999999 -1.782557 dtype: float64 print(ts_m.to_timestamp(how='start')) 2020-01-01 -0.111287 2020-01-01 1.442234 2020-01-01 -0.767553 2020-01-01 -0.265064 2020-01-01 1.200312 2020-01-01 -1.782557 dtype: float64 ### \u4ece\u6570\u7ec4\u751f\u6210PeriodIndex \u56fa\u5b9a\u9891\u7387\u6570\u636e\u96c6\u6709\u65f6\u5b58\u50a8\u5728\u8de8\u8d8a\u591a\u5217\u7684\u65f6\u95f4\u8303\u56f4\u4fe1\u606f\u4e2d\u3002\u4f8b\u5982\uff0c\u5728\u8fd9\u4e2a\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u96c6\u4e2d\uff0c\u5e74\u4efd\u548c\u5b63\u5ea6\u5728\u4e0d\u540c\u5217\u4e2d\uff1a data = pd.read_csv('../examples/macrodata.csv') print(data.head(5)) year quarter realgdp realcons ... unemp pop infl realint 0 1959.0 1.0 2710.349 1707.4 ... 5.8 177.146 0.00 0.00 1 1959.0 2.0 2778.801 1733.7 ... 5.1 177.830 2.34 0.74 2 1959.0 3.0 2775.488 1751.8 ... 5.3 178.657 2.74 1.09 3 1959.0 4.0 2785.204 1753.7 ... 5.6 179.386 0.27 4.06 4 1960.0 1.0 2847.699 1770.5 ... 5.2 180.007 2.31 1.19 print(data.year) 0 1959.0 1 1959.0 2 1959.0 3 1959.0 4 1960.0 ... 198 2008.0 199 2008.0 200 2009.0 201 2009.0 202 2009.0 Name: year, Length: 203, dtype: float64 print(data.quarter) 0 1.0 1 2.0 2 3.0 3 4.0 4 1.0 ... 198 3.0 199 4.0 200 1.0 201 2.0 202 3.0 Name: quarter, Length: 203, dtype: float64 \u901a\u8fc7\u5c06\u8fd9\u4e9b\u6570\u7ec4\u548c\u9891\u7387\u4f20\u9012\u7ed9`PeriodIndex`\uff0c\u53ef\u4ee5\u8054\u5408\u5f62\u6210DataFrame\u7684\u7d22\u5f15 index = pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC') print(index) PeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2', '1960Q3', '1960Q4', '1961Q1', '1961Q2', ... '2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3', '2008Q4', '2009Q1', '2009Q2', '2009Q3'], dtype='period[Q-DEC]', length=203) data.index = index # \u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628ayear\u548cquarter\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15 print(data.infl) 1959Q1 0.00 1959Q2 2.34 1959Q3 2.74 1959Q4 0.27 1960Q1 2.31 ... 2008Q3 -3.16 2008Q4 -8.79 2009Q1 0.94 2009Q2 3.37 2009Q3 3.56 Freq: Q-DEC, Name: infl, Length: 203, dtype: float64 ## \u91cd\u65b0\u91c7\u6837\u9891\u7387\u8f6c\u6362 import pandas as pd import numpy as np from pandas.tseries.frequencies import to_offset \u91cd\u65b0\u91c7\u6837\u662f\u6307\u5c06\u65f6\u95f4\u5e8f\u5217\u4ece\u4e00\u4e2a\u9891\u7387\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u9891\u7387\u7684\u8fc7\u7a0b\u3002 \u5c06\u66f4\u9ad8\u9891\u7387\u7684\u6570\u636e\u805a\u5408\u5230\u4f4e\u9891\u7387\u88ab\u79f0\u4e3a\u5411\u4e0b\u91c7\u6837\uff0c\u800c\u4ece\u4f4e\u9891\u7387\u8f6c\u6362\u5230\u9ad8\u9891\u7387\u79f0\u4e3a\u5411\u4e0a\u91c7\u6837\u3002 \u5e76\u4e0d\u662f\u6240\u6709\u7684\u91cd\u65b0\u91c7\u6837\u90fd\u5c5e\u4e8e\u4e0a\u9762\u8bf4\u7684\u4e24\u7c7b\u3002\u4f8b\u5982\uff0c\u5c06W-WED\uff08weekly on Wednesday\uff0c\u6bcf\u5468\u4e09\uff09\u8f6c\u6362\u5230W-FRI\uff08\u6bcf\u5468\u4e94\uff09\u65e2\u4e0d\u662f\u5411\u4e0a\u91c7\u6837\u4e5f\u4e0d\u662f\u5411\u4e0b\u91c7\u6837\u3002 pandas\u5bf9\u8c61\u90fd\u914d\u6709`resample`\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u6240\u6709\u9891\u7387\u8f6c\u6362\u7684\u5de5\u5177\u51fd\u6570\u3002`resample`\u62e5\u6709\u7c7b\u4f3c\u4e8e`groupby`\u7684API\uff1b\u8c03\u7528`resample`\u5bf9\u6570\u636e\u5206\u7ec4\uff0c\u4e4b\u540e\u518d\u8c03\u7528\u805a\u5408\u51fd\u6570\uff1a ### resample\u65b9\u6cd5\u53c2\u6570 \u53c2\u6570 * freq: \u8868\u793a\u91cd\u91c7\u6837\u9891\u7387\uff0c\u4f8b\u5982\u2018M'\u3001\u20185min'\uff0cSecond(15) * how='mean': \u7528\u4e8e\u4ea7\u751f\u805a\u5408\u503c\u7684\u51fd\u6570\u540d\u6216\u6570\u7ec4\u51fd\u6570\uff0c\u4f8b\u5982\u2018mean'\u3001\u2018ohlc'\u3001np.max\u7b49\uff0c\u9ed8\u8ba4\u662f\u2018mean'\uff0c\u5176\u4ed6\u5e38\u7528\u7684\u503c\u7531\uff1a\u2018first'\u3001\u2018last'\u3001\u2018median'\u3001\u2018max'\u3001\u2018min' * axis=0: \u9ed8\u8ba4\u662f\u7eb5\u8f74\uff0c\u6a2a\u8f74\u8bbe\u7f6eaxis=1 * fill_method = None: \u5347\u91c7\u6837\u65f6\u5982\u4f55\u63d2\u503c\uff0c\u6bd4\u5982\u2018ffill'\u3001\u2018bfill'\u7b49 * closed = \u2018right': \u5728\u964d\u91c7\u6837\u65f6\uff0c\u5404\u65f6\u95f4\u6bb5\u7684\u54ea\u4e00\u6bb5\u662f\u95ed\u5408\u7684\uff0c\u2018right'\u6216\u2018left'\uff0c\u9ed8\u8ba4\u2018right' * label= \u2018right': \u5728\u964d\u91c7\u6837\u65f6\uff0c\u5982\u4f55\u8bbe\u7f6e\u805a\u5408\u503c\u7684\u6807\u7b7e\uff0c\u4f8b\u5982\uff0c9\uff1a30-9\uff1a35\u4f1a\u88ab\u6807\u8bb0\u62109\uff1a30\u8fd8\u662f9\uff1a35,\u9ed8\u8ba49\uff1a35 * loffset = None: \u9762\u5143\u6807\u7b7e\u7684\u65f6\u95f4\u6821\u6b63\u503c\uff0c\u6bd4\u5982\u2018-1s'\u6216Second(-1)\u7528\u4e8e\u5c06\u805a\u5408\u6807\u7b7e\u8c03\u65e91\u79d2 * limit=None: \u5728\u5411\u524d\u6216\u5411\u540e\u586b\u5145\u65f6\uff0c\u5141\u8bb8\u586b\u5145\u7684\u6700\u5927\u65f6\u671f\u6570 * kind = None: \u805a\u5408\u5230\u65f6\u671f\uff08\u2018period'\uff09\u6216\u65f6\u95f4\u6233\uff08\u2018timestamp'\uff09\uff0c\u9ed8\u8ba4\u805a\u5408\u5230\u65f6\u95f4\u5e8f\u5217\u7684\u7d22\u5f15\u7c7b\u578b * convention = None: \u5f53\u91cd\u91c7\u6837\u65f6\u671f\u65f6\uff0c\u5c06\u4f4e\u9891\u7387\u8f6c\u6362\u5230\u9ad8\u9891\u7387\u6240\u91c7\u7528\u7684\u7ea6\u5b9a\uff08start\u6216end\uff09\u3002\u9ed8\u8ba4\u2018end' rng = pd.date_range('2020-1-1', periods=100, freq='D') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(ts) 2020-01-01 0.802409 2020-01-02 -1.147130 2020-01-03 -1.076115 2020-01-04 -2.097443 2020-01-05 0.577671 ... 2020-04-05 -0.110747 2020-04-06 0.132867 2020-04-07 -0.294061 2020-04-08 -0.246155 2020-04-09 0.927194 Freq: D, Length: 100, dtype: float64 print(ts.resample('M')) DatetimeIndexResampler [freq= , axis=0, closed=right, label=right, convention=start, origin=start_day] print(ts.resample('M').mean()) # \u628a100\u5929\u7684\u6570\u636e\u6309\u6708groupby\uff0c\u5e76\u8f93\u51fa\u6708\u672b\u6700\u540e\u4e00\u5929\uff0c\u8ba1\u7b97\u5e73\u5747\u503c 2020-01-31 -0.311714 2020-02-29 0.121526 2020-03-31 -0.051131 2020-04-30 -0.273113 Freq: M, dtype: float64 print(ts.resample('M', kind='period').mean()) # # \u628a100\u5929\u7684\u6570\u636e\u6309\u6708groupby\uff0c\u5e76\u8f93\u51fa\u6708\u4efd\uff08\u53c2\u6570period\uff09\uff0c\u8ba1\u7b97\u5e73\u5747\u503c 2020-01 -0.311714 2020-02 0.121526 2020-03 -0.051131 2020-04 -0.273113 Freq: M, dtype: float64 ### \u5411\u4e0b\u91c7\u6837 \u5c06\u6570\u636e\u805a\u5408\u5230\u4e00\u4e2a\u89c4\u5219\u7684\u4f4e\u9891\u7387\u4e0a\u662f\u4e00\u4e2a\u5e38\u89c1\u7684\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u3002 \u8981\u805a\u5408\u7684\u6570\u636e\u4e0d\u5fc5\u662f\u56fa\u5b9a\u9891\u7387\u7684\u3002 \u671f\u671b\u7684\u9891\u7387\u5b9a\u4e49\u4e86\u7528\u4e8e\u5bf9\u65f6\u95f4\u5e8f\u5217\u5207\u7247\u4ee5\u805a\u5408\u7684\u7bb1\u4f53\u8fb9\u754c\u3002\u4f8b\u5982\uff0c\u8981\u5c06\u65f6\u95f4\u8f6c\u6362\u4e3a\u6bcf\u6708\uff0c`M`\u6216`BM`\uff0c\u5219\u9700\u8981\u5c06\u6570\u636e\u5206\u6210\u4e00\u4e2a\u6708\u7684\u65f6\u95f4\u95f4\u9694\u3002 \u6bcf\u4e2a\u95f4\u9694\u662f\u534a\u95ed\u5408\u7684\uff0c\u4e00\u4e2a\u6570\u636e\u70b9\u53ea\u80fd\u5c5e\u4e8e\u4e00\u4e2a\u65f6\u95f4\u95f4\u9694\uff0c\u65f6\u95f4\u95f4\u9694\u7684\u5e76\u96c6\u5fc5\u987b\u662f\u6574\u4e2a\u65f6\u95f4\u5e27\u3002 \u5728\u4f7f\u7528resample\u8fdb\u884c\u5411\u4e0b\u91c7\u6837\u6570\u636e\u65f6\u6709\u4e9b\u4e8b\u60c5\u9700\u8981\u8003\u8651\uff1a * \u6bcf\u6bb5\u95f4\u9694\u7684\u54ea\u4e00\u8fb9\u662f\u95ed\u5408\u7684\u3002 * \u5982\u4f55\u5728\u95f4\u9694\u7684\u8d77\u59cb\u6216\u7ed3\u675f\u4f4d\u7f6e\u6807\u8bb0\u6bcf\u4e2a\u5df2\u805a\u5408\u7684\u7bb1\u4f53\u3002 rng = pd.date_range('2020-1-1', periods=12, freq='T') ts = pd.Series(np.arange(12), index=rng) print(ts) 2020-01-01 00:00:00 0 2020-01-01 00:01:00 1 2020-01-01 00:02:00 2 2020-01-01 00:03:00 3 2020-01-01 00:04:00 4 2020-01-01 00:05:00 5 2020-01-01 00:06:00 6 2020-01-01 00:07:00 7 2020-01-01 00:08:00 8 2020-01-01 00:09:00 9 2020-01-01 00:10:00 10 2020-01-01 00:11:00 11 Freq: T, dtype: int64 \u6309\u4e94\u5206\u949f\u9891\u7387\u805a\u5408\u5206\u7ec4\uff0c\u8ba1\u7b97\u6bcf\u4e00\u7ec4\u7684\u52a0\u548c\u3002\u9891\u7387\u6309\u4e94\u5206\u949f\u7684\u589e\u91cf\u5b9a\u4e49\u4e86\u7bb1\u4f53\u8fb9\u754c\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5de6\u7bb1\u4f53\u8fb9\u754c\u662f\u5305\u542b\u7684\uff0c\u56e0\u6b6400:00\u7684\u503c\u662f\u5305\u542b\u572800:00\u523000:05\u95f4\u9694\u5185\u7684\u3002 \u4f20\u9012`closed='right'`\u5c06\u95f4\u9694\u7684\u95ed\u5408\u7aef\u6539\u4e3a\u4e86\u53f3\u8fb9\u3002 \u5206\u7ec4\uff1a * left: [00:00,00:01,00:02,00:03,00:04],[00:05,00:06,00:07,00:08,00:09],[00:10,00:11] * right:[00:00],[00:01,00:02,00:03,00:04,00:05],[00:06,00:07,00:08,00:09,00:10],[00:11] result = ts.resample('5min', closed='right').sum() print(result) 2019-12-31 23:55:00 0 2020-01-01 00:00:00 15 2020-01-01 00:05:00 40 2020-01-01 00:10:00 11 Freq: 5T, dtype: int64 result = ts.resample('5min', closed='left').sum() print(result) 2020-01-01 00:00:00 10 2020-01-01 00:05:00 35 2020-01-01 00:10:00 21 Freq: 5T, dtype: int64 \u6700\u540e\uff0c\u5c06\u7ed3\u679c\u7d22\u5f15\u79fb\u52a8\u4e00\u5b9a\u7684\u6570\u91cf\uff0c\u4f8b\u5982\u4ece\u53f3\u8fb9\u7f18\u51cf\u53bb\u4e00\u79d2\uff0c\u4ee5\u4f7f\u5176\u66f4\u6e05\u695a\u5730\u8868\u660e\u65f6\u95f4\u6233\u6240\u6307\u7684\u95f4\u9694\u3002 \u8981\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u5411`loffset`\u4f20\u9012\u5b57\u7b26\u4e32\u6216\u65e5\u671f\u504f\u7f6e\uff1a result = ts.resample('5min', closed='right', label='right', loffset='-1s').sum() print(result) 2019-12-31 23:59:59 0 2020-01-01 00:04:59 15 2020-01-01 00:09:59 40 2020-01-01 00:14:59 11 Freq: 5T, dtype: int64 FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated. >>> df.resample(freq=\"3s\", loffset=\"8H\") becomes: >>> from pandas.tseries.frequencies import to_offset >>> df = df.resample(freq=\"3s\").mean() >>> df.index = df.index.to_timestamp() + to_offset(\"8H\") #### \u5f00\u7aef-\u5cf0\u503c-\u8c37\u503c-\u7ed3\u675f\uff08OHLC\uff09\u91cd\u65b0\u91c7\u6837 \u5728\u91d1\u878d\u4e2d\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u6876\u8ba1\u7b97\u56db\u4e2a\u503c\u662f\u4e00\u79cd\u6d41\u884c\u7684\u65f6\u95f4\u5e8f\u5217\u805a\u5408\u65b9\u6cd5\uff1a\u7b2c\u4e00\u4e2a\u503c\uff08\u5f00\u7aef\uff09\u3001\u6700\u540e\u4e00\u4e2a\u503c\uff08\u7ed3\u675f\uff09\u3001\u6700\u5927\u503c\uff08\u5cf0\u503c\uff09\u548c\u6700\u5c0f\u503c\uff08\u8c37\u503c\uff09\u3002 \u901a\u8fc7\u4f7f\u7528`ohlc`\u805a\u5408\u51fd\u6570\u53d6\u5f97\u5305\u542b\u56db\u79cd\u805a\u5408\u503c\u5217\u7684DataFrame\uff0c\u8fd9\u4e9b\u503c\u5728\u6570\u636e\u7684\u5355\u6b21\u626b\u63cf\u4e2d\u88ab\u9ad8\u6548\u8ba1\u7b97\uff1a result = ts.resample('5min').ohlc() print(result) open high low close 2020-01-01 00:00:00 0 4 0 4 2020-01-01 00:05:00 5 9 5 9 2020-01-01 00:10:00 10 11 10 11 ### \u5411\u4e0a\u91c7\u6837\u4e0e\u63d2\u503c \u5f53\u4ece\u4f4e\u9891\u7387\u8f6c\u6362\u4e3a\u9ad8\u9891\u7387\u65f6\uff0c\u5e76\u4e0d\u9700\u8981\u4efb\u4f55\u805a\u5408\u3002 df = pd.DataFrame( np.random.randn(2, 4), index=pd.date_range('2020/1/1', periods=2, freq='W-WED'), columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(df) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 df_daily = df.resample('W-WED').sum() print(df_daily) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 df_daily = df.resample('D').sum() print(df_daily) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-02 0.000000 0.000000 0.000000 0.000000 2020-01-03 0.000000 0.000000 0.000000 0.000000 2020-01-04 0.000000 0.000000 0.000000 0.000000 2020-01-05 0.000000 0.000000 0.000000 0.000000 2020-01-06 0.000000 0.000000 0.000000 0.000000 2020-01-07 0.000000 0.000000 0.000000 0.000000 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 \u5f53\u5bf9\u8fd9\u4e9b\u6570\u636e\u4f7f\u7528\u805a\u5408\u51fd\u6570\u65f6\uff0c\u6bcf\u4e00\u7ec4\u53ea\u6709\u4e00\u4e2a\u503c\uff0c\u5e76\u4e14\u4f1a\u5728\u95f4\u9699\u4e2d\u4ea7\u751f\u7f3a\u5931\u503c\u3002 \u4f7f\u7528`asfreq`\u65b9\u6cd5\u5728\u4e0d\u805a\u5408\u7684\u60c5\u51b5\u4e0b\u8f6c\u6362\u5230\u9ad8\u9891\u7387\uff1a df_daily = df.resample('D').asfreq() print(df_daily) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-02 NaN NaN NaN NaN 2020-01-03 NaN NaN NaN NaN 2020-01-04 NaN NaN NaN NaN 2020-01-05 NaN NaN NaN NaN 2020-01-06 NaN NaN NaN NaN 2020-01-07 NaN NaN NaN NaN 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 \u5728\u975e\u661f\u671f\u4e09\u7684\u65e5\u671f\u4e0a\u5411\u524d\u586b\u5145\u6bcf\u5468\u6570\u503c\u3002`fillna`\u548c`reindex`\u65b9\u6cd5\u4e2d\u53ef\u7528\u7684\u586b\u5145\u6216\u63d2\u503c\u65b9\u6cd5\u53ef\u7528\u4e8e\u91cd\u91c7\u6837\uff1a df_daily = df.resample('D').ffill() print(df_daily) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-03 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-04 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-05 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-06 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-07 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 \u53ef\u4ee5\u540c\u6837\u9009\u62e9\u4ec5\u5411\u524d\u586b\u5145\u4e00\u5b9a\u6570\u91cf\u7684\u533a\u95f4\uff0c\u4ee5\u9650\u5236\u7ee7\u7eed\u4f7f\u7528\u89c2\u6d4b\u503c\u7684\u65f6\u8ddd\uff1a df_daily = df.resample('D').ffill(limit=2) print(df_daily) Colorado Texas New York Ohio 2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-03 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-04 NaN NaN NaN NaN 2020-01-05 NaN NaN NaN NaN 2020-01-06 NaN NaN NaN NaN 2020-01-07 NaN NaN NaN NaN 2020-01-08 -0.704541 -0.261414 -0.863335 0.267101 \u6ce8\u610f\uff0c\u65b0\u7684\u65e5\u671f\u7d22\u5f15\u4e0d\u9700\u8981\u4e0e\u65e7\u7684\u7d22\u5f15\u91cd\u53e0\uff0c\u548c\u539f\u6765`df`\u7684\u503c\u4e00\u6837\uff0c\u53ea\u662f\u65e5\u671f\u7d22\u5f15\u53d8\u4e86\u3002 df_new = df.resample('W-THU').ffill() print(df_new) Colorado Texas New York Ohio 2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819 2020-01-09 -0.704541 -0.261414 -0.863335 0.267101 ### \u4f7f\u7528\u533a\u95f4\u8fdb\u884c\u91cd\u65b0\u91c7\u6837 \u5bf9\u4ee5\u533a\u95f4\u4e3a\u7d22\u5f15\u7684\u6570\u636e\u8fdb\u884c\u91c7\u6837\u4e0e\u65f6\u95f4\u6233\u7684\u60c5\u51b5\u7c7b\u4f3c\uff1a df = pd.DataFrame( np.random.randn(24, 4), index=pd.period_range('2020-1', periods=24, freq='M'), columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(df) 2020-01 0.721395 -1.492674 0.707410 1.641890 2020-02 -0.894880 0.032823 -0.676158 0.029203 2020-03 2.147365 -0.176796 0.562695 -0.747656 2020-04 1.496037 -0.797119 -0.495601 0.774147 2020-05 -0.309839 0.502563 0.237244 0.910624 2020-06 1.231869 -0.105227 1.315759 0.217701 2020-07 1.447419 0.263876 -0.342045 -0.768907 2020-08 -2.567162 -1.008827 0.391085 1.259560 2020-09 -0.772501 1.183532 0.450374 0.450714 2020-10 0.228974 0.461224 1.393178 0.175243 2020-11 -0.725193 -1.544131 1.372029 -0.659224 2020-12 0.718195 0.862024 -0.166460 -0.940191 2021-01 -0.617054 -0.887312 0.338451 -1.392838 2021-02 -0.081140 0.634730 -0.868051 -1.277167 2021-03 -0.999642 -1.959715 -0.930662 0.748687 2021-04 1.851453 1.561669 -0.688822 -0.371255 2021-05 -0.540777 -0.890403 -1.204188 0.243480 2021-06 1.318905 1.247457 0.518969 0.799793 2021-07 0.223238 0.747177 -0.410889 0.904593 2021-08 -0.652551 -0.254351 -0.464604 -0.676923 2021-09 0.562312 0.182099 0.018617 0.573331 2021-10 0.429490 -0.045959 -0.356292 -0.295776 2021-11 2.552155 0.801299 1.378421 1.232792 2021-12 1.102288 0.850280 -0.767015 -0.519840 df_annual = df.resample('A-DEC').mean() print(df_annual) Colorado Texas New York Ohio 2020 0.226807 -0.151561 0.395793 0.195259 2021 0.429056 0.165581 -0.286339 -0.002594 \u5411\u4e0a\u91c7\u6837\u66f4\u4e3a\u7ec6\u81f4\uff0c\u56e0\u4e3a\u5fc5\u987b\u5728\u91cd\u65b0\u91c7\u6837\u524d\u51b3\u5b9a\u65b0\u9891\u7387\u4e2d\u5728\u65f6\u95f4\u6bb5\u7684\u54ea\u4e00\u7aef\u653e\u7f6e\u6570\u503c\uff0c\u5c31\u50cfasfreq\u65b9\u6cd5\u4e00\u6837\u3002 `convention`\u53c2\u6570\u9ed8\u8ba4\u503c\u662f`start`\uff0c\u4f46\u4e5f\u53ef\u4ee5\u662f`end`\uff1a result = df_annual.resample('Q-DEC').ffill() print(result) Colorado Texas New York Ohio 2020Q1 0.226807 -0.151561 0.395793 0.195259 2020Q2 0.226807 -0.151561 0.395793 0.195259 2020Q3 0.226807 -0.151561 0.395793 0.195259 2020Q4 0.226807 -0.151561 0.395793 0.195259 2021Q1 0.429056 0.165581 -0.286339 -0.002594 2021Q2 0.429056 0.165581 -0.286339 -0.002594 2021Q3 0.429056 0.165581 -0.286339 -0.002594 2021Q4 0.429056 0.165581 -0.286339 -0.002594 result = df_annual.resample('Q-DEC', convention='end').ffill() print(result) Colorado Texas New York Ohio 2020Q4 0.226807 -0.151561 0.395793 0.195259 2021Q1 0.226807 -0.151561 0.395793 0.195259 2021Q2 0.226807 -0.151561 0.395793 0.195259 2021Q3 0.226807 -0.151561 0.395793 0.195259 2021Q4 0.429056 0.165581 -0.286339 -0.002594 \u7531\u4e8e\u533a\u95f4\u6d89\u53ca\u65f6\u95f4\u8303\u56f4\uff0c\u5411\u4e0a\u91c7\u6837\u548c\u5411\u4e0b\u91c7\u6837\u5c31\u66f4\u4e3a\u4e25\u683c\uff1a * \u5728\u5411\u4e0b\u91c7\u6837\u4e2d\uff0c\u76ee\u6807\u9891\u7387\u5fc5\u987b\u662f\u539f\u9891\u7387\u7684\u5b50\u533a\u95f4\u3002 * \u5728\u5411\u4e0a\u91c7\u6837\u4e2d\uff0c\u76ee\u6807\u9891\u7387\u5fc5\u987b\u662f\u539f\u9891\u7387\u7684\u7236\u533a\u95f4\u3002 \u5982\u679c\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u89c4\u5219\uff0c\u5c06\u4f1a\u5f15\u8d77\u5f02\u5e38\u3002\u8fd9\u4e3b\u8981\u4f1a\u5f71\u54cd\u6bcf\u5b63\u5ea6\u3001\u6bcf\u5e74\u548c\u6bcf\u5468\u7684\u9891\u7387\u3002 \u4f8b\u5982\uff0c\u6839\u636eQ-MAR\u5b9a\u4e49\u7684\u65f6\u95f4\u8303\u56f4\u5c06\u53ea\u548cA-MAR\u3001A-JUN\u3001A-SEP\u548cA-DEC\u4fdd\u6301\u4e00\u81f4\uff1a result = df_annual.resample('Q-MAR').ffill() print(result) Colorado Texas New York Ohio 2020Q4 0.226807 -0.151561 0.395793 0.195259 2021Q1 0.226807 -0.151561 0.395793 0.195259 2021Q2 0.226807 -0.151561 0.395793 0.195259 2021Q3 0.226807 -0.151561 0.395793 0.195259 2021Q4 0.429056 0.165581 -0.286339 -0.002594 2022Q1 0.429056 0.165581 -0.286339 -0.002594 2022Q2 0.429056 0.165581 -0.286339 -0.002594 2022Q3 0.429056 0.165581 -0.286339 -0.002594 ## \u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u7edf\u8ba1\u90a3\u4e9b\u901a\u8fc7\u79fb\u52a8\u7a97\u53e3\u6216\u6307\u6570\u8870\u51cf\u800c\u8fd0\u884c\u7684\u51fd\u6570\uff0c\u662f\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u64cd\u4f5c\u7684\u6570\u7ec4\u53d8\u6362\u7684\u4e00\u4e2a\u91cd\u8981\u7c7b\u522b\u3002 \u8fd9\u5bf9\u5e73\u6ed1\u566a\u58f0\u6216\u7c97\u7cd9\u7684\u6570\u636e\u975e\u5e38\u6709\u7528\u3002\u79f0\u8fd9\u4e9b\u51fd\u6570\u4e3a\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\uff0c\u5c3d\u7ba1\u5b83\u4e5f\u5305\u542b\u4e86\u4e00\u4e9b\u6ca1\u6709\u56fa\u5b9a\u957f\u5ea6\u7a97\u53e3\u7684\u51fd\u6570\uff0c\u6bd4\u5982\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u4e0e\u5176\u4ed6\u7684\u7edf\u8ba1\u51fd\u6570\u7c7b\u4f3c\uff0c\u8fd9\u4e9b\u51fd\u6570\u4f1a\u81ea\u52a8\u6392\u9664\u7f3a\u5931\u6570\u636e\u3002 import matplotlib.pyplot as plt import pandas as pd from scipy.stats import percentileofscore import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz \u5728\u6df1\u5165\u4e86\u89e3\u4e4b\u524d\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u8f7d\u5165\u4e00\u4e9b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e76\u6309\u7167\u5de5\u4f5c\u65e5\u9891\u7387\u8fdb\u884c\u91cd\u65b0\u91c7\u6837\uff1a close_px_all = pd.read_csv( '../examples/stock_px_2.csv', parse_dates = True, index_col=0 ) print(close_px_all.head(5)) AAPL MSFT XOM SPX 2003-01-02 7.40 21.11 29.22 909.03 2003-01-03 7.45 21.14 29.24 908.59 2003-01-06 7.45 21.52 29.96 929.01 2003-01-07 7.43 21.93 28.95 922.93 2003-01-08 7.28 21.31 28.83 909.93 close_px = close_px_all[ ['AAPL', 'MSFT', 'XOM'] ] close_px = close_px.resample('B').ffill() print(close_px) AAPL MSFT XOM 2003-01-02 7.40 21.11 29.22 2003-01-03 7.45 21.14 29.24 ... ... ... ... 2011-10-13 408.43 27.18 76.37 2011-10-14 422.00 27.27 78.11 [2292 rows x 3 columns] `rolling`\u7b97\u5b50\uff0c\u5b83\u7684\u884c\u4e3a\u4e0e`resample`\u548c`groupby`\u7c7b\u4f3c\u3002 `rolling`\u53ef\u4ee5\u5728Series\u6216DataFrame\u4e0a\u901a\u8fc7\u4e00\u4e2awindow\uff08\u4ee5\u4e00\u4e2a\u533a\u95f4\u7684\u6570\u5b57\u6765\u8868\u793a\uff09\u8fdb\u884c\u8c03\u7528\u3002 close_px.AAPL.plot() \u8868\u8fbe\u5f0f`rolling(250)`\u4e0e`groupby`\u7684\u884c\u4e3a\u7c7b\u4f3c\uff0c\u4f46\u662f\u5b83\u521b\u5efa\u7684\u5bf9\u8c61\u662f\u6839\u636e250\u65e5\u6ed1\u52a8\u7a97\u53e3\u5206\u7ec4\u7684\u800c\u4e0d\u662f\u76f4\u63a5\u5206\u7ec4\u3002 \u56e0\u6b64\u8fd9\u91cc\u6211\u4eec\u83b7\u5f97\u4e86\u82f9\u679c\u516c\u53f8\u80a1\u7968\u4ef7\u683c\u7684250\u65e5\u79fb\u52a8\u7a97\u53e3\u5e73\u5747\u503c\u3002 close_px.AAPL.rolling(250).mean().plot() plt.show() \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6eda\u52a8\u51fd\u6570\u9700\u8981\u7a97\u53e3\u4e2d\u6240\u6709\u7684\u503c\u5fc5\u987b\u662f\u975e`NA`\u503c\u3002 \u7531\u4e8e\u5b58\u5728\u7f3a\u5931\u503c\u8fd9\u79cd\u884c\u4e3a\u4f1a\u53d1\u751f\u6539\u53d8\uff0c\u5c24\u5176\u662f\u5728\u65f6\u95f4\u5e8f\u5217\u7684\u8d77\u59cb\u4f4d\u7f6e\u4f60\u62e5\u6709\u7684\u6570\u636e\u662f\u5c11\u4e8e\u7a97\u53e3\u533a\u95f4\u7684 apple_std250 = close_px.AAPL.rolling(250, min_periods=10).std() # \u82f9\u679c\u516c\u53f8250\u65e5\u6bcf\u65e5\u8fd4\u56de\u6807\u51c6\u5dee print(apple_std250[5:12]) 2003-01-09 NaN 2003-01-10 NaN 2003-01-13 NaN 2003-01-14 NaN 2003-01-15 0.077496 2003-01-16 0.074760 2003-01-17 0.112368 Freq: B, Name: AAPL, dtype: float64 apple_std250.plot() plt.show() expanding_mean = apple_std250.expanding().mean() print(expanding_mean[5:12]) 2003-01-09 NaN 2003-01-10 NaN 2003-01-13 NaN 2003-01-14 NaN 2003-01-15 0.077496 2003-01-16 0.076128 2003-01-17 0.088208 Freq: B, Name: AAPL, dtype: float64 expanding_mean.plot() plt.show() \u5728DataFrame\u4e0a\u8c03\u7528\u4e00\u4e2a\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\u4f1a\u5c06\u53d8\u6362\u5e94\u7528\u5230\u6bcf\u4e00\u5217\u4e0a: close_px.rolling(60).mean().plot(logy=True) # \u80a1\u7968\u4ef7\u683c60\u65e5MA\uff08Y\u8f74\u53d6\u5bf9\u6570\uff09 plt.show() `rolling`\u51fd\u6570\u4e5f\u63a5\u6536\u8868\u793a\u56fa\u5b9a\u5927\u5c0f\u7684\u65f6\u95f4\u504f\u7f6e\u5b57\u7b26\u4e32\uff0c\u800c\u4e0d\u53ea\u662f\u4e00\u4e2a\u533a\u95f4\u7684\u96c6\u5408\u6570\u5b57\u3002 \u5bf9\u4e0d\u89c4\u5219\u65f6\u95f4\u5e8f\u5217\u4f7f\u7528\u6ce8\u91ca\u975e\u5e38\u6709\u7528\u3002\u8fd9\u4e9b\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f20\u9012\u7ed9`resample`\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u50cf\u8fd9\u6837\u8ba1\u7b9720\u5929\u7684\u6eda\u52a8\u5e73\u5747\u503c\uff1a result = close_px.rolling('20D').mean() print(result) AAPL MSFT XOM 2003-01-02 7.400000 21.110000 29.220000 ... ... ... ... 2011-10-14 391.038000 26.048667 74.185333 [2292 rows x 3 columns] result.plot() plt.show() ### \u6307\u6570\u52a0\u6743\u51fd\u6570 \u6307\u5b9a\u4e00\u4e2a\u5e38\u6570\u8870\u51cf\u56e0\u5b50\u4ee5\u5411\u66f4\u591a\u8fd1\u671f\u89c2\u6d4b\u503c\u63d0\u4f9b\u66f4\u591a\u6743\u91cd\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f7f\u7528\u5177\u6709\u76f8\u7b49\u52a0\u6743\u89c2\u5bdf\u503c\u7684\u9759\u6001\u7a97\u53e3\u5c3a\u5bf8\u7684\u65b9\u6cd5\u3002 \u6709\u591a\u79cd\u65b9\u5f0f\u53ef\u4ee5\u6307\u5b9a\u8870\u51cf\u56e0\u5b50\u3002\u5176\u4e2d\u4e00\u79cd\u6d41\u884c\u7684\u65b9\u5f0f\u662f\u4f7f\u7528\u4e00\u4e2aspan\uff08\u8de8\u5ea6\uff09\uff0c\u8fd9\u4f7f\u5f97\u7ed3\u679c\u4e0e\u7a97\u53e3\u5927\u5c0f\u7b49\u4e8e\u8de8\u5ea6\u7684\u7b80\u5355\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\u3002 \u7531\u4e8e\u6307\u6570\u52a0\u6743\u7edf\u8ba1\u503c\u7ed9\u66f4\u8fd1\u671f\u7684\u89c2\u6d4b\u503c\u4ee5\u66f4\u591a\u7684\u6743\u91cd\uff0c\u4e0e\u7b49\u6743\u91cd\u7684\u7248\u672c\u76f8\u6bd4\uff0c\u5b83\u5bf9\u53d8\u5316\u201c\u9002\u5e94\u201d\u5f97\u66f4\u5feb\u3002 pandas\u62e5\u6709`ewm`\u7b97\u5b50\uff0c\u540c`rolling`\u3001`expanding`\u7b97\u5b50\u4e00\u8d77\u4f7f\u7528\u3002 \u4ee5\u4e0b\u662f\u5c06\u82f9\u679c\u516c\u53f8\u80a1\u7968\u4ef7\u683c\u768460\u65e5\u5747\u7ebf\u4e0e`span=60`\u7684EW\u79fb\u52a8\u5e73\u5747\u7ebf\u8fdb\u884c\u6bd4\u8f83\u7684\u4f8b\u5b50\uff1a aapl_ex = close_px.AAPL['2006':'2007'] ma60 = aapl_ex.rolling(30, min_periods=20).mean() ewma60 = aapl_ex.ewm(span=30).mean() ma60.plot(style='k--', label='Simple MA') ewma60.plot(style='k-', label='EWMA') plt.legend() plt.show() ### \u4e8c\u5143\u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u4e00\u4e9b\u7edf\u8ba1\u7b97\u5b50\uff0c\u4f8b\u5982\u76f8\u5173\u5ea6\u548c\u534f\u65b9\u5dee\uff0c\u9700\u8981\u64cd\u4f5c\u4e24\u4e2a\u65f6\u95f4\u5e8f\u5217\u3002 \u4f8b\u5982\uff0c\u91d1\u878d\u5206\u6790\u5e08\u7ecf\u5e38\u5bf9\u80a1\u7968\u4e0e\u57fa\u51c6\u6307\u6570\uff08\u5982\u6807\u666e500\uff09\u7684\u5173\u8054\u6027\u611f\u5174\u8da3\u3002 \u6211\u4eec\u9996\u5148\u8ba1\u7b97\u6240\u6709\u6211\u4eec\u611f\u5174\u8da3\u7684\u65f6\u95f4\u5e8f\u5217\u7684\u767e\u5206\u6bd4\u53d8\u5316\uff1a spx_px = close_px_all['SPX'] spx_rets = spx_px.pct_change() returns = close_px.pct_change() \u5728\u8c03\u7528rolling\u540e\uff0ccorr\u805a\u5408\u51fd\u6570\u53ef\u4ee5\u6839\u636espx_rets\u8ba1\u7b97\u6eda\u52a8\u76f8\u5173\u6027\uff1a corr = returns.AAPL.rolling(125, min_periods=100).corr(spx_rets) # \u82f9\u679c\u516c\u53f8\u4e0e\u6807\u666e500\u7684\u516d\u4e2a\u6708\u7684\u6536\u76ca\u76f8\u5173\u6027 corr.plot() plt.show() corr = returns.rolling(125, min_periods=100).corr(spx_rets) # \u591a\u53ea\u80a1\u7968\u4e0e\u6807\u666e500\u7684\u516d\u4e2a\u6708\u6536\u76ca\u76f8\u5173\u6027 corr.plot() plt.show() ### \u7528\u6237\u81ea\u5b9a\u4e49\u7684\u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u5728`rolling`\u53ca\u5176\u76f8\u5173\u65b9\u6cd5\u4e0a\u4f7f\u7528apply\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u79fb\u52a8\u7a97\u53e3\u4e2d\u5e94\u7528\u4f60\u81ea\u5df1\u8bbe\u8ba1\u7684\u6570\u7ec4\u51fd\u6570\u7684\u65b9\u6cd5\u3002 \u552f\u4e00\u7684\u8981\u6c42\u662f\u8be5\u51fd\u6570\u4ece\u6bcf\u4e2a\u6570\u7ec4\u4e2d\u4ea7\u751f\u4e00\u4e2a\u5355\u503c\uff08\u7f29\u805a\uff09\u3002 \u4f8b\u5982\uff0c\u5c3d\u7ba1\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`rolling(...).quantile(q)`\u8ba1\u7b97\u6837\u672c\u7684\u5206\u4f4d\u6570\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u4f1a\u5bf9\u6837\u672c\u4e2d\u7279\u5b9a\u503c\u7684\u767e\u5206\u4f4d\u6570\u611f\u5174\u8da3\u3002 `scipy.stats.percentileofscore`\u51fd\u6570\u5c31\u662f\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\u7684\uff1a score_at_2percent = lambda x: percentileofscore(x, 0.02) result = returns.AAPL.rolling(250).apply(score_at_2percent) # \u4e00\u5e74\u7a97\u53e3\u4e0b\u82f9\u679c\u516c\u53f8\u80a1\u4ef72%\u6536\u76ca\u7684\u767e\u5206\u4f4d\u7b49\u7ea7 result.plot() plt.show() result = returns.rolling(250).apply(score_at_2percent) # \u4e00\u5e74\u7a97\u53e3\u4e0b\u6240\u6709\u516c\u53f8\u80a1\u4ef72%\u6536\u76ca\u7684\u767e\u5206\u4f4d\u7b49\u7ea7 result.plot() plt.show() ```","title":"\u65f6\u95f4\u5e8f\u5217"},{"location":"python/DataAnalysis/ch08/#_1","text":"","title":"\u65f6\u95f4\u5e8f\u5217"},{"location":"python/DataAnalysis/ch08/#_2","text":"\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5f88\u591a\u9886\u57df\u90fd\u662f\u91cd\u8981\u7684\u7ed3\u6784\u5316\u6570\u636e\u5f62\u5f0f\u3002\u5728\u591a\u4e2a\u65f6\u95f4\u70b9\u89c2\u6d4b\u6216\u6d4b\u91cf\u7684\u6570\u636e\u5f62\u6210\u4e86\u65f6\u95f4\u5e8f\u5217\u3002 \u8bb8\u591a\u65f6\u95f4\u5e8f\u5217\u662f\u56fa\u5b9a\u9891\u7387\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u6570\u636e\u662f\u6839\u636e\u76f8\u540c\u7684\u89c4\u5219\u5b9a\u671f\u51fa\u73b0\u7684\uff0c\u4f8b\u5982\u6bcf15\u79d2\u3001\u6bcf5\u5206\u949f\u6216\u6bcf\u67081\u6b21\u3002 \u65f6\u95f4\u5e8f\u5217\u4e5f\u53ef\u4ee5\u662f\u4e0d\u89c4\u5219\u7684\uff0c\u6ca1\u6709\u56fa\u5b9a\u7684\u65f6\u95f4\u5355\u4f4d\u6216\u5355\u4f4d\u95f4\u7684\u504f\u79fb\u91cf\u3002 \u5982\u4f55\u6807\u8bb0\u548c\u5f15\u7528\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53d6\u51b3\u4e8e\u5e94\u7528\u7a0b\u5e8f\uff0c\u65f6\u95f4\u5e8f\u5217\u5305\u62ec\uff1a \u65f6\u95f4\u6233\uff0c\u5177\u4f53\u7684\u65f6\u523b\u3002 \u56fa\u5b9a\u7684\u65f6\u95f4\u533a\u95f4\uff0c\u4f8b\u59822007\u76841\u6708\u6216\u6574\u4e2a2010\u5e74\u3002 \u65f6\u95f4\u95f4\u9694\uff0c\u7531\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u6233\u8868\u793a\u3002\u65f6\u95f4\u533a\u95f4\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u95f4\u9694\u7684\u7279\u6b8a\u60c5\u51b5\u3002 \u5b9e\u9a8c\u65f6\u95f4\u6216\u6d88\u8017\u65f6\u95f4\u3002\u6bcf\u4e2a\u65f6\u95f4\u6233\u662f\u76f8\u5bf9\u4e8e\u7279\u5b9a\u5f00\u59cb\u65f6\u95f4\u7684\u65f6\u95f4\u7684\u91cf\u5ea6\uff08\u4f8b\u5982\uff0c\u81ea\u4ece\u88ab\u653e\u7f6e\u5728\u70e4\u7bb1\u4e2d\u6bcf\u79d2\u70d8\u70e4\u7684\u997c\u5e72\u7684\u76f4\u5f84\uff09\u3002 \u76ee\u524d\u4e3b\u8981\u5173\u6ce8\u524d\u4e09\u7c7b\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u3002 from datetime import datetime, timedelta import datetime as dt from dateutil.parser import parse import pandas as pd","title":"\u65e5\u671f\u548c\u65f6\u95f4\u6570\u636e\u7684\u7c7b\u578b\u53ca\u5de5\u5177"},{"location":"python/DataAnalysis/ch08/#datetime","text":"datetime\u683c\u5f0f\u7b26\uff1a %a \u661f\u671f\u7684\u82f1\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u661f\u671f\u4e00\uff0c \u5219\u8fd4\u56de Mon %A \u661f\u671f\u7684\u82f1\u6587\u5355\u8bcd\u7684\u5168\u62fc\uff1a\u5982\u661f\u671f\u4e00\uff0c\u8fd4\u56de Monday %b \u6708\u4efd\u7684\u82f1\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u4e00\u6708\uff0c \u5219\u8fd4\u56de Jan %B \u6708\u4efd\u7684\u5f15\u6587\u5355\u8bcd\u7684\u7f29\u5199\uff1a\u5982\u4e00\u6708\uff0c \u5219\u8fd4\u56de January %c \u8fd4\u56dedatetime\u7684\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u598203/08/15 23:01:26 %d \u8fd4\u56de\u7684\u662f\u5f53\u524d\u65f6\u95f4\u662f\u5f53\u524d\u6708\u7684\u7b2c\u51e0\u5929 %f \u5fae\u79d2\u7684\u8868\u793a\uff1a \u8303\u56f4: [0,999999] %H \u4ee524\u5c0f\u65f6\u5236\u8868\u793a\u5f53\u524d\u5c0f\u65f6 %I \u4ee512\u5c0f\u65f6\u5236\u8868\u793a\u5f53\u524d\u5c0f\u65f6 %m \u8fd4\u56de\u6708\u4efd \u8303\u56f4[0,12] %M \u8fd4\u56de\u5206\u949f\u6570 \u8303\u56f4 [0,59] %P \u8fd4\u56de\u662f\u4e0a\u5348\u8fd8\u662f\u4e0b\u5348\u2013AM or PM %S \u8fd4\u56de\u79d2\u6570 \u8303\u56f4 [0,61]\u3002\u3002\u3002\u624b\u518c\u8bf4\u660e\u7684 %U \u8fd4\u56de\u5f53\u5468\u662f\u5f53\u5e74\u7684\u7b2c\u51e0\u5468 \u4ee5\u5468\u65e5\u4e3a\u7b2c\u4e00\u5929 %W \u8fd4\u56de\u5f53\u5468\u662f\u5f53\u5e74\u7684\u7b2c\u51e0\u5468 \u4ee5\u5468\u4e00\u4e3a\u7b2c\u4e00\u5929 %w \u5f53\u5929\u5728\u5f53\u5468\u7684\u5929\u6570\uff0c\u8303\u56f4\u4e3a[0, 6]\uff0c6\u8868\u793a\u661f\u671f\u5929 %x \u65e5\u671f\u7684\u5b57\u7b26\u4e32\u8868\u793a \uff1a03/08/15 %X \u65f6\u95f4\u7684\u5b57\u7b26\u4e32\u8868\u793a \uff1a23:22:08 %y \u4e24\u4e2a\u6570\u5b57\u8868\u793a\u7684\u5e74\u4efd 15 %Y \u56db\u4e2a\u6570\u5b57\u8868\u793a\u7684\u5e74\u4efd 2015 %z \u4e0eutc\u65f6\u95f4\u7684\u95f4\u9694 \uff08\u5982\u679c\u662f\u672c\u5730\u65f6\u95f4\uff0c\u8fd4\u56de\u7a7a\u5b57\u7b26\u4e32\uff09 %Z \u65f6\u533a\u540d\u79f0\uff08\u5982\u679c\u662f\u672c\u5730\u65f6\u95f4\uff0c\u8fd4\u56de\u7a7a\u5b57\u7b26\u4e32\uff09 datestrs = ['2020/5/6', '2021/10/1'] # \u6ce8\u610f\u533a\u5206datetime\u6a21\u5757\u548cdatetime\u7c7b\uff0c\u540d\u5b57\u76f8\u540c\uff0c\u5bb9\u6613\u5f15\u8d77\u9519\u8bef\u3002 # \u6bd4\u5982datetime.datetime\u5c31\u62a5\u9519type object 'datetime.datetime' has no attribute 'datetime' print(datetime) # <class 'datetime.datetime'> print(dt) # <module 'datetime' from '/opt/Python-3.9.6/Lib/datetime.py'> Python\u6807\u51c6\u5e93\u5305\u542b\u4e86\u65e5\u671f\u548c\u65f6\u95f4\u6570\u636e\u7684\u7c7b\u578b\u3002 datetime \u3001 time \u548c calendar \u6a21\u5757\u662f\u5f00\u59cb\u5904\u7406\u65f6\u95f4\u6570\u636e\u7684\u4e3b\u8981\u5185\u5bb9\u3002 datetime.datetime \u7c7b\u578b\uff0c\u6216\u7b80\u5199\u4e3a datetime \uff0c\u662f\u5e7f\u6cdb\u4f7f\u7528\u7684\u3002 now = datetime.now() print(now) # 2021-10-07 20:24:43.834293 result = dt.datetime(2021, 10, 7, 20, 26, 00, 72973) print(result) # 2021-10-07 20:26:00.072973 datetime \u65e2\u5b58\u50a8\u4e86\u65e5\u671f\uff0c\u4e5f\u5b58\u50a8\u4e86\u7ec6\u5316\u5230\u5fae\u79d2\u7684\u65f6\u95f4\u3002 timedelta \u8868\u793a\u4e24\u4e2a datetime \u5bf9\u8c61\u7684\u65f6\u95f4\u5dee\u3002 delta = datetime(2021, 10, 7) - datetime(2021, 9, 7) print(delta) # 30 days, 0:00:00 print(delta.days) # 30 print(delta.seconds) # 0 result = dt.timedelta(926, 56700) print(result) # 926 days, 15:45:00 \u53ef\u4ee5\u4e3a\u4e00\u4e2a datetime \u5bf9\u8c61\u52a0\u4e0a\uff08\u6216\u51cf\u53bb\uff09\u4e00\u4e2a timedelta \u6216\u5176\u6574\u6570\u500d\u6765\u4ea7\u751f\u4e00\u4e2a\u65b0\u7684 datetime \u5bf9\u8c61\u3002 start = datetime(2021, 10, 7) result = start + timedelta(12) print(result) # 2021-10-19 00:00:00 result = start - 2 * timedelta(5) print(result) # 2021-09-27 00:00:00","title":"datetime"},{"location":"python/DataAnalysis/ch08/#datetime_1","text":"\u4f7f\u7528 str \u65b9\u6cd5\u6216\u4f20\u9012\u4e00\u4e2a\u6307\u5b9a\u7684\u683c\u5f0f\u7ed9 strftime \u65b9\u6cd5\u6765\u5bf9 datetime \u5bf9\u8c61\u548cpandas\u7684 Timestamp \u5bf9\u8c61\u8fdb\u884c\u683c\u5f0f\u5316\u3002 stamp = datetime(2021, 10, 7) result = str(stamp) print(result) # 2021-10-07 00:00:00 \u4f7f\u7528 datetime.srtptime \u548c datetime \u683c\u5f0f\u7b26\uff0c\u628a\u5b57\u7b26\u4e32\u8f6c\u6362\u65e5\u671f\u3002 datetime.strptime \u662f\u5728\u5df2\u77e5\u683c\u5f0f\u7684\u60c5\u51b5\u4e0b\u8f6c\u6362\u65e5\u671f\u7684\u597d\u65b9\u5f0f\u3002 value = '2021-10-7' result = datetime.strptime(value, '%Y-%m-%d') print(result) # 2021-10-07 00:00:00 datestrs = ['2020/5/6', '2021/10/1'] result = [datetime.strptime(x, '%Y/%m/%d') for x in datestrs] print(result) # [datetime.datetime(2020, 5, 6, 0, 0), datetime.datetime(2021, 10, 1, 0, 0)] dateutil \u89e3\u6790\u901a\u7528\u65e5\u671f\u683c\u5f0f\uff1a print(parse('2020/5/6')) # 2020-05-06 00:00:00 print(parse('Jan 31, 2021 10:25 AM')) # 2021-01-31 10:25:00 print(parse('5/6/2021', dayfirst=True)) # \u65e5\u671f\u51fa\u73b0\u5728\u6708\u4efd\u4e4b\u524d # 2021-06-05 00:00:00 pandas\u4e3b\u8981\u662f\u9762\u5411\u5904\u7406\u65e5\u671f\u6570\u7ec4\u7684\uff0c\u65e0\u8bba\u662f\u7528\u4f5c\u8f74\u7d22\u5f15\u8fd8\u662f\u7528\u4f5cDataFrame\u4e2d\u7684\u5217\u3002 to_datetime \u65b9\u6cd5\u53ef\u4ee5\u8f6c\u6362\u5f88\u591a\u4e0d\u540c\u7684\u65e5\u671f\u8868\u793a\u683c\u5f0f\u3002 to_datetime \u65b9\u6cd5\u8fd8\u53ef\u4ee5\u5904\u7406\u90a3\u4e9b\u88ab\u8ba4\u4e3a\u662f\u7f3a\u5931\u503c\u7684\u503c\uff08None\u3001\u7a7a\u5b57\u7b26\u4e32\u7b49\uff09\u3002 NaT \uff08Not a time\uff09\u662fpandas\u4e2d\u65f6\u95f4\u6233\u6570\u636e\u7684\u662fnull\u503c\u3002 datestrs = ['2020/5/6 12:00:00', '2021/10/1 09:00:00'] result = pd.to_datetime(datestrs) print(result) # DatetimeIndex(['2020-05-06 12:00:00', '2021-10-01 09:00:00'], dtype='datetime64[ns]', freq=None) idx = pd.to_datetime(datestrs + [None]) print(idx) # DatetimeIndex(['2020-05-06 12:00:00', '2021-10-01 09:00:00', 'NaT'], dtype='datetime64[ns]', freq=None) print(idx[2]) # NaT print(pd.isnull(idx)) # [False False True]","title":"\u5b57\u7b26\u4e32\u4e0edatetime\u4e92\u76f8\u8f6c\u6362"},{"location":"python/DataAnalysis/ch08/#_3","text":"from datetime import datetime import pandas as pd import numpy as np","title":"\u65f6\u95f4\u5e8f\u5217\u57fa\u7840"},{"location":"python/DataAnalysis/ch08/#datetimeindex","text":"pandas\u4e2d\u7684\u57fa\u7840\u65f6\u95f4\u5e8f\u5217\u79cd\u7c7b\u662f\u7531\u65f6\u95f4\u6233\u7d22\u5f15\u7684Series\uff0c\u5728pandas\u5916\u90e8\u5219\u901a\u5e38\u8868\u793a\u4e3aPython\u5b57\u7b26\u4e32\u6216 datetime \u5bf9\u8c61\u3002 \u6240\u6709\u4f7f\u7528 datetime \u5bf9\u8c61\u7684\u5730\u65b9\u90fd\u53ef\u4ee5\u7528 Timestamp \u3002 dates = [ datetime(2021, 10, 1), datetime(2021, 10, 3), datetime(2021, 10, 5), datetime(2021, 10, 7), datetime(2021, 10, 9), datetime(2021, 10, 11) ] data = np.random.rand(6) ts = pd.Series(data, index=dates) print(ts) # 2021-10-01 0.678297 # 2021-10-03 0.538631 # 2021-10-05 0.934413 # 2021-10-07 0.018534 # 2021-10-09 0.938441 # 2021-10-11 0.173329 # dtype: float64 \u8fd9\u4e9b datetime \u5bf9\u8c61\u88ab\u653e\u5165 DatetimeIndex \u4e2d\u3002 print(ts.index) # DatetimeIndex(['2021-10-01', '2021-10-03', '2021-10-05', '2021-10-07', # '2021-10-09', '2021-10-11'], # dtype='datetime64[ns]', freq=None) DatetimeIndex \u4e2d\u7684\u6807\u91cf\u503c\u662f pandas \u7684 Timestamp \u5bf9\u8c61\uff1a stamp = ts.index[0] print(stamp) # 2021-10-01 00:00:00 \u548c\u5176\u4ed6Series\u7c7b\u4f3c\uff0c\u4e0d\u540c\u7d22\u5f15\u7684\u65f6\u95f4\u5e8f\u5217\u4e4b\u95f4\u7684\u7b97\u672f\u8fd0\u7b97\u5728\u65e5\u671f\u4e0a\u81ea\u52a8\u5bf9\u9f50\uff1a print(ts + ts[::2]) # ts[::2]\u4f1a\u5c06ts\u4e2d\u6bcf\u9694\u4e00\u4e2a\u7684\u5143\u7d20\u9009\u62e9\u51fa # 2021-10-01 1.356595 # 2021-10-03 NaN # 2021-10-05 1.868825 # 2021-10-07 NaN # 2021-10-09 1.876883 # 2021-10-11 NaN # dtype: float64 pandas\u4f7f\u7528NumPy\u7684 datetime64 \u6570\u636e\u7c7b\u578b\u5728\u7eb3\u79d2\u7ea7\u7684\u5206\u8fa8\u7387\u4e0b\u5b58\u50a8\u65f6\u95f4\u6233 print(ts.index.dtype) # datetime64[ns]","title":"DatetimeIndex"},{"location":"python/DataAnalysis/ch08/#_4","text":"\u5f53\u57fa\u4e8e\u6807\u7b7e\u8fdb\u884c\u7d22\u5f15\u548c\u9009\u62e9\u65f6\uff0c\u65f6\u95f4\u5e8f\u5217\u7684\u884c\u4e3a\u548c\u5176\u4ed6\u7684pandas.Series\u7c7b\u4f3c\uff1a stamp = ts.index[2] print(ts[stamp]) # 0.9344125159374457 \u5bf9\u5e942021-10-05 \u4e5f\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u80fd\u89e3\u91ca\u4e3a\u65e5\u671f\u7684\u5b57\u7b26\u4e32\uff1a print(ts['10/9/2021']) print(ts['20211003']) \u5bf9\u4e00\u4e2a\u957f\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u5e74\u4efd\u6216\u4e00\u4e2a\u5e74\u4efd\u548c\u6708\u4efd\u6765\u9009\u62e9\u6570\u636e\u5207\u7247\uff1a data = np.random.randn(1000) longer_ts = pd.Series( data, index=pd.date_range('1/1/2021', periods=1000) ) print(longer_ts) # 2021-01-01 -0.009192 # 2021-01-02 -1.079068 # 2021-01-03 -1.851176 # 2021-01-04 1.347109 # 2021-01-05 -0.236394 # ... # 2023-09-23 -1.317943 # 2023-09-24 0.201741 # 2023-09-25 0.442282 # 2023-09-26 0.176137 # 2023-09-27 1.146437 # Freq: D, Length: 1000, dtype: float64 \u5b57\u7b26\u4e32\u20192001\u2019\u88ab\u89e3\u91ca\u4e3a\u4e00\u4e2a\u5e74\u4efd\uff0c\u5e76\u9009\u62e9\u4e86\u76f8\u5e94\u7684\u65f6\u95f4\u533a\u95f4\u3002 print(longer_ts['2021']) # 2021-01-01 2.170411 # 2021-01-02 1.186933 # 2021-01-03 0.399262 # 2021-01-04 -1.042606 # 2021-01-05 2.082112 # ... # 2021-12-27 -0.988282 # 2021-12-28 0.598683 # 2021-12-29 2.770580 # 2021-12-30 -1.463262 # 2021-12-31 -1.642846 # Freq: D, Length: 365, dtype: float64 \u6307\u5b9a\u4e86\u5e74\u4efd\u548c\u6708\u4efd\u4e5f\u662f\u6709\u6548\u7684\u3002 print(longer_ts['2021-10']) # 2021-10-01 0.712265 # 2021-10-02 1.195221 # 2021-10-03 -1.930220 # 2021-10-04 -0.720816 # 2021-10-05 0.081777 # 2021-10-06 -0.037466 # 2021-10-07 3.737303 # 2021-10-08 1.620383 # 2021-10-09 0.990797 # 2021-10-10 0.507850 # 2021-10-11 0.846935 # 2021-10-12 0.996947 # 2021-10-13 -1.078558 # 2021-10-14 0.871832 # 2021-10-15 -0.591698 # 2021-10-16 -0.805463 # 2021-10-17 0.160528 # 2021-10-18 -0.028474 # 2021-10-19 2.305579 # 2021-10-20 -1.132288 # 2021-10-21 0.649980 # 2021-10-22 0.615327 # 2021-10-23 0.185108 # 2021-10-24 0.857199 # 2021-10-25 -1.473752 # 2021-10-26 -0.895161 # 2021-10-27 -0.432717 # 2021-10-28 0.734504 # 2021-10-29 1.892493 # 2021-10-30 0.456619 # 2021-10-31 -0.255288 # Freq: D, dtype: float64 \u4f7f\u7528 datetime \u5bf9\u8c61\u8fdb\u884c\u5207\u7247\u4e5f\u662f\u53ef\u4ee5\u7684\uff1a print(longer_ts[datetime(2023, 1, 6):]) # 2023-01-06 0.952591 # 2023-01-07 -0.900259 # 2023-01-08 0.925332 # 2023-01-09 0.173215 # 2023-01-10 -0.507791 # ... # 2023-09-23 -0.319989 # 2023-09-24 -1.105417 # 2023-09-25 -2.118769 # 2023-09-26 0.009420 # 2023-09-27 -0.310281 # Freq: D, Length: 265, dtype: float64 \u56e0\u4e3a\u5927\u90e8\u5206\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u662f\u6309\u65f6\u95f4\u987a\u5e8f\u6392\u5e8f\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0d\u5305\u542b\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u6233\u8fdb\u884c\u5207\u7247\uff0c\u4ee5\u6267\u884c\u8303\u56f4\u67e5\u8be2\uff1a print(longer_ts['2021/10/1':'2021/10/5']) # 2021-10-01 -0.591853 # 2021-10-02 -1.554564 # 2021-10-03 -0.712585 # 2021-10-04 -0.326657 # 2021-10-05 1.044887 # Freq: D, dtype: float64 \u4f7f\u7528 truncate \u5728\u4e24\u4e2a\u65e5\u671f\u95f4\u5bf9Series\u8fdb\u884c\u5207\u7247\uff1a print(longer_ts.truncate(after='2021/10/1')) # 2021-01-01 -0.906685 # 2021-01-02 -0.470732 # 2021-01-03 -0.041316 # 2021-01-04 -0.287356 # 2021-01-05 0.104268 # ... # 2021-09-27 -0.669198 # 2021-09-28 -2.222169 # 2021-09-29 -0.653814 # 2021-09-30 -0.625868 # 2021-10-01 0.872684 # Freq: D, Length: 274, dtype: float64 \u4e0a\u9762\u8fd9\u4e9b\u64cd\u4f5c\u4e5f\u90fd\u9002\u7528\u4e8eDataFrame\uff0c\u5e76\u5728\u5176\u884c\u4e0a\u8fdb\u884c\u7d22\u5f15\uff1a dates = pd.date_range('10/1/2020', periods=100, freq='W-WED') data = np.random.randn(100, 4) long_df = pd.DataFrame( data, index=dates, columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(long_df) # Colorado Texas New York Ohio # 2020-10-07 -1.186789 2.020634 0.300076 -0.955234 # 2020-10-14 1.502838 0.965368 -0.797539 -0.292833 # ... ... ... ... ... # 2022-08-24 -0.253116 -0.263307 0.602425 0.370599 # 2022-08-31 0.907918 0.091939 0.789694 2.781535 # [100 rows x 4 columns] print(long_df.loc['10-2020']) # Colorado Texas New York Ohio # 2020-10-07 1.031616 -1.812038 -0.446577 0.395656 # 2020-10-14 -0.673167 0.198804 -0.439141 0.086004 # 2020-10-21 -1.139786 0.716820 0.006516 -0.284335 # 2020-10-28 -0.637939 1.647810 -0.750786 0.140637","title":"\u7d22\u5f15\u3001\u9009\u62e9\u3001\u5b50\u96c6"},{"location":"python/DataAnalysis/ch08/#_5","text":"\u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\uff0c\u53ef\u80fd\u4f1a\u6709\u591a\u4e2a\u6570\u636e\u89c2\u5bdf\u503c\u843d\u5728\u7279\u5b9a\u7684\u65f6\u95f4\u6233\u4e0a\u3002\u4e0b\u9762\u662f\u4e2a\u4f8b\u5b50\uff1a dates = pd.DatetimeIndex( ['2021/1/1', '2021/1/2', '2021/1/2', '2021/1/2', '2021/1/3'] ) dup_ts = pd.Series( np.arange(5), index=dates ) print(dup_ts) # 2021-01-01 0 # 2021-01-02 1 # 2021-01-02 2 # 2021-01-02 3 # 2021-01-03 4 # dtype: int64 \u901a\u8fc7\u68c0\u67e5\u7d22\u5f15\u7684 is_unique \u5c5e\u6027\uff0c\u53ef\u4ee5\u770b\u51fa\u7d22\u5f15\u5e76\u4e0d\u662f\u552f\u4e00\u7684\uff1a print(dup_ts.index.is_unique) # False \u5bf9\u4e0a\u9762\u7684Series\u8fdb\u884c\u7d22\u5f15\uff0c\u7ed3\u679c\u662f\u6807\u91cf\u503c\u8fd8\u662fSeries\u5207\u7247\u53d6\u51b3\u4e8e\u662f\u5426\u6709\u65f6\u95f4\u6233\u662f\u91cd\u590d\u7684\uff1a result = dup_ts['2021/1/3'] print(result) # 4 result = dup_ts['2021/1/2'] print(result) # 2021-01-02 1 # 2021-01-02 2 # 2021-01-02 3 # dtype: int64 \u5047\u8bbe\u60f3\u8981\u805a\u5408\u542b\u6709\u975e\u552f\u4e00\u65f6\u95f4\u6233\u7684\u6570\u636e\u3002\u4e00\u79cd\u65b9\u5f0f\u5c31\u662f\u4f7f\u7528 groupby \u5e76\u4f20\u9012 level=0 \uff1a grouped = dup_ts.groupby(level=0) result = grouped.mean() print(result) # 2021-01-01 0.0 # 2021-01-02 2.0 # 2021-01-03 4.0 # dtype: float64 result = grouped.count() print(result) # 2021-01-01 1 # 2021-01-02 3 # 2021-01-03 1 # dtype: int64","title":"\u542b\u6709\u91cd\u590d\u7d22\u5f15\u7684\u65f6\u95f4\u5e8f\u5217"},{"location":"python/DataAnalysis/ch08/#_6","text":"from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd pandas\u7684\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u662f\u4e0d\u89c4\u5219\u7684\uff0c\u5373\u65f6\u95f4\u5e8f\u5217\u7684\u9891\u7387\u4e0d\u662f\u56fa\u5b9a\u7684\u3002 \u4f46\u6709\u65f6\u9700\u8981\u5904\u7406\u56fa\u5b9a\u9891\u7387\u7684\u573a\u666f\uff0c\u4f8b\u5982\u6bcf\u65e5\u7684\u3001\u6bcf\u6708\u7684\u6216\u6bcf15\u5206\u949f\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002 \u53ef\u4ee5\u901a\u8fc7\u8c03\u7528resample\u65b9\u6cd5\u5c06\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fa\u5b9a\u7684\u6bcf\u65e5\u9891\u7387\u6570\u636e\u3002 \u5728\u9891\u7387\u95f4\u8f6c\u6362\uff0c\u53c8\u79f0\u4e3a\u91cd\u65b0\u91c7\u6837\u3002 dates = [ datetime(2021, 10, 1), datetime(2021, 10, 3), datetime(2021, 10, 5), datetime(2021, 10, 7), datetime(2021, 10, 9), datetime(2021, 10, 11) ] data = np.random.rand(6) ts = pd.Series(data, index=dates) print(ts) # 2021-10-01 0.956685 # 2021-10-03 0.817168 # 2021-10-05 0.275543 # 2021-10-07 0.614226 # 2021-10-09 0.061377 # 2021-10-11 0.357080 # dtype: float64 resampler = ts.resample('D') # \u5b57\u7b26\u4e32\u2019D\u2019\u88ab\u89e3\u91ca\u4e3a\u6bcf\u65e5\u9891\u7387 print(resampler) # DatetimeIndexResampler [freq=<Day>, axis=0, closed=left, label=left, convention=start, origin=start_day]","title":"\u65e5\u671f\u8303\u56f4\u3001\u9891\u7387\u548c\u79fb\u4f4d"},{"location":"python/DataAnalysis/ch08/#_7","text":"pandas.date_range \u662f\u7528\u4e8e\u6839\u636e\u7279\u5b9a\u9891\u7387\u751f\u6210\u6307\u5b9a\u957f\u5ea6\u7684 DatetimeIndex \u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c date_range \u751f\u6210\u7684\u662f\u6bcf\u65e5\u7684\u65f6\u95f4\u6233\u3002\u5982\u679c\u53ea\u4f20\u9012\u4e00\u4e2a\u8d77\u59cb\u6216\u7ed3\u5c3e\u65e5\u671f\uff0c\u4f60\u5fc5\u987b\u4f20\u9012\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u8303\u56f4\u7684\u6570\u5b57\u3002 \u5f00\u59cb\u65e5\u671f\u548c\u7ed3\u675f\u65e5\u671f\u4e25\u683c\u5b9a\u4e49\u4e86\u751f\u6210\u65e5\u671f\u7d22\u5f15\u7684\u8fb9\u754c\u3002 index = pd.date_range('2021/1/1', '2021/1/30') print(index) index = pd.date_range(start='2021/1/1', periods=30) print(index) index = pd.date_range(end='2021/1/30', periods=30) print(index) # DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', # '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', # '2021-01-09', '2021-01-10', '2021-01-11', '2021-01-12', # '2021-01-13', '2021-01-14', '2021-01-15', '2021-01-16', # '2021-01-17', '2021-01-18', '2021-01-19', '2021-01-20', # '2021-01-21', '2021-01-22', '2021-01-23', '2021-01-24', # '2021-01-25', '2021-01-26', '2021-01-27', '2021-01-28', # '2021-01-29', '2021-01-30'], # dtype='datetime64[ns]', freq='D') \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c date_range \u4fdd\u7559\u5f00\u59cb\u6216\u7ed3\u675f\u65f6\u95f4\u6233\u7684\u65f6\u95f4\uff08\u5982\u679c\u6709\u7684\u8bdd\uff09\u3002 normalize \u9009\u9879\u53ef\u4ee5\u5b9e\u73b0\u751f\u6210\u7684\u662f\u6807\u51c6\u5316\u4e3a\u96f6\u70b9\u7684\u65f6\u95f4\u6233\u3002 index = pd.date_range('2021/1/1 12:56:30', periods=5) print(index) # DatetimeIndex(['2021-01-01 12:56:30', '2021-01-02 12:56:30', # '2021-01-03 12:56:30', '2021-01-04 12:56:30', # '2021-01-05 12:56:30'], # dtype='datetime64[ns]', freq='D') index = pd.date_range('2021/1/1 12:56:30', periods=5, normalize=True) print(index) # DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', # '2021-01-05'], # dtype='datetime64[ns]', freq='D') Pandas\u65f6\u95f4\u5e8f\u5217\uff1a\u9891\u7387\u548c\u65e5\u671f\u504f\u79fb\u91cf\u3002 pandas\u4e2d\u7684\u9891\u7387\u662f\u7531\u4e00\u4e2a\u57fa\u7840\u9891\u7387(\u4f8b\u5982\u201c\u65e5\u201d\u3001\u201c\u6708\u201d)\u548c\u4e00\u4e2a\u4e58\u6570\u7ec4\u6210\u3002 \u57fa\u7840\u9891\u7387\u901a\u5e38\u4ee5\u4e00\u4e2a\u5b57\u7b26\u4e32\u522b\u540d\u8868\u793a\uff0c\u6bd4\u5982\u201cD\u201d\u8868\u793a\u65e5\uff0c\u201cM\u201d\u8868\u793a\u6708\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u57fa\u7840\u9891\u7387\uff0c\u90fd\u6709\u4e00\u4e2a\u88ab\u79f0\u4e3a\u65e5\u671f\u504f\u79fb\u91cf(dateoffset)\u7684\u5bf9\u8c61\u4e0e\u4e4b\u5bf9\u5e94\uff0c\u6bd4\u5982\u65e5\u671f\u504f\u79fb\u91cf Hour \u5bf9\u5e94\u7684\u9891\u7387\u662f H \u3002 \u5e38\u7528\u9891\u7387\u4e0e\u65e5\u671f\u504f\u79fb\u91cf\u3002 \u9891\u7387 \u65e5\u671f\u504f\u79fb\u91cf \u8bf4\u660e D Day \u65e5\u5386\u65e5 B BusinessDay \u5de5\u4f5c\u65e5 H Hour \u5c0f\u65f6 T/min Minute \u5206 S Second \u79d2 L/ms Milli \u6beb\u79d2 U Micro \u5fae\u79d2 M MonthEnd \u6bcf\u6708\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BM BusinessMonthEnd \u6bcf\u6708\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 MS MonthBegin \u6bcf\u6708\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BMS BussinessMonthBegin \u6bcf\u6708\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5 W-MON, W-TUE, ... Week \u6307\u5b9a\u661f\u671f\u51e0(MON,TUE,WED,THU,FRI,SAT,SUN) WOM-1MON,WOM-2MON, ... WeekOfMonth \u4ea7\u751f\u6bcf\u6708\u7b2c\u4e00,\u7b2c\u4e8c,\u7b2c\u4e09\u6216\u7b2c\u56db\u5468\u7684\u661f\u671f\u51e0\u3002\u4f8b\u5982WOM-3FRI\u8868\u793a\u6bcf\u6708\u7b2c3\u4e2a\u661f\u671f\u4e94 Q-JAN,Q-FEB, ... QuarterEnd \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BQ-JAN,BQ-FEB, ... BusinessQuarterEnd \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 QS-JAN,QS-FEB, ... QuarterBegin \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BQS-JAN,BQS-FEB, ... BusinessQuarterBegin \u4ee5\u6307\u5b9a\u6708\u4efd\u7ed3\u675f\u7684\u5e74\u5ea6\uff0c\u6bcf\u5b63\u5ea6\u6700\u540e\u4e00\u4e2a\u6708\u7684\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5 A-JAN,A-FEB, ... YearEnd \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5 BA-JAN,BA-FEB, ... BusinessYearEnd \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5 AS-JAN,AS-FEB, ... YearBegin \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u7b2c\u4e00\u4e2a\u65e5\u5386\u65e5 BAS-JAN,BAS-FEB, ... BusinessYearBegin \u6bcf\u5e74\u6307\u5b9a\u6708\u4efd\u7684\u7b2c\u4e00\u4e2a\u5de5\u4f5c\u65e5","title":"\u751f\u6210\u65e5\u671f\u8303\u56f4"},{"location":"python/DataAnalysis/ch08/#_8","text":"pandas\u4e2d\u7684\u9891\u7387\u662f\u7531\u57fa\u7840\u9891\u7387\u548c\u500d\u6570\u7ec4\u6210\u7684\u3002 \u57fa\u7840\u9891\u7387\u901a\u5e38\u4f1a\u6709\u5b57\u7b26\u4e32\u522b\u540d\uff0c\u4f8b\u5982 M \u4ee3\u8868\u6bcf\u6708\uff0c H \u4ee3\u8868\u6bcf\u5c0f\u65f6\u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u57fa\u7840\u9891\u7387\uff0c\u90fd\u6709\u4e00\u4e2a\u5bf9\u8c61\u53ef\u4ee5\u88ab\u7528\u4e8e\u5b9a\u4e49\u65e5\u671f\u504f\u7f6e\u3002 \u4f8b\u5982\uff0c\u6bcf\u5c0f\u65f6\u7684\u9891\u7387\u53ef\u4ee5\u4f7f\u7528 Hour \u7c7b\u6765\u8868\u793a\uff1a ```hour = Hour() print(hour)","title":"\u9891\u7387\u548c\u65e5\u671f\u504f\u7f6e"},{"location":"python/DataAnalysis/ch08/#_9","text":"\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u6574\u6570\u6765\u5b9a\u4e49\u504f\u7f6e\u91cf\u7684\u500d\u6570\uff1a four_hours = Hour(4) print(four_hours)","title":""},{"location":"python/DataAnalysis/ch08/#4-hours","text":"\u5728\u5927\u591a\u6570\u5e94\u7528\u4e2d\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u5730\u521b\u5efa\u8fd9\u4e9b\u5bf9\u8c61\uff0c\u800c\u662f\u4f7f\u7528\u5b57\u7b26\u4e32\u522b\u540d\uff0c\u5982`H`\u6216`4H`\u3002\u5728\u57fa\u7840\u9891\u7387\u524d\u653e\u4e00\u4e2a\u6574\u6570\u5c31\u53ef\u4ee5\u751f\u6210\u500d\u6570\uff1a ts = pd.date_range('2021/1/1', '2021/1/2 23:59', freq='4h') print(ts)","title":"&lt;4 * Hours&gt;"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-01-000000-2021-01-01-040000","text":"","title":"DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 04:00:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-01-080000-2021-01-01-120000","text":"","title":"'2021-01-01 08:00:00', '2021-01-01 12:00:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-01-160000-2021-01-01-200000","text":"","title":"'2021-01-01 16:00:00', '2021-01-01 20:00:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-02-000000-2021-01-02-040000","text":"","title":"'2021-01-02 00:00:00', '2021-01-02 04:00:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-02-080000-2021-01-02-120000","text":"","title":"'2021-01-02 08:00:00', '2021-01-02 12:00:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-02-160000-2021-01-02-200000","text":"","title":"'2021-01-02 16:00:00', '2021-01-02 20:00:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-freq4h","text":"\u591a\u4e2a\u504f\u7f6e\u53ef\u4ee5\u901a\u8fc7\u52a0\u6cd5\u8fdb\u884c\u8054\u5408\uff1a print(Hour(2) + Minute(30))","title":"dtype='datetime64[ns]', freq='4H')"},{"location":"python/DataAnalysis/ch08/#150-minutes","text":"\u7c7b\u4f3c\u5730\uff0c\u53ef\u4ee5\u4f20\u9012\u9891\u7387\u5b57\u7b26\u4e32\uff1a ts = pd.date_range('2021/1/1', '2021/1/1 23:59', freq='4h30min') print(ts)","title":"&lt;150 * Minutes&gt;"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-01-000000-2021-01-01-043000","text":"","title":"DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 04:30:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-01-090000-2021-01-01-133000","text":"","title":"'2021-01-01 09:00:00', '2021-01-01 13:30:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-01-180000-2021-01-01-223000","text":"","title":"'2021-01-01 18:00:00', '2021-01-01 22:30:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-freq270t","text":"\u6709\u4e9b\u9891\u7387\u63cf\u8ff0\u70b9\u7684\u65f6\u95f4\u5e76\u4e0d\u662f\u5747\u5300\u5206\u9694\u7684\u3002\u4f8b\u5982\uff0c`M`\uff08\u65e5\u5386\u6708\u672b\uff09\u548c`BM`\uff08\u6708\u5185\u6700\u540e\u5de5\u4f5c\u65e5\uff09\u53d6\u51b3\u4e8e\u5f53\u6708\u5929\u6570\uff0c\u6708\u672b\u662f\u5426\u662f\u5468\u672b\u3002\u6211\u4eec\u5c06\u8fd9\u4e9b\u65e5\u671f\u79f0\u4e3a\u951a\u5b9a\u504f\u7f6e\u91cf\u3002 #### \u6708\u4e2d\u67d0\u661f\u671f\u7684\u65e5\u671f \"\u6708\u4e2d\u67d0\u661f\u671f\"\uff08week of month \uff09\u7684\u65e5\u671f\u662f\u4e00\u4e2a\u6709\u7528\u7684\u9891\u7387\u7c7b\uff0c\u4ee5`WOM`\u5f00\u59cb\u3002 rng = pd.date_range('2021-1-1', '2021-9-1', freq='WOM-3FRI') # \u6bcf\u6708\u7b2c\u4e09\u4e2a\u661f\u671f\u4e94 print(rng)","title":"dtype='datetime64[ns]', freq='270T')"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-15-2021-02-19-2021-03-19-2021-04-16","text":"","title":"DatetimeIndex(['2021-01-15', '2021-02-19', '2021-03-19', '2021-04-16',"},{"location":"python/DataAnalysis/ch08/#2021-05-21-2021-06-18-2021-07-16-2021-08-20","text":"","title":"'2021-05-21', '2021-06-18', '2021-07-16', '2021-08-20'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-freqwom-3fri","text":"### \u79fb\u4f4d\uff08\u524d\u5411\u548c\u540e\u5411\uff09\u65e5\u671f \"\u79fb\u4f4d\"\u662f\u6307\u5c06\u65e5\u671f\u6309\u65f6\u95f4\u5411\u524d\u79fb\u52a8\u6216\u5411\u540e\u79fb\u52a8\u3002 Series\u548cDataFrame\u90fd\u6709\u4e00\u4e2a`shift`\u65b9\u6cd5\u7528\u4e8e\u8fdb\u884c\u7b80\u5355\u7684\u524d\u5411\u6216\u540e\u5411\u79fb\u4f4d\uff0c\u800c\u4e0d\u6539\u53d8\u7d22\u5f15\u3002 \u8fdb\u884c\u79fb\u4f4d\u65f6\uff0c\u4f1a\u5728\u65f6\u95f4\u5e8f\u5217\u7684\u8d77\u59cb\u4f4d\u6216\u7ed3\u675f\u4f4d\u5f15\u5165\u7f3a\u5931\u503c\u3002 data = [0.882972, 1.363282, -0.687750, -0.048117] ts = pd.Series(data, index=pd.date_range('2021-1-1', periods=4, freq='M')) print(ts)","title":"dtype='datetime64[ns]', freq='WOM-3FRI')"},{"location":"python/DataAnalysis/ch08/#2021-01-31-0882972","text":"","title":"2021-01-31    0.882972"},{"location":"python/DataAnalysis/ch08/#2021-02-28-1363282","text":"","title":"2021-02-28    1.363282"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0687750","text":"","title":"2021-03-31   -0.687750"},{"location":"python/DataAnalysis/ch08/#2021-04-30-0048117","text":"","title":"2021-04-30   -0.048117"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64","text":"print(ts.shift(2))","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-nan","text":"","title":"2021-01-31         NaN"},{"location":"python/DataAnalysis/ch08/#2021-02-28-nan","text":"","title":"2021-02-28         NaN"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0882972","text":"","title":"2021-03-31    0.882972"},{"location":"python/DataAnalysis/ch08/#2021-04-30-1363282","text":"","title":"2021-04-30    1.363282"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_1","text":"print(ts.shift(-2))","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-0687750","text":"","title":"2021-01-31   -0.687750"},{"location":"python/DataAnalysis/ch08/#2021-02-28-0048117","text":"","title":"2021-02-28   -0.048117"},{"location":"python/DataAnalysis/ch08/#2021-03-31-nan","text":"","title":"2021-03-31         NaN"},{"location":"python/DataAnalysis/ch08/#2021-04-30-nan","text":"","title":"2021-04-30         NaN"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_2","text":"`shift`\u5e38\u7528\u4e8e\u8ba1\u7b97\u65f6\u95f4\u5e8f\u5217\u6216DataFrame\u591a\u5217\u65f6\u95f4\u5e8f\u5217\u7684\u767e\u5206\u6bd4\u53d8\u5316\uff1a print(ts/ts.shift(1))","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-nan_1","text":"","title":"2021-01-31         NaN"},{"location":"python/DataAnalysis/ch08/#2021-02-28-1543970","text":"","title":"2021-02-28    1.543970"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0504481","text":"","title":"2021-03-31   -0.504481"},{"location":"python/DataAnalysis/ch08/#2021-04-30-0069963","text":"","title":"2021-04-30    0.069963"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_3","text":"print(ts/ts.shift(1) - 1)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-nan_2","text":"","title":"2021-01-31         NaN"},{"location":"python/DataAnalysis/ch08/#2021-02-28-0543970","text":"","title":"2021-02-28    0.543970"},{"location":"python/DataAnalysis/ch08/#2021-03-31-1504481","text":"","title":"2021-03-31   -1.504481"},{"location":"python/DataAnalysis/ch08/#2021-04-30-0930037","text":"","title":"2021-04-30   -0.930037"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_4","text":"\u5982\u679c\u9891\u7387\u662f\u5df2\u77e5\u7684\uff0c\u5219\u53ef\u4ee5\u5c06\u9891\u7387\u4f20\u9012\u7ed9`shift`\u6765\u63a8\u79fb\u65f6\u95f4\u6233\uff1a print(ts.shift(2, freq='M')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u6708\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0882972_1","text":"","title":"2021-03-31    0.882972"},{"location":"python/DataAnalysis/ch08/#2022021-10-31-0000001-04-30-1363282","text":"","title":"2022021-10-31 00:00:001-04-30    1.363282"},{"location":"python/DataAnalysis/ch08/#2021-05-31-0687750","text":"","title":"2021-05-31   -0.687750"},{"location":"python/DataAnalysis/ch08/#2021-06-30-0048117","text":"","title":"2021-06-30   -0.048117"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_5","text":"print(ts.shift(2, freq='D')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u65e5\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-02-02-0882972","text":"","title":"2021-02-02    0.882972"},{"location":"python/DataAnalysis/ch08/#2021-03-02-1363282","text":"","title":"2021-03-02    1.363282"},{"location":"python/DataAnalysis/ch08/#2021-04-02-0687750","text":"","title":"2021-04-02   -0.687750"},{"location":"python/DataAnalysis/ch08/#2021-05-02-0048117","text":"","title":"2021-05-02   -0.048117"},{"location":"python/DataAnalysis/ch08/#dtype-float64","text":"print(ts.shift(2, freq='90T')) # \u539f\u59cb\u6570\u636e\u7684\u201c\u5c0f\u65f6\u201c\u589e\u52a0\u4e86\u504f\u79fb\u503c","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-030000-0882972","text":"","title":"2021-01-31 03:00:00    0.882972"},{"location":"python/DataAnalysis/ch08/#2021-02-28-030000-1363282","text":"","title":"2021-02-28 03:00:00    1.363282"},{"location":"python/DataAnalysis/ch08/#2021-03-31-030000-0687750","text":"","title":"2021-03-31 03:00:00   -0.687750"},{"location":"python/DataAnalysis/ch08/#2021-04-30-030000-0048117","text":"","title":"2021-04-30 03:00:00   -0.048117"},{"location":"python/DataAnalysis/ch08/#dtype-float64_1","text":"#### \u4f7f\u7528\u504f\u7f6e\u8fdb\u884c\u79fb\u4f4d\u65e5\u671f pandas\u65e5\u671f\u504f\u7f6e\u4e5f\u53ef\u4ee5\u4f7f\u7528`datetime`\u6216`Timestamp`\u5bf9\u8c61\u5b8c\u6210\uff1a now = datetime(2021, 10, 9) print(now)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-10-09-000000","text":"print(now + 3 * Day())","title":"2021-10-09 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-10-12-000000","text":"\u951a\u5b9a\u504f\u7f6e\u53ef\u4ee5\u4f7f\u7528`rollforward`\u548c`rollback`\u5206\u522b\u663e\u5f0f\u5730\u5c06\u65e5\u671f\u5411\u524d\u6216\u5411\u540e\"\u6eda\u52a8\"\u3002 \u5982\u679c\u6dfb\u52a0\u4e86\u4e00\u4e2a\u951a\u5b9a\u504f\u7f6e\u91cf\uff0c\u6bd4\u5982`MonthEnd`\uff0c\u6839\u636e\u9891\u7387\u89c4\u5219\uff0c\u7b2c\u4e00\u4e2a\u589e\u91cf\u4f1a\u5c06\u65e5\u671f\u201c\u524d\u6eda\u201d\u5230\u4e0b\u4e00\u4e2a\u65e5\u671f\uff1a print(now + MonthEnd()) # \u201c\u524d\u6eda\u201d\u5230\u5f53\u524d\u6708\u7684\u6708\u5e95","title":"2021-10-12 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-10-31-000000","text":"print(now + MonthEnd(2)) # \u6ce8\u610f\u8fd9\u91cc\u7684\u5e8f\u5217\u53f7\uff0c\u5f53\u524d\u6708\u662f1,\u4e0b\u4e2a\u6708\u662f2","title":"2021-10-31 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-11-30-000000","text":"offset = MonthEnd() print(offset.rollback(now))","title":"2021-11-30 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-09-30-000000","text":"print(offset.rollforward(now))","title":"2021-09-30 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-10-31-000000_1","text":"\u5c06\u79fb\u4f4d\u65b9\u6cd5\u4e0e`groupby`\u4e00\u8d77\u4f7f\u7528\u662f\u65e5\u671f\u504f\u7f6e\u7684\u4e00\u79cd\u521b\u9020\u6027\u7528\u6cd5\uff1a ts = pd.Series( np.random.randn(20), index=pd.date_range('2021/1/1', periods=20, freq='4d') ) print(ts)","title":"2021-10-31 00:00:00"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0674348","text":"","title":"2021-01-01    0.674348"},{"location":"python/DataAnalysis/ch08/#2021-01-05-1437803","text":"","title":"2021-01-05   -1.437803"},{"location":"python/DataAnalysis/ch08/#2021-01-09-0079218","text":"","title":"2021-01-09   -0.079218"},{"location":"python/DataAnalysis/ch08/#2021-01-13-1444890","text":"","title":"2021-01-13   -1.444890"},{"location":"python/DataAnalysis/ch08/#2021-01-17-0643279","text":"","title":"2021-01-17    0.643279"},{"location":"python/DataAnalysis/ch08/#2021-01-21-1089965","text":"","title":"2021-01-21    1.089965"},{"location":"python/DataAnalysis/ch08/#2021-01-25-0021876","text":"","title":"2021-01-25    0.021876"},{"location":"python/DataAnalysis/ch08/#2021-01-29-0692138","text":"","title":"2021-01-29    0.692138"},{"location":"python/DataAnalysis/ch08/#2021-02-02-0833496","text":"","title":"2021-02-02    0.833496"},{"location":"python/DataAnalysis/ch08/#2021-02-06-1082616","text":"","title":"2021-02-06    1.082616"},{"location":"python/DataAnalysis/ch08/#2021-02-10-0729415","text":"","title":"2021-02-10   -0.729415"},{"location":"python/DataAnalysis/ch08/#2021-02-14-0271186","text":"","title":"2021-02-14    0.271186"},{"location":"python/DataAnalysis/ch08/#2021-02-18-1416218","text":"","title":"2021-02-18   -1.416218"},{"location":"python/DataAnalysis/ch08/#2021-02-22-0780402","text":"","title":"2021-02-22   -0.780402"},{"location":"python/DataAnalysis/ch08/#2021-02-26-0113773","text":"","title":"2021-02-26   -0.113773"},{"location":"python/DataAnalysis/ch08/#2021-03-02-2095338","text":"","title":"2021-03-02    2.095338"},{"location":"python/DataAnalysis/ch08/#2021-03-06-0302612","text":"","title":"2021-03-06   -0.302612"},{"location":"python/DataAnalysis/ch08/#2021-03-10-1113632","text":"","title":"2021-03-10    1.113632"},{"location":"python/DataAnalysis/ch08/#2021-03-14-1314581","text":"","title":"2021-03-14   -1.314581"},{"location":"python/DataAnalysis/ch08/#2021-03-18-0947746","text":"","title":"2021-03-18    0.947746"},{"location":"python/DataAnalysis/ch08/#freq-4d-dtype-float64","text":"print(ts.groupby(offset.rollforward).mean()) # \u524d\u6eda\u81f3\u5f53\u6708\u6708\u5e95\uff0c\u8ba1\u7b97\u5f53\u6708\u5e73\u5747\u503c","title":"Freq: 4D, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-31-0019962","text":"","title":"2021-01-31    0.019962"},{"location":"python/DataAnalysis/ch08/#2021-02-28-0121787","text":"","title":"2021-02-28   -0.121787"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0507905","text":"","title":"2021-03-31    0.507905"},{"location":"python/DataAnalysis/ch08/#dtype-float64_2","text":"","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#resample","text":"print(ts.resample('M').mean())","title":"\u4f7f\u7528resample\u662f\u66f4\u7b80\u5355\u66f4\u5feb\u6377\u7684\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch08/#2021-01-31-0019962_1","text":"","title":"2021-01-31    0.019962"},{"location":"python/DataAnalysis/ch08/#2021-02-28-0121787_1","text":"","title":"2021-02-28   -0.121787"},{"location":"python/DataAnalysis/ch08/#2021-03-31-0507905_1","text":"","title":"2021-03-31    0.507905"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_6","text":"## \u65f6\u533a\u5904\u7406 \u65f6\u533a\u901a\u5e38\u88ab\u8868\u793a\u4e3aUTC\u7684\u504f\u7f6e\u3002 \u5728Python\u8bed\u8a00\u4e2d\uff0c\u65f6\u533a\u4fe1\u606f\u6765\u6e90\u4e8e\u7b2c\u4e09\u65b9\u5e93pytz\uff08\u53ef\u4ee5\u4f7f\u7528pip\u6216conda\u5b89\u88c5\uff09\uff0c\u5176\u4e2d\u516c\u5f00\u4e86Olson\u6570\u636e\u5e93\uff0c\u8fd9\u662f\u4e16\u754c\u65f6\u533a\u4fe1\u606f\u7684\u6c47\u7f16\u3002 pandas\u5c01\u88c5\u4e86pytz\u7684\u529f\u80fd\u3002 from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz #### common_timezones tz = pytz.common_timezones[-5:] # \u8bfb\u53d6common_timezones\u8fd9\u4e2a\u5217\u8868\u7684\u6700\u540e5\u4e2a\u5143\u7d20 print(tz)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#useastern-ushawaii-usmountain-uspacific-utc","text":"\u8981\u83b7\u5f97pytz\u7684\u65f6\u533a\u5bf9\u8c61\uff0c\u53ef\u4f7f\u7528pytz.timezone\uff1a tz = pytz.timezone('Asia/Shanghai') print(tz) #### \u65f6\u533a\u7684\u672c\u5730\u5316\u548c\u8f6c\u6362 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cpandas\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u662f\u65f6\u533a\u7b80\u5355\u578b\u7684\u3002 rng = pd.date_range('2021/1/1 9:30', periods=6, freq='D') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(rng)","title":"['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-01-093000-2021-01-02-093000","text":"","title":"DatetimeIndex(['2021-01-01 09:30:00', '2021-01-02 09:30:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-03-093000-2021-01-04-093000","text":"","title":"'2021-01-03 09:30:00', '2021-01-04 09:30:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-05-093000-2021-01-06-093000","text":"","title":"'2021-01-05 09:30:00', '2021-01-06 09:30:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-freqd","text":"print(ts)","title":"dtype='datetime64[ns]', freq='D')"},{"location":"python/DataAnalysis/ch08/#2021-01-01-093000-0339822","text":"","title":"2021-01-01 09:30:00    0.339822"},{"location":"python/DataAnalysis/ch08/#2021-01-02-093000-1356382","text":"","title":"2021-01-02 09:30:00    1.356382"},{"location":"python/DataAnalysis/ch08/#2021-01-03-093000-0475429","text":"","title":"2021-01-03 09:30:00    0.475429"},{"location":"python/DataAnalysis/ch08/#2021-01-04-093000-1826654","text":"","title":"2021-01-04 09:30:00    1.826654"},{"location":"python/DataAnalysis/ch08/#2021-01-05-093000-0245510","text":"","title":"2021-01-05 09:30:00   -0.245510"},{"location":"python/DataAnalysis/ch08/#2021-01-06-093000-0705274","text":"","title":"2021-01-06 09:30:00    0.705274"},{"location":"python/DataAnalysis/ch08/#freq-d-dtype-float64","text":"print(ts.index.tz) # \u7d22\u5f15\u7684tz\u5c5e\u6027\u662fNone","title":"Freq: D, dtype: float64"},{"location":"python/DataAnalysis/ch08/#none","text":"\u65e5\u671f\u8303\u56f4\u53ef\u4ee5\u901a\u8fc7\u65f6\u533a\u96c6\u5408\u6765\u751f\u6210\uff1a rng = pd.date_range('2021/3/1', periods=10, freq='D', tz='UTC') print(rng)","title":"None"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-03-01-0000000000-2021-03-02-0000000000","text":"","title":"DatetimeIndex(['2021-03-01 00:00:00+00:00', '2021-03-02 00:00:00+00:00',"},{"location":"python/DataAnalysis/ch08/#2021-03-03-0000000000-2021-03-04-0000000000","text":"","title":"'2021-03-03 00:00:00+00:00', '2021-03-04 00:00:00+00:00',"},{"location":"python/DataAnalysis/ch08/#2021-03-05-0000000000-2021-03-06-0000000000","text":"","title":"'2021-03-05 00:00:00+00:00', '2021-03-06 00:00:00+00:00',"},{"location":"python/DataAnalysis/ch08/#2021-03-07-0000000000-2021-03-08-0000000000","text":"","title":"'2021-03-07 00:00:00+00:00', '2021-03-08 00:00:00+00:00',"},{"location":"python/DataAnalysis/ch08/#2021-03-09-0000000000-2021-03-10-0000000000","text":"","title":"'2021-03-09 00:00:00+00:00', '2021-03-10 00:00:00+00:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-utc-freqd","text":"\u4f7f\u7528`tz_localize`\u65b9\u6cd5\u53ef\u4ee5\u4ece\u7b80\u5355\u65f6\u533a\u8f6c\u6362\u5230\u672c\u5730\u5316\u65f6\u533a\uff1a print(ts)","title":"dtype='datetime64[ns, UTC]', freq='D')"},{"location":"python/DataAnalysis/ch08/#2021-01-01-093000-0294647","text":"","title":"2021-01-01 09:30:00    0.294647"},{"location":"python/DataAnalysis/ch08/#2021-01-02-093000-0958414","text":"","title":"2021-01-02 09:30:00    0.958414"},{"location":"python/DataAnalysis/ch08/#2021-01-03-093000-0424235","text":"","title":"2021-01-03 09:30:00    0.424235"},{"location":"python/DataAnalysis/ch08/#2021-01-04-093000-1714333","text":"","title":"2021-01-04 09:30:00   -1.714333"},{"location":"python/DataAnalysis/ch08/#2021-01-05-093000-0030319","text":"","title":"2021-01-05 09:30:00   -0.030319"},{"location":"python/DataAnalysis/ch08/#2021-01-06-093000-0744940","text":"","title":"2021-01-06 09:30:00   -0.744940"},{"location":"python/DataAnalysis/ch08/#freq-d-dtype-float64_1","text":"print(ts.tz_localize('UTC'))","title":"Freq: D, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0930000000-0294647","text":"","title":"2021-01-01 09:30:00+00:00    0.294647"},{"location":"python/DataAnalysis/ch08/#2021-01-02-0930000000-0958414","text":"","title":"2021-01-02 09:30:00+00:00    0.958414"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0930000000-0424235","text":"","title":"2021-01-03 09:30:00+00:00    0.424235"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0930000000-1714333","text":"","title":"2021-01-04 09:30:00+00:00   -1.714333"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000000-0030319","text":"","title":"2021-01-05 09:30:00+00:00   -0.030319"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0930000000-0744940","text":"","title":"2021-01-06 09:30:00+00:00   -0.744940"},{"location":"python/DataAnalysis/ch08/#freq-d-dtype-float64_2","text":"print(ts.tz_localize('Asia/Shanghai'))","title":"Freq: D, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0930000800-0052521","text":"","title":"2021-01-01 09:30:00+08:00    0.052521"},{"location":"python/DataAnalysis/ch08/#2021-01-02-0930000800-0305417","text":"","title":"2021-01-02 09:30:00+08:00   -0.305417"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0930000800-0150215","text":"","title":"2021-01-03 09:30:00+08:00    0.150215"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0930000800-0953715","text":"","title":"2021-01-04 09:30:00+08:00   -0.953715"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000800-0543622","text":"","title":"2021-01-05 09:30:00+08:00    0.543622"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0930000800-0222422","text":"","title":"2021-01-06 09:30:00+08:00    0.222422"},{"location":"python/DataAnalysis/ch08/#dtype-float64_3","text":"print(ts.tz_localize('Asia/Shanghai').index)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-01-0930000800-2021-01-02-0930000800","text":"","title":"DatetimeIndex(['2021-01-01 09:30:00+08:00', '2021-01-02 09:30:00+08:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0930000800-2021-01-04-0930000800","text":"","title":"'2021-01-03 09:30:00+08:00', '2021-01-04 09:30:00+08:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000800-2021-01-06-0930000800","text":"","title":"'2021-01-05 09:30:00+08:00', '2021-01-06 09:30:00+08:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-asiashanghai-freqnone","text":"\u4e00\u65e6\u65f6\u95f4\u5e8f\u5217\u88ab\u672c\u5730\u5316\u4e3a\u67d0\u4e2a\u7279\u5b9a\u7684\u65f6\u533a\uff0c\u5219\u53ef\u4ee5\u901a\u8fc7`tz_convert`\u5c06\u5176\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u65f6\u533a\uff1a tz_sha = ts.tz_localize('Asia/Shanghai') tz_utc = tz_sha.tz_convert('UTC') print(tz_sha)","title":"dtype='datetime64[ns, Asia/Shanghai]', freq=None)"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0930000800-0095689","text":"","title":"2021-01-01 09:30:00+08:00    0.095689"},{"location":"python/DataAnalysis/ch08/#2021-01-02-0930000800-0392730","text":"","title":"2021-01-02 09:30:00+08:00   -0.392730"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0930000800-0151468","text":"","title":"2021-01-03 09:30:00+08:00    0.151468"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0930000800-0027467","text":"","title":"2021-01-04 09:30:00+08:00    0.027467"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000800-0393709","text":"","title":"2021-01-05 09:30:00+08:00    0.393709"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0930000800-0872914","text":"","title":"2021-01-06 09:30:00+08:00    0.872914"},{"location":"python/DataAnalysis/ch08/#dtype-float64_4","text":"print(tz_utc)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0130000000-0095689","text":"","title":"2021-01-01 01:30:00+00:00    0.095689"},{"location":"python/DataAnalysis/ch08/#2021-01-02-0130000000-0392730","text":"","title":"2021-01-02 01:30:00+00:00   -0.392730"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0130000000-0151468","text":"","title":"2021-01-03 01:30:00+00:00    0.151468"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0130000000-0027467","text":"","title":"2021-01-04 01:30:00+00:00    0.027467"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0130000000-0393709","text":"","title":"2021-01-05 01:30:00+00:00    0.393709"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0130000000-0872914","text":"","title":"2021-01-06 01:30:00+00:00    0.872914"},{"location":"python/DataAnalysis/ch08/#dtype-float64_5","text":"","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#tz_localizetz_convertdatetimeindex","text":"print(ts.index.tz_localize('Asia/Shanghai'))","title":"tz_localize\u548ctz_convert\u4e5f\u662fDatetimeIndex\u7684\u5b9e\u4f8b\u65b9\u6cd5\uff1a"},{"location":"python/DataAnalysis/ch08/#datetimeindex2021-01-01-0930000800-2021-01-02-0930000800_1","text":"","title":"DatetimeIndex(['2021-01-01 09:30:00+08:00', '2021-01-02 09:30:00+08:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-03-0930000800-2021-01-04-0930000800_1","text":"","title":"'2021-01-03 09:30:00+08:00', '2021-01-04 09:30:00+08:00',"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000800-2021-01-06-0930000800_1","text":"","title":"'2021-01-05 09:30:00+08:00', '2021-01-06 09:30:00+08:00'],"},{"location":"python/DataAnalysis/ch08/#dtypedatetime64ns-asiashanghai-freqnone_1","text":"### \u65f6\u533a\u611f\u77e5\u65f6\u95f4\u6233\u5bf9\u8c61\u7684\u64cd\u4f5c \u4e0e\u65f6\u95f4\u5e8f\u5217\u548c\u65e5\u671f\u8303\u56f4\u7c7b\u4f3c\uff0c\u5355\u72ec\u7684`Timestamp`\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u4ece\u7b80\u5355\u65f6\u95f4\u6233\u672c\u5730\u5316\u4e3a\u65f6\u533a\u611f\u77e5\u65f6\u95f4\u6233\uff0c\u5e76\u4ece\u4e00\u4e2a\u65f6\u533a\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u65f6\u533a\uff1a stamp = pd.Timestamp('2021-5-1 05:30') print(stamp)","title":"dtype='datetime64[ns, Asia/Shanghai]', freq=None)"},{"location":"python/DataAnalysis/ch08/#2021-05-01-053000","text":"stamp_utc = stamp.tz_localize('utc') print(stamp_utc)","title":"2021-05-01 05:30:00"},{"location":"python/DataAnalysis/ch08/#2021-05-01-0530000000","text":"stamp_sha = stamp_utc.tz_convert('Asia/Shanghai') print(stamp_sha)","title":"2021-05-01 05:30:00+00:00"},{"location":"python/DataAnalysis/ch08/#2021-05-01-1330000800","text":"\u4e5f\u53ef\u4ee5\u5728\u521b\u5efa`Timestamp`\u7684\u65f6\u5019\u4f20\u9012\u4e00\u4e2a\u65f6\u533a\uff1a stamp_sha = pd.Timestamp('2021-5-1 05:30', tz='Asia/Shanghai') print(stamp_sha)","title":"2021-05-01 13:30:00+08:00"},{"location":"python/DataAnalysis/ch08/#2021-05-01-0530000800","text":"`Timestamp`\u5bf9\u8c61\u5185\u90e8\u5b58\u50a8\u4e86\u4e00\u4e2aUnix\u7eaa\u5143(1970\u5e741\u67081\u65e5)\u81f3\u4eca\u7684\u7eb3\u79d2\u6570\u91cfUTC\u65f6\u95f4\u6233\u6570\u503c\uff0c\u8be5\u6570\u503c\u5728\u65f6\u533a\u8f6c\u6362\u4e2d\u662f\u4e0d\u53d8\u7684\uff1a print(stamp_utc.value)","title":"2021-05-01 05:30:00+08:00"},{"location":"python/DataAnalysis/ch08/#1619847000000000000","text":"print(stamp_utc.tz_convert('Asia/Shanghai').value)","title":"1619847000000000000"},{"location":"python/DataAnalysis/ch08/#1619847000000000000_1","text":"\u5728\u4f7f\u7528pandas\u7684`DateOffset`\u8fdb\u884c\u65f6\u95f4\u7b97\u672f\u65f6\uff0cpandas\u5c3d\u53ef\u80fd\u9075\u4ece\u590f\u65f6\u5236\u3002 \u9996\u5148\uff0c\u6784\u9020\u8f6c\u6362\u5230DST\u4e4b\u524d\u768430\u5206\u949f\u7684\u65f6\u95f4\uff1a stamp = pd.Timestamp('2012-3-12 1:30', tz='US/Eastern') print(stamp)","title":"1619847000000000000"},{"location":"python/DataAnalysis/ch08/#2012-03-12-013000-0400","text":"print(stamp + Hour())","title":"2012-03-12 01:30:00-04:00"},{"location":"python/DataAnalysis/ch08/#2012-03-12-023000-0400","text":"\u4e4b\u540e\uff0c\u6784\u5efa\u4eceDST\u8fdb\u884c\u8f6c\u6362\u524d\u768490\u5206\u949f\uff1a stamp = pd.Timestamp('2012-11-04 0:30-04:00', tz='US/Eastern') print(stamp)","title":"2012-03-12 02:30:00-04:00"},{"location":"python/DataAnalysis/ch08/#2012-11-04-003000-0400","text":"print(stamp + 2 * Hour()) # \u53ea\u589e\u52a0\u4e86\u4e00\u5c0f\u65f6","title":"2012-11-04 00:30:00-04:00"},{"location":"python/DataAnalysis/ch08/#2012-11-04-013000-0500","text":"### \u4e0d\u540c\u65f6\u533a\u95f4\u7684\u64cd\u4f5c \u5982\u679c\u4e24\u4e2a\u65f6\u533a\u4e0d\u540c\u7684\u65f6\u95f4\u5e8f\u5217\u9700\u8981\u8054\u5408\uff0c\u90a3\u4e48\u7ed3\u679c\u5c06\u662fUTC\u65f6\u95f4\u7684\uff0c\u56e0\u4e3a\u65f6\u95f4\u6233\u4ee5UTC\u683c\u5f0f\u5b58\u50a8\u3002 rng = pd.date_range('2021/1/1 9:30', periods=9, freq='B') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(ts)","title":"2012-11-04 01:30:00-05:00"},{"location":"python/DataAnalysis/ch08/#2021-01-01-093000-0715681","text":"","title":"2021-01-01 09:30:00    0.715681"},{"location":"python/DataAnalysis/ch08/#2021-01-04-093000-0524563","text":"","title":"2021-01-04 09:30:00    0.524563"},{"location":"python/DataAnalysis/ch08/#2021-01-05-093000-0482199","text":"","title":"2021-01-05 09:30:00   -0.482199"},{"location":"python/DataAnalysis/ch08/#2021-01-06-093000-0661303","text":"","title":"2021-01-06 09:30:00   -0.661303"},{"location":"python/DataAnalysis/ch08/#2021-01-07-093000-1750010","text":"","title":"2021-01-07 09:30:00    1.750010"},{"location":"python/DataAnalysis/ch08/#2021-01-08-093000-0251478","text":"","title":"2021-01-08 09:30:00    0.251478"},{"location":"python/DataAnalysis/ch08/#2021-01-11-093000-1487268","text":"","title":"2021-01-11 09:30:00   -1.487268"},{"location":"python/DataAnalysis/ch08/#2021-01-12-093000-0224024","text":"","title":"2021-01-12 09:30:00   -0.224024"},{"location":"python/DataAnalysis/ch08/#2021-01-13-093000-1621853","text":"","title":"2021-01-13 09:30:00   -1.621853"},{"location":"python/DataAnalysis/ch08/#freq-b-dtype-float64","text":"ts1 = ts[:7].tz_localize('Europe/London') ts2 = ts1[2:].tz_convert('Europe/Moscow') result = ts1 + ts2 print(ts1)","title":"Freq: B, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0930000000-1393445","text":"","title":"2021-01-01 09:30:00+00:00   -1.393445"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0930000000-1179614","text":"","title":"2021-01-04 09:30:00+00:00   -1.179614"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000000-0716669","text":"","title":"2021-01-05 09:30:00+00:00    0.716669"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0930000000-0485656","text":"","title":"2021-01-06 09:30:00+00:00   -0.485656"},{"location":"python/DataAnalysis/ch08/#2021-01-07-0930000000-0433000","text":"","title":"2021-01-07 09:30:00+00:00    0.433000"},{"location":"python/DataAnalysis/ch08/#2021-01-08-0930000000-1540745","text":"","title":"2021-01-08 09:30:00+00:00    1.540745"},{"location":"python/DataAnalysis/ch08/#2021-01-11-0930000000-0343751","text":"","title":"2021-01-11 09:30:00+00:00    0.343751"},{"location":"python/DataAnalysis/ch08/#dtype-float64_6","text":"print(ts2)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-05-1230000300-0716669","text":"","title":"2021-01-05 12:30:00+03:00    0.716669"},{"location":"python/DataAnalysis/ch08/#2021-01-06-1230000300-0485656","text":"","title":"2021-01-06 12:30:00+03:00   -0.485656"},{"location":"python/DataAnalysis/ch08/#2021-01-07-1230000300-0433000","text":"","title":"2021-01-07 12:30:00+03:00    0.433000"},{"location":"python/DataAnalysis/ch08/#2021-01-08-1230000300-1540745","text":"","title":"2021-01-08 12:30:00+03:00    1.540745"},{"location":"python/DataAnalysis/ch08/#2021-01-11-1230000300-0343751","text":"","title":"2021-01-11 12:30:00+03:00    0.343751"},{"location":"python/DataAnalysis/ch08/#dtype-float64_7","text":"print(result)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021-01-01-0930000000-nan","text":"","title":"2021-01-01 09:30:00+00:00         NaN"},{"location":"python/DataAnalysis/ch08/#2021-01-04-0930000000-nan","text":"","title":"2021-01-04 09:30:00+00:00         NaN"},{"location":"python/DataAnalysis/ch08/#2021-01-05-0930000000-1433337","text":"","title":"2021-01-05 09:30:00+00:00    1.433337"},{"location":"python/DataAnalysis/ch08/#2021-01-06-0930000000-0971312","text":"","title":"2021-01-06 09:30:00+00:00   -0.971312"},{"location":"python/DataAnalysis/ch08/#2021-01-07-0930000000-0866000","text":"","title":"2021-01-07 09:30:00+00:00    0.866000"},{"location":"python/DataAnalysis/ch08/#2021-01-08-0930000000-3081489","text":"","title":"2021-01-08 09:30:00+00:00    3.081489"},{"location":"python/DataAnalysis/ch08/#2021-01-11-0930000000-0687502","text":"","title":"2021-01-11 09:30:00+00:00    0.687502"},{"location":"python/DataAnalysis/ch08/#dtype-float64_8","text":"## \u65f6\u95f4\u533a\u95f4\u548c\u533a\u95f4\u7b97\u672f from datetime import datetime, timedelta import pandas as pd import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz \u65f6\u95f4\u533a\u95f4\u8868\u793a\u7684\u662f\u65f6\u95f4\u8303\u56f4\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628a`year`\u548c`quarter`\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15\uff0c\u6bd4\u5982\u4e00\u4e9b\u5929\u3001\u4e00\u4e9b\u6708\u3001\u4e00\u4e9b\u5b63\u5ea6\u6216\u8005\u662f\u4e00\u4e9b\u5e74\u3002 `Period`\u7c7b\u8868\u793a\u7684\u6b63\u662f\u8fd9\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u9700\u8981\u4e00\u4e2a\u5b57\u7b26\u4e32\u6216\u6570\u5b57\u4ee5\u53ca\u9891\u7387\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c`Period`\u5bf9\u8c61\u8868\u793a\u7684\u662f\u4ece2007\u5e741\u67081\u65e5\u52302007\u5e7412\u670831\u65e5\uff08\u5305\u542b\u5728\u5185\uff09\u7684\u65f6\u95f4\u6bb5\u3002 \u5728\u65f6\u95f4\u6bb5\u4e0a\u589e\u52a0\u6216\u51cf\u53bb\u6574\u6570\u53ef\u4ee5\u65b9\u4fbf\u5730\u6839\u636e\u5b83\u4eec\u7684\u9891\u7387\u8fdb\u884c\u79fb\u4f4d\u3002 p = pd.Period(2020, freq='A-DEC') print(p)","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020","text":"print(p + 5)","title":"2020"},{"location":"python/DataAnalysis/ch08/#2025","text":"print(p - 5)","title":"2025"},{"location":"python/DataAnalysis/ch08/#2015","text":"\u5982\u679c\u4e24\u4e2a\u533a\u95f4\u62e5\u6709\u76f8\u540c\u7684\u9891\u7387\uff0c\u5219\u5b83\u4eec\u7684\u5dee\u662f\u5b83\u4eec\u4e4b\u95f4\u7684\u5355\u4f4d\u6570\u3002 p1 = pd.Period(2020, freq='A-DEC') p2 = pd.Period(2010, freq='A-DEC') print(p1 - p2)","title":"2015"},{"location":"python/DataAnalysis/ch08/#10-yearends-month12","text":"p1 = pd.Period(2020, freq='Q-DEC') p2 = pd.Period(2010, freq='Q-DEC') print(p1 - p2)","title":"&lt;10 * YearEnds: month=12&gt;"},{"location":"python/DataAnalysis/ch08/#40-quarterends-startingmonth12","text":"\u4f7f\u7528`period_range`\u51fd\u6570\u53ef\u4ee5\u6784\u9020\u89c4\u5219\u533a\u95f4\u5e8f\u5217\u3002`PeriodIndex`\u7c7b\u5b58\u50a8\u7684\u662f\u533a\u95f4\u7684\u5e8f\u5217\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u4efb\u610fpandas\u6570\u636e\u7ed3\u6784\u7684\u8f74\u7d22\u5f15\u3002 data = np.random.randn(6) strings = ['2021Q1', '2021Q2', '2021Q3', '2021Q4', '2022Q1', '2022Q2'] rng = pd.period_range('2001-1-1', '2001-6-30', freq='M') ts = pd.Series(data, index=rng) print(ts)","title":"&lt;40 * QuarterEnds: startingMonth=12&gt;"},{"location":"python/DataAnalysis/ch08/#2001-01-0481408","text":"","title":"2001-01   -0.481408"},{"location":"python/DataAnalysis/ch08/#2001-02-0297590","text":"","title":"2001-02   -0.297590"},{"location":"python/DataAnalysis/ch08/#2001-03-0860354","text":"","title":"2001-03   -0.860354"},{"location":"python/DataAnalysis/ch08/#2001-04-1281540","text":"","title":"2001-04    1.281540"},{"location":"python/DataAnalysis/ch08/#2001-05-1036551","text":"","title":"2001-05    1.036551"},{"location":"python/DataAnalysis/ch08/#2001-06-0522592","text":"","title":"2001-06   -0.522592"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_7","text":"rng = pd.PeriodIndex(strings, freq='Q-DEC') # \u5b57\u7b26\u4e32\u6570\u7ec4\u4e5f\u53ef\u4ee5\u4f7f\u7528PeriodIndex\u7c7b ts = pd.Series(data, index=rng) print(ts)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2021q1-2077200","text":"","title":"2021Q1   -2.077200"},{"location":"python/DataAnalysis/ch08/#2021q2-0948796","text":"","title":"2021Q2   -0.948796"},{"location":"python/DataAnalysis/ch08/#2021q3-1104737","text":"","title":"2021Q3   -1.104737"},{"location":"python/DataAnalysis/ch08/#2021q4-0090281","text":"","title":"2021Q4    0.090281"},{"location":"python/DataAnalysis/ch08/#2022q1-0431517","text":"","title":"2022Q1    0.431517"},{"location":"python/DataAnalysis/ch08/#2022q2-1537045","text":"","title":"2022Q2    1.537045"},{"location":"python/DataAnalysis/ch08/#freq-q-dec-dtype-float64","text":"### \u533a\u95f4\u9891\u7387\u8f6c\u6362 \u4f7f\u7528`asfreq`\u53ef\u4ee5\u5c06\u533a\u95f4\u548c`PeriodIndex`\u5bf9\u8c61\u8f6c\u6362\u4e3a\u5176\u4ed6\u7684\u9891\u7387\u3002 \u4f8b\u5982\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u5e74\u5ea6\u533a\u95f4\uff0c\u5e76\u4e14\u60f3\u8981\u5728\u4e00\u5e74\u7684\u5f00\u59cb\u6216\u7ed3\u675f\u65f6\u5c06\u5176\u8f6c\u6362\u4e3a\u6708\u5ea6\u533a\u95f4\u3002 \u53ef\u4ee5\u5c06`Period('2020', 'A-DEC')`\u770b\u4f5c\u4e00\u6bb5\u65f6\u95f4\u4e2d\u7684\u4e00\u79cd\u6e38\u6807\uff0c\u5c06\u65f6\u95f4\u6309\u6708\u4efd\u5212\u5206\u3002 p = pd.Period(2020, freq='A-DEC') print(p.asfreq('M', how='start'))","title":"Freq: Q-DEC, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01","text":"print(p.asfreq('M', how='end'))","title":"2020-01"},{"location":"python/DataAnalysis/ch08/#2020-12","text":"\u5982\u679c\u8d22\u5e74\u7ed3\u675f\u4e0d\u572812\u6708\uff0c\u5219\u6bcf\u6708\u5206\u671f\u4f1a\u81ea\u52a8\u8c03\u6574\u3002 \u6309\u5f53\u5e74\u8d22\u5e74\u7ed3\u675f\u8ba1\u7b97\uff0c\u8d77\u59cb\u5e74\u4efd\u5c31\u662f\u4e0a\u4e00\u5e74\u4e86\u3002 p = pd.Period(2020, freq='A-JUN') print(p.asfreq('M', how='start'))","title":"2020-12"},{"location":"python/DataAnalysis/ch08/#2019-07","text":"print(p.asfreq('M', how='end'))","title":"2019-07"},{"location":"python/DataAnalysis/ch08/#2020-06","text":"\u5f53\u4ece\u9ad8\u9891\u7387\u5411\u4f4e\u9891\u7387\u8f6c\u6362\u65f6\uff0cpandas\u6839\u636e\u5b50\u533a\u95f4\u7684\"\u6240\u5c5e\"\u6765\u51b3\u5b9a\u7236\u533a\u95f4\u3002 \u4f8b\u5982\uff0c\u5728A-JUN\u9891\u7387\u4e2d\uff0cAug-2020\u662f2020\u533a\u95f4\u7684\u4e00\u90e8\u5206\uff1a print(p.asfreq('A-JUN')) 2020\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628a`year`\u548c`quarter`\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15\u3002 \u5b8c\u6574\u7684`PeriodIndex`\u5bf9\u8c61\u6216\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u6309\u7167\u76f8\u540c\u7684\u8bed\u4e49\u8fdb\u884c\u8f6c\u6362\uff1a rng = pd.period_range('2018', '2021', freq='A-DEC') data = np.random.randn(len(rng)) ts = pd.Series(data, index=rng) print(ts)","title":"2020-06"},{"location":"python/DataAnalysis/ch08/#2018-0221634","text":"","title":"2018    0.221634"},{"location":"python/DataAnalysis/ch08/#2019-0392724","text":"","title":"2019   -0.392724"},{"location":"python/DataAnalysis/ch08/#2020-0355022","text":"","title":"2020   -0.355022"},{"location":"python/DataAnalysis/ch08/#2021-0114000","text":"","title":"2021    0.114000"},{"location":"python/DataAnalysis/ch08/#freq-a-dec-dtype-float64","text":"\u4e0b\u9762\u5e74\u5ea6\u533a\u95f4\u5c06\u901a\u8fc7`asfreq`\u88ab\u66ff\u6362\u4e3a\u5bf9\u5e94\u4e8e\u6bcf\u4e2a\u5e74\u5ea6\u533a\u95f4\u5185\u7684\u7b2c\u4e00\u4e2a\u6708\u7684\u6708\u5ea6\u533a\u95f4\u3002 print(ts.asfreq('M', how='start'))","title":"Freq: A-DEC, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2018-01-0681874","text":"","title":"2018-01    0.681874"},{"location":"python/DataAnalysis/ch08/#2019-01-1006585","text":"","title":"2019-01   -1.006585"},{"location":"python/DataAnalysis/ch08/#2020-01-0619142","text":"","title":"2020-01   -0.619142"},{"location":"python/DataAnalysis/ch08/#2021-01-1445820","text":"","title":"2021-01    1.445820"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_8","text":"\u5982\u679c\u6211\u4eec\u60f3\u8981\u6bcf\u5e74\u6700\u540e\u4e00\u4e2a\u5de5\u4f5c\u65e5\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`B`\u9891\u7387\u6765\u8868\u793a\u6211\u4eec\u60f3\u8981\u7684\u662f\u533a\u95f4\u7684\u672b\u7aef\u3002 print(ts.asfreq('B', how='end'))","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2018-12-31-1520316","text":"","title":"2018-12-31   -1.520316"},{"location":"python/DataAnalysis/ch08/#2019-12-31-0425544","text":"","title":"2019-12-31   -0.425544"},{"location":"python/DataAnalysis/ch08/#2020-12-31-0658073","text":"","title":"2020-12-31   -0.658073"},{"location":"python/DataAnalysis/ch08/#2021-12-31-1206881","text":"","title":"2021-12-31    1.206881"},{"location":"python/DataAnalysis/ch08/#freq-b-dtype-float64_1","text":"### \u5b63\u5ea6\u533a\u95f4\u9891\u7387 \u5b63\u5ea6\u6570\u636e\u662f\u4f1a\u8ba1\u3001\u91d1\u878d\u548c\u5176\u4ed6\u9886\u57df\u7684\u6807\u51c6\u3002 \u5f88\u591a\u5b63\u5ea6\u6570\u636e\u662f\u5728\u8d22\u5e74\u7ed3\u5c3e\u62a5\u544a\u7684\uff0c\u901a\u5e38\u662f\u4e00\u5e7412\u4e2a\u6708\u4e2d\u7684\u6700\u540e\u4e00\u4e2a\u65e5\u5386\u65e5\u6216\u5de5\u4f5c\u65e5\u3002 pandas\u652f\u6301\u6240\u6709\u7684\u53ef\u80fd\u768412\u4e2a\u5b63\u5ea6\u9891\u7387\u4eceQ-JAN\u5230Q-DEC\uff1a \u4e0b\u4f8b\u4e2d\uff0c\u8d22\u5e74\u7ed3\u675f\u4e8e1\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7411\u6708\u81f3\u5f53\u5e741\u6708\u3002\u53ef\u4ee5\u901a\u8fc7\u8f6c\u6362\u4e3a\u6bcf\u65e5\u9891\u7387\uff08asfreq\uff09\u8fdb\u884c\u68c0\u67e5\u3002 p = pd.Period('2020Q4', freq='Q-JAN') print(p)","title":"Freq: B, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020q4","text":"print(p.asfreq('D', 'start'))","title":"2020Q4"},{"location":"python/DataAnalysis/ch08/#2019-11-01","text":"print(p.asfreq('D', 'end'))","title":"2019-11-01"},{"location":"python/DataAnalysis/ch08/#2020-01-31","text":"\u5047\u5982\u8d22\u5e74\u7ed3\u675f\u4e8e2\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7412\u6708\u81f3\u5f53\u5e742\u6708\u3002 p = pd.Period('2020Q4', freq='Q-FEB') print(p)","title":"2020-01-31"},{"location":"python/DataAnalysis/ch08/#2020q4_1","text":"print(p.asfreq('D', 'start'))","title":"2020Q4"},{"location":"python/DataAnalysis/ch08/#2019-11-01_1","text":"print(p.asfreq('D', 'end'))","title":"2019-11-01"},{"location":"python/DataAnalysis/ch08/#2020-01-31_1","text":"\u5047\u5982\u8d22\u5e74\u7ed3\u675f\u4e8e4\u6708\uff0c2020Q4\u884c\u65f6\u95f4\u4e3a\u4e0a\u4e00\u5e7412\u6708\u81f3\u5f53\u5e742\u6708\u3002 p = pd.Period('2020Q4', freq='Q-APR') print(p)","title":"2020-01-31"},{"location":"python/DataAnalysis/ch08/#2020q4_2","text":"print(p.asfreq('D', 'start'))","title":"2020Q4"},{"location":"python/DataAnalysis/ch08/#2020-02-01","text":"print(p.asfreq('D', 'end'))","title":"2020-02-01"},{"location":"python/DataAnalysis/ch08/#2020-04-30","text":"\u53ef\u4ee5\u5bf9\u533a\u95f4\u6570\u636e\u505a\u7b97\u672f\u64cd\u4f5c\u3002\u4f8b\u5982\uff0c\u8981\u83b7\u53d6\u5728\u5b63\u5ea6\u5012\u6570\u7b2c\u4e8c\u4e2a\u5de5\u4f5c\u65e5\u4e0b\u53484\u70b9\u7684\u65f6\u95f4\u6233\uff0c\u53ef\u4ee5\u8fd9\u4e48\u505a\uff1a(\u7591\u95ee\uff1a\u8fd9\u91cc\u7684\u53c2\u6570e\u4ee3\u8868\u4ec0\u4e48 ???) p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60 print(p4pm)","title":"2020-04-30"},{"location":"python/DataAnalysis/ch08/#2020-04-29-1600","text":"print(p4pm.to_timestamp())","title":"2020-04-29 16:00"},{"location":"python/DataAnalysis/ch08/#2020-04-29-160000","text":"\u53ef\u4ee5\u4f7f\u7528`peroid_range`\u751f\u6210\u5b63\u5ea6\u5e8f\u5217\u3002\u5b83\u7684\u7b97\u672f\u4e5f\u662f\u4e00\u6837\u7684\uff1a rng = pd.period_range('2000Q3', '2001Q4', freq='Q-JAN') ts = pd.Series(np.arange(len(rng)), index=rng) print(ts)","title":"2020-04-29 16:00:00"},{"location":"python/DataAnalysis/ch08/#2000q3-0","text":"","title":"2000Q3    0"},{"location":"python/DataAnalysis/ch08/#2000q4-1","text":"","title":"2000Q4    1"},{"location":"python/DataAnalysis/ch08/#2001q1-2","text":"","title":"2001Q1    2"},{"location":"python/DataAnalysis/ch08/#2001q2-3","text":"","title":"2001Q2    3"},{"location":"python/DataAnalysis/ch08/#2001q3-4","text":"","title":"2001Q3    4"},{"location":"python/DataAnalysis/ch08/#2001q4-5","text":"","title":"2001Q4    5"},{"location":"python/DataAnalysis/ch08/#freq-q-jan-dtype-int64","text":"new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60 ts.index = new_rng.to_timestamp() print(ts)","title":"Freq: Q-JAN, dtype: int64"},{"location":"python/DataAnalysis/ch08/#1999-10-28-160000-0","text":"","title":"1999-10-28 16:00:00    0"},{"location":"python/DataAnalysis/ch08/#2000-01-28-160000-1","text":"","title":"2000-01-28 16:00:00    1"},{"location":"python/DataAnalysis/ch08/#2000-04-27-160000-2","text":"","title":"2000-04-27 16:00:00    2"},{"location":"python/DataAnalysis/ch08/#2000-07-28-160000-3","text":"","title":"2000-07-28 16:00:00    3"},{"location":"python/DataAnalysis/ch08/#2000-10-30-160000-4","text":"","title":"2000-10-30 16:00:00    4"},{"location":"python/DataAnalysis/ch08/#2001-01-30-160000-5","text":"","title":"2001-01-30 16:00:00    5"},{"location":"python/DataAnalysis/ch08/#dtype-int64","text":"### \u5c06\u65f6\u95f4\u6233\u8f6c\u6362\u4e3a\u533a\u95f4\uff08\u4ee5\u53ca\u9006\u8f6c\u6362\uff09 \u901a\u8fc7\u65f6\u95f4\u6233\u7d22\u5f15\u7684Series\u548cDataFrame\u53ef\u4ee5\u88ab`to_period`\u65b9\u6cd5\u8f6c\u6362\u4e3a\u533a\u95f4\uff1a rng = pd.date_range('2020-01-01', periods=3, freq='M') ts = pd.Series(np.random.randn(3), index=rng) print(ts)","title":"dtype: int64"},{"location":"python/DataAnalysis/ch08/#2020-01-31-0567097","text":"","title":"2020-01-31   -0.567097"},{"location":"python/DataAnalysis/ch08/#2020-02-29-0634521202yearquarter2","text":"","title":"2020-02-29    0.63452\u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628ayear\u548cquarter\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f152"},{"location":"python/DataAnalysis/ch08/#2020-03-31-0297777","text":"","title":"2020-03-31    0.297777"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_9","text":"pts = ts.to_period() print(pts)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-0567097","text":"","title":"2020-01   -0.567097"},{"location":"python/DataAnalysis/ch08/#2020-02-0634522","text":"","title":"2020-02    0.634522"},{"location":"python/DataAnalysis/ch08/#2020-03-0297777","text":"","title":"2020-03    0.297777"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_10","text":"\u7531\u4e8e\u533a\u95f4\u662f\u975e\u91cd\u53e0\u65f6\u95f4\u8303\u56f4\uff0c\u4e00\u4e2a\u65f6\u95f4\u6233\u53ea\u80fd\u5c5e\u4e8e\u7ed9\u5b9a\u9891\u7387\u7684\u5355\u4e2a\u533a\u95f4\u3002 \u5c3d\u7ba1\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u6839\u636e\u65f6\u95f4\u6233\u63a8\u65ad\u51fa\u65b0`PeriodIndex`\u7684\u9891\u7387\uff0c\u4f46\u53ef\u4ee5\u6307\u5b9a\u4efb\u4f55\u60f3\u8981\u7684\u9891\u7387\u3002 \u5728\u7ed3\u679c\u4e2d\u5305\u542b\u91cd\u590d\u7684\u533a\u95f4\u4e5f\u662f\u6ca1\u6709\u95ee\u9898\u7684\u3002 rng = pd.date_range('2020-01-01', periods=6, freq='D') ts = pd.Series(np.random.randn(6), index=rng) print(ts)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0111287","text":"","title":"2020-01-01   -0.111287"},{"location":"python/DataAnalysis/ch08/#2020-01-02-1442234","text":"","title":"2020-01-02    1.442234"},{"location":"python/DataAnalysis/ch08/#2020-01-03-0767553","text":"","title":"2020-01-03   -0.767553"},{"location":"python/DataAnalysis/ch08/#2020-01-04-0265064","text":"","title":"2020-01-04   -0.265064"},{"location":"python/DataAnalysis/ch08/#2020-01-05-1200312","text":"","title":"2020-01-05    1.200312"},{"location":"python/DataAnalysis/ch08/#2020-01-06-1782557","text":"","title":"2020-01-06   -1.782557"},{"location":"python/DataAnalysis/ch08/#freq-d-dtype-float64_3","text":"ts_m = ts.to_period('M') # \u6307\u5b9aperiod\u7684\u9891\u7387\uff08M\uff09,\u8f93\u51fa\u7ed3\u679c\u5305\u542b\u91cd\u590dperiod print(ts_m)","title":"Freq: D, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-0111287","text":"","title":"2020-01   -0.111287"},{"location":"python/DataAnalysis/ch08/#2020-01-1442234","text":"","title":"2020-01    1.442234"},{"location":"python/DataAnalysis/ch08/#2020-01-0767553","text":"","title":"2020-01   -0.767553"},{"location":"python/DataAnalysis/ch08/#2020-01-0265064","text":"","title":"2020-01   -0.265064"},{"location":"python/DataAnalysis/ch08/#2020-01-1200312","text":"","title":"2020-01    1.200312"},{"location":"python/DataAnalysis/ch08/#2020-01-1782557","text":"","title":"2020-01   -1.782557"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_11","text":"\u4f7f\u7528`to_timestamp`\u53ef\u4ee5\u5c06\u533a\u95f4\u518d\u8f6c\u6362\u4e3a\u65f6\u95f4\u6233\uff1a print(ts_m.to_timestamp(how='end'))","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-0111287","text":"","title":"2020-01-31 23:59:59.999999999   -0.111287"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-1442234","text":"","title":"2020-01-31 23:59:59.999999999    1.442234"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-0767553","text":"","title":"2020-01-31 23:59:59.999999999   -0.767553"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-0265064","text":"","title":"2020-01-31 23:59:59.999999999   -0.265064"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-1200312","text":"","title":"2020-01-31 23:59:59.999999999    1.200312"},{"location":"python/DataAnalysis/ch08/#2020-01-31-235959999999999-1782557","text":"","title":"2020-01-31 23:59:59.999999999   -1.782557"},{"location":"python/DataAnalysis/ch08/#dtype-float64_9","text":"print(ts_m.to_timestamp(how='start'))","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0111287_1","text":"","title":"2020-01-01   -0.111287"},{"location":"python/DataAnalysis/ch08/#2020-01-01-1442234","text":"","title":"2020-01-01    1.442234"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0767553","text":"","title":"2020-01-01   -0.767553"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0265064","text":"","title":"2020-01-01   -0.265064"},{"location":"python/DataAnalysis/ch08/#2020-01-01-1200312","text":"","title":"2020-01-01    1.200312"},{"location":"python/DataAnalysis/ch08/#2020-01-01-1782557","text":"","title":"2020-01-01   -1.782557"},{"location":"python/DataAnalysis/ch08/#dtype-float64_10","text":"### \u4ece\u6570\u7ec4\u751f\u6210PeriodIndex \u56fa\u5b9a\u9891\u7387\u6570\u636e\u96c6\u6709\u65f6\u5b58\u50a8\u5728\u8de8\u8d8a\u591a\u5217\u7684\u65f6\u95f4\u8303\u56f4\u4fe1\u606f\u4e2d\u3002\u4f8b\u5982\uff0c\u5728\u8fd9\u4e2a\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u96c6\u4e2d\uff0c\u5e74\u4efd\u548c\u5b63\u5ea6\u5728\u4e0d\u540c\u5217\u4e2d\uff1a data = pd.read_csv('../examples/macrodata.csv') print(data.head(5))","title":"dtype: float64"},{"location":"python/DataAnalysis/ch08/#year-quarter-realgdp-realcons-unemp-pop-infl-realint","text":"","title":"year  quarter   realgdp  realcons  ...  unemp      pop  infl  realint"},{"location":"python/DataAnalysis/ch08/#0-19590-10-2710349-17074-58-177146-000-000","text":"","title":"0  1959.0      1.0  2710.349    1707.4  ...    5.8  177.146  0.00     0.00"},{"location":"python/DataAnalysis/ch08/#1-19590-20-2778801-17337-51-177830-234-074","text":"","title":"1  1959.0      2.0  2778.801    1733.7  ...    5.1  177.830  2.34     0.74"},{"location":"python/DataAnalysis/ch08/#2-19590-30-2775488-17518-53-178657-274-109","text":"","title":"2  1959.0      3.0  2775.488    1751.8  ...    5.3  178.657  2.74     1.09"},{"location":"python/DataAnalysis/ch08/#3-19590-40-2785204-17537-56-179386-027-406","text":"","title":"3  1959.0      4.0  2785.204    1753.7  ...    5.6  179.386  0.27     4.06"},{"location":"python/DataAnalysis/ch08/#4-19600-10-2847699-17705-52-180007-231-119","text":"print(data.year)","title":"4  1960.0      1.0  2847.699    1770.5  ...    5.2  180.007  2.31     1.19"},{"location":"python/DataAnalysis/ch08/#0-19590","text":"","title":"0      1959.0"},{"location":"python/DataAnalysis/ch08/#1-19590","text":"","title":"1      1959.0"},{"location":"python/DataAnalysis/ch08/#2-19590","text":"","title":"2      1959.0"},{"location":"python/DataAnalysis/ch08/#3-19590","text":"","title":"3      1959.0"},{"location":"python/DataAnalysis/ch08/#4-19600","text":"","title":"4      1960.0"},{"location":"python/DataAnalysis/ch08/#_10","text":"","title":"..."},{"location":"python/DataAnalysis/ch08/#198-20080","text":"","title":"198    2008.0"},{"location":"python/DataAnalysis/ch08/#199-20080","text":"","title":"199    2008.0"},{"location":"python/DataAnalysis/ch08/#200-20090","text":"","title":"200    2009.0"},{"location":"python/DataAnalysis/ch08/#201-20090","text":"","title":"201    2009.0"},{"location":"python/DataAnalysis/ch08/#202-20090","text":"","title":"202    2009.0"},{"location":"python/DataAnalysis/ch08/#name-year-length-203-dtype-float64","text":"print(data.quarter)","title":"Name: year, Length: 203, dtype: float64"},{"location":"python/DataAnalysis/ch08/#0-10","text":"","title":"0      1.0"},{"location":"python/DataAnalysis/ch08/#1-20","text":"","title":"1      2.0"},{"location":"python/DataAnalysis/ch08/#2-30","text":"","title":"2      3.0"},{"location":"python/DataAnalysis/ch08/#3-40","text":"","title":"3      4.0"},{"location":"python/DataAnalysis/ch08/#4-10","text":"","title":"4      1.0"},{"location":"python/DataAnalysis/ch08/#_11","text":"","title":"..."},{"location":"python/DataAnalysis/ch08/#198-30","text":"","title":"198    3.0"},{"location":"python/DataAnalysis/ch08/#199-40","text":"","title":"199    4.0"},{"location":"python/DataAnalysis/ch08/#200-10","text":"","title":"200    1.0"},{"location":"python/DataAnalysis/ch08/#201-20","text":"","title":"201    2.0"},{"location":"python/DataAnalysis/ch08/#202-30","text":"","title":"202    3.0"},{"location":"python/DataAnalysis/ch08/#name-quarter-length-203-dtype-float64","text":"\u901a\u8fc7\u5c06\u8fd9\u4e9b\u6570\u7ec4\u548c\u9891\u7387\u4f20\u9012\u7ed9`PeriodIndex`\uff0c\u53ef\u4ee5\u8054\u5408\u5f62\u6210DataFrame\u7684\u7d22\u5f15 index = pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC') print(index)","title":"Name: quarter, Length: 203, dtype: float64"},{"location":"python/DataAnalysis/ch08/#periodindex1959q1-1959q2-1959q3-1959q4-1960q1-1960q2","text":"","title":"PeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2',"},{"location":"python/DataAnalysis/ch08/#1960q3-1960q4-1961q1-1961q2","text":"","title":"'1960Q3', '1960Q4', '1961Q1', '1961Q2',"},{"location":"python/DataAnalysis/ch08/#_12","text":"","title":"..."},{"location":"python/DataAnalysis/ch08/#2007q2-2007q3-2007q4-2008q1-2008q2-2008q3","text":"","title":"'2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3',"},{"location":"python/DataAnalysis/ch08/#2008q4-2009q1-2009q2-2009q3","text":"","title":"'2008Q4', '2009Q1', '2009Q2', '2009Q3'],"},{"location":"python/DataAnalysis/ch08/#dtypeperiodq-dec-length203","text":"data.index = index # \u901a\u8fc7\u539f\u7d22\u5f151~202\uff0c\u628ayear\u548cquarter\u8054\u5408\u8d77\u6765\uff0c\u751f\u6210\u65b0\u7d22\u5f15\uff0c\u5e76\u66ff\u6362\u539f\u7d22\u5f15 print(data.infl)","title":"dtype='period[Q-DEC]', length=203)"},{"location":"python/DataAnalysis/ch08/#1959q1-000","text":"","title":"1959Q1    0.00"},{"location":"python/DataAnalysis/ch08/#1959q2-234","text":"","title":"1959Q2    2.34"},{"location":"python/DataAnalysis/ch08/#1959q3-274","text":"","title":"1959Q3    2.74"},{"location":"python/DataAnalysis/ch08/#1959q4-027","text":"","title":"1959Q4    0.27"},{"location":"python/DataAnalysis/ch08/#1960q1-231","text":"","title":"1960Q1    2.31"},{"location":"python/DataAnalysis/ch08/#_13","text":"","title":"..."},{"location":"python/DataAnalysis/ch08/#2008q3-316","text":"","title":"2008Q3   -3.16"},{"location":"python/DataAnalysis/ch08/#2008q4-879","text":"","title":"2008Q4   -8.79"},{"location":"python/DataAnalysis/ch08/#2009q1-094","text":"","title":"2009Q1    0.94"},{"location":"python/DataAnalysis/ch08/#2009q2-337","text":"","title":"2009Q2    3.37"},{"location":"python/DataAnalysis/ch08/#2009q3-356","text":"","title":"2009Q3    3.56"},{"location":"python/DataAnalysis/ch08/#freq-q-dec-name-infl-length-203-dtype-float64","text":"## \u91cd\u65b0\u91c7\u6837\u9891\u7387\u8f6c\u6362 import pandas as pd import numpy as np from pandas.tseries.frequencies import to_offset \u91cd\u65b0\u91c7\u6837\u662f\u6307\u5c06\u65f6\u95f4\u5e8f\u5217\u4ece\u4e00\u4e2a\u9891\u7387\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u9891\u7387\u7684\u8fc7\u7a0b\u3002 \u5c06\u66f4\u9ad8\u9891\u7387\u7684\u6570\u636e\u805a\u5408\u5230\u4f4e\u9891\u7387\u88ab\u79f0\u4e3a\u5411\u4e0b\u91c7\u6837\uff0c\u800c\u4ece\u4f4e\u9891\u7387\u8f6c\u6362\u5230\u9ad8\u9891\u7387\u79f0\u4e3a\u5411\u4e0a\u91c7\u6837\u3002 \u5e76\u4e0d\u662f\u6240\u6709\u7684\u91cd\u65b0\u91c7\u6837\u90fd\u5c5e\u4e8e\u4e0a\u9762\u8bf4\u7684\u4e24\u7c7b\u3002\u4f8b\u5982\uff0c\u5c06W-WED\uff08weekly on Wednesday\uff0c\u6bcf\u5468\u4e09\uff09\u8f6c\u6362\u5230W-FRI\uff08\u6bcf\u5468\u4e94\uff09\u65e2\u4e0d\u662f\u5411\u4e0a\u91c7\u6837\u4e5f\u4e0d\u662f\u5411\u4e0b\u91c7\u6837\u3002 pandas\u5bf9\u8c61\u90fd\u914d\u6709`resample`\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u6240\u6709\u9891\u7387\u8f6c\u6362\u7684\u5de5\u5177\u51fd\u6570\u3002`resample`\u62e5\u6709\u7c7b\u4f3c\u4e8e`groupby`\u7684API\uff1b\u8c03\u7528`resample`\u5bf9\u6570\u636e\u5206\u7ec4\uff0c\u4e4b\u540e\u518d\u8c03\u7528\u805a\u5408\u51fd\u6570\uff1a ### resample\u65b9\u6cd5\u53c2\u6570 \u53c2\u6570 * freq: \u8868\u793a\u91cd\u91c7\u6837\u9891\u7387\uff0c\u4f8b\u5982\u2018M'\u3001\u20185min'\uff0cSecond(15) * how='mean': \u7528\u4e8e\u4ea7\u751f\u805a\u5408\u503c\u7684\u51fd\u6570\u540d\u6216\u6570\u7ec4\u51fd\u6570\uff0c\u4f8b\u5982\u2018mean'\u3001\u2018ohlc'\u3001np.max\u7b49\uff0c\u9ed8\u8ba4\u662f\u2018mean'\uff0c\u5176\u4ed6\u5e38\u7528\u7684\u503c\u7531\uff1a\u2018first'\u3001\u2018last'\u3001\u2018median'\u3001\u2018max'\u3001\u2018min' * axis=0: \u9ed8\u8ba4\u662f\u7eb5\u8f74\uff0c\u6a2a\u8f74\u8bbe\u7f6eaxis=1 * fill_method = None: \u5347\u91c7\u6837\u65f6\u5982\u4f55\u63d2\u503c\uff0c\u6bd4\u5982\u2018ffill'\u3001\u2018bfill'\u7b49 * closed = \u2018right': \u5728\u964d\u91c7\u6837\u65f6\uff0c\u5404\u65f6\u95f4\u6bb5\u7684\u54ea\u4e00\u6bb5\u662f\u95ed\u5408\u7684\uff0c\u2018right'\u6216\u2018left'\uff0c\u9ed8\u8ba4\u2018right' * label= \u2018right': \u5728\u964d\u91c7\u6837\u65f6\uff0c\u5982\u4f55\u8bbe\u7f6e\u805a\u5408\u503c\u7684\u6807\u7b7e\uff0c\u4f8b\u5982\uff0c9\uff1a30-9\uff1a35\u4f1a\u88ab\u6807\u8bb0\u62109\uff1a30\u8fd8\u662f9\uff1a35,\u9ed8\u8ba49\uff1a35 * loffset = None: \u9762\u5143\u6807\u7b7e\u7684\u65f6\u95f4\u6821\u6b63\u503c\uff0c\u6bd4\u5982\u2018-1s'\u6216Second(-1)\u7528\u4e8e\u5c06\u805a\u5408\u6807\u7b7e\u8c03\u65e91\u79d2 * limit=None: \u5728\u5411\u524d\u6216\u5411\u540e\u586b\u5145\u65f6\uff0c\u5141\u8bb8\u586b\u5145\u7684\u6700\u5927\u65f6\u671f\u6570 * kind = None: \u805a\u5408\u5230\u65f6\u671f\uff08\u2018period'\uff09\u6216\u65f6\u95f4\u6233\uff08\u2018timestamp'\uff09\uff0c\u9ed8\u8ba4\u805a\u5408\u5230\u65f6\u95f4\u5e8f\u5217\u7684\u7d22\u5f15\u7c7b\u578b * convention = None: \u5f53\u91cd\u91c7\u6837\u65f6\u671f\u65f6\uff0c\u5c06\u4f4e\u9891\u7387\u8f6c\u6362\u5230\u9ad8\u9891\u7387\u6240\u91c7\u7528\u7684\u7ea6\u5b9a\uff08start\u6216end\uff09\u3002\u9ed8\u8ba4\u2018end' rng = pd.date_range('2020-1-1', periods=100, freq='D') ts = pd.Series(np.random.randn(len(rng)), index=rng) print(ts)","title":"Freq: Q-DEC, Name: infl, Length: 203, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0802409","text":"","title":"2020-01-01    0.802409"},{"location":"python/DataAnalysis/ch08/#2020-01-02-1147130","text":"","title":"2020-01-02   -1.147130"},{"location":"python/DataAnalysis/ch08/#2020-01-03-1076115","text":"","title":"2020-01-03   -1.076115"},{"location":"python/DataAnalysis/ch08/#2020-01-04-2097443","text":"","title":"2020-01-04   -2.097443"},{"location":"python/DataAnalysis/ch08/#2020-01-05-0577671","text":"","title":"2020-01-05    0.577671"},{"location":"python/DataAnalysis/ch08/#_14","text":"","title":"..."},{"location":"python/DataAnalysis/ch08/#2020-04-05-0110747","text":"","title":"2020-04-05   -0.110747"},{"location":"python/DataAnalysis/ch08/#2020-04-06-0132867","text":"","title":"2020-04-06    0.132867"},{"location":"python/DataAnalysis/ch08/#2020-04-07-0294061","text":"","title":"2020-04-07   -0.294061"},{"location":"python/DataAnalysis/ch08/#2020-04-08-0246155","text":"","title":"2020-04-08   -0.246155"},{"location":"python/DataAnalysis/ch08/#2020-04-09-0927194","text":"","title":"2020-04-09    0.927194"},{"location":"python/DataAnalysis/ch08/#freq-d-length-100-dtype-float64","text":"print(ts.resample('M'))","title":"Freq: D, Length: 100, dtype: float64"},{"location":"python/DataAnalysis/ch08/#datetimeindexresampler-freq-axis0-closedright-labelright-conventionstart-originstart_day","text":"print(ts.resample('M').mean()) # \u628a100\u5929\u7684\u6570\u636e\u6309\u6708groupby\uff0c\u5e76\u8f93\u51fa\u6708\u672b\u6700\u540e\u4e00\u5929\uff0c\u8ba1\u7b97\u5e73\u5747\u503c","title":"DatetimeIndexResampler [freq=, axis=0, closed=right, label=right, convention=start, origin=start_day]"},{"location":"python/DataAnalysis/ch08/#2020-01-31-0311714","text":"","title":"2020-01-31   -0.311714"},{"location":"python/DataAnalysis/ch08/#2020-02-29-0121526","text":"","title":"2020-02-29    0.121526"},{"location":"python/DataAnalysis/ch08/#2020-03-31-0051131","text":"","title":"2020-03-31   -0.051131"},{"location":"python/DataAnalysis/ch08/#2020-04-30-0273113","text":"","title":"2020-04-30   -0.273113"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_12","text":"print(ts.resample('M', kind='period').mean()) # # \u628a100\u5929\u7684\u6570\u636e\u6309\u6708groupby\uff0c\u5e76\u8f93\u51fa\u6708\u4efd\uff08\u53c2\u6570period\uff09\uff0c\u8ba1\u7b97\u5e73\u5747\u503c","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-0311714","text":"","title":"2020-01   -0.311714"},{"location":"python/DataAnalysis/ch08/#2020-02-0121526","text":"","title":"2020-02    0.121526"},{"location":"python/DataAnalysis/ch08/#2020-03-0051131","text":"","title":"2020-03   -0.051131"},{"location":"python/DataAnalysis/ch08/#2020-04-0273113","text":"","title":"2020-04   -0.273113"},{"location":"python/DataAnalysis/ch08/#freq-m-dtype-float64_13","text":"### \u5411\u4e0b\u91c7\u6837 \u5c06\u6570\u636e\u805a\u5408\u5230\u4e00\u4e2a\u89c4\u5219\u7684\u4f4e\u9891\u7387\u4e0a\u662f\u4e00\u4e2a\u5e38\u89c1\u7684\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u3002 \u8981\u805a\u5408\u7684\u6570\u636e\u4e0d\u5fc5\u662f\u56fa\u5b9a\u9891\u7387\u7684\u3002 \u671f\u671b\u7684\u9891\u7387\u5b9a\u4e49\u4e86\u7528\u4e8e\u5bf9\u65f6\u95f4\u5e8f\u5217\u5207\u7247\u4ee5\u805a\u5408\u7684\u7bb1\u4f53\u8fb9\u754c\u3002\u4f8b\u5982\uff0c\u8981\u5c06\u65f6\u95f4\u8f6c\u6362\u4e3a\u6bcf\u6708\uff0c`M`\u6216`BM`\uff0c\u5219\u9700\u8981\u5c06\u6570\u636e\u5206\u6210\u4e00\u4e2a\u6708\u7684\u65f6\u95f4\u95f4\u9694\u3002 \u6bcf\u4e2a\u95f4\u9694\u662f\u534a\u95ed\u5408\u7684\uff0c\u4e00\u4e2a\u6570\u636e\u70b9\u53ea\u80fd\u5c5e\u4e8e\u4e00\u4e2a\u65f6\u95f4\u95f4\u9694\uff0c\u65f6\u95f4\u95f4\u9694\u7684\u5e76\u96c6\u5fc5\u987b\u662f\u6574\u4e2a\u65f6\u95f4\u5e27\u3002 \u5728\u4f7f\u7528resample\u8fdb\u884c\u5411\u4e0b\u91c7\u6837\u6570\u636e\u65f6\u6709\u4e9b\u4e8b\u60c5\u9700\u8981\u8003\u8651\uff1a * \u6bcf\u6bb5\u95f4\u9694\u7684\u54ea\u4e00\u8fb9\u662f\u95ed\u5408\u7684\u3002 * \u5982\u4f55\u5728\u95f4\u9694\u7684\u8d77\u59cb\u6216\u7ed3\u675f\u4f4d\u7f6e\u6807\u8bb0\u6bcf\u4e2a\u5df2\u805a\u5408\u7684\u7bb1\u4f53\u3002 rng = pd.date_range('2020-1-1', periods=12, freq='T') ts = pd.Series(np.arange(12), index=rng) print(ts)","title":"Freq: M, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000000-0","text":"","title":"2020-01-01 00:00:00     0"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000100-1","text":"","title":"2020-01-01 00:01:00     1"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000200-2","text":"","title":"2020-01-01 00:02:00     2"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000300-3","text":"","title":"2020-01-01 00:03:00     3"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000400-4","text":"","title":"2020-01-01 00:04:00     4"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000500-5","text":"","title":"2020-01-01 00:05:00     5"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000600-6","text":"","title":"2020-01-01 00:06:00     6"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000700-7","text":"","title":"2020-01-01 00:07:00     7"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000800-8","text":"","title":"2020-01-01 00:08:00     8"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000900-9","text":"","title":"2020-01-01 00:09:00     9"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001000-10","text":"","title":"2020-01-01 00:10:00    10"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001100-11","text":"","title":"2020-01-01 00:11:00    11"},{"location":"python/DataAnalysis/ch08/#freq-t-dtype-int64","text":"\u6309\u4e94\u5206\u949f\u9891\u7387\u805a\u5408\u5206\u7ec4\uff0c\u8ba1\u7b97\u6bcf\u4e00\u7ec4\u7684\u52a0\u548c\u3002\u9891\u7387\u6309\u4e94\u5206\u949f\u7684\u589e\u91cf\u5b9a\u4e49\u4e86\u7bb1\u4f53\u8fb9\u754c\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5de6\u7bb1\u4f53\u8fb9\u754c\u662f\u5305\u542b\u7684\uff0c\u56e0\u6b6400:00\u7684\u503c\u662f\u5305\u542b\u572800:00\u523000:05\u95f4\u9694\u5185\u7684\u3002 \u4f20\u9012`closed='right'`\u5c06\u95f4\u9694\u7684\u95ed\u5408\u7aef\u6539\u4e3a\u4e86\u53f3\u8fb9\u3002 \u5206\u7ec4\uff1a * left: [00:00,00:01,00:02,00:03,00:04],[00:05,00:06,00:07,00:08,00:09],[00:10,00:11] * right:[00:00],[00:01,00:02,00:03,00:04,00:05],[00:06,00:07,00:08,00:09,00:10],[00:11] result = ts.resample('5min', closed='right').sum() print(result)","title":"Freq: T, dtype: int64"},{"location":"python/DataAnalysis/ch08/#2019-12-31-235500-0","text":"","title":"2019-12-31 23:55:00     0"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000000-15","text":"","title":"2020-01-01 00:00:00    15"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000500-40","text":"","title":"2020-01-01 00:05:00    40"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001000-11","text":"","title":"2020-01-01 00:10:00    11"},{"location":"python/DataAnalysis/ch08/#freq-5t-dtype-int64","text":"result = ts.resample('5min', closed='left').sum() print(result)","title":"Freq: 5T, dtype: int64"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000000-10","text":"","title":"2020-01-01 00:00:00    10"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000500-35","text":"","title":"2020-01-01 00:05:00    35"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001000-21","text":"","title":"2020-01-01 00:10:00    21"},{"location":"python/DataAnalysis/ch08/#freq-5t-dtype-int64_1","text":"\u6700\u540e\uff0c\u5c06\u7ed3\u679c\u7d22\u5f15\u79fb\u52a8\u4e00\u5b9a\u7684\u6570\u91cf\uff0c\u4f8b\u5982\u4ece\u53f3\u8fb9\u7f18\u51cf\u53bb\u4e00\u79d2\uff0c\u4ee5\u4f7f\u5176\u66f4\u6e05\u695a\u5730\u8868\u660e\u65f6\u95f4\u6233\u6240\u6307\u7684\u95f4\u9694\u3002 \u8981\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\uff0c\u5411`loffset`\u4f20\u9012\u5b57\u7b26\u4e32\u6216\u65e5\u671f\u504f\u7f6e\uff1a result = ts.resample('5min', closed='right', label='right', loffset='-1s').sum() print(result)","title":"Freq: 5T, dtype: int64"},{"location":"python/DataAnalysis/ch08/#2019-12-31-235959-0","text":"","title":"2019-12-31 23:59:59     0"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000459-15","text":"","title":"2020-01-01 00:04:59    15"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000959-40","text":"","title":"2020-01-01 00:09:59    40"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001459-11","text":"","title":"2020-01-01 00:14:59    11"},{"location":"python/DataAnalysis/ch08/#freq-5t-dtype-int64_2","text":"","title":"Freq: 5T, dtype: int64"},{"location":"python/DataAnalysis/ch08/#futurewarning-loffset-in-resample-and-in-grouper-is-deprecated","text":"","title":"FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated."},{"location":"python/DataAnalysis/ch08/#dfresamplefreq3s-loffset8h","text":"","title":"&gt;&gt;&gt; df.resample(freq=\"3s\", loffset=\"8H\")"},{"location":"python/DataAnalysis/ch08/#becomes","text":"","title":"becomes:"},{"location":"python/DataAnalysis/ch08/#from-pandastseriesfrequencies-import-to_offset","text":"","title":"&gt;&gt;&gt; from pandas.tseries.frequencies import to_offset"},{"location":"python/DataAnalysis/ch08/#df-dfresamplefreq3smean","text":"","title":"&gt;&gt;&gt; df = df.resample(freq=\"3s\").mean()"},{"location":"python/DataAnalysis/ch08/#dfindex-dfindexto_timestamp-to_offset8h","text":"#### \u5f00\u7aef-\u5cf0\u503c-\u8c37\u503c-\u7ed3\u675f\uff08OHLC\uff09\u91cd\u65b0\u91c7\u6837 \u5728\u91d1\u878d\u4e2d\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u6876\u8ba1\u7b97\u56db\u4e2a\u503c\u662f\u4e00\u79cd\u6d41\u884c\u7684\u65f6\u95f4\u5e8f\u5217\u805a\u5408\u65b9\u6cd5\uff1a\u7b2c\u4e00\u4e2a\u503c\uff08\u5f00\u7aef\uff09\u3001\u6700\u540e\u4e00\u4e2a\u503c\uff08\u7ed3\u675f\uff09\u3001\u6700\u5927\u503c\uff08\u5cf0\u503c\uff09\u548c\u6700\u5c0f\u503c\uff08\u8c37\u503c\uff09\u3002 \u901a\u8fc7\u4f7f\u7528`ohlc`\u805a\u5408\u51fd\u6570\u53d6\u5f97\u5305\u542b\u56db\u79cd\u805a\u5408\u503c\u5217\u7684DataFrame\uff0c\u8fd9\u4e9b\u503c\u5728\u6570\u636e\u7684\u5355\u6b21\u626b\u63cf\u4e2d\u88ab\u9ad8\u6548\u8ba1\u7b97\uff1a result = ts.resample('5min').ohlc() print(result)","title":"&gt;&gt;&gt; df.index = df.index.to_timestamp() + to_offset(\"8H\")"},{"location":"python/DataAnalysis/ch08/#open-high-low-close","text":"","title":"open  high  low  close"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000000-0-4-0-4","text":"","title":"2020-01-01 00:00:00     0     4    0      4"},{"location":"python/DataAnalysis/ch08/#2020-01-01-000500-5-9-5-9","text":"","title":"2020-01-01 00:05:00     5     9    5      9"},{"location":"python/DataAnalysis/ch08/#2020-01-01-001000-10-11-10-11","text":"### \u5411\u4e0a\u91c7\u6837\u4e0e\u63d2\u503c \u5f53\u4ece\u4f4e\u9891\u7387\u8f6c\u6362\u4e3a\u9ad8\u9891\u7387\u65f6\uff0c\u5e76\u4e0d\u9700\u8981\u4efb\u4f55\u805a\u5408\u3002 df = pd.DataFrame( np.random.randn(2, 4), index=pd.date_range('2020/1/1', periods=2, freq='W-WED'), columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(df)","title":"2020-01-01 00:10:00    10    11   10     11"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101","text":"df_daily = df.resample('W-WED').sum() print(df_daily)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_1","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819_1","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101_1","text":"df_daily = df.resample('D').sum() print(df_daily)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_2","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819_2","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-02-0000000-0000000-0000000-0000000","text":"","title":"2020-01-02  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-03-0000000-0000000-0000000-0000000","text":"","title":"2020-01-03  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-04-0000000-0000000-0000000-0000000","text":"","title":"2020-01-04  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-05-0000000-0000000-0000000-0000000","text":"","title":"2020-01-05  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-06-0000000-0000000-0000000-0000000","text":"","title":"2020-01-06  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-07-0000000-0000000-0000000-0000000","text":"","title":"2020-01-07  0.000000  0.000000  0.000000  0.000000"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101_2","text":"\u5f53\u5bf9\u8fd9\u4e9b\u6570\u636e\u4f7f\u7528\u805a\u5408\u51fd\u6570\u65f6\uff0c\u6bcf\u4e00\u7ec4\u53ea\u6709\u4e00\u4e2a\u503c\uff0c\u5e76\u4e14\u4f1a\u5728\u95f4\u9699\u4e2d\u4ea7\u751f\u7f3a\u5931\u503c\u3002 \u4f7f\u7528`asfreq`\u65b9\u6cd5\u5728\u4e0d\u805a\u5408\u7684\u60c5\u51b5\u4e0b\u8f6c\u6362\u5230\u9ad8\u9891\u7387\uff1a df_daily = df.resample('D').asfreq() print(df_daily)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_3","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819_3","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-02-nan-nan-nan-nan","text":"","title":"2020-01-02       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-03-nan-nan-nan-nan","text":"","title":"2020-01-03       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-04-nan-nan-nan-nan","text":"","title":"2020-01-04       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-05-nan-nan-nan-nan","text":"","title":"2020-01-05       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-06-nan-nan-nan-nan","text":"","title":"2020-01-06       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-07-nan-nan-nan-nan","text":"","title":"2020-01-07       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101_3","text":"\u5728\u975e\u661f\u671f\u4e09\u7684\u65e5\u671f\u4e0a\u5411\u524d\u586b\u5145\u6bcf\u5468\u6570\u503c\u3002`fillna`\u548c`reindex`\u65b9\u6cd5\u4e2d\u53ef\u7528\u7684\u586b\u5145\u6216\u63d2\u503c\u65b9\u6cd5\u53ef\u7528\u4e8e\u91cd\u91c7\u6837\uff1a df_daily = df.resample('D').ffill() print(df_daily)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_4","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819_4","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-02-0228758-0758718-0025410-1001819","text":"","title":"2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-03-0228758-0758718-0025410-1001819","text":"","title":"2020-01-03 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-04-0228758-0758718-0025410-1001819","text":"","title":"2020-01-04 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-05-0228758-0758718-0025410-1001819","text":"","title":"2020-01-05 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-06-0228758-0758718-0025410-1001819","text":"","title":"2020-01-06 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-07-0228758-0758718-0025410-1001819","text":"","title":"2020-01-07 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101_4","text":"\u53ef\u4ee5\u540c\u6837\u9009\u62e9\u4ec5\u5411\u524d\u586b\u5145\u4e00\u5b9a\u6570\u91cf\u7684\u533a\u95f4\uff0c\u4ee5\u9650\u5236\u7ee7\u7eed\u4f7f\u7528\u89c2\u6d4b\u503c\u7684\u65f6\u8ddd\uff1a df_daily = df.resample('D').ffill(limit=2) print(df_daily)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_5","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-01-0228758-0758718-0025410-1001819_5","text":"","title":"2020-01-01 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-02-0228758-0758718-0025410-1001819_1","text":"","title":"2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-03-0228758-0758718-0025410-1001819_1","text":"","title":"2020-01-03 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-04-nan-nan-nan-nan_1","text":"","title":"2020-01-04       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-05-nan-nan-nan-nan_1","text":"","title":"2020-01-05       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-06-nan-nan-nan-nan_1","text":"","title":"2020-01-06       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-07-nan-nan-nan-nan_1","text":"","title":"2020-01-07       NaN       NaN       NaN       NaN"},{"location":"python/DataAnalysis/ch08/#2020-01-08-0704541-0261414-0863335-0267101_5","text":"\u6ce8\u610f\uff0c\u65b0\u7684\u65e5\u671f\u7d22\u5f15\u4e0d\u9700\u8981\u4e0e\u65e7\u7684\u7d22\u5f15\u91cd\u53e0\uff0c\u548c\u539f\u6765`df`\u7684\u503c\u4e00\u6837\uff0c\u53ea\u662f\u65e5\u671f\u7d22\u5f15\u53d8\u4e86\u3002 df_new = df.resample('W-THU').ffill() print(df_new)","title":"2020-01-08 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_6","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-01-02-0228758-0758718-0025410-1001819_2","text":"","title":"2020-01-02 -0.228758 -0.758718 -0.025410 -1.001819"},{"location":"python/DataAnalysis/ch08/#2020-01-09-0704541-0261414-0863335-0267101","text":"### \u4f7f\u7528\u533a\u95f4\u8fdb\u884c\u91cd\u65b0\u91c7\u6837 \u5bf9\u4ee5\u533a\u95f4\u4e3a\u7d22\u5f15\u7684\u6570\u636e\u8fdb\u884c\u91c7\u6837\u4e0e\u65f6\u95f4\u6233\u7684\u60c5\u51b5\u7c7b\u4f3c\uff1a df = pd.DataFrame( np.random.randn(24, 4), index=pd.period_range('2020-1', periods=24, freq='M'), columns=['Colorado', 'Texas', 'New York', 'Ohio'] ) print(df)","title":"2020-01-09 -0.704541 -0.261414 -0.863335  0.267101"},{"location":"python/DataAnalysis/ch08/#2020-01-0721395-1492674-0707410-1641890","text":"","title":"2020-01  0.721395 -1.492674  0.707410  1.641890"},{"location":"python/DataAnalysis/ch08/#2020-02-0894880-0032823-0676158-0029203","text":"","title":"2020-02 -0.894880  0.032823 -0.676158  0.029203"},{"location":"python/DataAnalysis/ch08/#2020-03-2147365-0176796-0562695-0747656","text":"","title":"2020-03  2.147365 -0.176796  0.562695 -0.747656"},{"location":"python/DataAnalysis/ch08/#2020-04-1496037-0797119-0495601-0774147","text":"","title":"2020-04  1.496037 -0.797119 -0.495601  0.774147"},{"location":"python/DataAnalysis/ch08/#2020-05-0309839-0502563-0237244-0910624","text":"","title":"2020-05 -0.309839  0.502563  0.237244  0.910624"},{"location":"python/DataAnalysis/ch08/#2020-06-1231869-0105227-1315759-0217701","text":"","title":"2020-06  1.231869 -0.105227  1.315759  0.217701"},{"location":"python/DataAnalysis/ch08/#2020-07-1447419-0263876-0342045-0768907","text":"","title":"2020-07  1.447419  0.263876 -0.342045 -0.768907"},{"location":"python/DataAnalysis/ch08/#2020-08-2567162-1008827-0391085-1259560","text":"","title":"2020-08 -2.567162 -1.008827  0.391085  1.259560"},{"location":"python/DataAnalysis/ch08/#2020-09-0772501-1183532-0450374-0450714","text":"","title":"2020-09 -0.772501  1.183532  0.450374  0.450714"},{"location":"python/DataAnalysis/ch08/#2020-10-0228974-0461224-1393178-0175243","text":"","title":"2020-10  0.228974  0.461224  1.393178  0.175243"},{"location":"python/DataAnalysis/ch08/#2020-11-0725193-1544131-1372029-0659224","text":"","title":"2020-11 -0.725193 -1.544131  1.372029 -0.659224"},{"location":"python/DataAnalysis/ch08/#2020-12-0718195-0862024-0166460-0940191","text":"","title":"2020-12  0.718195  0.862024 -0.166460 -0.940191"},{"location":"python/DataAnalysis/ch08/#2021-01-0617054-0887312-0338451-1392838","text":"","title":"2021-01 -0.617054 -0.887312  0.338451 -1.392838"},{"location":"python/DataAnalysis/ch08/#2021-02-0081140-0634730-0868051-1277167","text":"","title":"2021-02 -0.081140  0.634730 -0.868051 -1.277167"},{"location":"python/DataAnalysis/ch08/#2021-03-0999642-1959715-0930662-0748687","text":"","title":"2021-03 -0.999642 -1.959715 -0.930662  0.748687"},{"location":"python/DataAnalysis/ch08/#2021-04-1851453-1561669-0688822-0371255","text":"","title":"2021-04  1.851453  1.561669 -0.688822 -0.371255"},{"location":"python/DataAnalysis/ch08/#2021-05-0540777-0890403-1204188-0243480","text":"","title":"2021-05 -0.540777 -0.890403 -1.204188  0.243480"},{"location":"python/DataAnalysis/ch08/#2021-06-1318905-1247457-0518969-0799793","text":"","title":"2021-06  1.318905  1.247457  0.518969  0.799793"},{"location":"python/DataAnalysis/ch08/#2021-07-0223238-0747177-0410889-0904593","text":"","title":"2021-07  0.223238  0.747177 -0.410889  0.904593"},{"location":"python/DataAnalysis/ch08/#2021-08-0652551-0254351-0464604-0676923","text":"","title":"2021-08 -0.652551 -0.254351 -0.464604 -0.676923"},{"location":"python/DataAnalysis/ch08/#2021-09-0562312-0182099-0018617-0573331","text":"","title":"2021-09  0.562312  0.182099  0.018617  0.573331"},{"location":"python/DataAnalysis/ch08/#2021-10-0429490-0045959-0356292-0295776","text":"","title":"2021-10  0.429490 -0.045959 -0.356292 -0.295776"},{"location":"python/DataAnalysis/ch08/#2021-11-2552155-0801299-1378421-1232792","text":"","title":"2021-11  2.552155  0.801299  1.378421  1.232792"},{"location":"python/DataAnalysis/ch08/#2021-12-1102288-0850280-0767015-0519840","text":"df_annual = df.resample('A-DEC').mean() print(df_annual)","title":"2021-12  1.102288  0.850280 -0.767015 -0.519840"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_7","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020-0226807-0151561-0395793-0195259","text":"","title":"2020  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021-0429056-0165581-0286339-0002594","text":"\u5411\u4e0a\u91c7\u6837\u66f4\u4e3a\u7ec6\u81f4\uff0c\u56e0\u4e3a\u5fc5\u987b\u5728\u91cd\u65b0\u91c7\u6837\u524d\u51b3\u5b9a\u65b0\u9891\u7387\u4e2d\u5728\u65f6\u95f4\u6bb5\u7684\u54ea\u4e00\u7aef\u653e\u7f6e\u6570\u503c\uff0c\u5c31\u50cfasfreq\u65b9\u6cd5\u4e00\u6837\u3002 `convention`\u53c2\u6570\u9ed8\u8ba4\u503c\u662f`start`\uff0c\u4f46\u4e5f\u53ef\u4ee5\u662f`end`\uff1a result = df_annual.resample('Q-DEC').ffill() print(result)","title":"2021  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_8","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020q1-0226807-0151561-0395793-0195259","text":"","title":"2020Q1  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2020q2-0226807-0151561-0395793-0195259","text":"","title":"2020Q2  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2020q3-0226807-0151561-0395793-0195259","text":"","title":"2020Q3  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2020q4-0226807-0151561-0395793-0195259","text":"","title":"2020Q4  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q1-0429056-0165581-0286339-0002594","text":"","title":"2021Q1  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2021q2-0429056-0165581-0286339-0002594","text":"","title":"2021Q2  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2021q3-0429056-0165581-0286339-0002594","text":"","title":"2021Q3  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2021q4-0429056-0165581-0286339-0002594","text":"result = df_annual.resample('Q-DEC', convention='end').ffill() print(result)","title":"2021Q4  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_9","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020q4-0226807-0151561-0395793-0195259_1","text":"","title":"2020Q4  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q1-0226807-0151561-0395793-0195259","text":"","title":"2021Q1  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q2-0226807-0151561-0395793-0195259","text":"","title":"2021Q2  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q3-0226807-0151561-0395793-0195259","text":"","title":"2021Q3  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q4-0429056-0165581-0286339-0002594_1","text":"\u7531\u4e8e\u533a\u95f4\u6d89\u53ca\u65f6\u95f4\u8303\u56f4\uff0c\u5411\u4e0a\u91c7\u6837\u548c\u5411\u4e0b\u91c7\u6837\u5c31\u66f4\u4e3a\u4e25\u683c\uff1a * \u5728\u5411\u4e0b\u91c7\u6837\u4e2d\uff0c\u76ee\u6807\u9891\u7387\u5fc5\u987b\u662f\u539f\u9891\u7387\u7684\u5b50\u533a\u95f4\u3002 * \u5728\u5411\u4e0a\u91c7\u6837\u4e2d\uff0c\u76ee\u6807\u9891\u7387\u5fc5\u987b\u662f\u539f\u9891\u7387\u7684\u7236\u533a\u95f4\u3002 \u5982\u679c\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u89c4\u5219\uff0c\u5c06\u4f1a\u5f15\u8d77\u5f02\u5e38\u3002\u8fd9\u4e3b\u8981\u4f1a\u5f71\u54cd\u6bcf\u5b63\u5ea6\u3001\u6bcf\u5e74\u548c\u6bcf\u5468\u7684\u9891\u7387\u3002 \u4f8b\u5982\uff0c\u6839\u636eQ-MAR\u5b9a\u4e49\u7684\u65f6\u95f4\u8303\u56f4\u5c06\u53ea\u548cA-MAR\u3001A-JUN\u3001A-SEP\u548cA-DEC\u4fdd\u6301\u4e00\u81f4\uff1a result = df_annual.resample('Q-MAR').ffill() print(result)","title":"2021Q4  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#colorado-texas-new-york-ohio_10","text":"","title":"Colorado     Texas  New York      Ohio"},{"location":"python/DataAnalysis/ch08/#2020q4-0226807-0151561-0395793-0195259_2","text":"","title":"2020Q4  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q1-0226807-0151561-0395793-0195259_1","text":"","title":"2021Q1  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q2-0226807-0151561-0395793-0195259_1","text":"","title":"2021Q2  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q3-0226807-0151561-0395793-0195259_1","text":"","title":"2021Q3  0.226807 -0.151561  0.395793  0.195259"},{"location":"python/DataAnalysis/ch08/#2021q4-0429056-0165581-0286339-0002594_2","text":"","title":"2021Q4  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2022q1-0429056-0165581-0286339-0002594","text":"","title":"2022Q1  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2022q2-0429056-0165581-0286339-0002594","text":"","title":"2022Q2  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#2022q3-0429056-0165581-0286339-0002594","text":"## \u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u7edf\u8ba1\u90a3\u4e9b\u901a\u8fc7\u79fb\u52a8\u7a97\u53e3\u6216\u6307\u6570\u8870\u51cf\u800c\u8fd0\u884c\u7684\u51fd\u6570\uff0c\u662f\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u64cd\u4f5c\u7684\u6570\u7ec4\u53d8\u6362\u7684\u4e00\u4e2a\u91cd\u8981\u7c7b\u522b\u3002 \u8fd9\u5bf9\u5e73\u6ed1\u566a\u58f0\u6216\u7c97\u7cd9\u7684\u6570\u636e\u975e\u5e38\u6709\u7528\u3002\u79f0\u8fd9\u4e9b\u51fd\u6570\u4e3a\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\uff0c\u5c3d\u7ba1\u5b83\u4e5f\u5305\u542b\u4e86\u4e00\u4e9b\u6ca1\u6709\u56fa\u5b9a\u957f\u5ea6\u7a97\u53e3\u7684\u51fd\u6570\uff0c\u6bd4\u5982\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u3002 \u4e0e\u5176\u4ed6\u7684\u7edf\u8ba1\u51fd\u6570\u7c7b\u4f3c\uff0c\u8fd9\u4e9b\u51fd\u6570\u4f1a\u81ea\u52a8\u6392\u9664\u7f3a\u5931\u6570\u636e\u3002 import matplotlib.pyplot as plt import pandas as pd from scipy.stats import percentileofscore import numpy as np from pandas.tseries.offsets import Hour, Minute, Day, MonthEnd import pytz \u5728\u6df1\u5165\u4e86\u89e3\u4e4b\u524d\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u8f7d\u5165\u4e00\u4e9b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e76\u6309\u7167\u5de5\u4f5c\u65e5\u9891\u7387\u8fdb\u884c\u91cd\u65b0\u91c7\u6837\uff1a close_px_all = pd.read_csv( '../examples/stock_px_2.csv', parse_dates = True, index_col=0 ) print(close_px_all.head(5))","title":"2022Q3  0.429056  0.165581 -0.286339 -0.002594"},{"location":"python/DataAnalysis/ch08/#aapl-msft-xom-spx","text":"","title":"AAPL   MSFT    XOM     SPX"},{"location":"python/DataAnalysis/ch08/#2003-01-02-740-2111-2922-90903","text":"","title":"2003-01-02  7.40  21.11  29.22  909.03"},{"location":"python/DataAnalysis/ch08/#2003-01-03-745-2114-2924-90859","text":"","title":"2003-01-03  7.45  21.14  29.24  908.59"},{"location":"python/DataAnalysis/ch08/#2003-01-06-745-2152-2996-92901","text":"","title":"2003-01-06  7.45  21.52  29.96  929.01"},{"location":"python/DataAnalysis/ch08/#2003-01-07-743-2193-2895-92293","text":"","title":"2003-01-07  7.43  21.93  28.95  922.93"},{"location":"python/DataAnalysis/ch08/#2003-01-08-728-2131-2883-90993","text":"close_px = close_px_all[ ['AAPL', 'MSFT', 'XOM'] ] close_px = close_px.resample('B').ffill() print(close_px)","title":"2003-01-08  7.28  21.31  28.83  909.93"},{"location":"python/DataAnalysis/ch08/#aapl-msft-xom","text":"","title":"AAPL   MSFT    XOM"},{"location":"python/DataAnalysis/ch08/#2003-01-02-740-2111-2922","text":"","title":"2003-01-02    7.40  21.11  29.22"},{"location":"python/DataAnalysis/ch08/#2003-01-03-745-2114-2924","text":"","title":"2003-01-03    7.45  21.14  29.24"},{"location":"python/DataAnalysis/ch08/#_15","text":"","title":"...            ...    ...    ..."},{"location":"python/DataAnalysis/ch08/#2011-10-13-40843-2718-7637","text":"","title":"2011-10-13  408.43  27.18  76.37"},{"location":"python/DataAnalysis/ch08/#2011-10-14-42200-2727-7811","text":"","title":"2011-10-14  422.00  27.27  78.11"},{"location":"python/DataAnalysis/ch08/#2292-rows-x-3-columns","text":"`rolling`\u7b97\u5b50\uff0c\u5b83\u7684\u884c\u4e3a\u4e0e`resample`\u548c`groupby`\u7c7b\u4f3c\u3002 `rolling`\u53ef\u4ee5\u5728Series\u6216DataFrame\u4e0a\u901a\u8fc7\u4e00\u4e2awindow\uff08\u4ee5\u4e00\u4e2a\u533a\u95f4\u7684\u6570\u5b57\u6765\u8868\u793a\uff09\u8fdb\u884c\u8c03\u7528\u3002 close_px.AAPL.plot() \u8868\u8fbe\u5f0f`rolling(250)`\u4e0e`groupby`\u7684\u884c\u4e3a\u7c7b\u4f3c\uff0c\u4f46\u662f\u5b83\u521b\u5efa\u7684\u5bf9\u8c61\u662f\u6839\u636e250\u65e5\u6ed1\u52a8\u7a97\u53e3\u5206\u7ec4\u7684\u800c\u4e0d\u662f\u76f4\u63a5\u5206\u7ec4\u3002 \u56e0\u6b64\u8fd9\u91cc\u6211\u4eec\u83b7\u5f97\u4e86\u82f9\u679c\u516c\u53f8\u80a1\u7968\u4ef7\u683c\u7684250\u65e5\u79fb\u52a8\u7a97\u53e3\u5e73\u5747\u503c\u3002 close_px.AAPL.rolling(250).mean().plot() plt.show() \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6eda\u52a8\u51fd\u6570\u9700\u8981\u7a97\u53e3\u4e2d\u6240\u6709\u7684\u503c\u5fc5\u987b\u662f\u975e`NA`\u503c\u3002 \u7531\u4e8e\u5b58\u5728\u7f3a\u5931\u503c\u8fd9\u79cd\u884c\u4e3a\u4f1a\u53d1\u751f\u6539\u53d8\uff0c\u5c24\u5176\u662f\u5728\u65f6\u95f4\u5e8f\u5217\u7684\u8d77\u59cb\u4f4d\u7f6e\u4f60\u62e5\u6709\u7684\u6570\u636e\u662f\u5c11\u4e8e\u7a97\u53e3\u533a\u95f4\u7684 apple_std250 = close_px.AAPL.rolling(250, min_periods=10).std() # \u82f9\u679c\u516c\u53f8250\u65e5\u6bcf\u65e5\u8fd4\u56de\u6807\u51c6\u5dee print(apple_std250[5:12])","title":"[2292 rows x 3 columns]"},{"location":"python/DataAnalysis/ch08/#2003-01-09-nan","text":"","title":"2003-01-09         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-10-nan","text":"","title":"2003-01-10         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-13-nan","text":"","title":"2003-01-13         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-14-nan","text":"","title":"2003-01-14         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-15-0077496","text":"","title":"2003-01-15    0.077496"},{"location":"python/DataAnalysis/ch08/#2003-01-16-0074760","text":"","title":"2003-01-16    0.074760"},{"location":"python/DataAnalysis/ch08/#2003-01-17-0112368","text":"","title":"2003-01-17    0.112368"},{"location":"python/DataAnalysis/ch08/#freq-b-name-aapl-dtype-float64","text":"apple_std250.plot() plt.show() expanding_mean = apple_std250.expanding().mean() print(expanding_mean[5:12])","title":"Freq: B, Name: AAPL, dtype: float64"},{"location":"python/DataAnalysis/ch08/#2003-01-09-nan_1","text":"","title":"2003-01-09         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-10-nan_1","text":"","title":"2003-01-10         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-13-nan_1","text":"","title":"2003-01-13         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-14-nan_1","text":"","title":"2003-01-14         NaN"},{"location":"python/DataAnalysis/ch08/#2003-01-15-0077496_1","text":"","title":"2003-01-15    0.077496"},{"location":"python/DataAnalysis/ch08/#2003-01-16-0076128","text":"","title":"2003-01-16    0.076128"},{"location":"python/DataAnalysis/ch08/#2003-01-17-0088208","text":"","title":"2003-01-17    0.088208"},{"location":"python/DataAnalysis/ch08/#freq-b-name-aapl-dtype-float64_1","text":"expanding_mean.plot() plt.show() \u5728DataFrame\u4e0a\u8c03\u7528\u4e00\u4e2a\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\u4f1a\u5c06\u53d8\u6362\u5e94\u7528\u5230\u6bcf\u4e00\u5217\u4e0a: close_px.rolling(60).mean().plot(logy=True) # \u80a1\u7968\u4ef7\u683c60\u65e5MA\uff08Y\u8f74\u53d6\u5bf9\u6570\uff09 plt.show() `rolling`\u51fd\u6570\u4e5f\u63a5\u6536\u8868\u793a\u56fa\u5b9a\u5927\u5c0f\u7684\u65f6\u95f4\u504f\u7f6e\u5b57\u7b26\u4e32\uff0c\u800c\u4e0d\u53ea\u662f\u4e00\u4e2a\u533a\u95f4\u7684\u96c6\u5408\u6570\u5b57\u3002 \u5bf9\u4e0d\u89c4\u5219\u65f6\u95f4\u5e8f\u5217\u4f7f\u7528\u6ce8\u91ca\u975e\u5e38\u6709\u7528\u3002\u8fd9\u4e9b\u5b57\u7b26\u4e32\u53ef\u4ee5\u4f20\u9012\u7ed9`resample`\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u50cf\u8fd9\u6837\u8ba1\u7b9720\u5929\u7684\u6eda\u52a8\u5e73\u5747\u503c\uff1a result = close_px.rolling('20D').mean() print(result)","title":"Freq: B, Name: AAPL, dtype: float64"},{"location":"python/DataAnalysis/ch08/#aapl-msft-xom_1","text":"","title":"AAPL       MSFT        XOM"},{"location":"python/DataAnalysis/ch08/#2003-01-02-7400000-21110000-29220000","text":"","title":"2003-01-02    7.400000  21.110000  29.220000"},{"location":"python/DataAnalysis/ch08/#_16","text":"","title":"...                ...        ...        ..."},{"location":"python/DataAnalysis/ch08/#2011-10-14-391038000-26048667-74185333","text":"","title":"2011-10-14  391.038000  26.048667  74.185333"},{"location":"python/DataAnalysis/ch08/#2292-rows-x-3-columns_1","text":"result.plot() plt.show() ### \u6307\u6570\u52a0\u6743\u51fd\u6570 \u6307\u5b9a\u4e00\u4e2a\u5e38\u6570\u8870\u51cf\u56e0\u5b50\u4ee5\u5411\u66f4\u591a\u8fd1\u671f\u89c2\u6d4b\u503c\u63d0\u4f9b\u66f4\u591a\u6743\u91cd\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f7f\u7528\u5177\u6709\u76f8\u7b49\u52a0\u6743\u89c2\u5bdf\u503c\u7684\u9759\u6001\u7a97\u53e3\u5c3a\u5bf8\u7684\u65b9\u6cd5\u3002 \u6709\u591a\u79cd\u65b9\u5f0f\u53ef\u4ee5\u6307\u5b9a\u8870\u51cf\u56e0\u5b50\u3002\u5176\u4e2d\u4e00\u79cd\u6d41\u884c\u7684\u65b9\u5f0f\u662f\u4f7f\u7528\u4e00\u4e2aspan\uff08\u8de8\u5ea6\uff09\uff0c\u8fd9\u4f7f\u5f97\u7ed3\u679c\u4e0e\u7a97\u53e3\u5927\u5c0f\u7b49\u4e8e\u8de8\u5ea6\u7684\u7b80\u5355\u79fb\u52a8\u7a97\u53e3\u51fd\u6570\u3002 \u7531\u4e8e\u6307\u6570\u52a0\u6743\u7edf\u8ba1\u503c\u7ed9\u66f4\u8fd1\u671f\u7684\u89c2\u6d4b\u503c\u4ee5\u66f4\u591a\u7684\u6743\u91cd\uff0c\u4e0e\u7b49\u6743\u91cd\u7684\u7248\u672c\u76f8\u6bd4\uff0c\u5b83\u5bf9\u53d8\u5316\u201c\u9002\u5e94\u201d\u5f97\u66f4\u5feb\u3002 pandas\u62e5\u6709`ewm`\u7b97\u5b50\uff0c\u540c`rolling`\u3001`expanding`\u7b97\u5b50\u4e00\u8d77\u4f7f\u7528\u3002 \u4ee5\u4e0b\u662f\u5c06\u82f9\u679c\u516c\u53f8\u80a1\u7968\u4ef7\u683c\u768460\u65e5\u5747\u7ebf\u4e0e`span=60`\u7684EW\u79fb\u52a8\u5e73\u5747\u7ebf\u8fdb\u884c\u6bd4\u8f83\u7684\u4f8b\u5b50\uff1a aapl_ex = close_px.AAPL['2006':'2007'] ma60 = aapl_ex.rolling(30, min_periods=20).mean() ewma60 = aapl_ex.ewm(span=30).mean() ma60.plot(style='k--', label='Simple MA') ewma60.plot(style='k-', label='EWMA') plt.legend() plt.show() ### \u4e8c\u5143\u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u4e00\u4e9b\u7edf\u8ba1\u7b97\u5b50\uff0c\u4f8b\u5982\u76f8\u5173\u5ea6\u548c\u534f\u65b9\u5dee\uff0c\u9700\u8981\u64cd\u4f5c\u4e24\u4e2a\u65f6\u95f4\u5e8f\u5217\u3002 \u4f8b\u5982\uff0c\u91d1\u878d\u5206\u6790\u5e08\u7ecf\u5e38\u5bf9\u80a1\u7968\u4e0e\u57fa\u51c6\u6307\u6570\uff08\u5982\u6807\u666e500\uff09\u7684\u5173\u8054\u6027\u611f\u5174\u8da3\u3002 \u6211\u4eec\u9996\u5148\u8ba1\u7b97\u6240\u6709\u6211\u4eec\u611f\u5174\u8da3\u7684\u65f6\u95f4\u5e8f\u5217\u7684\u767e\u5206\u6bd4\u53d8\u5316\uff1a spx_px = close_px_all['SPX'] spx_rets = spx_px.pct_change() returns = close_px.pct_change()","title":"[2292 rows x 3 columns]"},{"location":"python/DataAnalysis/ch08/#rollingcorrspx_rets","text":"corr = returns.AAPL.rolling(125, min_periods=100).corr(spx_rets) # \u82f9\u679c\u516c\u53f8\u4e0e\u6807\u666e500\u7684\u516d\u4e2a\u6708\u7684\u6536\u76ca\u76f8\u5173\u6027 corr.plot() plt.show() corr = returns.rolling(125, min_periods=100).corr(spx_rets) # \u591a\u53ea\u80a1\u7968\u4e0e\u6807\u666e500\u7684\u516d\u4e2a\u6708\u6536\u76ca\u76f8\u5173\u6027 corr.plot() plt.show() ### \u7528\u6237\u81ea\u5b9a\u4e49\u7684\u79fb\u52a8\u7a97\u53e3\u51fd\u6570 \u5728`rolling`\u53ca\u5176\u76f8\u5173\u65b9\u6cd5\u4e0a\u4f7f\u7528apply\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u79fb\u52a8\u7a97\u53e3\u4e2d\u5e94\u7528\u4f60\u81ea\u5df1\u8bbe\u8ba1\u7684\u6570\u7ec4\u51fd\u6570\u7684\u65b9\u6cd5\u3002 \u552f\u4e00\u7684\u8981\u6c42\u662f\u8be5\u51fd\u6570\u4ece\u6bcf\u4e2a\u6570\u7ec4\u4e2d\u4ea7\u751f\u4e00\u4e2a\u5355\u503c\uff08\u7f29\u805a\uff09\u3002 \u4f8b\u5982\uff0c\u5c3d\u7ba1\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`rolling(...).quantile(q)`\u8ba1\u7b97\u6837\u672c\u7684\u5206\u4f4d\u6570\uff0c\u4f46\u6211\u4eec\u53ef\u80fd\u4f1a\u5bf9\u6837\u672c\u4e2d\u7279\u5b9a\u503c\u7684\u767e\u5206\u4f4d\u6570\u611f\u5174\u8da3\u3002 `scipy.stats.percentileofscore`\u51fd\u6570\u5c31\u662f\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\u7684\uff1a score_at_2percent = lambda x: percentileofscore(x, 0.02) result = returns.AAPL.rolling(250).apply(score_at_2percent) # \u4e00\u5e74\u7a97\u53e3\u4e0b\u82f9\u679c\u516c\u53f8\u80a1\u4ef72%\u6536\u76ca\u7684\u767e\u5206\u4f4d\u7b49\u7ea7 result.plot() plt.show() result = returns.rolling(250).apply(score_at_2percent) # \u4e00\u5e74\u7a97\u53e3\u4e0b\u6240\u6709\u516c\u53f8\u80a1\u4ef72%\u6536\u76ca\u7684\u767e\u5206\u4f4d\u7b49\u7ea7 result.plot() plt.show() ```","title":"\u5728\u8c03\u7528rolling\u540e\uff0ccorr\u805a\u5408\u51fd\u6570\u53ef\u4ee5\u6839\u636espx_rets\u8ba1\u7b97\u6eda\u52a8\u76f8\u5173\u6027\uff1a"},{"location":"python/DataAnalysis/ch09/","text":"\u9ad8\u9636pandas \u5206\u7c7b\u6570\u636e import numpy as np import pandas as pd \u80cc\u666f\u548c\u76ee\u6807 \u4e00\u4e2a\u5217\u7ecf\u5e38\u4f1a\u5305\u542b\u91cd\u590d\u503c\uff0c\u8fd9\u4e9b\u91cd\u590d\u503c\u662f\u4e00\u4e2a\u5c0f\u578b\u7684\u4e0d\u540c\u503c\u7684\u96c6\u5408\u3002 unique \u548c value_counts \u8fd9\u6837\u7684\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u4ece\u4e00\u4e2a\u6570\u7ec4\u4e2d\u63d0\u53d6\u4e0d\u540c\u503c\u5e76\u5206\u522b\u8ba1\u7b97\u8fd9\u4e9b\u4e0d\u540c\u503c\u7684\u9891\u7387\uff1a values = pd.Series(['apple', 'orange', 'apple', 'apple'] * 2) print(values) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # dtype: object print(pd.unique(values)) # ['apple' 'orange'] print(pd.value_counts(values)) # apple 6 # orange 2 # dtype: int64 \u5728\u6570\u636e\u5165\u5e93\u7684\u64cd\u4f5c\u4e2d\uff0c\u4f7f\u7528\u7ef4\u5ea6\u8868\u662f\u4e00\u79cd\u6700\u4f73\u5b9e\u8df5\uff0c\u7ef4\u5ea6\u8868\u5305\u542b\u4e86\u4e0d\u540c\u503c\uff0c\u5e76\u5c06\u4e3b\u8981\u89c2\u6d4b\u503c\u5b58\u50a8\u4e3a\u5f15\u7528\u7ef4\u5ea6\u8868\u7684\u6574\u6570\u952e\uff1a values = pd.Series([0, 1, 0, 0] * 2) dim = pd.Series(['apple', 'oragne']) \u4f7f\u7528 take \u65b9\u6cd5\u6765\u6062\u590d\u539f\u6765\u7684\u5b57\u7b26\u4e32Series\u3002\uff080\u5bf9\u5e94\u5230apple)\u3002 \u8fd9\u79cd\u6309\u7167\u6574\u6570\u5c55\u73b0\u7684\u65b9\u5f0f\u88ab\u79f0\u4e3a\u5206\u7c7b\u6216\u5b57\u5178\u7f16\u7801\u5c55\u73b0\u3002\u4e0d\u540c\u503c\u7684\u6570\u7ec4\u53ef\u4ee5\u88ab\u79f0\u4e3a\u6570\u636e\u7684\u7c7b\u522b\u3001\u5b57\u5178\u6216\u5c42\u7ea7\u3002 print(dim.take(values)) # 0 apple # 1 oragne # 0 apple # 0 apple # 0 apple # 1 oragne # 0 apple # 0 apple # dtype: object \u5728\u505a\u6570\u636e\u5206\u6790\u65f6\uff0c\u5206\u7c7b\u5c55\u793a\u4f1a\u4ea7\u751f\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u53ef\u4ee5\u5728\u7c7b\u522b\u4e0a\u8fdb\u884c\u8f6c\u6362\u540c\u65f6\u4e0d\u6539\u53d8\u4ee3\u7801\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e9b\u76f8\u5bf9\u4f4e\u5f00\u9500\u7684\u8f6c\u6362\u793a\u4f8b\uff1a \u91cd\u547d\u540d\u7c7b\u522b \u5728\u4e0d\u6539\u53d8\u5df2\u6709\u7684\u7c7b\u522b\u987a\u5e8f\u7684\u60c5\u51b5\u4e0b\u6dfb\u52a0\u4e00\u4e2a\u65b0\u7684\u7c7b\u522b pandas\u4e2d\u7684Categorical\u7c7b\u578b pandas\u62e5\u6709\u7279\u6b8a\u7684 Categorical \u7c7b\u578b\uff0c\u7528\u4e8e\u627f\u8f7d\u57fa\u4e8e\u6574\u6570\u7684\u7c7b\u522b\u5c55\u793a\u6216\u7f16\u7801\u7684\u6570\u636e\u3002 fruits = ['apple', 'orange', 'apple', 'apple'] * 2 N = len(fruits) df = pd.DataFrame( { 'fruit': fruits, 'basket_id': np.arange(N), 'count': np.random.randint(3, 15, size=N), 'weight': np.random.uniform(0, 4, size=N) }, columns=['basket_id', 'fruit', 'count', 'weight'] ) print(df) # basket_id fruit count weight # 0 0 apple 8 1.288867 # 1 1 orange 4 3.414430 # 2 2 apple 7 3.222160 # 3 3 apple 14 2.724804 # 4 4 apple 8 3.548828 # 5 5 orange 10 0.918739 # 6 6 apple 4 0.784816 # 7 7 apple 10 3.140607 df['fruit'] \u662f\u4e00\u4e2aPython\u5b57\u7b26\u4e32\u5bf9\u8c61\u7ec4\u6210\u7684\u6570\u7ec4\u3002\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u51fd\u6570\u5c06\u5b83\u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a fruit_cat = df['fruit'].astype('category') print(fruit_cat) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: category # Categories (2, object): ['apple', 'orange'] fruit_cat \u7684\u503c\u5e76\u4e0d\u662fNumPy\u6570\u7ec4\uff0c\u800c\u662f pandas.Categorical \u7684\u5b9e\u4f8b\uff1a c = fruit_cat.values print(type(c)) # <class 'pandas.core.arrays.categorical.Categorical'> print(c) # ['apple', 'orange', 'apple', 'apple', 'apple', 'orange', 'apple', 'apple'] # Categories (2, object): ['apple', 'orange'] Categorical \u5bf9\u8c61\u62e5\u6709 categories \u548c codes \u5c5e\u6027\uff1a print(c.categories) # Index(['apple', 'orange'], dtype='object') print(c.codes) # [0 1 0 0 0 1 0 0] \u901a\u8fc7\u5206\u914d\u5df2\u8f6c\u6362\u7684\u7ed3\u679c\u5c06DataFrame\u7684\u4e00\u5217\u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a print(df['fruit']) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: object df['fruit'] = df['fruit'].astype('category') print(df['fruit']) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: category # Categories (2, object): ['apple', 'orange'] \u4e5f\u53ef\u4ee5\u4ece\u5176\u4ed6Python\u5e8f\u5217\u7c7b\u578b\u76f4\u63a5\u751f\u6210 pandas.Categorical \uff1a my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar']) print(my_categories) # ['foo', 'bar', 'baz', 'foo', 'bar'] # Categories (3, object): ['bar', 'baz', 'foo'] \u4e5f\u53ef\u4ee5\u4f7f\u7528 from_codes \u6784\u9020\u51fd\u6570\u6765\u8f6c\u6362\u5176\u4ed6\u6570\u636e\u6e90\u7684\u5206\u7c7b\u7f16\u7801\u6570\u636e\uff1a categories = ['foo', 'bar', 'baz'] codes = [0, 1, 2, 0, 0, 1] my_cats_2 = pd.Categorical.from_codes(codes, categories) print(my_cats_2) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo', 'bar', 'baz'] \u8fd9\u4e2a\u672a\u6392\u5e8f\u7684\u5206\u7c7b\u5b9e\u4f8b\u53ef\u4ee5\u4f7f\u7528 as_ordered \u8fdb\u884c\u6392\u5e8f\uff1a print(my_cats_2.as_ordered()) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo' < 'bar' < 'baz'] \u9664\u975e\u663e\u5f0f\u5730\u6307\u5b9a\uff0c\u5206\u7c7b\u8f6c\u6362\u662f\u4e0d\u4f1a\u6307\u5b9a\u7c7b\u522b\u7684\u987a\u5e8f\u7684\u3002\u56e0\u6b64 categories \u6570\u7ec4\u53ef\u80fd\u4f1a\u4e0e\u8f93\u5165\u6570\u636e\u7684\u987a\u5e8f\u4e0d\u540c\u3002 \u5f53\u4f7f\u7528 from_codes \u6216\u5176\u4ed6\u4efb\u610f\u6784\u9020\u51fd\u6570\u65f6\uff0c\u53ef\u4ee5\u4e3a\u7c7b\u522b\u6307\u5b9a\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u987a\u5e8f\uff1a\u8f93\u51fa\u7684 [foo<bar<baz] \u8868\u660e foo \u7684\u987a\u5e8f\u5728 bar \u4e4b\u524d\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002 my_categories_ordered = pd.Categorical.from_codes(codes=codes, categories=categories, ordered=True) print(my_categories_ordered) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo' < 'bar' < 'baz'] \u5206\u7c7b\u6570\u636e\u53ef\u4ee5\u4e0d\u662f\u5b57\u7b26\u4e32\uff0c\u5c3d\u7ba1\u4e3e\u7684\u4f8b\u5b50\u90fd\u662f\u5b57\u7b26\u4e32\u4f8b\u5b50\u3002\u4e00\u4e2a\u5206\u7c7b\u6570\u7ec4\u53ef\u4ee5\u5305\u542b\u4efb\u4e00\u4e0d\u53ef\u53d8\u7684\u503c\u7c7b\u578b\u3002 \u4f7f\u7528Categorical\u5bf9\u8c61\u8fdb\u884c\u8ba1\u7b97 \u5728pandas\u4e2d\u4f7f\u7528 Categorical \u4e0e\u975e\u7f16\u7801\u7248\u672c\u76f8\u6bd4\uff08\u4f8b\u5982\u5b57\u7b26\u4e32\u6570\u7ec4\uff09\u6574\u4f53\u4e0a\u662f\u4e00\u81f4\u7684\u3002 pandas\u4e2d\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u6bd4\u5982 groupby \u51fd\u6570\uff0c\u5728\u4e0e Categorical \u5bf9\u8c61\u534f\u540c\u5de5\u4f5c\u65f6\u6027\u80fd\u66f4\u597d\u3002 \u8fd8\u6709\u4e00\u4e9b\u51fd\u6570\u53ef\u4ee5\u5229\u7528ordered\u6807\u8bc6\u3002 \u4e0b\u9762\u8003\u8651\u4e00\u4e9b\u968f\u673a\u6570\u5b57\u6570\u636e\uff0c\u5e76\u4f7f\u7528 pandas.qcut \u5206\u7bb1\u51fd\u6570\u3002\u7ed3\u679c\u4f1a\u8fd4\u56de pandas.Categorical \uff1b \u5728\u524d\u9762\u7ae0\u8282\u4f7f\u7528\u8fc7 pandas.cut \uff0c\u4f46\u5f53\u65f6\u6ca1\u6709\u5206\u6790\u5206\u7c7b\u662f\u5982\u4f55\u5de5\u4f5c\u7684\u7ec6\u8282\u3002 np.random.seed(12345) draws = np.random.randn(1000) print(draws[:5]) # [-0.20470766 0.47894334 -0.51943872 -0.5557303 1.96578057] \u8ba1\u7b97\u4e0a\u9762\u6570\u636e\u7684\u56db\u5206\u4f4d\u5206\u7bb1\uff0c\u5e76\u63d0\u53d6\u4e00\u4e9b\u7edf\u8ba1\u503c\uff1a bins = pd.qcut(draws, 4) print(bins) # [(-0.684, -0.0101], (-0.0101, 0.63], (-0.684, -0.0101], (-0.684, -0.0101], (0.63, 3.928], ..., (-0.0101, 0.63], (-0.684, -0.0101], (-2.9499999999999997, -0.684], (-0.0101, 0.63], (0.63, 3.928]] # Length: 1000 # Categories (4, interval[float64, right]): [(-2.9499999999999997, -0.684] < (-0.684, -0.0101] < (-0.0101, 0.63] < (0.63, 3.928]] \u901a\u8fc7\u5728 qcut \u51fd\u6570\u4e2d\u4f7f\u7528 labels \u53c2\u6570\u6765\u56db\u5206\u4f4d\u6570\u540d\u79f0\uff1a bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4']) print(bins) # ['Q2', 'Q3', 'Q2', 'Q2', 'Q4', ..., 'Q3', 'Q2', 'Q1', 'Q3', 'Q4'] # Length: 1000 # Categories (4, object): ['Q1' < 'Q2' < 'Q3' < 'Q4'] print(bins.codes[:10]) # [1 2 1 1 3 3 2 2 3 3] \u88ab\u6807\u8bb0\u7684 bins \u5206\u7c7b\u6570\u636e\u5e76\u4e0d\u5305\u542b\u6570\u636e\u4e2d\u7bb1\u4f53\u8fb9\u754c\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528 groupby \u6765\u63d0\u53d6\u4e00\u4e9b\u6c47\u603b\u7edf\u8ba1\u503c\uff1a bins = pd.Series(bins, name='quartile') result = (pd.Series(draws).groupby(bins).agg(['count', 'min', 'max']).reset_index()) print(result) # quartile count min max # 0 Q1 250 -2.949343 -0.685484 # 1 Q2 250 -0.683066 -0.010115 # 2 Q3 250 -0.010032 0.628894 # 3 Q4 250 0.634238 3.927528 \u7ed3\u679c\u4e2d\u7684 quartile \u5217\u4fdd\u7559\u4e86 bins \u4e2d\u539f\u59cb\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u5305\u62ec\u987a\u5e8f\uff1a print(result['quartile']) # 0 Q1 # 1 Q2 # 2 Q3 # 3 Q4 # Name: quartile, dtype: category # Categories (4, object): ['Q1' < 'Q2' < 'Q3' < 'Q4'] \u4f7f\u7528\u5206\u7c7b\u83b7\u5f97\u66f4\u9ad8\u6027\u80fd \u5982\u679c\u5bf9\u7279\u5b9a\u7684\u6570\u636e\u96c6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u5206\u6790\uff0c\u5c06\u6570\u636e\u8f6c\u6362\u4e3a\u5206\u7c7b\u6570\u636e\u53ef\u4ee5\u4ea7\u751f\u5927\u5e45\u7684\u6027\u80fd\u63d0\u5347\u3002DateFrame\u4e2d\u4e00\u5217\u7684\u5206\u7c7b\u7248\u672c\u901a\u5e38\u4e5f\u4f1a\u660e\u663e\u4f7f\u7528\u66f4\u5c11\u5185\u5b58\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u542b\u6709\u4e00\u5343\u4e07\u5143\u7d20\u7684Series\u4ee5\u53ca\u5c11\u91cf\u7684\u4e0d\u540c\u7c7b\u522b\uff1a N = 10000000 draws = pd.Series(np.random.randn(N)) labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4)) \u73b0\u5728\u5c06 labels \u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a categories = labels.astype('category') print(labels.memory_usage()) # labels\u6bd4categories\u4f7f\u7528\u4e86\u660e\u663e\u66f4\u591a\u7684\u5185\u5b58 # 80000128 print(categories.memory_usage()) # 10000332 \u5206\u7c7b\u65b9\u6cd5 Series\u5305\u542b\u7684\u5206\u7c7b\u6570\u636e\u62e5\u6709\u4e00\u4e9b\u7279\u6b8a\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7c7b\u4f3c\u4e8eSeries.str\u7684\u7279\u6b8a\u5b57\u7b26\u4e32\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5feb\u6377\u8bbf\u95ee\u7c7b\u522b\u548c\u4ee3\u7801\u7684\u65b9\u5f0f\u3002 s = pd.Series(['a', 'b', 'c', 'd'] * 2) cat_s = s.astype('category') print(cat_s) # 0 a # 1 b # 2 c # 3 d # 4 a # 5 b # 6 c # 7 d # dtype: category # Categories (4, object): ['a', 'b', 'c', 'd'] \u7279\u6b8a\u5c5e\u6027 cat \u63d0\u4f9b\u4e86\u5bf9\u5206\u7c7b\u65b9\u6cd5\u7684\u8bbf\u95ee\uff1a print(cat_s.cat.codes) # 0 0 # 1 1 # 2 2 # 3 3 # 4 0 # 5 1 # 6 2 # 7 3 # dtype: int8 print(cat_s.cat.categories) # Index(['a', 'b', 'c', 'd'], dtype='object') \u5047\u8bbe\u6570\u636e\u7684\u5b9e\u9645\u7c7b\u522b\u96c6\u5408\u8d85\u51fa\u4e86\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u56db\u4e2a\u503c\uff0c\u53ef\u4ee5\u4f7f\u7528 set_categories \u65b9\u6cd5\u6765\u6539\u53d8\u7c7b\u522b\uff1a actual_categories = ['a', 'b', 'c', 'd', 'e'] cat_s2 = cat_s.cat.set_categories(actual_categories) print(cat_s2) # 0 a # 1 b # 2 c # 3 d # 4 a # 5 b # 6 c # 7 d # dtype: category # Categories (5, object): ['a', 'b', 'c', 'd', 'e'] \u867d\u7136\u770b\u8d77\u6765\u6570\u636e\u5e76\u672a\u6539\u53d8\uff0c\u4f46\u65b0\u7c7b\u522b\u5c06\u53cd\u6620\u5728\u4f7f\u7528\u5b83\u4eec\u7684\u64cd\u4f5c\u4e2d\u3002\u4f8b\u5982\uff0c value_counts \u5c06\u9075\u5faa\u65b0\u7684\u7c7b\u522b\uff08\u5982\u679c\u5b58\u5728\uff09\uff1a print(cat_s.value_counts()) # a 2 # b 2 # c 2 # d 2 # dtype: int64 print(cat_s2.value_counts()) # a 2 # b 2 # c 2 # d 2 # e 0 # dtype: int64 \u5927\u578b\u6570\u636e\u96c6\u4e2d\uff0c\u5206\u7c7b\u6570\u636e\u7ecf\u5e38\u88ab\u7528\u4e8e\u8282\u7701\u5185\u5b58\u548c\u66f4\u9ad8\u6027\u80fd\u7684\u4fbf\u6377\u5de5\u5177\u3002 \u5728\u8fc7\u6ee4\u4e86\u4e00\u4e2a\u5927\u578bDataFrame\u6216Series\u4e4b\u540e\uff0c\u5f88\u591a\u7c7b\u522b\u5c06\u4e0d\u4f1a\u51fa\u73b0\u5728\u6570\u636e\u4e2d\u3002 \u53ef\u4ee5\u4f7f\u7528 remove_unused_categories \u65b9\u6cd5\u6765\u53bb\u9664\u672a\u89c2\u5bdf\u5230\u7684\u7c7b\u522b\uff1a cat_s3 = cat_s[cat_s.isin(['a', 'b'])] print(cat_s3) # 0 a # 1 b # 4 a # 5 b # dtype: category # Categories (4, object): ['a', 'b', 'c', 'd'] print(cat_s3.cat.remove_unused_categories()) # 0 a # 1 b # 4 a # 5 b # dtype: category # Categories (2, object): ['a', 'b'] \u521b\u5efa\u7528\u4e8e\u5efa\u6a21\u7684\u865a\u62df\u53d8\u91cf \u5f53\u4f7f\u7528\u7edf\u8ba1\u6570\u636e\u6216\u673a\u5668\u5b66\u4e60\u5de5\u5177\u65f6\uff0c\u901a\u5e38\u4f1a\u5c06\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u865a\u62df\u53d8\u91cf\uff0c\u4e5f\u79f0\u4e3aone-hot\u7f16\u7801\u3002 \u8fd9\u4f1a\u4ea7\u751f\u4e00\u4e2aDataFrame\uff0c\u6bcf\u4e2a\u4e0d\u540c\u7684\u7c7b\u522b\u90fd\u662f\u5b83\u7684\u4e00\u5217\u3002\u8fd9\u4e9b\u5217\u5305\u542b\u4e00\u4e2a\u7279\u5b9a\u7c7b\u522b\u7684\u51fa\u73b0\u6b21\u6570\uff0c\u5426\u5219\u4e3a0\u3002 cat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category') \u4f7f\u7528 pandas.get_dummies \u51fd\u6570\u5c06\u4e00\u7ef4\u7684\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u4e00\u4e2a\u5305\u542b\u865a\u62df\u53d8\u91cf\u7684DataFrame\uff1a print(pd.get_dummies(cat_s)) # a b c d # 0 1 0 0 0 # 1 0 1 0 0 # 2 0 0 1 0 # 3 0 0 0 1 # 4 1 0 0 0 # 5 0 1 0 0 # 6 0 0 1 0 # 7 0 0 0 1 \u9ad8\u9636GroupBy\u5e94\u7528 import numpy as np import pandas as pd \u5206\u7ec4\u8f6c\u6362\u548c\u201c\u5c55\u5f00\u201dGroupBy \u5728\u5206\u7ec4\u64cd\u4f5c\u4e2d\u53ef\u4ee5\u4f7f\u7528apply\u65b9\u6cd5\u5b9e\u73b0\u8f6c\u6362\u64cd\u4f5c\u3002\u8fd8\u6709\u53e6\u4e00\u4e2a\u5185\u5efa\u65b9\u6cd5transform\uff0c\u4e0eapply\u65b9\u6cd5\u7c7b\u4f3c\u4f46\u662f\u53ef\u4ee5\u5bf9\u4f7f\u7528\u7684\u51fd\u6570\u52a0\u4e0a\u66f4\u591a\u7684\u9650\u5236\uff1a transform\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u6807\u91cf\u503c\uff0c\u5e76\u5e7f\u64ad\u5230\u5404\u5206\u7ec4\u7684\u5c3a\u5bf8\u6570\u636e\u4e2d\u3002 transform\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u4e0e\u8f93\u5165\u5206\u7ec4\u5c3a\u5bf8\u76f8\u540c\u7684\u5bf9\u8c61\u3002 transform\u4e0d\u53ef\u6539\u53d8\u5b83\u7684\u8f93\u5165\u3002 df = pd.DataFrame( { 'key': ['a', 'b', 'c'] * 4, 'value': np.arange(12) } ) print(df) # key value # 0 a 0 # 1 b 1 # 2 c 2 # 3 a 3 # 4 b 4 # 5 c 5 # 6 a 6 # 7 b 7 # 8 c 8 # 9 a 9 # 10 b 10 # 11 c 11 \u6309 key \u5206\u7ec4\u7684\u5747\u503c\uff1a g = df.groupby('key').value print(g.mean()) # key # a 4.5 # b 5.5 # c 6.5 # Name: value, dtype: float64 \u5047\u8bbe\u8981\u4ea7\u751f\u4e00\u4e2aSeries\uff0c\u5b83\u7684\u5c3a\u5bf8\u548c df['value'] \u4e00\u6837\uff0c\u4f46\u503c\u90fd\u88ab\u6309 key \u5206\u7ec4\u7684\u5747\u503c\u66ff\u4ee3\u3002 \u53ef\u4ee5\u5411 transfrom \u4f20\u9012\u533f\u540d\u51fd\u6570 lambda x: x.mean() \uff1a result = g.transform(lambda x: x.mean()) print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 \u5bf9\u4e8e\u5185\u5efa\u7684\u805a\u5408\u51fd\u6570\uff0c\u53ef\u4ee5\u50cf GroupBy \u7684 agg \u65b9\u6cd5\u4e00\u6837\u4f20\u9012\u4e00\u4e2a\u5b57\u7b26\u4e32\u522b\u540d\uff1a result = g.transform('mean') print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 \u4e0e apply \u7c7b\u4f3c\uff0c transform \u53ef\u4ee5\u4e0e\u8fd4\u56de Series \u7684\u51fd\u6570\u4e00\u8d77\u4f7f\u7528\uff0c\u4f46\u7ed3\u679c\u5fc5\u987b\u548c\u8f93\u5165\u6709\u76f8\u540c\u7684\u5927\u5c0f\u3002 \u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528 lambda \u51fd\u6570\u7ed9\u6bcf\u4e2a\u7ec4\u4e58\u4ee52\uff1a result = g.transform(lambda x: x * 2) print(result) # 0 0 # 1 2 # 2 4 # 3 6 # 4 8 # 5 10 # 6 12 # 7 14 # 8 16 # 9 18 # 10 20 # 11 22 # Name: value, dtype: int64 \u66f4\u590d\u6742\u4e00\u4e9b\uff0c\u53ef\u4ee5\u6309\u7167\u6bcf\u4e2a\u7ec4\u7684\u964d\u5e8f\u8ba1\u7b97\u6392\u540d\uff1a result = g.transform(lambda x: x.rank(ascending=False)) print(result) # 0 4.0 # 1 4.0 # 2 4.0 # 3 3.0 # 4 3.0 # 5 3.0 # 6 2.0 # 7 2.0 # 8 2.0 # 9 1.0 # 10 1.0 # 11 1.0 # Name: value, dtype: float64 \u8003\u8651\u4e00\u4e2a\u7531\u7b80\u5355\u805a\u5408\u6784\u6210\u7684\u5206\u7ec4\u8f6c\u6362\u51fd\u6570\uff1a def normalize(x): return (x - x.mean()) / x.std() \u4f7f\u7528 transform \u6216 apply \u53ef\u4ee5\u83b7\u5f97\u7b49\u4ef7\u7684\u7ed3\u679c\uff1a result = g.transform(normalize) print(result) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64 result = g.apply(normalize) print(result) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64 \u5185\u5efa\u7684\u805a\u5408\u51fd\u6570\u5982 mean \u6216 sum \u901a\u5e38\u4f1a\u6bd4 apply \u51fd\u6570\u66f4\u5feb\u3002 \u8fd9\u4e9b\u51fd\u6570\u5728\u4e0e transform \u4e00\u8d77\u4f7f\u7528\u65f6\u4e5f\u4f1a\u5b58\u5728\u4e00\u4e2a\"\u5feb\u901f\u901a\u8fc7\"\u3002 \u8fd9\u5141\u8bb8\u6211\u4eec\u6267\u884c\u4e00\u4e2a\u6240\u8c13\u7684\u5c55\u5f00\u5206\u7ec4\u64cd\u4f5c\u3002 \u4e00\u4e2a\u5c55\u5f00\u5206\u7ec4\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5305\u542b\u591a\u4e2a\u5206\u7ec4\u805a\u5408\uff0c\u77e2\u91cf\u5316\u64cd\u4f5c\u7684\u6574\u4f53\u4f18\u52bf\u5f80\u5f80\u8d85\u8fc7\u4e86\u8fd9\u4e00\u70b9\u3002 result = g.transform('mean') print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 normalized = (df['value'] - g.transform('mean')) / g.transform('std') print(normalized) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64 \u5206\u7ec4\u7684\u65f6\u95f4\u91cd\u65b0\u91c7\u6837 \u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c resample \u65b9\u6cd5\u5728\u8bed\u4e49\u4e0a\u662f\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5206\u6bb5\u7684\u5206\u7ec4\u64cd\u4f5c\u3002 N = 15 times = pd.date_range('2020-5-20 00:00', freq='1min', periods=N) df = pd.DataFrame( { 'time': times, 'value': np.arange(N) } ) print(df) # time value # 0 2020-05-20 00:00:00 0 # 1 2020-05-20 00:01:00 1 # 2 2020-05-20 00:02:00 2 # 3 2020-05-20 00:03:00 3 # 4 2020-05-20 00:04:00 4 # 5 2020-05-20 00:05:00 5 # 6 2020-05-20 00:06:00 6 # 7 2020-05-20 00:07:00 7 # 8 2020-05-20 00:08:00 8 # 9 2020-05-20 00:09:00 9 # 10 2020-05-20 00:10:00 10 # 11 2020-05-20 00:11:00 11 # 12 2020-05-20 00:12:00 12 # 13 2020-05-20 00:13:00 13 # 14 2020-05-20 00:14:00 14 \u8fd9\u91cc\uff0c\u53ef\u4ee5\u6309 time \u8fdb\u884c\u7d22\u5f15\uff0c\u7136\u540e\u91cd\u65b0\u91c7\u6837\uff1a result = df.set_index('time').resample('5min').count() print(result) # value # time # 2020-05-20 00:00:00 5 # 2020-05-20 00:05:00 5 # 2020-05-20 00:10:00 5 \u5047\u8bbeDataFrame\u5305\u542b\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u6309\u4e00\u4e2a\u9644\u52a0\u7684\u5206\u7ec4\u952e\u5217\u8fdb\u884c\u4e86\u6807\u8bb0\uff1a df2 = pd.DataFrame( { 'time': times.repeat(3), 'key': np.tile(['a', 'b', 'c'], N), 'value': np.arange((N * 3)) } ) print(df2) # time key value # 0 2020-05-20 00:00:00 a 0 # 1 2020-05-20 00:00:00 b 1 # 2 2020-05-20 00:00:00 c 2 # 3 2020-05-20 00:01:00 a 3 # ...... # 43 2020-05-20 00:14:00 b 43 # 44 2020-05-20 00:14:00 c 44 \u4f7f\u7528 pandas.TimeGrouper \u5bf9\u8c61\uff0c\u6bcf\u4e2a key \u7684\u503c\u8fdb\u884c\u76f8\u540c\u7684\u91cd\u65b0\u91c7\u6837\uff1a pd.TimeGrouper() was formally deprecated in pandas v0.21.0 in favor of pd.Grouper(). \u65b9\u6cd5\u94fe\u6280\u672f import numpy as np import pandas as pd from numpy import nan as NA df = pd.DataFrame( [[1., 2., 3.], [1., NA, NA], [NA, NA, NA], [NA, 2., 3.]] ) v = ['a', 'b', 'c', 'd'] print(df) # 0 1 2 # 0 1.0 2.0 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 2.0 3.0 \u975e\u51fd\u6570\u8d4b\u503c\u7684\u65b9\u5f0f\u3002 df2 = df.copy() df2['k'] = v print(df2) # 0 1 2 k # 0 1.0 2.0 3.0 a # 1 1.0 NaN NaN b # 2 NaN NaN NaN c # 3 NaN 2.0 3.0 d \u51fd\u6570\u8d4b\u503c\u7684\u65b9\u5f0f\u3002 DataFrame.assign \u65b9\u6cd5\u662f\u5bf9 df[k] = v \u7684\u8d4b\u503c\u65b9\u5f0f\u7684\u4e00\u79cd\u529f\u80fd\u66ff\u4ee3\u3002\u5b83\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u6309\u6307\u5b9a\u4fee\u6539\u7684\u65b0\u7684DataFrame\uff0c\u800c\u4e0d\u662f\u5728\u539f\u5bf9\u8c61\u4e0a\u8fdb\u884c\u4fee\u6539\u3002 df2 = df.assign(k=v) print(df2) # 0 1 2 k # 0 1.0 2.0 3.0 a # 1 1.0 NaN NaN b # 2 NaN NaN NaN c # 3 NaN 2.0 3.0 d pipe\u65b9\u6cd5 \u5bf9\u6570\u636e\u8fde\u7eed\u64cd\u4f5c\u5f62\u6210\u65b9\u6cd5\u94fe\uff08\u591a\u4e2a\u65b9\u6cd5\u8fde\u7eed\u8c03\u7528\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09\u3002 Series.pipe \uff0c DataFrame.pipe \u610f\u5473\u7740 x.pipe(f, *args, **kwargs) \u548c f(x, *args, **kwargs) \u6548\u679c\u76f8\u540c\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u8be5\u51fd\u6570\u5e94\u7528\u4e8e\u6574\u4e2a\u6570\u636e\u3002 \u4ee5 DataFrame \u4e3a\u4f8b\uff1a \u8bed\u6cd5: DataFrame.pipe(func, *args, **kwargs) \u53c2\u6570\uff1a func\uff1a\u51fd\u6570\uff0c\u5e94\u7528\u4e8e\u7cfb\u5217/\u6570\u636e\u5e27\u7684\u51fd\u6570\u3002args \u548c kwargs \u88ab\u4f20\u9012\u5230 func\u3002\u6216\u8005\u662f\u4e00\u4e2a\uff08callable\uff0cdata_keyword\uff09\u5143\u7ec4\uff0c\u5176\u4e2d data_keyword \u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u8868\u793a\u9700\u8981Series/DataFrame \u7684 callable \u5173\u952e\u5b57 args\uff1a\u53ef\u8fed\u4ee3\u5bf9\u8c61, \u53ef\u9009\uff0c\u51fd\u6570\u7684\u4f4d\u7f6e\u53c2\u6570 kwargs\uff1amapping, \u53ef\u9009\uff0c\u4f20\u5165 func \u7684\u5173\u952e\u5b57\u53c2\u6570\u5b57\u5178 \u8fd4\u56de\uff1aobject\uff1afunc \u5904\u7406\u540e\u7684\u4efb\u610f\u6570\u636e\u7c7b\u578b DataFrame\u793a\u4f8b\uff1a df = pd.DataFrame( [[1., 2., 3.], [1., NA, NA], [NA, NA, NA], [NA, 2., 3.]] ) \u88ab\u4f20\u9012\u7684\u7c7b\u578b\u662f\u8c03\u7528\u7684\u5b9e\u4f8b\u3002 df.pipe(type) # \u4f20\u9012\u7684\u662ftype\u5b9e\u4f8b # <class 'pandas.core.frame.DataFrame'> df.pipe(len) # \u4f20\u9012\u7684\u662flen\u5b9e\u4f8b # 4 def fun(df): return df * 2 fun(df) # 0 1 2 # 0 2.0 4.0 6.0 # 1 2.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 4.0 6.0 df.pipe(fun) # \u4f20\u9012\u7684\u662ffun\u51fd\u6570 # 0 1 2 # 0 2.0 4.0 6.0 # 1 2.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 4.0 6.0 def fun2(x, df): # \u6570\u636e\u662f\u7b2c\u4e8c\u4e2a\u53c2\u6570 return df * 3 df.pipe((fun2, 'df'), 2) # \u6ce8\u610f\u4f20\u503c # 0 1 2 # 0 3.0 6.0 9.0 # 1 3.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.0 9.0 Series \u793a\u4f8b\uff1a s = pd.Series([1, 2, 3, 4, 5]) s.pipe(type) # <class 'pandas.core.series.Series'> s.pipe(len) # 5 def fun3(x, ss): return ss * 3 s.pipe((fun3, 'ss'), 2) # 0 3 # 1 6 # 2 9 # 3 12 # 4 15 # dtype: int64 GroupBy \u793a\u4f8b\uff1a df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]}) print(df) # A B # 0 a 1 # 1 b 2 # 2 a 3 # 3 b 4 \u6c42\u6bcf\u7ec4\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 df.groupby('A').pipe(lambda x: x.max() - x.min()) # B # A # a 2 # b 2 def mean1(groupby): return groupby.mean() df.groupby(['A']).pipe(mean1) # B # A # a 2.0 # b 3.0","title":"\u9ad8\u9636pandas"},{"location":"python/DataAnalysis/ch09/#pandas","text":"","title":"\u9ad8\u9636pandas"},{"location":"python/DataAnalysis/ch09/#_1","text":"import numpy as np import pandas as pd","title":"\u5206\u7c7b\u6570\u636e"},{"location":"python/DataAnalysis/ch09/#_2","text":"\u4e00\u4e2a\u5217\u7ecf\u5e38\u4f1a\u5305\u542b\u91cd\u590d\u503c\uff0c\u8fd9\u4e9b\u91cd\u590d\u503c\u662f\u4e00\u4e2a\u5c0f\u578b\u7684\u4e0d\u540c\u503c\u7684\u96c6\u5408\u3002 unique \u548c value_counts \u8fd9\u6837\u7684\u51fd\u6570\u5141\u8bb8\u6211\u4eec\u4ece\u4e00\u4e2a\u6570\u7ec4\u4e2d\u63d0\u53d6\u4e0d\u540c\u503c\u5e76\u5206\u522b\u8ba1\u7b97\u8fd9\u4e9b\u4e0d\u540c\u503c\u7684\u9891\u7387\uff1a values = pd.Series(['apple', 'orange', 'apple', 'apple'] * 2) print(values) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # dtype: object print(pd.unique(values)) # ['apple' 'orange'] print(pd.value_counts(values)) # apple 6 # orange 2 # dtype: int64 \u5728\u6570\u636e\u5165\u5e93\u7684\u64cd\u4f5c\u4e2d\uff0c\u4f7f\u7528\u7ef4\u5ea6\u8868\u662f\u4e00\u79cd\u6700\u4f73\u5b9e\u8df5\uff0c\u7ef4\u5ea6\u8868\u5305\u542b\u4e86\u4e0d\u540c\u503c\uff0c\u5e76\u5c06\u4e3b\u8981\u89c2\u6d4b\u503c\u5b58\u50a8\u4e3a\u5f15\u7528\u7ef4\u5ea6\u8868\u7684\u6574\u6570\u952e\uff1a values = pd.Series([0, 1, 0, 0] * 2) dim = pd.Series(['apple', 'oragne']) \u4f7f\u7528 take \u65b9\u6cd5\u6765\u6062\u590d\u539f\u6765\u7684\u5b57\u7b26\u4e32Series\u3002\uff080\u5bf9\u5e94\u5230apple)\u3002 \u8fd9\u79cd\u6309\u7167\u6574\u6570\u5c55\u73b0\u7684\u65b9\u5f0f\u88ab\u79f0\u4e3a\u5206\u7c7b\u6216\u5b57\u5178\u7f16\u7801\u5c55\u73b0\u3002\u4e0d\u540c\u503c\u7684\u6570\u7ec4\u53ef\u4ee5\u88ab\u79f0\u4e3a\u6570\u636e\u7684\u7c7b\u522b\u3001\u5b57\u5178\u6216\u5c42\u7ea7\u3002 print(dim.take(values)) # 0 apple # 1 oragne # 0 apple # 0 apple # 0 apple # 1 oragne # 0 apple # 0 apple # dtype: object \u5728\u505a\u6570\u636e\u5206\u6790\u65f6\uff0c\u5206\u7c7b\u5c55\u793a\u4f1a\u4ea7\u751f\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u53ef\u4ee5\u5728\u7c7b\u522b\u4e0a\u8fdb\u884c\u8f6c\u6362\u540c\u65f6\u4e0d\u6539\u53d8\u4ee3\u7801\u3002 \u4ee5\u4e0b\u662f\u4e00\u4e9b\u76f8\u5bf9\u4f4e\u5f00\u9500\u7684\u8f6c\u6362\u793a\u4f8b\uff1a \u91cd\u547d\u540d\u7c7b\u522b \u5728\u4e0d\u6539\u53d8\u5df2\u6709\u7684\u7c7b\u522b\u987a\u5e8f\u7684\u60c5\u51b5\u4e0b\u6dfb\u52a0\u4e00\u4e2a\u65b0\u7684\u7c7b\u522b","title":"\u80cc\u666f\u548c\u76ee\u6807"},{"location":"python/DataAnalysis/ch09/#pandascategorical","text":"pandas\u62e5\u6709\u7279\u6b8a\u7684 Categorical \u7c7b\u578b\uff0c\u7528\u4e8e\u627f\u8f7d\u57fa\u4e8e\u6574\u6570\u7684\u7c7b\u522b\u5c55\u793a\u6216\u7f16\u7801\u7684\u6570\u636e\u3002 fruits = ['apple', 'orange', 'apple', 'apple'] * 2 N = len(fruits) df = pd.DataFrame( { 'fruit': fruits, 'basket_id': np.arange(N), 'count': np.random.randint(3, 15, size=N), 'weight': np.random.uniform(0, 4, size=N) }, columns=['basket_id', 'fruit', 'count', 'weight'] ) print(df) # basket_id fruit count weight # 0 0 apple 8 1.288867 # 1 1 orange 4 3.414430 # 2 2 apple 7 3.222160 # 3 3 apple 14 2.724804 # 4 4 apple 8 3.548828 # 5 5 orange 10 0.918739 # 6 6 apple 4 0.784816 # 7 7 apple 10 3.140607 df['fruit'] \u662f\u4e00\u4e2aPython\u5b57\u7b26\u4e32\u5bf9\u8c61\u7ec4\u6210\u7684\u6570\u7ec4\u3002\u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u51fd\u6570\u5c06\u5b83\u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a fruit_cat = df['fruit'].astype('category') print(fruit_cat) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: category # Categories (2, object): ['apple', 'orange'] fruit_cat \u7684\u503c\u5e76\u4e0d\u662fNumPy\u6570\u7ec4\uff0c\u800c\u662f pandas.Categorical \u7684\u5b9e\u4f8b\uff1a c = fruit_cat.values print(type(c)) # <class 'pandas.core.arrays.categorical.Categorical'> print(c) # ['apple', 'orange', 'apple', 'apple', 'apple', 'orange', 'apple', 'apple'] # Categories (2, object): ['apple', 'orange'] Categorical \u5bf9\u8c61\u62e5\u6709 categories \u548c codes \u5c5e\u6027\uff1a print(c.categories) # Index(['apple', 'orange'], dtype='object') print(c.codes) # [0 1 0 0 0 1 0 0] \u901a\u8fc7\u5206\u914d\u5df2\u8f6c\u6362\u7684\u7ed3\u679c\u5c06DataFrame\u7684\u4e00\u5217\u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a print(df['fruit']) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: object df['fruit'] = df['fruit'].astype('category') print(df['fruit']) # 0 apple # 1 orange # 2 apple # 3 apple # 4 apple # 5 orange # 6 apple # 7 apple # Name: fruit, dtype: category # Categories (2, object): ['apple', 'orange'] \u4e5f\u53ef\u4ee5\u4ece\u5176\u4ed6Python\u5e8f\u5217\u7c7b\u578b\u76f4\u63a5\u751f\u6210 pandas.Categorical \uff1a my_categories = pd.Categorical(['foo', 'bar', 'baz', 'foo', 'bar']) print(my_categories) # ['foo', 'bar', 'baz', 'foo', 'bar'] # Categories (3, object): ['bar', 'baz', 'foo'] \u4e5f\u53ef\u4ee5\u4f7f\u7528 from_codes \u6784\u9020\u51fd\u6570\u6765\u8f6c\u6362\u5176\u4ed6\u6570\u636e\u6e90\u7684\u5206\u7c7b\u7f16\u7801\u6570\u636e\uff1a categories = ['foo', 'bar', 'baz'] codes = [0, 1, 2, 0, 0, 1] my_cats_2 = pd.Categorical.from_codes(codes, categories) print(my_cats_2) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo', 'bar', 'baz'] \u8fd9\u4e2a\u672a\u6392\u5e8f\u7684\u5206\u7c7b\u5b9e\u4f8b\u53ef\u4ee5\u4f7f\u7528 as_ordered \u8fdb\u884c\u6392\u5e8f\uff1a print(my_cats_2.as_ordered()) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo' < 'bar' < 'baz'] \u9664\u975e\u663e\u5f0f\u5730\u6307\u5b9a\uff0c\u5206\u7c7b\u8f6c\u6362\u662f\u4e0d\u4f1a\u6307\u5b9a\u7c7b\u522b\u7684\u987a\u5e8f\u7684\u3002\u56e0\u6b64 categories \u6570\u7ec4\u53ef\u80fd\u4f1a\u4e0e\u8f93\u5165\u6570\u636e\u7684\u987a\u5e8f\u4e0d\u540c\u3002 \u5f53\u4f7f\u7528 from_codes \u6216\u5176\u4ed6\u4efb\u610f\u6784\u9020\u51fd\u6570\u65f6\uff0c\u53ef\u4ee5\u4e3a\u7c7b\u522b\u6307\u5b9a\u4e00\u4e2a\u6709\u610f\u4e49\u7684\u987a\u5e8f\uff1a\u8f93\u51fa\u7684 [foo<bar<baz] \u8868\u660e foo \u7684\u987a\u5e8f\u5728 bar \u4e4b\u524d\uff0c\u4ee5\u6b64\u7c7b\u63a8\u3002 my_categories_ordered = pd.Categorical.from_codes(codes=codes, categories=categories, ordered=True) print(my_categories_ordered) # ['foo', 'bar', 'baz', 'foo', 'foo', 'bar'] # Categories (3, object): ['foo' < 'bar' < 'baz'] \u5206\u7c7b\u6570\u636e\u53ef\u4ee5\u4e0d\u662f\u5b57\u7b26\u4e32\uff0c\u5c3d\u7ba1\u4e3e\u7684\u4f8b\u5b50\u90fd\u662f\u5b57\u7b26\u4e32\u4f8b\u5b50\u3002\u4e00\u4e2a\u5206\u7c7b\u6570\u7ec4\u53ef\u4ee5\u5305\u542b\u4efb\u4e00\u4e0d\u53ef\u53d8\u7684\u503c\u7c7b\u578b\u3002","title":"pandas\u4e2d\u7684Categorical\u7c7b\u578b"},{"location":"python/DataAnalysis/ch09/#categorical","text":"\u5728pandas\u4e2d\u4f7f\u7528 Categorical \u4e0e\u975e\u7f16\u7801\u7248\u672c\u76f8\u6bd4\uff08\u4f8b\u5982\u5b57\u7b26\u4e32\u6570\u7ec4\uff09\u6574\u4f53\u4e0a\u662f\u4e00\u81f4\u7684\u3002 pandas\u4e2d\u7684\u67d0\u4e9b\u90e8\u5206\uff0c\u6bd4\u5982 groupby \u51fd\u6570\uff0c\u5728\u4e0e Categorical \u5bf9\u8c61\u534f\u540c\u5de5\u4f5c\u65f6\u6027\u80fd\u66f4\u597d\u3002 \u8fd8\u6709\u4e00\u4e9b\u51fd\u6570\u53ef\u4ee5\u5229\u7528ordered\u6807\u8bc6\u3002 \u4e0b\u9762\u8003\u8651\u4e00\u4e9b\u968f\u673a\u6570\u5b57\u6570\u636e\uff0c\u5e76\u4f7f\u7528 pandas.qcut \u5206\u7bb1\u51fd\u6570\u3002\u7ed3\u679c\u4f1a\u8fd4\u56de pandas.Categorical \uff1b \u5728\u524d\u9762\u7ae0\u8282\u4f7f\u7528\u8fc7 pandas.cut \uff0c\u4f46\u5f53\u65f6\u6ca1\u6709\u5206\u6790\u5206\u7c7b\u662f\u5982\u4f55\u5de5\u4f5c\u7684\u7ec6\u8282\u3002 np.random.seed(12345) draws = np.random.randn(1000) print(draws[:5]) # [-0.20470766 0.47894334 -0.51943872 -0.5557303 1.96578057] \u8ba1\u7b97\u4e0a\u9762\u6570\u636e\u7684\u56db\u5206\u4f4d\u5206\u7bb1\uff0c\u5e76\u63d0\u53d6\u4e00\u4e9b\u7edf\u8ba1\u503c\uff1a bins = pd.qcut(draws, 4) print(bins) # [(-0.684, -0.0101], (-0.0101, 0.63], (-0.684, -0.0101], (-0.684, -0.0101], (0.63, 3.928], ..., (-0.0101, 0.63], (-0.684, -0.0101], (-2.9499999999999997, -0.684], (-0.0101, 0.63], (0.63, 3.928]] # Length: 1000 # Categories (4, interval[float64, right]): [(-2.9499999999999997, -0.684] < (-0.684, -0.0101] < (-0.0101, 0.63] < (0.63, 3.928]] \u901a\u8fc7\u5728 qcut \u51fd\u6570\u4e2d\u4f7f\u7528 labels \u53c2\u6570\u6765\u56db\u5206\u4f4d\u6570\u540d\u79f0\uff1a bins = pd.qcut(draws, 4, labels=['Q1', 'Q2', 'Q3', 'Q4']) print(bins) # ['Q2', 'Q3', 'Q2', 'Q2', 'Q4', ..., 'Q3', 'Q2', 'Q1', 'Q3', 'Q4'] # Length: 1000 # Categories (4, object): ['Q1' < 'Q2' < 'Q3' < 'Q4'] print(bins.codes[:10]) # [1 2 1 1 3 3 2 2 3 3] \u88ab\u6807\u8bb0\u7684 bins \u5206\u7c7b\u6570\u636e\u5e76\u4e0d\u5305\u542b\u6570\u636e\u4e2d\u7bb1\u4f53\u8fb9\u754c\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u56e0\u6b64\u53ef\u4ee5\u4f7f\u7528 groupby \u6765\u63d0\u53d6\u4e00\u4e9b\u6c47\u603b\u7edf\u8ba1\u503c\uff1a bins = pd.Series(bins, name='quartile') result = (pd.Series(draws).groupby(bins).agg(['count', 'min', 'max']).reset_index()) print(result) # quartile count min max # 0 Q1 250 -2.949343 -0.685484 # 1 Q2 250 -0.683066 -0.010115 # 2 Q3 250 -0.010032 0.628894 # 3 Q4 250 0.634238 3.927528 \u7ed3\u679c\u4e2d\u7684 quartile \u5217\u4fdd\u7559\u4e86 bins \u4e2d\u539f\u59cb\u7684\u5206\u7c7b\u4fe1\u606f\uff0c\u5305\u62ec\u987a\u5e8f\uff1a print(result['quartile']) # 0 Q1 # 1 Q2 # 2 Q3 # 3 Q4 # Name: quartile, dtype: category # Categories (4, object): ['Q1' < 'Q2' < 'Q3' < 'Q4']","title":"\u4f7f\u7528Categorical\u5bf9\u8c61\u8fdb\u884c\u8ba1\u7b97"},{"location":"python/DataAnalysis/ch09/#_3","text":"\u5982\u679c\u5bf9\u7279\u5b9a\u7684\u6570\u636e\u96c6\u4e0a\u505a\u4e86\u5927\u91cf\u7684\u5206\u6790\uff0c\u5c06\u6570\u636e\u8f6c\u6362\u4e3a\u5206\u7c7b\u6570\u636e\u53ef\u4ee5\u4ea7\u751f\u5927\u5e45\u7684\u6027\u80fd\u63d0\u5347\u3002DateFrame\u4e2d\u4e00\u5217\u7684\u5206\u7c7b\u7248\u672c\u901a\u5e38\u4e5f\u4f1a\u660e\u663e\u4f7f\u7528\u66f4\u5c11\u5185\u5b58\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u542b\u6709\u4e00\u5343\u4e07\u5143\u7d20\u7684Series\u4ee5\u53ca\u5c11\u91cf\u7684\u4e0d\u540c\u7c7b\u522b\uff1a N = 10000000 draws = pd.Series(np.random.randn(N)) labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4)) \u73b0\u5728\u5c06 labels \u8f6c\u6362\u4e3a Categorical \u5bf9\u8c61\uff1a categories = labels.astype('category') print(labels.memory_usage()) # labels\u6bd4categories\u4f7f\u7528\u4e86\u660e\u663e\u66f4\u591a\u7684\u5185\u5b58 # 80000128 print(categories.memory_usage()) # 10000332","title":"\u4f7f\u7528\u5206\u7c7b\u83b7\u5f97\u66f4\u9ad8\u6027\u80fd"},{"location":"python/DataAnalysis/ch09/#_4","text":"Series\u5305\u542b\u7684\u5206\u7c7b\u6570\u636e\u62e5\u6709\u4e00\u4e9b\u7279\u6b8a\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7c7b\u4f3c\u4e8eSeries.str\u7684\u7279\u6b8a\u5b57\u7b26\u4e32\u65b9\u6cd5\u3002\u8fd9\u4e9b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5feb\u6377\u8bbf\u95ee\u7c7b\u522b\u548c\u4ee3\u7801\u7684\u65b9\u5f0f\u3002 s = pd.Series(['a', 'b', 'c', 'd'] * 2) cat_s = s.astype('category') print(cat_s) # 0 a # 1 b # 2 c # 3 d # 4 a # 5 b # 6 c # 7 d # dtype: category # Categories (4, object): ['a', 'b', 'c', 'd'] \u7279\u6b8a\u5c5e\u6027 cat \u63d0\u4f9b\u4e86\u5bf9\u5206\u7c7b\u65b9\u6cd5\u7684\u8bbf\u95ee\uff1a print(cat_s.cat.codes) # 0 0 # 1 1 # 2 2 # 3 3 # 4 0 # 5 1 # 6 2 # 7 3 # dtype: int8 print(cat_s.cat.categories) # Index(['a', 'b', 'c', 'd'], dtype='object') \u5047\u8bbe\u6570\u636e\u7684\u5b9e\u9645\u7c7b\u522b\u96c6\u5408\u8d85\u51fa\u4e86\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u56db\u4e2a\u503c\uff0c\u53ef\u4ee5\u4f7f\u7528 set_categories \u65b9\u6cd5\u6765\u6539\u53d8\u7c7b\u522b\uff1a actual_categories = ['a', 'b', 'c', 'd', 'e'] cat_s2 = cat_s.cat.set_categories(actual_categories) print(cat_s2) # 0 a # 1 b # 2 c # 3 d # 4 a # 5 b # 6 c # 7 d # dtype: category # Categories (5, object): ['a', 'b', 'c', 'd', 'e'] \u867d\u7136\u770b\u8d77\u6765\u6570\u636e\u5e76\u672a\u6539\u53d8\uff0c\u4f46\u65b0\u7c7b\u522b\u5c06\u53cd\u6620\u5728\u4f7f\u7528\u5b83\u4eec\u7684\u64cd\u4f5c\u4e2d\u3002\u4f8b\u5982\uff0c value_counts \u5c06\u9075\u5faa\u65b0\u7684\u7c7b\u522b\uff08\u5982\u679c\u5b58\u5728\uff09\uff1a print(cat_s.value_counts()) # a 2 # b 2 # c 2 # d 2 # dtype: int64 print(cat_s2.value_counts()) # a 2 # b 2 # c 2 # d 2 # e 0 # dtype: int64 \u5927\u578b\u6570\u636e\u96c6\u4e2d\uff0c\u5206\u7c7b\u6570\u636e\u7ecf\u5e38\u88ab\u7528\u4e8e\u8282\u7701\u5185\u5b58\u548c\u66f4\u9ad8\u6027\u80fd\u7684\u4fbf\u6377\u5de5\u5177\u3002 \u5728\u8fc7\u6ee4\u4e86\u4e00\u4e2a\u5927\u578bDataFrame\u6216Series\u4e4b\u540e\uff0c\u5f88\u591a\u7c7b\u522b\u5c06\u4e0d\u4f1a\u51fa\u73b0\u5728\u6570\u636e\u4e2d\u3002 \u53ef\u4ee5\u4f7f\u7528 remove_unused_categories \u65b9\u6cd5\u6765\u53bb\u9664\u672a\u89c2\u5bdf\u5230\u7684\u7c7b\u522b\uff1a cat_s3 = cat_s[cat_s.isin(['a', 'b'])] print(cat_s3) # 0 a # 1 b # 4 a # 5 b # dtype: category # Categories (4, object): ['a', 'b', 'c', 'd'] print(cat_s3.cat.remove_unused_categories()) # 0 a # 1 b # 4 a # 5 b # dtype: category # Categories (2, object): ['a', 'b']","title":"\u5206\u7c7b\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch09/#_5","text":"\u5f53\u4f7f\u7528\u7edf\u8ba1\u6570\u636e\u6216\u673a\u5668\u5b66\u4e60\u5de5\u5177\u65f6\uff0c\u901a\u5e38\u4f1a\u5c06\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u865a\u62df\u53d8\u91cf\uff0c\u4e5f\u79f0\u4e3aone-hot\u7f16\u7801\u3002 \u8fd9\u4f1a\u4ea7\u751f\u4e00\u4e2aDataFrame\uff0c\u6bcf\u4e2a\u4e0d\u540c\u7684\u7c7b\u522b\u90fd\u662f\u5b83\u7684\u4e00\u5217\u3002\u8fd9\u4e9b\u5217\u5305\u542b\u4e00\u4e2a\u7279\u5b9a\u7c7b\u522b\u7684\u51fa\u73b0\u6b21\u6570\uff0c\u5426\u5219\u4e3a0\u3002 cat_s = pd.Series(['a', 'b', 'c', 'd'] * 2, dtype='category') \u4f7f\u7528 pandas.get_dummies \u51fd\u6570\u5c06\u4e00\u7ef4\u7684\u5206\u7c7b\u6570\u636e\u8f6c\u6362\u4e3a\u4e00\u4e2a\u5305\u542b\u865a\u62df\u53d8\u91cf\u7684DataFrame\uff1a print(pd.get_dummies(cat_s)) # a b c d # 0 1 0 0 0 # 1 0 1 0 0 # 2 0 0 1 0 # 3 0 0 0 1 # 4 1 0 0 0 # 5 0 1 0 0 # 6 0 0 1 0 # 7 0 0 0 1","title":"\u521b\u5efa\u7528\u4e8e\u5efa\u6a21\u7684\u865a\u62df\u53d8\u91cf"},{"location":"python/DataAnalysis/ch09/#groupby","text":"import numpy as np import pandas as pd","title":"\u9ad8\u9636GroupBy\u5e94\u7528"},{"location":"python/DataAnalysis/ch09/#groupby_1","text":"\u5728\u5206\u7ec4\u64cd\u4f5c\u4e2d\u53ef\u4ee5\u4f7f\u7528apply\u65b9\u6cd5\u5b9e\u73b0\u8f6c\u6362\u64cd\u4f5c\u3002\u8fd8\u6709\u53e6\u4e00\u4e2a\u5185\u5efa\u65b9\u6cd5transform\uff0c\u4e0eapply\u65b9\u6cd5\u7c7b\u4f3c\u4f46\u662f\u53ef\u4ee5\u5bf9\u4f7f\u7528\u7684\u51fd\u6570\u52a0\u4e0a\u66f4\u591a\u7684\u9650\u5236\uff1a transform\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u6807\u91cf\u503c\uff0c\u5e76\u5e7f\u64ad\u5230\u5404\u5206\u7ec4\u7684\u5c3a\u5bf8\u6570\u636e\u4e2d\u3002 transform\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u4e0e\u8f93\u5165\u5206\u7ec4\u5c3a\u5bf8\u76f8\u540c\u7684\u5bf9\u8c61\u3002 transform\u4e0d\u53ef\u6539\u53d8\u5b83\u7684\u8f93\u5165\u3002 df = pd.DataFrame( { 'key': ['a', 'b', 'c'] * 4, 'value': np.arange(12) } ) print(df) # key value # 0 a 0 # 1 b 1 # 2 c 2 # 3 a 3 # 4 b 4 # 5 c 5 # 6 a 6 # 7 b 7 # 8 c 8 # 9 a 9 # 10 b 10 # 11 c 11 \u6309 key \u5206\u7ec4\u7684\u5747\u503c\uff1a g = df.groupby('key').value print(g.mean()) # key # a 4.5 # b 5.5 # c 6.5 # Name: value, dtype: float64 \u5047\u8bbe\u8981\u4ea7\u751f\u4e00\u4e2aSeries\uff0c\u5b83\u7684\u5c3a\u5bf8\u548c df['value'] \u4e00\u6837\uff0c\u4f46\u503c\u90fd\u88ab\u6309 key \u5206\u7ec4\u7684\u5747\u503c\u66ff\u4ee3\u3002 \u53ef\u4ee5\u5411 transfrom \u4f20\u9012\u533f\u540d\u51fd\u6570 lambda x: x.mean() \uff1a result = g.transform(lambda x: x.mean()) print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 \u5bf9\u4e8e\u5185\u5efa\u7684\u805a\u5408\u51fd\u6570\uff0c\u53ef\u4ee5\u50cf GroupBy \u7684 agg \u65b9\u6cd5\u4e00\u6837\u4f20\u9012\u4e00\u4e2a\u5b57\u7b26\u4e32\u522b\u540d\uff1a result = g.transform('mean') print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 \u4e0e apply \u7c7b\u4f3c\uff0c transform \u53ef\u4ee5\u4e0e\u8fd4\u56de Series \u7684\u51fd\u6570\u4e00\u8d77\u4f7f\u7528\uff0c\u4f46\u7ed3\u679c\u5fc5\u987b\u548c\u8f93\u5165\u6709\u76f8\u540c\u7684\u5927\u5c0f\u3002 \u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528 lambda \u51fd\u6570\u7ed9\u6bcf\u4e2a\u7ec4\u4e58\u4ee52\uff1a result = g.transform(lambda x: x * 2) print(result) # 0 0 # 1 2 # 2 4 # 3 6 # 4 8 # 5 10 # 6 12 # 7 14 # 8 16 # 9 18 # 10 20 # 11 22 # Name: value, dtype: int64 \u66f4\u590d\u6742\u4e00\u4e9b\uff0c\u53ef\u4ee5\u6309\u7167\u6bcf\u4e2a\u7ec4\u7684\u964d\u5e8f\u8ba1\u7b97\u6392\u540d\uff1a result = g.transform(lambda x: x.rank(ascending=False)) print(result) # 0 4.0 # 1 4.0 # 2 4.0 # 3 3.0 # 4 3.0 # 5 3.0 # 6 2.0 # 7 2.0 # 8 2.0 # 9 1.0 # 10 1.0 # 11 1.0 # Name: value, dtype: float64 \u8003\u8651\u4e00\u4e2a\u7531\u7b80\u5355\u805a\u5408\u6784\u6210\u7684\u5206\u7ec4\u8f6c\u6362\u51fd\u6570\uff1a def normalize(x): return (x - x.mean()) / x.std() \u4f7f\u7528 transform \u6216 apply \u53ef\u4ee5\u83b7\u5f97\u7b49\u4ef7\u7684\u7ed3\u679c\uff1a result = g.transform(normalize) print(result) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64 result = g.apply(normalize) print(result) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64 \u5185\u5efa\u7684\u805a\u5408\u51fd\u6570\u5982 mean \u6216 sum \u901a\u5e38\u4f1a\u6bd4 apply \u51fd\u6570\u66f4\u5feb\u3002 \u8fd9\u4e9b\u51fd\u6570\u5728\u4e0e transform \u4e00\u8d77\u4f7f\u7528\u65f6\u4e5f\u4f1a\u5b58\u5728\u4e00\u4e2a\"\u5feb\u901f\u901a\u8fc7\"\u3002 \u8fd9\u5141\u8bb8\u6211\u4eec\u6267\u884c\u4e00\u4e2a\u6240\u8c13\u7684\u5c55\u5f00\u5206\u7ec4\u64cd\u4f5c\u3002 \u4e00\u4e2a\u5c55\u5f00\u5206\u7ec4\u64cd\u4f5c\u53ef\u80fd\u4f1a\u5305\u542b\u591a\u4e2a\u5206\u7ec4\u805a\u5408\uff0c\u77e2\u91cf\u5316\u64cd\u4f5c\u7684\u6574\u4f53\u4f18\u52bf\u5f80\u5f80\u8d85\u8fc7\u4e86\u8fd9\u4e00\u70b9\u3002 result = g.transform('mean') print(result) # 0 4.5 # 1 5.5 # 2 6.5 # 3 4.5 # 4 5.5 # 5 6.5 # 6 4.5 # 7 5.5 # 8 6.5 # 9 4.5 # 10 5.5 # 11 6.5 # Name: value, dtype: float64 normalized = (df['value'] - g.transform('mean')) / g.transform('std') print(normalized) # 0 -1.161895 # 1 -1.161895 # 2 -1.161895 # 3 -0.387298 # 4 -0.387298 # 5 -0.387298 # 6 0.387298 # 7 0.387298 # 8 0.387298 # 9 1.161895 # 10 1.161895 # 11 1.161895 # Name: value, dtype: float64","title":"\u5206\u7ec4\u8f6c\u6362\u548c\u201c\u5c55\u5f00\u201dGroupBy"},{"location":"python/DataAnalysis/ch09/#_6","text":"\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c resample \u65b9\u6cd5\u5728\u8bed\u4e49\u4e0a\u662f\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5206\u6bb5\u7684\u5206\u7ec4\u64cd\u4f5c\u3002 N = 15 times = pd.date_range('2020-5-20 00:00', freq='1min', periods=N) df = pd.DataFrame( { 'time': times, 'value': np.arange(N) } ) print(df) # time value # 0 2020-05-20 00:00:00 0 # 1 2020-05-20 00:01:00 1 # 2 2020-05-20 00:02:00 2 # 3 2020-05-20 00:03:00 3 # 4 2020-05-20 00:04:00 4 # 5 2020-05-20 00:05:00 5 # 6 2020-05-20 00:06:00 6 # 7 2020-05-20 00:07:00 7 # 8 2020-05-20 00:08:00 8 # 9 2020-05-20 00:09:00 9 # 10 2020-05-20 00:10:00 10 # 11 2020-05-20 00:11:00 11 # 12 2020-05-20 00:12:00 12 # 13 2020-05-20 00:13:00 13 # 14 2020-05-20 00:14:00 14 \u8fd9\u91cc\uff0c\u53ef\u4ee5\u6309 time \u8fdb\u884c\u7d22\u5f15\uff0c\u7136\u540e\u91cd\u65b0\u91c7\u6837\uff1a result = df.set_index('time').resample('5min').count() print(result) # value # time # 2020-05-20 00:00:00 5 # 2020-05-20 00:05:00 5 # 2020-05-20 00:10:00 5 \u5047\u8bbeDataFrame\u5305\u542b\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u6309\u4e00\u4e2a\u9644\u52a0\u7684\u5206\u7ec4\u952e\u5217\u8fdb\u884c\u4e86\u6807\u8bb0\uff1a df2 = pd.DataFrame( { 'time': times.repeat(3), 'key': np.tile(['a', 'b', 'c'], N), 'value': np.arange((N * 3)) } ) print(df2) # time key value # 0 2020-05-20 00:00:00 a 0 # 1 2020-05-20 00:00:00 b 1 # 2 2020-05-20 00:00:00 c 2 # 3 2020-05-20 00:01:00 a 3 # ...... # 43 2020-05-20 00:14:00 b 43 # 44 2020-05-20 00:14:00 c 44 \u4f7f\u7528 pandas.TimeGrouper \u5bf9\u8c61\uff0c\u6bcf\u4e2a key \u7684\u503c\u8fdb\u884c\u76f8\u540c\u7684\u91cd\u65b0\u91c7\u6837\uff1a pd.TimeGrouper() was formally deprecated in pandas v0.21.0 in favor of pd.Grouper().","title":"\u5206\u7ec4\u7684\u65f6\u95f4\u91cd\u65b0\u91c7\u6837"},{"location":"python/DataAnalysis/ch09/#_7","text":"import numpy as np import pandas as pd from numpy import nan as NA df = pd.DataFrame( [[1., 2., 3.], [1., NA, NA], [NA, NA, NA], [NA, 2., 3.]] ) v = ['a', 'b', 'c', 'd'] print(df) # 0 1 2 # 0 1.0 2.0 3.0 # 1 1.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 2.0 3.0 \u975e\u51fd\u6570\u8d4b\u503c\u7684\u65b9\u5f0f\u3002 df2 = df.copy() df2['k'] = v print(df2) # 0 1 2 k # 0 1.0 2.0 3.0 a # 1 1.0 NaN NaN b # 2 NaN NaN NaN c # 3 NaN 2.0 3.0 d \u51fd\u6570\u8d4b\u503c\u7684\u65b9\u5f0f\u3002 DataFrame.assign \u65b9\u6cd5\u662f\u5bf9 df[k] = v \u7684\u8d4b\u503c\u65b9\u5f0f\u7684\u4e00\u79cd\u529f\u80fd\u66ff\u4ee3\u3002\u5b83\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u6309\u6307\u5b9a\u4fee\u6539\u7684\u65b0\u7684DataFrame\uff0c\u800c\u4e0d\u662f\u5728\u539f\u5bf9\u8c61\u4e0a\u8fdb\u884c\u4fee\u6539\u3002 df2 = df.assign(k=v) print(df2) # 0 1 2 k # 0 1.0 2.0 3.0 a # 1 1.0 NaN NaN b # 2 NaN NaN NaN c # 3 NaN 2.0 3.0 d","title":"\u65b9\u6cd5\u94fe\u6280\u672f"},{"location":"python/DataAnalysis/ch09/#pipe","text":"\u5bf9\u6570\u636e\u8fde\u7eed\u64cd\u4f5c\u5f62\u6210\u65b9\u6cd5\u94fe\uff08\u591a\u4e2a\u65b9\u6cd5\u8fde\u7eed\u8c03\u7528\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\uff09\u3002 Series.pipe \uff0c DataFrame.pipe \u610f\u5473\u7740 x.pipe(f, *args, **kwargs) \u548c f(x, *args, **kwargs) \u6548\u679c\u76f8\u540c\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u8be5\u51fd\u6570\u5e94\u7528\u4e8e\u6574\u4e2a\u6570\u636e\u3002 \u4ee5 DataFrame \u4e3a\u4f8b\uff1a \u8bed\u6cd5: DataFrame.pipe(func, *args, **kwargs) \u53c2\u6570\uff1a func\uff1a\u51fd\u6570\uff0c\u5e94\u7528\u4e8e\u7cfb\u5217/\u6570\u636e\u5e27\u7684\u51fd\u6570\u3002args \u548c kwargs \u88ab\u4f20\u9012\u5230 func\u3002\u6216\u8005\u662f\u4e00\u4e2a\uff08callable\uff0cdata_keyword\uff09\u5143\u7ec4\uff0c\u5176\u4e2d data_keyword \u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u8868\u793a\u9700\u8981Series/DataFrame \u7684 callable \u5173\u952e\u5b57 args\uff1a\u53ef\u8fed\u4ee3\u5bf9\u8c61, \u53ef\u9009\uff0c\u51fd\u6570\u7684\u4f4d\u7f6e\u53c2\u6570 kwargs\uff1amapping, \u53ef\u9009\uff0c\u4f20\u5165 func \u7684\u5173\u952e\u5b57\u53c2\u6570\u5b57\u5178 \u8fd4\u56de\uff1aobject\uff1afunc \u5904\u7406\u540e\u7684\u4efb\u610f\u6570\u636e\u7c7b\u578b","title":"pipe\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch09/#dataframe","text":"df = pd.DataFrame( [[1., 2., 3.], [1., NA, NA], [NA, NA, NA], [NA, 2., 3.]] ) \u88ab\u4f20\u9012\u7684\u7c7b\u578b\u662f\u8c03\u7528\u7684\u5b9e\u4f8b\u3002 df.pipe(type) # \u4f20\u9012\u7684\u662ftype\u5b9e\u4f8b # <class 'pandas.core.frame.DataFrame'> df.pipe(len) # \u4f20\u9012\u7684\u662flen\u5b9e\u4f8b # 4 def fun(df): return df * 2 fun(df) # 0 1 2 # 0 2.0 4.0 6.0 # 1 2.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 4.0 6.0 df.pipe(fun) # \u4f20\u9012\u7684\u662ffun\u51fd\u6570 # 0 1 2 # 0 2.0 4.0 6.0 # 1 2.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 4.0 6.0 def fun2(x, df): # \u6570\u636e\u662f\u7b2c\u4e8c\u4e2a\u53c2\u6570 return df * 3 df.pipe((fun2, 'df'), 2) # \u6ce8\u610f\u4f20\u503c # 0 1 2 # 0 3.0 6.0 9.0 # 1 3.0 NaN NaN # 2 NaN NaN NaN # 3 NaN 6.0 9.0","title":"DataFrame\u793a\u4f8b\uff1a"},{"location":"python/DataAnalysis/ch09/#series","text":"s = pd.Series([1, 2, 3, 4, 5]) s.pipe(type) # <class 'pandas.core.series.Series'> s.pipe(len) # 5 def fun3(x, ss): return ss * 3 s.pipe((fun3, 'ss'), 2) # 0 3 # 1 6 # 2 9 # 3 12 # 4 15 # dtype: int64","title":"Series \u793a\u4f8b\uff1a"},{"location":"python/DataAnalysis/ch09/#groupby_2","text":"df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]}) print(df) # A B # 0 a 1 # 1 b 2 # 2 a 3 # 3 b 4 \u6c42\u6bcf\u7ec4\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 df.groupby('A').pipe(lambda x: x.max() - x.min()) # B # A # a 2 # b 2 def mean1(groupby): return groupby.mean() df.groupby(['A']).pipe(mean1) # B # A # a 2.0 # b 3.0","title":"GroupBy \u793a\u4f8b\uff1a"},{"location":"python/DataAnalysis/ch10/","text":"NumPy\u8fdb\u9636 \u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a ndarray\u5bf9\u8c61\u7684\u5185\u90e8\u673a\u7406 \u9ad8\u7ea7\u6570\u7ec4\u64cd\u4f5c \u91cd\u5851\u6570\u7ec4 C\u987a\u5e8f\u548cF\u987a\u5e8f \u8fde\u63a5\u548c\u5206\u9694\u6570\u7ec4 \u5806\u53e0\u52a9\u624b\uff1ar \u548cc \u91cd\u590d\u5143\u7d20\uff1atile\u548crepeat \u795e\u5947\u7d22\u5f15\u7684\u7b49\u4ef7\u65b9\u6cd5\uff1atake\u548cput \u5e7f\u64ad ufunc\u9ad8\u7ea7\u5e94\u7528 \u7ed3\u6784\u5316\u548c\u8bb0\u5f55\u5f0f\u6570\u7ec4 ndarray\u5bf9\u8c61\u7684\u5185\u90e8\u673a\u7406 NumPy\u7684 ndarray \u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u540c\u8d28\u6570\u636e\u5757\uff08\u53ef\u4ee5\u662f\u8fde\u7eed\u6216\u8de8\u8d8a\uff09\u89e3\u91ca\u4e3a\u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61\u7684\u65b9\u5f0f\u3002 ndarray \u7684\u6570\u636e\u7c7b\u578b dtype \u51b3\u5b9a\u4e86\u6570\u636e\u7684\u89e3\u91ca\u65b9\u5f0f\uff0c\u6bd4\u5982\u6d6e\u70b9\u6570\u3001\u6574\u6570\u3001\u5e03\u5c14\u503c\u7b49\u3002 ndarray \u7684\u6240\u6709\u6570\u7ec4\u5bf9\u8c61\u90fd\u662f\u6570\u636e\u5757\u7684\u4e00\u4e2a\u8de8\u5ea6\u89c6\u56fe\uff08strided view\uff09\u3002 \u6570\u7ec4\u89c6\u56fe arr[::2,::-1] \u4e0d\u590d\u5236\u4efb\u4f55\u6570\u636e\u7684\u539f\u56e0\u662f\u4ec0\u4e48\uff1f \u7b80\u5355\u5730\u8bf4\uff0c ndarray \u4e0d\u53ea\u662f\u4e00\u5757\u5185\u5b58\u548c\u4e00\u4e2a dtype \uff0c\u5b83\u8fd8\u6709\u8de8\u5ea6\u4fe1\u606f\uff0c\u8fd9\u4f7f\u5f97\u6570\u7ec4\u80fd\u4ee5\u5404\u79cd\u6b65\u5e45\uff08step size\uff09\u5728\u5185\u5b58\u4e2d\u79fb\u52a8\u3002 \u66f4\u51c6\u786e\u5730\u8bb2\uff0c ndarray \u5185\u90e8\u7531\u4ee5\u4e0b\u5185\u5bb9\u7ec4\u6210\uff1a \u4e00\u4e2a\u6307\u5411\u6570\u636e\uff08\u5185\u5b58\u6216\u5185\u5b58\u6620\u5c04\u6587\u4ef6\u4e2d\u7684\u4e00\u5757\u6570\u636e\uff09\u7684\u6307\u9488\u3002 \u6570\u636e\u7c7b\u578b\u6216 dtype \uff0c\u63cf\u8ff0\u5728\u6570\u7ec4\u4e2d\u7684\u56fa\u5b9a\u5927\u5c0f\u503c\u7684\u683c\u5b50\u3002 \u4e00\u4e2a\u8868\u793a\u6570\u7ec4\u5f62\u72b6\uff08shape\uff09\u7684\u5143\u7ec4\u3002 \u4e00\u4e2a\u8de8\u5ea6\u5143\u7ec4\uff08stride\uff09\uff0c\u5176\u4e2d\u7684\u6574\u6570\u6307\u7684\u662f\u4e3a\u4e86\u524d\u8fdb\u5230\u5f53\u524d\u7ef4\u5ea6\u4e0b\u4e00\u4e2a\u5143\u7d20\u9700\u8981\u201c\u8de8\u8fc7\u201d\u7684\u5b57\u8282\u6570\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a10\u00d75\u7684\u6570\u7ec4\uff0c\u5176shape\u4e3a(10, 5)\uff1a s = np.ones((10, 5)).shape print(s) # (10, 5) \u4e00\u4e2a\u5178\u578b\u7684\uff08C\u9636\uff093\u00d74\u00d75 float64\u503c\uff088\u5b57\u8282\uff09\u7684\u6570\u7ec4\u5177\u6709\u8de8\u5ea6\uff08160,40,8\uff09\uff08\u901a\u5e38\u7279\u5b9a\u8f74\u4e0a\u7684\u8de8\u5ea6\u8d8a\u5927\uff0c\u6cbf\u7740\u8be5\u8f74\u6267\u884c\u8ba1\u7b97\u7684\u4ee3\u4ef7\u8d8a\u9ad8\uff09\uff1a s = np.ones((3, 4, 5), dtype=np.float64).strides print(s) # (160, 40, 8) \u6570\u7ec4\u8de8\u5ea6\uff08strides\uff09\u662f\u6784\u5efa\u201c\u96f6\u590d\u5236\u201d\u6570\u7ec4\u89c6\u56fe\u7684\u5173\u952e\u56e0\u7d20\u3002 \u6570\u7ec4\u8de8\u5ea6\u751a\u81f3\u53ef\u4ee5\u662f\u8d1f\u7684\uff0c\u8fd9\u4f7f\u5f97\u6570\u7ec4\u80fd\u591f\u7a7f\u8fc7\u5185\u5b58\u201c\u5411\u540e\u201d\u79fb\u52a8\uff08\u4f8b\u5982\uff0c\u5728\u8bf8\u5982obj[::-1]\u6216obj[:, ::-1]\u7684\u5207\u7247\u4e2d\u5c31\u662f\u8fd9\u79cd\u60c5\u51b5\uff09\u3002 NumPy dtype\u5c42\u6b21\u7ed3\u6784 \u6709\u65f6\u5019\u9700\u8981\u901a\u8fc7\u4e00\u4e9b\u4ee3\u7801\u6765\u68c0\u67e5\u6570\u7ec4\u662f\u5426\u5305\u542b\u6574\u6570\u3001\u6d6e\u70b9\u6570\u3001\u5b57\u7b26\u4e32\u6216Python\u5bf9\u8c61\u3002 \u7531\u4e8e\u6d6e\u70b9\u6570\u6709\u591a\u79cd\u7c7b\u578b\uff08float16\u5230float128\uff09\uff0c\u56e0\u6b64\u68c0\u67e5dtype\u662f\u5426\u5728\u7c7b\u578b\u5217\u8868\u4e2d\u4f1a\u975e\u5e38\u9ebb\u70e6\u3002 dtype\u6709\u8d85\u7c7b\uff0c\u5982np.integer\u548cnp.floating\uff0c\u5b83\u4eec\u53ef\u4ee5\u548cnp.issubdtype\u51fd\u6570\u4e00\u8d77\u4f7f\u7528\uff1a ints = np.ones(10, dtype=np.uint16) floats = np.ones(10, dtype=np.float32) \u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u7c7b\u578b\u7684mro\u65b9\u6cd5\u6765\u67e5\u770b\u7279\u5b9adtype\u7684\u6240\u6709\u7236\u7c7b\uff1a print(np.float64.mro()) # [<class 'numpy.float64'>, # <class 'numpy.floating'>, # <class 'numpy.inexact'>, # <class 'numpy.number'>, # <class 'numpy.generic'>, # <class 'float'>, # <class 'object'>] print(np.issubdtype(ints.dtype, np.integer)) # True print(np.issubdtype(floats.dtype, np.floating)) # True print(np.issubdtype(floats.dtype, np.number)) # True print(np.issubdtype(floats.dtype, np.generic)) # True \u9ad8\u7ea7\u6570\u7ec4\u64cd\u4f5c \u91cd\u5851\u6570\u7ec4 \u901a\u5e38\uff0c\u901a\u8fc7 reshape \u5c06\u6570\u7ec4\u4ece\u4e00\u4e2a\u5f62\u72b6\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u5f62\u72b6\uff0c\u5e76\u4e14\u4e0d\u590d\u5236\u4efb\u4f55\u6570\u636e\u3002 reshape \u91cc\u9762\u6709\u4e24\u79cd\u91cd\u5851\u987a\u5e8f\uff0c\u6309C\u987a\u5e8f\uff08\u884c\u65b9\u5411\uff09\u7684\u91cd\u5851\u548c\u6309Fortran\u987a\u5e8f\uff08\u5217\u65b9\u5411\uff09\u7684\u91cd\u5851\u3002 \u9996\u5148\u662f\u53d6\u6570\uff0c\u7136\u540e\u662f\u653e\u6570\uff0c\u53d6\u6570\u6309\u4ec0\u4e48\u987a\u5e8f\uff0c\u653e\u6570\u5c31\u6309\u4ec0\u4e48\u987a\u5e8f\u3002 \u4e0b\u9762\u662f\u5b98\u7f51\u7684\u89e3\u91ca\uff1a \u2018C\u2019 means to read / write the elements using C-like index order, with the last axis index changing fastest, back to the first axis index changing slowest. \u2018F\u2019 means to read / write the elements using Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of the memory layout of the underlying array, and only refer to the order of indexing. \u2018A\u2019 means to read / write the elements in Fortran-like index order if a is Fortran contiguous in memory, C-like order otherwise. \u4e00\u7ef4\u6570\u7ec4\u91cd\u5851\uff1a arr = np.arange(8) print(arr) # [0 1 2 3 4 5 6 7] a = arr.reshape((4, 2), order='C') print(a) # [[0 1] # [2 3] # [4 5] # [6 7]] a = arr.reshape((4, 2), order='F') print(a) # [[0 4] # [1 5] # [2 6] # [3 7]] \u591a\u7ef4\u6570\u7ec4\u91cd\u5851\uff1a\u4f20\u9012\u7684\u5f62\u72b6\u7ef4\u5ea6\u53ef\u4ee5\u6709\u4e00\u4e2a\u503c\u662f-1\uff0c\u8868\u793a\u7ef4\u5ea6\u901a\u8fc7\u6570\u636e\u8fdb\u884c\u63a8\u65ad\uff1a a = arr.reshape((4, 2)).reshape((2, 4)) print(a) # [[0 1 2 3] # [4 5 6 7]] arr = np.arange(15) a = arr.reshape((5, -1)) # 15 / 5 = 3\u5217 print(a) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] print(a.shape) # (5, 3) \u6570\u7ec4\u7684 shape \u5c5e\u6027\u662f\u4e00\u4e2a \u5143\u7ec4 \uff0c\u5b83\u4e5f\u53ef\u4ee5\u88ab\u4f20\u9012\u7ed9 reshape \uff0c\u63a5\u4e0a\u4f8b\uff1a other_arr = np.ones((3, 5)) print(other_arr.shape) # (3, 5) a = arr.reshape(other_arr.shape) print(a.shape) # (3, 5) reshape \u7684\u53cd\u64cd\u4f5c\u53ef\u4ee5\u5c06\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u7ec4\u8f6c\u6362\u4e3a\u4e00\u7ef4\u6570\u7ec4\uff0c\u8fd9\u79cd\u64cd\u4f5c\u901a\u5e38\u88ab\u6210\u4e3a\u6241\u5e73\u5316\uff08flattening\uff09\u6216\u5206\u6563\u5316\uff08raveling\uff09\u3002 \u5982\u679c\u7ed3\u679c\u4e2d\u7684\u503c\u5728\u539f\u59cb\u6570\u7ec4\u4e2d\u662f\u8fde\u7eed\u7684\uff0c\u5219 ravel \u4e0d\u4f1a\u751f\u6210\u5e95\u5c42\u6570\u503c\u7684\u526f\u672c\u3002 flatten \u65b9\u6cd5\u7684\u884c\u4e3a\u7c7b\u4f3c\u4e8e ravel \uff0c\u4f46\u5b83\u603b\u662f\u751f\u6210\u6570\u636e\u7684\u526f\u672c\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] a = arr.ravel() print(a) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] a = arr.flatten() print(a) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] C\u987a\u5e8f\u548cF\u987a\u5e8f \u6570\u636e\u53ef\u4ee5\u6309\u7167\u4e0d\u540c\u7684\u987a\u5e8f\u8fdb\u884c\u91cd\u5851\u6216\u6241\u5e73\u5316\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cNumPy\u6570\u7ec4\u662f\u6309\u884c\u65b9\u5411\u987a\u5e8f\u521b\u5efa\u7684\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u4e8c\u7ef4\u7684\u6570\u636e\u6570\u7ec4\uff0c C\u987a\u5e8f \u8bf4\u660e\u6570\u7ec4\u6bcf\u884c\u4e2d\u7684\u5143\u7d20\u5b58\u50a8\u5728\u76f8\u90bb\u7684\u5b58\u50a8\u5355\u5143\u4e2d\u3002 F\u987a\u5e8f \u610f\u5473\u7740\u6bcf\u5217\u6570\u636e\u4e2d\u7684\u503c\u90fd\u5b58\u50a8\u5728\u76f8\u90bb\u7684\u5185\u5b58\u4f4d\u7f6e\u4e2d\u3002 \u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e reshape \u548c ravel \u51fd\u6570\u7684 order \u53c2\u6570\u6765\u8868\u793a\u6570\u636e\u5728\u6570\u7ec4\u4e2d\u4f7f\u7528\u54ea\u79cd\u987a\u5e8f\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] print(arr.ravel()) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] print(arr.ravel('F')) # [ 0 3 6 9 12 1 4 7 10 13 2 5 8 11 14] C\u987a\u5e8f\u548cFortran\u987a\u5e8f\u7684\u6838\u5fc3\u533a\u522b\u5c31\u662f\u5728\u7ef4\u5ea6\u65b9\u5411\u4e0a\u904d\u5386\u7684\u65b9\u5f0f\u3002 C\u987a\u5e8f/\u884c\u65b9\u5411\u987a\u5e8f\u9996\u5148\u904d\u5386\u66f4\u9ad8\u7684\u7ef4\u5ea6\uff08\u4f8b\u5982\uff0c\u5728\u8f740\u4e0a\u884c\u8fdb\u4e4b\u524d\u5148\u5728\u8f741\u4e0a\u884c\u8fdb\uff09\u3002 Fortran\u987a\u5e8f/\u5217\u65b9\u5411\u987a\u5e8f\u6700\u540e\u904d\u5386\u66f4\u9ad8\u7684\u7ef4\u5ea6\uff08\u4f8b\u5982\uff0c\u5728\u8f741\u4e0a\u884c\u8fdb\u4e4b\u524d\u5148\u5728\u8f740\u4e0a\u884c\u8fdb\uff09\u3002 \u6570\u7ec4\u8fde\u63a5\u548c\u5206\u9694 numpy.concatenate \u53ef\u4ee5\u83b7\u53d6\u6570\u7ec4\u7684\u5e8f\u5217\uff08\u5143\u7ec4\u3001\u5217\u8868\u7b49\uff09\uff0c\u5e76\u6cbf\u7740\u8f93\u5165\u8f74\u5c06\u5b83\u4eec\u6309\u987a\u5e8f\u8fde\u63a5\u5728\u4e00\u8d77\uff1a arr1 = np.array( [ [1, 2, 3], [4, 5, 6] ] ) arr2 = np.array( [ [7, 8, 9], [10, 11, 12] ] ) a = np.concatenate([arr1, arr2], axis=0) print(a) # [[ 1 2 3] # [ 4 5 6] # [ 7 8 9] # [10 11 12]] a = np.concatenate([arr1, arr2], axis=1) print(a) # [[ 1 2 3 7 8 9] # [ 4 5 6 10 11 12]] \u5176\u4ed6\u7c7b\u4f3c concatenate \u7684\u51fd\u6570\u3002 vstack \u7c7b\u4f3c concatenate \u6cbf axis=0 \u64cd\u4f5c\uff0c hstack \u7c7b\u4f3c concatenate \u6cbf axis=1 \u64cd\u4f5c\u3002 a = np.vstack((arr1, arr2)) print(a) # [[ 1 2 3] # [ 4 5 6] # [ 7 8 9] # [10 11 12]] a = np.hstack((arr1, arr2)) print(a) # [[ 1 2 3 7 8 9] # [ 4 5 6 10 11 12]] split \u53ef\u4ee5\u5c06\u4e00\u4e2a\u6570\u7ec4\u6cbf\u8f74\u5411\u5207\u7247\u6210\u591a\u4e2a\u6570\u7ec4\u3002\u5148\u770b\u4e00\u7ef4\u6570\u7ec4\u3002 np.split(arr, 3) \u8868\u793a\u5c06\u6570\u7ec4\u62c6\u5206\u65f6\u7684 \u7d22\u5f15\u4f4d\u7f6e arr = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']) print(arr) # ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k'] print(np.split(arr, 3)) print(np.split(arr, [3])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g', 'h', 'i', 'j', 'k'], dtype='<U1')] print(np.split(arr, [3, 7])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u548c7\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g'], dtype='<U1'), array(['h', 'i', 'j', 'k'], dtype='<U1')] print(np.split(arr, [3, 7, 9])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u30017\u30019\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g'], dtype='<U1'), array(['h', 'i'], dtype='<U1'), array(['j', 'k'], dtype='<U1')] \u4e8c\u7ef4\u6570\u7ec4\u548c\u4e00\u7ef4\u6570\u7ec4\u7c7b\u4f3c\u3002 np.split(arr, [1, 2]) \u9ed8\u8ba4axis=0\uff0c\u6cbf\u6c34\u5e73\u65b9\u5411\u8fdb\u884c\u62c6\u5206\uff0c\u62c6\u5206\u884c\u7d22\u5f15\u5206\u522b\u4e3a\u884c\u53f71\u548c\u884c\u53f72\uff0c\u5373[0, 1)\uff0c[1, 2)\uff0c[2, 4]\u4e09\u4e2a\u884c\u533a\u95f4\u3002 np.split(arr, [1, 2], axis=1) \u6cbf\u5782\u76f4\u65b9\u5411\u8fdb\u884c\u62c6\u5206\uff0c\u62c6\u5206\u5217\u7d22\u5f15\u5206\u522b\u4e3a\u5217\u53f71\u548c\u5217\u53f72\uff0c\u5373[0, 1)\uff0c[1, 2)\uff0c[2, 3]\u4e09\u4e2a\u5217\u533a\u95f4\u3002 \u5982\u679c\u62c6\u5206\u533a\u95f4\u51fa\u73b0\u5012\u5e8f\uff0c\u5982 np.split(arr, [3, 1]) \uff0c\u6cbf\u6c34\u5e73\u65b9\u5411\u62c6\u5206\uff0c\u7b2c\u4e00\u4e2a\u884c\u533a\u95f4\u662f[0, 3)\uff0c\u7b2c\u4e8c\u4e2a\u884c\u533a\u95f4\u662f[3, 1)\uff0c\u65e0\u7ed3\u679c\uff0c\u5f53\u524d\u884c\u7d22\u5f15\u4e3a0\uff0c\u672a\u8fbe\u5230\u6700\u5927\u884c\u6570\uff0c\u6240\u4ee5\u8f93\u51fa\u7b2c\u4e09\u4e2a\u533a\u95f4[1, 4]\u3002\u540c\u7406\u53ef\u63a8 np.split(arr, [3, 1], axis=1) \u7684\u4e09\u4e2a\u5217\u533a\u95f4\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] result = np.split(arr, [1, 2]) print(result) # [array([[0, 1, 2]]), # array([[3, 4, 5]]), # array([[ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]])] result = np.split(arr, [1, 2], axis=1) print(result) # [array([[ 0], # [ 3], # [ 6], # [ 9], # [12]]), # array([[ 1], # [ 4], # [ 7], # [10], # [13]]), # array([[ 2], # [ 5], # [ 8], # [11], # [14]])] result = np.split(arr, [3, 1]) print(result) # [array([[0, 1, 2], # [3, 4, 5], # [6, 7, 8]]), # array([], shape=(0, 3), dtype=int64), # array([[ 3, 4, 5], # [ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]]) result = np.split(arr, [3, 1], axis=1) print(result) # [array([[ 0, 1, 2], # [ 3, 4, 5], # [ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]]), # array([], shape=(5, 0), dtype=int64), # array([[ 1, 2], # [ 4, 5], # [ 7, 8], # [10, 11], # [13, 14]])] \u6570\u7ec4\u5806\u53e0\u7684\u65b9\u6cd5\uff1ar_\u548cc_ \u5728NumPy\u4e2d\u6709\u4e24\u4e2a\u7279\u6b8a\u7684\u5bf9\u8c61\uff1ar_\u548cc_\uff0c\u5b83\u4eec\u53ef\u4ee5\u4f7f\u5806\u6808\u6570\u7ec4\u7684\u64cd\u4f5c\u66f4\u4e3a\u7b80\u6d01\uff1a np.r_ \u662f\u6309\u5217\u8fde\u63a5\u4e24\u4e2a\u77e9\u9635\uff0c\u5c31\u662f\u628a\u4e24\u77e9\u9635\u4e0a\u4e0b\u76f8\u52a0\uff0c\u8981\u6c42\u5217\u6570\u76f8\u7b49\u3002 np.c_ \u662f\u6309\u884c\u8fde\u63a5\u4e24\u4e2a\u77e9\u9635\uff0c\u5c31\u662f\u628a\u4e24\u77e9\u9635\u5de6\u53f3\u76f8\u52a0\uff0c\u8981\u6c42\u884c\u6570\u76f8\u7b49\u3002 arr = np.arange(6) arr1 = arr.reshape((3, 2)) arr2 = np.random.randn(3, 2) print(arr) # [0 1 2 3 4 5] print(arr1) # [[0 1] # [2 3] # [4 5]] print(arr2) # [[ 0.15407269 0.56316672] # [-1.2390795 -1.59294986] # [ 0.082398 0.75602857]] a = np.r_[arr1, arr2] print(a) # [[ 0. 1. ] # [ 2. 3. ] # [ 4. 5. ] # [ 0.15407269 0.56316672] # [-1.2390795 -1.59294986] # [ 0.082398 0.75602857]] a = np.c_[arr1, arr2] print(a) # [[ 0. 1. 0.15407269 0.56316672] # [ 2. 3. -1.2390795 -1.59294986] # [ 4. 5. 0.082398 0.75602857]] a = np.c_[np.r_[arr1, arr2], arr] print(a) # [[ 0. 1. 0. ] # [ 2. 3. 1. ] # [ 4. 5. 2. ] # [ 0.15407269 0.56316672 3. ] # [-1.2390795 -1.59294986 4. ] # [ 0.082398 0.75602857 5. ]] \u8fd8\u53ef\u4ee5\u5c06\u5207\u7247\u8f6c\u6362\u4e3a\u6570\u7ec4\uff1a a = np.c_[1:6, -10:-5] print(a) # [[ 1 -10] # [ 2 -9] # [ 3 -8] # [ 4 -7] # [ 5 -6]] \u91cd\u590d\u5143\u7d20\uff1atile\u548crepeat repeat \u548c tile \u51fd\u6570\u662f\u7528\u4e8e\u91cd\u590d\u6216\u590d\u5236\u6570\u7ec4\u7684\u4e24\u4e2a\u6709\u7528\u7684\u5de5\u5177\u3002 repeat \u51fd\u6570\u6309\u7167\u7ed9\u5b9a\u6b21\u6570\u5bf9\u6570\u7ec4\u4e2d\u7684 \u6bcf\u4e2a\u5143\u7d20 \u8fdb\u884c\u590d\u5236\uff0c\u751f\u6210\u4e00\u4e2a\u66f4\u5927\u7684\u6570\u7ec4\u3002 \u5bf9\u4e8eNumPy\u800c\u8a00\uff0c\u590d\u5236\u6216\u91cd\u590d\u6570\u7ec4\u7684\u9700\u6c42\u53ef\u80fd\u4e0d\u5982\u5176\u4ed6\u6570\u7ec4\u7f16\u7a0b\u6846\u67b6\uff08\u5982MATLAB\uff09\u90a3\u6837\u5e38\u89c1\u3002\u5176\u4e2d\u4e00\u4e2a\u539f\u56e0\u662f\u5e7f\u64ad\u901a\u5e38\u4f1a\u66f4\u597d\u5730\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u3002 arr = np.arange(3) print(arr) # [0 1 2] a = arr.repeat(3) print(a) # [0 0 0 1 1 1 2 2 2] \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u4f60\u4f20\u9012\u4e00\u4e2a\u6574\u6570\uff0c\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u590d\u5236\u76f8\u5e94\u7684\u6b21\u6570\u3002\u5982\u679c\u4f60\u4f20\u9012\u4e86\u4e00\u4e2a\u6574\u6570\u6570\u7ec4\uff0c\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u91cd\u590d\u76f8\u5e94\u7684\u4e0d\u540c\u6b21\u6570\uff1a arr = np.arange(3) print(arr) # [0 1 2] a = arr.repeat([2, 3, 4]) print(a) # [0 0 1 1 1 2 2 2 2] \u591a\u7ef4\u6570\u7ec4\u53ef\u4ee5\u5728\u6307\u5b9a\u7684\u8f74\u5411\u4e0a\u5bf9\u5b83\u4eec\u7684\u5143\u7d20\u8fdb\u884c\u91cd\u590d\uff0c\u6ce8\u610f\uff0c\u5982\u679c\u6ca1\u6709\u4f20\u9012\u8f74\uff0c\u6570\u7ec4\u5c06\u9996\u5148\u6241\u5e73\u5316\uff08\u6cbf0\u8f74\u590d\u5236\uff09\u3002 arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = arr.repeat(2, axis=0) print(a) # [[-0.15870621 0.26521446] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376]] a = arr.repeat(2, axis=1) print(a) # [[-0.15870621 -0.15870621 0.26521446 0.26521446] # [-1.35042383 -1.35042383 -0.65562376 -0.65562376]] \u540c\u6837\uff0c\u9700\u8981\u6309\u7167\u4e0d\u540c\u6b21\u6570\u91cd\u590d\u591a\u7ef4\u6570\u7ec4\u7684\u5207\u7247\u65f6\uff0c\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u6574\u6570\u6570\u7ec4\uff1a arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = arr.repeat([2, 3], axis=0) print(a) # [[-0.15870621 0.26521446] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376]] tile \u662f\u4e00\u79cd\u5feb\u6377\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u6cbf\u7740\u8f74\u5411\u5806\u53e0\u526f\u672c\u3002\u5728\u89c6\u89c9\u4e0a\uff0c\u4f60\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u7c7b\u4f3c\u4e8e\u201c\u94fa\u8bbe\u74f7\u7816\u201d\u3002 np.tile(arr, 2) \u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u74f7\u7816\u7684\u6570\u91cf\u3002\u7528\u6807\u91cf\u6765\u8bf4\uff0c\u94fa\u8bbe\u662f\u9010\u884c\u8fdb\u884c\u7684\uff0c\u800c\u4e0d\u662f\u9010\u5217\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e5f\u53ef\u4ee5\u662f\u8868\u793a\u201c\u94fa\u74f7\u7816\u201d\u5e03\u5c40\u7684\u5143\u7ec4\u3002 arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = np.tile(arr, 2) print(a) # [[-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376]] a = np.tile(arr, (2, 1)) print(a) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = np.tile(arr, (3, 2)) print(a) # [[-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376] # [-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376] # [-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376]] \u795e\u5947\u7d22\u5f15\uff08Fancy Indexing\uff09\u7684\u7b49\u4ef7\u65b9\u6cd5\uff1atake\u548cput take \u51fd\u6570\u53ef\u4ee5\u83b7\u53d6\u6570\u7ec4\u5b50\u96c6\uff0c put \u51fd\u6570\u53ef\u4ee5\u8bbe\u7f6e\u6570\u7ec4\u5b50\u96c6\u3002\u5176\u4ed6\u4e00\u4e9bndarray\u65b9\u6cd5\u53ef\u4ee5\u7528\u4e8e\u7279\u6b8a\u60c5\u51b5\u4e0b\u5728\u5355\u4e2a\u8f74\u4e0a\u7684\u6570\u636e\u9009\u53d6. arr = np.arange(10) * 100 inds = [7, 1, 2, 6] print(arr) # [ 0 100 200 300 400 500 600 700 800 900] print(inds) # [7, 1, 2, 6] # \u4ecearr\u5e8f\u5217\u4e2d\u4f9d\u6b21\u83b7\u53d6\u7d22\u5f15\u4e3a7,1,2,6\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u3002 a = np.take(arr, inds) print(a) # [700 100 200 600] print(arr) # [ 0 100 200 300 400 500 600 700 800 900] arr = np.arange(10) * 100 inds = [7, 1, 2, 6] # \u76f8\u5f53\u4e8e\u5c06arr\u5e8f\u5217\u4e2d\u7d22\u5f15\u4e3a7,1,2,6\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u752842\u6765\u66ff\u6362 np.put(arr, inds, 41) print(arr) # [ 0 41 41 300 400 500 41 41 800 900] arr = np.arange(10) * 100 inds = [7, 1, 2, 6] np.put(arr, inds, [40, 41, 42]) print(arr) # [ 0 41 42 300 400 500 40 40 800 900] \u6ce8\u610f\uff0c\u4e0a\u4f8b\u5982\u679c\u6539\u5199\u4e3a a = np.put(arr, inds, 41) \uff0c\u5219\u8fd4\u56de None \u3002 a = np.put(arr, inds, 41) print(a) # None \u5982\u679c\u8981\u5728\u522b\u7684\u8f74\u4e0a\u4f7f\u7528 take \uff0c\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012 axis \u5173\u952e\u5b57\u6765\u5b9e\u73b0\u3002 inds = [2, 0, 2, 1] arr = np.random.randn(2, 4) print(arr) # [[-0.82371274 -0.16911898 -0.01903239 -0.91792531] # [-0.55176496 -0.30111564 0.33872999 0.32454671]] a = arr.take(inds, axis=1) print(a) # [[-0.01903239 -0.82371274 -0.01903239 -0.16911898] # [ 0.33872999 -0.55176496 0.33872999 -0.30111564]] \u5e7f\u64ad \u5e7f\u64ad\uff08broadcasting\uff09 \u6307\u7684\u662f\u4e0d\u540c\u5f62\u72b6\u7684\u6570\u7ec4\u4e4b\u95f4\u7684\u7b97\u672f\u8fd0\u7b97\u7684\u6267\u884c\u65b9\u5f0f\u3002\u53d7\u67d0\u4e9b\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u8f83\u5c0f\u7684\u6570\u7ec4\u5728\u8f83\u5927\u7684\u6570\u7ec4\u4e0a\u201c\u5e7f\u64ad\u201d\uff0c\u4ee5\u4fbf\u5b83\u4eec\u5177\u6709\u517c\u5bb9\u7684\u5f62\u72b6\u3002\u5e7f\u64ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u77e2\u91cf\u5316\u6570\u7ec4\u64cd\u4f5c\u7684\u65b9\u6cd5\u3002 NumPy \u64cd\u4f5c\u901a\u5e38\u5728 \u9010\u4e2a\u5143\u7d20 \u7684\u57fa\u7840\u4e0a\u5728\u6570\u7ec4\u5bf9\u4e0a\u5b8c\u6210\u3002\u5728\u6700\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u4e24\u4e2a\u6570\u7ec4\u5fc5\u987b\u5177\u6709\u5b8c\u5168\u76f8\u540c\u7684\u5f62\u72b6\uff0c\u5982\u4e0b\u4f8b\u6240\u793a\uff1a a = np.array([1, 3, 5]) b = np.array([2, 2, 2]) print(a * b) # [ 2 6 10] print(a + b) # [3 5 7] \u5f53\u4e00\u4e2a\u6570\u7ec4\u548c\u4e00\u4e2a\u6807\u91cf\u503c\u5728\u4e00\u4e2a\u64cd\u4f5c\u4e2d\u7ec4\u5408\u65f6\uff0c\u4f1a\u53d1\u751f\u6700\u7b80\u5355\u7684\u5e7f\u64ad\u793a\u4f8b\uff0cNumPy\u7684\u5e7f\u64ad\u89c4\u5219\u653e\u5bbd\u4e86\u8fd9\u79cd\u7ea6\u675f\u3002 a = np.array([1, 3, 5]) b = 2 print(a * b) # [ 2 6 10] print(a + b) # [3 5 7] \u7ed3\u679c\u7b49\u540c\u4e8e\u524d\u9762\u7684\u793a\u4f8b\uff0c\u5176\u4e2d b \u662f\u6570\u7ec4\u3002\u53ef\u4ee5\u5047\u8c61\u5c06\u5728\u7b97\u672f\u8fd0\u7b97\u671f\u95f4\u6807\u91cf b \u88ab \u62c9\u4f38 \u6210\u4e0e\u6570\u7ec4 a \u5177\u6709\u76f8\u540c\u5f62\u72b6\u7684\u6570\u7ec4\u3002\u62c9\u4f38\u7c7b\u6bd4\u53ea\u662f\u6982\u5ff5\u6027\u7684\u3002NumPy\u5728\u5b9e\u9645\u8fd0\u7b97\u4e2d\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u6807\u91cf\u503c\u800c\u4e0d\u4f1a\u53bb\u5236\u4f5c\u62c9\u4f38\u526f\u672c\uff0c\u56e0\u6b64\u5e7f\u64ad\u64cd\u4f5c\u6548\u7387\u66f4\u9ad8\u6548\uff0c\u5728\u4e0a\u4f8b\u7684\u4e58\u6cd5\u671f\u95f4\uff0c\u901a\u8fc7\u5e7f\u64ad\u64cd\u4f5c\uff0c\u79fb\u52a8\u7684\u5185\u5b58\u8f83\u5c11\uff08b\u662f\u6807\u91cf\u800c\u4e0d\u662f\u6570\u7ec4\uff09\u3002 \u5e7f\u64ad\u7684\u89c4\u5219 \u5e7f\u64ad\u7684\u89c4\u5219 \uff1a \u5982\u679c\u4e24\u4e2a\u6570\u7ec4\u7684\u540e\u7f18\u7ef4\u5ea6\uff08trailing dimension\uff0c\u5373\u4ece\u672b\u5c3e\u5f00\u59cb\u7b97\u8d77\u7684\u7ef4\u5ea6\uff09\u7684\u8f74\u957f\u5ea6\u76f8\u7b26\uff0c\u6216\u5176\u4e2d\u7684\u4e00\u65b9\u7684\u957f\u5ea6\u4e3a1\uff0c\u5219\u8ba4\u4e3a\u5b83\u4eec\u662f\u5e7f\u64ad\u517c\u5bb9\u7684\u3002\u5e7f\u64ad\u4f1a\u5728\u7f3a\u5931\u548c\uff08\u6216\uff09\u957f\u5ea6\u4e3a1\u7684\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u3002 \u8fd9\u53e5\u8bdd\u662f\u7406\u89e3\u5e7f\u64ad\u7684\u6838\u5fc3\u3002\u5e7f\u64ad\u4e3b\u8981\u53d1\u751f\u5728\u4e24\u79cd\u60c5\u51b5\uff0c\u4e00\u79cd\u662f\u4e24\u4e2a\u6570\u7ec4\u7684\u7ef4\u6570\u4e0d\u76f8\u7b49\uff0c\u4f46\u662f\u5b83\u4eec\u7684\u540e\u7f18\u7ef4\u5ea6\u7684\u8f74\u957f\u76f8\u7b26\uff0c\u53e6\u5916\u4e00\u79cd\u662f\u6709\u4e00\u65b9\u7684\u957f\u5ea6\u4e3a1\u3002 \u5982\u679c\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\uff0c\u5219\u629b\u51fa ValueError: operands could not be broadcast together \u5f02\u5e38\uff0c\u6307\u793a\u6570\u7ec4\u5177\u6709\u4e0d\u517c\u5bb9\u7684\u5f62\u72b6\u3002\u7ed3\u679c\u6570\u7ec4\u7684\u5927\u5c0f\u662f\u6cbf\u8f93\u5165\u7684\u6bcf\u4e2a\u8f74\u4e0d\u662f1\u7684\u5927\u5c0f\u3002 \u5c06\u6807\u91cf\u503c\u8ddf\u6570\u7ec4\u5408\u5e76\u65f6\u5c31\u4f1a\u53d1\u751f\u6700\u7b80\u5355\u7684\u5e7f\u64ad\uff0c\u6807\u91cf\u503c4\u5df2\u7ecf\u88ab\u5e7f\u64ad\u7ed9\u4e58\u6cd5\u8fd0\u7b97\u4e2d\u7684\u6240\u6709\u5176\u4ed6\u5143\u7d20\u3002 arr = np.arange(5) print(arr * 4) # [ 0 4 8 12 16] \u4e00\u7ef4\u5e7f\u64ad \u4e0b\u9762\u662f\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\u6cbf0\u8f74\u5e7f\u64ad\u7684\u4f8b\u5b50\uff1a arr1 = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]]) print(arr1.shape) # (4, 3) arr2 = np.array([1, 2, 3]) print(arr2.shape) # (3,) arr_sum = arr1 + arr2 print(arr_sum) # [[1 2 3] # [2 3 4] # [3 4 5] # [4 5 6]] \u4e0a\u4f8b\u4e2d arr1 \u7684 shape \u4e3a (4,3) \uff0c arr2 \u7684 shape \u4e3a (3,) \u3002\u5373\uff0c arr1 \u662f\u4e8c\u7ef4\u6570\u7ec4\uff0c arr2 \u662f\u4e00\u7ef4\u6570\u7ec4\u3002\u867d\u7136\u5b83\u4eec\u7684\u7ef4\u5ea6 shape \u4e0d\u540c\uff0c\u4f46\u540e\u7f18\u7ef4\u5ea6\u90fd\u662f 3 \uff0c\u7b26\u5408\u5e7f\u64ad\u89c4\u5219\uff0c\u6240\u4ee5\u5b83\u4eec\u4e4b\u95f4\u662f\u53ef\u4ee5\u6267\u884c\u76f8\u52a0\u64cd\u4f5c\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u5f53\u4e2d\u662f\u5c06arr2\u6cbf\u77400\u8f74\u8fdb\u884c\u6269\u5c55\u3002\u76f4\u89c2\u7684\u63cf\u8ff0\u662f\uff0c arr2 \u5728\u53c2\u4e0e\u8fd0\u7b97\u65f6\u662f\u4ee5\u4e0b\u9762\u8fd9\u6837\u7684\u5f62\u5f0f\u8fdb\u884c0\u8f74\u6269\u5c55\u7684\uff08\u6cbf0\u8f74\u6c34\u5e73\u65b9\u5411\u79fb\u52a8\uff0c\u5728\u5217\u65b9\u5411\u8fdb\u884c\u201c\u62c9\u4f38\u201d\uff09\uff1a [[1 2 3] [1 2 3] [1 2 3] [1 2 3]] \u4e8c\u7ef4\u5e7f\u64ad \u5728\u4e0b\u9762\u884c\u51cf\u5747\u503c\u7684\u4f8b\u5b50\u4e2d\uff0c\u6839\u636e\u89c4\u5219\uff0c\u4e3a\u4e86\u4ece\u8f741\u51cf\u5747\u503c\uff08\u5373\u4ece\u6bcf\u884c\u51cf\u53bb\u884c\u5e73\u5747\u503c\uff09\uff0c\u5bf9\u8f83\u5c0f\u7684\u6570\u7ec4 row_means \u7684\u5851\u5f62\u5fc5\u987b\u662f\uff084, 1\uff09\uff0c\u5373\uff0c\u91cd\u65b0\u5851\u9020\u884c\u610f\u5473\u7740\u5f62\u72b6\u662f\uff084,1\uff09\u800c\u4e0d\u662f\uff084, \uff09\u3002 arr = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 3], [4, 5, 6]]) print(arr) # [[1 2 3] # [4 5 6] # [1 2 3] # [4 5 6]] row_means = arr.mean(1) print(row_means) # [2. 5. 2. 5.] print(row_means.reshape(4, 1)) # [[2.] # [5.] # [2.] # [5.]] demeaned = arr - row_means.reshape((4, 1)) print(demeaned) # [[-1. 0. 1.] # [-1. 0. 1.] # [-1. 0. 1.] # [-1. 0. 1.]] print(demeaned.mean(1)) # [0. 0. 0. 0.] \u4e09\u7ef4\u5e7f\u64ad \u5728\u8f740\u4ee5\u5916\u7684\u8f74\u4e0a\u4f7f\u7528\u8f83\u4f4e\u7ef4\u6570\u7ec4\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97\u4e5f\u662f\u76f8\u5f53\u666e\u904d\u7684\u3002\u6839\u636e\u5e7f\u64ad\u89c4\u5219\uff0c\u201c\u5e7f\u64ad\u7ef4\u5ea6\u201d\u5728\u8f83\u5c0f\u7684\u6570\u7ec4\u4e2d\u5fc5\u987b\u4e3a1\u3002 \u5728\u4e09\u7ef4\u60c5\u51b5\u4e0b\uff0c\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5e7f\u64ad\u53ea\u662f\u5c06\u6570\u636e\u91cd\u5851\u4e3a\u5f62\u72b6\u517c\u5bb9\u3002 \u56e0\u6b64\uff0c\u9700\u8981\u6dfb\u52a0\u4e00\u4e2a\u957f\u5ea6\u4e3a1\u7684\u65b0\u8f74\uff0c\u4e13\u95e8\u7528\u4e8e\u5e7f\u64ad\u76ee\u7684\u3002\u4f7f\u7528 reshape \u662f\u4e00\u79cd\u9009\u62e9\uff0c\u4f46\u63d2\u5165\u4e00\u4e2a\u8f74\u9700\u8981\u6784\u9020\u4e00\u4e2a\u65b0\u5f62\u72b6\u7684\u5143\u7ec4\u3002NumPy\u6570\u7ec4\u63d0\u4f9b\u4e86 np.newaxis \u5c5e\u6027\u548c\u201c\u5b8c\u6574\u201d\u5207\u7247\u6765\u63d2\u5165\u65b0\u8f74\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u4e86\u89e3\u4e00\u4e9b np.newaxis \u7684\u7528\u6cd5\u3002 x1[:, np.newaxis] \u5bf9\u539f x1 \u6dfb\u52a0\u4e861\u8f74\uff0c\u5373\uff0c\u884c\u65b9\u5411\u67095\u4e2a\u5143\u7d20\uff085\u884c\uff09\uff0c\u5217\u65b9\u5411\u53ea\u67091\u4e2a\u5143\u7d20\uff081\u5217\uff09\u3002 x1[np.newaxis, :] \u5bf9\u539f x1 \u6dfb\u52a0\u4e860\u8f74\uff0c\u5373\uff0c\u884c\u65b9\u5411\u67091\u4e2a\u5143\u7d20\uff081\u884c\uff09\uff0c\u5217\u65b9\u5411\u53ea\u67095\u4e2a\u5143\u7d20\uff085\u5217\uff09\u3002 x1 = np.array([1, 2, 3, 4, 5]) print(x1.shape) # (5,) x1_new = x1[:, np.newaxis] print(x1_new.shape) # (5, 1) print(x1_new) # [[1] # [2] # [3] # [4] # [5]] x2_new = x1[np.newaxis, :] print(x1_new.shape) # (1, 5) print(x1_new) # [[1 2 3 4 5]] \u4e0b\u4f8b\u4e00\u4e2a\u901a\u8fc7 np.newaxis \u5bf9\u4e8c\u7ef4\u6570\u7ec4\u5230\u4e09\u7ef4\u7684\u6269\u5c55\u3002 arr[np.newaxis, :, :, np.newaxis] \u8868\u793a\u5bf9 arr \u6dfb\u52a00\uff0c3\u8f74\uff0c\u539f\u6570\u7ec4 arr \u505a\u4e3a1\uff0c2\u8f74\u3002\u5176\u7b49\u4ef7\u5199\u6cd5\u662f arr[np.newaxis, ..., np.newaxis] arr[:, np.newaxis, np.newaxis] \u8868\u793a\u5bf9 arr \u6dfb\u52a01\uff0c2\u8f74\uff0c\u539f\u6570\u7ec4 arr \u505a\u4e3a0\uff0c3\u8f74\u3002\u5176\u7b49\u4ef7\u5199\u6cd5\u662f arr[np.newaxis, :, np.newaxis, :] \uff0c\u7406\u89e3\u4e0a\u9700\u8981\u6ce8\u610f\u7684\u662f : \u53ea\u4ee3\u8868\u4e00\u4e2a\u8f74\u3002 arr = np.arange(3 * 4).reshape(3, 4) print(arr.shape) # (3, 4) print(arr) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] arr_3D = arr[np.newaxis, :, :, np.newaxis] print(arr_3D.shape) # (1, 3, 1, 4) arr_3D = arr[np.newaxis, ..., np.newaxis] print(arr_3D.shape) # (1, 3, 4, 1) print(arr_3D) # [[[[ 0] # [ 1] # [ 2] # [ 3]] # # [[ 4] # [ 5] # [ 6] # [ 7]] # # [[ 8] # [ 9] # [10] # [11]]]] arr_3D = arr[np.newaxis, :, np.newaxis] print(arr_3D.shape) # (1, 3, 1, 4) arr_3D = arr[np.newaxis, :, np.newaxis, :] print(arr_3D.shape) # (1, 3, 1, 4) print(arr_3D) # [[[[ 0 1 2 3]] # # [[ 4 5 6 7]] # # [[ 8 9 10 11]]]] arr_3D = arr[:, np.newaxis, np.newaxis] print(arr_3D.shape) # (3, 1, 1, 4) arr_3D = arr[:, np.newaxis, np.newaxis, :] print(arr_3D.shape) # (3, 1, 1, 4) print(arr_3D) # [[[[0 1 2]]] # # [[[3 4 5]]] # # [[[6 7 8]]]] \u4e0b\u56fe\u663e\u793a\u4e86\u5728\u4e09\u7ef4\u6570\u7ec4\u7684\u6bcf\u4e2a\u8f74\u4e0a\u5e7f\u64ad\u6240\u9700\u7684\u5f62\u72b6\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u6f14\u793a\u4e86\u57fa\u4e8e\u4e00\u4e2a\u4e09\u7ef4\u6570\u7ec4\u8fdb\u884c\u7684\u5e7f\u64ad\u64cd\u4f5c\u3002 arr = np.zeros((3, 2, 4)) print(arr.shape) # (3, 2, 4) print(arr) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]] # \u751f\u62100\u8f74\u5207\u7247 arr_0 = np.arange(2) print(arr_0.shape) # (2,) print(arr_0) # [0 1] arr_new = arr_0[np.newaxis, :, np.newaxis] print(arr_new.shape) # (1, 2, 1) print(arr_new) # [[[0] # [1]]] arr = arr + arr_new print(arr.shape) # (3, 2, 4) print(arr) # [[[0. 0. 0. 0.] # [1. 1. 1. 1.]] # # [[0. 0. 0. 0.] # [1. 1. 1. 1.]] # # [[0. 0. 0. 0.] # [1. 1. 1. 1.]]] # \u751f\u62101\u8f74\u5207\u7247 arr = np.zeros((3, 2, 4)) arr_1 = np.arange(12).reshape(3, 4) print(arr_1.shape) # (3, 4) arr_new = arr_1[:, np.newaxis, :] print(arr_new.shape) # (3, 1, 4) print(arr_new) # [[[ 0 1 2 3]] # # [[ 4 5 6 7]] # # [[ 8 9 10 11]]] arr = arr + arr_new print(arr) # [[[ 0. 1. 2. 3.] # [ 0. 1. 2. 3.]] # [[ 4. 5. 6. 7.] # [ 4. 5. 6. 7.]] # [[ 8. 9. 10. 11.] # [ 8. 9. 10. 11.]]] # \u751f\u62102\u8f74\u5207\u7247 arr = np.zeros((3, 2, 4)) arr_2 = np.arange(6).reshape(3, 2) arr_new = arr_2[:, :, np.newaxis] print(arr_new.shape) # (3, 2, 1) print(arr_new) # [[[0] # [1]] # [[2] # [3]] # [[4] # [5]]] arr = arr + arr_new print(arr) # [[[0. 1. 2. 3.] # [1. 2. 3. 4.]] # # [[1. 2. 3. 4.] # [2. 3. 4. 5.]] # # [[2. 3. 4. 5.] # [3. 4. 5. 6.]]] # \u5728\u8f742\u4e0a\u51cf\u53bb\u5747\u503c depth_means = arr.mean(2) print(depth_means) # [[0. 1.] # [2. 3.] # [4. 5.]] arr_new = depth_means[:, :, np.newaxis] print(arr_new.shape) # (3, 2, 1) demeaned = arr - arr_new print(demeaned) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]] N\u7ef4\u5e7f\u64ad \u548c\u4e0a\u4f8b\u6700\u540e\u573a\u666f\u7684\u8ba1\u7b97\u7ed3\u679c\u76f8\u540c\u3002 arr = np.zeros((3, 2, 4)) def demean_axis(arr, axis=0): means = arr.mean(axis) indexer = [slice(None)] * arr.ndim indexer[axis] = np.newaxis return arr - means[indexer] print(demean_axis(arr, axis=2)) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]] \u901a\u8fc7\u5e7f\u64ad\u8bbe\u5b9a\u6570\u7ec4\u7684\u503c \u8fdb\u884c\u6570\u7ec4\u7b97\u672f\u8fd0\u7b97\u7684\u5e7f\u64ad\u89c4\u5219\u540c\u6837\u4e5f\u9002\u7528\u4e8e\u901a\u8fc7\u6570\u7ec4\u7d22\u5f15\u8bbe\u7f6e\u503c\u3002 arr = np.zeros((4, 3)) arr[:] = 5 print(arr) # [[5. 5. 5.] # [5. 5. 5.] # [5. 5. 5.] # [5. 5. 5.]] col = np.arange(4) arr[:] = col[:, np.newaxis] print(arr) # [[0. 0. 0.] # [1. 1. 1.] # [2. 2. 2.] # [3. 3. 3.]] ufunc\u9ad8\u7ea7\u5e94\u7528 ufunc\u5b9e\u4f8b\u65b9\u6cd5 \u901a\u7528\u51fd\u6570\uff08\u6216\u7b80\u79f0\u4e3aufunc \uff09 \u662f\u4e00\u79cd ndarrays \u4ee5\u9010\u5143\u7d20\u65b9\u5f0f\u64cd\u4f5c\u7684\u51fd\u6570\uff0c\u652f\u6301\u6570\u7ec4\u5e7f\u64ad\uff0c\u7c7b\u578b\u8f6c\u6362\u548c\u5176\u4ed6\u4e00\u4e9b\u6807\u51c6\u529f\u80fd\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0cufunc\u662f\u4e00\u4e2a\u51fd\u6570\u7684 \u77e2\u91cf\u5316\u5305\u88c5\u5668 \uff0c\u5b83\u63a5\u53d7\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5b9a\u8f93\u5165\u5e76\u4ea7\u751f\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5b9a\u8f93\u51fa\u3002 \u5728NumPy\u4e2d\uff0c\u901a\u7528\u51fd\u6570\u662fnumpy.ufunc\u7c7b\u7684\u5b9e\u4f8b\u3002 NumPy\u7684\u6bcf\u4e2a\u4e8c\u5143ufunc\uff08\u901a\u7528\u51fd\u6570\uff09\u90fd\u6709\u7279\u6b8a\u7684\u65b9\u6cd5\u6765\u6267\u884c\u67d0\u4e9b\u7279\u6b8a\u7684\u5411\u91cf\u5316\u64cd\u4f5c\u3002 reduce \u65b9\u6cd5\u63a5\u6536\u5355\u4e2a\u6570\u7ec4\u5e76\u901a\u8fc7\u6267\u884c\u4e00\u7cfb\u5217\u4e8c\u5143\u64cd\u4f5c\u5728\u6307\u5b9a\u7684\u8f74\u5411\u4e0a\u5bf9\u6570\u7ec4\u7684\u503c\u8fdb\u884c\u805a\u5408\u3002 \u4f8b\u5982\uff0c\u4f7f\u7528np.add.reduce\u662f\u5bf9\u6570\u7ec4\u4e2d\u5143\u7d20\u8fdb\u884c\u52a0\u548c\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\uff1a\u8d77\u59cb\u503c\uff08\u5bf9\u4e8eadd\u65b9\u6cd5\u662f0\uff09\u53d6\u51b3\u4e8eufunc\u3002\u5982\u679c\u4f20\u9012\u4e86\u4e00\u4e2a\u8f74\uff0c\u5219\u6cbf\u8be5\u8f74\u6267\u884c\u7f29\u805a\uff08collapse\uff09\u3002 arr = np.arange(10) a = np.add.reduce(arr) print(a) # 45 a = arr.sum() print(a) # 45 \u4f8b\u5982\uff1a\u4f7f\u7528np.logical_and\u6765\u68c0\u67e5\u6570\u7ec4\u7684\u6bcf\u4e00\u884c\u4e2d\u7684\u503c\u662f\u5426\u88ab\u6392\u5e8f(logical_and.reduce\u7b49\u4ef7\u4e8eall\u65b9\u6cd5)\uff1a arr = np.random.randn(5, 5) print(arr) # [[ 0.75217836 1.26134639 -0.39387918 0.46348823 -1.0026674 ] # [ 0.72085602 -0.50487667 3.21023694 -0.2752039 -1.41158734] # [ 1.69031532 0.61134097 0.58282835 1.03043232 -0.1609196 ] # [-3.05141239 0.47221317 1.36464297 0.17500156 1.26158638] # [-0.21578318 0.37700321 1.05427816 1.56526207 -0.08290142]] # \u5bf9\u6570\u7ec4arr\u884c\u8fdb\u884c\u6392\u5e8f a = arr[::2].sort(1) print(a) # None a = arr[:, :-1] < arr[:, 1:] print(a) # [[ True True True True] # [False True False False] # [ True True True True] # [ True True False True] # [ True True True True]] a = np.logical_and.reduce(arr[:, :-1] < arr[:, 1:], axis=1) print(a) # [ True False True False True] accumulate \u4e0e reduce \u662f\u76f8\u5173\u7684\uff0c\u5c31\u50cf cumsum \u4e0e sum \u76f8\u5173\u4e00\u6837\u3002 accumulate \u751f\u6210\u4e00\u4e2a\u6570\u7ec4\uff0c\u5176\u5c3a\u5bf8\u4e0e\u4e2d\u95f4\u201c\u7d2f\u8ba1\u201d\u503c\u76f8\u540c\uff1a arr = np.arange(15).reshape((3, 5)) print(arr) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] a = np.add.accumulate(arr, axis=1) print(a) # [[ 0 1 3 6 10] # [ 5 11 18 26 35] # [10 21 33 46 60]] outer \u5728\u4e24\u4e2a\u6570\u7ec4\u4e4b\u95f4\u6267\u884c\u6210\u5bf9\u7684\u4ea4\u53c9\u4e58\u79ef\uff1a arr = np.arange(3).repeat([1, 2, 2]) print(arr) # [0 1 1 2 2] a = np.multiply.outer(arr, np.arange(5)) print(a) # [[0 0 0 0 0] # [0 1 2 3 4] # [0 1 2 3 4] # [0 2 4 6 8] # [0 2 4 6 8]] outer \u8f93\u51fa\u7684\u7ef4\u5ea6\u7b49\u4e8e\u8f93\u5165\u7684\u7ef4\u5ea6\u603b\u548c\uff1a x, y = np.random.randn(3, 4), np.random.randn(5) result = np.subtract.outer(x, y) print(result.shape) # (3, 4, 5) reduceat \u65b9\u6cd5\u6267\u884c\u201c\u672c\u5730\u7f29\u805a\u201d\uff0c\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u6570\u7ec4groupby\u64cd\u4f5c\uff0c\u5728\u64cd\u4f5c\u4e2d\u6570\u7ec4\u7684\u5207\u7247\u805a\u5408\u5728\u4e86\u4e00\u8d77\u3002 reduceat \u65b9\u6cd5\u63a5\u53d7\u4e00\u7cfb\u5217\u7684\u201c\u7bb1\u4f53\u8fb9\u7f18\u201d\uff0c\u8fd9\u4e9b\u7bb1\u4f53\u8fb9\u7f18\u8868\u793a\u5982\u4f55\u5206\u9694\u4ee5\u53ca\u805a\u5408\u6570\u636e\u503c\u3002 \u4e0b\u4f8b\u662f\u5728arr\u7684 [0:5) \u3001 [5:8) \u548c [8:] \u4e09\u4e2a\u533a\u95f4\u4e0a\u6267\u884c\u4e86\u7f29\u805a\uff08\u6b64\u5904\u662f\u8ba1\u7b97\u7d2f\u52a0\u548c\uff09\u3002 arr = np.arange(10) a = np.add.reduceat(arr, [0, 5, 8]) print(a) # [10 18 17] \u53ef\u4ee5\u4f20\u9012\u4e00\u4e2aaxis\u53c2\u6570\uff1a arr = np.multiply.outer(np.arange(4), np.arange(5)) print(arr) # [[ 0 0 0 0 0] # [ 0 1 2 3 4] # [ 0 2 4 6 8] # [ 0 3 6 9 12]] a = np.add.reduceat(arr, [0, 2, 4], axis=1) print(a) # [[ 0 0 0] # [ 1 5 4] # [ 2 10 8] # [ 3 15 12]] \u4f7f\u7528Python\u7f16\u5199\u65b0\u7684ufunc\u65b9\u6cd5 \u6709\u5f88\u591a\u5de5\u5177\u53ef\u4ee5\u7528\u4e8e\u521b\u5efa\u4f60\u81ea\u5df1\u7684NumPy ufunc\uff0c\u6700\u5e38\u7528\u7684\u662fNumPy\u7684C\u8bed\u8a00API\uff0c\u4f46\u4e0d\u5728\u8fd9\u91cc\u8ba8\u8bba\u3002\u8fd9\u91cc\u4e3b\u8981\u5173\u6ce8\u7eafPython\u7684ufunc\u65b9\u6cd5\u3002 numpy.frompyfunc \u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u5177\u6709\u7279\u5b9a\u6570\u5b57\u8f93\u5165\u548c\u8f93\u51fa\u7684\u51fd\u6570\u3002\u4f7f\u7528 frompyfunc \u521b\u5efa\u7684\u51fd\u6570\u901a\u5e38\u8fd4\u56de\u7684\u662fPython\u5bf9\u8c61\u7684\u6570\u7ec4\uff0c\u8fd9\u5e76\u4e0d\u65b9\u4fbf\u3002\u8fd8\u6709\u53e6\u4e00\u4e2a\u51fd\u6570 numpy.vectorize \u5141\u8bb8\u6307\u5b9a\u8f93\u51fa\u7684\u7c7b\u578b\uff08\u4f46\u529f\u80fd\u7a0d\u5dee\uff09\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u7b80\u5355\u7684\u6309\u5143\u7d20\u76f8\u52a0\u7684\u51fd\u6570\u53ef\u4ee5\u5982\u4e0b\uff1a def add_elements(x, y): return x + y add_them = np.frompyfunc(add_elements, 2, 1) result = add_them(np.arange(8), np.arange(8)) print(result) # [0 2 4 6 8 10 12 14] add_them = np.vectorize(add_elements, otypes=[np.float64]) result = add_them(np.arange(8), np.arange(8)) print(result) # [ 0. 2. 4. 6. 8. 10. 12. 14.] \u7ed3\u6784\u5316\u548c\u8bb0\u5f55\u5f0f\u6570\u7ec4 ndarray \u662f\u4e00\u4e2a\u540c\u6784\u6570\u636e\u7684\u5bb9\u5668\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u8868\u793a\u4e00\u4e2a\u5185\u5b58\u5757\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5360\u7528\u76f8\u540c\u6570\u91cf\u7684\u5b57\u8282\uff0c\u7531dtype\u786e\u5b9a\u3002 ndarray \u7684\u8fd9\u79cd\u7279\u6027\u4e0d\u80fd\u7528\u6765\u8868\u793a\u5f02\u6784\u7684\u6570\u636e\u6216\u8868\u683c\u578b\u6570\u636e\u3002 \u7ed3\u6784\u5316\u6570\u7ec4 \u662f\u4e00\u4e2a ndarray \uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u4ee3\u8868C\u4e2d\u7684struct\uff08\u56e0\u6b64\u662f\u201c\u7ed3\u6784\u5316\u201d\u7684\u540d\u79f0\uff09\uff0c\u6216\u8005\u662fSQL\u8868\u4e2d\u5177\u6709\u591a\u4e2a\u547d\u540d\u5b57\u6bb5\u7684\u884c\uff1a dtype = [('x', np.float64), ('y', np.int32)] sarr = np.array( [ (1.5, 6), (np.pi, -2) ], dtype=dtype ) print(sarr) # [(1.5 , 6) (3.14159265, -2)] \u6709\u51e0\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6307\u5b9a\u7ed3\u6784\u5316\u7684dtype\uff08\u8bf7\u53c2\u9605NumPy\u5b98\u65b9\u5728\u7ebf\u6587\u6863\uff09\u3002\u4e00\u79cd\u5178\u578b\u7684\u65b9\u5f0f\u662f\u4f7f\u7528(field_name, field_data_type)\u4f5c\u4e3a\u5143\u7ec4\u7684\u5217\u8868\u3002 \u6570\u7ec4\u7684\u5143\u7d20\u662f\u5143\u7ec4\u5bf9\u8c61\uff0c\u5176\u5143\u7d20\u53ef\u4ee5\u50cf\u5b57\u5178\u4e00\u6837\u8bbf\u95ee\uff0c\u5b57\u6bb5\u540d\u79f0\u5b58\u50a8\u5728dtype.names\u5c5e\u6027\u4e2d\u3002 print(sarr[0]) # (1.5, 6) print(sarr['x']) # [1.5 3.14159265] print(sarr[0]['y']) # 6 \u5d4c\u5957dtype\u548c\u591a\u7ef4\u5b57\u6bb5 \u5f53\u6307\u5b9a\u7ed3\u6784\u5316\u7684dtype\u65f6\uff0c\u53ef\u4ee5\u53e6\u5916\u4f20\u9012\u4e00\u4e2a\u5f62\u72b6\uff08\u4ee5int\u6216\u5143\u7ec4\u7684\u5f62\u5f0f\uff09\uff1a dtype = [('x', np.int64, 3), ('y', np.int32)] arr = np.zeros(4, dtype=dtype) print(arr) # [([0, 0, 0], 0) ([0, 0, 0], 0) ([0, 0, 0], 0) ([0, 0, 0], 0)] x \u5b57\u6bb5\u5f15\u7528\u7684\u662f\u6bcf\u6761\u8bb0\u5f55\u4e2d\u957f\u5ea6\u4e3a3\u7684\u6570\u7ec4\uff1a print(arr[0]['x']) # [0 0 0] \u8bbf\u95ee arr['x'] \u7136\u540e\u8fd4\u56de\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\uff0c\u800c\u4e0d\u662f\u8fd4\u56de\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\uff1a print(arr['x']) # [[0 0 0] # [0 0 0] # [0 0 0] # [0 0 0]] \u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u7ed3\u6784\u5316\u6570\u7ec4 \u4e0epandas\u7684DataFrame\u76f8\u6bd4\uff0cNumPy\u7ed3\u6784\u5316\u6570\u7ec4\u662f\u4e00\u4e2a\u76f8\u5bf9\u5e95\u5c42\u7684\u5de5\u5177\u3002 \u7ed3\u6784\u5316\u6570\u7ec4\u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u5185\u5b58\u5757\u89e3\u91ca\u4e3a\u5177\u6709\u4efb\u610f\u590d\u6742\u5d4c\u5957\u5217\u7684\u8868\u683c\u7ed3\u6784\u7684\u65b9\u6cd5\u3002 \u7531\u4e8e\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5728\u5185\u5b58\u4e2d\u8868\u793a\u4e3a\u56fa\u5b9a\u6570\u91cf\u7684\u5b57\u8282\uff0c\u56e0\u6b64\u7ed3\u6784\u5316\u6570\u7ec4\u63d0\u4f9b\u4e86\u8bfb/\u5199\u78c1\u76d8\uff08\u5305\u62ec\u5185\u5b58\u6620\u5c04\uff09\u6570\u636e\uff0c\u4ee5\u53ca\u5728\u7f51\u7edc\u4e0a\u4f20\u8f93\u6570\u636e\u548c\u5176\u4ed6\u6b64\u7c7b\u7528\u9014\u7684\u975e\u5e38\u5feb\u901f\u6709\u6548\u7684\u65b9\u6cd5\u3002 \u4f5c\u4e3a\u7ed3\u6784\u5316\u6570\u7ec4\u7684\u53e6\u4e00\u79cd\u5e38\u89c1\u7528\u9014\uff0c\u5c06\u6570\u636e\u6587\u4ef6\u7f16\u5199\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u8bb0\u5f55\u5b57\u8282\u6d41\u662f\u5c06C\u548cC ++\u4ee3\u7801\u4e2d\u7684\u6570\u636e\u5e8f\u5217\u5316\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u8fd9\u5728\u4e1a\u754c\u4f20\u7edf\u7cfb\u7edf\u4e2d\u5f88\u5e38\u89c1\u3002 \u53ea\u8981\u77e5\u9053\u6587\u4ef6\u7684\u683c\u5f0f\uff08\u6bcf\u4e2a\u8bb0\u5f55\u7684\u5927\u5c0f\u4ee5\u53ca\u6bcf\u4e2a\u5143\u7d20\u7684\u987a\u5e8f\u3001\u5b57\u8282\u5927\u5c0f\u548c\u6570\u636e\u7c7b\u578b\uff09\uff0c\u5c31\u53ef\u4ee5\u7528np.fromfile\u5c06\u6570\u636e\u8bfb\u5165\u5185\u5b58\u3002","title":"NumPy\u8fdb\u9636"},{"location":"python/DataAnalysis/ch10/#numpy","text":"\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a ndarray\u5bf9\u8c61\u7684\u5185\u90e8\u673a\u7406 \u9ad8\u7ea7\u6570\u7ec4\u64cd\u4f5c \u91cd\u5851\u6570\u7ec4 C\u987a\u5e8f\u548cF\u987a\u5e8f \u8fde\u63a5\u548c\u5206\u9694\u6570\u7ec4 \u5806\u53e0\u52a9\u624b\uff1ar \u548cc \u91cd\u590d\u5143\u7d20\uff1atile\u548crepeat \u795e\u5947\u7d22\u5f15\u7684\u7b49\u4ef7\u65b9\u6cd5\uff1atake\u548cput \u5e7f\u64ad ufunc\u9ad8\u7ea7\u5e94\u7528 \u7ed3\u6784\u5316\u548c\u8bb0\u5f55\u5f0f\u6570\u7ec4","title":"NumPy\u8fdb\u9636"},{"location":"python/DataAnalysis/ch10/#ndarray","text":"NumPy\u7684 ndarray \u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u540c\u8d28\u6570\u636e\u5757\uff08\u53ef\u4ee5\u662f\u8fde\u7eed\u6216\u8de8\u8d8a\uff09\u89e3\u91ca\u4e3a\u591a\u7ef4\u6570\u7ec4\u5bf9\u8c61\u7684\u65b9\u5f0f\u3002 ndarray \u7684\u6570\u636e\u7c7b\u578b dtype \u51b3\u5b9a\u4e86\u6570\u636e\u7684\u89e3\u91ca\u65b9\u5f0f\uff0c\u6bd4\u5982\u6d6e\u70b9\u6570\u3001\u6574\u6570\u3001\u5e03\u5c14\u503c\u7b49\u3002 ndarray \u7684\u6240\u6709\u6570\u7ec4\u5bf9\u8c61\u90fd\u662f\u6570\u636e\u5757\u7684\u4e00\u4e2a\u8de8\u5ea6\u89c6\u56fe\uff08strided view\uff09\u3002 \u6570\u7ec4\u89c6\u56fe arr[::2,::-1] \u4e0d\u590d\u5236\u4efb\u4f55\u6570\u636e\u7684\u539f\u56e0\u662f\u4ec0\u4e48\uff1f \u7b80\u5355\u5730\u8bf4\uff0c ndarray \u4e0d\u53ea\u662f\u4e00\u5757\u5185\u5b58\u548c\u4e00\u4e2a dtype \uff0c\u5b83\u8fd8\u6709\u8de8\u5ea6\u4fe1\u606f\uff0c\u8fd9\u4f7f\u5f97\u6570\u7ec4\u80fd\u4ee5\u5404\u79cd\u6b65\u5e45\uff08step size\uff09\u5728\u5185\u5b58\u4e2d\u79fb\u52a8\u3002 \u66f4\u51c6\u786e\u5730\u8bb2\uff0c ndarray \u5185\u90e8\u7531\u4ee5\u4e0b\u5185\u5bb9\u7ec4\u6210\uff1a \u4e00\u4e2a\u6307\u5411\u6570\u636e\uff08\u5185\u5b58\u6216\u5185\u5b58\u6620\u5c04\u6587\u4ef6\u4e2d\u7684\u4e00\u5757\u6570\u636e\uff09\u7684\u6307\u9488\u3002 \u6570\u636e\u7c7b\u578b\u6216 dtype \uff0c\u63cf\u8ff0\u5728\u6570\u7ec4\u4e2d\u7684\u56fa\u5b9a\u5927\u5c0f\u503c\u7684\u683c\u5b50\u3002 \u4e00\u4e2a\u8868\u793a\u6570\u7ec4\u5f62\u72b6\uff08shape\uff09\u7684\u5143\u7ec4\u3002 \u4e00\u4e2a\u8de8\u5ea6\u5143\u7ec4\uff08stride\uff09\uff0c\u5176\u4e2d\u7684\u6574\u6570\u6307\u7684\u662f\u4e3a\u4e86\u524d\u8fdb\u5230\u5f53\u524d\u7ef4\u5ea6\u4e0b\u4e00\u4e2a\u5143\u7d20\u9700\u8981\u201c\u8de8\u8fc7\u201d\u7684\u5b57\u8282\u6570\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a10\u00d75\u7684\u6570\u7ec4\uff0c\u5176shape\u4e3a(10, 5)\uff1a s = np.ones((10, 5)).shape print(s) # (10, 5) \u4e00\u4e2a\u5178\u578b\u7684\uff08C\u9636\uff093\u00d74\u00d75 float64\u503c\uff088\u5b57\u8282\uff09\u7684\u6570\u7ec4\u5177\u6709\u8de8\u5ea6\uff08160,40,8\uff09\uff08\u901a\u5e38\u7279\u5b9a\u8f74\u4e0a\u7684\u8de8\u5ea6\u8d8a\u5927\uff0c\u6cbf\u7740\u8be5\u8f74\u6267\u884c\u8ba1\u7b97\u7684\u4ee3\u4ef7\u8d8a\u9ad8\uff09\uff1a s = np.ones((3, 4, 5), dtype=np.float64).strides print(s) # (160, 40, 8) \u6570\u7ec4\u8de8\u5ea6\uff08strides\uff09\u662f\u6784\u5efa\u201c\u96f6\u590d\u5236\u201d\u6570\u7ec4\u89c6\u56fe\u7684\u5173\u952e\u56e0\u7d20\u3002 \u6570\u7ec4\u8de8\u5ea6\u751a\u81f3\u53ef\u4ee5\u662f\u8d1f\u7684\uff0c\u8fd9\u4f7f\u5f97\u6570\u7ec4\u80fd\u591f\u7a7f\u8fc7\u5185\u5b58\u201c\u5411\u540e\u201d\u79fb\u52a8\uff08\u4f8b\u5982\uff0c\u5728\u8bf8\u5982obj[::-1]\u6216obj[:, ::-1]\u7684\u5207\u7247\u4e2d\u5c31\u662f\u8fd9\u79cd\u60c5\u51b5\uff09\u3002","title":"ndarray\u5bf9\u8c61\u7684\u5185\u90e8\u673a\u7406"},{"location":"python/DataAnalysis/ch10/#numpy-dtype","text":"\u6709\u65f6\u5019\u9700\u8981\u901a\u8fc7\u4e00\u4e9b\u4ee3\u7801\u6765\u68c0\u67e5\u6570\u7ec4\u662f\u5426\u5305\u542b\u6574\u6570\u3001\u6d6e\u70b9\u6570\u3001\u5b57\u7b26\u4e32\u6216Python\u5bf9\u8c61\u3002 \u7531\u4e8e\u6d6e\u70b9\u6570\u6709\u591a\u79cd\u7c7b\u578b\uff08float16\u5230float128\uff09\uff0c\u56e0\u6b64\u68c0\u67e5dtype\u662f\u5426\u5728\u7c7b\u578b\u5217\u8868\u4e2d\u4f1a\u975e\u5e38\u9ebb\u70e6\u3002 dtype\u6709\u8d85\u7c7b\uff0c\u5982np.integer\u548cnp.floating\uff0c\u5b83\u4eec\u53ef\u4ee5\u548cnp.issubdtype\u51fd\u6570\u4e00\u8d77\u4f7f\u7528\uff1a ints = np.ones(10, dtype=np.uint16) floats = np.ones(10, dtype=np.float32) \u53ef\u4ee5\u901a\u8fc7\u8c03\u7528\u7c7b\u578b\u7684mro\u65b9\u6cd5\u6765\u67e5\u770b\u7279\u5b9adtype\u7684\u6240\u6709\u7236\u7c7b\uff1a print(np.float64.mro()) # [<class 'numpy.float64'>, # <class 'numpy.floating'>, # <class 'numpy.inexact'>, # <class 'numpy.number'>, # <class 'numpy.generic'>, # <class 'float'>, # <class 'object'>] print(np.issubdtype(ints.dtype, np.integer)) # True print(np.issubdtype(floats.dtype, np.floating)) # True print(np.issubdtype(floats.dtype, np.number)) # True print(np.issubdtype(floats.dtype, np.generic)) # True","title":"NumPy dtype\u5c42\u6b21\u7ed3\u6784"},{"location":"python/DataAnalysis/ch10/#_1","text":"","title":"\u9ad8\u7ea7\u6570\u7ec4\u64cd\u4f5c"},{"location":"python/DataAnalysis/ch10/#_2","text":"\u901a\u5e38\uff0c\u901a\u8fc7 reshape \u5c06\u6570\u7ec4\u4ece\u4e00\u4e2a\u5f62\u72b6\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u5f62\u72b6\uff0c\u5e76\u4e14\u4e0d\u590d\u5236\u4efb\u4f55\u6570\u636e\u3002 reshape \u91cc\u9762\u6709\u4e24\u79cd\u91cd\u5851\u987a\u5e8f\uff0c\u6309C\u987a\u5e8f\uff08\u884c\u65b9\u5411\uff09\u7684\u91cd\u5851\u548c\u6309Fortran\u987a\u5e8f\uff08\u5217\u65b9\u5411\uff09\u7684\u91cd\u5851\u3002 \u9996\u5148\u662f\u53d6\u6570\uff0c\u7136\u540e\u662f\u653e\u6570\uff0c\u53d6\u6570\u6309\u4ec0\u4e48\u987a\u5e8f\uff0c\u653e\u6570\u5c31\u6309\u4ec0\u4e48\u987a\u5e8f\u3002 \u4e0b\u9762\u662f\u5b98\u7f51\u7684\u89e3\u91ca\uff1a \u2018C\u2019 means to read / write the elements using C-like index order, with the last axis index changing fastest, back to the first axis index changing slowest. \u2018F\u2019 means to read / write the elements using Fortran-like index order, with the first index changing fastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of the memory layout of the underlying array, and only refer to the order of indexing. \u2018A\u2019 means to read / write the elements in Fortran-like index order if a is Fortran contiguous in memory, C-like order otherwise. \u4e00\u7ef4\u6570\u7ec4\u91cd\u5851\uff1a arr = np.arange(8) print(arr) # [0 1 2 3 4 5 6 7] a = arr.reshape((4, 2), order='C') print(a) # [[0 1] # [2 3] # [4 5] # [6 7]] a = arr.reshape((4, 2), order='F') print(a) # [[0 4] # [1 5] # [2 6] # [3 7]] \u591a\u7ef4\u6570\u7ec4\u91cd\u5851\uff1a\u4f20\u9012\u7684\u5f62\u72b6\u7ef4\u5ea6\u53ef\u4ee5\u6709\u4e00\u4e2a\u503c\u662f-1\uff0c\u8868\u793a\u7ef4\u5ea6\u901a\u8fc7\u6570\u636e\u8fdb\u884c\u63a8\u65ad\uff1a a = arr.reshape((4, 2)).reshape((2, 4)) print(a) # [[0 1 2 3] # [4 5 6 7]] arr = np.arange(15) a = arr.reshape((5, -1)) # 15 / 5 = 3\u5217 print(a) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] print(a.shape) # (5, 3) \u6570\u7ec4\u7684 shape \u5c5e\u6027\u662f\u4e00\u4e2a \u5143\u7ec4 \uff0c\u5b83\u4e5f\u53ef\u4ee5\u88ab\u4f20\u9012\u7ed9 reshape \uff0c\u63a5\u4e0a\u4f8b\uff1a other_arr = np.ones((3, 5)) print(other_arr.shape) # (3, 5) a = arr.reshape(other_arr.shape) print(a.shape) # (3, 5) reshape \u7684\u53cd\u64cd\u4f5c\u53ef\u4ee5\u5c06\u66f4\u9ad8\u7ef4\u5ea6\u7684\u6570\u7ec4\u8f6c\u6362\u4e3a\u4e00\u7ef4\u6570\u7ec4\uff0c\u8fd9\u79cd\u64cd\u4f5c\u901a\u5e38\u88ab\u6210\u4e3a\u6241\u5e73\u5316\uff08flattening\uff09\u6216\u5206\u6563\u5316\uff08raveling\uff09\u3002 \u5982\u679c\u7ed3\u679c\u4e2d\u7684\u503c\u5728\u539f\u59cb\u6570\u7ec4\u4e2d\u662f\u8fde\u7eed\u7684\uff0c\u5219 ravel \u4e0d\u4f1a\u751f\u6210\u5e95\u5c42\u6570\u503c\u7684\u526f\u672c\u3002 flatten \u65b9\u6cd5\u7684\u884c\u4e3a\u7c7b\u4f3c\u4e8e ravel \uff0c\u4f46\u5b83\u603b\u662f\u751f\u6210\u6570\u636e\u7684\u526f\u672c\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] a = arr.ravel() print(a) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] a = arr.flatten() print(a) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14]","title":"\u91cd\u5851\u6570\u7ec4"},{"location":"python/DataAnalysis/ch10/#cf","text":"\u6570\u636e\u53ef\u4ee5\u6309\u7167\u4e0d\u540c\u7684\u987a\u5e8f\u8fdb\u884c\u91cd\u5851\u6216\u6241\u5e73\u5316\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cNumPy\u6570\u7ec4\u662f\u6309\u884c\u65b9\u5411\u987a\u5e8f\u521b\u5efa\u7684\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u4e8c\u7ef4\u7684\u6570\u636e\u6570\u7ec4\uff0c C\u987a\u5e8f \u8bf4\u660e\u6570\u7ec4\u6bcf\u884c\u4e2d\u7684\u5143\u7d20\u5b58\u50a8\u5728\u76f8\u90bb\u7684\u5b58\u50a8\u5355\u5143\u4e2d\u3002 F\u987a\u5e8f \u610f\u5473\u7740\u6bcf\u5217\u6570\u636e\u4e2d\u7684\u503c\u90fd\u5b58\u50a8\u5728\u76f8\u90bb\u7684\u5185\u5b58\u4f4d\u7f6e\u4e2d\u3002 \u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e reshape \u548c ravel \u51fd\u6570\u7684 order \u53c2\u6570\u6765\u8868\u793a\u6570\u636e\u5728\u6570\u7ec4\u4e2d\u4f7f\u7528\u54ea\u79cd\u987a\u5e8f\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] print(arr.ravel()) # [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] print(arr.ravel('F')) # [ 0 3 6 9 12 1 4 7 10 13 2 5 8 11 14] C\u987a\u5e8f\u548cFortran\u987a\u5e8f\u7684\u6838\u5fc3\u533a\u522b\u5c31\u662f\u5728\u7ef4\u5ea6\u65b9\u5411\u4e0a\u904d\u5386\u7684\u65b9\u5f0f\u3002 C\u987a\u5e8f/\u884c\u65b9\u5411\u987a\u5e8f\u9996\u5148\u904d\u5386\u66f4\u9ad8\u7684\u7ef4\u5ea6\uff08\u4f8b\u5982\uff0c\u5728\u8f740\u4e0a\u884c\u8fdb\u4e4b\u524d\u5148\u5728\u8f741\u4e0a\u884c\u8fdb\uff09\u3002 Fortran\u987a\u5e8f/\u5217\u65b9\u5411\u987a\u5e8f\u6700\u540e\u904d\u5386\u66f4\u9ad8\u7684\u7ef4\u5ea6\uff08\u4f8b\u5982\uff0c\u5728\u8f741\u4e0a\u884c\u8fdb\u4e4b\u524d\u5148\u5728\u8f740\u4e0a\u884c\u8fdb\uff09\u3002","title":"C\u987a\u5e8f\u548cF\u987a\u5e8f"},{"location":"python/DataAnalysis/ch10/#_3","text":"numpy.concatenate \u53ef\u4ee5\u83b7\u53d6\u6570\u7ec4\u7684\u5e8f\u5217\uff08\u5143\u7ec4\u3001\u5217\u8868\u7b49\uff09\uff0c\u5e76\u6cbf\u7740\u8f93\u5165\u8f74\u5c06\u5b83\u4eec\u6309\u987a\u5e8f\u8fde\u63a5\u5728\u4e00\u8d77\uff1a arr1 = np.array( [ [1, 2, 3], [4, 5, 6] ] ) arr2 = np.array( [ [7, 8, 9], [10, 11, 12] ] ) a = np.concatenate([arr1, arr2], axis=0) print(a) # [[ 1 2 3] # [ 4 5 6] # [ 7 8 9] # [10 11 12]] a = np.concatenate([arr1, arr2], axis=1) print(a) # [[ 1 2 3 7 8 9] # [ 4 5 6 10 11 12]] \u5176\u4ed6\u7c7b\u4f3c concatenate \u7684\u51fd\u6570\u3002 vstack \u7c7b\u4f3c concatenate \u6cbf axis=0 \u64cd\u4f5c\uff0c hstack \u7c7b\u4f3c concatenate \u6cbf axis=1 \u64cd\u4f5c\u3002 a = np.vstack((arr1, arr2)) print(a) # [[ 1 2 3] # [ 4 5 6] # [ 7 8 9] # [10 11 12]] a = np.hstack((arr1, arr2)) print(a) # [[ 1 2 3 7 8 9] # [ 4 5 6 10 11 12]] split \u53ef\u4ee5\u5c06\u4e00\u4e2a\u6570\u7ec4\u6cbf\u8f74\u5411\u5207\u7247\u6210\u591a\u4e2a\u6570\u7ec4\u3002\u5148\u770b\u4e00\u7ef4\u6570\u7ec4\u3002 np.split(arr, 3) \u8868\u793a\u5c06\u6570\u7ec4\u62c6\u5206\u65f6\u7684 \u7d22\u5f15\u4f4d\u7f6e arr = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']) print(arr) # ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k'] print(np.split(arr, 3)) print(np.split(arr, [3])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g', 'h', 'i', 'j', 'k'], dtype='<U1')] print(np.split(arr, [3, 7])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u548c7\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g'], dtype='<U1'), array(['h', 'i', 'j', 'k'], dtype='<U1')] print(np.split(arr, [3, 7, 9])) # \u4ece\u7d22\u5f15\u4f4d\u7f6e\u4e3a3\u30017\u30019\u8fdb\u884c\u62c6\u5206 # [array(['a', 'b', 'c'], dtype='<U1'), array(['d', 'e', 'f', 'g'], dtype='<U1'), array(['h', 'i'], dtype='<U1'), array(['j', 'k'], dtype='<U1')] \u4e8c\u7ef4\u6570\u7ec4\u548c\u4e00\u7ef4\u6570\u7ec4\u7c7b\u4f3c\u3002 np.split(arr, [1, 2]) \u9ed8\u8ba4axis=0\uff0c\u6cbf\u6c34\u5e73\u65b9\u5411\u8fdb\u884c\u62c6\u5206\uff0c\u62c6\u5206\u884c\u7d22\u5f15\u5206\u522b\u4e3a\u884c\u53f71\u548c\u884c\u53f72\uff0c\u5373[0, 1)\uff0c[1, 2)\uff0c[2, 4]\u4e09\u4e2a\u884c\u533a\u95f4\u3002 np.split(arr, [1, 2], axis=1) \u6cbf\u5782\u76f4\u65b9\u5411\u8fdb\u884c\u62c6\u5206\uff0c\u62c6\u5206\u5217\u7d22\u5f15\u5206\u522b\u4e3a\u5217\u53f71\u548c\u5217\u53f72\uff0c\u5373[0, 1)\uff0c[1, 2)\uff0c[2, 3]\u4e09\u4e2a\u5217\u533a\u95f4\u3002 \u5982\u679c\u62c6\u5206\u533a\u95f4\u51fa\u73b0\u5012\u5e8f\uff0c\u5982 np.split(arr, [3, 1]) \uff0c\u6cbf\u6c34\u5e73\u65b9\u5411\u62c6\u5206\uff0c\u7b2c\u4e00\u4e2a\u884c\u533a\u95f4\u662f[0, 3)\uff0c\u7b2c\u4e8c\u4e2a\u884c\u533a\u95f4\u662f[3, 1)\uff0c\u65e0\u7ed3\u679c\uff0c\u5f53\u524d\u884c\u7d22\u5f15\u4e3a0\uff0c\u672a\u8fbe\u5230\u6700\u5927\u884c\u6570\uff0c\u6240\u4ee5\u8f93\u51fa\u7b2c\u4e09\u4e2a\u533a\u95f4[1, 4]\u3002\u540c\u7406\u53ef\u63a8 np.split(arr, [3, 1], axis=1) \u7684\u4e09\u4e2a\u5217\u533a\u95f4\u3002 arr = np.arange(15).reshape((5, 3)) print(arr) # [[ 0 1 2] # [ 3 4 5] # [ 6 7 8] # [ 9 10 11] # [12 13 14]] result = np.split(arr, [1, 2]) print(result) # [array([[0, 1, 2]]), # array([[3, 4, 5]]), # array([[ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]])] result = np.split(arr, [1, 2], axis=1) print(result) # [array([[ 0], # [ 3], # [ 6], # [ 9], # [12]]), # array([[ 1], # [ 4], # [ 7], # [10], # [13]]), # array([[ 2], # [ 5], # [ 8], # [11], # [14]])] result = np.split(arr, [3, 1]) print(result) # [array([[0, 1, 2], # [3, 4, 5], # [6, 7, 8]]), # array([], shape=(0, 3), dtype=int64), # array([[ 3, 4, 5], # [ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]]) result = np.split(arr, [3, 1], axis=1) print(result) # [array([[ 0, 1, 2], # [ 3, 4, 5], # [ 6, 7, 8], # [ 9, 10, 11], # [12, 13, 14]]), # array([], shape=(5, 0), dtype=int64), # array([[ 1, 2], # [ 4, 5], # [ 7, 8], # [10, 11], # [13, 14]])]","title":"\u6570\u7ec4\u8fde\u63a5\u548c\u5206\u9694"},{"location":"python/DataAnalysis/ch10/#r_c_","text":"\u5728NumPy\u4e2d\u6709\u4e24\u4e2a\u7279\u6b8a\u7684\u5bf9\u8c61\uff1ar_\u548cc_\uff0c\u5b83\u4eec\u53ef\u4ee5\u4f7f\u5806\u6808\u6570\u7ec4\u7684\u64cd\u4f5c\u66f4\u4e3a\u7b80\u6d01\uff1a np.r_ \u662f\u6309\u5217\u8fde\u63a5\u4e24\u4e2a\u77e9\u9635\uff0c\u5c31\u662f\u628a\u4e24\u77e9\u9635\u4e0a\u4e0b\u76f8\u52a0\uff0c\u8981\u6c42\u5217\u6570\u76f8\u7b49\u3002 np.c_ \u662f\u6309\u884c\u8fde\u63a5\u4e24\u4e2a\u77e9\u9635\uff0c\u5c31\u662f\u628a\u4e24\u77e9\u9635\u5de6\u53f3\u76f8\u52a0\uff0c\u8981\u6c42\u884c\u6570\u76f8\u7b49\u3002 arr = np.arange(6) arr1 = arr.reshape((3, 2)) arr2 = np.random.randn(3, 2) print(arr) # [0 1 2 3 4 5] print(arr1) # [[0 1] # [2 3] # [4 5]] print(arr2) # [[ 0.15407269 0.56316672] # [-1.2390795 -1.59294986] # [ 0.082398 0.75602857]] a = np.r_[arr1, arr2] print(a) # [[ 0. 1. ] # [ 2. 3. ] # [ 4. 5. ] # [ 0.15407269 0.56316672] # [-1.2390795 -1.59294986] # [ 0.082398 0.75602857]] a = np.c_[arr1, arr2] print(a) # [[ 0. 1. 0.15407269 0.56316672] # [ 2. 3. -1.2390795 -1.59294986] # [ 4. 5. 0.082398 0.75602857]] a = np.c_[np.r_[arr1, arr2], arr] print(a) # [[ 0. 1. 0. ] # [ 2. 3. 1. ] # [ 4. 5. 2. ] # [ 0.15407269 0.56316672 3. ] # [-1.2390795 -1.59294986 4. ] # [ 0.082398 0.75602857 5. ]] \u8fd8\u53ef\u4ee5\u5c06\u5207\u7247\u8f6c\u6362\u4e3a\u6570\u7ec4\uff1a a = np.c_[1:6, -10:-5] print(a) # [[ 1 -10] # [ 2 -9] # [ 3 -8] # [ 4 -7] # [ 5 -6]]","title":"\u6570\u7ec4\u5806\u53e0\u7684\u65b9\u6cd5\uff1ar_\u548cc_"},{"location":"python/DataAnalysis/ch10/#tilerepeat","text":"repeat \u548c tile \u51fd\u6570\u662f\u7528\u4e8e\u91cd\u590d\u6216\u590d\u5236\u6570\u7ec4\u7684\u4e24\u4e2a\u6709\u7528\u7684\u5de5\u5177\u3002 repeat \u51fd\u6570\u6309\u7167\u7ed9\u5b9a\u6b21\u6570\u5bf9\u6570\u7ec4\u4e2d\u7684 \u6bcf\u4e2a\u5143\u7d20 \u8fdb\u884c\u590d\u5236\uff0c\u751f\u6210\u4e00\u4e2a\u66f4\u5927\u7684\u6570\u7ec4\u3002 \u5bf9\u4e8eNumPy\u800c\u8a00\uff0c\u590d\u5236\u6216\u91cd\u590d\u6570\u7ec4\u7684\u9700\u6c42\u53ef\u80fd\u4e0d\u5982\u5176\u4ed6\u6570\u7ec4\u7f16\u7a0b\u6846\u67b6\uff08\u5982MATLAB\uff09\u90a3\u6837\u5e38\u89c1\u3002\u5176\u4e2d\u4e00\u4e2a\u539f\u56e0\u662f\u5e7f\u64ad\u901a\u5e38\u4f1a\u66f4\u597d\u5730\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u3002 arr = np.arange(3) print(arr) # [0 1 2] a = arr.repeat(3) print(a) # [0 0 0 1 1 1 2 2 2] \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u4f60\u4f20\u9012\u4e00\u4e2a\u6574\u6570\uff0c\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u590d\u5236\u76f8\u5e94\u7684\u6b21\u6570\u3002\u5982\u679c\u4f60\u4f20\u9012\u4e86\u4e00\u4e2a\u6574\u6570\u6570\u7ec4\uff0c\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u91cd\u590d\u76f8\u5e94\u7684\u4e0d\u540c\u6b21\u6570\uff1a arr = np.arange(3) print(arr) # [0 1 2] a = arr.repeat([2, 3, 4]) print(a) # [0 0 1 1 1 2 2 2 2] \u591a\u7ef4\u6570\u7ec4\u53ef\u4ee5\u5728\u6307\u5b9a\u7684\u8f74\u5411\u4e0a\u5bf9\u5b83\u4eec\u7684\u5143\u7d20\u8fdb\u884c\u91cd\u590d\uff0c\u6ce8\u610f\uff0c\u5982\u679c\u6ca1\u6709\u4f20\u9012\u8f74\uff0c\u6570\u7ec4\u5c06\u9996\u5148\u6241\u5e73\u5316\uff08\u6cbf0\u8f74\u590d\u5236\uff09\u3002 arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = arr.repeat(2, axis=0) print(a) # [[-0.15870621 0.26521446] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376]] a = arr.repeat(2, axis=1) print(a) # [[-0.15870621 -0.15870621 0.26521446 0.26521446] # [-1.35042383 -1.35042383 -0.65562376 -0.65562376]] \u540c\u6837\uff0c\u9700\u8981\u6309\u7167\u4e0d\u540c\u6b21\u6570\u91cd\u590d\u591a\u7ef4\u6570\u7ec4\u7684\u5207\u7247\u65f6\uff0c\u53ef\u4ee5\u4f20\u9012\u4e00\u4e2a\u6574\u6570\u6570\u7ec4\uff1a arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = arr.repeat([2, 3], axis=0) print(a) # [[-0.15870621 0.26521446] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376] # [-1.35042383 -0.65562376]] tile \u662f\u4e00\u79cd\u5feb\u6377\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u6cbf\u7740\u8f74\u5411\u5806\u53e0\u526f\u672c\u3002\u5728\u89c6\u89c9\u4e0a\uff0c\u4f60\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u7c7b\u4f3c\u4e8e\u201c\u94fa\u8bbe\u74f7\u7816\u201d\u3002 np.tile(arr, 2) \u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u74f7\u7816\u7684\u6570\u91cf\u3002\u7528\u6807\u91cf\u6765\u8bf4\uff0c\u94fa\u8bbe\u662f\u9010\u884c\u8fdb\u884c\u7684\uff0c\u800c\u4e0d\u662f\u9010\u5217\uff0c\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e5f\u53ef\u4ee5\u662f\u8868\u793a\u201c\u94fa\u74f7\u7816\u201d\u5e03\u5c40\u7684\u5143\u7ec4\u3002 arr = np.random.randn(2, 2) print(arr) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = np.tile(arr, 2) print(a) # [[-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376]] a = np.tile(arr, (2, 1)) print(a) # [[-0.15870621 0.26521446] # [-1.35042383 -0.65562376] # [-0.15870621 0.26521446] # [-1.35042383 -0.65562376]] a = np.tile(arr, (3, 2)) print(a) # [[-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376] # [-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376] # [-0.15870621 0.26521446 -0.15870621 0.26521446] # [-1.35042383 -0.65562376 -1.35042383 -0.65562376]]","title":"\u91cd\u590d\u5143\u7d20\uff1atile\u548crepeat"},{"location":"python/DataAnalysis/ch10/#fancy-indexingtakeput","text":"take \u51fd\u6570\u53ef\u4ee5\u83b7\u53d6\u6570\u7ec4\u5b50\u96c6\uff0c put \u51fd\u6570\u53ef\u4ee5\u8bbe\u7f6e\u6570\u7ec4\u5b50\u96c6\u3002\u5176\u4ed6\u4e00\u4e9bndarray\u65b9\u6cd5\u53ef\u4ee5\u7528\u4e8e\u7279\u6b8a\u60c5\u51b5\u4e0b\u5728\u5355\u4e2a\u8f74\u4e0a\u7684\u6570\u636e\u9009\u53d6. arr = np.arange(10) * 100 inds = [7, 1, 2, 6] print(arr) # [ 0 100 200 300 400 500 600 700 800 900] print(inds) # [7, 1, 2, 6] # \u4ecearr\u5e8f\u5217\u4e2d\u4f9d\u6b21\u83b7\u53d6\u7d22\u5f15\u4e3a7,1,2,6\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u3002 a = np.take(arr, inds) print(a) # [700 100 200 600] print(arr) # [ 0 100 200 300 400 500 600 700 800 900] arr = np.arange(10) * 100 inds = [7, 1, 2, 6] # \u76f8\u5f53\u4e8e\u5c06arr\u5e8f\u5217\u4e2d\u7d22\u5f15\u4e3a7,1,2,6\u4f4d\u7f6e\u4e0a\u7684\u5143\u7d20\u752842\u6765\u66ff\u6362 np.put(arr, inds, 41) print(arr) # [ 0 41 41 300 400 500 41 41 800 900] arr = np.arange(10) * 100 inds = [7, 1, 2, 6] np.put(arr, inds, [40, 41, 42]) print(arr) # [ 0 41 42 300 400 500 40 40 800 900] \u6ce8\u610f\uff0c\u4e0a\u4f8b\u5982\u679c\u6539\u5199\u4e3a a = np.put(arr, inds, 41) \uff0c\u5219\u8fd4\u56de None \u3002 a = np.put(arr, inds, 41) print(a) # None \u5982\u679c\u8981\u5728\u522b\u7684\u8f74\u4e0a\u4f7f\u7528 take \uff0c\u53ef\u4ee5\u901a\u8fc7\u4f20\u9012 axis \u5173\u952e\u5b57\u6765\u5b9e\u73b0\u3002 inds = [2, 0, 2, 1] arr = np.random.randn(2, 4) print(arr) # [[-0.82371274 -0.16911898 -0.01903239 -0.91792531] # [-0.55176496 -0.30111564 0.33872999 0.32454671]] a = arr.take(inds, axis=1) print(a) # [[-0.01903239 -0.82371274 -0.01903239 -0.16911898] # [ 0.33872999 -0.55176496 0.33872999 -0.30111564]]","title":"\u795e\u5947\u7d22\u5f15\uff08Fancy Indexing\uff09\u7684\u7b49\u4ef7\u65b9\u6cd5\uff1atake\u548cput"},{"location":"python/DataAnalysis/ch10/#_4","text":"\u5e7f\u64ad\uff08broadcasting\uff09 \u6307\u7684\u662f\u4e0d\u540c\u5f62\u72b6\u7684\u6570\u7ec4\u4e4b\u95f4\u7684\u7b97\u672f\u8fd0\u7b97\u7684\u6267\u884c\u65b9\u5f0f\u3002\u53d7\u67d0\u4e9b\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u8f83\u5c0f\u7684\u6570\u7ec4\u5728\u8f83\u5927\u7684\u6570\u7ec4\u4e0a\u201c\u5e7f\u64ad\u201d\uff0c\u4ee5\u4fbf\u5b83\u4eec\u5177\u6709\u517c\u5bb9\u7684\u5f62\u72b6\u3002\u5e7f\u64ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u77e2\u91cf\u5316\u6570\u7ec4\u64cd\u4f5c\u7684\u65b9\u6cd5\u3002 NumPy \u64cd\u4f5c\u901a\u5e38\u5728 \u9010\u4e2a\u5143\u7d20 \u7684\u57fa\u7840\u4e0a\u5728\u6570\u7ec4\u5bf9\u4e0a\u5b8c\u6210\u3002\u5728\u6700\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u4e24\u4e2a\u6570\u7ec4\u5fc5\u987b\u5177\u6709\u5b8c\u5168\u76f8\u540c\u7684\u5f62\u72b6\uff0c\u5982\u4e0b\u4f8b\u6240\u793a\uff1a a = np.array([1, 3, 5]) b = np.array([2, 2, 2]) print(a * b) # [ 2 6 10] print(a + b) # [3 5 7] \u5f53\u4e00\u4e2a\u6570\u7ec4\u548c\u4e00\u4e2a\u6807\u91cf\u503c\u5728\u4e00\u4e2a\u64cd\u4f5c\u4e2d\u7ec4\u5408\u65f6\uff0c\u4f1a\u53d1\u751f\u6700\u7b80\u5355\u7684\u5e7f\u64ad\u793a\u4f8b\uff0cNumPy\u7684\u5e7f\u64ad\u89c4\u5219\u653e\u5bbd\u4e86\u8fd9\u79cd\u7ea6\u675f\u3002 a = np.array([1, 3, 5]) b = 2 print(a * b) # [ 2 6 10] print(a + b) # [3 5 7] \u7ed3\u679c\u7b49\u540c\u4e8e\u524d\u9762\u7684\u793a\u4f8b\uff0c\u5176\u4e2d b \u662f\u6570\u7ec4\u3002\u53ef\u4ee5\u5047\u8c61\u5c06\u5728\u7b97\u672f\u8fd0\u7b97\u671f\u95f4\u6807\u91cf b \u88ab \u62c9\u4f38 \u6210\u4e0e\u6570\u7ec4 a \u5177\u6709\u76f8\u540c\u5f62\u72b6\u7684\u6570\u7ec4\u3002\u62c9\u4f38\u7c7b\u6bd4\u53ea\u662f\u6982\u5ff5\u6027\u7684\u3002NumPy\u5728\u5b9e\u9645\u8fd0\u7b97\u4e2d\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u6807\u91cf\u503c\u800c\u4e0d\u4f1a\u53bb\u5236\u4f5c\u62c9\u4f38\u526f\u672c\uff0c\u56e0\u6b64\u5e7f\u64ad\u64cd\u4f5c\u6548\u7387\u66f4\u9ad8\u6548\uff0c\u5728\u4e0a\u4f8b\u7684\u4e58\u6cd5\u671f\u95f4\uff0c\u901a\u8fc7\u5e7f\u64ad\u64cd\u4f5c\uff0c\u79fb\u52a8\u7684\u5185\u5b58\u8f83\u5c11\uff08b\u662f\u6807\u91cf\u800c\u4e0d\u662f\u6570\u7ec4\uff09\u3002","title":"\u5e7f\u64ad"},{"location":"python/DataAnalysis/ch10/#_5","text":"\u5e7f\u64ad\u7684\u89c4\u5219 \uff1a \u5982\u679c\u4e24\u4e2a\u6570\u7ec4\u7684\u540e\u7f18\u7ef4\u5ea6\uff08trailing dimension\uff0c\u5373\u4ece\u672b\u5c3e\u5f00\u59cb\u7b97\u8d77\u7684\u7ef4\u5ea6\uff09\u7684\u8f74\u957f\u5ea6\u76f8\u7b26\uff0c\u6216\u5176\u4e2d\u7684\u4e00\u65b9\u7684\u957f\u5ea6\u4e3a1\uff0c\u5219\u8ba4\u4e3a\u5b83\u4eec\u662f\u5e7f\u64ad\u517c\u5bb9\u7684\u3002\u5e7f\u64ad\u4f1a\u5728\u7f3a\u5931\u548c\uff08\u6216\uff09\u957f\u5ea6\u4e3a1\u7684\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u3002 \u8fd9\u53e5\u8bdd\u662f\u7406\u89e3\u5e7f\u64ad\u7684\u6838\u5fc3\u3002\u5e7f\u64ad\u4e3b\u8981\u53d1\u751f\u5728\u4e24\u79cd\u60c5\u51b5\uff0c\u4e00\u79cd\u662f\u4e24\u4e2a\u6570\u7ec4\u7684\u7ef4\u6570\u4e0d\u76f8\u7b49\uff0c\u4f46\u662f\u5b83\u4eec\u7684\u540e\u7f18\u7ef4\u5ea6\u7684\u8f74\u957f\u76f8\u7b26\uff0c\u53e6\u5916\u4e00\u79cd\u662f\u6709\u4e00\u65b9\u7684\u957f\u5ea6\u4e3a1\u3002 \u5982\u679c\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\uff0c\u5219\u629b\u51fa ValueError: operands could not be broadcast together \u5f02\u5e38\uff0c\u6307\u793a\u6570\u7ec4\u5177\u6709\u4e0d\u517c\u5bb9\u7684\u5f62\u72b6\u3002\u7ed3\u679c\u6570\u7ec4\u7684\u5927\u5c0f\u662f\u6cbf\u8f93\u5165\u7684\u6bcf\u4e2a\u8f74\u4e0d\u662f1\u7684\u5927\u5c0f\u3002 \u5c06\u6807\u91cf\u503c\u8ddf\u6570\u7ec4\u5408\u5e76\u65f6\u5c31\u4f1a\u53d1\u751f\u6700\u7b80\u5355\u7684\u5e7f\u64ad\uff0c\u6807\u91cf\u503c4\u5df2\u7ecf\u88ab\u5e7f\u64ad\u7ed9\u4e58\u6cd5\u8fd0\u7b97\u4e2d\u7684\u6240\u6709\u5176\u4ed6\u5143\u7d20\u3002 arr = np.arange(5) print(arr * 4) # [ 0 4 8 12 16]","title":"\u5e7f\u64ad\u7684\u89c4\u5219"},{"location":"python/DataAnalysis/ch10/#_6","text":"\u4e0b\u9762\u662f\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\u6cbf0\u8f74\u5e7f\u64ad\u7684\u4f8b\u5b50\uff1a arr1 = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]]) print(arr1.shape) # (4, 3) arr2 = np.array([1, 2, 3]) print(arr2.shape) # (3,) arr_sum = arr1 + arr2 print(arr_sum) # [[1 2 3] # [2 3 4] # [3 4 5] # [4 5 6]] \u4e0a\u4f8b\u4e2d arr1 \u7684 shape \u4e3a (4,3) \uff0c arr2 \u7684 shape \u4e3a (3,) \u3002\u5373\uff0c arr1 \u662f\u4e8c\u7ef4\u6570\u7ec4\uff0c arr2 \u662f\u4e00\u7ef4\u6570\u7ec4\u3002\u867d\u7136\u5b83\u4eec\u7684\u7ef4\u5ea6 shape \u4e0d\u540c\uff0c\u4f46\u540e\u7f18\u7ef4\u5ea6\u90fd\u662f 3 \uff0c\u7b26\u5408\u5e7f\u64ad\u89c4\u5219\uff0c\u6240\u4ee5\u5b83\u4eec\u4e4b\u95f4\u662f\u53ef\u4ee5\u6267\u884c\u76f8\u52a0\u64cd\u4f5c\u3002 \u5728\u8fd9\u4e2a\u4f8b\u5b50\u5f53\u4e2d\u662f\u5c06arr2\u6cbf\u77400\u8f74\u8fdb\u884c\u6269\u5c55\u3002\u76f4\u89c2\u7684\u63cf\u8ff0\u662f\uff0c arr2 \u5728\u53c2\u4e0e\u8fd0\u7b97\u65f6\u662f\u4ee5\u4e0b\u9762\u8fd9\u6837\u7684\u5f62\u5f0f\u8fdb\u884c0\u8f74\u6269\u5c55\u7684\uff08\u6cbf0\u8f74\u6c34\u5e73\u65b9\u5411\u79fb\u52a8\uff0c\u5728\u5217\u65b9\u5411\u8fdb\u884c\u201c\u62c9\u4f38\u201d\uff09\uff1a [[1 2 3] [1 2 3] [1 2 3] [1 2 3]]","title":"\u4e00\u7ef4\u5e7f\u64ad"},{"location":"python/DataAnalysis/ch10/#_7","text":"\u5728\u4e0b\u9762\u884c\u51cf\u5747\u503c\u7684\u4f8b\u5b50\u4e2d\uff0c\u6839\u636e\u89c4\u5219\uff0c\u4e3a\u4e86\u4ece\u8f741\u51cf\u5747\u503c\uff08\u5373\u4ece\u6bcf\u884c\u51cf\u53bb\u884c\u5e73\u5747\u503c\uff09\uff0c\u5bf9\u8f83\u5c0f\u7684\u6570\u7ec4 row_means \u7684\u5851\u5f62\u5fc5\u987b\u662f\uff084, 1\uff09\uff0c\u5373\uff0c\u91cd\u65b0\u5851\u9020\u884c\u610f\u5473\u7740\u5f62\u72b6\u662f\uff084,1\uff09\u800c\u4e0d\u662f\uff084, \uff09\u3002 arr = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 3], [4, 5, 6]]) print(arr) # [[1 2 3] # [4 5 6] # [1 2 3] # [4 5 6]] row_means = arr.mean(1) print(row_means) # [2. 5. 2. 5.] print(row_means.reshape(4, 1)) # [[2.] # [5.] # [2.] # [5.]] demeaned = arr - row_means.reshape((4, 1)) print(demeaned) # [[-1. 0. 1.] # [-1. 0. 1.] # [-1. 0. 1.] # [-1. 0. 1.]] print(demeaned.mean(1)) # [0. 0. 0. 0.]","title":"\u4e8c\u7ef4\u5e7f\u64ad"},{"location":"python/DataAnalysis/ch10/#_8","text":"\u5728\u8f740\u4ee5\u5916\u7684\u8f74\u4e0a\u4f7f\u7528\u8f83\u4f4e\u7ef4\u6570\u7ec4\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97\u4e5f\u662f\u76f8\u5f53\u666e\u904d\u7684\u3002\u6839\u636e\u5e7f\u64ad\u89c4\u5219\uff0c\u201c\u5e7f\u64ad\u7ef4\u5ea6\u201d\u5728\u8f83\u5c0f\u7684\u6570\u7ec4\u4e2d\u5fc5\u987b\u4e3a1\u3002 \u5728\u4e09\u7ef4\u60c5\u51b5\u4e0b\uff0c\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5e7f\u64ad\u53ea\u662f\u5c06\u6570\u636e\u91cd\u5851\u4e3a\u5f62\u72b6\u517c\u5bb9\u3002 \u56e0\u6b64\uff0c\u9700\u8981\u6dfb\u52a0\u4e00\u4e2a\u957f\u5ea6\u4e3a1\u7684\u65b0\u8f74\uff0c\u4e13\u95e8\u7528\u4e8e\u5e7f\u64ad\u76ee\u7684\u3002\u4f7f\u7528 reshape \u662f\u4e00\u79cd\u9009\u62e9\uff0c\u4f46\u63d2\u5165\u4e00\u4e2a\u8f74\u9700\u8981\u6784\u9020\u4e00\u4e2a\u65b0\u5f62\u72b6\u7684\u5143\u7ec4\u3002NumPy\u6570\u7ec4\u63d0\u4f9b\u4e86 np.newaxis \u5c5e\u6027\u548c\u201c\u5b8c\u6574\u201d\u5207\u7247\u6765\u63d2\u5165\u65b0\u8f74\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u4e86\u89e3\u4e00\u4e9b np.newaxis \u7684\u7528\u6cd5\u3002 x1[:, np.newaxis] \u5bf9\u539f x1 \u6dfb\u52a0\u4e861\u8f74\uff0c\u5373\uff0c\u884c\u65b9\u5411\u67095\u4e2a\u5143\u7d20\uff085\u884c\uff09\uff0c\u5217\u65b9\u5411\u53ea\u67091\u4e2a\u5143\u7d20\uff081\u5217\uff09\u3002 x1[np.newaxis, :] \u5bf9\u539f x1 \u6dfb\u52a0\u4e860\u8f74\uff0c\u5373\uff0c\u884c\u65b9\u5411\u67091\u4e2a\u5143\u7d20\uff081\u884c\uff09\uff0c\u5217\u65b9\u5411\u53ea\u67095\u4e2a\u5143\u7d20\uff085\u5217\uff09\u3002 x1 = np.array([1, 2, 3, 4, 5]) print(x1.shape) # (5,) x1_new = x1[:, np.newaxis] print(x1_new.shape) # (5, 1) print(x1_new) # [[1] # [2] # [3] # [4] # [5]] x2_new = x1[np.newaxis, :] print(x1_new.shape) # (1, 5) print(x1_new) # [[1 2 3 4 5]] \u4e0b\u4f8b\u4e00\u4e2a\u901a\u8fc7 np.newaxis \u5bf9\u4e8c\u7ef4\u6570\u7ec4\u5230\u4e09\u7ef4\u7684\u6269\u5c55\u3002 arr[np.newaxis, :, :, np.newaxis] \u8868\u793a\u5bf9 arr \u6dfb\u52a00\uff0c3\u8f74\uff0c\u539f\u6570\u7ec4 arr \u505a\u4e3a1\uff0c2\u8f74\u3002\u5176\u7b49\u4ef7\u5199\u6cd5\u662f arr[np.newaxis, ..., np.newaxis] arr[:, np.newaxis, np.newaxis] \u8868\u793a\u5bf9 arr \u6dfb\u52a01\uff0c2\u8f74\uff0c\u539f\u6570\u7ec4 arr \u505a\u4e3a0\uff0c3\u8f74\u3002\u5176\u7b49\u4ef7\u5199\u6cd5\u662f arr[np.newaxis, :, np.newaxis, :] \uff0c\u7406\u89e3\u4e0a\u9700\u8981\u6ce8\u610f\u7684\u662f : \u53ea\u4ee3\u8868\u4e00\u4e2a\u8f74\u3002 arr = np.arange(3 * 4).reshape(3, 4) print(arr.shape) # (3, 4) print(arr) # [[ 0 1 2 3] # [ 4 5 6 7] # [ 8 9 10 11]] arr_3D = arr[np.newaxis, :, :, np.newaxis] print(arr_3D.shape) # (1, 3, 1, 4) arr_3D = arr[np.newaxis, ..., np.newaxis] print(arr_3D.shape) # (1, 3, 4, 1) print(arr_3D) # [[[[ 0] # [ 1] # [ 2] # [ 3]] # # [[ 4] # [ 5] # [ 6] # [ 7]] # # [[ 8] # [ 9] # [10] # [11]]]] arr_3D = arr[np.newaxis, :, np.newaxis] print(arr_3D.shape) # (1, 3, 1, 4) arr_3D = arr[np.newaxis, :, np.newaxis, :] print(arr_3D.shape) # (1, 3, 1, 4) print(arr_3D) # [[[[ 0 1 2 3]] # # [[ 4 5 6 7]] # # [[ 8 9 10 11]]]] arr_3D = arr[:, np.newaxis, np.newaxis] print(arr_3D.shape) # (3, 1, 1, 4) arr_3D = arr[:, np.newaxis, np.newaxis, :] print(arr_3D.shape) # (3, 1, 1, 4) print(arr_3D) # [[[[0 1 2]]] # # [[[3 4 5]]] # # [[[6 7 8]]]] \u4e0b\u56fe\u663e\u793a\u4e86\u5728\u4e09\u7ef4\u6570\u7ec4\u7684\u6bcf\u4e2a\u8f74\u4e0a\u5e7f\u64ad\u6240\u9700\u7684\u5f62\u72b6\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u6f14\u793a\u4e86\u57fa\u4e8e\u4e00\u4e2a\u4e09\u7ef4\u6570\u7ec4\u8fdb\u884c\u7684\u5e7f\u64ad\u64cd\u4f5c\u3002 arr = np.zeros((3, 2, 4)) print(arr.shape) # (3, 2, 4) print(arr) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]] # \u751f\u62100\u8f74\u5207\u7247 arr_0 = np.arange(2) print(arr_0.shape) # (2,) print(arr_0) # [0 1] arr_new = arr_0[np.newaxis, :, np.newaxis] print(arr_new.shape) # (1, 2, 1) print(arr_new) # [[[0] # [1]]] arr = arr + arr_new print(arr.shape) # (3, 2, 4) print(arr) # [[[0. 0. 0. 0.] # [1. 1. 1. 1.]] # # [[0. 0. 0. 0.] # [1. 1. 1. 1.]] # # [[0. 0. 0. 0.] # [1. 1. 1. 1.]]] # \u751f\u62101\u8f74\u5207\u7247 arr = np.zeros((3, 2, 4)) arr_1 = np.arange(12).reshape(3, 4) print(arr_1.shape) # (3, 4) arr_new = arr_1[:, np.newaxis, :] print(arr_new.shape) # (3, 1, 4) print(arr_new) # [[[ 0 1 2 3]] # # [[ 4 5 6 7]] # # [[ 8 9 10 11]]] arr = arr + arr_new print(arr) # [[[ 0. 1. 2. 3.] # [ 0. 1. 2. 3.]] # [[ 4. 5. 6. 7.] # [ 4. 5. 6. 7.]] # [[ 8. 9. 10. 11.] # [ 8. 9. 10. 11.]]] # \u751f\u62102\u8f74\u5207\u7247 arr = np.zeros((3, 2, 4)) arr_2 = np.arange(6).reshape(3, 2) arr_new = arr_2[:, :, np.newaxis] print(arr_new.shape) # (3, 2, 1) print(arr_new) # [[[0] # [1]] # [[2] # [3]] # [[4] # [5]]] arr = arr + arr_new print(arr) # [[[0. 1. 2. 3.] # [1. 2. 3. 4.]] # # [[1. 2. 3. 4.] # [2. 3. 4. 5.]] # # [[2. 3. 4. 5.] # [3. 4. 5. 6.]]] # \u5728\u8f742\u4e0a\u51cf\u53bb\u5747\u503c depth_means = arr.mean(2) print(depth_means) # [[0. 1.] # [2. 3.] # [4. 5.]] arr_new = depth_means[:, :, np.newaxis] print(arr_new.shape) # (3, 2, 1) demeaned = arr - arr_new print(demeaned) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]]","title":"\u4e09\u7ef4\u5e7f\u64ad"},{"location":"python/DataAnalysis/ch10/#n","text":"\u548c\u4e0a\u4f8b\u6700\u540e\u573a\u666f\u7684\u8ba1\u7b97\u7ed3\u679c\u76f8\u540c\u3002 arr = np.zeros((3, 2, 4)) def demean_axis(arr, axis=0): means = arr.mean(axis) indexer = [slice(None)] * arr.ndim indexer[axis] = np.newaxis return arr - means[indexer] print(demean_axis(arr, axis=2)) # [[[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]] # [[0. 0. 0. 0.] # [0. 0. 0. 0.]]]","title":"N\u7ef4\u5e7f\u64ad"},{"location":"python/DataAnalysis/ch10/#_9","text":"\u8fdb\u884c\u6570\u7ec4\u7b97\u672f\u8fd0\u7b97\u7684\u5e7f\u64ad\u89c4\u5219\u540c\u6837\u4e5f\u9002\u7528\u4e8e\u901a\u8fc7\u6570\u7ec4\u7d22\u5f15\u8bbe\u7f6e\u503c\u3002 arr = np.zeros((4, 3)) arr[:] = 5 print(arr) # [[5. 5. 5.] # [5. 5. 5.] # [5. 5. 5.] # [5. 5. 5.]] col = np.arange(4) arr[:] = col[:, np.newaxis] print(arr) # [[0. 0. 0.] # [1. 1. 1.] # [2. 2. 2.] # [3. 3. 3.]]","title":"\u901a\u8fc7\u5e7f\u64ad\u8bbe\u5b9a\u6570\u7ec4\u7684\u503c"},{"location":"python/DataAnalysis/ch10/#ufunc","text":"","title":"ufunc\u9ad8\u7ea7\u5e94\u7528"},{"location":"python/DataAnalysis/ch10/#ufunc_1","text":"\u901a\u7528\u51fd\u6570\uff08\u6216\u7b80\u79f0\u4e3aufunc \uff09 \u662f\u4e00\u79cd ndarrays \u4ee5\u9010\u5143\u7d20\u65b9\u5f0f\u64cd\u4f5c\u7684\u51fd\u6570\uff0c\u652f\u6301\u6570\u7ec4\u5e7f\u64ad\uff0c\u7c7b\u578b\u8f6c\u6362\u548c\u5176\u4ed6\u4e00\u4e9b\u6807\u51c6\u529f\u80fd\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0cufunc\u662f\u4e00\u4e2a\u51fd\u6570\u7684 \u77e2\u91cf\u5316\u5305\u88c5\u5668 \uff0c\u5b83\u63a5\u53d7\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5b9a\u8f93\u5165\u5e76\u4ea7\u751f\u56fa\u5b9a\u6570\u91cf\u7684\u7279\u5b9a\u8f93\u51fa\u3002 \u5728NumPy\u4e2d\uff0c\u901a\u7528\u51fd\u6570\u662fnumpy.ufunc\u7c7b\u7684\u5b9e\u4f8b\u3002 NumPy\u7684\u6bcf\u4e2a\u4e8c\u5143ufunc\uff08\u901a\u7528\u51fd\u6570\uff09\u90fd\u6709\u7279\u6b8a\u7684\u65b9\u6cd5\u6765\u6267\u884c\u67d0\u4e9b\u7279\u6b8a\u7684\u5411\u91cf\u5316\u64cd\u4f5c\u3002 reduce \u65b9\u6cd5\u63a5\u6536\u5355\u4e2a\u6570\u7ec4\u5e76\u901a\u8fc7\u6267\u884c\u4e00\u7cfb\u5217\u4e8c\u5143\u64cd\u4f5c\u5728\u6307\u5b9a\u7684\u8f74\u5411\u4e0a\u5bf9\u6570\u7ec4\u7684\u503c\u8fdb\u884c\u805a\u5408\u3002 \u4f8b\u5982\uff0c\u4f7f\u7528np.add.reduce\u662f\u5bf9\u6570\u7ec4\u4e2d\u5143\u7d20\u8fdb\u884c\u52a0\u548c\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\uff1a\u8d77\u59cb\u503c\uff08\u5bf9\u4e8eadd\u65b9\u6cd5\u662f0\uff09\u53d6\u51b3\u4e8eufunc\u3002\u5982\u679c\u4f20\u9012\u4e86\u4e00\u4e2a\u8f74\uff0c\u5219\u6cbf\u8be5\u8f74\u6267\u884c\u7f29\u805a\uff08collapse\uff09\u3002 arr = np.arange(10) a = np.add.reduce(arr) print(a) # 45 a = arr.sum() print(a) # 45 \u4f8b\u5982\uff1a\u4f7f\u7528np.logical_and\u6765\u68c0\u67e5\u6570\u7ec4\u7684\u6bcf\u4e00\u884c\u4e2d\u7684\u503c\u662f\u5426\u88ab\u6392\u5e8f(logical_and.reduce\u7b49\u4ef7\u4e8eall\u65b9\u6cd5)\uff1a arr = np.random.randn(5, 5) print(arr) # [[ 0.75217836 1.26134639 -0.39387918 0.46348823 -1.0026674 ] # [ 0.72085602 -0.50487667 3.21023694 -0.2752039 -1.41158734] # [ 1.69031532 0.61134097 0.58282835 1.03043232 -0.1609196 ] # [-3.05141239 0.47221317 1.36464297 0.17500156 1.26158638] # [-0.21578318 0.37700321 1.05427816 1.56526207 -0.08290142]] # \u5bf9\u6570\u7ec4arr\u884c\u8fdb\u884c\u6392\u5e8f a = arr[::2].sort(1) print(a) # None a = arr[:, :-1] < arr[:, 1:] print(a) # [[ True True True True] # [False True False False] # [ True True True True] # [ True True False True] # [ True True True True]] a = np.logical_and.reduce(arr[:, :-1] < arr[:, 1:], axis=1) print(a) # [ True False True False True] accumulate \u4e0e reduce \u662f\u76f8\u5173\u7684\uff0c\u5c31\u50cf cumsum \u4e0e sum \u76f8\u5173\u4e00\u6837\u3002 accumulate \u751f\u6210\u4e00\u4e2a\u6570\u7ec4\uff0c\u5176\u5c3a\u5bf8\u4e0e\u4e2d\u95f4\u201c\u7d2f\u8ba1\u201d\u503c\u76f8\u540c\uff1a arr = np.arange(15).reshape((3, 5)) print(arr) # [[ 0 1 2 3 4] # [ 5 6 7 8 9] # [10 11 12 13 14]] a = np.add.accumulate(arr, axis=1) print(a) # [[ 0 1 3 6 10] # [ 5 11 18 26 35] # [10 21 33 46 60]] outer \u5728\u4e24\u4e2a\u6570\u7ec4\u4e4b\u95f4\u6267\u884c\u6210\u5bf9\u7684\u4ea4\u53c9\u4e58\u79ef\uff1a arr = np.arange(3).repeat([1, 2, 2]) print(arr) # [0 1 1 2 2] a = np.multiply.outer(arr, np.arange(5)) print(a) # [[0 0 0 0 0] # [0 1 2 3 4] # [0 1 2 3 4] # [0 2 4 6 8] # [0 2 4 6 8]] outer \u8f93\u51fa\u7684\u7ef4\u5ea6\u7b49\u4e8e\u8f93\u5165\u7684\u7ef4\u5ea6\u603b\u548c\uff1a x, y = np.random.randn(3, 4), np.random.randn(5) result = np.subtract.outer(x, y) print(result.shape) # (3, 4, 5) reduceat \u65b9\u6cd5\u6267\u884c\u201c\u672c\u5730\u7f29\u805a\u201d\uff0c\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u6570\u7ec4groupby\u64cd\u4f5c\uff0c\u5728\u64cd\u4f5c\u4e2d\u6570\u7ec4\u7684\u5207\u7247\u805a\u5408\u5728\u4e86\u4e00\u8d77\u3002 reduceat \u65b9\u6cd5\u63a5\u53d7\u4e00\u7cfb\u5217\u7684\u201c\u7bb1\u4f53\u8fb9\u7f18\u201d\uff0c\u8fd9\u4e9b\u7bb1\u4f53\u8fb9\u7f18\u8868\u793a\u5982\u4f55\u5206\u9694\u4ee5\u53ca\u805a\u5408\u6570\u636e\u503c\u3002 \u4e0b\u4f8b\u662f\u5728arr\u7684 [0:5) \u3001 [5:8) \u548c [8:] \u4e09\u4e2a\u533a\u95f4\u4e0a\u6267\u884c\u4e86\u7f29\u805a\uff08\u6b64\u5904\u662f\u8ba1\u7b97\u7d2f\u52a0\u548c\uff09\u3002 arr = np.arange(10) a = np.add.reduceat(arr, [0, 5, 8]) print(a) # [10 18 17] \u53ef\u4ee5\u4f20\u9012\u4e00\u4e2aaxis\u53c2\u6570\uff1a arr = np.multiply.outer(np.arange(4), np.arange(5)) print(arr) # [[ 0 0 0 0 0] # [ 0 1 2 3 4] # [ 0 2 4 6 8] # [ 0 3 6 9 12]] a = np.add.reduceat(arr, [0, 2, 4], axis=1) print(a) # [[ 0 0 0] # [ 1 5 4] # [ 2 10 8] # [ 3 15 12]]","title":"ufunc\u5b9e\u4f8b\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch10/#pythonufunc","text":"\u6709\u5f88\u591a\u5de5\u5177\u53ef\u4ee5\u7528\u4e8e\u521b\u5efa\u4f60\u81ea\u5df1\u7684NumPy ufunc\uff0c\u6700\u5e38\u7528\u7684\u662fNumPy\u7684C\u8bed\u8a00API\uff0c\u4f46\u4e0d\u5728\u8fd9\u91cc\u8ba8\u8bba\u3002\u8fd9\u91cc\u4e3b\u8981\u5173\u6ce8\u7eafPython\u7684ufunc\u65b9\u6cd5\u3002 numpy.frompyfunc \u51fd\u6570\u63a5\u6536\u4e00\u4e2a\u5177\u6709\u7279\u5b9a\u6570\u5b57\u8f93\u5165\u548c\u8f93\u51fa\u7684\u51fd\u6570\u3002\u4f7f\u7528 frompyfunc \u521b\u5efa\u7684\u51fd\u6570\u901a\u5e38\u8fd4\u56de\u7684\u662fPython\u5bf9\u8c61\u7684\u6570\u7ec4\uff0c\u8fd9\u5e76\u4e0d\u65b9\u4fbf\u3002\u8fd8\u6709\u53e6\u4e00\u4e2a\u51fd\u6570 numpy.vectorize \u5141\u8bb8\u6307\u5b9a\u8f93\u51fa\u7684\u7c7b\u578b\uff08\u4f46\u529f\u80fd\u7a0d\u5dee\uff09\u3002 \u4f8b\u5982\uff0c\u4e00\u4e2a\u7b80\u5355\u7684\u6309\u5143\u7d20\u76f8\u52a0\u7684\u51fd\u6570\u53ef\u4ee5\u5982\u4e0b\uff1a def add_elements(x, y): return x + y add_them = np.frompyfunc(add_elements, 2, 1) result = add_them(np.arange(8), np.arange(8)) print(result) # [0 2 4 6 8 10 12 14] add_them = np.vectorize(add_elements, otypes=[np.float64]) result = add_them(np.arange(8), np.arange(8)) print(result) # [ 0. 2. 4. 6. 8. 10. 12. 14.]","title":"\u4f7f\u7528Python\u7f16\u5199\u65b0\u7684ufunc\u65b9\u6cd5"},{"location":"python/DataAnalysis/ch10/#_10","text":"ndarray \u662f\u4e00\u4e2a\u540c\u6784\u6570\u636e\u7684\u5bb9\u5668\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u8868\u793a\u4e00\u4e2a\u5185\u5b58\u5757\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5360\u7528\u76f8\u540c\u6570\u91cf\u7684\u5b57\u8282\uff0c\u7531dtype\u786e\u5b9a\u3002 ndarray \u7684\u8fd9\u79cd\u7279\u6027\u4e0d\u80fd\u7528\u6765\u8868\u793a\u5f02\u6784\u7684\u6570\u636e\u6216\u8868\u683c\u578b\u6570\u636e\u3002 \u7ed3\u6784\u5316\u6570\u7ec4 \u662f\u4e00\u4e2a ndarray \uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u53ef\u4ee5\u88ab\u8ba4\u4e3a\u4ee3\u8868C\u4e2d\u7684struct\uff08\u56e0\u6b64\u662f\u201c\u7ed3\u6784\u5316\u201d\u7684\u540d\u79f0\uff09\uff0c\u6216\u8005\u662fSQL\u8868\u4e2d\u5177\u6709\u591a\u4e2a\u547d\u540d\u5b57\u6bb5\u7684\u884c\uff1a dtype = [('x', np.float64), ('y', np.int32)] sarr = np.array( [ (1.5, 6), (np.pi, -2) ], dtype=dtype ) print(sarr) # [(1.5 , 6) (3.14159265, -2)] \u6709\u51e0\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6307\u5b9a\u7ed3\u6784\u5316\u7684dtype\uff08\u8bf7\u53c2\u9605NumPy\u5b98\u65b9\u5728\u7ebf\u6587\u6863\uff09\u3002\u4e00\u79cd\u5178\u578b\u7684\u65b9\u5f0f\u662f\u4f7f\u7528(field_name, field_data_type)\u4f5c\u4e3a\u5143\u7ec4\u7684\u5217\u8868\u3002 \u6570\u7ec4\u7684\u5143\u7d20\u662f\u5143\u7ec4\u5bf9\u8c61\uff0c\u5176\u5143\u7d20\u53ef\u4ee5\u50cf\u5b57\u5178\u4e00\u6837\u8bbf\u95ee\uff0c\u5b57\u6bb5\u540d\u79f0\u5b58\u50a8\u5728dtype.names\u5c5e\u6027\u4e2d\u3002 print(sarr[0]) # (1.5, 6) print(sarr['x']) # [1.5 3.14159265] print(sarr[0]['y']) # 6","title":"\u7ed3\u6784\u5316\u548c\u8bb0\u5f55\u5f0f\u6570\u7ec4"},{"location":"python/DataAnalysis/ch10/#dtype","text":"\u5f53\u6307\u5b9a\u7ed3\u6784\u5316\u7684dtype\u65f6\uff0c\u53ef\u4ee5\u53e6\u5916\u4f20\u9012\u4e00\u4e2a\u5f62\u72b6\uff08\u4ee5int\u6216\u5143\u7ec4\u7684\u5f62\u5f0f\uff09\uff1a dtype = [('x', np.int64, 3), ('y', np.int32)] arr = np.zeros(4, dtype=dtype) print(arr) # [([0, 0, 0], 0) ([0, 0, 0], 0) ([0, 0, 0], 0) ([0, 0, 0], 0)] x \u5b57\u6bb5\u5f15\u7528\u7684\u662f\u6bcf\u6761\u8bb0\u5f55\u4e2d\u957f\u5ea6\u4e3a3\u7684\u6570\u7ec4\uff1a print(arr[0]['x']) # [0 0 0] \u8bbf\u95ee arr['x'] \u7136\u540e\u8fd4\u56de\u4e00\u4e2a\u4e8c\u7ef4\u6570\u7ec4\uff0c\u800c\u4e0d\u662f\u8fd4\u56de\u4e00\u4e2a\u4e00\u7ef4\u6570\u7ec4\uff1a print(arr['x']) # [[0 0 0] # [0 0 0] # [0 0 0] # [0 0 0]]","title":"\u5d4c\u5957dtype\u548c\u591a\u7ef4\u5b57\u6bb5"},{"location":"python/DataAnalysis/ch10/#_11","text":"\u4e0epandas\u7684DataFrame\u76f8\u6bd4\uff0cNumPy\u7ed3\u6784\u5316\u6570\u7ec4\u662f\u4e00\u4e2a\u76f8\u5bf9\u5e95\u5c42\u7684\u5de5\u5177\u3002 \u7ed3\u6784\u5316\u6570\u7ec4\u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06\u5185\u5b58\u5757\u89e3\u91ca\u4e3a\u5177\u6709\u4efb\u610f\u590d\u6742\u5d4c\u5957\u5217\u7684\u8868\u683c\u7ed3\u6784\u7684\u65b9\u6cd5\u3002 \u7531\u4e8e\u6570\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5728\u5185\u5b58\u4e2d\u8868\u793a\u4e3a\u56fa\u5b9a\u6570\u91cf\u7684\u5b57\u8282\uff0c\u56e0\u6b64\u7ed3\u6784\u5316\u6570\u7ec4\u63d0\u4f9b\u4e86\u8bfb/\u5199\u78c1\u76d8\uff08\u5305\u62ec\u5185\u5b58\u6620\u5c04\uff09\u6570\u636e\uff0c\u4ee5\u53ca\u5728\u7f51\u7edc\u4e0a\u4f20\u8f93\u6570\u636e\u548c\u5176\u4ed6\u6b64\u7c7b\u7528\u9014\u7684\u975e\u5e38\u5feb\u901f\u6709\u6548\u7684\u65b9\u6cd5\u3002 \u4f5c\u4e3a\u7ed3\u6784\u5316\u6570\u7ec4\u7684\u53e6\u4e00\u79cd\u5e38\u89c1\u7528\u9014\uff0c\u5c06\u6570\u636e\u6587\u4ef6\u7f16\u5199\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u8bb0\u5f55\u5b57\u8282\u6d41\u662f\u5c06C\u548cC ++\u4ee3\u7801\u4e2d\u7684\u6570\u636e\u5e8f\u5217\u5316\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u8fd9\u5728\u4e1a\u754c\u4f20\u7edf\u7cfb\u7edf\u4e2d\u5f88\u5e38\u89c1\u3002 \u53ea\u8981\u77e5\u9053\u6587\u4ef6\u7684\u683c\u5f0f\uff08\u6bcf\u4e2a\u8bb0\u5f55\u7684\u5927\u5c0f\u4ee5\u53ca\u6bcf\u4e2a\u5143\u7d20\u7684\u987a\u5e8f\u3001\u5b57\u8282\u5927\u5c0f\u548c\u6570\u636e\u7c7b\u578b\uff09\uff0c\u5c31\u53ef\u4ee5\u7528np.fromfile\u5c06\u6570\u636e\u8bfb\u5165\u5185\u5b58\u3002","title":"\u4e3a\u4ec0\u4e48\u8981\u4f7f\u7528\u7ed3\u6784\u5316\u6570\u7ec4"},{"location":"python/DataAnalysis/ch11/","text":"Python\u5efa\u6a21\u5e93\u4ecb\u7ecd pandas\u4e0e\u5efa\u6a21\u4ee3\u7801\u7684\u7ed3\u5408 \u4ecb\u7ecd\u4e24\u4e2a\u6d41\u884c\u7684\u5efa\u6a21\u5de5\u5177\u5305\uff1a [statsmodels]http://statsmodels.org\uff09 [scikit-learn]http://scikit-learn.org\uff09 import pandas as pd import numpy as np \u4f7f\u7528pandas\u7528\u4e8e\u6570\u636e\u8f7d\u5165\u548c\u6570\u636e\u6e05\u6d17\uff0c\u4e4b\u540e\u5207\u6362\u5230\u6a21\u578b\u5e93\u53bb\u5efa\u7acb\u6a21\u578b\u662f\u4e00\u4e2a\u5e38\u89c1\u7684\u6a21\u578b\u5f00\u53d1\u5de5\u4f5c\u6d41\u3002 \u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7279\u5f81\u5de5\u7a0b\u662f\u6a21\u578b\u5f00\u53d1\u7684\u91cd\u8981\u90e8\u5206\u4e4b\u4e00\u3002 \u7279\u5f81\u5de5\u7a0b\u662f\u6307\u4ece\u539f\u751f\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u53ef\u7528\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u7684\u6709\u6548\u4fe1\u606f\u7684\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u6216\u5206\u6790\u3002 pandas\u548c\u5176\u4ed6\u5206\u6790\u5e93\u7684\u7ed3\u5408\u70b9\u901a\u5e38\u662fNumPy\u6570\u7ec4\u3002 \u8981\u5c06DataFrame\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\uff0c\u4f7f\u7528 .values \u5c5e\u6027\uff1a df = pd.DataFrame( { 'x0': [1, 2, 3, 4, 5], 'x1': [0.01, -0.01, 0.25, -4.1, 0.], 'y': [-1.5, 0., 3.6, 1.3, -2.] } ) print(df) # x0 x1 y # 0 1 0.01 -1.5 # 1 2 -0.01 0.0 # 2 3 0.25 3.6 # 3 4 -4.10 1.3 # 4 5 0.00 -2.0 print(df.columns) # Index(['x0', 'x1', 'y'], dtype='object') print(df.values) # [[ 1. 0.01 -1.5 ] # [ 2. -0.01 0. ] # [ 3. 0.25 3.6 ] # [ 4. -4.1 1.3 ] # [ 5. 0. -2. ]] \u5c06\u6570\u7ec4\u518d\u8f6c\u6362\u4e3aDataFrame\uff1a df2 = pd.DataFrame(df.values, columns=['one', 'two', 'three']) # \u9012\u4e00\u4e2a\u542b\u6709\u5217\u540d\u7684\u4e8c\u7ef4ndarray print(df2) # one two three # 0 1.0 0.01 -1.5 # 1 2.0 -0.01 0.0 # 2 3.0 0.25 3.6 # 3 4.0 -4.10 1.3 # 4 5.0 0.00 -2.0 .values \u5c5e\u6027\u4e00\u822c\u5728\u6570\u636e\u662f\u540c\u6784\u5316\u7684\u65f6\u5019\u4f7f\u7528\u2014\u2014\u4f8b\u5982\uff0c\u90fd\u662f\u6570\u5b57\u7c7b\u578b\u7684\u65f6\u5019\u3002\u5982\u679c\u6570\u636e\u662f\u5f02\u6784\u5316\u7684\uff0c\u7ed3\u679c\u5c06\u662fPython\u5bf9\u8c61\u7684 ndarray \uff1a \u6dfb\u52a0\u4e00\u4e2a\u975e\u6570\u5b57\u7c7b\u578b\u7684\u5217\u3002 df3 = df.copy() df3['category'] = pd.Categorical(['a', 'b', 'a', 'a', 'b'], categories=['a', 'b']) print(df3) # x0 x1 y category # 0 1 0.01 -1.5 a # 1 2 -0.01 0.0 b # 2 3 0.25 3.6 a # 3 4 -4.10 1.3 a # 4 5 0.00 -2.0 b print(df3.values) # [[1 0.01 -1.5 'a'] # [2 -0.01 0.0 'b'] # [3 0.25 3.6 'a'] # [4 -4.1 1.3 'a'] # [5 0.0 -2.0 'b']] \u901a\u8fc7 loc \u7d22\u5f15\u548c values \u4f7f\u7528\u4e00\u90e8\u5206\u5217\u6570\u636e\u3002 model_cols = ['x0', 'x1'] result = df.loc[:, model_cols].values print(result) # [[ 1. 0.01] # [ 2. -0.01] # [ 3. 0.25] # [ 4. -4.1 ] # [ 5. 0. ]] \u5982\u679c\u6211\u4f7f\u7528\u865a\u62df\u53d8\u91cf\u66ff\u4ee3 df3 \u7684 category \u5217\uff0c\u5148\u521b\u5efa\u865a\u62df\u53d8\u91cf\uff0c\u4e4b\u540e\u5220\u9664 categroy \u5217\uff0c\u7136\u540e\u8fde\u63a5\u7ed3\u679c\uff1a dummies = pd.get_dummies(df3.category, prefix='category') print(dummies) # category_a category_b # 0 1 0 # 1 0 1 # 2 1 0 # 3 1 0 # 4 0 1 data_with_dummies = df3.drop('category', axis=1).join(dummies) print(data_with_dummies) # x0 x1 y category_a category_b # 0 1 0.01 -1.5 1 0 # 1 2 -0.01 0.0 0 1 # 2 3 0.25 3.6 1 0 # 3 4 -4.10 1.3 1 0 # 4 5 0.00 -2.0 0 1 \u4f7f\u7528Patsy\u521b\u5efa\u6a21\u578b\u63cf\u8ff0 \u6837\u672c\u7684\u8868\u793a\u5f62\u5f0f\uff1a \u5728\u6570\u636e\u6316\u6398\u8fc7\u7a0b\u4e2d\uff0c\u6837\u672c\u4ee5\u7279\u5f81\u503c\u77e9\u9635X\u548c\u76ee\u6807\u503c\u5411\u91cfY\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u5bb9\u91cf\u4e3a n \uff0c\u6709 m \u4e2a\u7279\u5f81\u7684\u6837\u672c\uff0c\u5176\u7279\u5f81\u503c\u77e9\u9635X\u7531 n \u4e2a\u7ef4\u5ea6\u4e3a m \u7684\u5217\u5411\u91cf\u7ec4\u6210\uff0c\u7b2c j \u4e2a\u5217\u5411\u91cf\u4e3a\u6837\u672c\u4e2d\u7b2c j \u4e2a\u4e2a\u4f53\u7684\u7279\u5f81\u503c\u5411\u91cf\uff1b \u76ee\u6807\u503c\u5411\u91cfY\u7684\u7b2c j \u4e2a\u5206\u91cf\u4e3a\u6837\u672c\u4e2d\u7b2c j \u4e2a\u4e2a\u4f53\u7684\u76ee\u6807\u503c\u3002 \u53c2\u8003\uff1a How formulas work [Patsy](https://patsy.readthedocs.io/\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u63cf\u8ff0\u7edf\u8ba1\u6a21\u578b\uff08\u5c24\u5176\u662f\u7ebf\u6027\u6a21\u578b\uff09\u7684Python\u5e93\u3002 \u5b83\u4f7f\u7528\u4e00\u79cd\u5c0f\u578b\u57fa\u4e8e\u5b57\u7b26\u4e32\u7684\"\u516c\u5f0f\u8bed\u6cd5\"\u3002 Patsy\u80fd\u591f\u5f88\u597d\u5730\u652f\u6301 statsmodels \u4e2d\u7279\u5b9a\u7684\u7ebf\u6027\u6a21\u578b\u3002 \u50cf y ~ x0 + x1 \u8fd9\u79cd a + b \u7684\u8bed\u6cd5\u5e76\u4e0d\u4ee3\u8868\u5c06 a \u548c b \u76f8\u52a0\uff0c\u800c\u662f\u4ee3\u8868\u4e3a\u6a21\u578b\u521b\u5efa\u7684\u8bbe\u8ba1\u77e9\u9635\u7684\u672f\u8bed\uff08terms in the design matrix\uff09\u3002 patsy.dmatrices \u51fd\u6570\uff0c\u53d6\u4e00\u4e2a\u516c\u5f0f\u5b57\u7b26\u4e32\u548c\u4e00\u4e2a\u6570\u636e\u96c6\uff08\u53ef\u4ee5\u4f7fDataFrame\u6216dict\uff09\uff0c\u7136\u540e\u4e3a\u7ebf\u6027\u6a21\u578b\u4ea7\u751f\u8bbe\u8ba1\u77e9\u9635\uff1a import pandas as pd import numpy as np import patsy from patsy import dmatrices, dmatrix, demo_data df = pd.DataFrame( { 'x0': [1, 2, 3, 4, 5], 'x1': [0.01, -0.01, 0.25, -4.1, 0.], 'y': [-1.5, 0., 3.6, 1.3, -2.] } ) print(df) # x0 x1 y # 0 1 0.01 -1.5 # 1 2 -0.01 0.0 # 2 3 0.25 3.6 # 3 4 -4.10 1.3 # 4 5 0.00 -2.0 y, X = patsy.dmatrices('y ~ x0 + x1', df) print(y) # [[-1.5] # [ 0. ] # [ 3.6] # [ 1.3] # [-2. ]] print(X) # [[ 1. 1. 0.01] # [ 1. 2. -0.01] # [ 1. 3. 0.25] # [ 1. 4. -4.1 ] # [ 1. 5. 0. ]] print(np.asarray(y)) # Patsy\u7684DesignMatrix\u5b9e\u4f8b\uff0c\u542b\u6709\u9644\u52a0\u5143\u6570\u636e\u7684NumPy.ndarray # [[-1.5] # [ 0. ] # [ 3.6] # [ 1.3] # [-2. ]] print(np.asarray(X)) # Patsy\u7684DesignMatrix\u5b9e\u4f8b\uff0c\u542b\u6709\u9644\u52a0\u5143\u6570\u636e\u7684NumPy.ndarray # [[ 1. 1. 0.01] # [ 1. 2. -0.01] # [ 1. 3. 0.25] # [ 1. 4. -4.1 ] # [ 1. 5. 0. ]] \u4e0a\u9762X\u8f93\u51fa\u4e2d\u7684Intercept(\u6700\u5de6\u8fb9\u4e00\u5217)\u662f\u4ece\u54ea\u91cc\u6765\u7684\u3002 \u8fd9\u5176\u5b9e\u662f\u7ebf\u6027\u6a21\u578b\u7684\u4e00\u4e2a\u60ef\u4f8b\uff0c\u6bd4\u5982\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u6cd5\uff08ordinary least squares regression\uff09\u3002 \u53ef\u4ee5\u53bb\u6389\u8fd9\u4e2a\u622a\u8ddd\uff08intercept\uff09\uff0c\u901a\u8fc7 y ~ x0 + x1 + 0 \u7ed9\u6a21\u578b\u3002 y, X = patsy.dmatrices('y ~ x0 + x1 + 0', df) print(X) # [[ 1. 0.01] # [ 2. -0.01] # [ 3. 0.25] # [ 4. -4.1 ] # [ 5. 0. ]] \u8fd9\u79cdPatsy\u5bf9\u8c61\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165\u4e00\u4e2a\u7b97\u6cd5\uff0c\u6bd4\u5982 numpy.linalg.lstsq \uff0c\u6765\u8fdb\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u7684\u8ba1\u7b97 coef, resid, _, _ =np.linalg.lstsq(X, y, rcond=1) # \u6700\u5c0f\u4e8c\u4e58\u6cd5 print(coef) # [[ 0.00925424] # [-0.25485421]] print(resid) # [19.72552896] coef = pd.Series(coef.squeeze(), index=X.design_info.column_names) print(coef) # x0 0.009254 # x1 -0.254854 # dtype: float64 Patsy\u516c\u5f0f\u4e2d\u7684\u6570\u636e\u8f6c\u6362 \u53ef\u4ee5\u5c06Python\u4ee3\u7801\u6df7\u5408\u5230\u4f60\u7684Patsy\u516c\u5f0f\u4e2d\uff0c\u5728\u6267\u884c\u516c\u5f0f\u65f6\uff0cPatsy\u5e93\u5c06\u5c1d\u8bd5\u5728\u5c01\u95ed\u4f5c\u7528\u57df\u4e2d\u5bfb\u627e\u4f60\u4f7f\u7528\u7684\u51fd\u6570\uff1a y, X = patsy.dmatrices('y ~ x0 + np.log(np.abs(x1) +1)', df) print(X) # [[1. 1. 0.00995033] # [1. 2. 0.00995033] # [1. 3. 0.22314355] # [1. 4. 1.62924054] # [1. 5. 0. ]] \u4e00\u4e9b\u5e38\u7528\u7684\u53d8\u91cf\u53d8\u6362\uff0c\u5305\u62ec\u6807\u51c6\u5316\uff08standardizing (\u5e73\u5747\u503c0\uff0c\u65b9\u5dee1\uff09\u548c\u4e2d\u5fc3\u5316\uff08\u51cf\u53bb\u5e73\u5747\u503c\uff09\u3002Patsy\u6709\u5185\u5efa\u7684\u51fd\u6570\u53ef\u4ee5\u505a\u5230\u8fd9\u4e9b\u3002 y, X = patsy.dmatrices('y ~ standardize(x0) + center(x1)', df) print(X) # [[ 1. -1.41421356 0.78 ] # [ 1. -0.70710678 0.76 ] # [ 1. 0. 1.02 ] # [ 1. 0.70710678 -3.33 ] # [ 1. 1.41421356 0.77 ]] \u4f5c\u4e3a\u5efa\u6a21\u7684\u4e00\u90e8\u5206\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u5728\u4e00\u4e2a\u6570\u636e\u53ca\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u5728\u53e6\u4e00\u4e2a\u6570\u636e\u53ca\u4e0a\u8bc4\u4ef7\u6a21\u578b\u3002 \u5f53\u4f7f\u7528\u4e2d\u5fc3\u5316\u6216\u6807\u51c6\u5316\u8fd9\u6837\u7684\u8f6c\u6362\u65f6\uff0c\u6211\u4eec\u5fc5\u987b\u6ce8\u610f\uff0c\u5fc5\u987b\u7528\u6a21\u578b\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u505a\u9884\u6d4b\u3002 \u8fd9\u53eb\u505a\u72b6\u6001\u53d8\u6362\uff08stateful transformations\uff09\u3002 \u56e0\u4e3a\u6211\u4eec\u5fc5\u987b\u7528\u539f\u672c\u5728\u8bad\u7ec3\u96c6\u4e0a\u5f97\u5230\u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u7528\u5728\u65b0\u7684\u6570\u636e\u96c6\u4e0a\u3002 new_df = pd.DataFrame( { 'x0': [6, 7, 8, 9], 'x1': [3.1, -0.5, 0, 2.3], 'y': [1, 2, 3, 4] } ) new_X = patsy.build_design_matrices([X.design_info], new_df) print(new_X) # [DesignMatrix with shape (4, 3) # Intercept standardize(x0) center(x1) # 1 2.12132 3.87 # 1 2.82843 0.27 # 1 3.53553 0.77 # 1 4.24264 3.07 # Terms: # 'Intercept' (column 0), 'standardize(x0)' (column 1), 'center(x1)' (column 2)] \u56e0\u4e3a\u52a0\u53f7\uff08+\uff09\u5728Patsy\u516c\u5f0f\u7684\u4e0a\u4e0b\u6587\u4e2d\u5e76\u4e0d\u662f\u52a0\u6cd5\u7684\u610f\u601d\uff0c\u5f53\u60f3\u8981\u5bf9\u6570\u636e\u96c6\u4e2d\u4e24\u5217\u6309\u5217\u540d\u76f8\u52a0\u65f6\uff0c\u5fc5\u987b\u5c06\u5217\u540d\u5c01\u88c5\u5230\u7279\u6b8a\u7684I\u51fd\u6570\u4e2d\uff1a y, X = patsy.dmatrices('y ~ I(x0 + x1)', df) print(X) # [[ 1. 1.01] # [ 1. 1.99] # [ 1. 3.25] # [ 1. -0.1 ] # [ 1. 5. ]] \u5206\u7c7b\u6570\u636eCategorical\u548cPatsy \u975e\u6570\u503c\u578b\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u5f88\u591a\u79cd\u65b9\u5f0f\u53d8\u4e3a\u4e00\u4e2a\u6a21\u578b\u8bbe\u8ba1\u77e9\u9635\u3002 \u5f53\u6211\u4eec\u5728Patsy\u516c\u5f0f\u4e2d\u4f7f\u7528\u975e\u6570\u503c\u672f\u8bed\u65f6\uff0c\u8fd9\u4e9b\u7c7b\u578b\u6570\u636e\u9ed8\u8ba4\u4f1a\u88ab\u8f6c\u6362\u4e3a\u54d1\u53d8\u91cf\u3002\u5982\u679c\u6709\u622a\u8ddd\uff0c\u4e00\u4e2a\u5c42\u7ea7\u4e0a\u7684\u622a\u8ddd\u4f1a\u88ab\u820d\u5f03\uff0c\u9632\u6b62\u51fa\u73b0\u5171\u7ebf\u6027\u3002 data = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a', 'b', 'a', 'b'], 'key2': [0, 1, 0, 1, 0, 1, 0, 0], 'v1': [1, 2, 3, 4, 5, 6, 7, 8], 'v2': [-1, 0, 2.5, -0.5, 4., -1.2, 0.2, -1.7] } ) y, X = patsy.dmatrices('v2 ~ key1', data) print(y) # [[-1. ] # [ 0. ] # [ 2.5] # [-0.5] # [ 4. ] # [-1.2] # [ 0.2] # [-1.7]] print(X) # [[1. 0.] # [1. 0.] # [1. 1.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 1.]] \u5982\u679c\u4ece\u6a21\u578b\u4e2d\u820d\u5f03\u622a\u8ddd\uff0c\u6bcf\u4e2a\u7c7b\u578b\u7684\u5217\u4f1a\u88ab\u5305\u542b\u5728\u6a21\u578b\u8bbe\u8ba1\u77e9\u9635\u4e2d\u3002 y, X = patsy.dmatrices('v2 ~ key1 + 0', data) print(X) # [[1. 0.] # [1. 0.] # [0. 1.] # [0. 1.] # [1. 0.] # [0. 1.] # [1. 0.] # [0. 1.]] \u6570\u503c\u578b\u5217\u53ef\u4ee5\u901a\u8fc7C\u51fd\u6570\uff0c\u53d8\u4e3a\u7c7b\u578b\u5217\uff1a y, X = patsy.dmatrices('v2 ~ C(key2)', data) print(X) # [[1. 0.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 0.]] \u5f53\u6211\u4eec\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u4f7f\u7528\u591a\u4e2a\u7c7b\u578b\u672f\u8bed\u65f6\uff0c\u4f1a\u53d8\u5f97\u66f4\u590d\u6742\u4e00\u4e9b\uff0c\u4e4b\u524d\u7528key1:key2\u7684\u5f62\u5f0f\u6765\u5305\u542b\u6709\u4ea4\u96c6\u7684\u672f\u8bed\uff0c \u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u7528\u4e8e\u4f7f\u7528\u591a\u4e2a\u672f\u8bed\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u65b9\u6cd5\u5206\u6790\u6a21\u578b\uff08analysis of variance (ANOVA) models\uff09\uff1a data['key2'] = data['key2'].map({0: 'zero', 1: 'one'}) print(data) # key1 key2 v1 v2 # 0 a zero 1 -1.0 # 1 a one 2 0.0 # 2 b zero 3 2.5 # 3 b one 4 -0.5 # 4 a zero 5 4.0 # 5 b one 6 -1.2 # 6 a zero 7 0.2 # 7 b zero 8 -1.7 y, X = patsy.dmatrices('v2 ~ key1 + key2', data) print(X) # [[1. 0. 1.] # [1. 0. 0.] # [1. 1. 1.] # [1. 1. 0.] # [1. 0. 1.] # [1. 1. 0.] # [1. 0. 1.] # [1. 1. 1.]] y, X = patsy.dmatrices('v2 ~ key1 + key2 + key1:key2', data) print(X) # [[1. 0. 1. 0.] # [1. 0. 0. 0.] # [1. 1. 1. 1.] # [1. 1. 0. 0.] # [1. 0. 1. 0.] # [1. 1. 0. 0.] # [1. 0. 1. 0.] # [1. 1. 1. 1.]] statsmodels\u4ecb\u7ecd statsmodels \u662f\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u62df\u5408\u591a\u79cd\u7edf\u8ba1\u6a21\u578b\uff0c\u6267\u884c\u7edf\u8ba1\u6d4b\u8bd5\u4ee5\u53ca\u6570\u636e\u63a2\u7d22\u548c\u53ef\u89c6\u5316\u3002 statsmodels \u5305\u542b\u66f4\u591a\u7684\u201c\u7ecf\u5178\u201d\u9891\u7387\u5b66\u6d3e\u7edf\u8ba1\u65b9\u6cd5\uff0c\u800c\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u5728\u5176\u4ed6\u5e93\u4e2d\u627e\u5230\u3002 \u5305\u542b\u5728statsmodels\u4e2d\u7684\u4e00\u4e9b\u6a21\u578b\uff1a \u7ebf\u6027\u6a21\u578b\uff0c\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u548c\u9c81\u68d2\u7ebf\u6027\u6a21\u578b \u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b \u65b9\u5dee\u5206\u6790\uff08ANOVA\uff09\u65b9\u6cd5 \u65f6\u95f4\u5e8f\u5217\u8fc7\u7a0b\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b \u5e7f\u4e49\u7684\u77e9\u91cf\u6cd5 import pandas as pd import statsmodels.api as sm import statsmodels.formula.api as smf import numpy as np import random \u8bc4\u4f30\u7ebf\u6027\u6a21\u578b \u7edf\u8ba1\u6a21\u578b\u4e2d\u6709\u51e0\u79cd\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4ece\u8f83\u57fa\u672c\u7684\uff08\u4f8b\u5982\uff0c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\uff09\u5230\u66f4\u590d\u6742\u7684\uff08\u4f8b\u5982\uff0c\u8fed\u4ee3\u91cd\u65b0\u52a0\u6743\u7684\u6700\u5c0f\u4e8c\u4e58\uff09\u3002 tatsmodels \u4e2d\u7684\u7ebf\u6027\u6a21\u578b\u6709\u4e24\u4e2a\u4e0d\u540c\u7684\u4e3b\u8981\u63a5\u53e3\uff0c\u8fd9\u4e9b\u63a5\u53e3\u901a\u8fc7\u8fd9\u4e9bAPI\u6a21\u5757\u5bfc\u5165\u6765\u8bbf\u95ee\uff1a \u57fa\u4e8e\u6570\u7ec4 \u57fa\u4e8e\u516c\u5f0f \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u8c03\u7528\u5df2\u77e5\u53c2\u6570beta\u7684\u6a21\u578b\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c dnorm \u662f\u7528\u4e8e\u751f\u6210\u5177\u6709\u7279\u5b9a\u5747\u503c\u548c\u65b9\u5dee\u7684\u6b63\u6001\u5206\u5e03\u6570\u636e\u7684\u8f85\u52a9\u51fd\u6570\u3002 def dnorm (mean, variance, size=1): if isinstance(size, int): size = size, return mean + np.sqrt(variance) * np.random.randn(*size) np.random.seed(12345) N = 100 X = np.c_[ dnorm(0, 0.4, size=N), dnorm(0, 0.6, size=N), dnorm(0, 0.2, size=N) ] eps = dnorm(0, 0.1, size=N) beta = [0.1, 0.3, 0.5] y = np.dot(X, beta) + eps print(X[:5]) # [[-0.12946849 -1.21275292 0.50422488] # [ 0.30291036 -0.43574176 -0.25417986] # [-0.32852189 -0.02530153 0.13835097] # [-0.35147471 -0.71960511 -0.25821463] # [ 1.2432688 -0.37379916 -0.52262905]] print(y[:5]) # [ 0.42786349 -0.67348041 -0.09087764 -0.48949442 -0.12894109] \u7ebf\u6027\u6a21\u578b\u901a\u5e38\u4e0e\u6211\u4eec\u5728Patsy\u4e2d\u770b\u5230\u7684\u622a\u8ddd\u9879\u76f8\u5339\u914d\u3002 sm.add_constant \u51fd\u6570\u53ef\u4ee5\u5c06\u622a\u8ddd\u5217\u6dfb\u52a0\u5230\u73b0\u6709\u77e9\u9635\uff1a X_model = sm.add_constant(X) print(X_model[:5]) # [[ 1. -0.12946849 -1.21275292 0.50422488] # [ 1. 0.30291036 -0.43574176 -0.25417986] # [ 1. -0.32852189 -0.02530153 0.13835097] # [ 1. -0.35147471 -0.71960511 -0.25821463] # [ 1. 1.2432688 -0.37379916 -0.52262905]] sm.OLS \u7c7b\u53ef\u4ee5\u62df\u5408\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7ebf\u6027\u56de\u5f52\uff1a model = sm.OLS(y, X) \u6a21\u578b\u7684 fit \u65b9\u6cd5\u8fd4\u56de\u4e00\u4e2a\u56de\u5f52\u7ed3\u679c\u5bf9\u8c61\uff0c\u8be5\u5bf9\u8c61\u5305\u542b\u4e86\u4f30\u8ba1\u7684\u6a21\u578b\u53c2\u6570\u548c\u5176\u4ed6\u7684\u8bca\u65ad\uff1a results = model.fit() print(results.params) # [0.17826108 0.22303962 0.50095093] \u8c03\u7528 summary \u65b9\u6cd5\u53ef\u4ee5\u6253\u5370\u51fa\u4e00\u4e2a\u6a21\u578b\u7684\u8bca\u65ad\u7ec6\u8282\uff0c\u6b64\u5904\u7684\u53c2\u6570\u540d\u79f0\u5df2\u88ab\u8d4b\u4e88\u901a\u7528\u540d\u79f0 x1 \u3001 x2 \u7b49\uff1a print(results.summary()) # OLS Regression Results # ======================================================================================= # Dep. Variable: y R-squared (uncentered): 0.430 # Model: OLS Adj. R-squared (uncentered): 0.413 # Method: Least Squares F-statistic: 24.42 # Date: Sat, 16 Oct 2021 Prob (F-statistic): 7.44e-12 # Time: 14:21:45 Log-Likelihood: -34.305 # No. Observations: 100 AIC: 74.61 # Df Residuals: 97 BIC: 82.42 # Df Model: 3 # Covariance Type: nonrobust # ============================================================================== # coef std err t P>|t| [0.025 0.975] # ------------------------------------------------------------------------------ # x1 0.1783 0.053 3.364 0.001 0.073 0.283 # x2 0.2230 0.046 4.818 0.000 0.131 0.315 # x3 0.5010 0.080 6.237 0.000 0.342 0.660 # ============================================================================== # Omnibus: 4.662 Durbin-Watson: 0 -0.002327 # Prob(Omnibus): 0.097 Jarque-Bera (JB): 4.098 # Skew: 0.481 Prob(JB): 0.129 # Kurtosis: 3.243 Cond. No. 1.74 # ============================================================================== # # Notes: # [1] R\u00b2 is computed without centering (uncentered) since the model does not contain a constant. # [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \u5047\u8bbe\u6240\u6709\u6a21\u578b\u53c2\u6570\u90fd\u5728DataFrame\u4e2d\uff1a data = pd.DataFrame(X, columns=['col0', 'col1', 'col2']) data['y'] = y print(data[:5]) # col0 col1 col2 y # 0 -0.129468 -1.212753 0.504225 0.427863 # 1 0.302910 -0.435742 -0.254180 -0.673480 # 2 -0.328522 -0.025302 0.138351 -0.090878 # 3 -0.351475 -0.719605 -0.258215 -0.489494 # 4 1.243269 -0.373799 -0.522629 -0.128941 \u73b0\u5728\u53ef\u4ee5\u4f7f\u7528 statsmodels \u516c\u5f0fAPI\u548cPatsy\u516c\u5f0f\u5b57\u7b26\u4e32\u3002\u89c2\u5bdf statsmodels \u5982\u4f55\u5c06\u7ed3\u679c\u4f5c\u4e3a\u5e26\u6709DataFrame\u5217\u540d\u79f0\u7684Series\u8fd4\u56de\u3002 results = smf.ols('y ~ col0 + col1 + col2', data=data).fit() print(results.params) # Intercept 0.033559 # col0 0.176149 # col1 0.224826 # col2 0.514808 # dtype: float64 \u7ed9\u5b9a\u65b0\u7684\u6837\u672c\u5916\u6570\u636e\u540e\uff0c\u53ef\u4ee5\u6839\u636e\u4f30\u8ba1\u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u9884\u6d4b\u503c\uff1a print(results.predict(data[:5])) # 0 -0.002327 # 1 -0.141904 # 2 0.041226 # 3 -0.323070 # 4 -0.100535 # dtype: float64 \u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u5904\u7406 statsmodels\u4e2d\u7684\u53e6\u4e00\u7c7b\u6a21\u578b\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u3002\u5176\u4e2d\u5305\u62ec\u81ea\u56de\u5f52\u8fc7\u7a0b\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u5176\u4ed6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u4ee5\u53ca\u591a\u53d8\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u3002 \u4e0b\u4f8b\u6a21\u62df\u4e00\u4e9b\u5177\u6709\u81ea\u56de\u5f52\u7ed3\u6784\u548c\u566a\u58f0\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8be5\u6570\u636e\u5177\u6709\u53c2\u6570\u4e3a0.8\u548c-0.4\u7684AR\uff082\uff09\u7ed3\u6784\uff08\u4e24\u4e2a\u6ede\u540e\uff09\u3002 init_x = 4 values = [init_x, init_x] N = 1000 b0 = 0.8 b1 = -0.4 noise = dnorm(0, 0.1, N) for i in range(N): new_x = values[-1] * b0 + values[-2] * b1 + noise[i] values.append(new_x) \u5f53\u62df\u5408\u4e00\u4e2aAR\u6a21\u578b\u65f6\uff0c\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u5305\u542b\u7684\u6ede\u540e\u9879\u7684\u6570\u91cf\uff0c\u6240\u4ee5\u53ef\u4ee5\u7528\u66f4\u5927\u7684\u6ede\u540e\u6570\u6765\u62df\u5408\u8be5\u6a21\u578b\uff1a MAXLAGS = 5 model = sm.tsa.AR(values) results = model.fit(MAXLAGS) print(results.params) # NotImplementedError: AR has been removed from statsmodels and replaced with statsmodels.tsa.ar_model.AutoReg. sikit-learn\u4ecb\u7ecd scikit-learn\uff08http://scikit-learn.org\uff09\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u4e14\u6700\u53d7\u4fe1\u4efb\u7684\u901a\u7528Python\u673a\u5668\u5b66\u4e60\u5e93\u3002\\ \u5b83\u5305\u542b\u5e7f\u6cdb\u7684\u6807\u51c6\u76d1\u7763\u7684\u548c\u65e0\u76d1\u7763\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u7528\u4e8e\u6a21\u578b\u9009\u62e9\u548c\u8bc4\u4f30\u3001\u6570\u636e\u8f6c\u6362\u3001\u6570\u636e\u52a0\u8f7d\u548c\u6a21\u578b\u6301\u4e45\u5316\u7684\u5de5\u5177\u3002\\ \u8fd9\u4e9b\u6a21\u578b\u53ef\u7528\u4e8e\u5206\u7c7b\u3001\u805a\u7c7b\u3001\u9884\u6d4b\u548c\u5176\u4ed6\u5e38\u89c1\u4efb\u52a1\u3002\\ pandas\u975e\u5e38\u9002\u5408\u5728\u6a21\u578b\u62df\u5408\u524d\u5904\u7406\u6570\u636e\u96c6\u3002 \u4e3e\u4e2a\u4f8b\u5b50\uff0c\u7528\u4e00\u4e2aKaggle\u7ade\u8d5b\u7684\u7ecf\u5178\u6570\u636e\u96c6\uff0c\u5173\u4e8e\u6cf0\u5766\u5c3c\u514b\u53f7\u4e58\u5ba2\u7684\u751f\u8fd8\u7387\u3002\u6211\u4eec\u7528pandas\u52a0\u8f7d\u6d4b\u8bd5\u548c\u8bad\u7ec3\u6570\u636e\u96c6\uff1a import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LogisticRegressionCV from sklearn.model_selection import cross_val_score train = pd.read_csv('../datasets/titanic/train.csv') test = pd.read_csv('../datasets/titanic/test.csv') print(train[:4]) # PassengerId Survived Pclass ... Fare Cabin Embarked # 0 1 0 3 ... 7.2500 NaN S # 1 2 1 1 ... 71.2833 C85 C # 2 3 1 3 ... 7.9250 NaN S # 3 4 1 1 ... 53.1000 C123 S \u50cfstatsmodels\u548cscikit-learn\u901a\u5e38\u4e0d\u80fd\u63d0\u4f9b\u7f3a\u5931\u6570\u636e\uff0c\u56e0\u6b64\u6211\u4eec\u8981\u68c0\u67e5\u5404\u5217\uff0c\u770b\u770b\u662f\u5426\u6709\u5305\u542b\u7f3a\u5931\u6570\u636e\uff1a print(train.isnull().sum()) # PassengerId 0 # Survived 0 # Pclass 0 # Name 0 # Sex 0 # Age 177 # SibSp 0 # Parch 0 # Ticket 0 # Fare 0 # Cabin 687 # Embarked 2 # dtype: int64 print(test.isnull().sum()) # PassengerId 0 # Pclass 0 # Name 0 # Sex 0 # Age 86 # SibSp 0 # Parch 0 # Ticket 0 # Fare 1 # Cabin 327 # Embarked 0 # dtype: int64 \u5728\u50cf\u8fd9\u6837\u7684\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u7684\u4f8b\u5b50\u4e2d\uff0c\u4e00\u4e2a\u5178\u578b\u7684\u4efb\u52a1\u662f\u6839\u636e\u6570\u636e\u4e2d\u7684\u7279\u5f81\u6765\u9884\u6d4b\u4e58\u5ba2\u662f\u5426\u80fd\u5e78\u5b58\u4e0b\u6765\u3002\\ \u5c06\u6a21\u578b\u62df\u5408\u5230\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\uff0c\u7136\u540e\u5728\u6837\u672c\u5916\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\\ \u5982\u679c\u7528Age\u4f5c\u4e3a\u9884\u6d4b\uff0c\u4f46\u5b83\u7f3a\u5c11\u6570\u636e\u3002\u9700\u8981\u8fdb\u884c\u7f3a\u5931\u6570\u636e\u63d2\u8865\uff08imputation\uff09\uff0c\u5e76\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u4e2d\u95f4\u503c\u586b\u5145\u4e24\u4e2a\u8868\u4e2d\u7684\u7a7a\u503c\uff1a impute_value = train['Age'].median() train['Age'] = train['Age'].fillna(impute_value) test['Age'] = test['Age'].fillna(impute_value) \u73b0\u5728\u5efa\u7acb\u6a21\u578b\u3002\\ \u6dfb\u52a0\u4e00\u5217IsFemale\u4f5c\u4e3a\u2019Sex\u2019\u5217\u7684\u7f16\u7801\u7248\u672c\uff1a train['IsFemale'] = (train['Sex'] == 'female').astype(int) test['IsFemale'] = (test['Sex'] == 'female').astype(int) \u786e\u5b9a\u4e00\u4e9b\u6a21\u578b\u53d8\u91cf\u5e76\u521b\u5efaNumPy\u6570\u7ec4\uff1a predictors = ['Pclass', 'IsFemale', 'Age'] X_train = train[predictors].values X_test = test[predictors].values y_train = train['Survived'].values print(X_train[:5]) # [[ 3. 0. 22.] # [ 1. 1. 38.] # [ 3. 1. 26.] # [ 1. 1. 35.] # [ 3. 0. 35.]] print(y_train[:5]) # [0 1 1 1 0] \u4f7f\u7528scikit-learn\u7684LogisticRegression\u6a21\u578b\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u5b9e\u4f8b\uff1a model = LogisticRegression() \u4e0estatsmodels\u7c7b\u4f3c\uff0c\u4f7f\u7528\u6a21\u578b\u7684fit\u65b9\u6cd5\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u62df\u5408\u6a21\u578b\uff1a result = model.fit(X_train, y_train) print(result) # LogisticRegression() \u4f7f\u7528model.predict\u4e3a\u6d4b\u8bd5\u6570\u636e\u96c6\u5f62\u6210\u9884\u6d4b\uff1a y_predict = model.predict(X_test) print(y_predict[:10]) # [0 0 0 0 1 0 1 0 1 0] \u5b9e\u9645\u4e0a\uff0c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7ecf\u5e38\u5b58\u5728\u8bb8\u591a\u9644\u52a0\u7684\u590d\u6742\u5c42\u6b21\u3002\\ \u8bb8\u591a\u6a21\u578b\u5177\u6709\u53ef\u4ee5\u8c03\u6574\u7684\u53c2\u6570\uff0c\u5e76\u4e14\u5b58\u5728\u53ef\u7528\u4e8e\u53c2\u6570\u8c03\u6574\u7684\u4ea4\u53c9\u9a8c\u8bc1\u7b49\u6280\u672f\u4ee5\u907f\u514d\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u6570\u636e\u3002\\ \u8fd9\u901a\u5e38\u53ef\u4ee5\u5728\u65b0\u6570\u636e\u4e0a\u4ea7\u751f\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\u6216\u7a33\u5065\u6027\u3002\u4ea4\u53c9\u9a8c\u8bc1\u901a\u8fc7\u5206\u5272\u8bad\u7ec3\u6570\u636e\u6765\u6a21\u62df\u6837\u672c\u5916\u9884\u6d4b\u3002\\ \u57fa\u4e8e\u50cf\u5747\u65b9\u8bef\u5dee\u4e4b\u7c7b\u7684\u6a21\u578b\u51c6\u786e\u5ea6\u5206\u6570\uff0c\u53ef\u4ee5\u5bf9\u6a21\u578b\u53c2\u6570\u6267\u884c\u7f51\u683c\u641c\u7d22\u3002\\ \u4e00\u4e9b\u6a21\u578b\uff0c\u5982\u903b\u8f91\u56de\u5f52\uff0c\u5177\u6709\u5185\u7f6e\u4ea4\u53c9\u9a8c\u8bc1\u7684\u4f30\u8ba1\u7c7b\u3002\\ \u4f8b\u5982\uff0cLogisticRegressionCV\u7c7b\u53ef\u4ee5\u4e0e\u4e00\u4e2a\u53c2\u6570\u4e00\u8d77\u4f7f\u7528\uff0c\u8be5\u53c2\u6570\u8868\u793a\u7f51\u683c\u641c\u7d22\u5728\u6a21\u578b\u6b63\u5219\u5316\u53c2\u6570C\u4e0a\u7684\u7ec6\u81f4\u5ea6\uff1a model_cv = LogisticRegressionCV() result = model_cv.fit(X_train, y_train) print(result) # LogisticRegressionCV() \u8981\u624b\u52a8\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u4f7f\u7528cross_val_score\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5904\u7406\u6570\u636e\u62c6\u5206\u8fc7\u7a0b\u3002\\ \u4f8b\u5982\uff0c\u4e3a\u4e86\u7528\u6211\u4eec\u7684\u6a21\u578b\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u56db\u4e2a\u975e\u91cd\u53e0\u5206\u5272\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u8fd9\u6837\u505a\uff1a model = LogisticRegression(C=10) scores = cross_val_score(model, X_train, y_train, cv=4) print(scores) # [0.77578475 0.79820628 0.77578475 0.78828829] \u9ed8\u8ba4\u8bc4\u5206\u6307\u6807\u662f\u4f9d\u8d56\u4e8e\u6a21\u578b\u7684\uff0c\u4f46\u53ef\u4ee5\u9009\u62e9\u660e\u786e\u7684\u8bc4\u5206\u51fd\u6570\u3002\u7ecf\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u7684\u6a21\u578b\u9700\u8981\u66f4\u957f\u65f6\u95f4\u7684\u8bad\u7ec3\uff0c\u4f46\u901a\u5e38\u53ef\u4ee5\u4ea7\u751f\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u3002","title":"Python\u5efa\u6a21\u5e93\u4ecb\u7ecd"},{"location":"python/DataAnalysis/ch11/#python","text":"","title":"Python\u5efa\u6a21\u5e93\u4ecb\u7ecd"},{"location":"python/DataAnalysis/ch11/#pandas","text":"\u4ecb\u7ecd\u4e24\u4e2a\u6d41\u884c\u7684\u5efa\u6a21\u5de5\u5177\u5305\uff1a [statsmodels]http://statsmodels.org\uff09 [scikit-learn]http://scikit-learn.org\uff09 import pandas as pd import numpy as np \u4f7f\u7528pandas\u7528\u4e8e\u6570\u636e\u8f7d\u5165\u548c\u6570\u636e\u6e05\u6d17\uff0c\u4e4b\u540e\u5207\u6362\u5230\u6a21\u578b\u5e93\u53bb\u5efa\u7acb\u6a21\u578b\u662f\u4e00\u4e2a\u5e38\u89c1\u7684\u6a21\u578b\u5f00\u53d1\u5de5\u4f5c\u6d41\u3002 \u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7279\u5f81\u5de5\u7a0b\u662f\u6a21\u578b\u5f00\u53d1\u7684\u91cd\u8981\u90e8\u5206\u4e4b\u4e00\u3002 \u7279\u5f81\u5de5\u7a0b\u662f\u6307\u4ece\u539f\u751f\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u53ef\u7528\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u7684\u6709\u6548\u4fe1\u606f\u7684\u6570\u636e\u8f6c\u6362\u8fc7\u7a0b\u6216\u5206\u6790\u3002 pandas\u548c\u5176\u4ed6\u5206\u6790\u5e93\u7684\u7ed3\u5408\u70b9\u901a\u5e38\u662fNumPy\u6570\u7ec4\u3002 \u8981\u5c06DataFrame\u8f6c\u6362\u4e3aNumPy\u6570\u7ec4\uff0c\u4f7f\u7528 .values \u5c5e\u6027\uff1a df = pd.DataFrame( { 'x0': [1, 2, 3, 4, 5], 'x1': [0.01, -0.01, 0.25, -4.1, 0.], 'y': [-1.5, 0., 3.6, 1.3, -2.] } ) print(df) # x0 x1 y # 0 1 0.01 -1.5 # 1 2 -0.01 0.0 # 2 3 0.25 3.6 # 3 4 -4.10 1.3 # 4 5 0.00 -2.0 print(df.columns) # Index(['x0', 'x1', 'y'], dtype='object') print(df.values) # [[ 1. 0.01 -1.5 ] # [ 2. -0.01 0. ] # [ 3. 0.25 3.6 ] # [ 4. -4.1 1.3 ] # [ 5. 0. -2. ]] \u5c06\u6570\u7ec4\u518d\u8f6c\u6362\u4e3aDataFrame\uff1a df2 = pd.DataFrame(df.values, columns=['one', 'two', 'three']) # \u9012\u4e00\u4e2a\u542b\u6709\u5217\u540d\u7684\u4e8c\u7ef4ndarray print(df2) # one two three # 0 1.0 0.01 -1.5 # 1 2.0 -0.01 0.0 # 2 3.0 0.25 3.6 # 3 4.0 -4.10 1.3 # 4 5.0 0.00 -2.0 .values \u5c5e\u6027\u4e00\u822c\u5728\u6570\u636e\u662f\u540c\u6784\u5316\u7684\u65f6\u5019\u4f7f\u7528\u2014\u2014\u4f8b\u5982\uff0c\u90fd\u662f\u6570\u5b57\u7c7b\u578b\u7684\u65f6\u5019\u3002\u5982\u679c\u6570\u636e\u662f\u5f02\u6784\u5316\u7684\uff0c\u7ed3\u679c\u5c06\u662fPython\u5bf9\u8c61\u7684 ndarray \uff1a \u6dfb\u52a0\u4e00\u4e2a\u975e\u6570\u5b57\u7c7b\u578b\u7684\u5217\u3002 df3 = df.copy() df3['category'] = pd.Categorical(['a', 'b', 'a', 'a', 'b'], categories=['a', 'b']) print(df3) # x0 x1 y category # 0 1 0.01 -1.5 a # 1 2 -0.01 0.0 b # 2 3 0.25 3.6 a # 3 4 -4.10 1.3 a # 4 5 0.00 -2.0 b print(df3.values) # [[1 0.01 -1.5 'a'] # [2 -0.01 0.0 'b'] # [3 0.25 3.6 'a'] # [4 -4.1 1.3 'a'] # [5 0.0 -2.0 'b']] \u901a\u8fc7 loc \u7d22\u5f15\u548c values \u4f7f\u7528\u4e00\u90e8\u5206\u5217\u6570\u636e\u3002 model_cols = ['x0', 'x1'] result = df.loc[:, model_cols].values print(result) # [[ 1. 0.01] # [ 2. -0.01] # [ 3. 0.25] # [ 4. -4.1 ] # [ 5. 0. ]] \u5982\u679c\u6211\u4f7f\u7528\u865a\u62df\u53d8\u91cf\u66ff\u4ee3 df3 \u7684 category \u5217\uff0c\u5148\u521b\u5efa\u865a\u62df\u53d8\u91cf\uff0c\u4e4b\u540e\u5220\u9664 categroy \u5217\uff0c\u7136\u540e\u8fde\u63a5\u7ed3\u679c\uff1a dummies = pd.get_dummies(df3.category, prefix='category') print(dummies) # category_a category_b # 0 1 0 # 1 0 1 # 2 1 0 # 3 1 0 # 4 0 1 data_with_dummies = df3.drop('category', axis=1).join(dummies) print(data_with_dummies) # x0 x1 y category_a category_b # 0 1 0.01 -1.5 1 0 # 1 2 -0.01 0.0 0 1 # 2 3 0.25 3.6 1 0 # 3 4 -4.10 1.3 1 0 # 4 5 0.00 -2.0 0 1","title":"pandas\u4e0e\u5efa\u6a21\u4ee3\u7801\u7684\u7ed3\u5408"},{"location":"python/DataAnalysis/ch11/#patsy","text":"\u6837\u672c\u7684\u8868\u793a\u5f62\u5f0f\uff1a \u5728\u6570\u636e\u6316\u6398\u8fc7\u7a0b\u4e2d\uff0c\u6837\u672c\u4ee5\u7279\u5f81\u503c\u77e9\u9635X\u548c\u76ee\u6807\u503c\u5411\u91cfY\u7684\u5f62\u5f0f\u8868\u793a\u3002 \u5bb9\u91cf\u4e3a n \uff0c\u6709 m \u4e2a\u7279\u5f81\u7684\u6837\u672c\uff0c\u5176\u7279\u5f81\u503c\u77e9\u9635X\u7531 n \u4e2a\u7ef4\u5ea6\u4e3a m \u7684\u5217\u5411\u91cf\u7ec4\u6210\uff0c\u7b2c j \u4e2a\u5217\u5411\u91cf\u4e3a\u6837\u672c\u4e2d\u7b2c j \u4e2a\u4e2a\u4f53\u7684\u7279\u5f81\u503c\u5411\u91cf\uff1b \u76ee\u6807\u503c\u5411\u91cfY\u7684\u7b2c j \u4e2a\u5206\u91cf\u4e3a\u6837\u672c\u4e2d\u7b2c j \u4e2a\u4e2a\u4f53\u7684\u76ee\u6807\u503c\u3002 \u53c2\u8003\uff1a How formulas work [Patsy](https://patsy.readthedocs.io/\uff09\u662f\u4e00\u4e2a\u7528\u4e8e\u63cf\u8ff0\u7edf\u8ba1\u6a21\u578b\uff08\u5c24\u5176\u662f\u7ebf\u6027\u6a21\u578b\uff09\u7684Python\u5e93\u3002 \u5b83\u4f7f\u7528\u4e00\u79cd\u5c0f\u578b\u57fa\u4e8e\u5b57\u7b26\u4e32\u7684\"\u516c\u5f0f\u8bed\u6cd5\"\u3002 Patsy\u80fd\u591f\u5f88\u597d\u5730\u652f\u6301 statsmodels \u4e2d\u7279\u5b9a\u7684\u7ebf\u6027\u6a21\u578b\u3002 \u50cf y ~ x0 + x1 \u8fd9\u79cd a + b \u7684\u8bed\u6cd5\u5e76\u4e0d\u4ee3\u8868\u5c06 a \u548c b \u76f8\u52a0\uff0c\u800c\u662f\u4ee3\u8868\u4e3a\u6a21\u578b\u521b\u5efa\u7684\u8bbe\u8ba1\u77e9\u9635\u7684\u672f\u8bed\uff08terms in the design matrix\uff09\u3002 patsy.dmatrices \u51fd\u6570\uff0c\u53d6\u4e00\u4e2a\u516c\u5f0f\u5b57\u7b26\u4e32\u548c\u4e00\u4e2a\u6570\u636e\u96c6\uff08\u53ef\u4ee5\u4f7fDataFrame\u6216dict\uff09\uff0c\u7136\u540e\u4e3a\u7ebf\u6027\u6a21\u578b\u4ea7\u751f\u8bbe\u8ba1\u77e9\u9635\uff1a import pandas as pd import numpy as np import patsy from patsy import dmatrices, dmatrix, demo_data df = pd.DataFrame( { 'x0': [1, 2, 3, 4, 5], 'x1': [0.01, -0.01, 0.25, -4.1, 0.], 'y': [-1.5, 0., 3.6, 1.3, -2.] } ) print(df) # x0 x1 y # 0 1 0.01 -1.5 # 1 2 -0.01 0.0 # 2 3 0.25 3.6 # 3 4 -4.10 1.3 # 4 5 0.00 -2.0 y, X = patsy.dmatrices('y ~ x0 + x1', df) print(y) # [[-1.5] # [ 0. ] # [ 3.6] # [ 1.3] # [-2. ]] print(X) # [[ 1. 1. 0.01] # [ 1. 2. -0.01] # [ 1. 3. 0.25] # [ 1. 4. -4.1 ] # [ 1. 5. 0. ]] print(np.asarray(y)) # Patsy\u7684DesignMatrix\u5b9e\u4f8b\uff0c\u542b\u6709\u9644\u52a0\u5143\u6570\u636e\u7684NumPy.ndarray # [[-1.5] # [ 0. ] # [ 3.6] # [ 1.3] # [-2. ]] print(np.asarray(X)) # Patsy\u7684DesignMatrix\u5b9e\u4f8b\uff0c\u542b\u6709\u9644\u52a0\u5143\u6570\u636e\u7684NumPy.ndarray # [[ 1. 1. 0.01] # [ 1. 2. -0.01] # [ 1. 3. 0.25] # [ 1. 4. -4.1 ] # [ 1. 5. 0. ]] \u4e0a\u9762X\u8f93\u51fa\u4e2d\u7684Intercept(\u6700\u5de6\u8fb9\u4e00\u5217)\u662f\u4ece\u54ea\u91cc\u6765\u7684\u3002 \u8fd9\u5176\u5b9e\u662f\u7ebf\u6027\u6a21\u578b\u7684\u4e00\u4e2a\u60ef\u4f8b\uff0c\u6bd4\u5982\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u6cd5\uff08ordinary least squares regression\uff09\u3002 \u53ef\u4ee5\u53bb\u6389\u8fd9\u4e2a\u622a\u8ddd\uff08intercept\uff09\uff0c\u901a\u8fc7 y ~ x0 + x1 + 0 \u7ed9\u6a21\u578b\u3002 y, X = patsy.dmatrices('y ~ x0 + x1 + 0', df) print(X) # [[ 1. 0.01] # [ 2. -0.01] # [ 3. 0.25] # [ 4. -4.1 ] # [ 5. 0. ]] \u8fd9\u79cdPatsy\u5bf9\u8c61\u53ef\u4ee5\u76f4\u63a5\u4f20\u5165\u4e00\u4e2a\u7b97\u6cd5\uff0c\u6bd4\u5982 numpy.linalg.lstsq \uff0c\u6765\u8fdb\u884c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u7684\u8ba1\u7b97 coef, resid, _, _ =np.linalg.lstsq(X, y, rcond=1) # \u6700\u5c0f\u4e8c\u4e58\u6cd5 print(coef) # [[ 0.00925424] # [-0.25485421]] print(resid) # [19.72552896] coef = pd.Series(coef.squeeze(), index=X.design_info.column_names) print(coef) # x0 0.009254 # x1 -0.254854 # dtype: float64","title":"\u4f7f\u7528Patsy\u521b\u5efa\u6a21\u578b\u63cf\u8ff0"},{"location":"python/DataAnalysis/ch11/#patsy_1","text":"\u53ef\u4ee5\u5c06Python\u4ee3\u7801\u6df7\u5408\u5230\u4f60\u7684Patsy\u516c\u5f0f\u4e2d\uff0c\u5728\u6267\u884c\u516c\u5f0f\u65f6\uff0cPatsy\u5e93\u5c06\u5c1d\u8bd5\u5728\u5c01\u95ed\u4f5c\u7528\u57df\u4e2d\u5bfb\u627e\u4f60\u4f7f\u7528\u7684\u51fd\u6570\uff1a y, X = patsy.dmatrices('y ~ x0 + np.log(np.abs(x1) +1)', df) print(X) # [[1. 1. 0.00995033] # [1. 2. 0.00995033] # [1. 3. 0.22314355] # [1. 4. 1.62924054] # [1. 5. 0. ]] \u4e00\u4e9b\u5e38\u7528\u7684\u53d8\u91cf\u53d8\u6362\uff0c\u5305\u62ec\u6807\u51c6\u5316\uff08standardizing (\u5e73\u5747\u503c0\uff0c\u65b9\u5dee1\uff09\u548c\u4e2d\u5fc3\u5316\uff08\u51cf\u53bb\u5e73\u5747\u503c\uff09\u3002Patsy\u6709\u5185\u5efa\u7684\u51fd\u6570\u53ef\u4ee5\u505a\u5230\u8fd9\u4e9b\u3002 y, X = patsy.dmatrices('y ~ standardize(x0) + center(x1)', df) print(X) # [[ 1. -1.41421356 0.78 ] # [ 1. -0.70710678 0.76 ] # [ 1. 0. 1.02 ] # [ 1. 0.70710678 -3.33 ] # [ 1. 1.41421356 0.77 ]] \u4f5c\u4e3a\u5efa\u6a21\u7684\u4e00\u90e8\u5206\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u5728\u4e00\u4e2a\u6570\u636e\u53ca\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u5728\u53e6\u4e00\u4e2a\u6570\u636e\u53ca\u4e0a\u8bc4\u4ef7\u6a21\u578b\u3002 \u5f53\u4f7f\u7528\u4e2d\u5fc3\u5316\u6216\u6807\u51c6\u5316\u8fd9\u6837\u7684\u8f6c\u6362\u65f6\uff0c\u6211\u4eec\u5fc5\u987b\u6ce8\u610f\uff0c\u5fc5\u987b\u7528\u6a21\u578b\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u505a\u9884\u6d4b\u3002 \u8fd9\u53eb\u505a\u72b6\u6001\u53d8\u6362\uff08stateful transformations\uff09\u3002 \u56e0\u4e3a\u6211\u4eec\u5fc5\u987b\u7528\u539f\u672c\u5728\u8bad\u7ec3\u96c6\u4e0a\u5f97\u5230\u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u7528\u5728\u65b0\u7684\u6570\u636e\u96c6\u4e0a\u3002 new_df = pd.DataFrame( { 'x0': [6, 7, 8, 9], 'x1': [3.1, -0.5, 0, 2.3], 'y': [1, 2, 3, 4] } ) new_X = patsy.build_design_matrices([X.design_info], new_df) print(new_X) # [DesignMatrix with shape (4, 3) # Intercept standardize(x0) center(x1) # 1 2.12132 3.87 # 1 2.82843 0.27 # 1 3.53553 0.77 # 1 4.24264 3.07 # Terms: # 'Intercept' (column 0), 'standardize(x0)' (column 1), 'center(x1)' (column 2)] \u56e0\u4e3a\u52a0\u53f7\uff08+\uff09\u5728Patsy\u516c\u5f0f\u7684\u4e0a\u4e0b\u6587\u4e2d\u5e76\u4e0d\u662f\u52a0\u6cd5\u7684\u610f\u601d\uff0c\u5f53\u60f3\u8981\u5bf9\u6570\u636e\u96c6\u4e2d\u4e24\u5217\u6309\u5217\u540d\u76f8\u52a0\u65f6\uff0c\u5fc5\u987b\u5c06\u5217\u540d\u5c01\u88c5\u5230\u7279\u6b8a\u7684I\u51fd\u6570\u4e2d\uff1a y, X = patsy.dmatrices('y ~ I(x0 + x1)', df) print(X) # [[ 1. 1.01] # [ 1. 1.99] # [ 1. 3.25] # [ 1. -0.1 ] # [ 1. 5. ]]","title":"Patsy\u516c\u5f0f\u4e2d\u7684\u6570\u636e\u8f6c\u6362"},{"location":"python/DataAnalysis/ch11/#categoricalpatsy","text":"\u975e\u6570\u503c\u578b\u6570\u636e\u53ef\u4ee5\u901a\u8fc7\u5f88\u591a\u79cd\u65b9\u5f0f\u53d8\u4e3a\u4e00\u4e2a\u6a21\u578b\u8bbe\u8ba1\u77e9\u9635\u3002 \u5f53\u6211\u4eec\u5728Patsy\u516c\u5f0f\u4e2d\u4f7f\u7528\u975e\u6570\u503c\u672f\u8bed\u65f6\uff0c\u8fd9\u4e9b\u7c7b\u578b\u6570\u636e\u9ed8\u8ba4\u4f1a\u88ab\u8f6c\u6362\u4e3a\u54d1\u53d8\u91cf\u3002\u5982\u679c\u6709\u622a\u8ddd\uff0c\u4e00\u4e2a\u5c42\u7ea7\u4e0a\u7684\u622a\u8ddd\u4f1a\u88ab\u820d\u5f03\uff0c\u9632\u6b62\u51fa\u73b0\u5171\u7ebf\u6027\u3002 data = pd.DataFrame( { 'key1': ['a', 'a', 'b', 'b', 'a', 'b', 'a', 'b'], 'key2': [0, 1, 0, 1, 0, 1, 0, 0], 'v1': [1, 2, 3, 4, 5, 6, 7, 8], 'v2': [-1, 0, 2.5, -0.5, 4., -1.2, 0.2, -1.7] } ) y, X = patsy.dmatrices('v2 ~ key1', data) print(y) # [[-1. ] # [ 0. ] # [ 2.5] # [-0.5] # [ 4. ] # [-1.2] # [ 0.2] # [-1.7]] print(X) # [[1. 0.] # [1. 0.] # [1. 1.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 1.]] \u5982\u679c\u4ece\u6a21\u578b\u4e2d\u820d\u5f03\u622a\u8ddd\uff0c\u6bcf\u4e2a\u7c7b\u578b\u7684\u5217\u4f1a\u88ab\u5305\u542b\u5728\u6a21\u578b\u8bbe\u8ba1\u77e9\u9635\u4e2d\u3002 y, X = patsy.dmatrices('v2 ~ key1 + 0', data) print(X) # [[1. 0.] # [1. 0.] # [0. 1.] # [0. 1.] # [1. 0.] # [0. 1.] # [1. 0.] # [0. 1.]] \u6570\u503c\u578b\u5217\u53ef\u4ee5\u901a\u8fc7C\u51fd\u6570\uff0c\u53d8\u4e3a\u7c7b\u578b\u5217\uff1a y, X = patsy.dmatrices('v2 ~ C(key2)', data) print(X) # [[1. 0.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 1.] # [1. 0.] # [1. 0.]] \u5f53\u6211\u4eec\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u4f7f\u7528\u591a\u4e2a\u7c7b\u578b\u672f\u8bed\u65f6\uff0c\u4f1a\u53d8\u5f97\u66f4\u590d\u6742\u4e00\u4e9b\uff0c\u4e4b\u524d\u7528key1:key2\u7684\u5f62\u5f0f\u6765\u5305\u542b\u6709\u4ea4\u96c6\u7684\u672f\u8bed\uff0c \u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u7528\u4e8e\u4f7f\u7528\u591a\u4e2a\u672f\u8bed\uff0c\u4f8b\u5982\uff0c\u4e00\u4e2a\u65b9\u6cd5\u5206\u6790\u6a21\u578b\uff08analysis of variance (ANOVA) models\uff09\uff1a data['key2'] = data['key2'].map({0: 'zero', 1: 'one'}) print(data) # key1 key2 v1 v2 # 0 a zero 1 -1.0 # 1 a one 2 0.0 # 2 b zero 3 2.5 # 3 b one 4 -0.5 # 4 a zero 5 4.0 # 5 b one 6 -1.2 # 6 a zero 7 0.2 # 7 b zero 8 -1.7 y, X = patsy.dmatrices('v2 ~ key1 + key2', data) print(X) # [[1. 0. 1.] # [1. 0. 0.] # [1. 1. 1.] # [1. 1. 0.] # [1. 0. 1.] # [1. 1. 0.] # [1. 0. 1.] # [1. 1. 1.]] y, X = patsy.dmatrices('v2 ~ key1 + key2 + key1:key2', data) print(X) # [[1. 0. 1. 0.] # [1. 0. 0. 0.] # [1. 1. 1. 1.] # [1. 1. 0. 0.] # [1. 0. 1. 0.] # [1. 1. 0. 0.] # [1. 0. 1. 0.] # [1. 1. 1. 1.]]","title":"\u5206\u7c7b\u6570\u636eCategorical\u548cPatsy"},{"location":"python/DataAnalysis/ch11/#statsmodels","text":"statsmodels \u662f\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u62df\u5408\u591a\u79cd\u7edf\u8ba1\u6a21\u578b\uff0c\u6267\u884c\u7edf\u8ba1\u6d4b\u8bd5\u4ee5\u53ca\u6570\u636e\u63a2\u7d22\u548c\u53ef\u89c6\u5316\u3002 statsmodels \u5305\u542b\u66f4\u591a\u7684\u201c\u7ecf\u5178\u201d\u9891\u7387\u5b66\u6d3e\u7edf\u8ba1\u65b9\u6cd5\uff0c\u800c\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u5728\u5176\u4ed6\u5e93\u4e2d\u627e\u5230\u3002 \u5305\u542b\u5728statsmodels\u4e2d\u7684\u4e00\u4e9b\u6a21\u578b\uff1a \u7ebf\u6027\u6a21\u578b\uff0c\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u548c\u9c81\u68d2\u7ebf\u6027\u6a21\u578b \u7ebf\u6027\u6df7\u5408\u6548\u5e94\u6a21\u578b \u65b9\u5dee\u5206\u6790\uff08ANOVA\uff09\u65b9\u6cd5 \u65f6\u95f4\u5e8f\u5217\u8fc7\u7a0b\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b \u5e7f\u4e49\u7684\u77e9\u91cf\u6cd5 import pandas as pd import statsmodels.api as sm import statsmodels.formula.api as smf import numpy as np import random","title":"statsmodels\u4ecb\u7ecd"},{"location":"python/DataAnalysis/ch11/#_1","text":"\u7edf\u8ba1\u6a21\u578b\u4e2d\u6709\u51e0\u79cd\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u4ece\u8f83\u57fa\u672c\u7684\uff08\u4f8b\u5982\uff0c\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\uff09\u5230\u66f4\u590d\u6742\u7684\uff08\u4f8b\u5982\uff0c\u8fed\u4ee3\u91cd\u65b0\u52a0\u6743\u7684\u6700\u5c0f\u4e8c\u4e58\uff09\u3002 tatsmodels \u4e2d\u7684\u7ebf\u6027\u6a21\u578b\u6709\u4e24\u4e2a\u4e0d\u540c\u7684\u4e3b\u8981\u63a5\u53e3\uff0c\u8fd9\u4e9b\u63a5\u53e3\u901a\u8fc7\u8fd9\u4e9bAPI\u6a21\u5757\u5bfc\u5165\u6765\u8bbf\u95ee\uff1a \u57fa\u4e8e\u6570\u7ec4 \u57fa\u4e8e\u516c\u5f0f \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u8c03\u7528\u5df2\u77e5\u53c2\u6570beta\u7684\u6a21\u578b\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c dnorm \u662f\u7528\u4e8e\u751f\u6210\u5177\u6709\u7279\u5b9a\u5747\u503c\u548c\u65b9\u5dee\u7684\u6b63\u6001\u5206\u5e03\u6570\u636e\u7684\u8f85\u52a9\u51fd\u6570\u3002 def dnorm (mean, variance, size=1): if isinstance(size, int): size = size, return mean + np.sqrt(variance) * np.random.randn(*size) np.random.seed(12345) N = 100 X = np.c_[ dnorm(0, 0.4, size=N), dnorm(0, 0.6, size=N), dnorm(0, 0.2, size=N) ] eps = dnorm(0, 0.1, size=N) beta = [0.1, 0.3, 0.5] y = np.dot(X, beta) + eps print(X[:5]) # [[-0.12946849 -1.21275292 0.50422488] # [ 0.30291036 -0.43574176 -0.25417986] # [-0.32852189 -0.02530153 0.13835097] # [-0.35147471 -0.71960511 -0.25821463] # [ 1.2432688 -0.37379916 -0.52262905]] print(y[:5]) # [ 0.42786349 -0.67348041 -0.09087764 -0.48949442 -0.12894109] \u7ebf\u6027\u6a21\u578b\u901a\u5e38\u4e0e\u6211\u4eec\u5728Patsy\u4e2d\u770b\u5230\u7684\u622a\u8ddd\u9879\u76f8\u5339\u914d\u3002 sm.add_constant \u51fd\u6570\u53ef\u4ee5\u5c06\u622a\u8ddd\u5217\u6dfb\u52a0\u5230\u73b0\u6709\u77e9\u9635\uff1a X_model = sm.add_constant(X) print(X_model[:5]) # [[ 1. -0.12946849 -1.21275292 0.50422488] # [ 1. 0.30291036 -0.43574176 -0.25417986] # [ 1. -0.32852189 -0.02530153 0.13835097] # [ 1. -0.35147471 -0.71960511 -0.25821463] # [ 1. 1.2432688 -0.37379916 -0.52262905]] sm.OLS \u7c7b\u53ef\u4ee5\u62df\u5408\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u7ebf\u6027\u56de\u5f52\uff1a model = sm.OLS(y, X) \u6a21\u578b\u7684 fit \u65b9\u6cd5\u8fd4\u56de\u4e00\u4e2a\u56de\u5f52\u7ed3\u679c\u5bf9\u8c61\uff0c\u8be5\u5bf9\u8c61\u5305\u542b\u4e86\u4f30\u8ba1\u7684\u6a21\u578b\u53c2\u6570\u548c\u5176\u4ed6\u7684\u8bca\u65ad\uff1a results = model.fit() print(results.params) # [0.17826108 0.22303962 0.50095093] \u8c03\u7528 summary \u65b9\u6cd5\u53ef\u4ee5\u6253\u5370\u51fa\u4e00\u4e2a\u6a21\u578b\u7684\u8bca\u65ad\u7ec6\u8282\uff0c\u6b64\u5904\u7684\u53c2\u6570\u540d\u79f0\u5df2\u88ab\u8d4b\u4e88\u901a\u7528\u540d\u79f0 x1 \u3001 x2 \u7b49\uff1a print(results.summary()) # OLS Regression Results # ======================================================================================= # Dep. Variable: y R-squared (uncentered): 0.430 # Model: OLS Adj. R-squared (uncentered): 0.413 # Method: Least Squares F-statistic: 24.42 # Date: Sat, 16 Oct 2021 Prob (F-statistic): 7.44e-12 # Time: 14:21:45 Log-Likelihood: -34.305 # No. Observations: 100 AIC: 74.61 # Df Residuals: 97 BIC: 82.42 # Df Model: 3 # Covariance Type: nonrobust # ============================================================================== # coef std err t P>|t| [0.025 0.975] # ------------------------------------------------------------------------------ # x1 0.1783 0.053 3.364 0.001 0.073 0.283 # x2 0.2230 0.046 4.818 0.000 0.131 0.315 # x3 0.5010 0.080 6.237 0.000 0.342 0.660 # ============================================================================== # Omnibus: 4.662 Durbin-Watson: 0 -0.002327 # Prob(Omnibus): 0.097 Jarque-Bera (JB): 4.098 # Skew: 0.481 Prob(JB): 0.129 # Kurtosis: 3.243 Cond. No. 1.74 # ============================================================================== # # Notes: # [1] R\u00b2 is computed without centering (uncentered) since the model does not contain a constant. # [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \u5047\u8bbe\u6240\u6709\u6a21\u578b\u53c2\u6570\u90fd\u5728DataFrame\u4e2d\uff1a data = pd.DataFrame(X, columns=['col0', 'col1', 'col2']) data['y'] = y print(data[:5]) # col0 col1 col2 y # 0 -0.129468 -1.212753 0.504225 0.427863 # 1 0.302910 -0.435742 -0.254180 -0.673480 # 2 -0.328522 -0.025302 0.138351 -0.090878 # 3 -0.351475 -0.719605 -0.258215 -0.489494 # 4 1.243269 -0.373799 -0.522629 -0.128941 \u73b0\u5728\u53ef\u4ee5\u4f7f\u7528 statsmodels \u516c\u5f0fAPI\u548cPatsy\u516c\u5f0f\u5b57\u7b26\u4e32\u3002\u89c2\u5bdf statsmodels \u5982\u4f55\u5c06\u7ed3\u679c\u4f5c\u4e3a\u5e26\u6709DataFrame\u5217\u540d\u79f0\u7684Series\u8fd4\u56de\u3002 results = smf.ols('y ~ col0 + col1 + col2', data=data).fit() print(results.params) # Intercept 0.033559 # col0 0.176149 # col1 0.224826 # col2 0.514808 # dtype: float64 \u7ed9\u5b9a\u65b0\u7684\u6837\u672c\u5916\u6570\u636e\u540e\uff0c\u53ef\u4ee5\u6839\u636e\u4f30\u8ba1\u7684\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u9884\u6d4b\u503c\uff1a print(results.predict(data[:5])) # 0 -0.002327 # 1 -0.141904 # 2 0.041226 # 3 -0.323070 # 4 -0.100535 # dtype: float64","title":"\u8bc4\u4f30\u7ebf\u6027\u6a21\u578b"},{"location":"python/DataAnalysis/ch11/#_2","text":"statsmodels\u4e2d\u7684\u53e6\u4e00\u7c7b\u6a21\u578b\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u3002\u5176\u4e2d\u5305\u62ec\u81ea\u56de\u5f52\u8fc7\u7a0b\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u5176\u4ed6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u4ee5\u53ca\u591a\u53d8\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u3002 \u4e0b\u4f8b\u6a21\u62df\u4e00\u4e9b\u5177\u6709\u81ea\u56de\u5f52\u7ed3\u6784\u548c\u566a\u58f0\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8be5\u6570\u636e\u5177\u6709\u53c2\u6570\u4e3a0.8\u548c-0.4\u7684AR\uff082\uff09\u7ed3\u6784\uff08\u4e24\u4e2a\u6ede\u540e\uff09\u3002 init_x = 4 values = [init_x, init_x] N = 1000 b0 = 0.8 b1 = -0.4 noise = dnorm(0, 0.1, N) for i in range(N): new_x = values[-1] * b0 + values[-2] * b1 + noise[i] values.append(new_x) \u5f53\u62df\u5408\u4e00\u4e2aAR\u6a21\u578b\u65f6\uff0c\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u5305\u542b\u7684\u6ede\u540e\u9879\u7684\u6570\u91cf\uff0c\u6240\u4ee5\u53ef\u4ee5\u7528\u66f4\u5927\u7684\u6ede\u540e\u6570\u6765\u62df\u5408\u8be5\u6a21\u578b\uff1a MAXLAGS = 5 model = sm.tsa.AR(values) results = model.fit(MAXLAGS) print(results.params) # NotImplementedError: AR has been removed from statsmodels and replaced with statsmodels.tsa.ar_model.AutoReg.","title":"\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u5904\u7406"},{"location":"python/DataAnalysis/ch11/#sikit-learn","text":"scikit-learn\uff08http://scikit-learn.org\uff09\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u4e14\u6700\u53d7\u4fe1\u4efb\u7684\u901a\u7528Python\u673a\u5668\u5b66\u4e60\u5e93\u3002\\ \u5b83\u5305\u542b\u5e7f\u6cdb\u7684\u6807\u51c6\u76d1\u7763\u7684\u548c\u65e0\u76d1\u7763\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u7528\u4e8e\u6a21\u578b\u9009\u62e9\u548c\u8bc4\u4f30\u3001\u6570\u636e\u8f6c\u6362\u3001\u6570\u636e\u52a0\u8f7d\u548c\u6a21\u578b\u6301\u4e45\u5316\u7684\u5de5\u5177\u3002\\ \u8fd9\u4e9b\u6a21\u578b\u53ef\u7528\u4e8e\u5206\u7c7b\u3001\u805a\u7c7b\u3001\u9884\u6d4b\u548c\u5176\u4ed6\u5e38\u89c1\u4efb\u52a1\u3002\\ pandas\u975e\u5e38\u9002\u5408\u5728\u6a21\u578b\u62df\u5408\u524d\u5904\u7406\u6570\u636e\u96c6\u3002 \u4e3e\u4e2a\u4f8b\u5b50\uff0c\u7528\u4e00\u4e2aKaggle\u7ade\u8d5b\u7684\u7ecf\u5178\u6570\u636e\u96c6\uff0c\u5173\u4e8e\u6cf0\u5766\u5c3c\u514b\u53f7\u4e58\u5ba2\u7684\u751f\u8fd8\u7387\u3002\u6211\u4eec\u7528pandas\u52a0\u8f7d\u6d4b\u8bd5\u548c\u8bad\u7ec3\u6570\u636e\u96c6\uff1a import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LogisticRegressionCV from sklearn.model_selection import cross_val_score train = pd.read_csv('../datasets/titanic/train.csv') test = pd.read_csv('../datasets/titanic/test.csv') print(train[:4]) # PassengerId Survived Pclass ... Fare Cabin Embarked # 0 1 0 3 ... 7.2500 NaN S # 1 2 1 1 ... 71.2833 C85 C # 2 3 1 3 ... 7.9250 NaN S # 3 4 1 1 ... 53.1000 C123 S \u50cfstatsmodels\u548cscikit-learn\u901a\u5e38\u4e0d\u80fd\u63d0\u4f9b\u7f3a\u5931\u6570\u636e\uff0c\u56e0\u6b64\u6211\u4eec\u8981\u68c0\u67e5\u5404\u5217\uff0c\u770b\u770b\u662f\u5426\u6709\u5305\u542b\u7f3a\u5931\u6570\u636e\uff1a print(train.isnull().sum()) # PassengerId 0 # Survived 0 # Pclass 0 # Name 0 # Sex 0 # Age 177 # SibSp 0 # Parch 0 # Ticket 0 # Fare 0 # Cabin 687 # Embarked 2 # dtype: int64 print(test.isnull().sum()) # PassengerId 0 # Pclass 0 # Name 0 # Sex 0 # Age 86 # SibSp 0 # Parch 0 # Ticket 0 # Fare 1 # Cabin 327 # Embarked 0 # dtype: int64 \u5728\u50cf\u8fd9\u6837\u7684\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u7684\u4f8b\u5b50\u4e2d\uff0c\u4e00\u4e2a\u5178\u578b\u7684\u4efb\u52a1\u662f\u6839\u636e\u6570\u636e\u4e2d\u7684\u7279\u5f81\u6765\u9884\u6d4b\u4e58\u5ba2\u662f\u5426\u80fd\u5e78\u5b58\u4e0b\u6765\u3002\\ \u5c06\u6a21\u578b\u62df\u5408\u5230\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\uff0c\u7136\u540e\u5728\u6837\u672c\u5916\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\\ \u5982\u679c\u7528Age\u4f5c\u4e3a\u9884\u6d4b\uff0c\u4f46\u5b83\u7f3a\u5c11\u6570\u636e\u3002\u9700\u8981\u8fdb\u884c\u7f3a\u5931\u6570\u636e\u63d2\u8865\uff08imputation\uff09\uff0c\u5e76\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u4e2d\u95f4\u503c\u586b\u5145\u4e24\u4e2a\u8868\u4e2d\u7684\u7a7a\u503c\uff1a impute_value = train['Age'].median() train['Age'] = train['Age'].fillna(impute_value) test['Age'] = test['Age'].fillna(impute_value) \u73b0\u5728\u5efa\u7acb\u6a21\u578b\u3002\\ \u6dfb\u52a0\u4e00\u5217IsFemale\u4f5c\u4e3a\u2019Sex\u2019\u5217\u7684\u7f16\u7801\u7248\u672c\uff1a train['IsFemale'] = (train['Sex'] == 'female').astype(int) test['IsFemale'] = (test['Sex'] == 'female').astype(int) \u786e\u5b9a\u4e00\u4e9b\u6a21\u578b\u53d8\u91cf\u5e76\u521b\u5efaNumPy\u6570\u7ec4\uff1a predictors = ['Pclass', 'IsFemale', 'Age'] X_train = train[predictors].values X_test = test[predictors].values y_train = train['Survived'].values print(X_train[:5]) # [[ 3. 0. 22.] # [ 1. 1. 38.] # [ 3. 1. 26.] # [ 1. 1. 35.] # [ 3. 0. 35.]] print(y_train[:5]) # [0 1 1 1 0] \u4f7f\u7528scikit-learn\u7684LogisticRegression\u6a21\u578b\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u5b9e\u4f8b\uff1a model = LogisticRegression() \u4e0estatsmodels\u7c7b\u4f3c\uff0c\u4f7f\u7528\u6a21\u578b\u7684fit\u65b9\u6cd5\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u62df\u5408\u6a21\u578b\uff1a result = model.fit(X_train, y_train) print(result) # LogisticRegression() \u4f7f\u7528model.predict\u4e3a\u6d4b\u8bd5\u6570\u636e\u96c6\u5f62\u6210\u9884\u6d4b\uff1a y_predict = model.predict(X_test) print(y_predict[:10]) # [0 0 0 0 1 0 1 0 1 0] \u5b9e\u9645\u4e0a\uff0c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7ecf\u5e38\u5b58\u5728\u8bb8\u591a\u9644\u52a0\u7684\u590d\u6742\u5c42\u6b21\u3002\\ \u8bb8\u591a\u6a21\u578b\u5177\u6709\u53ef\u4ee5\u8c03\u6574\u7684\u53c2\u6570\uff0c\u5e76\u4e14\u5b58\u5728\u53ef\u7528\u4e8e\u53c2\u6570\u8c03\u6574\u7684\u4ea4\u53c9\u9a8c\u8bc1\u7b49\u6280\u672f\u4ee5\u907f\u514d\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u6570\u636e\u3002\\ \u8fd9\u901a\u5e38\u53ef\u4ee5\u5728\u65b0\u6570\u636e\u4e0a\u4ea7\u751f\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\u6216\u7a33\u5065\u6027\u3002\u4ea4\u53c9\u9a8c\u8bc1\u901a\u8fc7\u5206\u5272\u8bad\u7ec3\u6570\u636e\u6765\u6a21\u62df\u6837\u672c\u5916\u9884\u6d4b\u3002\\ \u57fa\u4e8e\u50cf\u5747\u65b9\u8bef\u5dee\u4e4b\u7c7b\u7684\u6a21\u578b\u51c6\u786e\u5ea6\u5206\u6570\uff0c\u53ef\u4ee5\u5bf9\u6a21\u578b\u53c2\u6570\u6267\u884c\u7f51\u683c\u641c\u7d22\u3002\\ \u4e00\u4e9b\u6a21\u578b\uff0c\u5982\u903b\u8f91\u56de\u5f52\uff0c\u5177\u6709\u5185\u7f6e\u4ea4\u53c9\u9a8c\u8bc1\u7684\u4f30\u8ba1\u7c7b\u3002\\ \u4f8b\u5982\uff0cLogisticRegressionCV\u7c7b\u53ef\u4ee5\u4e0e\u4e00\u4e2a\u53c2\u6570\u4e00\u8d77\u4f7f\u7528\uff0c\u8be5\u53c2\u6570\u8868\u793a\u7f51\u683c\u641c\u7d22\u5728\u6a21\u578b\u6b63\u5219\u5316\u53c2\u6570C\u4e0a\u7684\u7ec6\u81f4\u5ea6\uff1a model_cv = LogisticRegressionCV() result = model_cv.fit(X_train, y_train) print(result) # LogisticRegressionCV() \u8981\u624b\u52a8\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u4f7f\u7528cross_val_score\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5904\u7406\u6570\u636e\u62c6\u5206\u8fc7\u7a0b\u3002\\ \u4f8b\u5982\uff0c\u4e3a\u4e86\u7528\u6211\u4eec\u7684\u6a21\u578b\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u56db\u4e2a\u975e\u91cd\u53e0\u5206\u5272\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u8fd9\u6837\u505a\uff1a model = LogisticRegression(C=10) scores = cross_val_score(model, X_train, y_train, cv=4) print(scores) # [0.77578475 0.79820628 0.77578475 0.78828829] \u9ed8\u8ba4\u8bc4\u5206\u6307\u6807\u662f\u4f9d\u8d56\u4e8e\u6a21\u578b\u7684\uff0c\u4f46\u53ef\u4ee5\u9009\u62e9\u660e\u786e\u7684\u8bc4\u5206\u51fd\u6570\u3002\u7ecf\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u7684\u6a21\u578b\u9700\u8981\u66f4\u957f\u65f6\u95f4\u7684\u8bad\u7ec3\uff0c\u4f46\u901a\u5e38\u53ef\u4ee5\u4ea7\u751f\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u3002","title":"sikit-learn\u4ecb\u7ecd"},{"location":"python/DataAnalysis/ch12/","text":"\u4eceBitly\u83b7\u53d61.USA.gov\u6570\u636e MovieLens 1M\u6570\u636e\u96c6 \u7f8e\u56fd1880~2020\u5e74\u5a74\u513f\u540d\u5b57 \u7f8e\u56fd\u519c\u4e1a\u90e8\u98df\u54c1\u6570\u636e\u5e93 2012\u5e74\u8054\u90a6\u9009\u4e3e\u59d4\u5458\u4f1ai\u6570\u636e\u5e93","title":"Ch12"},{"location":"python/DataAnalysis/ch12/#bitly1usagov","text":"","title":"\u4eceBitly\u83b7\u53d61.USA.gov\u6570\u636e"},{"location":"python/DataAnalysis/ch12/#movielens-1m","text":"","title":"MovieLens 1M\u6570\u636e\u96c6"},{"location":"python/DataAnalysis/ch12/#18802020","text":"","title":"\u7f8e\u56fd1880~2020\u5e74\u5a74\u513f\u540d\u5b57"},{"location":"python/DataAnalysis/ch12/#_1","text":"","title":"\u7f8e\u56fd\u519c\u4e1a\u90e8\u98df\u54c1\u6570\u636e\u5e93"},{"location":"python/DataAnalysis/ch12/#2012i","text":"","title":"2012\u5e74\u8054\u90a6\u9009\u4e3e\u59d4\u5458\u4f1ai\u6570\u636e\u5e93"},{"location":"python/DataAnalysis/python_data_analysis_index/","text":"NumPy\u57fa\u7840 NumPy\u8fdb\u9636 Pandas\u5165\u95e8 \u6570\u636e\u8f7d\u5165\u3001\u5b58\u50a8\u53ca\u6587\u4ef6\u683c\u5f0f \u6570\u636e\u6e05\u6d17\u4e0e\u51c6\u5907 \u6570\u636e\u89c4\u6574\uff1a\u8fde\u63a5\u3001\u8054\u5408\u4e0e\u91cd\u5851 \u7ed8\u56fe\u4e0e\u53ef\u89c6\u5316 \u6570\u636e\u805a\u5408\u4e0e\u5206\u7ec4\u64cd\u4f5c \u65f6\u95f4\u5e8f\u5217 \u9ad8\u9636pandas Python\u5efa\u6a21\u5e93\u4ecb\u7ecd \u6570\u636e\u5206\u6790\u793a\u4f8b","title":"Python data analysis index"},{"location":"python/DataAnalysis/python_data_analysis_index/#numpy","text":"","title":"NumPy\u57fa\u7840"},{"location":"python/DataAnalysis/python_data_analysis_index/#numpy_1","text":"","title":"NumPy\u8fdb\u9636"},{"location":"python/DataAnalysis/python_data_analysis_index/#pandas","text":"","title":"Pandas\u5165\u95e8"},{"location":"python/DataAnalysis/python_data_analysis_index/#_1","text":"","title":"\u6570\u636e\u8f7d\u5165\u3001\u5b58\u50a8\u53ca\u6587\u4ef6\u683c\u5f0f"},{"location":"python/DataAnalysis/python_data_analysis_index/#_2","text":"","title":"\u6570\u636e\u6e05\u6d17\u4e0e\u51c6\u5907"},{"location":"python/DataAnalysis/python_data_analysis_index/#_3","text":"","title":"\u6570\u636e\u89c4\u6574\uff1a\u8fde\u63a5\u3001\u8054\u5408\u4e0e\u91cd\u5851"},{"location":"python/DataAnalysis/python_data_analysis_index/#_4","text":"","title":"\u7ed8\u56fe\u4e0e\u53ef\u89c6\u5316"},{"location":"python/DataAnalysis/python_data_analysis_index/#_5","text":"","title":"\u6570\u636e\u805a\u5408\u4e0e\u5206\u7ec4\u64cd\u4f5c"},{"location":"python/DataAnalysis/python_data_analysis_index/#_6","text":"","title":"\u65f6\u95f4\u5e8f\u5217"},{"location":"python/DataAnalysis/python_data_analysis_index/#pandas_1","text":"","title":"\u9ad8\u9636pandas"},{"location":"python/DataAnalysis/python_data_analysis_index/#python","text":"","title":"Python\u5efa\u6a21\u5e93\u4ecb\u7ecd"},{"location":"python/DataAnalysis/python_data_analysis_index/#_7","text":"","title":"\u6570\u636e\u5206\u6790\u793a\u4f8b"},{"location":"python/Demo/CourseSystem/","text":"\u9009\u8bfe\u7cfb\u7edf \u4efb\u52a1\u9700\u6c42 \u89d2\u8272\uff1a\u5b66\u6821\u3001\u5b66\u5458\u3001\u8bfe\u7a0b\u3001\u8bb2\u5e08 \u8981\u6c42\uff1a \u521b\u5efa\u5317\u4eac\u3001\u4e0a\u6d772\u6240\u5b66\u6821\u3002 \u521b\u5efaLinux\u3001Python\u3001go\u4e09\u4e2a\u8bfe\u7a0b\uff0cLinux\u548cPython\u5728\u5317\u4eac\u5f00\uff0cgo\u5728\u4e0a\u6d77\u5f00\u3002 \u8bfe\u7a0b\u5305\u542b\u5468\u671f\u3001\u4ef7\u683c\uff0c\u901a\u8fc7\u5b66\u6821\u521b\u5efa\u8bfe\u7a0b\u3002 \u901a\u8fc7\u5b66\u6821\u521b\u5efa\u73ed\u7ea7\uff0c\u73ed\u7ea7\u5173\u8054\u8bfe\u7a0b\u3001\u8bb2\u5e08\u3002 \u521b\u5efa\u8bb2\u5e08\u3002 \u521b\u5efa\u5b66\u5458\u65f6\uff0c\u9009\u62e9\u5b66\u6821\uff0c\u5173\u8054\u73ed\u7ea7\u3002 \u521b\u5efa\u8bb2\u5e08\u89d2\u8272\uff08\u4e0d\u9700\u8981\u5173\u8054\u5b66\u6821\uff09\u3002 \u63d0\u4f9b\u4e24\u4e2a\u89d2\u8272\u63a5\u53e3\u3002 \u5b66\u5458\u89c6\u56fe\uff1a\u53ef\u4ee5\u6ce8\u518c\uff0c\u4ea4\u5b66\u8d39\uff0c\u9009\u62e9\u73ed\u7ea7\u3002 \u8bb2\u5e08\u89c6\u56fe\uff1a\u8bb2\u5e08\u53ef\u4ee5\u7ba1\u7406\u81ea\u5df1\u7684\u73ed\u7ea7\uff0c\u4e0a\u8bfe\u65f6\u9009\u62e9\u73ed\u7ea7\uff0c\u67e5\u770b\u73ed\u7ea7\u5b66\u5458\u5217\u8868\uff0c\u4fee\u6539\u6240\u7ba1\u7406\u7684\u5b66\u5458\u7684\u6210\u7ee9\u3002 \u7ba1\u7406\u89c6\u56fe\uff1a\u521b\u5efa\u8bb2\u5e08\uff0c\u521b\u5efa\u73ed\u7ea7\uff0c\u521b\u5efa\u8bfe\u7a0b\u3002 \u4e0a\u8ff0\u64cd\u4f5c\u6240\u4ea7\u751f\u7684\u6570\u636e\u901a\u8fc7pickle\u4fdd\u5b58\u5230\u6587\u4ef6\u3002 \u9700\u6c42\u5206\u6790 \u7ba1\u7406\u89c6\u56fe \u6ce8\u518c \u767b\u5f55 \u521b\u5efa\u5b66\u6821 \u521b\u5efa\u8bfe\u7a0b\uff08\u5148\u9009\u62e9\u5b66\u6821\uff09 \u521b\u5efa\u8bb2\u5e08 \u5b66\u5458\u89c6\u56fe \u6ce8\u518c \u767b\u5f55\u529f\u80fd \u9009\u62e9\u6821\u533a \u9009\u62e9\u8bfe\u7a0b\uff08\u5148\u9009\u62e9\u6821\u533a\uff0c\u5728\u9009\u62e9\u6821\u533a\u4e2d\u7684\u67d0\u4e00\u95e8\u8bfe\u7a0b\uff0c\u9009\u62e9\u8bfe\u7a0b\u5373\u9009\u62e9\u73ed\u7ea7\uff09 \u5b66\u751f\u9009\u62e9\u8bfe\u7a0b\uff0c\u8bfe\u7a0b\u4e5f\u9009\u62e9\u5b66\u751f \u67e5\u770b\u5206\u6570 \u4ea4\u5b66\u8d39 \u8bb2\u5e08\u89c6\u56fe \u767b\u5f55 \u67e5\u770b\u6559\u6388\u8bfe\u7a0b \u9009\u62e9\u6559\u6388\u8bfe\u7a0b \u67e5\u770b\u8bfe\u7a0b\u4e0b\u7684\u5b66\u751f \u4fee\u6539\u5b66\u751f\u5206\u6570 \u67b6\u6784\u8bbe\u8ba1\uff08\u4e09\u5c42\u67b6\u6784\uff09 \u7528\u6237\u89c6\u56fe\u5c42 \u7528\u4e8e\u4e0e\u7528\u6237\u8fdb\u884c\u4ea4\u4e92\u3002 \u5b9e\u73b0\u7b80\u5355\u7684\u903b\u8f91\u5224\u65ad\uff0c\u6bd4\u5982\u6ce8\u518c\u529f\u80fd\u4e2d\u4e24\u6b21\u5bc6\u7801\u662f\u5426\u4e00\u81f4\u7684\u6821\u9a8c\u3002 core src.py \u4e3b\u89c6\u56fe admin.py: \u7ba1\u7406\u89c6\u56fe student.py: \u5b66\u5458\u89c6\u56fe teacher.py: \u8bb2\u5e08\u89c6\u56fe \u903b\u8f91\u63a5\u53e3\u5c42 \u6838\u5fc3\u4e1a\u52a1\u903b\u8f91\u7684\u5904\u7406 interface admin_interface.py studeng_interface.py teacher_interface.py \u6570\u636e\u5904\u7406\u5c42 \u6570\u636e\u5904\u7406\uff0c\u6bd4\u5982\u589e\u5220\u6539\u67e5\u3002 db models.py db_handler.py pickle\u4fdd\u5b58\u5bf9\u8c61 object --> pickle \u6587\u4ef6\u7ed3\u6784\uff1a /--conf/ | |--settings.py | |--core/ | |--src.py | |--admin.py | |--student.py | |--teacher.py | |--db/ | |--models.py | |--db_handler.py | |--pickle | |--interface/ | |--admin_interface.py | |--student_interface.py | |--teacher_interface.py | |--common_interface.py | |--lib/ | |--common.py | |--start.py \u9009\u8bfe\u7cfb\u7edf\u603b\u7ed3 1.\u7ba1\u7406\u5458 1.1.\u6ce8\u518c \u7528\u6237\u518d\u89c6\u56fe\u5c42\u8f93\u5165\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684models.get()\u8fdb\u884c\u6821\u9a8c\u3002 \u82e5\u4e0d\u5b58\u5728\u5219\u521b\u5efa\uff0c\u5e76\u8bb2\u6ce8\u518c\u6210\u529f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 1.2.\u767b\u5f55 \u7528\u6237\u5728\u89c6\u56fe\u5c42\u8f93\u5165\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684models.get()\u8fdb\u884c\u6821\u9a8c\u3002 \u82e5\u4e0d\u5b58\u5728\u5219\u521b\u5efa\uff0c\u5e76\u8bb2\u6ce8\u518c\u6210\u529f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 1.3.\u521b\u5efa\u5b66\u6821 \u8ba9\u7528\u6237\u8f93\u5165\u5b66\u6821\u540d\u548c\u5b66\u6821\u5730\u5740\u3002 \u8c03\u7528\u7ba1\u7406\u5458\u63a5\u53e3\u521b\u5efa\u5b66\u6821\u3002 \u5224\u65ad\u5b66\u6821\u662f\u5426\u5b58\u5728\uff0c\u82e5\u5b58\u5728\uff0c\u4e0d\u521b\u5efa\u3002 \u82e5\u4e0d\u5b58\u5728\uff0c\u5219\u8c03\u7528\u63a5\u53e3\u5c42\u521b\u5efa\u5b66\u6821\uff0c\u83b7\u53d6\u7ba1\u7406\u5458\u5bf9\u8c61\u7684\u521b\u5efa\u5b66\u6821\u65b9\u6cd5\u4fdd\u6301\u5b66\u6821\u5bf9\u8c61\u3002 \u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 1.4.\u521b\u5efa\u8bfe\u7a0b \u83b7\u53d6\u6240\u6709\u5b66\u6821\uff0c\u5e76\u6253\u5370\uff0c\u8ba9\u7528\u6237\u9009\u62e9\u3002 \u83b7\u53d6\u7528\u6237\u9009\u62e9\u7684\u5b66\u6821\u4e0e\u521b\u5efa\u7684\u8bfe\u7a0b\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u7ba1\u7406\u5458\u5bf9\u8c61\u4e2d\u7684\u521b\u5efa\u8bfe\u7a0b\u65b9\u6cd5\uff0c\u4fdd\u5b58\u8bfe\u7a0b\u5bf9\u8c61\u3002 \u8bfe\u7a0b\u9700\u8981\u7ed1\u5b9a\u7ed9\u5b66\u6821\u5bf9\u8c61\uff0c\u6700\u7ec8\u5c06\u521b\u5efa\u6210\u529f\u7684\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 1.5.\u521b\u5efa\u8001\u5e08 \u7528\u6237\u8f93\u5165\u8001\u5e08\u540d\u79f0\u3002 \u8c03\u7528\u63a5\u53e3\u5c42\uff0c\u63a5\u53e3\u5c42\u4e2d\u8bbe\u7f6e\u9ed8\u8ba4\u5bc6\u7801123\uff0c\u8c03\u7528\u6570\u636e\u5c42\u3002 \u5224\u65ad\u8001\u5e08\u662f\u5426\u5b58\u5728\uff0c\u4e0d\u5b58\u5728\u5219\u8c03\u7528\u7ba1\u7406\u5458\u5bf9\u8c61\u4e2d\u7684\u521b\u5efa\u8001\u5e08\u65b9\u6cd5\u3002 \u4fdd\u5b58\u8001\u5e08\u5bf9\u8c61\uff0c\u5e76\u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 2.\u5b66\u751f 2.1.\u6ce8\u518c \u540c\u4e0a 2.2.\u767b\u5f55 \u540c\u4e0a 2.3.\u9009\u62e9\u5b66\u6821 \u83b7\u53d6\u6240\u6709\u5b66\u6821\uff0c\u8ba9\u5b66\u751f\u9009\u62e9\uff0c\u5e76\u5c06\u9009\u62e9\u7684\u5b66\u6821\u4f20\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u5224\u65ad\u5f53\u524d\u5b66\u751f\u662f\u5426\u9009\u62e9\u5b66\u6821\u3002 \u82e5\u6ca1\u6709\u9009\u62e9\uff0c\u5219\u8c03\u7528\u5b66\u751f\u5bf9\u8c61\u4e2d\u7684\u6dfb\u52a0\u5b66\u6821\u65b9\u6cd5\u3002 \u5c06\u6dfb\u52a0\u540e\u6d88\u606f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 2.4.\u9009\u62e9\u8bfe\u7a0b \u5148\u83b7\u53d6\u5f53\u524d\u5b66\u751f\u6240\u5728\u5b66\u6821\u7684\u6240\u6709\u8bfe\u7a0b\uff0c\u5e76\u9009\u62e9\u3002 \u63a5\u53e3\u5c42\u5c06\u9009\u62e9\u540e\u7684\u8bfe\u7a0b\uff0c\u8c03\u7528\u6570\u636e\u5c42\u7684\u6dfb\u52a0\u8bfe\u7a0b\u65b9\u6cd5\u4fdd\u5b58\u3002 \u5b66\u751f\u5bf9\u8c61\u4e2d\u8bfe\u7a0b\u5217\u8868\u6dfb\u52a0\u8bfe\u7a0b\uff0c\u8bbe\u7f6e\u8bfe\u7a0b\u5206\u6570\uff0c\u9ed8\u8ba4\u4e3a0. \u6700\u7ec8\u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 2.5.\u67e5\u770b\u6210\u7ee9 \u76f4\u63a5\u8c03\u7528\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684\u67e5\u770b\u6210\u7ee9\u65b9\u6cd5\u3002 \u8fd4\u56de\u6210\u7ee9\u7ed9\u89c6\u56fe\u5c42\u5e76\u6253\u5370\u3002 3.\u8001\u5e08 3.1.\u767b\u5f55 \u540c\u4e0a 3.2.\u67e5\u770b\u6559\u6388\u8bfe\u7a0b \u76f4\u63a5\u8c03\u7528\u63a5\u53e3\u5c42\uff0c\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u8bfe\u7a0b\u5217\u8868\u6570\u636e\u3002 \u82e5\u6709\u5219\u6253\u5370\uff0c\u6ca1\u6709\u5219\u9000\u51fa\u3002 3.3.\u9009\u62e9\u6559\u6388\u8bfe\u7a0b \u8c03\u7528\u63a5\u53e3\u5c42\u4e2d\u7684\u9009\u62e9\u6559\u6388\u8bfe\u7a0b\u63a5\u53e3\uff0c\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u6539\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u6253\u5370\u6240\u6709\u7684\u8bfe\u7a0b\uff0c\u8ba9\u8001\u5e08\u9009\u62e9\uff0c\u82e5\u8001\u5e08\u8bfe\u7a0b\u4e2d\u6709\u8be5\u8bfe\u7a0b\u5219\u4e0d\u6dfb\u52a0\u3002 \u6ca1\u6709\uff0c\u5219\u55f2\u7528\u8001\u5e08\u5bf9\u8c61\u4e2d\u7684\u6dfb\u52a0\u8bfe\u7a0b\u65b9\u6cd5\u8fdb\u884c\u6dfb\u52a0\u3002 3.4.\u67e5\u770b\u8bfe\u7a0b\u4e0b\u7684\u5b66\u751f \u76f4\u63a5\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u8bfe\u7a0b\uff0c\u9009\u62e9\u8bfe\u7a0b\u3002 \u4ece\u8001\u5e08\u5bf9\u8c61\u4e2d\uff0c\u8c03\u7528\u67e5\u770b\u8bfe\u7a0b\u4e0b\u5b66\u751f\u7684\u65b9\u6cd5\uff0c\u83b7\u53d6\u8bfe\u7a0b\u5bf9\u8c61\u4e0b\u7684\u6240\u6709\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u89c6\u56fe\u5c42\u6253\u5370\u8be5\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\u3002 3.5.\u4fee\u6539\u5b66\u751f\u5206\u6570 \u76f4\u63a5\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u8bfe\u7a0b\u3002 \u4ece\u8001\u5e08\u5bf9\u8c61\u4e2d\uff0c\u8c03\u7528\u67e5\u770b\u8bfe\u7a0b\u4e0b\u5b66\u751f\u65b9\u6cd5\uff0c\u83b7\u53d6\u8bfe\u7a0b\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u89c6\u56fe\u5c42\u6253\u5370\u6539\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u5e76\u8ba9\u7528\u6237\u9009\u62e9\u9700\u8981\u5206\u6570\u7684\u5b66\u751f\u3002 \u55f2\u7528\u8001\u5e08\u4fee\u6539\u5206\u6570\u63a5\u53e3\uff0c\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\uff0c\u8c03\u7528\u5bf9\u8c61\u4e2d\u4fee\u6539\u5206\u6570\u65b9\u6cd5\u3002 \u83b7\u53d6\u5b66\u751f\u5bf9\u8c61\u4e2d\u7684\u5206\u6570\u5b57\u5178\uff0c\u8fdb\u884c\u4fee\u6539\u3002 3.4.\u67e5\u770b\u6210\u7ee9 \u793a\u610f\u56fe","title":"\u9009\u8bfe\u7cfb\u7edf"},{"location":"python/Demo/CourseSystem/#_1","text":"","title":"\u9009\u8bfe\u7cfb\u7edf"},{"location":"python/Demo/CourseSystem/#_2","text":"\u89d2\u8272\uff1a\u5b66\u6821\u3001\u5b66\u5458\u3001\u8bfe\u7a0b\u3001\u8bb2\u5e08 \u8981\u6c42\uff1a \u521b\u5efa\u5317\u4eac\u3001\u4e0a\u6d772\u6240\u5b66\u6821\u3002 \u521b\u5efaLinux\u3001Python\u3001go\u4e09\u4e2a\u8bfe\u7a0b\uff0cLinux\u548cPython\u5728\u5317\u4eac\u5f00\uff0cgo\u5728\u4e0a\u6d77\u5f00\u3002 \u8bfe\u7a0b\u5305\u542b\u5468\u671f\u3001\u4ef7\u683c\uff0c\u901a\u8fc7\u5b66\u6821\u521b\u5efa\u8bfe\u7a0b\u3002 \u901a\u8fc7\u5b66\u6821\u521b\u5efa\u73ed\u7ea7\uff0c\u73ed\u7ea7\u5173\u8054\u8bfe\u7a0b\u3001\u8bb2\u5e08\u3002 \u521b\u5efa\u8bb2\u5e08\u3002 \u521b\u5efa\u5b66\u5458\u65f6\uff0c\u9009\u62e9\u5b66\u6821\uff0c\u5173\u8054\u73ed\u7ea7\u3002 \u521b\u5efa\u8bb2\u5e08\u89d2\u8272\uff08\u4e0d\u9700\u8981\u5173\u8054\u5b66\u6821\uff09\u3002 \u63d0\u4f9b\u4e24\u4e2a\u89d2\u8272\u63a5\u53e3\u3002 \u5b66\u5458\u89c6\u56fe\uff1a\u53ef\u4ee5\u6ce8\u518c\uff0c\u4ea4\u5b66\u8d39\uff0c\u9009\u62e9\u73ed\u7ea7\u3002 \u8bb2\u5e08\u89c6\u56fe\uff1a\u8bb2\u5e08\u53ef\u4ee5\u7ba1\u7406\u81ea\u5df1\u7684\u73ed\u7ea7\uff0c\u4e0a\u8bfe\u65f6\u9009\u62e9\u73ed\u7ea7\uff0c\u67e5\u770b\u73ed\u7ea7\u5b66\u5458\u5217\u8868\uff0c\u4fee\u6539\u6240\u7ba1\u7406\u7684\u5b66\u5458\u7684\u6210\u7ee9\u3002 \u7ba1\u7406\u89c6\u56fe\uff1a\u521b\u5efa\u8bb2\u5e08\uff0c\u521b\u5efa\u73ed\u7ea7\uff0c\u521b\u5efa\u8bfe\u7a0b\u3002 \u4e0a\u8ff0\u64cd\u4f5c\u6240\u4ea7\u751f\u7684\u6570\u636e\u901a\u8fc7pickle\u4fdd\u5b58\u5230\u6587\u4ef6\u3002","title":"\u4efb\u52a1\u9700\u6c42"},{"location":"python/Demo/CourseSystem/#_3","text":"\u7ba1\u7406\u89c6\u56fe \u6ce8\u518c \u767b\u5f55 \u521b\u5efa\u5b66\u6821 \u521b\u5efa\u8bfe\u7a0b\uff08\u5148\u9009\u62e9\u5b66\u6821\uff09 \u521b\u5efa\u8bb2\u5e08 \u5b66\u5458\u89c6\u56fe \u6ce8\u518c \u767b\u5f55\u529f\u80fd \u9009\u62e9\u6821\u533a \u9009\u62e9\u8bfe\u7a0b\uff08\u5148\u9009\u62e9\u6821\u533a\uff0c\u5728\u9009\u62e9\u6821\u533a\u4e2d\u7684\u67d0\u4e00\u95e8\u8bfe\u7a0b\uff0c\u9009\u62e9\u8bfe\u7a0b\u5373\u9009\u62e9\u73ed\u7ea7\uff09 \u5b66\u751f\u9009\u62e9\u8bfe\u7a0b\uff0c\u8bfe\u7a0b\u4e5f\u9009\u62e9\u5b66\u751f \u67e5\u770b\u5206\u6570 \u4ea4\u5b66\u8d39 \u8bb2\u5e08\u89c6\u56fe \u767b\u5f55 \u67e5\u770b\u6559\u6388\u8bfe\u7a0b \u9009\u62e9\u6559\u6388\u8bfe\u7a0b \u67e5\u770b\u8bfe\u7a0b\u4e0b\u7684\u5b66\u751f \u4fee\u6539\u5b66\u751f\u5206\u6570","title":"\u9700\u6c42\u5206\u6790"},{"location":"python/Demo/CourseSystem/#_4","text":"\u7528\u6237\u89c6\u56fe\u5c42 \u7528\u4e8e\u4e0e\u7528\u6237\u8fdb\u884c\u4ea4\u4e92\u3002 \u5b9e\u73b0\u7b80\u5355\u7684\u903b\u8f91\u5224\u65ad\uff0c\u6bd4\u5982\u6ce8\u518c\u529f\u80fd\u4e2d\u4e24\u6b21\u5bc6\u7801\u662f\u5426\u4e00\u81f4\u7684\u6821\u9a8c\u3002 core src.py \u4e3b\u89c6\u56fe admin.py: \u7ba1\u7406\u89c6\u56fe student.py: \u5b66\u5458\u89c6\u56fe teacher.py: \u8bb2\u5e08\u89c6\u56fe \u903b\u8f91\u63a5\u53e3\u5c42 \u6838\u5fc3\u4e1a\u52a1\u903b\u8f91\u7684\u5904\u7406 interface admin_interface.py studeng_interface.py teacher_interface.py \u6570\u636e\u5904\u7406\u5c42 \u6570\u636e\u5904\u7406\uff0c\u6bd4\u5982\u589e\u5220\u6539\u67e5\u3002 db models.py db_handler.py pickle\u4fdd\u5b58\u5bf9\u8c61 object --> pickle","title":"\u67b6\u6784\u8bbe\u8ba1\uff08\u4e09\u5c42\u67b6\u6784\uff09"},{"location":"python/Demo/CourseSystem/#_5","text":"/--conf/ | |--settings.py | |--core/ | |--src.py | |--admin.py | |--student.py | |--teacher.py | |--db/ | |--models.py | |--db_handler.py | |--pickle | |--interface/ | |--admin_interface.py | |--student_interface.py | |--teacher_interface.py | |--common_interface.py | |--lib/ | |--common.py | |--start.py","title":"\u6587\u4ef6\u7ed3\u6784\uff1a"},{"location":"python/Demo/CourseSystem/#_6","text":"","title":"\u9009\u8bfe\u7cfb\u7edf\u603b\u7ed3"},{"location":"python/Demo/CourseSystem/#1","text":"","title":"1.\u7ba1\u7406\u5458"},{"location":"python/Demo/CourseSystem/#11","text":"\u7528\u6237\u518d\u89c6\u56fe\u5c42\u8f93\u5165\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684models.get()\u8fdb\u884c\u6821\u9a8c\u3002 \u82e5\u4e0d\u5b58\u5728\u5219\u521b\u5efa\uff0c\u5e76\u8bb2\u6ce8\u518c\u6210\u529f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"1.1.\u6ce8\u518c"},{"location":"python/Demo/CourseSystem/#12","text":"\u7528\u6237\u5728\u89c6\u56fe\u5c42\u8f93\u5165\u7528\u6237\u540d\u548c\u5bc6\u7801\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684models.get()\u8fdb\u884c\u6821\u9a8c\u3002 \u82e5\u4e0d\u5b58\u5728\u5219\u521b\u5efa\uff0c\u5e76\u8bb2\u6ce8\u518c\u6210\u529f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"1.2.\u767b\u5f55"},{"location":"python/Demo/CourseSystem/#13","text":"\u8ba9\u7528\u6237\u8f93\u5165\u5b66\u6821\u540d\u548c\u5b66\u6821\u5730\u5740\u3002 \u8c03\u7528\u7ba1\u7406\u5458\u63a5\u53e3\u521b\u5efa\u5b66\u6821\u3002 \u5224\u65ad\u5b66\u6821\u662f\u5426\u5b58\u5728\uff0c\u82e5\u5b58\u5728\uff0c\u4e0d\u521b\u5efa\u3002 \u82e5\u4e0d\u5b58\u5728\uff0c\u5219\u8c03\u7528\u63a5\u53e3\u5c42\u521b\u5efa\u5b66\u6821\uff0c\u83b7\u53d6\u7ba1\u7406\u5458\u5bf9\u8c61\u7684\u521b\u5efa\u5b66\u6821\u65b9\u6cd5\u4fdd\u6301\u5b66\u6821\u5bf9\u8c61\u3002 \u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"1.3.\u521b\u5efa\u5b66\u6821"},{"location":"python/Demo/CourseSystem/#14","text":"\u83b7\u53d6\u6240\u6709\u5b66\u6821\uff0c\u5e76\u6253\u5370\uff0c\u8ba9\u7528\u6237\u9009\u62e9\u3002 \u83b7\u53d6\u7528\u6237\u9009\u62e9\u7684\u5b66\u6821\u4e0e\u521b\u5efa\u7684\u8bfe\u7a0b\uff0c\u4ea4\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u7ba1\u7406\u5458\u5bf9\u8c61\u4e2d\u7684\u521b\u5efa\u8bfe\u7a0b\u65b9\u6cd5\uff0c\u4fdd\u5b58\u8bfe\u7a0b\u5bf9\u8c61\u3002 \u8bfe\u7a0b\u9700\u8981\u7ed1\u5b9a\u7ed9\u5b66\u6821\u5bf9\u8c61\uff0c\u6700\u7ec8\u5c06\u521b\u5efa\u6210\u529f\u7684\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"1.4.\u521b\u5efa\u8bfe\u7a0b"},{"location":"python/Demo/CourseSystem/#15","text":"\u7528\u6237\u8f93\u5165\u8001\u5e08\u540d\u79f0\u3002 \u8c03\u7528\u63a5\u53e3\u5c42\uff0c\u63a5\u53e3\u5c42\u4e2d\u8bbe\u7f6e\u9ed8\u8ba4\u5bc6\u7801123\uff0c\u8c03\u7528\u6570\u636e\u5c42\u3002 \u5224\u65ad\u8001\u5e08\u662f\u5426\u5b58\u5728\uff0c\u4e0d\u5b58\u5728\u5219\u8c03\u7528\u7ba1\u7406\u5458\u5bf9\u8c61\u4e2d\u7684\u521b\u5efa\u8001\u5e08\u65b9\u6cd5\u3002 \u4fdd\u5b58\u8001\u5e08\u5bf9\u8c61\uff0c\u5e76\u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"1.5.\u521b\u5efa\u8001\u5e08"},{"location":"python/Demo/CourseSystem/#2","text":"","title":"2.\u5b66\u751f"},{"location":"python/Demo/CourseSystem/#21","text":"\u540c\u4e0a","title":"2.1.\u6ce8\u518c"},{"location":"python/Demo/CourseSystem/#22","text":"\u540c\u4e0a","title":"2.2.\u767b\u5f55"},{"location":"python/Demo/CourseSystem/#23","text":"\u83b7\u53d6\u6240\u6709\u5b66\u6821\uff0c\u8ba9\u5b66\u751f\u9009\u62e9\uff0c\u5e76\u5c06\u9009\u62e9\u7684\u5b66\u6821\u4f20\u7ed9\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u5224\u65ad\u5f53\u524d\u5b66\u751f\u662f\u5426\u9009\u62e9\u5b66\u6821\u3002 \u82e5\u6ca1\u6709\u9009\u62e9\uff0c\u5219\u8c03\u7528\u5b66\u751f\u5bf9\u8c61\u4e2d\u7684\u6dfb\u52a0\u5b66\u6821\u65b9\u6cd5\u3002 \u5c06\u6dfb\u52a0\u540e\u6d88\u606f\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"2.3.\u9009\u62e9\u5b66\u6821"},{"location":"python/Demo/CourseSystem/#24","text":"\u5148\u83b7\u53d6\u5f53\u524d\u5b66\u751f\u6240\u5728\u5b66\u6821\u7684\u6240\u6709\u8bfe\u7a0b\uff0c\u5e76\u9009\u62e9\u3002 \u63a5\u53e3\u5c42\u5c06\u9009\u62e9\u540e\u7684\u8bfe\u7a0b\uff0c\u8c03\u7528\u6570\u636e\u5c42\u7684\u6dfb\u52a0\u8bfe\u7a0b\u65b9\u6cd5\u4fdd\u5b58\u3002 \u5b66\u751f\u5bf9\u8c61\u4e2d\u8bfe\u7a0b\u5217\u8868\u6dfb\u52a0\u8bfe\u7a0b\uff0c\u8bbe\u7f6e\u8bfe\u7a0b\u5206\u6570\uff0c\u9ed8\u8ba4\u4e3a0. \u6700\u7ec8\u5c06\u7ed3\u679c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002","title":"2.4.\u9009\u62e9\u8bfe\u7a0b"},{"location":"python/Demo/CourseSystem/#25","text":"\u76f4\u63a5\u8c03\u7528\u63a5\u53e3\u5c42\u3002 \u63a5\u53e3\u5c42\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u7684\u67e5\u770b\u6210\u7ee9\u65b9\u6cd5\u3002 \u8fd4\u56de\u6210\u7ee9\u7ed9\u89c6\u56fe\u5c42\u5e76\u6253\u5370\u3002","title":"2.5.\u67e5\u770b\u6210\u7ee9"},{"location":"python/Demo/CourseSystem/#3","text":"","title":"3.\u8001\u5e08"},{"location":"python/Demo/CourseSystem/#31","text":"\u540c\u4e0a","title":"3.1.\u767b\u5f55"},{"location":"python/Demo/CourseSystem/#32","text":"\u76f4\u63a5\u8c03\u7528\u63a5\u53e3\u5c42\uff0c\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u8bfe\u7a0b\u5217\u8868\u6570\u636e\u3002 \u82e5\u6709\u5219\u6253\u5370\uff0c\u6ca1\u6709\u5219\u9000\u51fa\u3002","title":"3.2.\u67e5\u770b\u6559\u6388\u8bfe\u7a0b"},{"location":"python/Demo/CourseSystem/#33","text":"\u8c03\u7528\u63a5\u53e3\u5c42\u4e2d\u7684\u9009\u62e9\u6559\u6388\u8bfe\u7a0b\u63a5\u53e3\uff0c\u8c03\u7528\u6570\u636e\u5c42\u4e2d\u6539\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u6253\u5370\u6240\u6709\u7684\u8bfe\u7a0b\uff0c\u8ba9\u8001\u5e08\u9009\u62e9\uff0c\u82e5\u8001\u5e08\u8bfe\u7a0b\u4e2d\u6709\u8be5\u8bfe\u7a0b\u5219\u4e0d\u6dfb\u52a0\u3002 \u6ca1\u6709\uff0c\u5219\u55f2\u7528\u8001\u5e08\u5bf9\u8c61\u4e2d\u7684\u6dfb\u52a0\u8bfe\u7a0b\u65b9\u6cd5\u8fdb\u884c\u6dfb\u52a0\u3002","title":"3.3.\u9009\u62e9\u6559\u6388\u8bfe\u7a0b"},{"location":"python/Demo/CourseSystem/#34","text":"\u76f4\u63a5\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u8bfe\u7a0b\uff0c\u9009\u62e9\u8bfe\u7a0b\u3002 \u4ece\u8001\u5e08\u5bf9\u8c61\u4e2d\uff0c\u8c03\u7528\u67e5\u770b\u8bfe\u7a0b\u4e0b\u5b66\u751f\u7684\u65b9\u6cd5\uff0c\u83b7\u53d6\u8bfe\u7a0b\u5bf9\u8c61\u4e0b\u7684\u6240\u6709\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u89c6\u56fe\u5c42\u6253\u5370\u8be5\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\u3002","title":"3.4.\u67e5\u770b\u8bfe\u7a0b\u4e0b\u7684\u5b66\u751f"},{"location":"python/Demo/CourseSystem/#35","text":"\u76f4\u63a5\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u8bfe\u7a0b\u3002 \u4ece\u8001\u5e08\u5bf9\u8c61\u4e2d\uff0c\u8c03\u7528\u67e5\u770b\u8bfe\u7a0b\u4e0b\u5b66\u751f\u65b9\u6cd5\uff0c\u83b7\u53d6\u8bfe\u7a0b\u5bf9\u8c61\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u8fd4\u56de\u7ed9\u89c6\u56fe\u5c42\u3002 \u89c6\u56fe\u5c42\u6253\u5370\u6539\u8bfe\u7a0b\u4e0b\u6240\u6709\u7684\u5b66\u751f\uff0c\u5e76\u8ba9\u7528\u6237\u9009\u62e9\u9700\u8981\u5206\u6570\u7684\u5b66\u751f\u3002 \u55f2\u7528\u8001\u5e08\u4fee\u6539\u5206\u6570\u63a5\u53e3\uff0c\u83b7\u53d6\u8001\u5e08\u5bf9\u8c61\uff0c\u8c03\u7528\u5bf9\u8c61\u4e2d\u4fee\u6539\u5206\u6570\u65b9\u6cd5\u3002 \u83b7\u53d6\u5b66\u751f\u5bf9\u8c61\u4e2d\u7684\u5206\u6570\u5b57\u5178\uff0c\u8fdb\u884c\u4fee\u6539\u3002","title":"3.5.\u4fee\u6539\u5b66\u751f\u5206\u6570"},{"location":"python/Demo/CourseSystem/#34_1","text":"","title":"3.4.\u67e5\u770b\u6210\u7ee9"},{"location":"python/Demo/CourseSystem/#_7","text":"","title":"\u793a\u610f\u56fe"},{"location":"python/Demo/python_demo_index/","text":"\u5c0f\u7ec3\u4e60 \u8bfe\u7a0b\u7cfb\u7edf","title":"\u5c0f\u7ec3\u4e60"},{"location":"python/Demo/python_demo_index/#_1","text":"\u8bfe\u7a0b\u7cfb\u7edf","title":"\u5c0f\u7ec3\u4e60"},{"location":"python/Foundation/ch00/","text":"Python\u73af\u5883 \u8fd9\u91cc\u4f7f\u7528\u7cfb\u7edf\u81ea\u5e26\u7684Python\u73af\u5883\uff1a \u4e3b\u673a\uff1aVMWare\u865a\u62df\u673a \u64cd\u4f5c\u7cfb\u7edf(Guest)\uff1aopenSUSE 15.3 Python\u7248\u672c\uff1a3.6.15(openSUSE\u81ea\u5e26) \u68c0\u67e5Python\u7248\u672c james@lizard:/opt/myProject/mySite> python --version Python 2.7.18 james@lizard:/opt/myProject/mySite> python3 --version Python 3.6.15 \u5347\u7ea7pip james@lizard:/opt> pip3 install --upgrade pip james@lizard:~> pip --version pip 21.3.1 from /home/james/.local/lib/python3.6/site-packages/pip (python 3.6) james@lizard:~> pip3 --version pip 21.3.1 from /home/james/.local/lib/python3.6/site-packages/pip (python 3.6) pip\u56fd\u5185\u6e90 https://mirrors.aliyun.com/pypi/simple/ https://pypi.tuna.tsinghua.edu.cn/simple/ http://pypi.doubanio.com/simple/ https://mirrors.cloud.tencent.com/pypi/simple/ \u5b89\u88c5Python\u5305(\u6307\u5b9a\u6e90) james@lizard:/opt> pip3 install jinja2 -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install Django -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install sqlite_utils -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pymongo -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install numpy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install matplotlib -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install scikit-learn -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install xlrd -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pandas -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pydotplus -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install seaborn -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install selenium -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install mlxtend -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pandas-datareader -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install lxml -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install beautifulsoup4 -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install html5lib -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install tables -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install openpyxl -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install sqlalchemy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install statsmodels -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install patsy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install numba -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install jason -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install openpyxl -i https://mirrors.aliyun.com/pypi/simple/ \u6e90\u7801\u7f16\u8bd1\u65b9\u6cd5 \u4e0b\u9762\u662f\u6e90\u7801\u7f16\u8bd1\u65b9\u5f0f\u81ea\u884c\u5b89\u88c5Python\u7684\u65b9\u6cd5\uff0c\u4ee53.9.6\u7248\u672c\u4e3a\u4f8b\u3002 \u5b98\u7f51\u4e0b\u8f7dpython3.9.6 \uff08 \u8fde\u63a5 \uff09 \u89e3\u538b\u5b89\u88c5\u5305 james@lizard:/opt> tar xvf Python-3.9.6.tgz \u5b89\u88c5\u8def\u5f84\u4e3a /opt/Python-3.9.6/ \uff0c\u9700\u8981\u628a\u5b89\u88c5\u8def\u5f84\u7684owner\u6539\u4e3a\u5f53\u524d\u7528\u6237\uff0c\u5426\u5219\u540e\u671fpython\u7f16\u8bd1\u4ee5\u53ca\u4f7f\u7528pip\u5b89\u88c5python\u5305\u4f1a\u62a5\u9519\u3002 james@lizard:/opt> chown -R james.wheel /opt/Python-3.9.6 \u5728\u5b89\u88c5\u524d\u7684\u4e00\u4e9b\u5efa\u8bae \u5728openSUSE\u4e2d\u628a\u5f00\u53d1\u5305\u90fd\u5b89\u88c5\u4e00\u4e0b\uff0c\u7279\u522b\u662fc\u548cc++\u7684\u5f00\u53d1\u5305\u3002\u8fd9\u4e9b\u90fd\u662fPython\u7f16\u8bd1\u7684\u4f9d\u8d56\u5305\u3002 \u5728openSUSE\u4e2d\u5b89\u88c5sqlite3. \u4f7f\u7528openSUSE\u81ea\u5e26\u7684openSSL\uff0c\u5982\u679c\u81ea\u884c\u7f16\u8bd1openSSL\uff0c\u5728\u7f16\u8bd1Python\u65f6\u4f1a\u9047\u5230\u4e00\u4e9b\u672a\u77e5\u95ee\u9898\u3002 \u7f16\u8bd1\u548c\u5b89\u88c5\uff1a james@lizard:/opt/Python-3.9.6> sudo ./configure --enable-optimizations --with-ensurepip=install james@lizard:/opt/Python-3.9.6> sudo make james@lizard:/opt/Python-3.9.6> sudo make test james@lizard:/opt/Python-3.9.6> sudo make install \u4fee\u6539\u7cfb\u7edf\u9ed8\u8ba4Python\u7684\u914d\u7f6e\uff0c\u5c06python3\u6307\u5411\u65b0\u5b89\u88c5\u7684Python\u3002\u9700\u8981\u4fee\u6539\u7684\u8def\u5f84\u67092\u4e2a\uff0c /usr/bin/python3 \u548c /usr/local/bin/ \u5c06/usr/bin/python3\u91cd\u65b0\u6307\u5411\u65b0\u5b89\u88c5\u7684Python\u3002 james@lizard:/opt/Python-3.9.6> sudo rm /usr/bin/python3 james@lizard:/opt/Python-3.9.6> sudo ln -s /opt/Python-3.9.6/python /usr/bin/python3 \u68c0\u67e5/usr/local/bin/\u76ee\u5f55\u4e0b\u7684python\u6587\u4ef6\u662f\u5426\u6307\u5411\u65b0\u5b89\u88c5\u7684Pyton\u3002\u9ed8\u8ba4\u662f\u7f16\u8bd1\u5b89\u88c5\u5b8c\u6210\u540e\u5df2\u7ecf\u88ab\u4fee\u6539\u4e86\u3002 james@lizard:/opt/Python-3.9.6> ls -l /usr/local/bin/python* lrwxrwxrwx 1 root root 9 Jul 25 02:15 python3 -> python3.9 -rwxr-xr-x 1 root root 17645928 Jul 25 02:14 python3.9 -rwxr-xr-x 1 root root 3087 Jul 25 02:15 python3.9-config lrwxrwxrwx 1 root root 16 Jul 25 02:15 python3-config -> python3.9-config \u9a8c\u8bc1python\u7684\u7248\u672c\u3002 james@lizard:/opt> python Python 2.7.18 (default, Mar 04 2021, 23:25:57) [GCC] on linux2 james@lizard:/opt> python3 Python 3.9.6 (default, Jul 25 2021, 02:13:27) [GCC 7.5.0] on linux \u6dfb\u52a0\u4e0b\u9762\u7684\u73af\u5883\u53d8\u91cf\u5230\u914d\u7f6e\u6587\u4ef6 /etc/profile.local \u3002 export PATH=/usr/local/bin:/home/$USER/.local/bin:$PATH \u5e76\u6267\u884c\u4e0b\u9762\u7684\u547d\u4ee4\u4f7f\u4e4b\u751f\u6548\u3002 james@lizard:/opt> source /etc/profile.local \u4e0b\u9762\u4fee\u6539pip\u7684\u914d\u7f6e\u3002 james@lizard:/opt/Python-3.9.6> whereis pip pip: /usr/bin/pip /usr/bin/pip3.6 /usr/local/bin/pip3.9 \u901a\u8fc7\u4e0b\u9762\u53ef\u4ee5\u770b\u5230pip\u5b9e\u9645\u6307\u5411\u7684\u662f\u7cfb\u7edf\u9ed8\u8ba4\u76843.6\u7248\u672c\u3002 james@lizard:/opt> l /usr/bin/pip* lrwxrwxrwx 1 root root 21 Dec 4 2020 /usr/bin/pip -> /etc/alternatives/pip* -rwxr-xr-x 1 root root 367 Dec 4 2020 /usr/bin/pip3* -rwxr-xr-x 1 root root 371 Dec 4 2020 /usr/bin/pip3.6* -rwxr-xr-x 1 root root 10608 Jun 10 06:15 /usr/bin/pipewire* -rwxr-xr-x 1 root root 720208 Jun 10 06:15 /usr/bin/pipewire-media-session* james@lizard:/opt> l /etc/alternatives/pip* lrwxrwxrwx 1 root root 15 Jul 24 20:24 /etc/alternatives/pip -> /usr/bin/pip3.6* \u68c0\u67e5\u4e00\u4e0b\u5f53\u524dpip\u5728alternative\u91cc\u9762\u7684\u8bbe\u7f6e\u3002 james@lizard:/opt> sudo update-alternatives --display pip pip - auto mode link best version is /usr/bin/pip3.6 link currently points to /usr/bin/pip3.6 link pip is /usr/bin/pip /usr/bin/pip3.6 - priority 36 \u5220\u9664\u8001\u7248\u672c\uff0c\u6dfb\u52a0\u65b0\u7248\u672c\u3002 james@lizard:/opt> sudo update-alternatives --remove pip /usr/bin/pip3.6 james@lizard:/opt/Python-3.9.6> sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3.9 100 update-alternatives: using /usr/bin/pip3.9 to provide /usr/bin/pip (pip) in auto mode","title":"Python\u73af\u5883"},{"location":"python/Foundation/ch00/#python","text":"\u8fd9\u91cc\u4f7f\u7528\u7cfb\u7edf\u81ea\u5e26\u7684Python\u73af\u5883\uff1a \u4e3b\u673a\uff1aVMWare\u865a\u62df\u673a \u64cd\u4f5c\u7cfb\u7edf(Guest)\uff1aopenSUSE 15.3 Python\u7248\u672c\uff1a3.6.15(openSUSE\u81ea\u5e26)","title":"Python\u73af\u5883"},{"location":"python/Foundation/ch00/#python_1","text":"james@lizard:/opt/myProject/mySite> python --version Python 2.7.18 james@lizard:/opt/myProject/mySite> python3 --version Python 3.6.15","title":"\u68c0\u67e5Python\u7248\u672c"},{"location":"python/Foundation/ch00/#pip","text":"james@lizard:/opt> pip3 install --upgrade pip james@lizard:~> pip --version pip 21.3.1 from /home/james/.local/lib/python3.6/site-packages/pip (python 3.6) james@lizard:~> pip3 --version pip 21.3.1 from /home/james/.local/lib/python3.6/site-packages/pip (python 3.6)","title":"\u5347\u7ea7pip"},{"location":"python/Foundation/ch00/#pip_1","text":"https://mirrors.aliyun.com/pypi/simple/ https://pypi.tuna.tsinghua.edu.cn/simple/ http://pypi.doubanio.com/simple/ https://mirrors.cloud.tencent.com/pypi/simple/","title":"pip\u56fd\u5185\u6e90"},{"location":"python/Foundation/ch00/#python_2","text":"james@lizard:/opt> pip3 install jinja2 -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install Django -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install sqlite_utils -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pymongo -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install numpy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install matplotlib -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install scikit-learn -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install xlrd -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pandas -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pydotplus -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install seaborn -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install selenium -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install mlxtend -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install pandas-datareader -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install lxml -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install beautifulsoup4 -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install html5lib -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install tables -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install openpyxl -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install sqlalchemy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install statsmodels -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install patsy -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install numba -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install jason -i https://mirrors.aliyun.com/pypi/simple/ james@lizard:/opt> pip3 install openpyxl -i https://mirrors.aliyun.com/pypi/simple/","title":"\u5b89\u88c5Python\u5305(\u6307\u5b9a\u6e90)"},{"location":"python/Foundation/ch00/#_1","text":"\u4e0b\u9762\u662f\u6e90\u7801\u7f16\u8bd1\u65b9\u5f0f\u81ea\u884c\u5b89\u88c5Python\u7684\u65b9\u6cd5\uff0c\u4ee53.9.6\u7248\u672c\u4e3a\u4f8b\u3002 \u5b98\u7f51\u4e0b\u8f7dpython3.9.6 \uff08 \u8fde\u63a5 \uff09 \u89e3\u538b\u5b89\u88c5\u5305 james@lizard:/opt> tar xvf Python-3.9.6.tgz \u5b89\u88c5\u8def\u5f84\u4e3a /opt/Python-3.9.6/ \uff0c\u9700\u8981\u628a\u5b89\u88c5\u8def\u5f84\u7684owner\u6539\u4e3a\u5f53\u524d\u7528\u6237\uff0c\u5426\u5219\u540e\u671fpython\u7f16\u8bd1\u4ee5\u53ca\u4f7f\u7528pip\u5b89\u88c5python\u5305\u4f1a\u62a5\u9519\u3002 james@lizard:/opt> chown -R james.wheel /opt/Python-3.9.6 \u5728\u5b89\u88c5\u524d\u7684\u4e00\u4e9b\u5efa\u8bae \u5728openSUSE\u4e2d\u628a\u5f00\u53d1\u5305\u90fd\u5b89\u88c5\u4e00\u4e0b\uff0c\u7279\u522b\u662fc\u548cc++\u7684\u5f00\u53d1\u5305\u3002\u8fd9\u4e9b\u90fd\u662fPython\u7f16\u8bd1\u7684\u4f9d\u8d56\u5305\u3002 \u5728openSUSE\u4e2d\u5b89\u88c5sqlite3. \u4f7f\u7528openSUSE\u81ea\u5e26\u7684openSSL\uff0c\u5982\u679c\u81ea\u884c\u7f16\u8bd1openSSL\uff0c\u5728\u7f16\u8bd1Python\u65f6\u4f1a\u9047\u5230\u4e00\u4e9b\u672a\u77e5\u95ee\u9898\u3002 \u7f16\u8bd1\u548c\u5b89\u88c5\uff1a james@lizard:/opt/Python-3.9.6> sudo ./configure --enable-optimizations --with-ensurepip=install james@lizard:/opt/Python-3.9.6> sudo make james@lizard:/opt/Python-3.9.6> sudo make test james@lizard:/opt/Python-3.9.6> sudo make install \u4fee\u6539\u7cfb\u7edf\u9ed8\u8ba4Python\u7684\u914d\u7f6e\uff0c\u5c06python3\u6307\u5411\u65b0\u5b89\u88c5\u7684Python\u3002\u9700\u8981\u4fee\u6539\u7684\u8def\u5f84\u67092\u4e2a\uff0c /usr/bin/python3 \u548c /usr/local/bin/ \u5c06/usr/bin/python3\u91cd\u65b0\u6307\u5411\u65b0\u5b89\u88c5\u7684Python\u3002 james@lizard:/opt/Python-3.9.6> sudo rm /usr/bin/python3 james@lizard:/opt/Python-3.9.6> sudo ln -s /opt/Python-3.9.6/python /usr/bin/python3 \u68c0\u67e5/usr/local/bin/\u76ee\u5f55\u4e0b\u7684python\u6587\u4ef6\u662f\u5426\u6307\u5411\u65b0\u5b89\u88c5\u7684Pyton\u3002\u9ed8\u8ba4\u662f\u7f16\u8bd1\u5b89\u88c5\u5b8c\u6210\u540e\u5df2\u7ecf\u88ab\u4fee\u6539\u4e86\u3002 james@lizard:/opt/Python-3.9.6> ls -l /usr/local/bin/python* lrwxrwxrwx 1 root root 9 Jul 25 02:15 python3 -> python3.9 -rwxr-xr-x 1 root root 17645928 Jul 25 02:14 python3.9 -rwxr-xr-x 1 root root 3087 Jul 25 02:15 python3.9-config lrwxrwxrwx 1 root root 16 Jul 25 02:15 python3-config -> python3.9-config \u9a8c\u8bc1python\u7684\u7248\u672c\u3002 james@lizard:/opt> python Python 2.7.18 (default, Mar 04 2021, 23:25:57) [GCC] on linux2 james@lizard:/opt> python3 Python 3.9.6 (default, Jul 25 2021, 02:13:27) [GCC 7.5.0] on linux \u6dfb\u52a0\u4e0b\u9762\u7684\u73af\u5883\u53d8\u91cf\u5230\u914d\u7f6e\u6587\u4ef6 /etc/profile.local \u3002 export PATH=/usr/local/bin:/home/$USER/.local/bin:$PATH \u5e76\u6267\u884c\u4e0b\u9762\u7684\u547d\u4ee4\u4f7f\u4e4b\u751f\u6548\u3002 james@lizard:/opt> source /etc/profile.local \u4e0b\u9762\u4fee\u6539pip\u7684\u914d\u7f6e\u3002 james@lizard:/opt/Python-3.9.6> whereis pip pip: /usr/bin/pip /usr/bin/pip3.6 /usr/local/bin/pip3.9 \u901a\u8fc7\u4e0b\u9762\u53ef\u4ee5\u770b\u5230pip\u5b9e\u9645\u6307\u5411\u7684\u662f\u7cfb\u7edf\u9ed8\u8ba4\u76843.6\u7248\u672c\u3002 james@lizard:/opt> l /usr/bin/pip* lrwxrwxrwx 1 root root 21 Dec 4 2020 /usr/bin/pip -> /etc/alternatives/pip* -rwxr-xr-x 1 root root 367 Dec 4 2020 /usr/bin/pip3* -rwxr-xr-x 1 root root 371 Dec 4 2020 /usr/bin/pip3.6* -rwxr-xr-x 1 root root 10608 Jun 10 06:15 /usr/bin/pipewire* -rwxr-xr-x 1 root root 720208 Jun 10 06:15 /usr/bin/pipewire-media-session* james@lizard:/opt> l /etc/alternatives/pip* lrwxrwxrwx 1 root root 15 Jul 24 20:24 /etc/alternatives/pip -> /usr/bin/pip3.6* \u68c0\u67e5\u4e00\u4e0b\u5f53\u524dpip\u5728alternative\u91cc\u9762\u7684\u8bbe\u7f6e\u3002 james@lizard:/opt> sudo update-alternatives --display pip pip - auto mode link best version is /usr/bin/pip3.6 link currently points to /usr/bin/pip3.6 link pip is /usr/bin/pip /usr/bin/pip3.6 - priority 36 \u5220\u9664\u8001\u7248\u672c\uff0c\u6dfb\u52a0\u65b0\u7248\u672c\u3002 james@lizard:/opt> sudo update-alternatives --remove pip /usr/bin/pip3.6 james@lizard:/opt/Python-3.9.6> sudo update-alternatives --install /usr/bin/pip pip /usr/bin/pip3.9 100 update-alternatives: using /usr/bin/pip3.9 to provide /usr/bin/pip (pip) in auto mode","title":"\u6e90\u7801\u7f16\u8bd1\u65b9\u6cd5"},{"location":"python/Foundation/ch01/","text":"Python\u8bed\u8a00\u57fa\u7840 1. Python\u6570\u636e\u7c7b\u578b\uff086\u4e2a\uff09 \u6570\u503c\u578b\uff08number\uff09\uff1a\u8868\u793a\u6570\u636e\u7ec4\u6210\u4e3a\u6570\u5b57 \u6574\u578b\uff08int\uff09 \u5341\u8fdb\u5236 \u516b\u8fdb\u5236 \u5341\u516d\u8fdb\u5236 \u6d6e\u70b9\u578b\uff08float\uff09 \u5e03\u5c14\u578b\uff08bool\uff09 \u590d\u6570\u6027\uff08complex\uff09 \u5b57\u7b26\u578b\uff08string\uff09\uff1a\u8868\u793a\u6570\u636e\u7ec4\u6210\u662f\u5b57\u7b26 \u5217\u8868\uff08list\uff09\uff1a\u7528\u6765\u8868\u793a\u4e00\u7ec4\u6709\u5e8f\u5143\u7d20\uff0c\u540e\u671f\u6570\u636e\u53ef\u4ee5\u4fee\u6539 ['A','B','C'] \u5143\u7ec4\uff08tuple\uff09\uff1a\u7528\u6765\u8868\u793a\u4e00\u7ec4\u6709\u5e8f\u5143\u7d20\uff0c\u540e\u671f\u6570\u636e\u4e0d\u53ef\u4fee\u6539 ('A','B','C','1') \u96c6\u5408\uff08set\uff09\uff1a\u4e00\u7ec4\u6570\u636e\u65e0\u5e8f\u4e0d\u91cd\u590d\u5143\u7d20 set([1,2,3,4]) \u5b57\u5178\uff08dictionary\uff09\uff1a\u7528\u952e\u503c\u5bf9\u7684\u5f62\u5f0f\u4fdd\u5b58\u4e00\u7ec4\u5143\u7d20 {'A':7,'B':1,'C':9} \u53ef\u8fed\u4ee3\u5bf9\u8c61\uff08Iterable\uff09 An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an iter() method or with a getitem() method that implements Sequence semantics. \u5e8f\u5217\uff08Sequence\uff09 An iterable which supports efficient element access using integer indices via the getitem() special method and defines a len() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports getitem() and len(), but is considered a mapping rather than a sequence because the lookups use arbitrary immutable keys rather than integers. \u8fed\u4ee3\u5668\uff08Iterator\uff09 An object representing a stream of data. Repeated calls to the iterator\u2019s next() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its next() method just raise StopIteration again. Iterators are required to have an iter() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container. \u53ef\u53d8\u6570\u636e\uff08immutable\uff09\uff1a \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09\u3002 \u4e0d\u53ef\u53d8\u6570\u636e\uff08immutable\uff09\uff1a \u6570\u5b57\uff08number\uff09 \u5b57\u7b26\uff08string\uff09 \u5143\u7ec4\uff08tuple\uff09 \u53ef\u8fed\u4ee3\uff08iterable\uff09\uff1a \u5b57\u7b26\uff08string\uff09 \u5143\u7ec4\uff08tuple\uff09 \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09 \u5e8f\u5217\uff1a \u6709\u5e8f\u5e8f\u5217\uff1a\u5b57\u7b26\uff08string\uff09\uff0c\u5143\u7ec4\uff08tuple\uff09\uff0c\u5217\u8868\uff08list\uff09 \u65e0\u5e8f\u5e8f\u5217\uff1a\u5b57\u5178\uff08dictionary\uff09\uff0c\u96c6\u5408\uff08set\uff09 Python\u5e8f\u5217\u7c7b\u578b\u6700\u5e38\u89c1\u7684\u5206\u7c7b\u5c31\u662f\u53ef\u53d8\u548c\u4e0d\u53ef\u53d8\u5e8f\u5217\u3002\u4f46\u53e6\u5916\u4e00\u79cd\u5206\u7c7b\u65b9\u5f0f\u4e5f\u5f88\u6709\u7528\uff0c\u90a3\u5c31\u662f\u628a\u5b83\u4eec\u5206\u4e3a \u6241\u5e73\u5e8f\u5217 \u548c \u5bb9\u5668\u5e8f\u5217 \u3002\u524d\u8005\u7684\u4f53\u79ef\u66f4\u5c0f\u3001\u901f\u5ea6\u66f4\u5feb\u800c\u4e14\u7528\u8d77\u6765\u66f4\u7b80\u5355\uff0c\u4f46\u662f\u5b83\u53ea\u80fd\u4fdd\u5b58\u4e00\u4e9b\u539f\u5b50\u6027\u7684\u6570\u636e\uff0c\u6bd4\u5982\u6570\u5b57\u3001\u5b57\u7b26\u548c\u5b57\u8282\u3002\u5bb9\u5668\u5e8f\u5217\u5219\u6bd4\u8f83\u7075\u6d3b\uff0c\u4f46\u662f\u5f53\u5bb9\u5668\u5e8f\u5217\u9047\u5230\u53ef\u53d8\u5bf9\u8c61\u65f6\uff0c\u5c31\u9700\u8981\u683c\u5916\u5c0f\u5fc3\uff0c\u56e0\u4e3a\u8fd9\u79cd\u7ec4\u5408\u65f6\u5e38\u4f1a\u51fa\u73b0\u4e00\u4e9b\u201c\u610f\u5916\u201d\uff0c\u7279\u522b\u662f\u5e26\u5d4c\u5957\u7684\u6570\u636e\u7ed3\u6784\u51fa\u73b0\u65f6\uff0c\u66f4\u9700\u8981\u9a8c\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002 Python\u4e2d\u7684\u53d8\u91cf\u3001\u5e38\u91cf\u548c\u5b57\u9762\u91cf \u53d8\u91cf \u53d8\u91cf\u662f\u7528\u4e8e\u5728\u5185\u5b58\u4e2d\u5b58\u50a8\u6570\u636e\u7684\u547d\u540d\u4f4d\u7f6e\u3002\u53ef\u4ee5\u5c06\u53d8\u91cf\u89c6\u4e3a\u4fdd\u5b58\u6570\u636e\u7684\u5bb9\u5668\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u4ee5\u5728\u540e\u9762\u7a0b\u5e8f\u4e2d\u8fdb\u884c\u66f4\u6539\u3002\u4f8b\u5982\uff1a number = 10 \u3002\u4ece\u4f8b\u5b50\u4e2d\u53ef\u4ee5\u770b\u5230\uff0cPython\u4f7f\u7528\u8d4b\u503c\u8fd0\u7b97\u7b26 = \u4e3a\u53d8\u91cf\u8d4b\u503c\u3002 \u5e38\u91cf \u5e38\u91cf\u4e5f\u662f\u4e00\u79cd\u53d8\u91cf\uff0c\u53ea\u662f\u5176\u503c\u4e00\u65e6\u8d4b\u4e88\u540e\u65e0\u6cd5\u66f4\u6539\u3002\u53ef\u4ee5\u5c06\u5e38\u91cf\u89c6\u4e3a\u4fdd\u5b58\u4e86\u4ee5\u540e\u65e0\u6cd5\u66f4\u6539\u7684\u4fe1\u606f\u7684\u5bb9\u5668\u3002 \u5728Python\u4e2d\uff0c\u5e38\u91cf\u901a\u5e38\u662f\u5728\u6a21\u5757\u4e2d\u58f0\u660e\u548c\u5206\u914d\u7684\u3002\u5728\u8fd9\u91cc\uff0c\u6a21\u5757\u662f\u4e00\u4e2a\u5305\u542b\u53d8\u91cf\uff0c\u51fd\u6570\u7b49\u7684\u65b0\u6587\u4ef6\uff0c\u8be5\u6587\u4ef6\u88ab\u5bfc\u5165\u5230\u4e3b\u6587\u4ef6\u4e2d\u3002\u5728\u6a21\u5757\u5185\u90e8\uff0c\u7528\u6240\u6709\u5927\u5199\u5b57\u6bcd\u5199\u7684\u5e38\u91cf\u548c\u4e0b\u5212\u7ebf\u5c06\u5355\u8bcd\u5206\u5f00\u3002\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u4e0d\u5728Python\u4e2d\u4f7f\u7528\u5e38\u91cf\u3002\u7528\u5927\u5199\u5b57\u6bcd\u547d\u540d\u5b83\u4eec\u662f\u4e00\u79cd\u5c06\u5176\u4e0e\u666e\u901a\u53d8\u91cf\u5206\u5f00\u7684\u4e00\u79cd\u7ea6\u5b9a\uff0c\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a\u5e76\u4e0d\u80fd\u963b\u6b62\u91cd\u65b0\u5206\u914d\u3002 \u5b57\u9762\u91cf\uff08literal\uff09 \u5b57\u9762\u91cf\u662f\u4ee5\u53d8\u91cf\u6216\u5e38\u91cf\u7ed9\u51fa\u7684\u539f\u59cb\u6570\u636e\uff08\u5176\u5b9e\u5c31\u662f\u6307\u53d8\u91cf\u7684\u5e38\u6570\u503c\uff0c\u5b57\u9762\u4e0a\u6240\u770b\u5230\u7684\u503c\uff09\u3002\u5728Python\u4e2d\u5b57\u9762\u91cf\u7c7b\u578b\u5982\u4e0b\uff1a \u6570\u5b57\u5b57\u9762\u91cf\u3002\u6570\u5b57\u5b57\u9762\u91cf\u662f\u4e0d\u53ef\u53d8\u7684\uff08\u4e0d\u53ef\u66f4\u6539\uff09\u3002\u6570\u5b57\u5b57\u9762\u91cf\u53ef\u4ee5\u5c5e\u4e8e3\u79cd\u4e0d\u540c\u7684\u6570\u503c\u7c7b\u578b\uff1aInteger\uff0cFloat \u548c Complex\u3002\u4f8b\u5982\uff1a float_1 = 10.5 \u662f\u5c5e\u4e8eFloat\u5b57\u9762\u91cf\u3002 \u5b57\u7b26\u4e32\u5b57\u9762\u91cf\u662f\u7531\u5f15\u53f7\u62ec\u8d77\u6765\u7684\u4e00\u7cfb\u5217\u5b57\u7b26\u3002\u6211\u4eec\u53ef\u4ee5\u5bf9\u5b57\u7b26\u4e32\u4f7f\u7528\u5355\u5f15\u53f7\uff0c\u53cc\u5f15\u53f7 \u6216 \u4e09\u5f15\u53f7\u3002\u5e76\u4e14\uff0c\u5b57\u7b26\u5b57\u9762\u91cf\u662f\u7528\u5355\u5f15\u53f7\u6216\u53cc\u5f15\u53f7\u5f15\u8d77\u6765\u7684\u5355\u4e2a\u5b57\u7b26\u3002\u4f8b\u5982\uff1a strings = \"This is Python\" \u3002 \u5e03\u5c14\u5b57\u9762\u91cf\u3002\u5e03\u5c14\u5b57\u9762\u91cf\u53ef\u4ee5\u5177\u6709\u4e24\u4e2a\u503c\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\uff1a True \u6216 False \u3002\u4f8b\u5982\uff1a a = True + 4 \u3002 \u7279\u6b8a\u5b57\u9762\u91cf\u3002Python\u5305\u542b\u4e00\u4e2a\u7279\u6b8a\u5b57\u9762\u91cf\uff0c\u5373 None \u3002 \u5b57\u9762\u91cf\u96c6\u3002\u6709\u56db\u79cd\u4e0d\u540c\u7684\u5b57\u9762\u91cf\u96c6\u5408\uff1a\u5217\u8868\u5b57\u9762\u91cf\uff0c\u5143\u7ec4\u5b57\u9762\u91cf\uff0c\u5b57\u5178\u5b57\u9762\u91cf \u548c \u96c6\u5408\u5b57\u9762\u91cf\u3002 1.1 \u6570\u503c\u578b\uff08number\uff09 \u4f8b\u5b50\uff1a a, b, c, d = 20, 5.5, True, 4+3j print(a, b, c, d) # 20 5.5 True (4+3j) print(type(a), type(b), type(c), type(d)) # <class 'int'> <class 'float'> <class 'bool'> <class 'complex'> Python\u4e5f\u53ef\u4ee5\u8fd9\u6837\u8d4b\u503c\uff1a a = b = c = d = 1 print(a, b, c, d) # 1 1 1 1 \u8fdb\u5236\u8f6c\u6362\uff1a a = -15 print(f'{a}\u5bf9\u5e94\u7684\u5341\u8fdb\u5236\u662f{a}, \u4e8c\u8fdb\u5236\u662f{a:b}, \u516b\u8fdb\u5236\u662f{a:o}, \u5341\u516d\u8fdb\u5236\u662f{a:x}') 1.2 \u5b57\u7b26\u578b\uff08string\uff09 \u5355\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u5305\u542b\u5927\u91cf\u53cc\u5f15\u53f7 \u53cc\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u5305\u542b\u5927\u91cf\u5355\u5f15\u53f7 \u4e09\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u540c\u65f6\u5305\u542b\u5355\u53cc\u5f15\u53f7\uff0c\u4e09\u4e2a\u5355\u5f15\u53f7\u6bd4\u8f83\u597d\u3002 a = 'string is \"special\"' b = \"string's value\" c = '''string's value is \"special\"''' d = \"\"\"string's context \"\"\" \u5b57\u7b26\u4e32\u5e38\u7528\u65b9\u6cd5 \u5b57\u7b26\u4e32\u5207\u7247 s = 'Python is very good' print(s[2:4]) # th print(s[5]) # n print(s[-1]) # d print(s[-3:-1]) # oo # \u975e\u8fed\u4ee3\u578b\uff0c\u4e0d\u53ef\u4fee\u6539 s[3] = 'b' # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'str' object does not support item assignment \u5b57\u7b26\u4e32\u5408\u5e76 print(s + '!!!') # Python is very good!!! replace( a,b \u5c06\u5b57\u7b26\u4e32\u4e2d\u7684 a \u66ff\u6362\u6210 b print(s.replace('is', 'we')) # Python we very good find(str) : \u8fd4\u56de str \u51fa\u73b0\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0c\u5982\u679c\u627e\u4e0d\u5230\u8be5\u503c\uff0c\u5219 find() \u65b9\u6cd5\u5c06\u8fd4\u56de -1\u3002 print(s.find('a')) # -1 print(s.find('s')) # 8 str.index(a): \u67e5\u627e\u6307\u5b9a\u503c\u7684\u9996\u6b21\u51fa\u73b0\u3002\u5982\u679c\u627e\u4e0d\u5230\u8be5\u503c\uff0cindex() \u65b9\u6cd5\u5c06\u5f15\u53d1\u5f02\u5e38\u3002 print(s.index('s')) # 8 print(s.index('a')) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ValueError: substring not found str.count(a): \u7edf\u8ba1\u5b57\u7b26\u4e32\u4e2d a \u51fa\u73b0\u7684\u6b21\u6570 print(s.count('a')) # 0 print(s.count('o')) # 3 split: \u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5206\u5272\u3002\u5982\u679c\u53c2\u6570 num \u6709\u6307\u5b9a\u503c\uff0c\u5219\u5206\u9694 num+1 \u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 # \u6309\u7a7a\u683c\u5206\u5272 print(s.split(' ')) # ['Python', 'is', 'very', 'good'] # \u6309\u7a7a\u683c\u5206\u5272\u62102\u4e2a\u5b50\u5b57\u7b26\u4e32 print(s.split(' ', 1)) # ['Python', 'is very good'] strip: \u79fb\u9664\u5b57\u7b26\u4e32\u9996\u5c3e\u6307\u5b9a\u7684\u5b57\u7b26 \u9ed8\u8ba4\u4e3a\u7a7a\u683c\u3002\u8be5\u65b9\u6cd5\u53ea\u80fd\u5220\u9664\u5f00\u5934\u6216\u662f\u7ed3\u5c3e\u7684\u5b57\u7b26\uff0c\u4e0d\u80fd\u5220\u9664\u4e2d\u95f4\u90e8\u5206\u7684\u5b57\u7b26\u3002 print(s) # Python is very good # \u79fb\u9664\u672b\u5c3e\u5b57\u7b26d print(s.strip('d')) # Python is very goo endswith (str): \u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u4ee5 str \u7ed3\u5c3e print(s.endswith('d')) # True print(s.endswith('a')) # False startswith (str): \u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u4ee5 str \u5f00\u5934 print(s.startswith('p')) # False print(s.startswith('P')) # True isdigit \uff1a\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u5168\u4e3a\u6570\u5b57 d = '+86-123' print(d.isdigit()) # False d = '86123' print(d.isdigit()) # True isalpha \uff1a\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u5168\u4e3a\u5b57\u6bcd b = 'Ab?' print(b.isalpha()) # False c = 'Ab' print()c.isalpha() # True \u8f6c\u4e49\u5b57\u7b26 \u4f7f\u7528\u53cd\u659c\u6760\\\u8868\u793a\u8f6c\u4e49\u5b57\u7b26\u3002\u53cd\u659c\u6760\u524d\u9762\u52a0r\u4ee3\u8868\u539f\u59cb\u5b57\u7b26\u3002 a = 'str\\ning' print(a) # str # ing a = r'str\\ning' print(a) # str\\ning \u8f6c\u4e49\u7b26 \u63cf\u8ff0 \\\u5728\u884c\u5c3e \u7eed\u884c\u7b26 \\\\ \u53cd\u659c\u6760\u7b26\u53f7\\ \\' \u5355\u5f15\u53f7 \\b \u9000\u683c(Backspace) \\000 \u7a7a \\n \u6362\u884c \\v \u7eb5\u5411\u5236\u8868\u7b26 \\t \u6a2a\u5411\u5236\u8868\u7b26 \\r \u56de\u8f66\uff0c\u5c06 \\r \u540e\u9762\u7684\u5185\u5bb9\u79fb\u5230\u5b57\u7b26\u4e32\u5f00\u5934\uff0c\u5e76\u9010\u4e00\u66ff\u6362\u5f00\u5934\u90e8\u5206\u7684\u5b57\u7b26\uff0c\u76f4\u81f3\u5c06 \\r \u540e\u9762\u7684\u5185\u5bb9\u5b8c\u5168\u66ff\u6362\u5b8c\u6210\u3002 \\yyy \u516b\u8fdb\u5236\u6570\uff0cy \u4ee3\u8868 0~7 \u7684\u5b57\u7b26 \\xyy \u5341\u516d\u8fdb\u5236\u6570\uff0c\u4ee5 \\x \u5f00\u5934\uff0cy \u4ee3\u8868\u7684\u5b57\u7b26 \u53ef\u8fed\u4ee3\u6027 \u5b57\u7b26\u4e32\u662f\u53ef\u8fed\u4ee3\u7684\u3002\u7d22\u5f15\u503c\u4ece0\u5f00\u59cb\uff0c-1\u4ee3\u8868\u4ece\u672b\u5c3e\u5f00\u59cb\u3002\u7d22\u5f15\u533a\u95f4\u662f\u5de6\u95ed\u53f3\u5f00\u3002 a = 'string is \"special\"' print(a[2:4]) 'ri' print(a[-4:-1]) # ial f-string f-string\u662fPython3.6\u63a8\u51fa\u7684\u65b0\u529f\u80fd\u3002\u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5bf9\u6bd4\u4f20\u7edf\u8868\u793a\u65b9\u6cd5\u548cf-string\u7684\u65b9\u6cd5\u3002 age = 32 name = 'Tom' fstring = f'My name is {name} and I am {age} years old.' print(fstring) # My name is Tom and I am 32 years old. \u5728f-string\u4e2d\u4f7f\u7528\u8868\u8fbe\u5f0f\u3002 height = 2 base = 3 fstring = f'The area of the triangle is {base*height/2}.' print(fstring) # The area of the triangle is 3.0. \u901a\u8fc7f-string\u5bf9\u5b57\u5178\u8fdb\u884c\u64cd\u4f5c\u3002 person1 = { 'name': 'Tom', 'age': 20, 'gender': 'male' } person2 = { 'name': 'Jerry', 'age': 20, 'gender': 'female' } # \u8bfb\u53d6\u5b57\u5178 fstring = f'{person1.get(\"name\")} is {person1.get(\"age\")} and is {person1.get(\"ender\")}' print(fstring) # Tom is 20 and is None # \u904d\u5386\u5b57\u5178 people = [person1, person2] for person in people: fstring = f'{person.get(\"name\")} is {person.get(\"age\")} and is {person.get(\"ender\")}' print(fstring) # Tom is 20 and is None # Jerry is 20 and is None \u5728f-string\u4e2d\u4f7f\u7528\u6761\u4ef6\u3002 person1 = { 'name': 'Tom', 'age': 20, 'gender': 'male' } person2 = { 'name': 'Jerry', 'age': 20, 'gender': 'female' } people = [person1, person2] for person in people: fstring = f'{\"She\" if person.get(\"gender\") == \"female\" else \"He\"} is watching TV.' print(fstring) # He is watching TV. # She is watching TV. \u4f7f\u7528f-string\u683c\u5f0f\u5316\u8f93\u51fa\u3002 \u5de6\u5bf9\u9f50\uff1a< \u53f3\u5bf9\u9f50\uff1a> \u5c45\u4e2d\u5bf9\u9f50\uff1a^ print(f'{\"apple\": >30}') print(f'{\"apple\": ^30}') print(f'{\"apple\": <30}') # apple # apple # apple \u4f7f\u7528f-string\u683c\u5f0f\u5316\u6570\u5b57\u3002 number = 0.9124325345 # \u767e\u5206\u6bd4 fstring = f'Percentage format for number with two decimal places: {number:.2%}' print(fstring) # Percentage format for number with two decimal places: 91.24% # \u4fdd\u7559\u5c0f\u6570\u70b9\u540e3\u4f4d fstring = f'Fixed point format for number with three decimal places: {number:.3f}' print(fstring) # Fixed point format for number with three decimal places: 0.912 # \u79d1\u5b66\u8ba1\u6570\u6cd5\u8868\u793a fstring = f'Exponent format for number: {number:e}' print(fstring) # Exponent format for number: 9.124325e-01 # \u5e26\u8d27\u5e01\u7b26\u53f7 number = 123456.78921 fstring = f'Currency format for number with two decimal places: ${number:.2f}' print(fstring) # Currency format for number with two decimal places: $123456.79 # \u5e26\u8d27\u5e01\u7b26\u53f7\u548c\u5343\u5206\u4f4d number = 123456.78921 fstring = f'Currency format for number with two decimal places and comma seperators: ${number:,.2f}' print(fstring) # Currency format for number with two decimal places and comma seperators: $123,456.79 # \u8f93\u51fa\u6570\u503c\u5e26\u6b63\u8d1f\u7b26\u5408 numbers = [1, -3, 5] for number in numbers: fstring = f'The number is {number:+}' print(fstring) # The number is +1 # The number is -3 # The number is +5 # Debug\u8c03\u8bd5 number = 2 print(f'{number = }') # number = 2 1.3 \u5217\u8868\uff08list\uff09 \u5217\u8868\u662f Python \u5185\u7f6e\u7684\u4e00\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u662f\u4e00\u79cd\u6709\u5e8f\u7684\u96c6\u5408\uff0c\u7528\u6765\u5b58\u50a8\u4e00\u8fde\u4e32\u5143\u7d20\u7684\u5bb9\u5668\u3002\u5217\u8868\u4e2d\u5143\u7d20\u7c7b\u578b\u53ef\u4ee5\u4e0d\u76f8\u540c\uff0c\u5b83\u652f\u6301\u6570\u5b57\u3001\u5b57\u7b26\u4e32\u7b49\u3002 \u5217\u8868\u7684\u6bcf\u4e2a\u503c\u90fd\u6709\u5bf9\u5e94\u7684\u7d22\u5f15\u503c\uff0c\u7d22\u5f15\u503c\u4ece0\u5f00\u59cb\u3002 \u5217\u8868\u5207\u7247\uff1a \u4f7f\u7528\u5207\u7247\u7b26\u53f7\u53ef\u4ee5\u5bf9\u5927\u591a\u6570\u5e8f\u5217\u7c7b\u578b\u9009\u53d6\u5176\u5b50\u96c6\u3002 \u8d77\u59cb\u4f4d\u7f6estart\u7684\u7d22\u5f15\u662f\u5305\u542b\u7684\uff0c\u800c\u7ed3\u675f\u4f4d\u7f6estop\u7684\u7d22\u5f15\u5e76\u4e0d\u5305\u542b\uff08\u5de6\u95ed\u53f3\u5f00\uff09\u3002 \u6b65\u8fdb\u503cstep\u53ef\u4ee5\u5728\u7b2c\u4e8c\u4e2a\u5192\u53f7\u540e\u9762\u4f7f\u7528\uff0c\u610f\u601d\u662f\u6bcf\u9694\u591a\u5c11\u4e2a\u6570\u53d6\u4e00\u4e2a\u503c \u3002 color = ['red', 'green', 'blue', 'yellow', 'white', 'black'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u7b2c1\uff0c2\u4f4d print(color[1: 3]) # ['green', 'blue'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u4ece\u7b2c1\u4f4d\u5230\u5012\u6570\u7b2c3\u4f4d print(color[1: -2]) # ['green', 'blue', 'yellow'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u4ece\u5012\u6570\u7b2c4\u4f4d\u5230\u5012\u6570\u7b2c3\u4f4d print(color[-4: -2]) # ['blue', 'yellow'] # \u5982\u679c\u5199\u6210\u4e0b\u9762\u8fd9\u6837\uff0c\u5219\u65e0\u8f93\u51fa\u3002 print(color[-2: -4]) # [] print(color[::2]) # ['red', 'blue', 'white'] \u5bf9\u4e8e\u7c7b\u4f3c\u4e0b\u9762 invoice \u683c\u5f0f\u7684\u7eaf\u6587\u672c\u89e3\u6790\uff0c\u4f7f\u7528\u6709\u540d\u5b57\u7684\u5207\u7247\u6bd4\u7528\u4e0a\u9762\u6240\u5217\u4e3e\u7684\u786c\u7f16\u7801\u7684\u6570\u5b57\u533a\u95f4\u8981\u65b9\u4fbf\u5f97\u591a\u3002 invoice = \"\"\" 0 6 40 52 55 1909 Primoroni PiBrella $17.50 3 $52.50 1489 6mm Tactile Switch x20 $4.19 2 $9.90 1510 Panavise JR.-PV-201 $28.00 1 $28.00 1601 PiTFT Mini Kit 320x240 $34.95 1 $34.95 \"\"\" SKU = slice(0, 6) DESCRIPTION = slice(6, 40) UNIT_PRICE = slice(40, 52) QUANTITY = slice(52, 55) ITEM_TOTAL = slice(55, None) line_items = invoice.split('\\n')[2:] # \u6309\u4e0a\u9762invoice\u7684\u683c\u5f0f\uff0c\u7b2c0\u548c1\u884c\u820d\u5f03 for item in line_items: print(item[UNIT_PRICE], item[DESCRIPTION]) # $17.50 Primoroni PiBrella # $4.19 6mm Tactile Switch x20 # $28.00 Panavise JR.-PV-201 # $34.95 PiTFT Mini Kit 320x240 Python\u5185\u7f6e\u7684\u5e8f\u5217\u7c7b\u578b\u90fd\u662f\u4e00\u7ef4\u7684\uff0c\u56e0\u6b64\u5b83\u4eec\u53ea\u652f\u6301\u5355\u4e00\u7684\u7d22\u5f15\uff0c\u6210\u5bf9\u51fa\u73b0\u7684\u7d22\u5f15\u662f\u6ca1\u6709\u7528\u7684\u3002 \u7701\u7565\uff08ellipsis\uff09 \u7684\u6b63\u786e\u4e66\u5199\u65b9\u6cd5\u662f\u4e09\u4e2a\u82f1\u8bed\u53e5\u53f7\uff08...\uff09\uff0c\u800c\u4e0d\u662fUnicdoe\u7801\u4f4dU+2026\u8868\u793a\u7684\u534a\u4e2a\u7701\u7565\u53f7\uff08...\uff09\u3002 \u7701\u7565\u5728Python\u89e3\u6790\u5668\u773c\u91cc\u662f\u4e00\u4e2a\u7b26\u53f7\uff0c\u800c\u5b9e\u9645\u4e0a\u5b83\u662f Ellipsis \u5bf9\u8c61\u7684\u522b\u540d\uff0c\u800c Ellipsis \u5bf9\u8c61\u53c8\u662f ellipsis \u7c7b\u7684\u5355\u4e00\u5b9e\u4f8b\u3002 \u5b83\u53ef\u4ee5\u5f53\u4f5c\u5207\u7247\u89c4\u8303\u7684\u4e00\u90e8\u5206\uff0c\u4e5f\u53ef\u4ee5\u7528\u5728\u51fd\u6570\u7684\u53c2\u6570\u6e05\u5355\u4e2d\uff0c\u6bd4\u5982 f(a, ..., z) \uff0c\u6216 a[i:...] \u3002 \u5728NumPy\u4e2d\uff0c ... \u7528\u4f5c\u591a\u7ef4\u6570\u7ec4\u5207\u7247\u7684\u5feb\u6377\u65b9\u5f0f\u3002\u5982\u679c `x\u662f\u56db\u7ef4\u6570\u7ec4\uff0c\u90a3\u4e48 x[i, ...] \u5c31\u662f x[i, :, :, :]`\u7684\u7f29\u5199\u3002\u5982\u679c\u60f3\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u89c1\u201cTentative NumPy Tutorial\u201d\u3002 \u5217\u8868\u5e38\u7528\u65b9\u6cd5\uff1a \u65b9\u6cd5\u540d\u79f0 \u4f5c\u7528 a.index() \u8fd4\u56dea\u4e2d\u9996\u4e2a\u5339\u914d\u9879\u7684\u4f4d\u7f6e a.pop() \u5220\u9664\u6307\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20 a.insert() \u5411\u6307\u5b9a\u4f4d\u7f6e\u63d2\u5165\u5143\u7d20 a.reverse() \u53cd\u5411\u6392\u5e8f a.append() \u5411\u672b\u5c3e\u6dfb\u52a0\u5143\u7d20 a.sort() \u5bf9\u5217\u8868\u8fdb\u884c\u6392\u5e8f a.remove() \u5220\u9664\u9996\u4e2a\u5339\u914d\u9879\u7684\u5143\u7d20 a.extend() \u5c06\u4e00\u4e2a\u5217\u8868\u6269\u5c55\u81f3\u53e6\u4e00\u4e2a\u5217\u8868 a.count() \u7edf\u8ba1\u67d0\u4e2a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570 \u521b\u5efa\u5217\u8868list a = [1, 2, 3, 4, 5] print(a) # [1, 2, 3, 4, 5] b = list('12345') print(b) # ['1', '2', '3', '4', '5'] c = list(12345) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'int' object is not iterable \u5217\u8868\u5207\u7247\uff08\u4ece0\u5f00\u59cb\uff0c\u5de6\u95ed\u53f3\u5f00\uff09\uff1a print(a[2:3]) # [3] print(a[:3]) # [1, 2, 3] print(a[::-1]) # \u5012\u5e8f # [5, 4, 3, 2, 1] print(a[::]) # [1, 2, 3, 4, 5] print(a[::1]) [1, 2, 3, 4, 5] \u5217\u8868\u662f\u53ef\u4fee\u6539\u7684\uff1a print(a[1]) # 2 a[1] = 'one' print(a) @ [1, 'one', 3, 4, 5] \u5217\u8868\u8ffd\u52a0\u548c\u63d2\u5165\u3002insert\u4e0eappend\u76f8\u6bd4\uff0c\u8ba1\u7b97\u4ee3\u4ef7\u66f4\u9ad8\u3002\u56e0\u4e3a\u5b50\u5e8f\u5217\u5143\u7d20\u9700\u8981\u5728\u5185\u90e8\u79fb\u52a8\u4e3a\u65b0\u5143\u7d20\u63d0\u4f9b\u7a7a\u95f4\u3002 a.append(6) # \u6ce8\u610f\uff0c\u76f4\u63a5\u4fee\u6539\u539f\u5217\u8868\uff0c\u4e0d\u662f\u521b\u5efa\u526f\u672c\u3002 print(a) # [1, 'one', 3, 4, 5, 6] a.extend([7, 8, 9]) print(a) # [1, 'one', 3, 4, 5, 6, 7, 8, 9] a.insert(0, 'Italy') print(a) # ['Italy', 1, 3, 5, 6, 7, 8] \u5217\u8868\u5220\u9664\u5143\u7d20\uff0c\u9ed8\u8ba4\u5220\u9664\u6700\u540e\u4e00\u4e2a\u3002insert\u7684\u53cd\u64cd\u4f5c\u662fpop\u3002 a.pop() # 9 print(a) # [1, 'one', 3, 4, 5, 6, 7, 8] a.pop(3) # 4 print(a) # [1, 'one', 3, 5, 6, 7, 8] \u5220\u9664\u5217\u8868\u4e2d\u67d0\u4e2a\u5143\u7d20\u3002 print(a[1]) # one del a[1] print(a) [1, 3, 5, 6, 7, 8] \u5220\u9664\u5217\u8868\u4e2d\u67d0\u4e2a\u5143\u7d20\u3002remove\u65b9\u6cd5\u4f1a\u5b9a\u4f4d\u7b2c\u4e00\u4e2a\u7b26\u5408\u8981\u6c42\u7684\u503c\u5e76\u79fb\u9664 a.remove('Italy') print(a) # [1, 3, 5, 6, 7, 8] \u7edf\u8ba1\u67d0\u4e2a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570\u3002 print(a.count(1)) # 1 \u8fd4\u56de\u5217\u8868\u4e2d\u5339\u914d\u9879\u7684\u7d22\u5f15\u4f4d\u7f6e\u3002\u5339\u914d\u4e0d\u5230\u629b\u51fa\u5f02\u5e38\u3002 print(a.index(2)) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ValueError: 2 is not in list print(a.index(3)) # 1 \u5224\u65ad\u5143\u7d20\u662f\u5426\u5b58\u5728\u4e8e\u5217\u8868\u3002 print(3 in a) # True print('3' in a) # False \u53cd\u5411\u8f93\u51fa\u5217\u8868\u3002 a.reverse() print(a) # [8, 7, 6, 5, 3, 1] \u53d6\u5217\u8868\u4e2d\u6700\u5927\u503c\u3001\u6700\u5c0f\u503c\u3002 print(min(a)) # 1 print(max(a)) # 78 \u8ba1\u7b97\u5217\u8868\u957f\u5ea6\u3002 print(len(a)) # 6 \u5217\u8868\u6269\u5c55\uff1a a = [1, 2, 3] b = [4, 5, 6] print(a + b) # [1, 2, 3, 4, 5, 6] a.extend(b) # a\u5217\u8868\u88ab\u4fee\u6539 print(a) # [1, 2, 3, 4, 5, 6] print(b) # [4, 5, 6] \u4f7f\u7528extend\u6dfb\u52a0\u5143\u7d20\u6bd4\u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fde\u63a5\u6548\u7387\u66f4\u9ad8\u3002\u56e0\u4e3a\u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fde\u63a5\u8fc7\u7a0b\u4e2d\u521b\u5efa\u4e86\u65b0\u5217\u8868\uff0c\u5e76\u4e14\u8fd8\u8981\u590d\u5236\u5bf9\u8c61\u3002 a_list = [4, None, 'foo'] b_list = [7, 8, (2, 3)] print(a_list + b_list) # [4, None, 'foo', 7, 8, (2, 3)] \u4f7f\u7528+\u53f7\u8fde\u63a5 a_list.extend(b_list) print(a_list) # [4, None, 'foo', 7, 8, (2, 3)] Python\u7684\u4e00\u4e2a\u60ef\u4f8b\uff1a\u5982\u679c\u4e00\u4e2a\u51fd\u6570\u6216\u8005\u65b9\u6cd5\u5bf9\u5bf9\u8c61\u8fdb\u884c\u7684\u662f\u5c31\u5730\u6539\u52a8\uff0c\u90a3\u5b83\u5c31\u5e94\u8be5\u8fd4\u56deNone\uff0c\u597d\u8ba9\u8c03\u7528\u8005\u77e5\u9053\u4f20\u5165\u7684\u53c2\u6570\u53d1\u751f\u4e86\u53d8\u52a8\uff0c\u800c\u4e14\u5e76\u672a\u4ea7\u751f\u65b0\u7684\u5bf9\u8c61\u3002 \u4e0b\u9762\u662f\u6392\u5e8f\u7684\u4f8b\u5b50 list.sort() \u548c sorted(list) \u7684\u533a\u522b\u3002 list1 = ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] print(list1) # ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] # \u4e0b\u9762\u7684\u64cd\u4f5c\u4e0d\u6539\u53d8\u539f\u5217\u8868 print(sorted(list1)) # ['1', '3', '5', '8', '9', 'Four', 'apple', 'one', 'two'] print(sorted(list1, reverse=True)) # ['two', 'one', 'apple', 'Four', '9', '8', '5', '3', '1'] print(sorted(list1, key=len)) # ['1', '3', '5', '8', '9', 'one', 'two', 'Four', 'apple'] print(list1) # ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] # \u4e0b\u9762\u7684\u64cd\u4f5c\u76f4\u63a5\u4fee\u6539\u539f\u5217\u8868\uff0c\u8fd4\u56de\u503c\u662fNone print(list1.sort()) # None print(list1) # ['1', '3', '5', '8', '9', 'Four', 'apple', 'one', 'two'] \u5217\u8868\u590d\u5236\uff0c + \u548c * \u7684\u64cd\u4f5c\u90fd\u662f\u4e0d\u4fee\u6539\u539f\u6709\u7684\u64cd\u4f5c\u5bf9\u8c61\uff0c\u800c\u662f\u6784\u5efa\u4e00\u4e2a\u5168\u65b0\u7684\u5217\u8868\u3002 c = list('Python') print(a + c) # [1, 2, 3, 4, 5, 6, 'P', 'y', 't', 'h', 'o', 'n'] print(a * 3) # [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6] \u5982\u679c\u5728 a * n \u8fd9\u4e2a\u8bed\u53e5\u4e2d\uff0c\u5e8f\u5217 a \u91cc\u7684\u5143\u7d20\u662f\u5bf9\u5176\u4ed6\u53ef\u53d8\u5bf9\u8c61\u7684\u5f15\u7528\u7684\u8bdd\uff0c\u5c31\u9700\u8981\u683c\u5916\u6ce8\u610f\u4e86\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u5f0f\u5b50\u7684\u7ed3\u679c\u53ef\u80fd\u4f1a\u51fa\u4e4e\u610f\u6599\u3002 \u6bd4\u5982\uff0c\u6211\u4eec\u60f3\u7528 my_list=[[]] * 3 \u6765\u521d\u59cb\u5316\u4e00\u4e2a\u7531\u5217\u8868\u7ec4\u6210\u7684\u5217\u8868\uff0c\u4f46\u662f\u6211\u4eec\u5b9e\u9645\u5f97\u5230\u7684\u5217\u8868\u91cc\u5305\u542b\u76843\u4e2a\u5143\u7d20\u5176\u5b9e\u662f3\u4e2a\u5f15\u7528\uff0c\u800c\u4e14\u8fd93\u4e2a\u5f15\u7528\u6307\u5411\u7684\u90fd\u662f \u540c\u4e00\u4e2a \u5217\u8868\u3002\u770b\u4e0b\u9762\u4f8b\u5b50\u3002 # \u505a\u6cd51 board = [['_'] * 3 for i in range(3)] print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[1][2] = 'X' print(board) # [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] # \u505a\u6cd52 board = [['_'] * 3] * 3 print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[1][2] = 'X' print(board) # [['_', '_', 'X'], ['_', '_', 'X'], ['_', '_', 'X']] \u4e0b\u9762\u4e5f\u662f\u540c\u6837\u7684\u95ee\u9898\u3002 # \u65b9\u6cd51 row = ['_'] * 3 board = [] for i in range(3): board.append(row) print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[2][0] = 'X' print(board) # [['X', '_', '_'], ['X', '_', '_'], ['X', '_', '_']] # \u65b9\u6cd52 row = [] board = [] for i in range(3): row = ['_'] * 3 board.append(row) print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[2][0] = 'X' print(board) # [['_', '_', '_'], ['_', '_', '_'], ['X', '_', '_']] \u53cc\u7aef\u961f\u5217collections.deque \uff0c\u53ef\u4ee5\u6ee1\u8db3\u5217\u8868\u5934\u5c3e\u90e8\u90fd\u589e\u52a0\u7684\u8981\u6c42\u3002 deque() \u4e2d maxlen \u662f\u4e00\u4e2a\u53ef\u9009\u53c2\u6570\uff0c\u4ee3\u8868\u8fd9\u4e2a\u961f\u5217\u53ef\u4ee5\u5bb9\u7eb3\u7684\u5143\u7d20\u7684\u6570\u91cf\uff0c\u800c\u4e14\u4e00\u65e6\u8bbe\u5b9a\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5c31\u4e0d\u80fd\u4fee\u6539\u4e86\u3002 \u5f53\u8bd5\u56fe\u5bf9\u4e00\u4e2a\u5df2\u6ee1 len(d)==d.maxlen \u7684\u961f\u5217\u505a\u5934\u90e8\u6dfb\u52a0\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u5b83\u5c3e\u90e8\u7684\u5143\u7d20\u4f1a\u88ab\u5220\u9664\u6389\u3002 extendleft(iter) \u65b9\u6cd5\u4f1a\u628a\u8fed\u4ee3\u5668\u91cc\u7684\u5143\u7d20\u9010\u4e2a\u6dfb\u52a0\u5230\u53cc\u5411\u961f\u5217\u7684\u5de6\u8fb9\uff0c\u56e0\u6b64\u8fed\u4ee3\u5668\u91cc\u7684\u5143\u7d20\u4f1a\u9006\u5e8f\u51fa\u73b0\u5728\u961f\u5217\u91cc\u3002 \u961f\u5217\u7684\u65cb\u8f6c\u64cd\u4f5c rotate \u63a5\u53d7\u4e00\u4e2a\u53c2\u6570n\uff0c\u5f53n > 0\u65f6\uff0c\u961f\u5217\u7684\u6700\u53f3\u8fb9\u7684n\u4e2a\u5143\u7d20\u4f1a\u88ab\u79fb\u52a8\u5230\u961f\u5217\u7684\u5de6\u8fb9\u3002\u5f53n < 0\u65f6\uff0c\u6700\u5de6\u8fb9\u7684n\u4e2a\u5143\u7d20\u4f1a\u88ab\u79fb\u52a8\u5230\u53f3\u8fb9\u3002 from collections import deque d = deque([1, 2, 3]) print(d) # deque([1, 2, 3]) # \u6ce8\u610f\u63d2\u5165\u987a\u5e8f d.extendleft(['a', 'b', 'c']) print(d) # deque(['c', 'b', 'a', 1, 2, 3]) print(len(d)) # 6 print(d[-2]) # 2 # \u7edf\u8ba1\u5b57\u7b26a\u51fa\u73b0\u7684\u6b21\u6570 print(d.count('a')) # 1 # \u8fd4\u56de\u5b57\u7b26a\u7684\u7d22\u5f15\u503c print(d.index('a')) # 2 # \u7b2c0\u4f4d\u63d2\u5165\u6570\u5b571\uff0c\u5176\u4f59\u987a\u79fb d.insert(0, 1) print(d) # deque([1, 'c', 'b', 'a', 1, 2, 3]) # \u628a\u53f3\u8fb92\u4e2a\u5143\u7d20\u653e\u5230\u5de6\u8fb9\uff0c\u6ce8\u610f\u987a\u5e8f\uff0c\u548cextendleft\u4e0d\u4e00\u6837 d.rotate(2) print(d) # deque([2, 3, 1, 'c', 'b', 'a', 1]) d.rotate(-2) print(d) # deque([1, 'c', 'b', 'a', 1, 2, 3]) \u4e0b\u8868\u603b\u7ed3\u4e86\u5217\u8868\u548c\u53cc\u5411\u961f\u5217\u7684\u65b9\u6cd5\uff08\u4e0d\u5305\u62ec\u7531\u5bf9\u8c61\u5b9e\u73b0\u7684\u65b9\u6cd5\uff09\u3002 \u5217\u8868\u6392\u5e8f\u3002\u6392\u5e8f\u5bf9\u5217\u8868\u5143\u7d20\u7684\u6570\u636e\u7c7b\u578b\u662f\u6709\u8981\u6c42\u7684\u3002 a_list = [4, None, 'foo', 7, 8, (2, 3)] a_list.sort() # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: '<' not supported between instances of 'NoneType' and 'int' b_list = [7, 8, (2, 3)] b_list.sort() # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: '<' not supported between instances of 'tuple' and 'int' a_list = [7, 2, 5, 1, 3] a_list.sort() # \u6309\u6570\u503c\u5927\u5c0f\u6392\u5e8f print(a_list) # [1, 2, 3, 5, 7] b_list = ['saw', 'small', 'He', 'foxes', 'six'] b_list.sort(key=len) # \u901a\u8fc7\u5b57\u7b26\u4e32\u7684\u957f\u5ea6\u8fdb\u884c\u6392\u5e8f print(b_list) # ['He', 'saw', 'six', 'small', 'foxes'] \u5217\u8868\u4e8c\u5206\u641c\u7d22\u548c\u5df2\u6392\u5e8f\u5217\u8868\u7684\u7ef4\u62a4 bisect \u8fd4\u56de\u8981\u63d2\u5165\u5143\u7d20\u5728\u5217\u8868\u4e2d\u7684\u4e0b\u6807\u3002\u5047\u5b9a\u5217\u8868\u662f\u6709\u5e8f\u7684\u3002 bisect_left \u4e0e bisect \u7c7b\u4f3c\uff0c\u53ea\u4e0d\u8fc7\u5176\u9ed8\u8ba4\u5c06\u5143\u7d20\u63d2\u5230\u5de6\u8fb9\uff0c\u6240\u4ee5\u8fd4\u56de\u7684\u662f\u63d2\u5165\u5230\u5de6\u8fb9\u7684\u4e0b\u6807 bisect_right\u4e0e bisect_left \u76f8\u53cd\u3002 \u4ee5\u4e0a\u65b9\u6cd5\u82e5\u5217\u8868\u65e0\u5e8f\uff0c\u90a3\u4e48\u4f1a\u8fd4\u56de\u63d2\u5165\u5230\u5217\u8868\u6700\u540e\u4e00\u4e2a\u5408\u9002\u7684\u4f4d\u7f6e\u3002 insort \u4f1a\u5728\u5217\u8868\u4e2d\u63d2\u5165\u5143\u7d20\u5230\u6b63\u786e\u4f4d\u7f6e\uff0c\u5047\u5b9a\u5217\u8868\u6709\u5e8f\u3002\u5982\u679c\u5217\u8868\u65e0\u5e8f\uff0c\u90a3\u4e48\u4f1a\u8fd4\u56de\u7a7a\u3002\u9ed8\u8ba4\u63d2\u5165\u5230\u53f3\u8fb9\u3002 insort_left \u548cinsort_right \u7c7b\u4f3c\u3002 import bisect c = [1, 2, 3, 4, 7] print(bisect.bisect(c, 2)) # 2 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a2,\u5e76\u628a\u65b0\u76842\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 2) # [1, 2, 2, 3, 4, 7] print(bisect.bisect(c, 5)) # 5 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a4,\u5e76\u628a\u65b0\u76845\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 5) print(bisect.bisect(c, 6)) # 6 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a5,\u5e76\u628a\u65b0\u76846\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 6) print(c) # [1, 2, 2, 3, 4, 5, 6, 7] bisect\u53ef\u4ee5\u7528\u6765\u5efa\u7acb\u4e00\u4e2a\u7528\u6570\u5b57\u4f5c\u4e3a\u7d22\u5f15\u7684\u67e5\u8be2\u8868\u683c\uff0c\u5982\u4e0b\u4f8b\uff0c\u628a\u5206\u6570\u548c\u6210\u7ee9\u5bf9\u5e94\u8d77\u6765\uff0c\u6839\u636e\u4e00\u4e2a\u5206\u6570\uff0c\u627e\u5230\u5b83\u6240\u5bf9\u5e94\u7684\u6210\u7ee9\u3002 import bisect def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): i = bisect.bisect(breakpoints, score) return grades[i] [grade(score) for score in [15, 26, 31, 62, 79, 85]] # ['F', 'F', 'F', 'D', 'C', 'B'] \u7528bisect.insort\u63d2\u5165\u65b0\u5143\u7d20\uff0c\u5e76\u80fd\u4fdd\u6301seq\u7684\u5347\u5e8f\u987a\u5e8f\u3002 import bisect import random size = 7 random.seed(1729) my_list = [] for i in range(size): new_item = random.randrange(size*2) bisect.insort(my_list, new_item) print(f'{new_item:2d} :--> {my_list}') # 10 :--> [10] # 0 :--> [0, 10] # 6 :--> [0, 6, 10] # 8 :--> [0, 6, 8, 10] # 7 :--> [0, 6, 7, 8, 10] # 2 :--> [0, 2, 6, 7, 8, 10] # 10 :--> [0, 2, 6, 7, 8, 10, 10] 1.4 \u5b57\u5178\uff08dictionary\uff09 \u5b57\u5178(dict)\u662f\u4f7f\u7528\u952e-\u503c\uff08key-value\uff09\u5b58\u50a8\uff0c\u952e\u662f\u4e0d\u53ef\u53d8\u5bf9\u8c61\uff0c\u4e14\u4e0d\u5141\u8bb8\u91cd\u590d\u3002 dict\uff08\u5b57\u5178\uff09\u66f4\u4e3a\u5e38\u7528\u7684\u540d\u5b57\u662f\u54c8\u5e0c\u8868\u6216\u8005\u662f\u5173\u8054\u6570\u7ec4\u3002 \u5b57\u5178\u662f\u62e5\u6709\u7075\u6d3b\u5c3a\u5bf8\u7684\u952e\u503c\u5bf9\u96c6\u5408\uff0c\u4e0d\u662f\u901a\u8fc7\u4f4d\u7f6e\u8fdb\u884c\u7d22\u5f15\uff0c\u5176\u4e2d\u952e\u548c\u503c\u90fd\u662fPython\u5bf9\u8c61\u3002\u7528\u5927\u62ec\u53f7{}\u662f\u521b\u5efa\u5b57\u5178\u7684\u4e00\u79cd\u65b9\u5f0f\uff0c\u5728\u5b57\u5178\u4e2d\u7528\u9017\u53f7\u5c06\u952e\u503c\u5bf9\u5206\u9694\u3002 \u521b\u5efa\u5b57\u5178\u7684\u51e0\u79cd\u65b9\u6cd5\uff1a a = dict(one=1, two=2, three=3) b = {'one': 1, 'two': 2, 'three': 3} c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) d = dict([('two', 2), ('three', 3), ('one', 1)]) e = dict({'three': 3, 'one': 1, 'two': 2}) print(a == b == c == d == e) # True \u5b57\u5178\u5e38\u7528\u65b9\u6cd5 \u65b9\u6cd5\u540d\u79f0 \u4f5c\u7528 a.items() \u8fd4\u56dea\u4e2d\u6240\u6709\u952e\u503c\u5bf9 a.values() \u8fd4\u56dea\u4e2d\u6240\u6709\u503c a.keys() \u8fd4\u56dea\u4e2d\u6240\u6709\u952e a.get() \u901a\u8fc7\u952e\u6765\u67e5\u503c\uff0c\u8fd4\u56de\u5bf9\u5e94\u7684\u503c a.clear() \u6e05\u7a7a\u5b57\u5178a\u7684\u503c a.setdefault \u901a\u8fc7\u952e\u503c\u6765\u67e5\u627e\u503c\uff0c\u627e\u4e0d\u5230\u5219\u63d2\u5165 a.update() \u952e\u548c\u503c\u66f4\u65b0\u5230\u65b0\u7684\u5b57\u5178 a.pop() \u5220\u9664\u6307\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20 \u751f\u6210\u4e00\u4e2a\u5b57\u5178 dict_a = {'name': 'Ming', 'id': 1001, 'age': 35} print(type(dict_a)) # <class 'dict'> dict_b = dict(city='Shanghai', strict='Xuhui', zip='200000') print(type(dict_b)) # <class 'dict'> \u901a\u8fc7\u952e\u67e5\u8be2\u503c\uff0c\u67e5\u8be2\u4e0d\u5230\u629b\u51fa\u5f02\u5e38 print(dict_a['name']) # Ming print(dict_a['Name']) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'Name' \u63d2\u5165\u65b0\u7684\u952e\u503c\u5bf9 dict_a['city'] = 'Chengdu' print(dict_a) # {'name': 'Ming', 'id': 1001, 'city': 'Chengdu'} \u5220\u9664\u67d0\u4e2a\u952e\u503c\u5bf9\u3002pop\u65b9\u6cd5\u4f1a\u5728\u5220\u9664\u7684\u540c\u65f6\u8fd4\u56de\u88ab\u5220\u7684\u503c\uff0c\u5e76\u5220\u9664\u952e\u3002 dict_a.pop('city') # Chengdu print(dict_a) # {'name': 'Ming', 'id': 1001} \u53e6\u4e00\u79cd\u65b9\u5f0f\u5220\u9664\u67d0\u4e2a\u952e\u503c\u5bf9 del dict_a['age'] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'age' del dict_a['id'] print(dict_a) # {'name': 'Ming'} \u5224\u65ad\u952e\u662f\u5426\u5b58\u5728 dict_a[23] = 'Hello World' print(dict_a) # {'name': 'Ming', 23: 'Hello World'} print(23 in dict_a) # True print(35 in dict_a) # False \u901a\u8fc7\u952e\u67e5\u8be2\u503c\u7684\u53e6\u4e00\u79cd\u65b9\u5f0f\uff0c\u67e5\u8be2\u4e0d\u5230\u4e0d\u629b\u5f02\u5e38 dict_a.get('hai') dict_a.get('hai', 1) # 1 dict_a.get('name', 1) # Ming dict_a['hai'] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'hai' \u901a\u8fc7\u952e\u67e5\u8be2\u503c\u7684\u53e6\u4e00\u79cd\u65b9\u5f0f\uff0c\u67e5\u8be2\u4e0d\u5230\u5219\u6dfb\u52a0 dict_a.setdefault('name') # Ming dict_a.setdefault('hai', 1) # 1 print(dict_a) # {'name': 'Ming', 23: 'Hello World', 'hai': 1} dict_a.setdefault('go') print(dict_a) # {'name': 'Ming', 23: 'Hello World', 'hai': 1, 'go': None} \u8bfb\u53d6\u5b57\u5178\u6240\u6709\u952e\u503c\u5bf9\uff0c\u8fd4\u56de\u7684\u662f\u5217\u8868\u5f62\u5f0f print(dict_a.items()) # dict_items([('name', 'Ming'), (23, 'Hello World'), ('hai', 1), ('go', None)]) \u8bfb\u53d6\u5b57\u5178\u7684\u952e print(dict_a.keys()) # dict_keys(['name', 23, 'hai', 'go']) \u8bfb\u53d6\u5b57\u5178\u7684\u503c print(dict_a.values()) # dict_values(['Ming', 'Hello World', 1, None]) \u5c06\u5b57\u5178\u503c\u8f6c\u5316\u6210\u5217\u8868 print(list(dict_a.values())) # ['Ming', 'Hello World', 1, None] for key in dict_a.keys(): print(dict_a[key]) # Ming # Hello World # 1 # None \u6e05\u7a7a\u5b57\u5178 dict_a.clear() print(dict_a) # {} print(len(dict_a)) # 0 \u5bf9\u4e8e\u4efb\u4f55\u539f\u5b57\u5178\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684\u952e\uff0c\u5982\u679c\u4f20\u7ed9update\u65b9\u6cd5\u7684\u6570\u636e\u4e5f\u542b\u6709\u76f8\u540c\u7684\u952e\uff0c\u5219\u5b83\u7684\u503c\u5c06\u4f1a\u88ab\u8986\u76d6\u3002 dict_a = {'name': 'Ming', 'id': 1001, 'age': 35} dict_b = dict(city='Shanghai', id=2001, zip='200000') dict_a.update(dict_b) print(dict_a) # {'name': 'Ming', 'id': 2001, 'age': 35, 'city': 'Shanghai', 'zip': '200000'} \u4ece\u5217\u8868\u751f\u6210\u5b57\u5178 \u5b57\u5178\u672c\u8d28\u4e0a\u662f2-\u5143\u7ec4\uff08\u542b\u67092\u4e2a\u5143\u7d20\u7684\u5143\u7ec4\uff09\u7684\u96c6\u5408\uff0c\u5b57\u5178\u662f\u53ef\u4ee5\u63a5\u53d7\u4e00\u4e2a2-\u5143\u7ec4\u7684\u5217\u8868\u4f5c\u4e3a\u53c2\u6570\u7684\u3002 # \u65b9\u6cd51 mapping = {} key_list = list(range(5)) value_list = list(reversed(range(5))) for key, value in zip(key_list, value_list): mapping[key] = value print(mapping) # {0: 4, 1: 3, 2: 2, 3: 1, 4: 0} # \u65b9\u6cd52\u3002 mapping = {} key_list = list(range(5)) value_list = list(reversed(range(5))) mapping = dict(zip(key_list, value_list)) print(mapping) # {0: 4, 1: 3, 2: 2, 3: 1, 4: 0} \u6709\u6548\u7684\u5b57\u5178\u952e\u7c7b\u578b \u5c3d\u7ba1\u5b57\u5178\u7684\u503c\u53ef\u4ee5\u662f\u4efb\u4f55Python\u5bf9\u8c61\uff0c\u4f46\u952e\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u7684\u5bf9\u8c61\uff0c\u6bd4\u5982\u6807\u91cf\u7c7b\u578b\uff08\u6574\u6570\u3001\u6d6e\u70b9\u6570\u3001\u5b57\u7b26\u4e32\uff09\u6216\u5143\u7ec4\uff08\u4e14\u5143\u7ec4\u5185\u5bf9\u8c61\u4e5f\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u5bf9\u8c61\uff09\u3002 \u901a\u8fc7hash\u51fd\u6570\u53ef\u4ee5\u68c0\u67e5\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u53ef\u4ee5\u54c8\u5e0c\u5316\uff08\u5373\u662f\u5426\u53ef\u4ee5\u7528\u4f5c\u5b57\u5178\u7684\u952e\uff09\uff0c\u672f\u8bed\u53eb\u4f5c\u54c8\u5e0c\u5316\u3002 print(hash('string')) # -4368784820203065343 print(hash((1, 2, (2, 3)))) # -9209053662355515447 print(hash((1, 2, [2, 3]))) # TypeError: unhashable type: 'list' print(hash((1, 2, tuple([2, 3])))) # -9209053662355515447 \u4e3a\u4e86\u5c06\u5217\u8868\u4f5c\u4e3a\u952e\uff0c\u4e00\u79cd\u65b9\u5f0f\u5c31\u662f\u5c06\u5176\u8f6c\u6362\u4e3a\u5143\u7ec4 \u5b57\u5178\u9ed8\u8ba4\u503c \u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5b9e\u73b0\u4e86\u5c06\u4e00\u4e2a\u5355\u8bcd\u7ec4\u6210\u7684\u5217\u8868\uff0c\u8f6c\u6362\u6210\u5355\u8bcd\u9996\u5b57\u6bcd\u548c\u5355\u8bcd\u4e3a\u952e\u503c\u5bf9\u7684\u5b57\u5178\u3002\u5148\u7528\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\uff0c\u518d\u7528\u5b57\u5178\u7684setdefault\u65b9\u6cd5\u8fdb\u884c\u6539\u5199\u3002 \u5148\u770b\u4f20\u7edf\u65b9\u6cd5\u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u628a\u5217\u8868words\u7684\u6bcf\u4e2a\u5143\u7d20\u5217\u8868\u5316\uff0c\u5e76\u53d6\u9996\u5b57\u6bcd\u3002\u8f93\u51fa\u7684\u662fa, b, b, a, b\u8fd95\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcd if letter not in by_letter: # \u751f\u6210\u7b2c\u4e00\u4e2a\u952e\u503c\u5bf9 print(letter) by_letter[letter] = [word] # \u5bf9\u6bd4[word]\u548cword[]\u7684\u7528\u6cd5 print(by_letter) # a # {'a': ['apple']} # b # {'a': ['apple'], 'b': ['bat']} else: # append\u5176\u4ed6\u952e\u503c\u5bf9 print(letter) by_letter[letter].append(word) print(by_letter) # b # {'a': ['apple'], 'b': ['bat', 'bar']} # a # {'a': ['apple', 'atom'], 'b': ['bat', 'bar']} # b # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} print(by_letter) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u7528\u5b57\u5178\u7684setdefault\u65b9\u6cd5\uff0c\u4e0a\u8ff0\u7684for\u5faa\u73af\u8bed\u53e5\u53ef\u4ee5\u88ab\u5199\u4e3a\u5982\u4e0b\u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u7684\u8f93\u51fa\u4f9d\u7136\u662f5\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcda, b, b, a, b by_letter.setdefault(letter, []).append(word) # \u5982\u679cletter\u4e0d\u5728[]\u5219\u901a\u8fc7append\u6dfb\u52a0word print(by_letter) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u5982\u679c\u6539\u5199\u4e3a by_letter.setdefault(letter, ['a']).append(word) \uff0c\u5219\u8f93\u51fa by_letter \u662f {'a': ['a', 'apple', 'atom'], 'b': ['a', 'bat', 'bar', 'book']} \u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u7684\u8f93\u51fa\u4f9d\u7136\u662f5\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcda, b, b, a, b by_letter.setdefault(letter, ['a']).append(word) print(by_letter) # {'a': ['a', 'apple', 'atom'], 'b': ['a', 'bat', 'bar', 'book']} \u4f53\u4f1asetdefault()\u7684\u6ce8\u91ca\u201cInsert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default.\u201d \u901a\u8fc7defaultdict\u7c7b\u4f7f\u5f97\u4e0a\u8ff0\u76ee\u7684\u5b9e\u73b0\u66f4\u4e3a\u7b80\u5355\u3002 from collections import defaultdict by_letter = defaultdict(list) # list\u662f\u5185\u7f6e\u7684\u53ef\u53d8\u5e8f\u5217(Built-in mutable sequence) print(dict(by_letter)) # {} for word in words: by_letter[word[0]].append(word) print(by_letter) # defaultdict(<class 'list'>, {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}) print(dict(by_letter)) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u4e0b\u8868\u5c55\u793a\u4e86 dict \u3001 defaultdict \u548c OrderedDict \u7684\u5e38\u89c1\u65b9\u6cd5\uff0c\u540e\u9762\u4e24\u4e2a\u6570\u636e\u7c7b\u578b\u662f dict \u7684\u53d8\u79cd\uff0c\u4f4d\u4e8e collections \u6a21\u5757\u5185\u3002 * default_factory \u5e76\u4e0d\u662f\u4e00\u4e2a\u65b9\u6cd5\uff0c\u800c\u662f\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61\uff08callable\uff09\uff0c\u5b83\u7684\u503c\u5728 defaultdict \u521d\u59cb\u5316\u7684\u65f6\u5019\u7531\u7528\u6237\u8bbe\u5b9a\u3002 # OrderedDict.popitem() \u4f1a\u79fb\u9664\u5b57\u5178\u91cc\u6700\u5148\u63d2\u5165\u7684\u5143\u7d20\uff08\u5148\u8fdb\u5148\u51fa\uff09\uff1b\u540c\u65f6\u8fd9\u4e2a\u65b9\u6cd5\u8fd8\u6709\u4e00\u4e2a\u53ef\u9009\u7684last\u53c2\u6570\uff0c\u82e5\u4e3a\u771f\uff0c\u5219\u4f1a\u79fb\u9664\u6700\u540e\u63d2\u5165\u7684\u5143\u7d20\uff08\u540e\u8fdb\u5148\u51fa\uff09\u3002 \u4e0a\u9762\u7684\u8868\u683c\u4e2d\uff0cupdate\u65b9\u6cd5\u5904\u7406\u53c2\u6570m\u7684\u65b9\u5f0f\uff0c\u662f\u5178\u578b\u7684\u201c\u9e2d\u5b50\u7c7b\u578b\u201d\u3002\u51fd\u6570\u9996\u5148\u68c0\u67e5m\u662f\u5426\u6709keys\u65b9\u6cd5\uff0c\u5982\u679c\u6709\uff0c\u90a3\u4e48update\u51fd\u6570\u5c31\u628a\u5b83\u5f53\u4f5c\u6620\u5c04\u5bf9\u8c61\u6765\u5904\u7406\u3002\u5426\u5219\uff0c\u51fd\u6570\u4f1a\u9000\u4e00\u6b65\uff0c\u8f6c\u800c\u628am\u5f53\u4f5c\u5305\u542b\u4e86\u952e\u503c\u5bf9(key, value)\u5143\u7d20\u7684\u8fed\u4ee3\u5668\u3002Python\u91cc\u5927\u591a\u6570\u6620\u5c04\u7c7b\u578b\u7684\u6784\u9020\u65b9\u6cd5\u90fd\u91c7\u7528\u4e86\u7c7b\u4f3c\u7684\u903b\u8f91\uff0c\u56e0\u6b64\u4f60\u65e2\u53ef\u4ee5\u7528\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u6765\u65b0\u5efa\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u7528\u5305\u542b(key, value)\u5143\u7d20\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6765\u521d\u59cb\u5316\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u3002 \u5b57\u5178\u7684\u53d8\u79cd collections.OrderedDict \u8fd9\u4e2a\u7c7b\u578b\u5728\u6dfb\u52a0\u952e\u7684\u65f6\u5019\u4f1a\u4fdd\u6301\u987a\u5e8f\uff0c\u56e0\u6b64\u952e\u7684\u8fed\u4ee3\u6b21\u5e8f\u603b\u662f\u4e00\u81f4\u7684\u3002OrderedDict\u7684popitem\u65b9\u6cd5\u9ed8\u8ba4\u5220\u9664\u5e76\u8fd4\u56de\u7684\u662f\u5b57\u5178\u91cc\u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u4f46\u662f\u5982\u679c\u50cfmy_odict.popitem(last=False)\u8fd9\u6837\u8c03\u7528\u5b83\uff0c\u90a3\u4e48\u5b83\u5220\u9664\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a\u88ab\u6dfb\u52a0\u8fdb\u53bb\u7684\u5143\u7d20\u3002 collections.ChainMap \u8be5\u7c7b\u578b\u53ef\u4ee5\u5bb9\u7eb3\u6570\u4e2a\u4e0d\u540c\u7684\u6620\u5c04\u5bf9\u8c61\uff0c\u7136\u540e\u5728\u8fdb\u884c\u952e\u67e5\u627e\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u8fd9\u4e9b\u5bf9\u8c61\u4f1a\u88ab\u5f53\u4f5c\u4e00\u4e2a\u6574\u4f53\u88ab\u9010\u4e2a\u67e5\u627e\uff0c\u76f4\u5230\u952e\u88ab\u627e\u5230\u4e3a\u6b62\u3002\u8fd9\u4e2a\u529f\u80fd\u5728\u7ed9\u6709\u5d4c\u5957\u4f5c\u7528\u57df\u7684\u8bed\u8a00\u505a\u89e3\u91ca\u5668\u7684\u65f6\u5019\u5f88\u6709\u7528\uff0c\u53ef\u4ee5\u7528\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u6765\u4ee3\u8868\u4e00\u4e2a\u4f5c\u7528\u57df\u7684\u4e0a\u4e0b\u6587\u3002 collections.Counter \u8fd9\u4e2a\u6620\u5c04\u7c7b\u578b\u4f1a\u7ed9\u952e\u51c6\u5907\u4e00\u4e2a\u6574\u6570\u8ba1\u6570\u5668\u3002\u6bcf\u6b21\u66f4\u65b0\u4e00\u4e2a\u952e\u7684\u65f6\u5019\u90fd\u4f1a\u589e\u52a0\u8fd9\u4e2a\u8ba1\u6570\u5668\u3002\u6240\u4ee5\u8fd9\u4e2a\u7c7b\u578b\u53ef\u4ee5\u7528\u6765\u7ed9\u53ef\u6563\u5217\u8868\u5bf9\u8c61\u8ba1\u6570\uff0c\u6216\u8005\u662f\u5f53\u6210\u591a\u91cd\u96c6\u6765\u7528\u2014\u2014\u591a\u91cd\u96c6\u5408\u5c31\u662f\u96c6\u5408\u91cc\u7684\u5143\u7d20\u53ef\u4ee5\u51fa\u73b0\u4e0d\u6b62\u4e00\u6b21\u3002Counter\u5b9e\u73b0\u4e86+\u548c-\u8fd0\u7b97\u7b26\u7528\u6765\u5408\u5e76\u8bb0\u5f55\uff0c\u8fd8\u6709\u50cfmost_common([n])\u8fd9\u7c7b\u5f88\u6709\u7528\u7684\u65b9\u6cd5\u3002most_common([n])\u4f1a\u6309\u7167\u6b21\u5e8f\u8fd4\u56de\u6620\u5c04\u91cc\u6700\u5e38\u89c1\u7684n\u4e2a\u952e\u548c\u5b83\u4eec\u7684\u8ba1\u6570 \u4e0b\u9762\u7684\u4f8b\u5b50\u5229\u7528Counter\u6765\u8ba1\u7b97\u5355\u8bcd\u4e2d\u5404\u4e2a\u5b57\u6bcd\u51fa\u73b0\u7684\u6b21\u6570\uff1a str = 'abracadabra' ct = collections.Counter(str) print(ct) # Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) collections.UserDict \u8fd9\u4e2a\u7c7b\u5176\u5b9e\u5c31\u662f\u628a\u6807\u51c6dict\u7528\u7eafPython\u53c8\u5b9e\u73b0\u4e86\u4e00\u904d\u3002\u8ddfOrderedDict\u3001ChainMap\u548cCounter\u8fd9\u4e9b\u5f00\u7bb1\u5373\u7528\u7684\u7c7b\u578b\u4e0d\u540c\uff0cUserDict\u662f\u8ba9\u7528\u6237\u7ee7\u627f\u5199\u5b50\u7c7b\u7684\u3002 \u4e0d\u53ef\u53d8\u6620\u5c04\u7c7b\u578b \u6807\u51c6\u5e93\u91cc\u6240\u6709\u7684\u6620\u5c04\u7c7b\u578b\u90fd\u662f\u53ef\u53d8\u7684\uff0c\u4f46\u6709\u65f6\u5019\u4f60\u4f1a\u6709\u8fd9\u6837\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u4e0d\u80fd\u8ba9\u7528\u6237\u9519\u8bef\u5730\u4fee\u6539\u67d0\u4e2a\u6620\u5c04\u3002 \u4ecePython 3.3\u5f00\u59cb\uff0ctypes\u6a21\u5757\u4e2d\u5f15\u5165\u4e86\u4e00\u4e2a\u5c01\u88c5\u7c7b\u540d\u53ebMappingProxyType\u3002\u5982\u679c\u7ed9\u8fd9\u4e2a\u7c7b\u4e00\u4e2a\u6620\u5c04\uff0c\u5b83\u4f1a\u8fd4\u56de\u4e00\u4e2a\u53ea\u8bfb\u7684\u6620\u5c04\u89c6\u56fe\u3002\u867d\u7136\u662f\u4e2a\u53ea\u8bfb\u89c6\u56fe\uff0c\u4f46\u662f\u5b83\u662f\u52a8\u6001\u7684\u3002\u8fd9\u610f\u5473\u7740\u5982\u679c\u5bf9\u539f\u6620\u5c04\u505a\u51fa\u4e86\u6539\u52a8\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2a\u89c6\u56fe\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u4f46\u662f\u65e0\u6cd5\u901a\u8fc7\u8fd9\u4e2a\u89c6\u56fe\u5bf9\u539f\u6620\u5c04\u505a\u51fa\u4fee\u6539\u3002 \u901a\u8fc7\u4e0b\u4f8b\u53ef\u4ee5\u770b\u51fa\uff0c d \u4e2d\u7684\u5185\u5bb9\u53ef\u4ee5\u901a\u8fc7 d_proxy \u770b\u5230\u3002\u4f46\u662f\u901a\u8fc7 d_proxy \u5e76\u4e0d\u80fd\u505a\u4efb\u4f55\u4fee\u6539\u3002 d_proxy \u662f\u52a8\u6001\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u5bf9 d \u6240\u505a\u7684\u4efb\u4f55\u6539\u52a8\u90fd\u4f1a\u53cd\u9988\u5230\u5b83\u4e0a\u9762\u3002 from types import MappingProxyType d = {1: 'A'} d_proxy = MappingProxyType(d) print(d) # {1: 'A'} print(d_proxy) # {1: 'A'} print(d[1]) # A print(d_proxy[1]) # A d[2] = 'W' print(d) # {1: 'A', 2: 'W'} d_proxy[2] = 'W' # TypeError: 'mappingproxy' object does not support item assignment print(d_proxy) # {1: 'A', 2: 'W'} 1.5 \u96c6\u5408\uff08set\uff09 \u201c\u96c6\u201d\u8fd9\u4e2a\u6982\u5ff5\u5728Python\u4e2d\u7b97\u662f\u6bd4\u8f83\u5e74\u8f7b\u7684\uff0c\u540c\u65f6\u5b83\u7684\u4f7f\u7528\u7387\u4e5f\u6bd4\u8f83\u4f4e\u3002set\u548c\u5b83\u7684\u4e0d\u53ef\u53d8\u7684\u59ca\u59b9\u7c7b\u578bfrozenset\u76f4\u5230Python 2.3\u624d\u9996\u6b21\u4ee5\u6a21\u5757\u7684\u5f62\u5f0f\u51fa\u73b0\uff0c\u7136\u540e\u5728Python 2.6\u4e2d\u5b83\u4eec\u5347\u7ea7\u6210\u4e3a\u5185\u7f6e\u7c7b\u578b\u3002 \u96c6\u5408(set) \uff0c\u5305\u542b\u4e0d\u53ef\u53d8\u7684\u96c6\u5408\uff08frozenset\uff09\uff0c\u662f\u4e00\u79cd\u65e0\u5e8f\u4e14\u5143\u7d20\u552f\u4e00\u7684\u5e8f\u5217\uff0c\u6240\u4ee5\u96c6\u5408\u7684\u672c\u8d28\u662f\u8bb8\u591a\u552f\u4e00\u5bf9\u8c61\u7684\u805a\u96c6\u3002 \u548c\u5b57\u5178\u7c7b\u4f3c\uff0c\u96c6\u5408\u7684\u5143\u7d20\u662f\u4e0d\u53ef\u53d8\u7684\u3002\u53ef\u4ee5\u8ba4\u4e3a\u96c6\u5408\u4e5f\u50cf\u5b57\u5178\uff0c\u4f46\u662f\u53ea\u6709\u952e\u6ca1\u6709\u503c\u3002\u57fa\u672c\u529f\u80fd\u662f\u8fdb\u884c\u6210\u5458\u5173\u7cfb\u6d4b\u8bd5\u548c\u5220\u9664\u91cd\u590d\u5143\u7d20\u3002\u6240\u4ee5\u96c6\u5408\u53e6\u4e00\u4e2a\u7528\u9014\u662f\u53bb\u91cd\u590d\u3002 \u96c6\u5408\u4e2d\u7684\u5143\u7d20\u5fc5\u987b\u662f\u53ef\u6563\u5217\u7684\uff0cset\u7c7b\u578b\u672c\u8eab\u662f\u4e0d\u53ef\u6563\u5217\u7684\uff0c\u4f46\u662ffrozenset\u53ef\u4ee5\u3002\u56e0\u6b64\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u5305\u542b\u4e0d\u540cfrozenset\u7684set\u3002 \u96c6\u5408\u53ef\u4ee5\u6709\u4e24\u79cd\u521b\u5efa\u65b9\u5f0f\uff1a\u901a\u8fc7set()\u51fd\u6570\u6216\u8005{}\u6765\u521b\u5efa\uff08\u7528\u5927\u62ec\u53f7\u62ec\u4f4f\u7684\u5185\u5bb9\uff0cPython3\u81ea\u52a8\u5b9a\u4e49\u4e3a\u96c6\u5408\uff09\u3002 \u96c6\u5408\u4e0d\u5c5e\u4e8e\u5e8f\u5217\u7c7b\u6570\u636e\uff0c \u96c6\u5408\u4e0d\u652f\u6301\u901a\u8fc7\u7d22\u5f15\u8bbf\u95ee\u6307\u5b9a\u5143\u7d20\uff0c\u4f46\u53ef\u4ee5\u589e\u52a0\u548c\u5220\u9664\u5143\u7d20\u3002 \u9762\u7684\u4f8b\u5b50\u662f\u6c42 haystacke \u548c needles \u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u5143\u7d20\u4e2a\u6570\u3002 haystacke = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'f', 'g', 'h', 'c', 'd', 'e', 'c', 'd', 'e', 'f', 'g', 'h'} needles = {'c', 'h', 'w'} type(haystacke) # <class 'set'> type(needles) # <class 'set'> # \u4f20\u7edf\u65b9\u6cd5 found = 0 for i in needles: if i in haystacke: found += 1 print(found) # 2 # \u96c6\u5408\u65b9\u6cd5\u4e00 found = len(needles & haystacke) print(found) # 2 # \u96c6\u5408\u65b9\u6cd5\u4e8c found = len(needles.intersection(haystacke)) print(found) # 2 \u96c6\u5408\u5b9e\u73b0\u4e86\u5f88\u591a\u57fa\u7840\u7684\u4e2d\u7f00\u8fd0\u7b97\u7b26\uff0c\u6bd4\u5982\uff0c\u96c6\u5408\u652f\u6301\u6570\u5b66\u4e0a\u7684\u96c6\u5408\u64cd\u4f5c\uff1a\u5e76\u96c6\u3001\u4ea4\u96c6\u3001\u5dee\u96c6\u3001\u5bf9\u79f0\u5dee\u96c6\u3002 \u65b9\u6cd5\u540d\u79f0 \u8bf4\u660e add() \u4e3a\u96c6\u5408\u6dfb\u52a0\u5143\u7d20 update() \u7ed9\u96c6\u5408\u6dfb\u52a0\u5143\u7d20 clear() \u79fb\u9664\u96c6\u5408\u4e2d\u7684\u6240\u6709\u5143\u7d20 copy() \u62f7\u8d1d\u4e00\u4e2a\u96c6\u5408 remove() \u79fb\u9664\u6307\u5b9a\u5143\u7d20 pop() \u968f\u673a\u79fb\u9664\u5143\u7d20 discard() \u5220\u9664\u96c6\u5408\u4e2d\u6307\u5b9a\u7684\u5143\u7d20 < \u6216\u8005issubset() \u5224\u65ad\u6307\u5b9a\u96c6\u5408\u662f\u5426\u4e3a\u8be5\u65b9\u6cd5\u53c2\u6570\u96c6\u5408\u7684\u5b50\u96c6 | \u6216\u8005union() \u8fd4\u56de\u4e24\u4e2a\u96c6\u5408\u7684\u5e76\u96c6 & \u6216\u8005intersection() \u8fd4\u56de\u96c6\u5408\u7684\u4ea4\u96c6 intersection_update() \u8fd4\u56de\u96c6\u5408\u7684\u4ea4\u96c6 - \u6216\u8005difference() \u8fd4\u56de\u591a\u4e2a\u96c6\u5408\u7684\u5dee\u96c6 difference_update() \u79fb\u9664\u96c6\u5408\u4e2d\u7684\u5143\u7d20\uff0c\u8be5\u5143\u7d20\u5728\u6307\u5b9a\u7684\u96c6\u5408\u4e5f\u5b58\u5728 ^ \u6216\u8005symmetric_difference() \u8fd4\u56de\u4e24\u4e2a\u96c6\u5408\u4e2d\u4e0d\u91cd\u590d\u7684\u5143\u7d20\u96c6\u5408(\u4e24\u96c6\u5408\u9664\u53bb\u4ea4\u96c6\u90e8\u5206\u7684\u5143\u7d20) symmetric_difference_update() \u79fb\u9664\u5f53\u524d\u96c6\u5408\u4e2d\u5728\u53e6\u5916\u4e00\u4e2a\u6307\u5b9a\u96c6\u5408\u76f8\u540c\u7684\u5143\u7d20\uff0c\u5e76\u5c06\u53e6\u5916\u4e00\u4e2a\u6307\u5b9a\u96c6\u5408\u4e2d\u4e0d\u540c\u7684\u5143\u7d20\u63d2\u5165\u5230\u5f53\u524d\u96c6\u5408\u4e2d isdisjoint() \u5224\u65ad\u4e24\u4e2a\u96c6\u5408\u662f\u5426\u5305\u542b\u76f8\u540c\u7684\u5143\u7d20\uff0c\u5982\u679c\u6ca1\u6709\u8fd4\u56de True\uff0c\u5426\u5219\u8fd4\u56de False issuperset() \u5224\u65ad\u8be5\u65b9\u6cd5\u7684\u53c2\u6570\u96c6\u5408\u662f\u5426\u4e3a\u6307\u5b9a\u96c6\u5408\u7684\u5b50\u96c6 \u4e3e\u4f8b a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} \u5e76\u96c6(a\u548cb\u4e2d\u7684\u6240\u6709\u4e0d\u540c\u5143\u7d20) print(a.union(b)) # {'c', 1, 2, 'd', 'a', 'b'} print(a | b) # {'c', 1, 2, 'd', 'a', 'b'} \u4ea4\u96c6(a\u3001b\u4e2d\u540c\u65f6\u5305\u542b\u7684\u5143\u7d20) print(a.intersection(b)) # {'c', 1} print(a & b) # {'c', 1} \u5c06a\u7684\u5185\u5bb9\u8bbe\u7f6e\u4e3aa\u548cb\u7684\u4ea4\u96c6 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.intersection_update(b) print(a) # {1, 'c'} \u5728a\u4e0d\u5728b\u7684\u5143\u7d20 print(a.difference(b)) # {'a', 2, 'b'} print(a - b) # {2, 'a', 'b'} \u5c06a\u7684\u5185\u5bb9\u8bbe\u4e3a\u5728a\u4e0d\u5728b\u7684\u5143\u7d20 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.difference_update(b) print(a) # {2, 'b', 'a'} a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a -= b print(a) # {2, 'a', 'b'} \u5c06\u5143\u7d20\u52a0\u5165\u96c6\u5408a a.add(7) print(a) # {1, 2, 'c', 7, 'a', 'b'} \u6bcf\u6b21\u8f93\u51fa\u7684\u987a\u5e8f\u662f\u4e0d\u4e00\u6837\u7684 \u4ece\u96c6\u5408a\u79fb\u9664\u67d0\u4e2a\u5143\u7d20 a.remove(7) print(a) # {1, 2, 'c', 'a', 'b'} \u5982\u679ca\u88ab\u6e05\u7a7a\uff0c\u5219\u62a5\u9519 KeyError: 7 \u6240\u6709\u5728a\u6216b\u4e2d\uff0c\u4f46\u4e0d\u662f\u540c\u65f6\u5728a\u3001b\u4e2d\u7684\u5143\u7d20 print(a.symmetric_difference(b)) # {2, 'd', 'b', 'a'} print(a ^ b) # {2, 'd', 'b', 'a'} \u5c06a\u7684\u5185\u5bb9\u8bbe\u4e3a\u6240\u6709\u5728a\u6216b\u4e2d\uff0c\u4f46\u4e0d\u662f\u540c\u65f6\u5728a\u3001b\u4e2d\u7684\u5143\u7d20 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.symmetric_difference_update(b) print(a) # {'a', 2, 'd', 'b'} a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a ^= b print(a) # {2, 'd', 'a', 'b'} \u5982\u679ca\u5305\u542b\u4e8eb\uff0c\u8fd4\u56deTure print(a.issubset(b)) # False \u5c06a\u7684\u5185\u5bb9\u8bbe\u7f6e\u4e3aa\u548cb\u7684\u5e76\u96c6 print(a) # {'a', 2, 'd', 'b'} a = {'a', 'b', 'c', 1, 2} a.update(b) print(a) # {1, 2, 'a', 'b', 'd', 'c'} \u79fb\u9664\u4efb\u610f\u5143\u7d20\uff0c\u5982\u679c\u96c6\u5408\u662f\u7a7a\u7684\uff0c\u629b\u51fakeyError a.pop() # \u968f\u673a\u79fb\u9664\u67d0\u4e2a\u5143\u7d20\uff0c\u6ca1\u6709\u8f93\u5165\u53d8\u91cf\uff0c\u5982\u679c\u96c6\u5408\u662f\u7a7a\u7684\uff0c\u629b\u51faKeyError: 'pop from an empty set' print(a) # {2, 1, 'd', 'b', 'a'} \u5c06\u96c6\u5408\u91cd\u7f6e\u4e3a\u7a7a\uff0c\u6e05\u7a7a\u6240\u6709\u5143\u7d20 a.clear() print(a) # set() \u96c6\u5408\u7684\u5143\u7d20\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u5982\u679c\u60f3\u8981\u5305\u542b\u5217\u8868\u578b\u7684\u5143\u7d20\uff0c\u5fc5\u987b\u5148\u8f6c\u6362\u4e3a\u5143\u7ec4 my_data1 = [1, 2, 3, 4] my_data2 = [3, 4, 5, 6] my_set = {tuple(my_data1), tuple(my_data2)} print(my_set) # {(1, 2, 3, 4), (3, 4, 5, 6)} 1.6 \u5143\u7ec4\uff08tuple\uff09 Python \u7684\u5143\u7ec4\u4e0e\u5217\u8868\u7c7b\u4f3c\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u5143\u7ec4\u7684\u5143\u7d20\u4e0d\u80fd\u4fee\u6539\u3002 \u5143\u7ec4\u4f7f\u7528\u5c0f\u62ec\u53f7( )\uff0c\u5217\u8868\u4f7f\u7528\u65b9\u62ec\u53f7[ ]\u3002 \u5143\u7ec4\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u65f6\uff0c\u9700\u8981\u5728\u5143\u7d20\u540e\u9762\u6dfb\u52a0\u9017\u53f7 \uff0c\u5426\u5219\u62ec\u53f7\u4f1a\u88ab\u5f53\u4f5c\u8fd0\u7b97\u7b26\u4f7f\u7528\u3002 \u5143\u7ec4\u53ef\u4ee5\u4f7f\u7528\u4e0b\u6807\u7d22\u5f15\u6765\u8bbf\u95ee\u5143\u7ec4\u4e2d\u7684\u503c\u3002 \u5143\u7ec4\u4e2d\u7684\u5143\u7d20\u503c\u662f\u4e0d\u5141\u8bb8\u4fee\u6539\u7684\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u5bf9\u5143\u7ec4\u8fdb\u884c\u8fde\u63a5\u7ec4\u5408\u3002 \u5143\u7ec4\u4e2d\u7684\u5143\u7d20\u503c\u662f\u4e0d\u5141\u8bb8\u5220\u9664\u7684\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528del\u8bed\u53e5\u6765\u5220\u9664\u6574\u4e2a\u5143\u7ec4\u3002 # \u6b64\u5904\u62ec\u53f7\u88ab\u89e3\u6790\u4e3a\u8fd0\u7b97\u7b26\uff0c\u9700\u8981\u5728\u540e\u9762\u52a0\u4e0a\u9017\u53f7\u624d\u4f1a\u88ab\u89e3\u91ca\u4e3a\u5143\u7ec4 tup1 = (10) print(type(tup1)) # <class 'int'> tup1 = (10,) print(type(tup1)) # <class 'tuple'> \u521b\u5efa\u5143\u7ec4\u6700\u7b80\u5355\u7684\u529e\u6cd5\u5c31\u662f\u7528\u9017\u53f7\u5206\u9694\u5e8f\u5217\u503c\u3002\u5143\u7ec4\u5bf9\u6570\u636e\u7c7b\u578b\u6ca1\u6709\u4e00\u81f4\u6027\u8981\u6c42\u3002 tup = 4, 5, 6 print(tup) # (4, 5, 6) nested_tup = (4, 5, 6), (7, 8) print(nested_tup) # # ((4, 5, 6), (7, 8)) tup = ('a', 'b', {'one': 1}) print(type(tup)) # <class 'tuple'> \u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fdb\u884c\u5143\u7ec4\u8fde\u63a5\u5408\u5e76\u3002 tup = tuple((4, None, 'fool') + (6, 0) + ('bar',)) print(tup) # (4, None, 'fool', 6, 0, 'bar') \u5143\u7ec4\u7684\u4e0d\u53ef\u53d8\u6307\u7684\u662f \u5143\u7ec4\u6240\u6307\u5411\u7684\u5185\u5b58\u4e2d\u7684\u5185\u5bb9\u4e0d\u53ef\u53d8 \u3002 tup = ('h', 'e', 'l', 'l', 'o') print(id(tup)) # 139820353350208 tup = (1, 2, 3, 4, 5) print(id(tup)) # 139820353298896 tup[0] = 'x' # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'tuple' object does not support item assignment \u5c06\u5143\u7ec4\u4e58\u4ee5\u6574\u6570\uff0c\u5219\u4f1a\u548c\u5217\u8868\u4e00\u6837\uff0c\u751f\u6210\u542b\u6709\u591a\u4efd\u62f7\u8d1d\u7684\u5143\u7ec4\u3002\u5bf9\u8c61\u81ea\u8eab\u5e76\u6ca1\u6709\u590d\u5236\uff0c\u53ea\u662f\u6307\u5411\u5b83\u4eec\u7684\u5f15\u7528\u8fdb\u884c\u4e86\u590d\u5236\u3002 tup = tuple(('fool', 'bar') * 4) print(tup) # ('fool', 'bar', 'fool', 'bar', 'fool', 'bar', 'fool', 'bar') \u5982\u679c\u5143\u7ec4\u4e2d\u7684\u4e00\u4e2a\u5bf9\u8c61\u662f\u53ef\u53d8\u7684\uff0c\u4f8b\u5982\u5217\u8868\uff0c\u4f60\u53ef\u4ee5\u5728\u5b83\u5185\u90e8\u8fdb\u884c\u4fee\u6539 tup = tuple(['foo', [4, 5, 6], True]) tup[1].append(0) print(tup) # ('foo', [4, 5, 6, 0], True) tup[1].append([9]) print(tup) # ('foo', [4, 5, 6, 0, [9]], True) \u4f7f\u7528tuple\u51fd\u6570\u5c06\u4efb\u610f\u5e8f\u5217\u6216\u8fed\u4ee3\u5668\u8f6c\u6362\u4e3a\u5143\u7ec4 tup = tuple([4, 5, 6]) print(tup) # (4, 5, 6) tup = tuple('string') print(tup) # ('s', 't', 'r', 'i', 'n', 'g') print(tup[2]) # r # \u5143\u7ec4\u7684\u5143\u7d20\u53ef\u4ee5\u901a\u8fc7\u4e2d\u62ec\u53f7[]\u6765\u83b7\u53d6 \u5982\u679c\u8981\u5c06\u5143\u7ec4\u578b\u7684\u8868\u8fbe\u5f0f\u8d4b\u503c\u7ed9\u53d8\u91cf\uff0cPython\u4f1a\u5bf9\u7b49\u53f7\u53f3\u8fb9\u7684\u503c\u8fdb\u884c \u62c6\u5305 tup = (9, 5, (8, 7)) a, b, c = tup print(a) # 9 print(b) # 5 print(c) # (8, 7) a, b, (c, d) = tup print(a) # 9 print(b) # 5 print(c) # 8 print(d) # 7 tup = (9, 5, (8, 7)) a, b, c = tup c, a = a, c # \u5229\u7528\u62c6\u5305\u5b9e\u73b0\u4ea4\u6362 print(a) # (8, 7) print(b) # 5 print(c) # 9 \u5229\u7528\u62c6\u5305\u5b9e\u73b0\u904d\u5386\u5143\u7ec4\u6216\u5217\u8868\u7ec4\u6210\u7684\u5e8f\u5217 seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)] for a, b, c in seq: print('a={0}, b={0}, c={0}'.format(a, b, c)) # \u5217\u8868\u6bcf\u4e2a\u5143\u7d20\u7684\u53d6\u503c\u987a\u5e8f # a=1, b=1, c=1 # a=4, b=4, c=4 # a=7, b=7, c=7 print('a={0}, b={1}, c={2}'.format(a, b, c)) # a=1, b=2, c=3 # a=4, b=5, c=6 # a=7, b=8, c=9 print('a={2}, b={0}, c={1}'.format(a, b, c)) # a=3, b=1, c=2 # a=6, b=4, c=5 # a=9, b=7, c=8 \u5143\u7ec4\u62c6\u5305\u529f\u80fd\u8fd8\u5305\u62ec\u7279\u6b8a\u7684\u8bed\u6cd5*rest\u3002\u5f88\u591aPython\u7f16\u7a0b\u8005\u4f1a\u4f7f\u7528\u4e0b\u5212\u7ebf\uff08_\uff09\u6765\u8868\u793a\u4e0d\u60f3\u8981\u7684\u53d8\u91cf values = 1, 2, 3, 4, 5 a, b, *rest = values print(a) # 1 print(b) # 2 print(*rest) # 3 4 5 a, b, *_ = values print(*_) # 3 4 5 \u5177\u540d\u5143\u7ec4 collections.namedtuple \u662f\u4e00\u4e2a\u5de5\u5382\u51fd\u6570\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u4e00\u4e2a\u5e26\u5b57\u6bb5\u540d\u7684\u5143\u7ec4\u548c\u4e00\u4e2a\u6709\u540d\u5b57\u7684\u7c7b\u3002 \u7528namedtuple\u6784\u5efa\u7684\u7c7b\u7684\u5b9e\u4f8b\u6240\u6d88\u8017\u7684\u5185\u5b58\u8ddf\u5143\u7ec4\u662f\u4e00\u6837\u7684\uff0c\u56e0\u4e3a\u5b57\u6bb5\u540d\u90fd\u88ab\u5b58\u5728\u5bf9\u5e94\u7684\u7c7b\u91cc\u9762\u3002 \u521b\u5efa\u4e00\u4e2a\u5177\u540d\u5143\u7ec4\u9700\u8981\u4e24\u4e2a\u53c2\u6570\uff0c\u4e00\u4e2a\u662f\u7c7b\u540d( City )\uff0c\u53e6\u4e00\u4e2a\u662f\u7c7b\u7684\u5404\u4e2a\u5b57\u6bb5\u7684\u540d\u5b57( 'name country population coordinates' )\u3002\u540e\u8005\u53ef\u4ee5\u662f\u7531\u6570\u4e2a\u5b57\u7b26\u4e32\u7ec4\u6210\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6216\u8005\u662f\u7531\u7a7a\u683c\u5206\u9694\u5f00\u7684\u5b57\u6bb5\u540d\u7ec4\u6210\u7684\u5b57\u7b26\u4e32\u3002 \u5b58\u653e\u5728\u5bf9\u5e94\u5b57\u6bb5\u91cc\u7684\u6570\u636e\u8981\u4ee5\u4e00\u4e32\u53c2\u6570\u7684\u5f62\u5f0f\u4f20\u5165\u5230\u6784\u9020\u51fd\u6570\u4e2d\uff08\u6ce8\u610f\uff0c\u5143\u7ec4\u7684\u6784\u9020\u51fd\u6570\u5374\u53ea\u63a5\u53d7\u5355\u4e00\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff09\u3002 \u5177\u540d\u5143\u7ec4\u8fd8\u6709\u4e00\u4e9b\u81ea\u5df1\u4e13\u6709\u7684\u5c5e\u6027\u3002\u4e0b\u9762\u5c55\u793a\u4e86\u51e0\u4e2a\u6700\u6709\u7528\u7684\uff1a _fields \u7c7b\u5c5e\u6027\u3001\u7c7b\u65b9\u6cd5 _make(iterable) \u548c\u5b9e\u4f8b\u65b9\u6cd5 _asdict() \u3002 _fields \u5c5e\u6027\u662f\u4e00\u4e2a\u5305\u542b\u8fd9\u4e2a\u7c7b\u6240\u6709\u5b57\u6bb5\u540d\u79f0\u7684\u5143\u7ec4\u3002 \u7528 _make() \u901a\u8fc7\u63a5\u53d7\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6765\u751f\u6210\u8fd9\u4e2a\u7c7b\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5b83\u7684\u4f5c\u7528\u8ddf City(*delhi_data) \u662f\u4e00\u6837\u7684\u3002 _asdict() \u628a\u5177\u540d\u5143\u7ec4\u4ee5 collections.OrderedDict \u7684\u5f62\u5f0f\u8fd4\u56de\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u5b83\u6765\u628a\u5143\u7ec4\u91cc\u7684\u4fe1\u606f\u53cb\u597d\u5730\u5448\u73b0\u51fa\u6765\u3002 from collections import namedtuple City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139691667)) print(tokyo) # City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139691667)) print(tokyo.population) # 36.933 print(tokyo[3]) # (35.689722, 139691667) print(City._fields) # ('name', 'country', 'population', 'coordinates') LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613899, 77.208889)) delhi = City._make(delhi_data) print(delhi) # City(name='Delhi NCR', country='IN', population=21.935, coordinates=LatLong(lat=28.613899, long=77.208889)) print(delhi._asdict()) # OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613899, long=77.208889))]) for key, value in delhi._asdict().items(): print(key + ':', value) # name: Delhi NCR # country: IN # population: 21.935 # coordinates: LatLong(lat=28.613899, long=77.208889) \u5143\u7ec4\u8fd8\u6709\u7b2c\u4e8c\u91cd\u529f\u80fd\uff1a\u4f5c\u4e3a\u4e0d\u53ef\u53d8\u5217\u8868\u7684\u5143\u7ec4\u3002 \u4e0b\u9762\u662f\u5217\u8868\u6216\u5143\u7ec4\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u5bf9\u6bd4\u3002\u9664\u4e86\u8ddf\u589e\u51cf\u5143\u7d20\u76f8\u5173\u7684\u65b9\u6cd5\u4e4b\u5916\uff0c\u5143\u7ec4\u652f\u6301\u5217\u8868\u7684\u5176\u4ed6\u6240\u6709\u65b9\u6cd5\u3002\u8fd8\u6709\u4e00\u4e2a\u4f8b\u5916\uff0c\u5143\u7ec4\u6ca1\u6709__reversed__\u65b9\u6cd5\u3002 \u4e00\u4e2a\u5173\u4e8e+=\u548c*=\u7684\u8c1c\u9898 \u4e0b\u9762\u7684\u4f8b\u5b50\u5c55\u793a\u4e86 *= \u5728\u53ef\u53d8\u548c\u4e0d\u53ef\u53d8\u5e8f\u5217\u4e0a\u7684\u4f5c\u7528\u3002\u5217\u8868\u7684ID\u6ca1\u53d8\uff0c\u65b0\u5143\u7d20\u8ffd\u52a0\u5230\u5217\u8868\u4e0a\uff0c\u4f46\u6267\u884c\u589e\u91cf\u4e58\u6cd5\u540e\uff0c\u65b0\u7684\u5143\u7ec4\u88ab\u521b\u5efa\u3002 list1 = [1, 2, 3, 4] id(list1) # 140409777308808 list1 *= 2 print(list1) # [1, 2, 3, 4, 1, 2, 3, 4] id(list1) # 140409777308808 tuple1 = (1, 2, 3, 4) id(tuple1) # 140409777230536 tuple1 *= 2 print(tuple1) # (1, 2, 3, 4, 1, 2, 3, 4) id(tuple1) # 140409780104888 \u4f46\u5bf9\u4e8e\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u867d\u7136 tuple1[2] += [50, 60] \u6267\u884c\u65f6\u6709\u5f02\u5e38\u629b\u51fa\uff0c\u4f46 tuple1 \u5374\u88ab\u4fee\u6539\u4e86\u3002 t = (1, 2, [10, 20]) t[2] += [50, 60] # TypeError: 'tuple' object does not support item assignment print(t) # (1, 2, [10, 20, 50, 60]) \u4e0b\u56fe\u5927\u81f4\u63cf\u8ff0\u4e86\u4e0a\u8ff0\u6267\u884c\u8fc7\u7a0b\u3002 \u4e3a\u4e86\u907f\u514d\u4e0a\u9762\u60c5\u51b5\u7684\u53d1\u751f\uff0c\u6211\u4eec \u4e0d\u8981\u628a\u53ef\u53d8\u5bf9\u8c61\u653e\u5728\u5143\u7ec4\u91cc\u9762 \u3002\u589e\u91cf\u8d4b\u503c\u4e0d\u662f\u4e00\u4e2a\u539f\u5b50\u64cd\u4f5c\uff0c\u5b83\u867d\u7136\u629b\u51fa\u4e86\u5f02\u5e38\uff0c\u4f46\u8fd8\u662f\u5b8c\u6210\u4e86\u64cd\u4f5c\u3002 1.7 \u5185\u5b58\u89c6\u56feMemoryview memoryview\u662f\u4e00\u4e2a\u5185\u7f6e\u7c7b\uff0c\u5b83\u80fd\u8ba9\u7528\u6237\u5728\u4e0d\u590d\u5236\u5185\u5bb9\u7684\u60c5\u51b5\u4e0b\u64cd\u4f5c\u540c\u4e00\u4e2a\u6570\u7ec4\u7684\u4e0d\u540c\u5207\u7247\u3002 \u5185\u5b58\u89c6\u56fe\u5176\u5b9e\u662f\u6cdb\u5316\u548c\u53bb\u6570\u5b66\u5316\u7684NumPy\u6570\u7ec4\u3002\u5b83\u8ba9\u4f60\u5728\u4e0d\u9700\u8981\u590d\u5236\u5185\u5bb9\u7684\u524d\u63d0\u4e0b\uff0c\u5728\u6570\u636e\u7ed3\u6784\u4e4b\u95f4\u5171\u4eab\u5185\u5b58\u3002 \u5176\u4e2d\u6570\u636e\u7ed3\u6784\u53ef\u4ee5\u662f\u4efb\u4f55\u5f62\u5f0f\uff0c\u6bd4\u5982PIL\u56fe\u7247\u3001SQLite\u6570\u636e\u5e93\u548cNumPy\u7684\u6570\u7ec4\uff0c\u7b49\u7b49\u3002\u8fd9\u4e2a\u529f\u80fd\u5728\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u5408\u7684\u65f6\u5019\u975e\u5e38\u91cd\u8981\u3002 memoryview.cast\u7684\u6982\u5ff5\u8ddf\u6570\u7ec4\u6a21\u5757\u7c7b\u4f3c\uff0c\u80fd\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u8bfb\u5199\u540c\u4e00\u5757\u5185\u5b58\u6570\u636e\uff0c\u800c\u4e14\u5185\u5bb9\u5b57\u8282\u4e0d\u4f1a\u968f\u610f\u79fb\u52a8\u3002\u8fd9\u8ddfC\u8bed\u8a00\u4e2d\u7c7b\u578b\u8f6c\u6362\u7684\u6982\u5ff5\u5dee\u4e0d\u591a\u3002 memoryview.cast\u4f1a\u628a\u540c\u4e00\u5757\u5185\u5b58\u91cc\u7684\u5185\u5bb9\u6253\u5305\u6210\u4e00\u4e2a\u5168\u65b0\u7684memoryview\u5bf9\u8c61\u7ed9\u4f60\u3002 array \u91cc\u9762\u7684Type code\uff1a 'b' signed integer 1 'B' unsigned integer 1 'u' Unicode character 2 (see note) 'h' signed integer 2 'H' unsigned integer 2 'i' signed integer 2 'I' unsigned integer 2 'l' signed integer 4 'L' unsigned integer 4 'q' signed integer 8 (see note) 'Q' unsigned integer 8 (see note) 'f' floating point 4 'd' floating point 8 numbers = array('h', [-2, -1, 0, 1, 2]) # array('h', [-2, -1, 0, 1, 2]) # \u75285\u4e2a\u77ed\u6574\u578b\u6709\u7b26\u53f7\u6574\u6570\u7684\u6570\u7ec4\uff08\u7c7b\u578b\u7801\u662f'h'\uff09\u521b\u5efa\u4e00\u4e2amemoryview\u3002 memv = memoryview(numbers) # memv\u91cc\u76845\u4e2a\u5143\u7d20\u8ddf\u6570\u7ec4\u91cc\u7684\u6ca1\u6709\u533a\u522b\u3002 print(len(memv)) # 5 print(memv[0]) # -2 print(memv.tolist()) # [-2, -1, 0, 1, 2] # \u521b\u5efa\u4e00\u4e2amemv_oct\uff0c\u8fd9\u4e00\u6b21\u662f\u628amemv\u91cc\u7684\u5185\u5bb9\u8f6c\u6362\u6210'B'\u7c7b\u578b\uff0c\u4e5f\u5c31\u662f\u65e0\u7b26\u53f7\u5b57\u7b26\u3002 memv_oct = memv.cast('B') print(memv_oct.tolist()) # [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] # \u628a\u4f4d\u4e8e\u4f4d\u7f6e5\u7684\u5b57\u8282\u8d4b\u503c\u62104\u3002\u56e0\u4e3a\u6211\u4eec\u628a\u53602\u4e2a\u5b57\u8282\u7684\u6574\u6570\u7684\u9ad8\u4f4d\u5b57\u8282\u6539\u6210\u4e864\uff0c\u6240\u4ee5\u8fd9\u4e2a\u6709\u7b26\u53f7\u6574\u6570\u7684\u503c\u5c31\u53d8\u6210\u4e861024\u3002 memv_oct[5] = 4 print(numbers) # array('h', [-2, -1, 1024, 1, 2]) 2. \u52a8\u6001\u5f15\u7528\u3001\u5f3a\u7c7b\u578b \u661f\u53f7 * \u7684\u53c2\u6570\u4f1a\u4ee5\u5143\u7ec4(tuple)\u7684\u5f62\u5f0f\u5bfc\u5165\uff0c\u5b58\u653e\u6240\u6709\u672a\u547d\u540d\u7684\u53d8\u91cf\u53c2\u6570 def printinfo(arg1, *vartuple): print(\"\u8f93\u51fa\u4efb\u4f55\u4f20\u5165\u7684\u53c2\u6570: \") print(arg1) print(vartuple) for var in vartuple: print(var) return printinfo(10) # 10 # () printinfo(70, 60, 50) # 70 # (60, 50) # 60 # 50 \u4e24\u4e2a\u661f\u53f7 ** \u7684\u53c2\u6570\u4f1a\u4ee5\u5b57\u5178\u7684\u5f62\u5f0f\u5bfc\u5165 def printinfo(arg1, **vardict): print(\"\u8f93\u51fa\u4efb\u4f55\u4f20\u5165\u7684\u53c2\u6570: \") print(arg1) print(vardict) printinfo(1, a=2, b=3) # 1 # {'a': 2, 'b': 3} \u5b57\u5178\u683c\u5f0f\u8f93\u51fa Python\u4e2d\u7684\u5bf9\u8c61\u5f15\u7528\u5e76\u4e0d\u6d89\u53ca\u7c7b\u578b\u3002\u53d8\u91cf\u5bf9\u4e8e\u5bf9\u8c61\u6765\u8bf4\u53ea\u662f\u7279\u5b9a\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u540d\u79f0\uff1b\u7c7b\u578b\u4fe1\u606f\u662f\u5b58\u50a8\u5728\u5bf9\u8c61\u81ea\u8eab\u4e4b\u4e2d\u3002 a = 5 print(type(a)) # <class 'int'> a = 'foo' print(type(a)) # <class 'str'> Python\u662f\u5f3a\u7c7b\u578b\u8bed\u8a00\uff0c\u6240\u6709\u7684\u5bf9\u8c61\u90fd\u62e5\u6709\u4e00\u4e2a\u6307\u5b9a\u7684\u7c7b\u578b\uff08\u6216\u7c7b\uff09\uff0c\u9690\u5f0f\u7684\u8f6c\u6362\u53ea\u5728\u67d0\u4e9b\u7279\u5b9a\u3001\u660e\u663e\u7684\u60c5\u51b5\u4e0b\u53d1\u751f\u3002 a = 4.5 b = 2 print('a is {0}, b is {1}'.format(type(a), type(b))) # a is <class 'float'>, b is <class 'int'> \u5b57\u4e32\u683c\u5f0f\u5316\uff0c\u7528\u4e8e\u540e\u7eed\u8bbf\u95ee print(a / b) # 2.25 \u4f7f\u7528isinstance\u51fd\u6570\u6765\u68c0\u67e5\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u662f\u7279\u5b9a\u7c7b\u578b\u7684\u5b9e\u4f8b\u3002isinstance\u63a5\u53d7\u4e00\u4e2a\u5305\u542b\u7c7b\u578b\u7684\u5143\u7ec4\uff0c\u53ef\u4ee5\u68c0\u67e5\u5bf9\u8c61\u7684\u7c7b\u578b\u662f\u5426\u5728\u5143\u7ec4\u4e2d\u7684\u7c7b\u578b\u4e2d\u3002 a = 5 b = 4.5 c = 'foo' print(isinstance(a, int)) # True print(isinstance(b, str)) # False print(isinstance(c, (str, int))) # True print(isinstance(c, (float, int))) # False \u5c5e\u6027\u548c\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u901a\u8fc7getattr\u51fd\u6570\u83b7\u5f97\u3002\u5728\u5176\u4ed6\u7684\u8bed\u8a00\u4e2d\uff0c\u901a\u8fc7\u53d8\u91cf\u540d\u8bbf\u95ee\u5bf9\u8c61\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u53cd\u5c04\u201d\u3002 b = 'foo' print(getattr(b, 'split')) # <built-in method split of str object at 0x7f1d603ba430> 3. \u4e8c\u5143\u8fd0\u7b97\u7b26\u548c\u6bd4\u8f83\u8fd0\u7b97 \u68c0\u67e5\u4e24\u4e2a\u5f15\u7528\u662f\u5426\u6307\u5411\u540c\u4e00\u4e2a\u5bf9\u8c61\uff0c\u53ef\u4ee5\u4f7f\u7528is\u5173\u952e\u5b57\u3002 is\u548cis not\u7684\u5e38\u7528\u4e4b\u5904\u662f\u68c0\u67e5\u4e00\u4e2a\u53d8\u91cf\u662f\u5426\u4e3aNone\uff0c\u56e0\u4e3aNone\u53ea\u6709\u4e00\u4e2a\u5b9e\u4f8b\u3002 a = [1, 2, 3] b = a c = list(a) # list\u51fd\u6570\u603b\u662f\u521b\u5efa\u4e00\u4e2a\u65b0\u7684Python\u5217\u8868\uff08\u5373\u4e00\u4efd\u62f7\u8d1d\uff09 print(a is b) # True print(a is not c) # True print(a == c) # True d = None print(d is None) # True Python\u4e2d\u7684\u5927\u90e8\u5206\u5bf9\u8c61\uff0c\u4f8b\u5982\u5217\u8868\u3001\u5b57\u5178\u3001NumPy\u6570\u7ec4\u90fd\u662f\u53ef\u53d8\u5bf9\u8c61\uff0c\u5927\u591a\u6570\u7528\u6237\u5b9a\u4e49\u7684\u7c7b\u578b\uff08\u7c7b\uff09\u4e5f\u662f\u53ef\u53d8\u7684\u3002 \u53ef\u53d8\u5bf9\u8c61\u4e2d\u5305\u542b\u7684\u5bf9\u8c61\u548c\u503c\u662f\u53ef\u4ee5\u88ab\u4fee\u6539\u7684\u3002\u8fd8\u6709\u5176\u4ed6\u4e00\u4e9b\u5bf9\u8c61\u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u6bd4\u5982\u5b57\u7b26\u4e32\u3001\u5143\u7ec4\u3002 a_list = ['foo', 2, [4, 5]] # \u5217\u8868 a_list[2] = (3, 4) print(a_list) # ['foo', 2, (3, 4)] a_tuple = (3, 5, (4, 5)) # \u5143\u7ec4 a_tuple[1] = 'four' # TypeError: 'tuple' object does not support item assignment \u4e0d\u53ef\u88ab\u4fee\u6539 print(a_tuple) # (3, 5, (4, 5)) 4. \u6807\u91cf\u7c7b\u578b Python\u6807\u91cf\u7c7b\u578b\uff1aNone, str, bytes, float, bool, int \u6570\u503c\u7c7b\u578b\u3002 \u57fa\u7840\u7684Python\u6570\u5b57\u7c7b\u578b\u5c31\u662fint\u548cfloat\u3002int\u53ef\u4ee5\u5b58\u50a8\u4efb\u610f\u5927\u5c0f\u6570\u5b57\u3002\u6d6e\u70b9\u6570\u5728Python\u4e2d\u7528float\u8868\u793a\uff0c\u6bcf\u4e00\u4e2a\u6d6e\u70b9\u6570\u90fd\u662f\u53cc\u7cbe\u5ea664\u4f4d\u6570\u503c\u3002 ival = 17338971 print(ival ** 6) # 27173145946003847721495630081806010734757321 fval = 17338971.0 print(fval ** 6) # 2.7173145946003847e+43 print(3 / 2) # 1.5 print(3 // 2) # 1 \u5b57\u7b26\u4e32\u3002 Python\u7684\u5b57\u7b26\u4e32\u662f\u4e0d\u53ef\u53d8\u7684\u3002 a = 5.6 s = str(a) print(s) # 5.6 b = 'python' print(list(b)) # ['p', 'y', 't', 'h', 'o', 'n'] print(b[2]) # t b[2] = 'f' # TypeError: 'str' object does not support item assignment \u5b57\u7b26\u4e32\u662f\u4e0d\u53ef\u53d8\u7684 \u53cd\u659c\u6760\u7b26\u53f7\\\u662f\u4e00\u79cd\u8f6c\u4e49\u7b26\u53f7\uff0c\u5b83\u7528\u6765\u6307\u660e\u7279\u6b8a\u7b26\u53f7\u3002 \u5982\u679c\u4f60\u6709\u4e00\u4e2a\u4e0d\u542b\u7279\u6b8a\u7b26\u53f7\u4f46\u542b\u6709\u5927\u91cf\u53cd\u659c\u6760\u7684\u5b57\u7b26\u4e32\u65f6\uff0c\u53ef\u4ee5\u5728\u5b57\u7b26\u4e32\u524d\u9762\u52a0\u4e00\u4e2a\u524d\u7f00\u7b26\u53f7r\uff0c\u8868\u660e\u8fd9\u4e9b\u5b57\u7b26\u662f\u539f\u751f\u5b57\u7b26\uff0cr\u662fraw\u7684\u7b80\u5199\uff0c\u8868\u793a\u539f\u751f\u7684\u3002 x = '12\\\\34' y = r'this\\has\\no\\special\\characters' print(x) # 12\\34 print(y) # this\\has\\no\\special\\characters \u5b57\u7b26\u4e32\u683c\u5f0f\u5316 {0:.2f}\u8868\u793a\u5c06\u7b2c\u4e00\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u4e3a2\u4f4d\u5c0f\u6570\u7684\u6d6e\u70b9\u6570 {1:s}\u8868\u793a\u5c06\u7b2c\u4e8c\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u4e3a\u5b57\u7b26\u4e32 {2:d}\u8868\u793a\u5c06\u7b2c\u4e09\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u6574\u6570 \u53c2\u8003Python\u5b98\u65b9\u6587\u6863 https://docs.python.org/3.6/library/string.html template = '{0:.2f} {1:s} are worth US${2:d}' print(template.format(4.5560, 'Argentine Pesos', 1)) # 4.56 Argentine Pesos are worth US$1 \u65e5\u671f\u548c\u65f6\u95f4 from datetime import datetime, date, time dt = datetime(2011, 10, 29, 20, 30, 21) print(dt.day) # 29 print(dt.minute) # 30 print(dt.date()) # 2011-10-29 print(dt.time()) # 20:30:21 print(dt.replace(minute=0, second=0)) # 2011-10-29 20:00:00 \u5c06\u5206\u949f\u3001\u79d2\u66ff\u6362\u4e3a0 print(datetime.strptime('20091021', '%Y%m%d')) # 2009-10-21 00:00:00 \u5b57\u7b26\u4e32\u53ef\u4ee5\u901a\u8fc7 strptime \u51fd\u6570\u8f6c\u6362\u4e3adatetime\u5bf9\u8c61 dt2 = datetime(2011, 11, 15, 22, 30) delta = dt2 - dt print(delta) # 17 days, 1:59:39 print(dt + delta) # 2011-11-15 22:30:00 range\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u8be5\u8fed\u4ee3\u5668\u751f\u6210\u4e00\u4e2a\u7b49\u5dee\u6574\u6570\u5e8f\u5217\u3002 print(range(10)) # range(0, 10) print(list(range(10))) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] print(list(range(0, 20, 2))) # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] 5. \u4e09\u5143\u8868\u8fbe\u5f0f value = true-expr if condition else false-expr x = 5 print('non-negative' if x >= 0 else 'negative') # non-negative","title":"Python\u8bed\u8a00\u57fa\u7840"},{"location":"python/Foundation/ch01/#python","text":"","title":"Python\u8bed\u8a00\u57fa\u7840"},{"location":"python/Foundation/ch01/#1-python6","text":"\u6570\u503c\u578b\uff08number\uff09\uff1a\u8868\u793a\u6570\u636e\u7ec4\u6210\u4e3a\u6570\u5b57 \u6574\u578b\uff08int\uff09 \u5341\u8fdb\u5236 \u516b\u8fdb\u5236 \u5341\u516d\u8fdb\u5236 \u6d6e\u70b9\u578b\uff08float\uff09 \u5e03\u5c14\u578b\uff08bool\uff09 \u590d\u6570\u6027\uff08complex\uff09 \u5b57\u7b26\u578b\uff08string\uff09\uff1a\u8868\u793a\u6570\u636e\u7ec4\u6210\u662f\u5b57\u7b26 \u5217\u8868\uff08list\uff09\uff1a\u7528\u6765\u8868\u793a\u4e00\u7ec4\u6709\u5e8f\u5143\u7d20\uff0c\u540e\u671f\u6570\u636e\u53ef\u4ee5\u4fee\u6539 ['A','B','C'] \u5143\u7ec4\uff08tuple\uff09\uff1a\u7528\u6765\u8868\u793a\u4e00\u7ec4\u6709\u5e8f\u5143\u7d20\uff0c\u540e\u671f\u6570\u636e\u4e0d\u53ef\u4fee\u6539 ('A','B','C','1') \u96c6\u5408\uff08set\uff09\uff1a\u4e00\u7ec4\u6570\u636e\u65e0\u5e8f\u4e0d\u91cd\u590d\u5143\u7d20 set([1,2,3,4]) \u5b57\u5178\uff08dictionary\uff09\uff1a\u7528\u952e\u503c\u5bf9\u7684\u5f62\u5f0f\u4fdd\u5b58\u4e00\u7ec4\u5143\u7d20 {'A':7,'B':1,'C':9} \u53ef\u8fed\u4ee3\u5bf9\u8c61\uff08Iterable\uff09 An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an iter() method or with a getitem() method that implements Sequence semantics. \u5e8f\u5217\uff08Sequence\uff09 An iterable which supports efficient element access using integer indices via the getitem() special method and defines a len() method that returns the length of the sequence. Some built-in sequence types are list, str, tuple, and bytes. Note that dict also supports getitem() and len(), but is considered a mapping rather than a sequence because the lookups use arbitrary immutable keys rather than integers. \u8fed\u4ee3\u5668\uff08Iterator\uff09 An object representing a stream of data. Repeated calls to the iterator\u2019s next() method (or passing it to the built-in function next()) return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its next() method just raise StopIteration again. Iterators are required to have an iter() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container. \u53ef\u53d8\u6570\u636e\uff08immutable\uff09\uff1a \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09\u3002 \u4e0d\u53ef\u53d8\u6570\u636e\uff08immutable\uff09\uff1a \u6570\u5b57\uff08number\uff09 \u5b57\u7b26\uff08string\uff09 \u5143\u7ec4\uff08tuple\uff09 \u53ef\u8fed\u4ee3\uff08iterable\uff09\uff1a \u5b57\u7b26\uff08string\uff09 \u5143\u7ec4\uff08tuple\uff09 \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09 \u5e8f\u5217\uff1a \u6709\u5e8f\u5e8f\u5217\uff1a\u5b57\u7b26\uff08string\uff09\uff0c\u5143\u7ec4\uff08tuple\uff09\uff0c\u5217\u8868\uff08list\uff09 \u65e0\u5e8f\u5e8f\u5217\uff1a\u5b57\u5178\uff08dictionary\uff09\uff0c\u96c6\u5408\uff08set\uff09 Python\u5e8f\u5217\u7c7b\u578b\u6700\u5e38\u89c1\u7684\u5206\u7c7b\u5c31\u662f\u53ef\u53d8\u548c\u4e0d\u53ef\u53d8\u5e8f\u5217\u3002\u4f46\u53e6\u5916\u4e00\u79cd\u5206\u7c7b\u65b9\u5f0f\u4e5f\u5f88\u6709\u7528\uff0c\u90a3\u5c31\u662f\u628a\u5b83\u4eec\u5206\u4e3a \u6241\u5e73\u5e8f\u5217 \u548c \u5bb9\u5668\u5e8f\u5217 \u3002\u524d\u8005\u7684\u4f53\u79ef\u66f4\u5c0f\u3001\u901f\u5ea6\u66f4\u5feb\u800c\u4e14\u7528\u8d77\u6765\u66f4\u7b80\u5355\uff0c\u4f46\u662f\u5b83\u53ea\u80fd\u4fdd\u5b58\u4e00\u4e9b\u539f\u5b50\u6027\u7684\u6570\u636e\uff0c\u6bd4\u5982\u6570\u5b57\u3001\u5b57\u7b26\u548c\u5b57\u8282\u3002\u5bb9\u5668\u5e8f\u5217\u5219\u6bd4\u8f83\u7075\u6d3b\uff0c\u4f46\u662f\u5f53\u5bb9\u5668\u5e8f\u5217\u9047\u5230\u53ef\u53d8\u5bf9\u8c61\u65f6\uff0c\u5c31\u9700\u8981\u683c\u5916\u5c0f\u5fc3\uff0c\u56e0\u4e3a\u8fd9\u79cd\u7ec4\u5408\u65f6\u5e38\u4f1a\u51fa\u73b0\u4e00\u4e9b\u201c\u610f\u5916\u201d\uff0c\u7279\u522b\u662f\u5e26\u5d4c\u5957\u7684\u6570\u636e\u7ed3\u6784\u51fa\u73b0\u65f6\uff0c\u66f4\u9700\u8981\u9a8c\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002 Python\u4e2d\u7684\u53d8\u91cf\u3001\u5e38\u91cf\u548c\u5b57\u9762\u91cf \u53d8\u91cf \u53d8\u91cf\u662f\u7528\u4e8e\u5728\u5185\u5b58\u4e2d\u5b58\u50a8\u6570\u636e\u7684\u547d\u540d\u4f4d\u7f6e\u3002\u53ef\u4ee5\u5c06\u53d8\u91cf\u89c6\u4e3a\u4fdd\u5b58\u6570\u636e\u7684\u5bb9\u5668\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u4ee5\u5728\u540e\u9762\u7a0b\u5e8f\u4e2d\u8fdb\u884c\u66f4\u6539\u3002\u4f8b\u5982\uff1a number = 10 \u3002\u4ece\u4f8b\u5b50\u4e2d\u53ef\u4ee5\u770b\u5230\uff0cPython\u4f7f\u7528\u8d4b\u503c\u8fd0\u7b97\u7b26 = \u4e3a\u53d8\u91cf\u8d4b\u503c\u3002 \u5e38\u91cf \u5e38\u91cf\u4e5f\u662f\u4e00\u79cd\u53d8\u91cf\uff0c\u53ea\u662f\u5176\u503c\u4e00\u65e6\u8d4b\u4e88\u540e\u65e0\u6cd5\u66f4\u6539\u3002\u53ef\u4ee5\u5c06\u5e38\u91cf\u89c6\u4e3a\u4fdd\u5b58\u4e86\u4ee5\u540e\u65e0\u6cd5\u66f4\u6539\u7684\u4fe1\u606f\u7684\u5bb9\u5668\u3002 \u5728Python\u4e2d\uff0c\u5e38\u91cf\u901a\u5e38\u662f\u5728\u6a21\u5757\u4e2d\u58f0\u660e\u548c\u5206\u914d\u7684\u3002\u5728\u8fd9\u91cc\uff0c\u6a21\u5757\u662f\u4e00\u4e2a\u5305\u542b\u53d8\u91cf\uff0c\u51fd\u6570\u7b49\u7684\u65b0\u6587\u4ef6\uff0c\u8be5\u6587\u4ef6\u88ab\u5bfc\u5165\u5230\u4e3b\u6587\u4ef6\u4e2d\u3002\u5728\u6a21\u5757\u5185\u90e8\uff0c\u7528\u6240\u6709\u5927\u5199\u5b57\u6bcd\u5199\u7684\u5e38\u91cf\u548c\u4e0b\u5212\u7ebf\u5c06\u5355\u8bcd\u5206\u5f00\u3002\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u4e0d\u5728Python\u4e2d\u4f7f\u7528\u5e38\u91cf\u3002\u7528\u5927\u5199\u5b57\u6bcd\u547d\u540d\u5b83\u4eec\u662f\u4e00\u79cd\u5c06\u5176\u4e0e\u666e\u901a\u53d8\u91cf\u5206\u5f00\u7684\u4e00\u79cd\u7ea6\u5b9a\uff0c\u4f46\u662f\uff0c\u5b9e\u9645\u4e0a\u5e76\u4e0d\u80fd\u963b\u6b62\u91cd\u65b0\u5206\u914d\u3002 \u5b57\u9762\u91cf\uff08literal\uff09 \u5b57\u9762\u91cf\u662f\u4ee5\u53d8\u91cf\u6216\u5e38\u91cf\u7ed9\u51fa\u7684\u539f\u59cb\u6570\u636e\uff08\u5176\u5b9e\u5c31\u662f\u6307\u53d8\u91cf\u7684\u5e38\u6570\u503c\uff0c\u5b57\u9762\u4e0a\u6240\u770b\u5230\u7684\u503c\uff09\u3002\u5728Python\u4e2d\u5b57\u9762\u91cf\u7c7b\u578b\u5982\u4e0b\uff1a \u6570\u5b57\u5b57\u9762\u91cf\u3002\u6570\u5b57\u5b57\u9762\u91cf\u662f\u4e0d\u53ef\u53d8\u7684\uff08\u4e0d\u53ef\u66f4\u6539\uff09\u3002\u6570\u5b57\u5b57\u9762\u91cf\u53ef\u4ee5\u5c5e\u4e8e3\u79cd\u4e0d\u540c\u7684\u6570\u503c\u7c7b\u578b\uff1aInteger\uff0cFloat \u548c Complex\u3002\u4f8b\u5982\uff1a float_1 = 10.5 \u662f\u5c5e\u4e8eFloat\u5b57\u9762\u91cf\u3002 \u5b57\u7b26\u4e32\u5b57\u9762\u91cf\u662f\u7531\u5f15\u53f7\u62ec\u8d77\u6765\u7684\u4e00\u7cfb\u5217\u5b57\u7b26\u3002\u6211\u4eec\u53ef\u4ee5\u5bf9\u5b57\u7b26\u4e32\u4f7f\u7528\u5355\u5f15\u53f7\uff0c\u53cc\u5f15\u53f7 \u6216 \u4e09\u5f15\u53f7\u3002\u5e76\u4e14\uff0c\u5b57\u7b26\u5b57\u9762\u91cf\u662f\u7528\u5355\u5f15\u53f7\u6216\u53cc\u5f15\u53f7\u5f15\u8d77\u6765\u7684\u5355\u4e2a\u5b57\u7b26\u3002\u4f8b\u5982\uff1a strings = \"This is Python\" \u3002 \u5e03\u5c14\u5b57\u9762\u91cf\u3002\u5e03\u5c14\u5b57\u9762\u91cf\u53ef\u4ee5\u5177\u6709\u4e24\u4e2a\u503c\u4e2d\u7684\u4efb\u4f55\u4e00\u4e2a\uff1a True \u6216 False \u3002\u4f8b\u5982\uff1a a = True + 4 \u3002 \u7279\u6b8a\u5b57\u9762\u91cf\u3002Python\u5305\u542b\u4e00\u4e2a\u7279\u6b8a\u5b57\u9762\u91cf\uff0c\u5373 None \u3002 \u5b57\u9762\u91cf\u96c6\u3002\u6709\u56db\u79cd\u4e0d\u540c\u7684\u5b57\u9762\u91cf\u96c6\u5408\uff1a\u5217\u8868\u5b57\u9762\u91cf\uff0c\u5143\u7ec4\u5b57\u9762\u91cf\uff0c\u5b57\u5178\u5b57\u9762\u91cf \u548c \u96c6\u5408\u5b57\u9762\u91cf\u3002","title":"1. Python\u6570\u636e\u7c7b\u578b\uff086\u4e2a\uff09"},{"location":"python/Foundation/ch01/#11-number","text":"\u4f8b\u5b50\uff1a a, b, c, d = 20, 5.5, True, 4+3j print(a, b, c, d) # 20 5.5 True (4+3j) print(type(a), type(b), type(c), type(d)) # <class 'int'> <class 'float'> <class 'bool'> <class 'complex'> Python\u4e5f\u53ef\u4ee5\u8fd9\u6837\u8d4b\u503c\uff1a a = b = c = d = 1 print(a, b, c, d) # 1 1 1 1 \u8fdb\u5236\u8f6c\u6362\uff1a a = -15 print(f'{a}\u5bf9\u5e94\u7684\u5341\u8fdb\u5236\u662f{a}, \u4e8c\u8fdb\u5236\u662f{a:b}, \u516b\u8fdb\u5236\u662f{a:o}, \u5341\u516d\u8fdb\u5236\u662f{a:x}')","title":"1.1 \u6570\u503c\u578b\uff08number\uff09"},{"location":"python/Foundation/ch01/#12-string","text":"\u5355\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u5305\u542b\u5927\u91cf\u53cc\u5f15\u53f7 \u53cc\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u5305\u542b\u5927\u91cf\u5355\u5f15\u53f7 \u4e09\u5f15\u53f7\uff1a\u5185\u5bb9\u4e2d\u540c\u65f6\u5305\u542b\u5355\u53cc\u5f15\u53f7\uff0c\u4e09\u4e2a\u5355\u5f15\u53f7\u6bd4\u8f83\u597d\u3002 a = 'string is \"special\"' b = \"string's value\" c = '''string's value is \"special\"''' d = \"\"\"string's context \"\"\"","title":"1.2 \u5b57\u7b26\u578b\uff08string\uff09"},{"location":"python/Foundation/ch01/#_1","text":"\u5b57\u7b26\u4e32\u5207\u7247 s = 'Python is very good' print(s[2:4]) # th print(s[5]) # n print(s[-1]) # d print(s[-3:-1]) # oo # \u975e\u8fed\u4ee3\u578b\uff0c\u4e0d\u53ef\u4fee\u6539 s[3] = 'b' # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'str' object does not support item assignment \u5b57\u7b26\u4e32\u5408\u5e76 print(s + '!!!') # Python is very good!!! replace( a,b \u5c06\u5b57\u7b26\u4e32\u4e2d\u7684 a \u66ff\u6362\u6210 b print(s.replace('is', 'we')) # Python we very good find(str) : \u8fd4\u56de str \u51fa\u73b0\u7684\u7d22\u5f15\u4f4d\u7f6e\uff0c\u5982\u679c\u627e\u4e0d\u5230\u8be5\u503c\uff0c\u5219 find() \u65b9\u6cd5\u5c06\u8fd4\u56de -1\u3002 print(s.find('a')) # -1 print(s.find('s')) # 8 str.index(a): \u67e5\u627e\u6307\u5b9a\u503c\u7684\u9996\u6b21\u51fa\u73b0\u3002\u5982\u679c\u627e\u4e0d\u5230\u8be5\u503c\uff0cindex() \u65b9\u6cd5\u5c06\u5f15\u53d1\u5f02\u5e38\u3002 print(s.index('s')) # 8 print(s.index('a')) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ValueError: substring not found str.count(a): \u7edf\u8ba1\u5b57\u7b26\u4e32\u4e2d a \u51fa\u73b0\u7684\u6b21\u6570 print(s.count('a')) # 0 print(s.count('o')) # 3 split: \u5bf9\u5b57\u7b26\u4e32\u8fdb\u884c\u5206\u5272\u3002\u5982\u679c\u53c2\u6570 num \u6709\u6307\u5b9a\u503c\uff0c\u5219\u5206\u9694 num+1 \u4e2a\u5b50\u5b57\u7b26\u4e32\u3002 # \u6309\u7a7a\u683c\u5206\u5272 print(s.split(' ')) # ['Python', 'is', 'very', 'good'] # \u6309\u7a7a\u683c\u5206\u5272\u62102\u4e2a\u5b50\u5b57\u7b26\u4e32 print(s.split(' ', 1)) # ['Python', 'is very good'] strip: \u79fb\u9664\u5b57\u7b26\u4e32\u9996\u5c3e\u6307\u5b9a\u7684\u5b57\u7b26 \u9ed8\u8ba4\u4e3a\u7a7a\u683c\u3002\u8be5\u65b9\u6cd5\u53ea\u80fd\u5220\u9664\u5f00\u5934\u6216\u662f\u7ed3\u5c3e\u7684\u5b57\u7b26\uff0c\u4e0d\u80fd\u5220\u9664\u4e2d\u95f4\u90e8\u5206\u7684\u5b57\u7b26\u3002 print(s) # Python is very good # \u79fb\u9664\u672b\u5c3e\u5b57\u7b26d print(s.strip('d')) # Python is very goo endswith (str): \u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u4ee5 str \u7ed3\u5c3e print(s.endswith('d')) # True print(s.endswith('a')) # False startswith (str): \u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u4ee5 str \u5f00\u5934 print(s.startswith('p')) # False print(s.startswith('P')) # True isdigit \uff1a\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u5168\u4e3a\u6570\u5b57 d = '+86-123' print(d.isdigit()) # False d = '86123' print(d.isdigit()) # True isalpha \uff1a\u5224\u65ad\u5b57\u7b26\u4e32\u662f\u5426\u5168\u4e3a\u5b57\u6bcd b = 'Ab?' print(b.isalpha()) # False c = 'Ab' print()c.isalpha() # True","title":"\u5b57\u7b26\u4e32\u5e38\u7528\u65b9\u6cd5"},{"location":"python/Foundation/ch01/#_2","text":"\u4f7f\u7528\u53cd\u659c\u6760\\\u8868\u793a\u8f6c\u4e49\u5b57\u7b26\u3002\u53cd\u659c\u6760\u524d\u9762\u52a0r\u4ee3\u8868\u539f\u59cb\u5b57\u7b26\u3002 a = 'str\\ning' print(a) # str # ing a = r'str\\ning' print(a) # str\\ning \u8f6c\u4e49\u7b26 \u63cf\u8ff0 \\\u5728\u884c\u5c3e \u7eed\u884c\u7b26 \\\\ \u53cd\u659c\u6760\u7b26\u53f7\\ \\' \u5355\u5f15\u53f7 \\b \u9000\u683c(Backspace) \\000 \u7a7a \\n \u6362\u884c \\v \u7eb5\u5411\u5236\u8868\u7b26 \\t \u6a2a\u5411\u5236\u8868\u7b26 \\r \u56de\u8f66\uff0c\u5c06 \\r \u540e\u9762\u7684\u5185\u5bb9\u79fb\u5230\u5b57\u7b26\u4e32\u5f00\u5934\uff0c\u5e76\u9010\u4e00\u66ff\u6362\u5f00\u5934\u90e8\u5206\u7684\u5b57\u7b26\uff0c\u76f4\u81f3\u5c06 \\r \u540e\u9762\u7684\u5185\u5bb9\u5b8c\u5168\u66ff\u6362\u5b8c\u6210\u3002 \\yyy \u516b\u8fdb\u5236\u6570\uff0cy \u4ee3\u8868 0~7 \u7684\u5b57\u7b26 \\xyy \u5341\u516d\u8fdb\u5236\u6570\uff0c\u4ee5 \\x \u5f00\u5934\uff0cy \u4ee3\u8868\u7684\u5b57\u7b26","title":"\u8f6c\u4e49\u5b57\u7b26"},{"location":"python/Foundation/ch01/#_3","text":"\u5b57\u7b26\u4e32\u662f\u53ef\u8fed\u4ee3\u7684\u3002\u7d22\u5f15\u503c\u4ece0\u5f00\u59cb\uff0c-1\u4ee3\u8868\u4ece\u672b\u5c3e\u5f00\u59cb\u3002\u7d22\u5f15\u533a\u95f4\u662f\u5de6\u95ed\u53f3\u5f00\u3002 a = 'string is \"special\"' print(a[2:4]) 'ri' print(a[-4:-1]) # ial","title":"\u53ef\u8fed\u4ee3\u6027"},{"location":"python/Foundation/ch01/#f-string","text":"f-string\u662fPython3.6\u63a8\u51fa\u7684\u65b0\u529f\u80fd\u3002\u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5bf9\u6bd4\u4f20\u7edf\u8868\u793a\u65b9\u6cd5\u548cf-string\u7684\u65b9\u6cd5\u3002 age = 32 name = 'Tom' fstring = f'My name is {name} and I am {age} years old.' print(fstring) # My name is Tom and I am 32 years old. \u5728f-string\u4e2d\u4f7f\u7528\u8868\u8fbe\u5f0f\u3002 height = 2 base = 3 fstring = f'The area of the triangle is {base*height/2}.' print(fstring) # The area of the triangle is 3.0. \u901a\u8fc7f-string\u5bf9\u5b57\u5178\u8fdb\u884c\u64cd\u4f5c\u3002 person1 = { 'name': 'Tom', 'age': 20, 'gender': 'male' } person2 = { 'name': 'Jerry', 'age': 20, 'gender': 'female' } # \u8bfb\u53d6\u5b57\u5178 fstring = f'{person1.get(\"name\")} is {person1.get(\"age\")} and is {person1.get(\"ender\")}' print(fstring) # Tom is 20 and is None # \u904d\u5386\u5b57\u5178 people = [person1, person2] for person in people: fstring = f'{person.get(\"name\")} is {person.get(\"age\")} and is {person.get(\"ender\")}' print(fstring) # Tom is 20 and is None # Jerry is 20 and is None \u5728f-string\u4e2d\u4f7f\u7528\u6761\u4ef6\u3002 person1 = { 'name': 'Tom', 'age': 20, 'gender': 'male' } person2 = { 'name': 'Jerry', 'age': 20, 'gender': 'female' } people = [person1, person2] for person in people: fstring = f'{\"She\" if person.get(\"gender\") == \"female\" else \"He\"} is watching TV.' print(fstring) # He is watching TV. # She is watching TV. \u4f7f\u7528f-string\u683c\u5f0f\u5316\u8f93\u51fa\u3002 \u5de6\u5bf9\u9f50\uff1a< \u53f3\u5bf9\u9f50\uff1a> \u5c45\u4e2d\u5bf9\u9f50\uff1a^ print(f'{\"apple\": >30}') print(f'{\"apple\": ^30}') print(f'{\"apple\": <30}') # apple # apple # apple \u4f7f\u7528f-string\u683c\u5f0f\u5316\u6570\u5b57\u3002 number = 0.9124325345 # \u767e\u5206\u6bd4 fstring = f'Percentage format for number with two decimal places: {number:.2%}' print(fstring) # Percentage format for number with two decimal places: 91.24% # \u4fdd\u7559\u5c0f\u6570\u70b9\u540e3\u4f4d fstring = f'Fixed point format for number with three decimal places: {number:.3f}' print(fstring) # Fixed point format for number with three decimal places: 0.912 # \u79d1\u5b66\u8ba1\u6570\u6cd5\u8868\u793a fstring = f'Exponent format for number: {number:e}' print(fstring) # Exponent format for number: 9.124325e-01 # \u5e26\u8d27\u5e01\u7b26\u53f7 number = 123456.78921 fstring = f'Currency format for number with two decimal places: ${number:.2f}' print(fstring) # Currency format for number with two decimal places: $123456.79 # \u5e26\u8d27\u5e01\u7b26\u53f7\u548c\u5343\u5206\u4f4d number = 123456.78921 fstring = f'Currency format for number with two decimal places and comma seperators: ${number:,.2f}' print(fstring) # Currency format for number with two decimal places and comma seperators: $123,456.79 # \u8f93\u51fa\u6570\u503c\u5e26\u6b63\u8d1f\u7b26\u5408 numbers = [1, -3, 5] for number in numbers: fstring = f'The number is {number:+}' print(fstring) # The number is +1 # The number is -3 # The number is +5 # Debug\u8c03\u8bd5 number = 2 print(f'{number = }') # number = 2","title":"f-string"},{"location":"python/Foundation/ch01/#13-list","text":"\u5217\u8868\u662f Python \u5185\u7f6e\u7684\u4e00\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u662f\u4e00\u79cd\u6709\u5e8f\u7684\u96c6\u5408\uff0c\u7528\u6765\u5b58\u50a8\u4e00\u8fde\u4e32\u5143\u7d20\u7684\u5bb9\u5668\u3002\u5217\u8868\u4e2d\u5143\u7d20\u7c7b\u578b\u53ef\u4ee5\u4e0d\u76f8\u540c\uff0c\u5b83\u652f\u6301\u6570\u5b57\u3001\u5b57\u7b26\u4e32\u7b49\u3002 \u5217\u8868\u7684\u6bcf\u4e2a\u503c\u90fd\u6709\u5bf9\u5e94\u7684\u7d22\u5f15\u503c\uff0c\u7d22\u5f15\u503c\u4ece0\u5f00\u59cb\u3002 \u5217\u8868\u5207\u7247\uff1a \u4f7f\u7528\u5207\u7247\u7b26\u53f7\u53ef\u4ee5\u5bf9\u5927\u591a\u6570\u5e8f\u5217\u7c7b\u578b\u9009\u53d6\u5176\u5b50\u96c6\u3002 \u8d77\u59cb\u4f4d\u7f6estart\u7684\u7d22\u5f15\u662f\u5305\u542b\u7684\uff0c\u800c\u7ed3\u675f\u4f4d\u7f6estop\u7684\u7d22\u5f15\u5e76\u4e0d\u5305\u542b\uff08\u5de6\u95ed\u53f3\u5f00\uff09\u3002 \u6b65\u8fdb\u503cstep\u53ef\u4ee5\u5728\u7b2c\u4e8c\u4e2a\u5192\u53f7\u540e\u9762\u4f7f\u7528\uff0c\u610f\u601d\u662f\u6bcf\u9694\u591a\u5c11\u4e2a\u6570\u53d6\u4e00\u4e2a\u503c \u3002 color = ['red', 'green', 'blue', 'yellow', 'white', 'black'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u7b2c1\uff0c2\u4f4d print(color[1: 3]) # ['green', 'blue'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u4ece\u7b2c1\u4f4d\u5230\u5012\u6570\u7b2c3\u4f4d print(color[1: -2]) # ['green', 'blue', 'yellow'] # \u4ece0\u5f00\u59cb\u7edf\u8ba1\uff0c\u8bfb\u53d6\u4ece\u5012\u6570\u7b2c4\u4f4d\u5230\u5012\u6570\u7b2c3\u4f4d print(color[-4: -2]) # ['blue', 'yellow'] # \u5982\u679c\u5199\u6210\u4e0b\u9762\u8fd9\u6837\uff0c\u5219\u65e0\u8f93\u51fa\u3002 print(color[-2: -4]) # [] print(color[::2]) # ['red', 'blue', 'white'] \u5bf9\u4e8e\u7c7b\u4f3c\u4e0b\u9762 invoice \u683c\u5f0f\u7684\u7eaf\u6587\u672c\u89e3\u6790\uff0c\u4f7f\u7528\u6709\u540d\u5b57\u7684\u5207\u7247\u6bd4\u7528\u4e0a\u9762\u6240\u5217\u4e3e\u7684\u786c\u7f16\u7801\u7684\u6570\u5b57\u533a\u95f4\u8981\u65b9\u4fbf\u5f97\u591a\u3002 invoice = \"\"\" 0 6 40 52 55 1909 Primoroni PiBrella $17.50 3 $52.50 1489 6mm Tactile Switch x20 $4.19 2 $9.90 1510 Panavise JR.-PV-201 $28.00 1 $28.00 1601 PiTFT Mini Kit 320x240 $34.95 1 $34.95 \"\"\" SKU = slice(0, 6) DESCRIPTION = slice(6, 40) UNIT_PRICE = slice(40, 52) QUANTITY = slice(52, 55) ITEM_TOTAL = slice(55, None) line_items = invoice.split('\\n')[2:] # \u6309\u4e0a\u9762invoice\u7684\u683c\u5f0f\uff0c\u7b2c0\u548c1\u884c\u820d\u5f03 for item in line_items: print(item[UNIT_PRICE], item[DESCRIPTION]) # $17.50 Primoroni PiBrella # $4.19 6mm Tactile Switch x20 # $28.00 Panavise JR.-PV-201 # $34.95 PiTFT Mini Kit 320x240 Python\u5185\u7f6e\u7684\u5e8f\u5217\u7c7b\u578b\u90fd\u662f\u4e00\u7ef4\u7684\uff0c\u56e0\u6b64\u5b83\u4eec\u53ea\u652f\u6301\u5355\u4e00\u7684\u7d22\u5f15\uff0c\u6210\u5bf9\u51fa\u73b0\u7684\u7d22\u5f15\u662f\u6ca1\u6709\u7528\u7684\u3002 \u7701\u7565\uff08ellipsis\uff09 \u7684\u6b63\u786e\u4e66\u5199\u65b9\u6cd5\u662f\u4e09\u4e2a\u82f1\u8bed\u53e5\u53f7\uff08...\uff09\uff0c\u800c\u4e0d\u662fUnicdoe\u7801\u4f4dU+2026\u8868\u793a\u7684\u534a\u4e2a\u7701\u7565\u53f7\uff08...\uff09\u3002 \u7701\u7565\u5728Python\u89e3\u6790\u5668\u773c\u91cc\u662f\u4e00\u4e2a\u7b26\u53f7\uff0c\u800c\u5b9e\u9645\u4e0a\u5b83\u662f Ellipsis \u5bf9\u8c61\u7684\u522b\u540d\uff0c\u800c Ellipsis \u5bf9\u8c61\u53c8\u662f ellipsis \u7c7b\u7684\u5355\u4e00\u5b9e\u4f8b\u3002 \u5b83\u53ef\u4ee5\u5f53\u4f5c\u5207\u7247\u89c4\u8303\u7684\u4e00\u90e8\u5206\uff0c\u4e5f\u53ef\u4ee5\u7528\u5728\u51fd\u6570\u7684\u53c2\u6570\u6e05\u5355\u4e2d\uff0c\u6bd4\u5982 f(a, ..., z) \uff0c\u6216 a[i:...] \u3002 \u5728NumPy\u4e2d\uff0c ... \u7528\u4f5c\u591a\u7ef4\u6570\u7ec4\u5207\u7247\u7684\u5feb\u6377\u65b9\u5f0f\u3002\u5982\u679c `x\u662f\u56db\u7ef4\u6570\u7ec4\uff0c\u90a3\u4e48 x[i, ...] \u5c31\u662f x[i, :, :, :]`\u7684\u7f29\u5199\u3002\u5982\u679c\u60f3\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u89c1\u201cTentative NumPy Tutorial\u201d\u3002 \u5217\u8868\u5e38\u7528\u65b9\u6cd5\uff1a \u65b9\u6cd5\u540d\u79f0 \u4f5c\u7528 a.index() \u8fd4\u56dea\u4e2d\u9996\u4e2a\u5339\u914d\u9879\u7684\u4f4d\u7f6e a.pop() \u5220\u9664\u6307\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20 a.insert() \u5411\u6307\u5b9a\u4f4d\u7f6e\u63d2\u5165\u5143\u7d20 a.reverse() \u53cd\u5411\u6392\u5e8f a.append() \u5411\u672b\u5c3e\u6dfb\u52a0\u5143\u7d20 a.sort() \u5bf9\u5217\u8868\u8fdb\u884c\u6392\u5e8f a.remove() \u5220\u9664\u9996\u4e2a\u5339\u914d\u9879\u7684\u5143\u7d20 a.extend() \u5c06\u4e00\u4e2a\u5217\u8868\u6269\u5c55\u81f3\u53e6\u4e00\u4e2a\u5217\u8868 a.count() \u7edf\u8ba1\u67d0\u4e2a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570 \u521b\u5efa\u5217\u8868list a = [1, 2, 3, 4, 5] print(a) # [1, 2, 3, 4, 5] b = list('12345') print(b) # ['1', '2', '3', '4', '5'] c = list(12345) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'int' object is not iterable \u5217\u8868\u5207\u7247\uff08\u4ece0\u5f00\u59cb\uff0c\u5de6\u95ed\u53f3\u5f00\uff09\uff1a print(a[2:3]) # [3] print(a[:3]) # [1, 2, 3] print(a[::-1]) # \u5012\u5e8f # [5, 4, 3, 2, 1] print(a[::]) # [1, 2, 3, 4, 5] print(a[::1]) [1, 2, 3, 4, 5] \u5217\u8868\u662f\u53ef\u4fee\u6539\u7684\uff1a print(a[1]) # 2 a[1] = 'one' print(a) @ [1, 'one', 3, 4, 5] \u5217\u8868\u8ffd\u52a0\u548c\u63d2\u5165\u3002insert\u4e0eappend\u76f8\u6bd4\uff0c\u8ba1\u7b97\u4ee3\u4ef7\u66f4\u9ad8\u3002\u56e0\u4e3a\u5b50\u5e8f\u5217\u5143\u7d20\u9700\u8981\u5728\u5185\u90e8\u79fb\u52a8\u4e3a\u65b0\u5143\u7d20\u63d0\u4f9b\u7a7a\u95f4\u3002 a.append(6) # \u6ce8\u610f\uff0c\u76f4\u63a5\u4fee\u6539\u539f\u5217\u8868\uff0c\u4e0d\u662f\u521b\u5efa\u526f\u672c\u3002 print(a) # [1, 'one', 3, 4, 5, 6] a.extend([7, 8, 9]) print(a) # [1, 'one', 3, 4, 5, 6, 7, 8, 9] a.insert(0, 'Italy') print(a) # ['Italy', 1, 3, 5, 6, 7, 8] \u5217\u8868\u5220\u9664\u5143\u7d20\uff0c\u9ed8\u8ba4\u5220\u9664\u6700\u540e\u4e00\u4e2a\u3002insert\u7684\u53cd\u64cd\u4f5c\u662fpop\u3002 a.pop() # 9 print(a) # [1, 'one', 3, 4, 5, 6, 7, 8] a.pop(3) # 4 print(a) # [1, 'one', 3, 5, 6, 7, 8] \u5220\u9664\u5217\u8868\u4e2d\u67d0\u4e2a\u5143\u7d20\u3002 print(a[1]) # one del a[1] print(a) [1, 3, 5, 6, 7, 8] \u5220\u9664\u5217\u8868\u4e2d\u67d0\u4e2a\u5143\u7d20\u3002remove\u65b9\u6cd5\u4f1a\u5b9a\u4f4d\u7b2c\u4e00\u4e2a\u7b26\u5408\u8981\u6c42\u7684\u503c\u5e76\u79fb\u9664 a.remove('Italy') print(a) # [1, 3, 5, 6, 7, 8] \u7edf\u8ba1\u67d0\u4e2a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570\u3002 print(a.count(1)) # 1 \u8fd4\u56de\u5217\u8868\u4e2d\u5339\u914d\u9879\u7684\u7d22\u5f15\u4f4d\u7f6e\u3002\u5339\u914d\u4e0d\u5230\u629b\u51fa\u5f02\u5e38\u3002 print(a.index(2)) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # ValueError: 2 is not in list print(a.index(3)) # 1 \u5224\u65ad\u5143\u7d20\u662f\u5426\u5b58\u5728\u4e8e\u5217\u8868\u3002 print(3 in a) # True print('3' in a) # False \u53cd\u5411\u8f93\u51fa\u5217\u8868\u3002 a.reverse() print(a) # [8, 7, 6, 5, 3, 1] \u53d6\u5217\u8868\u4e2d\u6700\u5927\u503c\u3001\u6700\u5c0f\u503c\u3002 print(min(a)) # 1 print(max(a)) # 78 \u8ba1\u7b97\u5217\u8868\u957f\u5ea6\u3002 print(len(a)) # 6 \u5217\u8868\u6269\u5c55\uff1a a = [1, 2, 3] b = [4, 5, 6] print(a + b) # [1, 2, 3, 4, 5, 6] a.extend(b) # a\u5217\u8868\u88ab\u4fee\u6539 print(a) # [1, 2, 3, 4, 5, 6] print(b) # [4, 5, 6] \u4f7f\u7528extend\u6dfb\u52a0\u5143\u7d20\u6bd4\u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fde\u63a5\u6548\u7387\u66f4\u9ad8\u3002\u56e0\u4e3a\u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fde\u63a5\u8fc7\u7a0b\u4e2d\u521b\u5efa\u4e86\u65b0\u5217\u8868\uff0c\u5e76\u4e14\u8fd8\u8981\u590d\u5236\u5bf9\u8c61\u3002 a_list = [4, None, 'foo'] b_list = [7, 8, (2, 3)] print(a_list + b_list) # [4, None, 'foo', 7, 8, (2, 3)] \u4f7f\u7528+\u53f7\u8fde\u63a5 a_list.extend(b_list) print(a_list) # [4, None, 'foo', 7, 8, (2, 3)] Python\u7684\u4e00\u4e2a\u60ef\u4f8b\uff1a\u5982\u679c\u4e00\u4e2a\u51fd\u6570\u6216\u8005\u65b9\u6cd5\u5bf9\u5bf9\u8c61\u8fdb\u884c\u7684\u662f\u5c31\u5730\u6539\u52a8\uff0c\u90a3\u5b83\u5c31\u5e94\u8be5\u8fd4\u56deNone\uff0c\u597d\u8ba9\u8c03\u7528\u8005\u77e5\u9053\u4f20\u5165\u7684\u53c2\u6570\u53d1\u751f\u4e86\u53d8\u52a8\uff0c\u800c\u4e14\u5e76\u672a\u4ea7\u751f\u65b0\u7684\u5bf9\u8c61\u3002 \u4e0b\u9762\u662f\u6392\u5e8f\u7684\u4f8b\u5b50 list.sort() \u548c sorted(list) \u7684\u533a\u522b\u3002 list1 = ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] print(list1) # ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] # \u4e0b\u9762\u7684\u64cd\u4f5c\u4e0d\u6539\u53d8\u539f\u5217\u8868 print(sorted(list1)) # ['1', '3', '5', '8', '9', 'Four', 'apple', 'one', 'two'] print(sorted(list1, reverse=True)) # ['two', 'one', 'apple', 'Four', '9', '8', '5', '3', '1'] print(sorted(list1, key=len)) # ['1', '3', '5', '8', '9', 'one', 'two', 'Four', 'apple'] print(list1) # ['1', 'one', '3', 'Four', '5', 'two', 'apple', '8', '9'] # \u4e0b\u9762\u7684\u64cd\u4f5c\u76f4\u63a5\u4fee\u6539\u539f\u5217\u8868\uff0c\u8fd4\u56de\u503c\u662fNone print(list1.sort()) # None print(list1) # ['1', '3', '5', '8', '9', 'Four', 'apple', 'one', 'two'] \u5217\u8868\u590d\u5236\uff0c + \u548c * \u7684\u64cd\u4f5c\u90fd\u662f\u4e0d\u4fee\u6539\u539f\u6709\u7684\u64cd\u4f5c\u5bf9\u8c61\uff0c\u800c\u662f\u6784\u5efa\u4e00\u4e2a\u5168\u65b0\u7684\u5217\u8868\u3002 c = list('Python') print(a + c) # [1, 2, 3, 4, 5, 6, 'P', 'y', 't', 'h', 'o', 'n'] print(a * 3) # [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6] \u5982\u679c\u5728 a * n \u8fd9\u4e2a\u8bed\u53e5\u4e2d\uff0c\u5e8f\u5217 a \u91cc\u7684\u5143\u7d20\u662f\u5bf9\u5176\u4ed6\u53ef\u53d8\u5bf9\u8c61\u7684\u5f15\u7528\u7684\u8bdd\uff0c\u5c31\u9700\u8981\u683c\u5916\u6ce8\u610f\u4e86\uff0c\u56e0\u4e3a\u8fd9\u4e2a\u5f0f\u5b50\u7684\u7ed3\u679c\u53ef\u80fd\u4f1a\u51fa\u4e4e\u610f\u6599\u3002 \u6bd4\u5982\uff0c\u6211\u4eec\u60f3\u7528 my_list=[[]] * 3 \u6765\u521d\u59cb\u5316\u4e00\u4e2a\u7531\u5217\u8868\u7ec4\u6210\u7684\u5217\u8868\uff0c\u4f46\u662f\u6211\u4eec\u5b9e\u9645\u5f97\u5230\u7684\u5217\u8868\u91cc\u5305\u542b\u76843\u4e2a\u5143\u7d20\u5176\u5b9e\u662f3\u4e2a\u5f15\u7528\uff0c\u800c\u4e14\u8fd93\u4e2a\u5f15\u7528\u6307\u5411\u7684\u90fd\u662f \u540c\u4e00\u4e2a \u5217\u8868\u3002\u770b\u4e0b\u9762\u4f8b\u5b50\u3002 # \u505a\u6cd51 board = [['_'] * 3 for i in range(3)] print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[1][2] = 'X' print(board) # [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] # \u505a\u6cd52 board = [['_'] * 3] * 3 print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[1][2] = 'X' print(board) # [['_', '_', 'X'], ['_', '_', 'X'], ['_', '_', 'X']] \u4e0b\u9762\u4e5f\u662f\u540c\u6837\u7684\u95ee\u9898\u3002 # \u65b9\u6cd51 row = ['_'] * 3 board = [] for i in range(3): board.append(row) print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[2][0] = 'X' print(board) # [['X', '_', '_'], ['X', '_', '_'], ['X', '_', '_']] # \u65b9\u6cd52 row = [] board = [] for i in range(3): row = ['_'] * 3 board.append(row) print(board) # [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] board[2][0] = 'X' print(board) # [['_', '_', '_'], ['_', '_', '_'], ['X', '_', '_']] \u53cc\u7aef\u961f\u5217collections.deque \uff0c\u53ef\u4ee5\u6ee1\u8db3\u5217\u8868\u5934\u5c3e\u90e8\u90fd\u589e\u52a0\u7684\u8981\u6c42\u3002 deque() \u4e2d maxlen \u662f\u4e00\u4e2a\u53ef\u9009\u53c2\u6570\uff0c\u4ee3\u8868\u8fd9\u4e2a\u961f\u5217\u53ef\u4ee5\u5bb9\u7eb3\u7684\u5143\u7d20\u7684\u6570\u91cf\uff0c\u800c\u4e14\u4e00\u65e6\u8bbe\u5b9a\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5c31\u4e0d\u80fd\u4fee\u6539\u4e86\u3002 \u5f53\u8bd5\u56fe\u5bf9\u4e00\u4e2a\u5df2\u6ee1 len(d)==d.maxlen \u7684\u961f\u5217\u505a\u5934\u90e8\u6dfb\u52a0\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u5b83\u5c3e\u90e8\u7684\u5143\u7d20\u4f1a\u88ab\u5220\u9664\u6389\u3002 extendleft(iter) \u65b9\u6cd5\u4f1a\u628a\u8fed\u4ee3\u5668\u91cc\u7684\u5143\u7d20\u9010\u4e2a\u6dfb\u52a0\u5230\u53cc\u5411\u961f\u5217\u7684\u5de6\u8fb9\uff0c\u56e0\u6b64\u8fed\u4ee3\u5668\u91cc\u7684\u5143\u7d20\u4f1a\u9006\u5e8f\u51fa\u73b0\u5728\u961f\u5217\u91cc\u3002 \u961f\u5217\u7684\u65cb\u8f6c\u64cd\u4f5c rotate \u63a5\u53d7\u4e00\u4e2a\u53c2\u6570n\uff0c\u5f53n > 0\u65f6\uff0c\u961f\u5217\u7684\u6700\u53f3\u8fb9\u7684n\u4e2a\u5143\u7d20\u4f1a\u88ab\u79fb\u52a8\u5230\u961f\u5217\u7684\u5de6\u8fb9\u3002\u5f53n < 0\u65f6\uff0c\u6700\u5de6\u8fb9\u7684n\u4e2a\u5143\u7d20\u4f1a\u88ab\u79fb\u52a8\u5230\u53f3\u8fb9\u3002 from collections import deque d = deque([1, 2, 3]) print(d) # deque([1, 2, 3]) # \u6ce8\u610f\u63d2\u5165\u987a\u5e8f d.extendleft(['a', 'b', 'c']) print(d) # deque(['c', 'b', 'a', 1, 2, 3]) print(len(d)) # 6 print(d[-2]) # 2 # \u7edf\u8ba1\u5b57\u7b26a\u51fa\u73b0\u7684\u6b21\u6570 print(d.count('a')) # 1 # \u8fd4\u56de\u5b57\u7b26a\u7684\u7d22\u5f15\u503c print(d.index('a')) # 2 # \u7b2c0\u4f4d\u63d2\u5165\u6570\u5b571\uff0c\u5176\u4f59\u987a\u79fb d.insert(0, 1) print(d) # deque([1, 'c', 'b', 'a', 1, 2, 3]) # \u628a\u53f3\u8fb92\u4e2a\u5143\u7d20\u653e\u5230\u5de6\u8fb9\uff0c\u6ce8\u610f\u987a\u5e8f\uff0c\u548cextendleft\u4e0d\u4e00\u6837 d.rotate(2) print(d) # deque([2, 3, 1, 'c', 'b', 'a', 1]) d.rotate(-2) print(d) # deque([1, 'c', 'b', 'a', 1, 2, 3]) \u4e0b\u8868\u603b\u7ed3\u4e86\u5217\u8868\u548c\u53cc\u5411\u961f\u5217\u7684\u65b9\u6cd5\uff08\u4e0d\u5305\u62ec\u7531\u5bf9\u8c61\u5b9e\u73b0\u7684\u65b9\u6cd5\uff09\u3002 \u5217\u8868\u6392\u5e8f\u3002\u6392\u5e8f\u5bf9\u5217\u8868\u5143\u7d20\u7684\u6570\u636e\u7c7b\u578b\u662f\u6709\u8981\u6c42\u7684\u3002 a_list = [4, None, 'foo', 7, 8, (2, 3)] a_list.sort() # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: '<' not supported between instances of 'NoneType' and 'int' b_list = [7, 8, (2, 3)] b_list.sort() # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: '<' not supported between instances of 'tuple' and 'int' a_list = [7, 2, 5, 1, 3] a_list.sort() # \u6309\u6570\u503c\u5927\u5c0f\u6392\u5e8f print(a_list) # [1, 2, 3, 5, 7] b_list = ['saw', 'small', 'He', 'foxes', 'six'] b_list.sort(key=len) # \u901a\u8fc7\u5b57\u7b26\u4e32\u7684\u957f\u5ea6\u8fdb\u884c\u6392\u5e8f print(b_list) # ['He', 'saw', 'six', 'small', 'foxes'] \u5217\u8868\u4e8c\u5206\u641c\u7d22\u548c\u5df2\u6392\u5e8f\u5217\u8868\u7684\u7ef4\u62a4 bisect \u8fd4\u56de\u8981\u63d2\u5165\u5143\u7d20\u5728\u5217\u8868\u4e2d\u7684\u4e0b\u6807\u3002\u5047\u5b9a\u5217\u8868\u662f\u6709\u5e8f\u7684\u3002 bisect_left \u4e0e bisect \u7c7b\u4f3c\uff0c\u53ea\u4e0d\u8fc7\u5176\u9ed8\u8ba4\u5c06\u5143\u7d20\u63d2\u5230\u5de6\u8fb9\uff0c\u6240\u4ee5\u8fd4\u56de\u7684\u662f\u63d2\u5165\u5230\u5de6\u8fb9\u7684\u4e0b\u6807 bisect_right\u4e0e bisect_left \u76f8\u53cd\u3002 \u4ee5\u4e0a\u65b9\u6cd5\u82e5\u5217\u8868\u65e0\u5e8f\uff0c\u90a3\u4e48\u4f1a\u8fd4\u56de\u63d2\u5165\u5230\u5217\u8868\u6700\u540e\u4e00\u4e2a\u5408\u9002\u7684\u4f4d\u7f6e\u3002 insort \u4f1a\u5728\u5217\u8868\u4e2d\u63d2\u5165\u5143\u7d20\u5230\u6b63\u786e\u4f4d\u7f6e\uff0c\u5047\u5b9a\u5217\u8868\u6709\u5e8f\u3002\u5982\u679c\u5217\u8868\u65e0\u5e8f\uff0c\u90a3\u4e48\u4f1a\u8fd4\u56de\u7a7a\u3002\u9ed8\u8ba4\u63d2\u5165\u5230\u53f3\u8fb9\u3002 insort_left \u548cinsort_right \u7c7b\u4f3c\u3002 import bisect c = [1, 2, 3, 4, 7] print(bisect.bisect(c, 2)) # 2 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a2,\u5e76\u628a\u65b0\u76842\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 2) # [1, 2, 2, 3, 4, 7] print(bisect.bisect(c, 5)) # 5 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a4,\u5e76\u628a\u65b0\u76845\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 5) print(bisect.bisect(c, 6)) # 6 bisect\u4f1a\u627e\u5230\u7b2c\u4e00\u4e2a5,\u5e76\u628a\u65b0\u76846\u63d2\u5165\u5b83\u540e\u9762 bisect.insort(c, 6) print(c) # [1, 2, 2, 3, 4, 5, 6, 7] bisect\u53ef\u4ee5\u7528\u6765\u5efa\u7acb\u4e00\u4e2a\u7528\u6570\u5b57\u4f5c\u4e3a\u7d22\u5f15\u7684\u67e5\u8be2\u8868\u683c\uff0c\u5982\u4e0b\u4f8b\uff0c\u628a\u5206\u6570\u548c\u6210\u7ee9\u5bf9\u5e94\u8d77\u6765\uff0c\u6839\u636e\u4e00\u4e2a\u5206\u6570\uff0c\u627e\u5230\u5b83\u6240\u5bf9\u5e94\u7684\u6210\u7ee9\u3002 import bisect def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): i = bisect.bisect(breakpoints, score) return grades[i] [grade(score) for score in [15, 26, 31, 62, 79, 85]] # ['F', 'F', 'F', 'D', 'C', 'B'] \u7528bisect.insort\u63d2\u5165\u65b0\u5143\u7d20\uff0c\u5e76\u80fd\u4fdd\u6301seq\u7684\u5347\u5e8f\u987a\u5e8f\u3002 import bisect import random size = 7 random.seed(1729) my_list = [] for i in range(size): new_item = random.randrange(size*2) bisect.insort(my_list, new_item) print(f'{new_item:2d} :--> {my_list}') # 10 :--> [10] # 0 :--> [0, 10] # 6 :--> [0, 6, 10] # 8 :--> [0, 6, 8, 10] # 7 :--> [0, 6, 7, 8, 10] # 2 :--> [0, 2, 6, 7, 8, 10] # 10 :--> [0, 2, 6, 7, 8, 10, 10]","title":"1.3 \u5217\u8868\uff08list\uff09"},{"location":"python/Foundation/ch01/#14-dictionary","text":"\u5b57\u5178(dict)\u662f\u4f7f\u7528\u952e-\u503c\uff08key-value\uff09\u5b58\u50a8\uff0c\u952e\u662f\u4e0d\u53ef\u53d8\u5bf9\u8c61\uff0c\u4e14\u4e0d\u5141\u8bb8\u91cd\u590d\u3002 dict\uff08\u5b57\u5178\uff09\u66f4\u4e3a\u5e38\u7528\u7684\u540d\u5b57\u662f\u54c8\u5e0c\u8868\u6216\u8005\u662f\u5173\u8054\u6570\u7ec4\u3002 \u5b57\u5178\u662f\u62e5\u6709\u7075\u6d3b\u5c3a\u5bf8\u7684\u952e\u503c\u5bf9\u96c6\u5408\uff0c\u4e0d\u662f\u901a\u8fc7\u4f4d\u7f6e\u8fdb\u884c\u7d22\u5f15\uff0c\u5176\u4e2d\u952e\u548c\u503c\u90fd\u662fPython\u5bf9\u8c61\u3002\u7528\u5927\u62ec\u53f7{}\u662f\u521b\u5efa\u5b57\u5178\u7684\u4e00\u79cd\u65b9\u5f0f\uff0c\u5728\u5b57\u5178\u4e2d\u7528\u9017\u53f7\u5c06\u952e\u503c\u5bf9\u5206\u9694\u3002 \u521b\u5efa\u5b57\u5178\u7684\u51e0\u79cd\u65b9\u6cd5\uff1a a = dict(one=1, two=2, three=3) b = {'one': 1, 'two': 2, 'three': 3} c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) d = dict([('two', 2), ('three', 3), ('one', 1)]) e = dict({'three': 3, 'one': 1, 'two': 2}) print(a == b == c == d == e) # True \u5b57\u5178\u5e38\u7528\u65b9\u6cd5 \u65b9\u6cd5\u540d\u79f0 \u4f5c\u7528 a.items() \u8fd4\u56dea\u4e2d\u6240\u6709\u952e\u503c\u5bf9 a.values() \u8fd4\u56dea\u4e2d\u6240\u6709\u503c a.keys() \u8fd4\u56dea\u4e2d\u6240\u6709\u952e a.get() \u901a\u8fc7\u952e\u6765\u67e5\u503c\uff0c\u8fd4\u56de\u5bf9\u5e94\u7684\u503c a.clear() \u6e05\u7a7a\u5b57\u5178a\u7684\u503c a.setdefault \u901a\u8fc7\u952e\u503c\u6765\u67e5\u627e\u503c\uff0c\u627e\u4e0d\u5230\u5219\u63d2\u5165 a.update() \u952e\u548c\u503c\u66f4\u65b0\u5230\u65b0\u7684\u5b57\u5178 a.pop() \u5220\u9664\u6307\u5b9a\u4f4d\u7f6e\u7684\u5143\u7d20 \u751f\u6210\u4e00\u4e2a\u5b57\u5178 dict_a = {'name': 'Ming', 'id': 1001, 'age': 35} print(type(dict_a)) # <class 'dict'> dict_b = dict(city='Shanghai', strict='Xuhui', zip='200000') print(type(dict_b)) # <class 'dict'> \u901a\u8fc7\u952e\u67e5\u8be2\u503c\uff0c\u67e5\u8be2\u4e0d\u5230\u629b\u51fa\u5f02\u5e38 print(dict_a['name']) # Ming print(dict_a['Name']) # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'Name' \u63d2\u5165\u65b0\u7684\u952e\u503c\u5bf9 dict_a['city'] = 'Chengdu' print(dict_a) # {'name': 'Ming', 'id': 1001, 'city': 'Chengdu'} \u5220\u9664\u67d0\u4e2a\u952e\u503c\u5bf9\u3002pop\u65b9\u6cd5\u4f1a\u5728\u5220\u9664\u7684\u540c\u65f6\u8fd4\u56de\u88ab\u5220\u7684\u503c\uff0c\u5e76\u5220\u9664\u952e\u3002 dict_a.pop('city') # Chengdu print(dict_a) # {'name': 'Ming', 'id': 1001} \u53e6\u4e00\u79cd\u65b9\u5f0f\u5220\u9664\u67d0\u4e2a\u952e\u503c\u5bf9 del dict_a['age'] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'age' del dict_a['id'] print(dict_a) # {'name': 'Ming'} \u5224\u65ad\u952e\u662f\u5426\u5b58\u5728 dict_a[23] = 'Hello World' print(dict_a) # {'name': 'Ming', 23: 'Hello World'} print(23 in dict_a) # True print(35 in dict_a) # False \u901a\u8fc7\u952e\u67e5\u8be2\u503c\u7684\u53e6\u4e00\u79cd\u65b9\u5f0f\uff0c\u67e5\u8be2\u4e0d\u5230\u4e0d\u629b\u5f02\u5e38 dict_a.get('hai') dict_a.get('hai', 1) # 1 dict_a.get('name', 1) # Ming dict_a['hai'] # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # KeyError: 'hai' \u901a\u8fc7\u952e\u67e5\u8be2\u503c\u7684\u53e6\u4e00\u79cd\u65b9\u5f0f\uff0c\u67e5\u8be2\u4e0d\u5230\u5219\u6dfb\u52a0 dict_a.setdefault('name') # Ming dict_a.setdefault('hai', 1) # 1 print(dict_a) # {'name': 'Ming', 23: 'Hello World', 'hai': 1} dict_a.setdefault('go') print(dict_a) # {'name': 'Ming', 23: 'Hello World', 'hai': 1, 'go': None} \u8bfb\u53d6\u5b57\u5178\u6240\u6709\u952e\u503c\u5bf9\uff0c\u8fd4\u56de\u7684\u662f\u5217\u8868\u5f62\u5f0f print(dict_a.items()) # dict_items([('name', 'Ming'), (23, 'Hello World'), ('hai', 1), ('go', None)]) \u8bfb\u53d6\u5b57\u5178\u7684\u952e print(dict_a.keys()) # dict_keys(['name', 23, 'hai', 'go']) \u8bfb\u53d6\u5b57\u5178\u7684\u503c print(dict_a.values()) # dict_values(['Ming', 'Hello World', 1, None]) \u5c06\u5b57\u5178\u503c\u8f6c\u5316\u6210\u5217\u8868 print(list(dict_a.values())) # ['Ming', 'Hello World', 1, None] for key in dict_a.keys(): print(dict_a[key]) # Ming # Hello World # 1 # None \u6e05\u7a7a\u5b57\u5178 dict_a.clear() print(dict_a) # {} print(len(dict_a)) # 0 \u5bf9\u4e8e\u4efb\u4f55\u539f\u5b57\u5178\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684\u952e\uff0c\u5982\u679c\u4f20\u7ed9update\u65b9\u6cd5\u7684\u6570\u636e\u4e5f\u542b\u6709\u76f8\u540c\u7684\u952e\uff0c\u5219\u5b83\u7684\u503c\u5c06\u4f1a\u88ab\u8986\u76d6\u3002 dict_a = {'name': 'Ming', 'id': 1001, 'age': 35} dict_b = dict(city='Shanghai', id=2001, zip='200000') dict_a.update(dict_b) print(dict_a) # {'name': 'Ming', 'id': 2001, 'age': 35, 'city': 'Shanghai', 'zip': '200000'} \u4ece\u5217\u8868\u751f\u6210\u5b57\u5178 \u5b57\u5178\u672c\u8d28\u4e0a\u662f2-\u5143\u7ec4\uff08\u542b\u67092\u4e2a\u5143\u7d20\u7684\u5143\u7ec4\uff09\u7684\u96c6\u5408\uff0c\u5b57\u5178\u662f\u53ef\u4ee5\u63a5\u53d7\u4e00\u4e2a2-\u5143\u7ec4\u7684\u5217\u8868\u4f5c\u4e3a\u53c2\u6570\u7684\u3002 # \u65b9\u6cd51 mapping = {} key_list = list(range(5)) value_list = list(reversed(range(5))) for key, value in zip(key_list, value_list): mapping[key] = value print(mapping) # {0: 4, 1: 3, 2: 2, 3: 1, 4: 0} # \u65b9\u6cd52\u3002 mapping = {} key_list = list(range(5)) value_list = list(reversed(range(5))) mapping = dict(zip(key_list, value_list)) print(mapping) # {0: 4, 1: 3, 2: 2, 3: 1, 4: 0} \u6709\u6548\u7684\u5b57\u5178\u952e\u7c7b\u578b \u5c3d\u7ba1\u5b57\u5178\u7684\u503c\u53ef\u4ee5\u662f\u4efb\u4f55Python\u5bf9\u8c61\uff0c\u4f46\u952e\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u7684\u5bf9\u8c61\uff0c\u6bd4\u5982\u6807\u91cf\u7c7b\u578b\uff08\u6574\u6570\u3001\u6d6e\u70b9\u6570\u3001\u5b57\u7b26\u4e32\uff09\u6216\u5143\u7ec4\uff08\u4e14\u5143\u7ec4\u5185\u5bf9\u8c61\u4e5f\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u5bf9\u8c61\uff09\u3002 \u901a\u8fc7hash\u51fd\u6570\u53ef\u4ee5\u68c0\u67e5\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u53ef\u4ee5\u54c8\u5e0c\u5316\uff08\u5373\u662f\u5426\u53ef\u4ee5\u7528\u4f5c\u5b57\u5178\u7684\u952e\uff09\uff0c\u672f\u8bed\u53eb\u4f5c\u54c8\u5e0c\u5316\u3002 print(hash('string')) # -4368784820203065343 print(hash((1, 2, (2, 3)))) # -9209053662355515447 print(hash((1, 2, [2, 3]))) # TypeError: unhashable type: 'list' print(hash((1, 2, tuple([2, 3])))) # -9209053662355515447 \u4e3a\u4e86\u5c06\u5217\u8868\u4f5c\u4e3a\u952e\uff0c\u4e00\u79cd\u65b9\u5f0f\u5c31\u662f\u5c06\u5176\u8f6c\u6362\u4e3a\u5143\u7ec4 \u5b57\u5178\u9ed8\u8ba4\u503c \u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5b9e\u73b0\u4e86\u5c06\u4e00\u4e2a\u5355\u8bcd\u7ec4\u6210\u7684\u5217\u8868\uff0c\u8f6c\u6362\u6210\u5355\u8bcd\u9996\u5b57\u6bcd\u548c\u5355\u8bcd\u4e3a\u952e\u503c\u5bf9\u7684\u5b57\u5178\u3002\u5148\u7528\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\uff0c\u518d\u7528\u5b57\u5178\u7684setdefault\u65b9\u6cd5\u8fdb\u884c\u6539\u5199\u3002 \u5148\u770b\u4f20\u7edf\u65b9\u6cd5\u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u628a\u5217\u8868words\u7684\u6bcf\u4e2a\u5143\u7d20\u5217\u8868\u5316\uff0c\u5e76\u53d6\u9996\u5b57\u6bcd\u3002\u8f93\u51fa\u7684\u662fa, b, b, a, b\u8fd95\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcd if letter not in by_letter: # \u751f\u6210\u7b2c\u4e00\u4e2a\u952e\u503c\u5bf9 print(letter) by_letter[letter] = [word] # \u5bf9\u6bd4[word]\u548cword[]\u7684\u7528\u6cd5 print(by_letter) # a # {'a': ['apple']} # b # {'a': ['apple'], 'b': ['bat']} else: # append\u5176\u4ed6\u952e\u503c\u5bf9 print(letter) by_letter[letter].append(word) print(by_letter) # b # {'a': ['apple'], 'b': ['bat', 'bar']} # a # {'a': ['apple', 'atom'], 'b': ['bat', 'bar']} # b # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} print(by_letter) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u7528\u5b57\u5178\u7684setdefault\u65b9\u6cd5\uff0c\u4e0a\u8ff0\u7684for\u5faa\u73af\u8bed\u53e5\u53ef\u4ee5\u88ab\u5199\u4e3a\u5982\u4e0b\u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u7684\u8f93\u51fa\u4f9d\u7136\u662f5\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcda, b, b, a, b by_letter.setdefault(letter, []).append(word) # \u5982\u679cletter\u4e0d\u5728[]\u5219\u901a\u8fc7append\u6dfb\u52a0word print(by_letter) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u5982\u679c\u6539\u5199\u4e3a by_letter.setdefault(letter, ['a']).append(word) \uff0c\u5219\u8f93\u51fa by_letter \u662f {'a': ['a', 'apple', 'atom'], 'b': ['a', 'bat', 'bar', 'book']} \u3002 words = ['apple', 'bat', 'bar', 'atom', 'book'] by_letter = {} for word in words: letter = word[0] # word[0]\u7684\u8f93\u51fa\u4f9d\u7136\u662f5\u4e2a\u5217\u8868\u5143\u7d20\u7684\u9996\u5b57\u6bcda, b, b, a, b by_letter.setdefault(letter, ['a']).append(word) print(by_letter) # {'a': ['a', 'apple', 'atom'], 'b': ['a', 'bat', 'bar', 'book']} \u4f53\u4f1asetdefault()\u7684\u6ce8\u91ca\u201cInsert key with a value of default if key is not in the dictionary. Return the value for key if key is in the dictionary, else default.\u201d \u901a\u8fc7defaultdict\u7c7b\u4f7f\u5f97\u4e0a\u8ff0\u76ee\u7684\u5b9e\u73b0\u66f4\u4e3a\u7b80\u5355\u3002 from collections import defaultdict by_letter = defaultdict(list) # list\u662f\u5185\u7f6e\u7684\u53ef\u53d8\u5e8f\u5217(Built-in mutable sequence) print(dict(by_letter)) # {} for word in words: by_letter[word[0]].append(word) print(by_letter) # defaultdict(<class 'list'>, {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}) print(dict(by_letter)) # {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']} \u4e0b\u8868\u5c55\u793a\u4e86 dict \u3001 defaultdict \u548c OrderedDict \u7684\u5e38\u89c1\u65b9\u6cd5\uff0c\u540e\u9762\u4e24\u4e2a\u6570\u636e\u7c7b\u578b\u662f dict \u7684\u53d8\u79cd\uff0c\u4f4d\u4e8e collections \u6a21\u5757\u5185\u3002 * default_factory \u5e76\u4e0d\u662f\u4e00\u4e2a\u65b9\u6cd5\uff0c\u800c\u662f\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61\uff08callable\uff09\uff0c\u5b83\u7684\u503c\u5728 defaultdict \u521d\u59cb\u5316\u7684\u65f6\u5019\u7531\u7528\u6237\u8bbe\u5b9a\u3002 # OrderedDict.popitem() \u4f1a\u79fb\u9664\u5b57\u5178\u91cc\u6700\u5148\u63d2\u5165\u7684\u5143\u7d20\uff08\u5148\u8fdb\u5148\u51fa\uff09\uff1b\u540c\u65f6\u8fd9\u4e2a\u65b9\u6cd5\u8fd8\u6709\u4e00\u4e2a\u53ef\u9009\u7684last\u53c2\u6570\uff0c\u82e5\u4e3a\u771f\uff0c\u5219\u4f1a\u79fb\u9664\u6700\u540e\u63d2\u5165\u7684\u5143\u7d20\uff08\u540e\u8fdb\u5148\u51fa\uff09\u3002 \u4e0a\u9762\u7684\u8868\u683c\u4e2d\uff0cupdate\u65b9\u6cd5\u5904\u7406\u53c2\u6570m\u7684\u65b9\u5f0f\uff0c\u662f\u5178\u578b\u7684\u201c\u9e2d\u5b50\u7c7b\u578b\u201d\u3002\u51fd\u6570\u9996\u5148\u68c0\u67e5m\u662f\u5426\u6709keys\u65b9\u6cd5\uff0c\u5982\u679c\u6709\uff0c\u90a3\u4e48update\u51fd\u6570\u5c31\u628a\u5b83\u5f53\u4f5c\u6620\u5c04\u5bf9\u8c61\u6765\u5904\u7406\u3002\u5426\u5219\uff0c\u51fd\u6570\u4f1a\u9000\u4e00\u6b65\uff0c\u8f6c\u800c\u628am\u5f53\u4f5c\u5305\u542b\u4e86\u952e\u503c\u5bf9(key, value)\u5143\u7d20\u7684\u8fed\u4ee3\u5668\u3002Python\u91cc\u5927\u591a\u6570\u6620\u5c04\u7c7b\u578b\u7684\u6784\u9020\u65b9\u6cd5\u90fd\u91c7\u7528\u4e86\u7c7b\u4f3c\u7684\u903b\u8f91\uff0c\u56e0\u6b64\u4f60\u65e2\u53ef\u4ee5\u7528\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u6765\u65b0\u5efa\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u7528\u5305\u542b(key, value)\u5143\u7d20\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6765\u521d\u59cb\u5316\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u3002 \u5b57\u5178\u7684\u53d8\u79cd collections.OrderedDict \u8fd9\u4e2a\u7c7b\u578b\u5728\u6dfb\u52a0\u952e\u7684\u65f6\u5019\u4f1a\u4fdd\u6301\u987a\u5e8f\uff0c\u56e0\u6b64\u952e\u7684\u8fed\u4ee3\u6b21\u5e8f\u603b\u662f\u4e00\u81f4\u7684\u3002OrderedDict\u7684popitem\u65b9\u6cd5\u9ed8\u8ba4\u5220\u9664\u5e76\u8fd4\u56de\u7684\u662f\u5b57\u5178\u91cc\u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20\uff0c\u4f46\u662f\u5982\u679c\u50cfmy_odict.popitem(last=False)\u8fd9\u6837\u8c03\u7528\u5b83\uff0c\u90a3\u4e48\u5b83\u5220\u9664\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a\u88ab\u6dfb\u52a0\u8fdb\u53bb\u7684\u5143\u7d20\u3002 collections.ChainMap \u8be5\u7c7b\u578b\u53ef\u4ee5\u5bb9\u7eb3\u6570\u4e2a\u4e0d\u540c\u7684\u6620\u5c04\u5bf9\u8c61\uff0c\u7136\u540e\u5728\u8fdb\u884c\u952e\u67e5\u627e\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u8fd9\u4e9b\u5bf9\u8c61\u4f1a\u88ab\u5f53\u4f5c\u4e00\u4e2a\u6574\u4f53\u88ab\u9010\u4e2a\u67e5\u627e\uff0c\u76f4\u5230\u952e\u88ab\u627e\u5230\u4e3a\u6b62\u3002\u8fd9\u4e2a\u529f\u80fd\u5728\u7ed9\u6709\u5d4c\u5957\u4f5c\u7528\u57df\u7684\u8bed\u8a00\u505a\u89e3\u91ca\u5668\u7684\u65f6\u5019\u5f88\u6709\u7528\uff0c\u53ef\u4ee5\u7528\u4e00\u4e2a\u6620\u5c04\u5bf9\u8c61\u6765\u4ee3\u8868\u4e00\u4e2a\u4f5c\u7528\u57df\u7684\u4e0a\u4e0b\u6587\u3002 collections.Counter \u8fd9\u4e2a\u6620\u5c04\u7c7b\u578b\u4f1a\u7ed9\u952e\u51c6\u5907\u4e00\u4e2a\u6574\u6570\u8ba1\u6570\u5668\u3002\u6bcf\u6b21\u66f4\u65b0\u4e00\u4e2a\u952e\u7684\u65f6\u5019\u90fd\u4f1a\u589e\u52a0\u8fd9\u4e2a\u8ba1\u6570\u5668\u3002\u6240\u4ee5\u8fd9\u4e2a\u7c7b\u578b\u53ef\u4ee5\u7528\u6765\u7ed9\u53ef\u6563\u5217\u8868\u5bf9\u8c61\u8ba1\u6570\uff0c\u6216\u8005\u662f\u5f53\u6210\u591a\u91cd\u96c6\u6765\u7528\u2014\u2014\u591a\u91cd\u96c6\u5408\u5c31\u662f\u96c6\u5408\u91cc\u7684\u5143\u7d20\u53ef\u4ee5\u51fa\u73b0\u4e0d\u6b62\u4e00\u6b21\u3002Counter\u5b9e\u73b0\u4e86+\u548c-\u8fd0\u7b97\u7b26\u7528\u6765\u5408\u5e76\u8bb0\u5f55\uff0c\u8fd8\u6709\u50cfmost_common([n])\u8fd9\u7c7b\u5f88\u6709\u7528\u7684\u65b9\u6cd5\u3002most_common([n])\u4f1a\u6309\u7167\u6b21\u5e8f\u8fd4\u56de\u6620\u5c04\u91cc\u6700\u5e38\u89c1\u7684n\u4e2a\u952e\u548c\u5b83\u4eec\u7684\u8ba1\u6570 \u4e0b\u9762\u7684\u4f8b\u5b50\u5229\u7528Counter\u6765\u8ba1\u7b97\u5355\u8bcd\u4e2d\u5404\u4e2a\u5b57\u6bcd\u51fa\u73b0\u7684\u6b21\u6570\uff1a str = 'abracadabra' ct = collections.Counter(str) print(ct) # Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) collections.UserDict \u8fd9\u4e2a\u7c7b\u5176\u5b9e\u5c31\u662f\u628a\u6807\u51c6dict\u7528\u7eafPython\u53c8\u5b9e\u73b0\u4e86\u4e00\u904d\u3002\u8ddfOrderedDict\u3001ChainMap\u548cCounter\u8fd9\u4e9b\u5f00\u7bb1\u5373\u7528\u7684\u7c7b\u578b\u4e0d\u540c\uff0cUserDict\u662f\u8ba9\u7528\u6237\u7ee7\u627f\u5199\u5b50\u7c7b\u7684\u3002 \u4e0d\u53ef\u53d8\u6620\u5c04\u7c7b\u578b \u6807\u51c6\u5e93\u91cc\u6240\u6709\u7684\u6620\u5c04\u7c7b\u578b\u90fd\u662f\u53ef\u53d8\u7684\uff0c\u4f46\u6709\u65f6\u5019\u4f60\u4f1a\u6709\u8fd9\u6837\u7684\u9700\u6c42\uff0c\u6bd4\u5982\u4e0d\u80fd\u8ba9\u7528\u6237\u9519\u8bef\u5730\u4fee\u6539\u67d0\u4e2a\u6620\u5c04\u3002 \u4ecePython 3.3\u5f00\u59cb\uff0ctypes\u6a21\u5757\u4e2d\u5f15\u5165\u4e86\u4e00\u4e2a\u5c01\u88c5\u7c7b\u540d\u53ebMappingProxyType\u3002\u5982\u679c\u7ed9\u8fd9\u4e2a\u7c7b\u4e00\u4e2a\u6620\u5c04\uff0c\u5b83\u4f1a\u8fd4\u56de\u4e00\u4e2a\u53ea\u8bfb\u7684\u6620\u5c04\u89c6\u56fe\u3002\u867d\u7136\u662f\u4e2a\u53ea\u8bfb\u89c6\u56fe\uff0c\u4f46\u662f\u5b83\u662f\u52a8\u6001\u7684\u3002\u8fd9\u610f\u5473\u7740\u5982\u679c\u5bf9\u539f\u6620\u5c04\u505a\u51fa\u4e86\u6539\u52a8\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2a\u89c6\u56fe\u53ef\u4ee5\u89c2\u5bdf\u5230\uff0c\u4f46\u662f\u65e0\u6cd5\u901a\u8fc7\u8fd9\u4e2a\u89c6\u56fe\u5bf9\u539f\u6620\u5c04\u505a\u51fa\u4fee\u6539\u3002 \u901a\u8fc7\u4e0b\u4f8b\u53ef\u4ee5\u770b\u51fa\uff0c d \u4e2d\u7684\u5185\u5bb9\u53ef\u4ee5\u901a\u8fc7 d_proxy \u770b\u5230\u3002\u4f46\u662f\u901a\u8fc7 d_proxy \u5e76\u4e0d\u80fd\u505a\u4efb\u4f55\u4fee\u6539\u3002 d_proxy \u662f\u52a8\u6001\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\u5bf9 d \u6240\u505a\u7684\u4efb\u4f55\u6539\u52a8\u90fd\u4f1a\u53cd\u9988\u5230\u5b83\u4e0a\u9762\u3002 from types import MappingProxyType d = {1: 'A'} d_proxy = MappingProxyType(d) print(d) # {1: 'A'} print(d_proxy) # {1: 'A'} print(d[1]) # A print(d_proxy[1]) # A d[2] = 'W' print(d) # {1: 'A', 2: 'W'} d_proxy[2] = 'W' # TypeError: 'mappingproxy' object does not support item assignment print(d_proxy) # {1: 'A', 2: 'W'}","title":"1.4 \u5b57\u5178\uff08dictionary\uff09"},{"location":"python/Foundation/ch01/#15-set","text":"\u201c\u96c6\u201d\u8fd9\u4e2a\u6982\u5ff5\u5728Python\u4e2d\u7b97\u662f\u6bd4\u8f83\u5e74\u8f7b\u7684\uff0c\u540c\u65f6\u5b83\u7684\u4f7f\u7528\u7387\u4e5f\u6bd4\u8f83\u4f4e\u3002set\u548c\u5b83\u7684\u4e0d\u53ef\u53d8\u7684\u59ca\u59b9\u7c7b\u578bfrozenset\u76f4\u5230Python 2.3\u624d\u9996\u6b21\u4ee5\u6a21\u5757\u7684\u5f62\u5f0f\u51fa\u73b0\uff0c\u7136\u540e\u5728Python 2.6\u4e2d\u5b83\u4eec\u5347\u7ea7\u6210\u4e3a\u5185\u7f6e\u7c7b\u578b\u3002 \u96c6\u5408(set) \uff0c\u5305\u542b\u4e0d\u53ef\u53d8\u7684\u96c6\u5408\uff08frozenset\uff09\uff0c\u662f\u4e00\u79cd\u65e0\u5e8f\u4e14\u5143\u7d20\u552f\u4e00\u7684\u5e8f\u5217\uff0c\u6240\u4ee5\u96c6\u5408\u7684\u672c\u8d28\u662f\u8bb8\u591a\u552f\u4e00\u5bf9\u8c61\u7684\u805a\u96c6\u3002 \u548c\u5b57\u5178\u7c7b\u4f3c\uff0c\u96c6\u5408\u7684\u5143\u7d20\u662f\u4e0d\u53ef\u53d8\u7684\u3002\u53ef\u4ee5\u8ba4\u4e3a\u96c6\u5408\u4e5f\u50cf\u5b57\u5178\uff0c\u4f46\u662f\u53ea\u6709\u952e\u6ca1\u6709\u503c\u3002\u57fa\u672c\u529f\u80fd\u662f\u8fdb\u884c\u6210\u5458\u5173\u7cfb\u6d4b\u8bd5\u548c\u5220\u9664\u91cd\u590d\u5143\u7d20\u3002\u6240\u4ee5\u96c6\u5408\u53e6\u4e00\u4e2a\u7528\u9014\u662f\u53bb\u91cd\u590d\u3002 \u96c6\u5408\u4e2d\u7684\u5143\u7d20\u5fc5\u987b\u662f\u53ef\u6563\u5217\u7684\uff0cset\u7c7b\u578b\u672c\u8eab\u662f\u4e0d\u53ef\u6563\u5217\u7684\uff0c\u4f46\u662ffrozenset\u53ef\u4ee5\u3002\u56e0\u6b64\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u5305\u542b\u4e0d\u540cfrozenset\u7684set\u3002 \u96c6\u5408\u53ef\u4ee5\u6709\u4e24\u79cd\u521b\u5efa\u65b9\u5f0f\uff1a\u901a\u8fc7set()\u51fd\u6570\u6216\u8005{}\u6765\u521b\u5efa\uff08\u7528\u5927\u62ec\u53f7\u62ec\u4f4f\u7684\u5185\u5bb9\uff0cPython3\u81ea\u52a8\u5b9a\u4e49\u4e3a\u96c6\u5408\uff09\u3002 \u96c6\u5408\u4e0d\u5c5e\u4e8e\u5e8f\u5217\u7c7b\u6570\u636e\uff0c \u96c6\u5408\u4e0d\u652f\u6301\u901a\u8fc7\u7d22\u5f15\u8bbf\u95ee\u6307\u5b9a\u5143\u7d20\uff0c\u4f46\u53ef\u4ee5\u589e\u52a0\u548c\u5220\u9664\u5143\u7d20\u3002 \u9762\u7684\u4f8b\u5b50\u662f\u6c42 haystacke \u548c needles \u4e24\u4e2a\u96c6\u5408\u7684\u4ea4\u96c6\u5143\u7d20\u4e2a\u6570\u3002 haystacke = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'f', 'g', 'h', 'c', 'd', 'e', 'c', 'd', 'e', 'f', 'g', 'h'} needles = {'c', 'h', 'w'} type(haystacke) # <class 'set'> type(needles) # <class 'set'> # \u4f20\u7edf\u65b9\u6cd5 found = 0 for i in needles: if i in haystacke: found += 1 print(found) # 2 # \u96c6\u5408\u65b9\u6cd5\u4e00 found = len(needles & haystacke) print(found) # 2 # \u96c6\u5408\u65b9\u6cd5\u4e8c found = len(needles.intersection(haystacke)) print(found) # 2 \u96c6\u5408\u5b9e\u73b0\u4e86\u5f88\u591a\u57fa\u7840\u7684\u4e2d\u7f00\u8fd0\u7b97\u7b26\uff0c\u6bd4\u5982\uff0c\u96c6\u5408\u652f\u6301\u6570\u5b66\u4e0a\u7684\u96c6\u5408\u64cd\u4f5c\uff1a\u5e76\u96c6\u3001\u4ea4\u96c6\u3001\u5dee\u96c6\u3001\u5bf9\u79f0\u5dee\u96c6\u3002 \u65b9\u6cd5\u540d\u79f0 \u8bf4\u660e add() \u4e3a\u96c6\u5408\u6dfb\u52a0\u5143\u7d20 update() \u7ed9\u96c6\u5408\u6dfb\u52a0\u5143\u7d20 clear() \u79fb\u9664\u96c6\u5408\u4e2d\u7684\u6240\u6709\u5143\u7d20 copy() \u62f7\u8d1d\u4e00\u4e2a\u96c6\u5408 remove() \u79fb\u9664\u6307\u5b9a\u5143\u7d20 pop() \u968f\u673a\u79fb\u9664\u5143\u7d20 discard() \u5220\u9664\u96c6\u5408\u4e2d\u6307\u5b9a\u7684\u5143\u7d20 < \u6216\u8005issubset() \u5224\u65ad\u6307\u5b9a\u96c6\u5408\u662f\u5426\u4e3a\u8be5\u65b9\u6cd5\u53c2\u6570\u96c6\u5408\u7684\u5b50\u96c6 | \u6216\u8005union() \u8fd4\u56de\u4e24\u4e2a\u96c6\u5408\u7684\u5e76\u96c6 & \u6216\u8005intersection() \u8fd4\u56de\u96c6\u5408\u7684\u4ea4\u96c6 intersection_update() \u8fd4\u56de\u96c6\u5408\u7684\u4ea4\u96c6 - \u6216\u8005difference() \u8fd4\u56de\u591a\u4e2a\u96c6\u5408\u7684\u5dee\u96c6 difference_update() \u79fb\u9664\u96c6\u5408\u4e2d\u7684\u5143\u7d20\uff0c\u8be5\u5143\u7d20\u5728\u6307\u5b9a\u7684\u96c6\u5408\u4e5f\u5b58\u5728 ^ \u6216\u8005symmetric_difference() \u8fd4\u56de\u4e24\u4e2a\u96c6\u5408\u4e2d\u4e0d\u91cd\u590d\u7684\u5143\u7d20\u96c6\u5408(\u4e24\u96c6\u5408\u9664\u53bb\u4ea4\u96c6\u90e8\u5206\u7684\u5143\u7d20) symmetric_difference_update() \u79fb\u9664\u5f53\u524d\u96c6\u5408\u4e2d\u5728\u53e6\u5916\u4e00\u4e2a\u6307\u5b9a\u96c6\u5408\u76f8\u540c\u7684\u5143\u7d20\uff0c\u5e76\u5c06\u53e6\u5916\u4e00\u4e2a\u6307\u5b9a\u96c6\u5408\u4e2d\u4e0d\u540c\u7684\u5143\u7d20\u63d2\u5165\u5230\u5f53\u524d\u96c6\u5408\u4e2d isdisjoint() \u5224\u65ad\u4e24\u4e2a\u96c6\u5408\u662f\u5426\u5305\u542b\u76f8\u540c\u7684\u5143\u7d20\uff0c\u5982\u679c\u6ca1\u6709\u8fd4\u56de True\uff0c\u5426\u5219\u8fd4\u56de False issuperset() \u5224\u65ad\u8be5\u65b9\u6cd5\u7684\u53c2\u6570\u96c6\u5408\u662f\u5426\u4e3a\u6307\u5b9a\u96c6\u5408\u7684\u5b50\u96c6 \u4e3e\u4f8b a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} \u5e76\u96c6(a\u548cb\u4e2d\u7684\u6240\u6709\u4e0d\u540c\u5143\u7d20) print(a.union(b)) # {'c', 1, 2, 'd', 'a', 'b'} print(a | b) # {'c', 1, 2, 'd', 'a', 'b'} \u4ea4\u96c6(a\u3001b\u4e2d\u540c\u65f6\u5305\u542b\u7684\u5143\u7d20) print(a.intersection(b)) # {'c', 1} print(a & b) # {'c', 1} \u5c06a\u7684\u5185\u5bb9\u8bbe\u7f6e\u4e3aa\u548cb\u7684\u4ea4\u96c6 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.intersection_update(b) print(a) # {1, 'c'} \u5728a\u4e0d\u5728b\u7684\u5143\u7d20 print(a.difference(b)) # {'a', 2, 'b'} print(a - b) # {2, 'a', 'b'} \u5c06a\u7684\u5185\u5bb9\u8bbe\u4e3a\u5728a\u4e0d\u5728b\u7684\u5143\u7d20 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.difference_update(b) print(a) # {2, 'b', 'a'} a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a -= b print(a) # {2, 'a', 'b'} \u5c06\u5143\u7d20\u52a0\u5165\u96c6\u5408a a.add(7) print(a) # {1, 2, 'c', 7, 'a', 'b'} \u6bcf\u6b21\u8f93\u51fa\u7684\u987a\u5e8f\u662f\u4e0d\u4e00\u6837\u7684 \u4ece\u96c6\u5408a\u79fb\u9664\u67d0\u4e2a\u5143\u7d20 a.remove(7) print(a) # {1, 2, 'c', 'a', 'b'} \u5982\u679ca\u88ab\u6e05\u7a7a\uff0c\u5219\u62a5\u9519 KeyError: 7 \u6240\u6709\u5728a\u6216b\u4e2d\uff0c\u4f46\u4e0d\u662f\u540c\u65f6\u5728a\u3001b\u4e2d\u7684\u5143\u7d20 print(a.symmetric_difference(b)) # {2, 'd', 'b', 'a'} print(a ^ b) # {2, 'd', 'b', 'a'} \u5c06a\u7684\u5185\u5bb9\u8bbe\u4e3a\u6240\u6709\u5728a\u6216b\u4e2d\uff0c\u4f46\u4e0d\u662f\u540c\u65f6\u5728a\u3001b\u4e2d\u7684\u5143\u7d20 a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a.symmetric_difference_update(b) print(a) # {'a', 2, 'd', 'b'} a = {'a', 'b', 'c', 1, 2} b = {1, 'c', 'd'} a ^= b print(a) # {2, 'd', 'a', 'b'} \u5982\u679ca\u5305\u542b\u4e8eb\uff0c\u8fd4\u56deTure print(a.issubset(b)) # False \u5c06a\u7684\u5185\u5bb9\u8bbe\u7f6e\u4e3aa\u548cb\u7684\u5e76\u96c6 print(a) # {'a', 2, 'd', 'b'} a = {'a', 'b', 'c', 1, 2} a.update(b) print(a) # {1, 2, 'a', 'b', 'd', 'c'} \u79fb\u9664\u4efb\u610f\u5143\u7d20\uff0c\u5982\u679c\u96c6\u5408\u662f\u7a7a\u7684\uff0c\u629b\u51fakeyError a.pop() # \u968f\u673a\u79fb\u9664\u67d0\u4e2a\u5143\u7d20\uff0c\u6ca1\u6709\u8f93\u5165\u53d8\u91cf\uff0c\u5982\u679c\u96c6\u5408\u662f\u7a7a\u7684\uff0c\u629b\u51faKeyError: 'pop from an empty set' print(a) # {2, 1, 'd', 'b', 'a'} \u5c06\u96c6\u5408\u91cd\u7f6e\u4e3a\u7a7a\uff0c\u6e05\u7a7a\u6240\u6709\u5143\u7d20 a.clear() print(a) # set() \u96c6\u5408\u7684\u5143\u7d20\u5fc5\u987b\u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u5982\u679c\u60f3\u8981\u5305\u542b\u5217\u8868\u578b\u7684\u5143\u7d20\uff0c\u5fc5\u987b\u5148\u8f6c\u6362\u4e3a\u5143\u7ec4 my_data1 = [1, 2, 3, 4] my_data2 = [3, 4, 5, 6] my_set = {tuple(my_data1), tuple(my_data2)} print(my_set) # {(1, 2, 3, 4), (3, 4, 5, 6)}","title":"1.5 \u96c6\u5408\uff08set\uff09"},{"location":"python/Foundation/ch01/#16-tuple","text":"Python \u7684\u5143\u7ec4\u4e0e\u5217\u8868\u7c7b\u4f3c\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u5143\u7ec4\u7684\u5143\u7d20\u4e0d\u80fd\u4fee\u6539\u3002 \u5143\u7ec4\u4f7f\u7528\u5c0f\u62ec\u53f7( )\uff0c\u5217\u8868\u4f7f\u7528\u65b9\u62ec\u53f7[ ]\u3002 \u5143\u7ec4\u4e2d\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u65f6\uff0c\u9700\u8981\u5728\u5143\u7d20\u540e\u9762\u6dfb\u52a0\u9017\u53f7 \uff0c\u5426\u5219\u62ec\u53f7\u4f1a\u88ab\u5f53\u4f5c\u8fd0\u7b97\u7b26\u4f7f\u7528\u3002 \u5143\u7ec4\u53ef\u4ee5\u4f7f\u7528\u4e0b\u6807\u7d22\u5f15\u6765\u8bbf\u95ee\u5143\u7ec4\u4e2d\u7684\u503c\u3002 \u5143\u7ec4\u4e2d\u7684\u5143\u7d20\u503c\u662f\u4e0d\u5141\u8bb8\u4fee\u6539\u7684\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u5bf9\u5143\u7ec4\u8fdb\u884c\u8fde\u63a5\u7ec4\u5408\u3002 \u5143\u7ec4\u4e2d\u7684\u5143\u7d20\u503c\u662f\u4e0d\u5141\u8bb8\u5220\u9664\u7684\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528del\u8bed\u53e5\u6765\u5220\u9664\u6574\u4e2a\u5143\u7ec4\u3002 # \u6b64\u5904\u62ec\u53f7\u88ab\u89e3\u6790\u4e3a\u8fd0\u7b97\u7b26\uff0c\u9700\u8981\u5728\u540e\u9762\u52a0\u4e0a\u9017\u53f7\u624d\u4f1a\u88ab\u89e3\u91ca\u4e3a\u5143\u7ec4 tup1 = (10) print(type(tup1)) # <class 'int'> tup1 = (10,) print(type(tup1)) # <class 'tuple'> \u521b\u5efa\u5143\u7ec4\u6700\u7b80\u5355\u7684\u529e\u6cd5\u5c31\u662f\u7528\u9017\u53f7\u5206\u9694\u5e8f\u5217\u503c\u3002\u5143\u7ec4\u5bf9\u6570\u636e\u7c7b\u578b\u6ca1\u6709\u4e00\u81f4\u6027\u8981\u6c42\u3002 tup = 4, 5, 6 print(tup) # (4, 5, 6) nested_tup = (4, 5, 6), (7, 8) print(nested_tup) # # ((4, 5, 6), (7, 8)) tup = ('a', 'b', {'one': 1}) print(type(tup)) # <class 'tuple'> \u4f7f\u7528\u52a0\u53f7\uff08+\uff09\u8fdb\u884c\u5143\u7ec4\u8fde\u63a5\u5408\u5e76\u3002 tup = tuple((4, None, 'fool') + (6, 0) + ('bar',)) print(tup) # (4, None, 'fool', 6, 0, 'bar') \u5143\u7ec4\u7684\u4e0d\u53ef\u53d8\u6307\u7684\u662f \u5143\u7ec4\u6240\u6307\u5411\u7684\u5185\u5b58\u4e2d\u7684\u5185\u5bb9\u4e0d\u53ef\u53d8 \u3002 tup = ('h', 'e', 'l', 'l', 'o') print(id(tup)) # 139820353350208 tup = (1, 2, 3, 4, 5) print(id(tup)) # 139820353298896 tup[0] = 'x' # Traceback (most recent call last): # File \"<stdin>\", line 1, in <module> # TypeError: 'tuple' object does not support item assignment \u5c06\u5143\u7ec4\u4e58\u4ee5\u6574\u6570\uff0c\u5219\u4f1a\u548c\u5217\u8868\u4e00\u6837\uff0c\u751f\u6210\u542b\u6709\u591a\u4efd\u62f7\u8d1d\u7684\u5143\u7ec4\u3002\u5bf9\u8c61\u81ea\u8eab\u5e76\u6ca1\u6709\u590d\u5236\uff0c\u53ea\u662f\u6307\u5411\u5b83\u4eec\u7684\u5f15\u7528\u8fdb\u884c\u4e86\u590d\u5236\u3002 tup = tuple(('fool', 'bar') * 4) print(tup) # ('fool', 'bar', 'fool', 'bar', 'fool', 'bar', 'fool', 'bar') \u5982\u679c\u5143\u7ec4\u4e2d\u7684\u4e00\u4e2a\u5bf9\u8c61\u662f\u53ef\u53d8\u7684\uff0c\u4f8b\u5982\u5217\u8868\uff0c\u4f60\u53ef\u4ee5\u5728\u5b83\u5185\u90e8\u8fdb\u884c\u4fee\u6539 tup = tuple(['foo', [4, 5, 6], True]) tup[1].append(0) print(tup) # ('foo', [4, 5, 6, 0], True) tup[1].append([9]) print(tup) # ('foo', [4, 5, 6, 0, [9]], True) \u4f7f\u7528tuple\u51fd\u6570\u5c06\u4efb\u610f\u5e8f\u5217\u6216\u8fed\u4ee3\u5668\u8f6c\u6362\u4e3a\u5143\u7ec4 tup = tuple([4, 5, 6]) print(tup) # (4, 5, 6) tup = tuple('string') print(tup) # ('s', 't', 'r', 'i', 'n', 'g') print(tup[2]) # r # \u5143\u7ec4\u7684\u5143\u7d20\u53ef\u4ee5\u901a\u8fc7\u4e2d\u62ec\u53f7[]\u6765\u83b7\u53d6 \u5982\u679c\u8981\u5c06\u5143\u7ec4\u578b\u7684\u8868\u8fbe\u5f0f\u8d4b\u503c\u7ed9\u53d8\u91cf\uff0cPython\u4f1a\u5bf9\u7b49\u53f7\u53f3\u8fb9\u7684\u503c\u8fdb\u884c \u62c6\u5305 tup = (9, 5, (8, 7)) a, b, c = tup print(a) # 9 print(b) # 5 print(c) # (8, 7) a, b, (c, d) = tup print(a) # 9 print(b) # 5 print(c) # 8 print(d) # 7 tup = (9, 5, (8, 7)) a, b, c = tup c, a = a, c # \u5229\u7528\u62c6\u5305\u5b9e\u73b0\u4ea4\u6362 print(a) # (8, 7) print(b) # 5 print(c) # 9 \u5229\u7528\u62c6\u5305\u5b9e\u73b0\u904d\u5386\u5143\u7ec4\u6216\u5217\u8868\u7ec4\u6210\u7684\u5e8f\u5217 seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)] for a, b, c in seq: print('a={0}, b={0}, c={0}'.format(a, b, c)) # \u5217\u8868\u6bcf\u4e2a\u5143\u7d20\u7684\u53d6\u503c\u987a\u5e8f # a=1, b=1, c=1 # a=4, b=4, c=4 # a=7, b=7, c=7 print('a={0}, b={1}, c={2}'.format(a, b, c)) # a=1, b=2, c=3 # a=4, b=5, c=6 # a=7, b=8, c=9 print('a={2}, b={0}, c={1}'.format(a, b, c)) # a=3, b=1, c=2 # a=6, b=4, c=5 # a=9, b=7, c=8 \u5143\u7ec4\u62c6\u5305\u529f\u80fd\u8fd8\u5305\u62ec\u7279\u6b8a\u7684\u8bed\u6cd5*rest\u3002\u5f88\u591aPython\u7f16\u7a0b\u8005\u4f1a\u4f7f\u7528\u4e0b\u5212\u7ebf\uff08_\uff09\u6765\u8868\u793a\u4e0d\u60f3\u8981\u7684\u53d8\u91cf values = 1, 2, 3, 4, 5 a, b, *rest = values print(a) # 1 print(b) # 2 print(*rest) # 3 4 5 a, b, *_ = values print(*_) # 3 4 5 \u5177\u540d\u5143\u7ec4 collections.namedtuple \u662f\u4e00\u4e2a\u5de5\u5382\u51fd\u6570\uff0c\u5b83\u53ef\u4ee5\u7528\u6765\u6784\u5efa\u4e00\u4e2a\u5e26\u5b57\u6bb5\u540d\u7684\u5143\u7ec4\u548c\u4e00\u4e2a\u6709\u540d\u5b57\u7684\u7c7b\u3002 \u7528namedtuple\u6784\u5efa\u7684\u7c7b\u7684\u5b9e\u4f8b\u6240\u6d88\u8017\u7684\u5185\u5b58\u8ddf\u5143\u7ec4\u662f\u4e00\u6837\u7684\uff0c\u56e0\u4e3a\u5b57\u6bb5\u540d\u90fd\u88ab\u5b58\u5728\u5bf9\u5e94\u7684\u7c7b\u91cc\u9762\u3002 \u521b\u5efa\u4e00\u4e2a\u5177\u540d\u5143\u7ec4\u9700\u8981\u4e24\u4e2a\u53c2\u6570\uff0c\u4e00\u4e2a\u662f\u7c7b\u540d( City )\uff0c\u53e6\u4e00\u4e2a\u662f\u7c7b\u7684\u5404\u4e2a\u5b57\u6bb5\u7684\u540d\u5b57( 'name country population coordinates' )\u3002\u540e\u8005\u53ef\u4ee5\u662f\u7531\u6570\u4e2a\u5b57\u7b26\u4e32\u7ec4\u6210\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6216\u8005\u662f\u7531\u7a7a\u683c\u5206\u9694\u5f00\u7684\u5b57\u6bb5\u540d\u7ec4\u6210\u7684\u5b57\u7b26\u4e32\u3002 \u5b58\u653e\u5728\u5bf9\u5e94\u5b57\u6bb5\u91cc\u7684\u6570\u636e\u8981\u4ee5\u4e00\u4e32\u53c2\u6570\u7684\u5f62\u5f0f\u4f20\u5165\u5230\u6784\u9020\u51fd\u6570\u4e2d\uff08\u6ce8\u610f\uff0c\u5143\u7ec4\u7684\u6784\u9020\u51fd\u6570\u5374\u53ea\u63a5\u53d7\u5355\u4e00\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff09\u3002 \u5177\u540d\u5143\u7ec4\u8fd8\u6709\u4e00\u4e9b\u81ea\u5df1\u4e13\u6709\u7684\u5c5e\u6027\u3002\u4e0b\u9762\u5c55\u793a\u4e86\u51e0\u4e2a\u6700\u6709\u7528\u7684\uff1a _fields \u7c7b\u5c5e\u6027\u3001\u7c7b\u65b9\u6cd5 _make(iterable) \u548c\u5b9e\u4f8b\u65b9\u6cd5 _asdict() \u3002 _fields \u5c5e\u6027\u662f\u4e00\u4e2a\u5305\u542b\u8fd9\u4e2a\u7c7b\u6240\u6709\u5b57\u6bb5\u540d\u79f0\u7684\u5143\u7ec4\u3002 \u7528 _make() \u901a\u8fc7\u63a5\u53d7\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u6765\u751f\u6210\u8fd9\u4e2a\u7c7b\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5b83\u7684\u4f5c\u7528\u8ddf City(*delhi_data) \u662f\u4e00\u6837\u7684\u3002 _asdict() \u628a\u5177\u540d\u5143\u7ec4\u4ee5 collections.OrderedDict \u7684\u5f62\u5f0f\u8fd4\u56de\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u5b83\u6765\u628a\u5143\u7ec4\u91cc\u7684\u4fe1\u606f\u53cb\u597d\u5730\u5448\u73b0\u51fa\u6765\u3002 from collections import namedtuple City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139691667)) print(tokyo) # City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139691667)) print(tokyo.population) # 36.933 print(tokyo[3]) # (35.689722, 139691667) print(City._fields) # ('name', 'country', 'population', 'coordinates') LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613899, 77.208889)) delhi = City._make(delhi_data) print(delhi) # City(name='Delhi NCR', country='IN', population=21.935, coordinates=LatLong(lat=28.613899, long=77.208889)) print(delhi._asdict()) # OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613899, long=77.208889))]) for key, value in delhi._asdict().items(): print(key + ':', value) # name: Delhi NCR # country: IN # population: 21.935 # coordinates: LatLong(lat=28.613899, long=77.208889) \u5143\u7ec4\u8fd8\u6709\u7b2c\u4e8c\u91cd\u529f\u80fd\uff1a\u4f5c\u4e3a\u4e0d\u53ef\u53d8\u5217\u8868\u7684\u5143\u7ec4\u3002 \u4e0b\u9762\u662f\u5217\u8868\u6216\u5143\u7ec4\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u5bf9\u6bd4\u3002\u9664\u4e86\u8ddf\u589e\u51cf\u5143\u7d20\u76f8\u5173\u7684\u65b9\u6cd5\u4e4b\u5916\uff0c\u5143\u7ec4\u652f\u6301\u5217\u8868\u7684\u5176\u4ed6\u6240\u6709\u65b9\u6cd5\u3002\u8fd8\u6709\u4e00\u4e2a\u4f8b\u5916\uff0c\u5143\u7ec4\u6ca1\u6709__reversed__\u65b9\u6cd5\u3002 \u4e00\u4e2a\u5173\u4e8e+=\u548c*=\u7684\u8c1c\u9898 \u4e0b\u9762\u7684\u4f8b\u5b50\u5c55\u793a\u4e86 *= \u5728\u53ef\u53d8\u548c\u4e0d\u53ef\u53d8\u5e8f\u5217\u4e0a\u7684\u4f5c\u7528\u3002\u5217\u8868\u7684ID\u6ca1\u53d8\uff0c\u65b0\u5143\u7d20\u8ffd\u52a0\u5230\u5217\u8868\u4e0a\uff0c\u4f46\u6267\u884c\u589e\u91cf\u4e58\u6cd5\u540e\uff0c\u65b0\u7684\u5143\u7ec4\u88ab\u521b\u5efa\u3002 list1 = [1, 2, 3, 4] id(list1) # 140409777308808 list1 *= 2 print(list1) # [1, 2, 3, 4, 1, 2, 3, 4] id(list1) # 140409777308808 tuple1 = (1, 2, 3, 4) id(tuple1) # 140409777230536 tuple1 *= 2 print(tuple1) # (1, 2, 3, 4, 1, 2, 3, 4) id(tuple1) # 140409780104888 \u4f46\u5bf9\u4e8e\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u867d\u7136 tuple1[2] += [50, 60] \u6267\u884c\u65f6\u6709\u5f02\u5e38\u629b\u51fa\uff0c\u4f46 tuple1 \u5374\u88ab\u4fee\u6539\u4e86\u3002 t = (1, 2, [10, 20]) t[2] += [50, 60] # TypeError: 'tuple' object does not support item assignment print(t) # (1, 2, [10, 20, 50, 60]) \u4e0b\u56fe\u5927\u81f4\u63cf\u8ff0\u4e86\u4e0a\u8ff0\u6267\u884c\u8fc7\u7a0b\u3002 \u4e3a\u4e86\u907f\u514d\u4e0a\u9762\u60c5\u51b5\u7684\u53d1\u751f\uff0c\u6211\u4eec \u4e0d\u8981\u628a\u53ef\u53d8\u5bf9\u8c61\u653e\u5728\u5143\u7ec4\u91cc\u9762 \u3002\u589e\u91cf\u8d4b\u503c\u4e0d\u662f\u4e00\u4e2a\u539f\u5b50\u64cd\u4f5c\uff0c\u5b83\u867d\u7136\u629b\u51fa\u4e86\u5f02\u5e38\uff0c\u4f46\u8fd8\u662f\u5b8c\u6210\u4e86\u64cd\u4f5c\u3002","title":"1.6 \u5143\u7ec4\uff08tuple\uff09"},{"location":"python/Foundation/ch01/#17-memoryview","text":"memoryview\u662f\u4e00\u4e2a\u5185\u7f6e\u7c7b\uff0c\u5b83\u80fd\u8ba9\u7528\u6237\u5728\u4e0d\u590d\u5236\u5185\u5bb9\u7684\u60c5\u51b5\u4e0b\u64cd\u4f5c\u540c\u4e00\u4e2a\u6570\u7ec4\u7684\u4e0d\u540c\u5207\u7247\u3002 \u5185\u5b58\u89c6\u56fe\u5176\u5b9e\u662f\u6cdb\u5316\u548c\u53bb\u6570\u5b66\u5316\u7684NumPy\u6570\u7ec4\u3002\u5b83\u8ba9\u4f60\u5728\u4e0d\u9700\u8981\u590d\u5236\u5185\u5bb9\u7684\u524d\u63d0\u4e0b\uff0c\u5728\u6570\u636e\u7ed3\u6784\u4e4b\u95f4\u5171\u4eab\u5185\u5b58\u3002 \u5176\u4e2d\u6570\u636e\u7ed3\u6784\u53ef\u4ee5\u662f\u4efb\u4f55\u5f62\u5f0f\uff0c\u6bd4\u5982PIL\u56fe\u7247\u3001SQLite\u6570\u636e\u5e93\u548cNumPy\u7684\u6570\u7ec4\uff0c\u7b49\u7b49\u3002\u8fd9\u4e2a\u529f\u80fd\u5728\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u5408\u7684\u65f6\u5019\u975e\u5e38\u91cd\u8981\u3002 memoryview.cast\u7684\u6982\u5ff5\u8ddf\u6570\u7ec4\u6a21\u5757\u7c7b\u4f3c\uff0c\u80fd\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u8bfb\u5199\u540c\u4e00\u5757\u5185\u5b58\u6570\u636e\uff0c\u800c\u4e14\u5185\u5bb9\u5b57\u8282\u4e0d\u4f1a\u968f\u610f\u79fb\u52a8\u3002\u8fd9\u8ddfC\u8bed\u8a00\u4e2d\u7c7b\u578b\u8f6c\u6362\u7684\u6982\u5ff5\u5dee\u4e0d\u591a\u3002 memoryview.cast\u4f1a\u628a\u540c\u4e00\u5757\u5185\u5b58\u91cc\u7684\u5185\u5bb9\u6253\u5305\u6210\u4e00\u4e2a\u5168\u65b0\u7684memoryview\u5bf9\u8c61\u7ed9\u4f60\u3002 array \u91cc\u9762\u7684Type code\uff1a 'b' signed integer 1 'B' unsigned integer 1 'u' Unicode character 2 (see note) 'h' signed integer 2 'H' unsigned integer 2 'i' signed integer 2 'I' unsigned integer 2 'l' signed integer 4 'L' unsigned integer 4 'q' signed integer 8 (see note) 'Q' unsigned integer 8 (see note) 'f' floating point 4 'd' floating point 8 numbers = array('h', [-2, -1, 0, 1, 2]) # array('h', [-2, -1, 0, 1, 2]) # \u75285\u4e2a\u77ed\u6574\u578b\u6709\u7b26\u53f7\u6574\u6570\u7684\u6570\u7ec4\uff08\u7c7b\u578b\u7801\u662f'h'\uff09\u521b\u5efa\u4e00\u4e2amemoryview\u3002 memv = memoryview(numbers) # memv\u91cc\u76845\u4e2a\u5143\u7d20\u8ddf\u6570\u7ec4\u91cc\u7684\u6ca1\u6709\u533a\u522b\u3002 print(len(memv)) # 5 print(memv[0]) # -2 print(memv.tolist()) # [-2, -1, 0, 1, 2] # \u521b\u5efa\u4e00\u4e2amemv_oct\uff0c\u8fd9\u4e00\u6b21\u662f\u628amemv\u91cc\u7684\u5185\u5bb9\u8f6c\u6362\u6210'B'\u7c7b\u578b\uff0c\u4e5f\u5c31\u662f\u65e0\u7b26\u53f7\u5b57\u7b26\u3002 memv_oct = memv.cast('B') print(memv_oct.tolist()) # [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] # \u628a\u4f4d\u4e8e\u4f4d\u7f6e5\u7684\u5b57\u8282\u8d4b\u503c\u62104\u3002\u56e0\u4e3a\u6211\u4eec\u628a\u53602\u4e2a\u5b57\u8282\u7684\u6574\u6570\u7684\u9ad8\u4f4d\u5b57\u8282\u6539\u6210\u4e864\uff0c\u6240\u4ee5\u8fd9\u4e2a\u6709\u7b26\u53f7\u6574\u6570\u7684\u503c\u5c31\u53d8\u6210\u4e861024\u3002 memv_oct[5] = 4 print(numbers) # array('h', [-2, -1, 1024, 1, 2])","title":"1.7 \u5185\u5b58\u89c6\u56feMemoryview"},{"location":"python/Foundation/ch01/#2","text":"\u661f\u53f7 * \u7684\u53c2\u6570\u4f1a\u4ee5\u5143\u7ec4(tuple)\u7684\u5f62\u5f0f\u5bfc\u5165\uff0c\u5b58\u653e\u6240\u6709\u672a\u547d\u540d\u7684\u53d8\u91cf\u53c2\u6570 def printinfo(arg1, *vartuple): print(\"\u8f93\u51fa\u4efb\u4f55\u4f20\u5165\u7684\u53c2\u6570: \") print(arg1) print(vartuple) for var in vartuple: print(var) return printinfo(10) # 10 # () printinfo(70, 60, 50) # 70 # (60, 50) # 60 # 50 \u4e24\u4e2a\u661f\u53f7 ** \u7684\u53c2\u6570\u4f1a\u4ee5\u5b57\u5178\u7684\u5f62\u5f0f\u5bfc\u5165 def printinfo(arg1, **vardict): print(\"\u8f93\u51fa\u4efb\u4f55\u4f20\u5165\u7684\u53c2\u6570: \") print(arg1) print(vardict) printinfo(1, a=2, b=3) # 1 # {'a': 2, 'b': 3} \u5b57\u5178\u683c\u5f0f\u8f93\u51fa Python\u4e2d\u7684\u5bf9\u8c61\u5f15\u7528\u5e76\u4e0d\u6d89\u53ca\u7c7b\u578b\u3002\u53d8\u91cf\u5bf9\u4e8e\u5bf9\u8c61\u6765\u8bf4\u53ea\u662f\u7279\u5b9a\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u540d\u79f0\uff1b\u7c7b\u578b\u4fe1\u606f\u662f\u5b58\u50a8\u5728\u5bf9\u8c61\u81ea\u8eab\u4e4b\u4e2d\u3002 a = 5 print(type(a)) # <class 'int'> a = 'foo' print(type(a)) # <class 'str'> Python\u662f\u5f3a\u7c7b\u578b\u8bed\u8a00\uff0c\u6240\u6709\u7684\u5bf9\u8c61\u90fd\u62e5\u6709\u4e00\u4e2a\u6307\u5b9a\u7684\u7c7b\u578b\uff08\u6216\u7c7b\uff09\uff0c\u9690\u5f0f\u7684\u8f6c\u6362\u53ea\u5728\u67d0\u4e9b\u7279\u5b9a\u3001\u660e\u663e\u7684\u60c5\u51b5\u4e0b\u53d1\u751f\u3002 a = 4.5 b = 2 print('a is {0}, b is {1}'.format(type(a), type(b))) # a is <class 'float'>, b is <class 'int'> \u5b57\u4e32\u683c\u5f0f\u5316\uff0c\u7528\u4e8e\u540e\u7eed\u8bbf\u95ee print(a / b) # 2.25 \u4f7f\u7528isinstance\u51fd\u6570\u6765\u68c0\u67e5\u4e00\u4e2a\u5bf9\u8c61\u662f\u5426\u662f\u7279\u5b9a\u7c7b\u578b\u7684\u5b9e\u4f8b\u3002isinstance\u63a5\u53d7\u4e00\u4e2a\u5305\u542b\u7c7b\u578b\u7684\u5143\u7ec4\uff0c\u53ef\u4ee5\u68c0\u67e5\u5bf9\u8c61\u7684\u7c7b\u578b\u662f\u5426\u5728\u5143\u7ec4\u4e2d\u7684\u7c7b\u578b\u4e2d\u3002 a = 5 b = 4.5 c = 'foo' print(isinstance(a, int)) # True print(isinstance(b, str)) # False print(isinstance(c, (str, int))) # True print(isinstance(c, (float, int))) # False \u5c5e\u6027\u548c\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u901a\u8fc7getattr\u51fd\u6570\u83b7\u5f97\u3002\u5728\u5176\u4ed6\u7684\u8bed\u8a00\u4e2d\uff0c\u901a\u8fc7\u53d8\u91cf\u540d\u8bbf\u95ee\u5bf9\u8c61\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u53cd\u5c04\u201d\u3002 b = 'foo' print(getattr(b, 'split')) # <built-in method split of str object at 0x7f1d603ba430>","title":"2. \u52a8\u6001\u5f15\u7528\u3001\u5f3a\u7c7b\u578b"},{"location":"python/Foundation/ch01/#3","text":"\u68c0\u67e5\u4e24\u4e2a\u5f15\u7528\u662f\u5426\u6307\u5411\u540c\u4e00\u4e2a\u5bf9\u8c61\uff0c\u53ef\u4ee5\u4f7f\u7528is\u5173\u952e\u5b57\u3002 is\u548cis not\u7684\u5e38\u7528\u4e4b\u5904\u662f\u68c0\u67e5\u4e00\u4e2a\u53d8\u91cf\u662f\u5426\u4e3aNone\uff0c\u56e0\u4e3aNone\u53ea\u6709\u4e00\u4e2a\u5b9e\u4f8b\u3002 a = [1, 2, 3] b = a c = list(a) # list\u51fd\u6570\u603b\u662f\u521b\u5efa\u4e00\u4e2a\u65b0\u7684Python\u5217\u8868\uff08\u5373\u4e00\u4efd\u62f7\u8d1d\uff09 print(a is b) # True print(a is not c) # True print(a == c) # True d = None print(d is None) # True Python\u4e2d\u7684\u5927\u90e8\u5206\u5bf9\u8c61\uff0c\u4f8b\u5982\u5217\u8868\u3001\u5b57\u5178\u3001NumPy\u6570\u7ec4\u90fd\u662f\u53ef\u53d8\u5bf9\u8c61\uff0c\u5927\u591a\u6570\u7528\u6237\u5b9a\u4e49\u7684\u7c7b\u578b\uff08\u7c7b\uff09\u4e5f\u662f\u53ef\u53d8\u7684\u3002 \u53ef\u53d8\u5bf9\u8c61\u4e2d\u5305\u542b\u7684\u5bf9\u8c61\u548c\u503c\u662f\u53ef\u4ee5\u88ab\u4fee\u6539\u7684\u3002\u8fd8\u6709\u5176\u4ed6\u4e00\u4e9b\u5bf9\u8c61\u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u6bd4\u5982\u5b57\u7b26\u4e32\u3001\u5143\u7ec4\u3002 a_list = ['foo', 2, [4, 5]] # \u5217\u8868 a_list[2] = (3, 4) print(a_list) # ['foo', 2, (3, 4)] a_tuple = (3, 5, (4, 5)) # \u5143\u7ec4 a_tuple[1] = 'four' # TypeError: 'tuple' object does not support item assignment \u4e0d\u53ef\u88ab\u4fee\u6539 print(a_tuple) # (3, 5, (4, 5))","title":"3. \u4e8c\u5143\u8fd0\u7b97\u7b26\u548c\u6bd4\u8f83\u8fd0\u7b97"},{"location":"python/Foundation/ch01/#4","text":"Python\u6807\u91cf\u7c7b\u578b\uff1aNone, str, bytes, float, bool, int \u6570\u503c\u7c7b\u578b\u3002 \u57fa\u7840\u7684Python\u6570\u5b57\u7c7b\u578b\u5c31\u662fint\u548cfloat\u3002int\u53ef\u4ee5\u5b58\u50a8\u4efb\u610f\u5927\u5c0f\u6570\u5b57\u3002\u6d6e\u70b9\u6570\u5728Python\u4e2d\u7528float\u8868\u793a\uff0c\u6bcf\u4e00\u4e2a\u6d6e\u70b9\u6570\u90fd\u662f\u53cc\u7cbe\u5ea664\u4f4d\u6570\u503c\u3002 ival = 17338971 print(ival ** 6) # 27173145946003847721495630081806010734757321 fval = 17338971.0 print(fval ** 6) # 2.7173145946003847e+43 print(3 / 2) # 1.5 print(3 // 2) # 1 \u5b57\u7b26\u4e32\u3002 Python\u7684\u5b57\u7b26\u4e32\u662f\u4e0d\u53ef\u53d8\u7684\u3002 a = 5.6 s = str(a) print(s) # 5.6 b = 'python' print(list(b)) # ['p', 'y', 't', 'h', 'o', 'n'] print(b[2]) # t b[2] = 'f' # TypeError: 'str' object does not support item assignment \u5b57\u7b26\u4e32\u662f\u4e0d\u53ef\u53d8\u7684 \u53cd\u659c\u6760\u7b26\u53f7\\\u662f\u4e00\u79cd\u8f6c\u4e49\u7b26\u53f7\uff0c\u5b83\u7528\u6765\u6307\u660e\u7279\u6b8a\u7b26\u53f7\u3002 \u5982\u679c\u4f60\u6709\u4e00\u4e2a\u4e0d\u542b\u7279\u6b8a\u7b26\u53f7\u4f46\u542b\u6709\u5927\u91cf\u53cd\u659c\u6760\u7684\u5b57\u7b26\u4e32\u65f6\uff0c\u53ef\u4ee5\u5728\u5b57\u7b26\u4e32\u524d\u9762\u52a0\u4e00\u4e2a\u524d\u7f00\u7b26\u53f7r\uff0c\u8868\u660e\u8fd9\u4e9b\u5b57\u7b26\u662f\u539f\u751f\u5b57\u7b26\uff0cr\u662fraw\u7684\u7b80\u5199\uff0c\u8868\u793a\u539f\u751f\u7684\u3002 x = '12\\\\34' y = r'this\\has\\no\\special\\characters' print(x) # 12\\34 print(y) # this\\has\\no\\special\\characters \u5b57\u7b26\u4e32\u683c\u5f0f\u5316 {0:.2f}\u8868\u793a\u5c06\u7b2c\u4e00\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u4e3a2\u4f4d\u5c0f\u6570\u7684\u6d6e\u70b9\u6570 {1:s}\u8868\u793a\u5c06\u7b2c\u4e8c\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u4e3a\u5b57\u7b26\u4e32 {2:d}\u8868\u793a\u5c06\u7b2c\u4e09\u4e2a\u53c2\u6570\u683c\u5f0f\u5316\u6574\u6570 \u53c2\u8003Python\u5b98\u65b9\u6587\u6863 https://docs.python.org/3.6/library/string.html template = '{0:.2f} {1:s} are worth US${2:d}' print(template.format(4.5560, 'Argentine Pesos', 1)) # 4.56 Argentine Pesos are worth US$1 \u65e5\u671f\u548c\u65f6\u95f4 from datetime import datetime, date, time dt = datetime(2011, 10, 29, 20, 30, 21) print(dt.day) # 29 print(dt.minute) # 30 print(dt.date()) # 2011-10-29 print(dt.time()) # 20:30:21 print(dt.replace(minute=0, second=0)) # 2011-10-29 20:00:00 \u5c06\u5206\u949f\u3001\u79d2\u66ff\u6362\u4e3a0 print(datetime.strptime('20091021', '%Y%m%d')) # 2009-10-21 00:00:00 \u5b57\u7b26\u4e32\u53ef\u4ee5\u901a\u8fc7 strptime \u51fd\u6570\u8f6c\u6362\u4e3adatetime\u5bf9\u8c61 dt2 = datetime(2011, 11, 15, 22, 30) delta = dt2 - dt print(delta) # 17 days, 1:59:39 print(dt + delta) # 2011-11-15 22:30:00 range\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u8be5\u8fed\u4ee3\u5668\u751f\u6210\u4e00\u4e2a\u7b49\u5dee\u6574\u6570\u5e8f\u5217\u3002 print(range(10)) # range(0, 10) print(list(range(10))) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] print(list(range(0, 20, 2))) # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]","title":"4. \u6807\u91cf\u7c7b\u578b"},{"location":"python/Foundation/ch01/#5","text":"value = true-expr if condition else false-expr x = 5 print('non-negative' if x >= 0 else 'negative') # non-negative","title":"5. \u4e09\u5143\u8868\u8fbe\u5f0f"},{"location":"python/Foundation/ch02/","text":"Python\u4e2d\u7684\u6253\u5305Packing\u548c\u89e3\u5305Unpacking \u89e3\u5305Unpacking Python \u5141\u8bb8\u53d8\u91cf\u7684\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u51fa\u73b0\u5728\u8d4b\u503c\u64cd\u4f5c\u7684\u5de6\u4fa7\u3002 \u5143\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u90fd\u53ef\u4ee5\u4ece\u8d4b\u503c\u53f3\u4fa7\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff08iterable\uff09\u4e2d\u63a5\u6536\u4e00\u4e2a\u503c\uff08\u6216\u8005\u66f4\u591a\uff0c\u5982\u679c\u6211\u4eec\u4f7f\u7528 * \u8fd0\u7b97\u7b26\uff09\u3002 Python \u4e2d\u7684\u89e3\u5305\u662f\u6307\u4e00\u79cd\u64cd\u4f5c\uff0c\u8be5\u64cd\u4f5c\u5305\u62ec\u5728\u5355\u4e2a\u8d4b\u503c\u8bed\u53e5\u4e2d\u5c06\u53ef\u8fed\u4ee3\u7684\u503c\u5206\u914d\u7ed9\u53d8\u91cf\u7684\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u3002 \u5728 Python \u4e2d\uff0c\u53ef\u4ee5\u5728\u8d4b\u503c\u8fd0\u7b97\u7b26 (=) \u7684\u5de6\u4fa7\u653e\u7f6e\u4e00\u4e2a\u53d8\u91cf\u5143\u7ec4\uff0c\u5728\u53f3\u4fa7\u653e\u7f6e\u4e00\u4e2a\u503c\u5143\u7ec4\u3002 \u53f3\u8fb9\u7684\u503c\u5c06\u6839\u636e\u5b83\u4eec\u5728\u5143\u7ec4\u4e2d\u7684\u4f4d\u7f6e\u81ea\u52a8\u5206\u914d\u7ed9\u5de6\u8fb9\u7684\u53d8\u91cf\u3002 \u8fd9\u5728 Python \u4e2d\u901a\u5e38\u79f0\u4e3a\u5143\u7ec4\u89e3\u5305\u3002 \u5982\u4e0b\u793a\u4f8b\uff1a >>> (a, b, c) = (1, 2, 3) >>> a 1 >>> b 2 >>> c 3 >>> birthday = ('April', 5, 2001) >>> month, day, year = birthday >>> month 'April' >>> day 5 >>> year 2001 \u5143\u7ec4\u89e3\u5305\u529f\u80fd\u5728 Python \u4e2d\u53ef\u4ee5\u6269\u5c55\u4e3a\u9002\u7528\u4e8e\u4efb\u4f55\u53ef\u8fed\u4ee3\u5bf9\u8c61\u3002 \u552f\u4e00\u7684\u8981\u6c42\u662f\u53ef\u8fed\u4ee3\u7684\u63a5\u6536\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u6070\u597d\u5bf9\u5e94\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u4e00\u4e2a\u5143\u7d20\uff08item\uff09\u3002 \u4e0b\u9762\u7684\u793a\u4f8b\u4ecb\u7ecd\u4e86 Python \u4e2d\u53ef\u8fed\u4ee3\u89e3\u5305\u7684\u5de5\u4f5c\u539f\u7406\uff1a >>> # Unpackage strings >>> a, b, c = '123' >>> a '1' >>> b '2' >>> c '3' >>> # Unpacking lists >>> a, b, c = [1, 2, 3] >>> a 1 >>> b 2 >>> c 3 >>> # Unpacking generators >>> gen = (i ** 2 for i in range(3)) >>> a, b, c = gen >>> a 0 >>> b 1 >>> c 4 >>> # Upacking dictionaries (keys, values, and items) >>> my_dict = {'one': 1, 'two': 2, 'three': 3} >>> a, b, c = my_dict >>> a 'one' >>> b 'two' >>> c 'three' >>> a, b, c = my_dict.values() >>> a 1 >>> b 2 >>> c 3 >>> a, b, c = my_dict.items() >>> a ('one', 1) >>> b ('two', 2) >>> c ('three', 3) >>> # Use a tuple on the right side of assignment statement >>> [a, b, c] = 1, 2, 3 >>> a 1 >>> b 2 >>> c 3 >>> # Use range() iterator >>> x, y, z = range(3) >>> x 0 >>> y 1 >>> z 2 \u6253\u5305Packing \u6253\u5305\u53ef\u4ee5\u7406\u89e3\u4e3a\u4f7f\u7528\u53ef\u8fed\u4ee3\u89e3\u5305\u8fd0\u7b97\u7b26\u5728\u5355\u4e2a\u53d8\u91cf\u4e2d\u6536\u96c6\u591a\u4e2a\u503c\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c * \u8fd0\u7b97\u7b26\u88ab\u79f0\u4e3a\u5143\u7ec4\uff08\u6216\u53ef\u8fed\u4ee3\uff09\u89e3\u5305\u8fd0\u7b97\u7b26\u3002 \u5b83\u6269\u5c55\u4e86\u89e3\u5305\u529f\u80fd\uff0c\u5141\u8bb8\u5728\u5355\u4e2a\u53d8\u91cf\u4e2d\u6536\u96c6\u6216\u6253\u5305\u591a\u4e2a\u503c\u3002 \u5728\u4ee5\u4e0b\u793a\u4f8b\u4e2d\u53ef\u4ee5\u770b\u5230 * \u8fd0\u7b97\u7b26\u5c06\u5143\u7ec4\u503c\u6253\u5305\u5230\u5355\u4e2a\u53d8\u91cf\u4e2d\uff1a >>> # The right side is a tuple, the left side is a list >>> *a, = 1, 2 >>> a [1, 2] >>> type(a) <class 'list'> \u5728\u4e0a\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u8d4b\u503c\u7684\u5de6\u4fa7\u5fc5\u987b\u662f\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\uff0c\u8fd9\u5c31\u662f\u4f7f\u7528\u5c3e\u968f\u9017\u53f7\u7684\u539f\u56e0\u3002\u8fd9\u4e2a\u5143\u7ec4\u53ef\u4ee5\u5305\u542b\u6240\u9700\u8981\u7684\u5c3d\u53ef\u80fd\u591a\u7684\u53d8\u91cf\uff0c\u4f46\u662f\uff0c\u5b83\u53ea\u80fd\u5305\u542b\u4e00\u4e2a\u661f\u53f7\u8868\u8fbe\u5f0f(starred expression)\u3002 >>> # Packing trailing values >>> a, *b = 1, 2, 3 >>> a 1 >>> b [2, 3] >>> type(a) <class 'int'> >>> type(b) <class 'list'> >>> >>> *a, b, c = 1, 2, 3 >>> a [1] >>> b 2 >>> c 3 >>> *a, b, c, d, e = 1, 2, 3 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: not enough values to unpack (expected at least 4, got 3) >>> *a, b, c, d = 1, 2, 3 >>> a [] >>> b 1 >>> c 2 >>> d 3 >>> >>> seq = [1, 2, 3, 4] >>> first, *body, last = seq >>> first, body, last (1, [2, 3], 4) >>> first, body, *last = seq >>> first, body, last (1, 2, [3, 4]) >>> >>> ran = range(10) >>> *r, = ran >>> r [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u4e0b\u9762\u662f\u4e00\u4e9b\u6253\u5305\u548c\u89e3\u5305\u7684\u4f8b\u5b50\u3002 >>> employee = ['John Doe', '40', 'Software Engineer'] >>> name = employee[0] >>> age = employee[1] >>> job = employee[2] >>> name 'John Doe' >>> age '40' >>> job 'Software Engineer' >>> >>> name, age, job = ['John Doe', '40', 'Software Engineer'] >>> name 'John Doe' >>> age '40' >>> job 'Software Engineer' >>> >>> a = 100 >>> b = 200 >>> a, b = b, a >>> a 200 >>> b 100 \u4f7f\u7528 * \u5220\u9664\u4e0d\u9700\u8981\u7684\u503c\u3002 >>> a, b, *_ = 1, 2, 0, 0, 0, 0 >>> a 1 >>> b 2 >>> _ [0, 0, 0, 0] \u5728\u4e0a\u4f8b\u4e2d\uff0c\u4e0d\u9700\u8981\u7684\u4fe1\u606f\u5b58\u50a8\u5728\u865a\u62df\u53d8\u91cf _ \u4e2d\uff0c\u5728\u540e\u7eed\u7684\u4f7f\u7528\u4e2d\u53ef\u4ee5\u5ffd\u7565\u5b83\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cPython \u89e3\u91ca\u5668\u4f7f\u7528\u4e0b\u5212\u7ebf\u5b57\u7b26 _ \u6765\u5b58\u50a8\u5728\u4ea4\u4e92\u5f0f\u4f1a\u8bdd\u4e2d\u8fd0\u884c\u7684\u8bed\u53e5\u7684\u7ed3\u679c\u503c\u3002 \u56e0\u6b64\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u8fd9\u4e2a\u5b57\u7b26\u6765\u8bc6\u522b\u865a\u62df\u53d8\u91cf\u53ef\u80fd\u662f\u6a21\u68f1\u4e24\u53ef\u7684\u3002 \u5728\u51fd\u6570\u4e2d\u8fd4\u56de\u5143\u7ec4\u3002 >>> def powers(num): ... return num, num ** 2, num ** 3 ... >>> # Packaging returned values in a tuple >>> result = powers(3) >>> result (3, 9, 27) >>> # Unpacking returned values to multiple variables >>> number, square, cube = powers(3) >>> number 3 >>> square 9 >>> cube 27 >>> *_, cube = powers(3) >>> cube 27 \u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26 \u4f7f\u7528 * \u8fd0\u7b97\u7b26\u5408\u5e76\u8fed\u4ee3\u53d8\u91cf\uff08iterables\uff09\u3002\u4e0a\u9762\u4e24\u4e2a\u4f8b\u5b50\u8bf4\u660e\uff0c\u8fd9\u4e2d\u65b9\u6cd5\u4e5f\u662f\u8fde\u63a5\u8fed\u4ee3\u53d8\u91cf\uff08iterables\uff09\u7684\u4e00\u79cd\u66f4\u6613\u8bfb\u548c\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002 \u8fd9\u4e2a\u65b9\u6cd5 (my_set) + my_list + list(my_tuple) + list(range(1, 4)) + list(my_str) \u53ef\u4ee5\u751f\u6210\u4e00\u4e2a\u5217\u8868 \uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u66f4\u7b80\u6d01\u7684\u65b9\u6cd5 [*my_set, *my_list, *my_tuple, *range(1, 4), *my_str] \u3002 >>> my_tuple = (1, 2, 3) >>> (0, *my_tuple, 4) (0, 1, 2, 3, 4) >>> my_list = [1, 2, 3] >>> [0, *my_list, 4] [0, 1, 2, 3, 4] >>> my_set = {1, 2, 3} >>> {0, *my_set, 4} {0, 1, 2, 3, 4} >>> [*my_set, *my_list, *my_tuple, *range(1, 4)] [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] >>> my_str = \"123\" >>> [*my_set, *my_list, *my_tuple, *range(1, 4), *my_str] [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, '1', '2', '3'] \u4f7f\u7528 ** \u8fd0\u7b97\u7b26\u89e3\u5305\u5b57\u5178\u3002 >>> numbers = {'one': 1, 'two': 2, 'three': 3} >>> letters = {'a': 'A', 'b': 'B', 'c': 'C'} >>> combination = {**numbers, **letters} >>> combination {'one': 1, 'two': 2, 'three': 3, 'a': 'A', 'b': 'B', 'c': 'C'} \u9700\u8981\u6ce8\u610f\u7684\u91cd\u8981\u4e00\u70b9\u662f\uff0c\u5982\u679c\u6211\u4eec\u5408\u5e76\u7684\u5b57\u5178\u5177\u6709\u91cd\u590d\u952e\u6216\u516c\u5171\u952e\uff0c\u5219\u6700\u53f3\u4fa7\u5b57\u5178\u7684\u503c\u5c06\u8986\u76d6\u6700\u5de6\u4fa7\u5b57\u5178\u7684\u503c\u3002\u4f8b\u5982: >>> letters = {'a': 'A', 'b': 'B', 'c': 'C'} >>> vowels = {'a': 'a', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u'} >>> {**letters, **vowels} {'a': 'a', 'b': 'B', 'c': 'C', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u'} >>> {**vowels, **letters} {'a': 'A', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u', 'b': 'B', 'c': 'C'} \u901a\u8fc7 For-Loops \u89e3\u5305 \u6211\u4eec\u8fd8\u53ef\u4ee5\u5728 for \u5faa\u73af\u7684\u4e0a\u4e0b\u6587\u4e2d\u4f7f\u7528\u53ef\u8fed\u4ee3\u89e3\u5305\u3002 \u5f53\u6211\u4eec\u8fd0\u884c for \u5faa\u73af\u65f6\uff0c\u5728\u6bcf\u6b21\u5faa\u73af\u8fed\u4ee3\u4e2d\u5c06\u5176\u53ef\u8fed\u4ee3\u5bf9\u8c61\u4e2d\u7684\u4e00\u9879(item)\u5206\u914d\u7ed9\u76ee\u6807\u53d8\u91cf\u3002 \u5982\u679c\u8981\u5206\u914d\u7684\u9879(item)\u662f\u53ef\u8fed\u4ee3\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5143\u7ec4\u4f5c\u4e3a\u76ee\u6807\u53d8\u91cf\uff0c\u901a\u8fc7\u5faa\u73af\u5c06\u53ef\u8fed\u4ee3\u5bf9\u8c61\u89e3\u5305\u5230\u76ee\u6807\u53d8\u91cf\u7684\u5143\u7ec4\u4e2d\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u5143\u7d20\u7684\u5143\u7ec4\u7684\u5217\u8868\u3002 \u6bcf\u4e2a\u5143\u7ec4\u5c06\u5305\u542b\u4ea7\u54c1\u540d\u79f0\u3001\u4ef7\u683c\u548c\u9500\u552e\u5355\u4f4d\uff0c\u6211\u4eec\u901a\u8fc7 for \u5faa\u73af\u904d\u5386\u6bcf\u4e2a\u5143\u7ec4\u5143\u7d20\u6765\u8ba1\u7b97\u6bcf\u4e2a\u4ea7\u54c1\u7684\u6536\u5165\u3002 >>> sales = [('Pencle', 0.22, 1500), ('Notebook', 1.30, 550), ('Eraser', 0.75, 1000)] >>> for items in sales: ... print(f\"Income for {items[0]} is: {items[1] * items[2]}\") ... Income for Pencle is: 330.0 Income for Notebook is: 715.0 Income for Eraser is: 750.0 \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u6765\u8bbf\u95ee\u6bcf\u4e2a\u5143\u7ec4\u7684\u5404\u4e2a\u5143\u7d20\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u4ee3\u7801\u4e2d\uff0c\u5728 for \u5faa\u73af\u4f7f\u7528\u89e3\u5305\uff0c\u8fd9\u4e5f\u662f Python \u4e2d\u89e3\u5305\u7684\u4e00\u79cd\u5b9e\u73b0\u3002 >>> sales = [('Pencle', 0.22, 1500), ('Notebook', 1.30, 550), ('Eraser', 0.75, 1000)] >>> for product, price, sold_units in sales: ... print(f\"Income for {product} is: {price * sold_units}\") ... Income for Pencle is: 330.0 Income for Notebook is: 715.0 Income for Eraser is: 750.0 \u4e5f\u53ef\u4ee5\u5728 for \u5faa\u73af\u4e2d\u4f7f\u7528 * \u8fd0\u7b97\u7b26\u5c06\u591a\u4e2a\u9879\u6253\u5305\u5230\u5355\u4e2a\u76ee\u6807\u53d8\u91cf\u4e2d\u3002 \u5728\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u53d6\u5f97\u6bcf\u4e2a\u5e8f\u5217\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u3002 \u5176\u4f59\u503c\u901a\u8fc7 * \u8fd0\u7b97\u7b26\u8d4b\u7ed9\u76ee\u6807\u53d8\u91cf rest\u3002 >>> for first, *rest in [(1, 2, 3),(4, 5, 6)]: ... print('First: ', first) ... print('Rest: ', rest) ... First: 1 Rest: [2, 3] First: 4 Rest: [5, 6] >>> \u76ee\u6807\u53d8\u91cf\u7684\u7ed3\u6784\u5fc5\u987b\u4e0e\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u7ed3\u6784\u4e00\u81f4\uff0c\u5426\u5219\u4f1a\u62a5\u9519\u3002\u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u3002 >>> data = [((1, 2), 3), ((2, 3), 3)] >>> for (a, b), c in data: ... print(a, b, c) ... 1 2 3 2 3 3 >>> for a, b, c in data: ... print(a, b, c) ... Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: not enough values to unpack (expected 3, got 2) \u7528 * \u548c ** \u5b9a\u4e49\u51fd\u6570 \u4e0b\u9762\u4f8b\u5b50\u4e2d\u7684\u51fd\u6570func\u81f3\u5c11\u9700\u8981\u4e00\u4e2a\u540d\u4e3a\u201crequired\u201d\u7684\u53c2\u6570\u3002 \u5b83\u4e5f\u53ef\u4ee5\u63a5\u53d7\u4e00\u4e2a\u6216\u591a\u4e2a\u4f4d\u7f6e\u53c2\u6570\u6216\u5173\u952e\u5b57\u53c2\u6570\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c * \u8fd0\u7b97\u7b26\u5728\u4e00\u4e2a\u53eb args \u7684\u5143\u7ec4\u4e2d\u6536\u96c6\u6216\u6253\u5305\u989d\u5916\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u800c ** \u8fd0\u7b97\u7b26\u5728\u4e00\u4e2a\u53eb kwargs \u7684\u5b57\u5178\u4e2d\u6536\u96c6\u6216\u6253\u5305\u989d\u5916\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 args \u548c kwargs \u90fd\u662f\u53ef\u9009\u7684\uff0c\u5e76\u4e14\u5206\u522b\u81ea\u52a8\u9ed8\u8ba4\u4e3a\u5143\u7ec4()\u548c\u5b57\u5178{}\u3002 \u8fd9\u91cc args \u548c kwargs \u7684\u547d\u540d\u5e76\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u8bed\u6cd5\u4e0a\u53ea\u9700\u8981 * \u6216 ** \u540e\u8ddf\u6709\u6548\u6807\u8bc6\u7b26\u5373\u53ef\uff0c\u5efa\u8bae\u7ed9\u53d8\u91cf\u8d77\u4e2a\u6709\u610f\u4e49\u7684\u540d\u5b57\uff0c\u63d0\u9ad8\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u3002 >>> def func(required, *args, **kwargs): ... print(required) ... print(args) ... print(kwargs) ... >>> func('Welcome to ...', 1, 2, 3, site='CloudAcademy.com') Welcome to ... (1, 2, 3) {'site': 'CloudAcademy.com'} >>> func('Welcome to ...', 1, 2, 3, 4) Welcome to ... (1, 2, 3, 4) {} >>> func('Welcome to ...', 1, 2, 3, (1, 2)) Welcome to ... (1, 2, 3, (1, 2)) {} >>> func('Welcome to ...', 1, 2, 3, [1, 2]) Welcome to ... (1, 2, 3, [1, 2]) {} >>> func('Welcome to ...', 1, 2, 3, ([2, 3], [1, 2])) Welcome to ... (1, 2, 3, ([2, 3], [1, 2])) {} \u4f7f\u7528 * \u548c ** \u8c03\u7528\u51fd\u6570 \u8c03\u7528\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u53d7\u76ca\u4e8e\u4f7f\u7528 * \u548c \u8fd0\u7b97\u7b26\u5c06\u53c2\u6570\u96c6\u5408\u5206\u522b\u89e3\u538b\u7f29\u4e3a\u5355\u72ec\u7684\u4f4d\u7f6e\u53c2\u6570\u6216\u5173\u952e\u5b57\u53c2\u6570\u3002 \u8fd9\u4e0e\u5728\u51fd\u6570\u7b7e\u540d(signature of a function)\u4e2d\u4f7f\u7528 * \u548c \u662f\u76f8\u53cd\u7684\u3002 \u5728\u51fd\u6570\u7b7e\u540d\u4e2d\uff0c\u8fd0\u7b97\u7b26\u7684\u610f\u601d\u662f\u5728\u4e00\u4e2a\u6807\u8bc6\u7b26\u4e2d\u6536\u96c6\u6216\u6253\u5305\u53ef\u53d8\u6570\u91cf\u7684\u53c2\u6570\u3002 \u5728\u8c03\u7528(calling)\u4e2d\uff0c\u5b83\u4eec\u7684\u610f\u601d\u662f\u89e3\u5305(unpack)\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5230\u591a\u4e2a\u53c2\u6570\u4e2d\u3002 \u7eed\u4e0a\u4f8b\uff0c \u8fd0\u7b97\u7b26\u5c06\u50cf [\"Welcome\", \"to\"] \u8fd9\u6837\u7684\u5e8f\u5217\u89e3\u5305\u5230\u4f4d\u7f6e\u53c2\u6570\u4e2d\u3002 \u7c7b\u4f3c\u5730\uff0c * \u8fd0\u7b97\u7b26\u5c06\u5b57\u5178\u89e3\u5305\u4e3a\u4e0e\u5b57\u5178\u7684\u952e\u503c\u5339\u914d\u7684\u53c2\u6570\u540d\u3002 >>> def func(welcome, to, site): ... print(welcome, to, site) ... >>> func(*['Welcome', 'to'], **{'site': 'CloudAcademy.com'}) Welcome to CloudAcademy.com \u7efc\u5408\u8fd0\u7528\u524d\u9762\u7684\u65b9\u6cd5\u6765\u7f16\u5199\u975e\u5e38\u7075\u6d3b\u7684\u51fd\u6570\uff0c\u6bd4\u5982\uff0c\u5728\u5b9a\u4e49\u548c\u8c03\u7528 Python \u51fd\u6570\u65f6\uff0c\u66f4\u7075\u6d3b\u7684\u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26\u3002 \u4f8b\u5982\uff1a >>> def func(required, *args, **kwargs): ... print(required) ... print(args) ... print(kwargs) ... >>> func('Welcome to...', *(1, 2, 3), **{'Site': 'CloudAcademy.com'}) Welcome to... (1, 2, 3) {'Site': 'CloudAcademy.com'} \u603b\u7ed3 \u53ef\u8fed\u4ee3\u89e3\u5305\uff08iterable unpacking\uff09\u8fd9\u4e2a\u7279\u6027\u5141\u8bb8\u6211\u4eec\u5c06\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u89e3\u5305\u6210\u51e0\u4e2a\u53d8\u91cf\u3002 \u53e6\u4e00\u65b9\u9762\uff0c\u6253\u5305\u5305\u62ec\u4f7f\u7528\u89e3\u5305\u8fd0\u7b97\u7b26 * \u5c06\u591a\u4e2a\u503c\u8d4b\u5230\u4e00\u4e2a\u53d8\u91cf\u4e2d\u3002 \u53ef\u8fed\u4ee3\u89e3\u5305\uff08iterable unpacking\uff09\u4e5f\u53ef\u4ee5\u7528\u6765\u8fdb\u884c\u5e76\u884c\u8d4b\u503c\u548c\u53d8\u91cf\u4e4b\u95f4\u7684\u503c\u4ea4\u6362\uff0c\u4e5f\u53ef\u4ee5\u7528\u5728 for \u5faa\u73af\u3001\u51fd\u6570\u8c03\u7528\u548c\u51fd\u6570\u5b9a\u4e49\u4e2d\u3002","title":"Python\u4e2d\u7684\u6253\u5305Packing\u548c\u89e3\u5305Unpacking"},{"location":"python/Foundation/ch02/#pythonpackingunpacking","text":"","title":"Python\u4e2d\u7684\u6253\u5305Packing\u548c\u89e3\u5305Unpacking"},{"location":"python/Foundation/ch02/#unpacking","text":"Python \u5141\u8bb8\u53d8\u91cf\u7684\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u51fa\u73b0\u5728\u8d4b\u503c\u64cd\u4f5c\u7684\u5de6\u4fa7\u3002 \u5143\u7ec4\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u90fd\u53ef\u4ee5\u4ece\u8d4b\u503c\u53f3\u4fa7\u7684\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff08iterable\uff09\u4e2d\u63a5\u6536\u4e00\u4e2a\u503c\uff08\u6216\u8005\u66f4\u591a\uff0c\u5982\u679c\u6211\u4eec\u4f7f\u7528 * \u8fd0\u7b97\u7b26\uff09\u3002 Python \u4e2d\u7684\u89e3\u5305\u662f\u6307\u4e00\u79cd\u64cd\u4f5c\uff0c\u8be5\u64cd\u4f5c\u5305\u62ec\u5728\u5355\u4e2a\u8d4b\u503c\u8bed\u53e5\u4e2d\u5c06\u53ef\u8fed\u4ee3\u7684\u503c\u5206\u914d\u7ed9\u53d8\u91cf\u7684\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u3002 \u5728 Python \u4e2d\uff0c\u53ef\u4ee5\u5728\u8d4b\u503c\u8fd0\u7b97\u7b26 (=) \u7684\u5de6\u4fa7\u653e\u7f6e\u4e00\u4e2a\u53d8\u91cf\u5143\u7ec4\uff0c\u5728\u53f3\u4fa7\u653e\u7f6e\u4e00\u4e2a\u503c\u5143\u7ec4\u3002 \u53f3\u8fb9\u7684\u503c\u5c06\u6839\u636e\u5b83\u4eec\u5728\u5143\u7ec4\u4e2d\u7684\u4f4d\u7f6e\u81ea\u52a8\u5206\u914d\u7ed9\u5de6\u8fb9\u7684\u53d8\u91cf\u3002 \u8fd9\u5728 Python \u4e2d\u901a\u5e38\u79f0\u4e3a\u5143\u7ec4\u89e3\u5305\u3002 \u5982\u4e0b\u793a\u4f8b\uff1a >>> (a, b, c) = (1, 2, 3) >>> a 1 >>> b 2 >>> c 3 >>> birthday = ('April', 5, 2001) >>> month, day, year = birthday >>> month 'April' >>> day 5 >>> year 2001 \u5143\u7ec4\u89e3\u5305\u529f\u80fd\u5728 Python \u4e2d\u53ef\u4ee5\u6269\u5c55\u4e3a\u9002\u7528\u4e8e\u4efb\u4f55\u53ef\u8fed\u4ee3\u5bf9\u8c61\u3002 \u552f\u4e00\u7684\u8981\u6c42\u662f\u53ef\u8fed\u4ee3\u7684\u63a5\u6536\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u6070\u597d\u5bf9\u5e94\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u4e00\u4e2a\u5143\u7d20\uff08item\uff09\u3002 \u4e0b\u9762\u7684\u793a\u4f8b\u4ecb\u7ecd\u4e86 Python \u4e2d\u53ef\u8fed\u4ee3\u89e3\u5305\u7684\u5de5\u4f5c\u539f\u7406\uff1a >>> # Unpackage strings >>> a, b, c = '123' >>> a '1' >>> b '2' >>> c '3' >>> # Unpacking lists >>> a, b, c = [1, 2, 3] >>> a 1 >>> b 2 >>> c 3 >>> # Unpacking generators >>> gen = (i ** 2 for i in range(3)) >>> a, b, c = gen >>> a 0 >>> b 1 >>> c 4 >>> # Upacking dictionaries (keys, values, and items) >>> my_dict = {'one': 1, 'two': 2, 'three': 3} >>> a, b, c = my_dict >>> a 'one' >>> b 'two' >>> c 'three' >>> a, b, c = my_dict.values() >>> a 1 >>> b 2 >>> c 3 >>> a, b, c = my_dict.items() >>> a ('one', 1) >>> b ('two', 2) >>> c ('three', 3) >>> # Use a tuple on the right side of assignment statement >>> [a, b, c] = 1, 2, 3 >>> a 1 >>> b 2 >>> c 3 >>> # Use range() iterator >>> x, y, z = range(3) >>> x 0 >>> y 1 >>> z 2","title":"\u89e3\u5305Unpacking"},{"location":"python/Foundation/ch02/#packing","text":"\u6253\u5305\u53ef\u4ee5\u7406\u89e3\u4e3a\u4f7f\u7528\u53ef\u8fed\u4ee3\u89e3\u5305\u8fd0\u7b97\u7b26\u5728\u5355\u4e2a\u53d8\u91cf\u4e2d\u6536\u96c6\u591a\u4e2a\u503c\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c * \u8fd0\u7b97\u7b26\u88ab\u79f0\u4e3a\u5143\u7ec4\uff08\u6216\u53ef\u8fed\u4ee3\uff09\u89e3\u5305\u8fd0\u7b97\u7b26\u3002 \u5b83\u6269\u5c55\u4e86\u89e3\u5305\u529f\u80fd\uff0c\u5141\u8bb8\u5728\u5355\u4e2a\u53d8\u91cf\u4e2d\u6536\u96c6\u6216\u6253\u5305\u591a\u4e2a\u503c\u3002 \u5728\u4ee5\u4e0b\u793a\u4f8b\u4e2d\u53ef\u4ee5\u770b\u5230 * \u8fd0\u7b97\u7b26\u5c06\u5143\u7ec4\u503c\u6253\u5305\u5230\u5355\u4e2a\u53d8\u91cf\u4e2d\uff1a >>> # The right side is a tuple, the left side is a list >>> *a, = 1, 2 >>> a [1, 2] >>> type(a) <class 'list'> \u5728\u4e0a\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u8d4b\u503c\u7684\u5de6\u4fa7\u5fc5\u987b\u662f\u5143\u7ec4\uff08\u6216\u5217\u8868\uff09\uff0c\u8fd9\u5c31\u662f\u4f7f\u7528\u5c3e\u968f\u9017\u53f7\u7684\u539f\u56e0\u3002\u8fd9\u4e2a\u5143\u7ec4\u53ef\u4ee5\u5305\u542b\u6240\u9700\u8981\u7684\u5c3d\u53ef\u80fd\u591a\u7684\u53d8\u91cf\uff0c\u4f46\u662f\uff0c\u5b83\u53ea\u80fd\u5305\u542b\u4e00\u4e2a\u661f\u53f7\u8868\u8fbe\u5f0f(starred expression)\u3002 >>> # Packing trailing values >>> a, *b = 1, 2, 3 >>> a 1 >>> b [2, 3] >>> type(a) <class 'int'> >>> type(b) <class 'list'> >>> >>> *a, b, c = 1, 2, 3 >>> a [1] >>> b 2 >>> c 3 >>> *a, b, c, d, e = 1, 2, 3 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: not enough values to unpack (expected at least 4, got 3) >>> *a, b, c, d = 1, 2, 3 >>> a [] >>> b 1 >>> c 2 >>> d 3 >>> >>> seq = [1, 2, 3, 4] >>> first, *body, last = seq >>> first, body, last (1, [2, 3], 4) >>> first, body, *last = seq >>> first, body, last (1, 2, [3, 4]) >>> >>> ran = range(10) >>> *r, = ran >>> r [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u4e0b\u9762\u662f\u4e00\u4e9b\u6253\u5305\u548c\u89e3\u5305\u7684\u4f8b\u5b50\u3002 >>> employee = ['John Doe', '40', 'Software Engineer'] >>> name = employee[0] >>> age = employee[1] >>> job = employee[2] >>> name 'John Doe' >>> age '40' >>> job 'Software Engineer' >>> >>> name, age, job = ['John Doe', '40', 'Software Engineer'] >>> name 'John Doe' >>> age '40' >>> job 'Software Engineer' >>> >>> a = 100 >>> b = 200 >>> a, b = b, a >>> a 200 >>> b 100 \u4f7f\u7528 * \u5220\u9664\u4e0d\u9700\u8981\u7684\u503c\u3002 >>> a, b, *_ = 1, 2, 0, 0, 0, 0 >>> a 1 >>> b 2 >>> _ [0, 0, 0, 0] \u5728\u4e0a\u4f8b\u4e2d\uff0c\u4e0d\u9700\u8981\u7684\u4fe1\u606f\u5b58\u50a8\u5728\u865a\u62df\u53d8\u91cf _ \u4e2d\uff0c\u5728\u540e\u7eed\u7684\u4f7f\u7528\u4e2d\u53ef\u4ee5\u5ffd\u7565\u5b83\u3002 \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cPython \u89e3\u91ca\u5668\u4f7f\u7528\u4e0b\u5212\u7ebf\u5b57\u7b26 _ \u6765\u5b58\u50a8\u5728\u4ea4\u4e92\u5f0f\u4f1a\u8bdd\u4e2d\u8fd0\u884c\u7684\u8bed\u53e5\u7684\u7ed3\u679c\u503c\u3002 \u56e0\u6b64\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u8fd9\u4e2a\u5b57\u7b26\u6765\u8bc6\u522b\u865a\u62df\u53d8\u91cf\u53ef\u80fd\u662f\u6a21\u68f1\u4e24\u53ef\u7684\u3002 \u5728\u51fd\u6570\u4e2d\u8fd4\u56de\u5143\u7ec4\u3002 >>> def powers(num): ... return num, num ** 2, num ** 3 ... >>> # Packaging returned values in a tuple >>> result = powers(3) >>> result (3, 9, 27) >>> # Unpacking returned values to multiple variables >>> number, square, cube = powers(3) >>> number 3 >>> square 9 >>> cube 27 >>> *_, cube = powers(3) >>> cube 27","title":"\u6253\u5305Packing"},{"location":"python/Foundation/ch02/#_1","text":"\u4f7f\u7528 * \u8fd0\u7b97\u7b26\u5408\u5e76\u8fed\u4ee3\u53d8\u91cf\uff08iterables\uff09\u3002\u4e0a\u9762\u4e24\u4e2a\u4f8b\u5b50\u8bf4\u660e\uff0c\u8fd9\u4e2d\u65b9\u6cd5\u4e5f\u662f\u8fde\u63a5\u8fed\u4ee3\u53d8\u91cf\uff08iterables\uff09\u7684\u4e00\u79cd\u66f4\u6613\u8bfb\u548c\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002 \u8fd9\u4e2a\u65b9\u6cd5 (my_set) + my_list + list(my_tuple) + list(range(1, 4)) + list(my_str) \u53ef\u4ee5\u751f\u6210\u4e00\u4e2a\u5217\u8868 \uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u66f4\u7b80\u6d01\u7684\u65b9\u6cd5 [*my_set, *my_list, *my_tuple, *range(1, 4), *my_str] \u3002 >>> my_tuple = (1, 2, 3) >>> (0, *my_tuple, 4) (0, 1, 2, 3, 4) >>> my_list = [1, 2, 3] >>> [0, *my_list, 4] [0, 1, 2, 3, 4] >>> my_set = {1, 2, 3} >>> {0, *my_set, 4} {0, 1, 2, 3, 4} >>> [*my_set, *my_list, *my_tuple, *range(1, 4)] [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] >>> my_str = \"123\" >>> [*my_set, *my_list, *my_tuple, *range(1, 4), *my_str] [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, '1', '2', '3'] \u4f7f\u7528 ** \u8fd0\u7b97\u7b26\u89e3\u5305\u5b57\u5178\u3002 >>> numbers = {'one': 1, 'two': 2, 'three': 3} >>> letters = {'a': 'A', 'b': 'B', 'c': 'C'} >>> combination = {**numbers, **letters} >>> combination {'one': 1, 'two': 2, 'three': 3, 'a': 'A', 'b': 'B', 'c': 'C'} \u9700\u8981\u6ce8\u610f\u7684\u91cd\u8981\u4e00\u70b9\u662f\uff0c\u5982\u679c\u6211\u4eec\u5408\u5e76\u7684\u5b57\u5178\u5177\u6709\u91cd\u590d\u952e\u6216\u516c\u5171\u952e\uff0c\u5219\u6700\u53f3\u4fa7\u5b57\u5178\u7684\u503c\u5c06\u8986\u76d6\u6700\u5de6\u4fa7\u5b57\u5178\u7684\u503c\u3002\u4f8b\u5982: >>> letters = {'a': 'A', 'b': 'B', 'c': 'C'} >>> vowels = {'a': 'a', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u'} >>> {**letters, **vowels} {'a': 'a', 'b': 'B', 'c': 'C', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u'} >>> {**vowels, **letters} {'a': 'A', 'e': 'e', 'i': 'i', 'o': 'o', 'u': 'u', 'b': 'B', 'c': 'C'}","title":"\u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26"},{"location":"python/Foundation/ch02/#for-loops","text":"\u6211\u4eec\u8fd8\u53ef\u4ee5\u5728 for \u5faa\u73af\u7684\u4e0a\u4e0b\u6587\u4e2d\u4f7f\u7528\u53ef\u8fed\u4ee3\u89e3\u5305\u3002 \u5f53\u6211\u4eec\u8fd0\u884c for \u5faa\u73af\u65f6\uff0c\u5728\u6bcf\u6b21\u5faa\u73af\u8fed\u4ee3\u4e2d\u5c06\u5176\u53ef\u8fed\u4ee3\u5bf9\u8c61\u4e2d\u7684\u4e00\u9879(item)\u5206\u914d\u7ed9\u76ee\u6807\u53d8\u91cf\u3002 \u5982\u679c\u8981\u5206\u914d\u7684\u9879(item)\u662f\u53ef\u8fed\u4ee3\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5143\u7ec4\u4f5c\u4e3a\u76ee\u6807\u53d8\u91cf\uff0c\u901a\u8fc7\u5faa\u73af\u5c06\u53ef\u8fed\u4ee3\u5bf9\u8c61\u89e3\u5305\u5230\u76ee\u6807\u53d8\u91cf\u7684\u5143\u7ec4\u4e2d\u3002 \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u5143\u7d20\u7684\u5143\u7ec4\u7684\u5217\u8868\u3002 \u6bcf\u4e2a\u5143\u7ec4\u5c06\u5305\u542b\u4ea7\u54c1\u540d\u79f0\u3001\u4ef7\u683c\u548c\u9500\u552e\u5355\u4f4d\uff0c\u6211\u4eec\u901a\u8fc7 for \u5faa\u73af\u904d\u5386\u6bcf\u4e2a\u5143\u7ec4\u5143\u7d20\u6765\u8ba1\u7b97\u6bcf\u4e2a\u4ea7\u54c1\u7684\u6536\u5165\u3002 >>> sales = [('Pencle', 0.22, 1500), ('Notebook', 1.30, 550), ('Eraser', 0.75, 1000)] >>> for items in sales: ... print(f\"Income for {items[0]} is: {items[1] * items[2]}\") ... Income for Pencle is: 330.0 Income for Notebook is: 715.0 Income for Eraser is: 750.0 \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7d22\u5f15\u6765\u8bbf\u95ee\u6bcf\u4e2a\u5143\u7ec4\u7684\u5404\u4e2a\u5143\u7d20\u3002\u4e0b\u9762\u7684\u793a\u4f8b\u4ee3\u7801\u4e2d\uff0c\u5728 for \u5faa\u73af\u4f7f\u7528\u89e3\u5305\uff0c\u8fd9\u4e5f\u662f Python \u4e2d\u89e3\u5305\u7684\u4e00\u79cd\u5b9e\u73b0\u3002 >>> sales = [('Pencle', 0.22, 1500), ('Notebook', 1.30, 550), ('Eraser', 0.75, 1000)] >>> for product, price, sold_units in sales: ... print(f\"Income for {product} is: {price * sold_units}\") ... Income for Pencle is: 330.0 Income for Notebook is: 715.0 Income for Eraser is: 750.0 \u4e5f\u53ef\u4ee5\u5728 for \u5faa\u73af\u4e2d\u4f7f\u7528 * \u8fd0\u7b97\u7b26\u5c06\u591a\u4e2a\u9879\u6253\u5305\u5230\u5355\u4e2a\u76ee\u6807\u53d8\u91cf\u4e2d\u3002 \u5728\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u53d6\u5f97\u6bcf\u4e2a\u5e8f\u5217\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u3002 \u5176\u4f59\u503c\u901a\u8fc7 * \u8fd0\u7b97\u7b26\u8d4b\u7ed9\u76ee\u6807\u53d8\u91cf rest\u3002 >>> for first, *rest in [(1, 2, 3),(4, 5, 6)]: ... print('First: ', first) ... print('Rest: ', rest) ... First: 1 Rest: [2, 3] First: 4 Rest: [5, 6] >>> \u76ee\u6807\u53d8\u91cf\u7684\u7ed3\u6784\u5fc5\u987b\u4e0e\u53ef\u8fed\u4ee3\u5bf9\u8c61\u7684\u7ed3\u6784\u4e00\u81f4\uff0c\u5426\u5219\u4f1a\u62a5\u9519\u3002\u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u3002 >>> data = [((1, 2), 3), ((2, 3), 3)] >>> for (a, b), c in data: ... print(a, b, c) ... 1 2 3 2 3 3 >>> for a, b, c in data: ... print(a, b, c) ... Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: not enough values to unpack (expected 3, got 2)","title":"\u901a\u8fc7 For-Loops \u89e3\u5305"},{"location":"python/Foundation/ch02/#_2","text":"\u4e0b\u9762\u4f8b\u5b50\u4e2d\u7684\u51fd\u6570func\u81f3\u5c11\u9700\u8981\u4e00\u4e2a\u540d\u4e3a\u201crequired\u201d\u7684\u53c2\u6570\u3002 \u5b83\u4e5f\u53ef\u4ee5\u63a5\u53d7\u4e00\u4e2a\u6216\u591a\u4e2a\u4f4d\u7f6e\u53c2\u6570\u6216\u5173\u952e\u5b57\u53c2\u6570\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c * \u8fd0\u7b97\u7b26\u5728\u4e00\u4e2a\u53eb args \u7684\u5143\u7ec4\u4e2d\u6536\u96c6\u6216\u6253\u5305\u989d\u5916\u7684\u4f4d\u7f6e\u53c2\u6570\uff0c\u800c ** \u8fd0\u7b97\u7b26\u5728\u4e00\u4e2a\u53eb kwargs \u7684\u5b57\u5178\u4e2d\u6536\u96c6\u6216\u6253\u5305\u989d\u5916\u7684\u5173\u952e\u5b57\u53c2\u6570\u3002 args \u548c kwargs \u90fd\u662f\u53ef\u9009\u7684\uff0c\u5e76\u4e14\u5206\u522b\u81ea\u52a8\u9ed8\u8ba4\u4e3a\u5143\u7ec4()\u548c\u5b57\u5178{}\u3002 \u8fd9\u91cc args \u548c kwargs \u7684\u547d\u540d\u5e76\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u8bed\u6cd5\u4e0a\u53ea\u9700\u8981 * \u6216 ** \u540e\u8ddf\u6709\u6548\u6807\u8bc6\u7b26\u5373\u53ef\uff0c\u5efa\u8bae\u7ed9\u53d8\u91cf\u8d77\u4e2a\u6709\u610f\u4e49\u7684\u540d\u5b57\uff0c\u63d0\u9ad8\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u3002 >>> def func(required, *args, **kwargs): ... print(required) ... print(args) ... print(kwargs) ... >>> func('Welcome to ...', 1, 2, 3, site='CloudAcademy.com') Welcome to ... (1, 2, 3) {'site': 'CloudAcademy.com'} >>> func('Welcome to ...', 1, 2, 3, 4) Welcome to ... (1, 2, 3, 4) {} >>> func('Welcome to ...', 1, 2, 3, (1, 2)) Welcome to ... (1, 2, 3, (1, 2)) {} >>> func('Welcome to ...', 1, 2, 3, [1, 2]) Welcome to ... (1, 2, 3, [1, 2]) {} >>> func('Welcome to ...', 1, 2, 3, ([2, 3], [1, 2])) Welcome to ... (1, 2, 3, ([2, 3], [1, 2])) {}","title":"\u7528 * \u548c ** \u5b9a\u4e49\u51fd\u6570"},{"location":"python/Foundation/ch02/#_3","text":"\u8c03\u7528\u51fd\u6570\u65f6\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u53d7\u76ca\u4e8e\u4f7f\u7528 * \u548c \u8fd0\u7b97\u7b26\u5c06\u53c2\u6570\u96c6\u5408\u5206\u522b\u89e3\u538b\u7f29\u4e3a\u5355\u72ec\u7684\u4f4d\u7f6e\u53c2\u6570\u6216\u5173\u952e\u5b57\u53c2\u6570\u3002 \u8fd9\u4e0e\u5728\u51fd\u6570\u7b7e\u540d(signature of a function)\u4e2d\u4f7f\u7528 * \u548c \u662f\u76f8\u53cd\u7684\u3002 \u5728\u51fd\u6570\u7b7e\u540d\u4e2d\uff0c\u8fd0\u7b97\u7b26\u7684\u610f\u601d\u662f\u5728\u4e00\u4e2a\u6807\u8bc6\u7b26\u4e2d\u6536\u96c6\u6216\u6253\u5305\u53ef\u53d8\u6570\u91cf\u7684\u53c2\u6570\u3002 \u5728\u8c03\u7528(calling)\u4e2d\uff0c\u5b83\u4eec\u7684\u610f\u601d\u662f\u89e3\u5305(unpack)\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u5230\u591a\u4e2a\u53c2\u6570\u4e2d\u3002 \u7eed\u4e0a\u4f8b\uff0c \u8fd0\u7b97\u7b26\u5c06\u50cf [\"Welcome\", \"to\"] \u8fd9\u6837\u7684\u5e8f\u5217\u89e3\u5305\u5230\u4f4d\u7f6e\u53c2\u6570\u4e2d\u3002 \u7c7b\u4f3c\u5730\uff0c * \u8fd0\u7b97\u7b26\u5c06\u5b57\u5178\u89e3\u5305\u4e3a\u4e0e\u5b57\u5178\u7684\u952e\u503c\u5339\u914d\u7684\u53c2\u6570\u540d\u3002 >>> def func(welcome, to, site): ... print(welcome, to, site) ... >>> func(*['Welcome', 'to'], **{'site': 'CloudAcademy.com'}) Welcome to CloudAcademy.com \u7efc\u5408\u8fd0\u7528\u524d\u9762\u7684\u65b9\u6cd5\u6765\u7f16\u5199\u975e\u5e38\u7075\u6d3b\u7684\u51fd\u6570\uff0c\u6bd4\u5982\uff0c\u5728\u5b9a\u4e49\u548c\u8c03\u7528 Python \u51fd\u6570\u65f6\uff0c\u66f4\u7075\u6d3b\u7684\u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26\u3002 \u4f8b\u5982\uff1a >>> def func(required, *args, **kwargs): ... print(required) ... print(args) ... print(kwargs) ... >>> func('Welcome to...', *(1, 2, 3), **{'Site': 'CloudAcademy.com'}) Welcome to... (1, 2, 3) {'Site': 'CloudAcademy.com'}","title":"\u4f7f\u7528 * \u548c ** \u8c03\u7528\u51fd\u6570"},{"location":"python/Foundation/ch02/#_4","text":"\u53ef\u8fed\u4ee3\u89e3\u5305\uff08iterable unpacking\uff09\u8fd9\u4e2a\u7279\u6027\u5141\u8bb8\u6211\u4eec\u5c06\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\u89e3\u5305\u6210\u51e0\u4e2a\u53d8\u91cf\u3002 \u53e6\u4e00\u65b9\u9762\uff0c\u6253\u5305\u5305\u62ec\u4f7f\u7528\u89e3\u5305\u8fd0\u7b97\u7b26 * \u5c06\u591a\u4e2a\u503c\u8d4b\u5230\u4e00\u4e2a\u53d8\u91cf\u4e2d\u3002 \u53ef\u8fed\u4ee3\u89e3\u5305\uff08iterable unpacking\uff09\u4e5f\u53ef\u4ee5\u7528\u6765\u8fdb\u884c\u5e76\u884c\u8d4b\u503c\u548c\u53d8\u91cf\u4e4b\u95f4\u7684\u503c\u4ea4\u6362\uff0c\u4e5f\u53ef\u4ee5\u7528\u5728 for \u5faa\u73af\u3001\u51fd\u6570\u8c03\u7528\u548c\u51fd\u6570\u5b9a\u4e49\u4e2d\u3002","title":"\u603b\u7ed3"},{"location":"python/Foundation/ch03/","text":"\u5185\u7f6e\u51fd\u6570\u53ca\u6587\u4ef6 1. \u533f\u540d\uff08Lambda\uff09\u51fd\u6570 \u533f\u540d\u51fd\u6570\u662f\u4e00\u79cd\u901a\u8fc7\u5355\u4e2a\u8bed\u53e5\u751f\u6210\u51fd\u6570\u7684\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u662f\u8fd4\u56de\u503c\u3002\u533f\u540d\u51fd\u6570\u4f7f\u7528lambda\u5173\u952e\u5b57\u5b9a\u4e49\uff0c\u8be5\u5173\u952e\u5b57\u4ec5\u8868\u8fbe\u201c\u6211\u4eec\u58f0\u660e\u4e00\u4e2a\u533f\u540d\u51fd\u6570\u201d\u7684\u610f\u601d\u3002 lambda \u51fd\u6570\u53ef\u4ee5\u63a5\u6536\u4efb\u610f\u591a\u4e2a\u53c2\u6570 (\u5305\u62ec\u53ef\u9009\u53c2\u6570) \u5e76\u4e14\u8fd4\u56de\u5355\u4e2a\u8868\u8fbe\u5f0f\u7684\u503c\u3002 lambda arg1,arg2,arg3\u2026 :<\u8868\u8fbe\u5f0f> f = lambda x, y: x * y print(f(2, 3)) # 6 f = [lambda a: a * 2, lambda b: b * 3] print(f[0](5)) # \u6267\u884cf\u5217\u8868\u7b2c\u4e00\u4e2a\u5143\u7d20 # 10 print(f[1](5)) # \u6267\u884cf\u5143\u7d20\u7b2c\u4e8c\u4e2a\u5143\u7d20 # 15 print(f[0, 1](5, 5)) # TypeError: list indices must be integers or slices, not tuple \u793a\u4f8b1\uff1a def short_func1(x): return x * 2 short_func2 = lambda x: x * 2 print(short_func1(5)) # 10 print(short_func2(5)) # 10 \u793a\u4f8b2\uff1a def apply_to_list(some_list, f): return [f(x) for x in some_list] ints = [4, 0, 1, 5, 6] result5 = apply_to_list(ints, lambda x: x * 2) print(result5) # [8, 0, 2, 10, 12] lambda: None \u51fd\u6570\u6ca1\u6709\u8f93\u5165\u53c2\u6570\uff0c\u8f93\u51fa\u662fNone\u3002 print(lambda: None) # <function <lambda> at 0x7fa5c4097670> lambda **kwargs: 1 \u8f93\u5165\u662f\u4efb\u610f\u952e\u503c\u5bf9\u53c2\u6570\uff0c\u8f93\u51fa\u662f1\u3002 print(lambda **kwargs: 1) # <function <lambda> at 0x7fa5c4097670> 2. \u5185\u7f6e\u5e8f\u5217\u51fd\u6570enumerate \u5f53\u9700\u8981\u5bf9\u6570\u636e\u5efa\u7acb\u7d22\u5f15\u65f6\uff0c\u4e00\u79cd\u6709\u6548\u7684\u6a21\u5f0f\u5c31\u662f\u4f7f\u7528enumerate\u6784\u9020\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u5e8f\u5217\u503c\uff08\u5047\u8bbe\u662f\u552f\u4e00\u7684\uff09\u6620\u5c04\u5230\u7d22\u5f15\u4f4d\u7f6e\u4e0a\u3002 seasons = ['Spring', 'Summer', 'Fall', 'Winter'] print(list(enumerate(seasons))) # [(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')] \u5bf9\u6bd4\u4e0b\u97622\u4e2a\u5faa\u73af a_list = ['foo', 'bar', 'baz'] mapping = {} for i, v in enumerate(a_list): # enumerate\u751f\u6210\u7d22\u5f15\u503ci\u548c\u5e8f\u5217\u503cv mapping[v] = i print(mapping) # {'foo': 0, 'bar': 1, 'baz': 2} i = 0 mapping = {} for v in a_list: print(i, a_list[i]) mapping[v] = i # \u53ef\u4ee5\u628ai\u548cv\u4e92\u6362 i += 1 print(mapping) # {'foo': 0, 'bar': 1, 'baz': 2} \u5229\u7528 enumerate() \u6279\u91cf\u4fee\u6539\u5217\u8868\u5185\u7684\u5143\u7d20 a_list = ['01', '02', '03'] unit_element = '1' for i, element in enumerate(a_list): a_list[i] = unit_element + element print(a_list) # ['101', '102', '103'] sorted\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6839\u636e\u4efb\u610f\u5e8f\u5217\u4e2d\u7684\u5143\u7d20\u65b0\u5efa\u7684\u5df2\u6392\u5e8f\u5217\u8868\u3002sorted\u51fd\u6570\u63a5\u53d7\u7684\u53c2\u6570\u4e0e\u5217\u8868\u7684sort\u65b9\u6cd5\u4e00\u81f4\u3002 y = sorted([7, 1, 2, 6, 0, 3, 2]) print(y) # [0, 1, 2, 2, 3, 6, 7] \u7ed3\u679c\u5df2\u6392\u5e8f z = sorted('Hello World') print(z) # [' ', 'H', 'W', 'd', 'e', 'l', 'l', 'l', 'o', 'o', 'r'] zip\u5c06\u5217\u8868\u3001\u5143\u7ec4\u6216\u5176\u4ed6\u5e8f\u5217\u7684\u5143\u7d20\u914d\u5bf9\uff0c\u65b0\u5efa\u4e00\u4e2a\u5143\u7ec4\u6784\u6210\u7684\u5217\u8868\u3002 seq1 = ['foo', 'bar', 'baz'] seq2 = ['one', 'two', 'three'] seq3 = [False, True] zipped = zip(seq1, seq2) print(list(zipped)) # [('foo', 'one'), ('bar', 'two'), ('baz', 'three')] zipped = zip(seq1, seq2, seq3) print(list(zipped)) # [('foo', 'one', False), ('bar', 'two', True)] for i, (a, b) in enumerate(zip(seq1, seq2)): print('{0}: {1}, {2}'.format(i, a, b)) # \u65b9\u6cd51 {0}\u5217\u8868\u5143\u7d20\u7684\u7d22\u5f15, {1}\u5143\u7ec4\u4e2d\u7b2c\u4e00\u4e2a\u503c, {2}\u5143\u7ec4\u4e2d\u7b2c\u4e8c\u4e2a\u503c print(f'{i}: {a}, {b}') # \u65b9\u6cd52 # 0: foo, one # 1: bar, two # 2: baz, three \u7ed9\u5b9a\u4e00\u4e2a\u5df2\u201c\u914d\u5bf9\u201d\u7684\u5e8f\u5217\u65f6\uff0czip\u51fd\u6570\u53ef\u4ee5\u53bb\u201c\u62c6\u5206\u201d\u5e8f\u5217\u3002\u8fd9\u79cd\u65b9\u5f0f\u7684\u53e6\u4e00\u79cd\u601d\u8def\u5c31\u662f\u5c06\u884c\u7684\u5217\u8868\u8f6c\u6362\u4e3a\u5217\u7684\u5217\u8868\u3002\u53c2\u8003Python\u7684 Unpacking pitchers = [('Jack', 'Ma'), ('Tom', 'Li'), ('Jimmy', 'Zhang')] first_names, last_names = zip(*pitchers) print(first_names) # ('Jack', 'Tom', 'Jimmy') print(last_names) # ('Ma', 'Li', 'Zhang') reversed\u51fd\u6570\u5c06\u5e8f\u5217\u7684\u5143\u7d20\u5012\u5e8f\u6392\u5217 print(list(reversed(range(10)))) # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] 3. \u5217\u8868\u3001\u96c6\u5408\u548c\u5b57\u5178\u7684\u63a8\u5bfc\u5f0f \u63a8\u5bfc\u5f0fcomprehensions\uff08\u53c8\u79f0\u89e3\u6790\u5f0f\uff09\uff0c\u662fPython\u7684\u4e00\u79cd\u7279\u6027\u3002\u4f7f\u7528\u63a8\u5bfc\u5f0f\u53ef\u4ee5\u5feb\u901f\u751f\u6210\u5217\u8868\u3001\u5143\u7ec4\u3001\u96c6\u5408\u3001\u5b57\u5178\u7c7b\u578b\u7684\u6570\u636e\u3002\u63a8\u5bfc\u5f0f\u53c8\u5206\u4e3a\u5217\u8868\u63a8\u5bfc\u5f0f\u3001\u5143\u7ec4\u63a8\u5bfc\u5f0f\u3001\u96c6\u5408\u63a8\u5bfc\u5f0f\u3001\u5b57\u5178\u63a8\u5bfc\u5f0f\u3002 \u5217\u8868\u63a8\u5bfc\u5f0f(list comprehension) \u5217\u8868\u63a8\u5bfc\u5f0f(list comprehension)\u5141\u8bb8\u4f60\u8fc7\u6ee4\u4e00\u4e2a\u5bb9\u5668\u7684\u5143\u7d20\uff0c\u7528\u4e00\u79cd\u7b80\u660e\u7684\u8868\u8fbe\u5f0f\u8f6c\u6362\u4f20\u9012\u7ed9\u8fc7\u6ee4\u5668\u7684\u5143\u7d20\uff0c\u4ece\u800c\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u5217\u8868\u3002 \u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u57fa\u672c\u5f62\u5f0f\u4e3a\uff1a[expr for val in collection if condition]\uff0c\u6761\u4ef6if-condition\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u53ef\u4ee5\u53ea\u4fdd\u7559\u8868\u8fbe\u5f0f\u3002\u5217\u8868\u63a8\u5bfc\u5f0f\u4e0e\u4e0b\u9762\u7684for\u5faa\u73af\u662f\u7b49\u4ef7\u7684\uff1a result = [] for val in collection: if condition: result.append(expr) \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a data = [] for i in range(-5, 5): if i >= -1: data.append(i**2) print(data) # [1, 0, 1, 4, 9, 16] data = [i**2 for i in range(-5, 5) if i >= -1] print(data) # [1, 0, 1, 4, 9, 16] \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u4f7f\u7528for\u53bb\u904d\u5386\u4e00\u4e2a\u53ef\u8fed\u4ee3\u7684\u5217\u8868\u3002 data = [] fruit = [ 'pomegranate', 'cherry', 'apricot', 'date', 'Apple', 'lemon', 'kiwi', 'ORANGE', 'lime', 'Watermelon', 'guava', 'papaya', 'FIG', 'pear', 'banana', 'Tamarind', 'persimmon', 'elderberry', 'peach', 'BLUEberry', 'lychee', 'grape' ] data = [x.upper() if x.startswith('p') else x.title() for x in fruit] print(data) # ['POMEGRANATE', 'Cherry', 'Apricot', 'Date', 'Apple', 'Lemon', 'Kiwi', 'Orange', 'Lime', 'Watermelon', 'Guava', 'PAPAYA', 'Fig', 'PEAR', 'Banana', 'Tamarind', 'PERSIMMON', 'Elderberry', 'PEACH', 'Blueberry', 'Lychee', 'Grape'] \u5957\u5217\u8868\u63a8\u5bfc\u5f0f \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u4ee3\u66ff2\u5c42for\u5faa\u73af\u3002 data = [] for i in range(1, 3): if i >= 0: for j in range(1, 3): data.append((i, j)) print(data) # [(1, 1), (1, 2), (2, 1), (2, 2)] data = [(i, j) for i in range(1, 3) if i >= -1 for j in range(1, 3)] print(data) # [(1, 1), (1, 2), (2, 1), (2, 2)] \u518d\u4e3e\u4e00\u4e2a\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u4f8b\u5b50\u3002 all_data = [ ['John', 'Emily', 'Michael', 'Lee', 'Steven'], ['Maria', 'Juan', 'Javier', 'Natalia', 'Pilar'], ] names_of_interest = [] for names in all_data: enough_es = [name for name in names if name.count('e') >=2] names_of_interest.extend(enough_es) print(names_of_interest) # ['Lee', 'Steven'] result = [name for names in all_data for name in names if name.count('e') >= 2] print(result) # ['Lee', 'Steven'] \u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u77e9\u9635\u6241\u5e73\u5316\u3002 \u8003\u8651\u4e0b\u9762\u8fd9\u4e2a3x4\u7684\u77e9\u9635\uff0c\u5b83\u75313\u4e2a\u957f\u5ea6\u4e3a4\u7684\u5217\u8868\u7ec4\u6210\u3002\u4e0b\u9762\u4f8b\u5b50\u5bf9\u6bd4\u4e86\u7528\u4f20\u7edffor\u5faa\u73af\u5c06\u77e9\u9635\u6241\u5e73\u5316\uff0c\u548c\u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u77e9\u9635\u6241\u5e73\u5316\u3002\u5e76\u4e14\u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u4e2d\u7684\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u6241\u5e73\u77e9\u9635\u8fd8\u539f\u4e3a3x4\u77e9\u9635\u3002 matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], ] flattened = [] # \u4f20\u7edffor\u5faa\u73af\u5d4c\u5957 for m in matrix: for x in m: flattened.append(x) print(flattened) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # \u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f flattened = [x for m in matrix for x in m] print(flattened) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # \u5217\u8868\u63a8\u5bfc\u5f0f\u4e2d\u7684\u5217\u8868\u63a8\u5bfc\u5f0f z = [[x for x in m] for m in matrix] print(z) # [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]] \u5143\u7ec4\u63a8\u5bfc\u5f0f \u4e0b\u9762\u7684\u4f8b\u5b50\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6570\u5b571~5\u7684\u5143\u7ec4\u3002\u4ece\u7ed3\u679c\u53ef\u4ee5\u770b\u5230\uff0c\u5143\u7ec4\u63a8\u5bfc\u5f0f\u751f\u6210\u7684\u7ed3\u679c\u5e76\u4e0d\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u800c\u662f\u4e00\u4e2a\u751f\u6210\u5668\u5bf9\u8c61\uff0c\u9700\u8981\u901a\u8fc7tuple()\u51fd\u6570\uff0c\u5c06\u751f\u6210\u5668\u5bf9\u8c61\u8f6c\u6362\u6210\u5143\u7ec4\u3002 data = (x for x in range(5)) print(data) # <generator object <genexpr> at 0x7f87217a8e40> print(type(data)) # <class 'generator'> print(tuple(data)) # (0, 1, 2, 3, 4) \u96c6\u5408\u63a8\u5bfc\u5f0f \u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u96c6\u5408\u63a8\u5bfc\u5f0f\u4f8b\u5b50\u3002 data = {x**2 for x in range(5)} print(data) # {0, 1, 4, 9, 16} print(type(data)) # <class 'set'> \u96c6\u5408\u8981\u4fdd\u8bc1\u5143\u7d20\u5fc5\u987b\u662f\u552f\u4e00\u7684\u3002 data = (1, 1, 2, 2, 3, 3, 4, 5, 6) newset = {x**2 for x in data} print(newset) # {1, 4, 36, 9, 16, 25} print(type(newset) # <class 'set'> \u5b57\u5178\u63a8\u5bfc\u5f0f \u5b57\u5178\u63a8\u5bfc\u5f0f: dict_comp = {key-expr : value-expr for value in collection if condition} \u5b57\u5178\u63a8\u5bfc\u5f0f\u7684\u7b80\u5355\u793a\u4f8b\uff1a strings = ['a', 'as', 'bat', 'car', 'dove', 'python'] loc_mapping = {index: val for index, val in enumerate(strings)} print(loc_mapping) # {0: 'a', 1: 'as', 2: 'bat', 3: 'car', 4: 'dove', 5: 'python'} # \u4ea4\u6362\u952e\u548c\u503c loc_mapping = {index: val for val, index in enumerate(strings)} print(loc_mapping) # {'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5} 4. \u51fd\u6570\u58f0\u660e \u5982\u679cPython\u8fbe\u5230\u51fd\u6570\u7684\u5c3e\u90e8\u65f6\u4ecd\u7136\u6ca1\u6709\u9047\u5230return\u8bed\u53e5\uff0c\u5c31\u4f1a\u81ea\u52a8\u8fd4\u56deNone\u3002 \u6bcf\u4e2a\u51fd\u6570\u90fd\u53ef\u4ee5\u6709\u4f4d\u7f6e\u53c2\u6570\u548c\u5173\u952e\u5b57\u53c2\u6570\u3002\u5173\u952e\u5b57\u53c2\u6570\u6700\u5e38\u7528\u4e8e\u6307\u5b9a\u9ed8\u8ba4\u503c\u6216\u53ef\u9009\u53c2\u6570\u3002\u5173\u952e\u5b57\u53c2\u6570\u5fc5\u987b\u8ddf\u5728\u4f4d\u7f6e\u53c2\u6570\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528\u5173\u952e\u5b57\u53c2\u6570\u5411\u4f4d\u7f6e\u53c2\u6570\u4f20\u53c2\u3002 import sys def my_function1(x, y, z=1.5): if z > 1: return z * (x + y) else: return z / (x + y) result1 = my_function1(5, 6, z=0.7) print(result1) # 0.06363636363636363 result1 = my_function1(x=5, y=6, z=0.7) print(result1) # 0.06363636363636363 result1 = my_function1(3.14, 7, 3.5) print(result1) # 35.49 result1 = my_function1(10, 20) print(result1) # 45.0 5. \u547d\u540d\u7a7a\u95f4\u3001\u4f5c\u7528\u57df\u548c\u672c\u5730\u51fd\u6570 \u51fd\u6570\u6709\u4e24\u79cd\u8fde\u63a5\u53d8\u91cf\u7684\u65b9\u5f0f\uff1a\u5168\u5c40\u3001\u672c\u5730\u3002 def func1(): list1 = [] # \u672c\u5730\u53d8\u91cf for i in range(5): list1.append(i) print(list1) func1() # [0, 1, 2, 3, 4] list2 = [] # \u5168\u5c40\u53d8\u91cf def func2(): global list2 # \u5168\u5c40\u53d8\u91cf for i in range(5): list2.append(i) print(list2) func2() # [0, 1, 2, 3, 4] \u6570\u636e\u6e05\u6d17\u793a\u4f8b states = [' Alabama', 'Georgia!', 'georgia', 'Georgia', 'FlOrIda', 'south carolina##', 'West virginia? '] # \u65b9\u6cd51 import re def clean_string1(strings): result2 = [] for value in strings: value = value.strip() value = re.sub('[! #? ]', '', value) value = value.title() result2.append(value) return result2 print(clean_string1((states))) # ['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'Southcarolina', 'Westvirginia'] # \u65b9\u6cd52 def remove_punctuaion(value): return re.sub('[! #? ]', '', value) clean_ops = [str.strip, remove_punctuaion, str.title] def clean_string2(strings, ops): result3 = [] for value in strings: for function in ops: value = function(value) result3.append(value) return result3 result4 = clean_string2(states, clean_ops) print(result4) # ['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'Southcarolina', 'Westvirginia'] # \u53ef\u4ee5\u5c06\u51fd\u6570\u4f5c\u4e3a\u4e00\u4e2a\u53c2\u6570\u4f20\u7ed9\u5176\u4ed6\u7684\u51fd\u6570\u3002 for x in map(remove_punctuaion, states): print(x) # Alabama # Georgia # georgia # Georgia # FlOrIda # southcarolina # Westvirginia 6. \u67ef\u91cc\u5316\uff1a\u90e8\u5206\u53c2\u6570\u5e94\u7528 \u67ef\u91cc\u5316\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u672f\u8bed\uff08\u4ee5\u6570\u5b66\u5bb6Haskell Curry\u547d\u540d\uff09\uff0c\u5b83\u8868\u793a\u901a\u8fc7\u90e8\u5206\u53c2\u6570\u5e94\u7528\u7684\u65b9\u5f0f\u4ece\u5df2\u6709\u7684\u51fd\u6570\u4e2d\u884d\u751f\u51fa\u65b0\u7684\u51fd\u6570\u3002\u67ef\u91cc\u5316\u662f\u4e00\u79cd\u5c06\u591a\u53c2\u6570\u51fd\u6570\u8f6c\u5316\u4e3a\u5355\u53c2\u6570\u9ad8\u9636\u51fd\u6570\u7684\u6280\u672f\uff0c\u5982\u679c\u4f60\u56fa\u5b9a\u67d0\u4e9b\u53c2\u6570\uff0c\u4f60\u5c06\u5f97\u5230\u63a5\u53d7\u4f59\u4e0b\u53c2\u6570\u7684\u4e00\u4e2a\u51fd\u6570\u3002 \u5b9a\u4e49\u4e00\uff1a \u67ef\u91cc\u5316\uff1a\u4e00\u4e2a\u51fd\u6570\u4e2d\u6709\u4e2a\u591a\u4e2a\u53c2\u6570\uff0c\u60f3\u56fa\u5b9a\u5176\u4e2d\u67d0\u4e2a\u6216\u8005\u51e0\u4e2a\u53c2\u6570\u7684\u503c\uff0c\u800c\u53ea\u63a5\u53d7\u53e6\u5916\u51e0\u4e2a\u8fd8\u672a\u56fa\u5b9a\u7684\u53c2\u6570\uff0c\u8fd9\u6837\u51fd\u6570\u6f14\u53d8\u6210\u65b0\u7684\u51fd\u6570\u3002 \u5b9a\u4e49\u4e8c\uff1a \u51fd\u6570\u67ef\u91cc\u5316\uff08currying\uff09\u53c8\u79f0\u90e8\u5206\u6c42\u503c\u3002\u4e00\u4e2a currying \u7684\u51fd\u6570\u9996\u5148\u4f1a\u63a5\u53d7\u4e00\u4e9b\u53c2\u6570\uff0c\u63a5\u53d7\u4e86\u8fd9\u4e9b\u53c2\u6570\u4e4b\u540e\uff0c\u8be5\u51fd\u6570\u5e76\u4e0d\u4f1a\u7acb\u5373\u6c42\u503c\uff0c\u800c\u662f\u7ee7\u7eed\u8fd4\u56de\u53e6\u5916\u4e00\u4e2a\u51fd\u6570\uff0c\u521a\u624d\u4f20\u5165\u7684\u53c2\u6570\u5728\u51fd\u6570\u5f62\u6210\u7684\u95ed\u5305\u4e2d\u88ab\u4fdd\u5b58\u8d77\u6765\u3002\u5f85\u5230\u51fd\u6570\u88ab\u771f\u6b63\u9700\u8981\u6c42\u503c\u7684\u65f6\u5019\uff0c\u4e4b\u524d\u4f20\u5165\u7684\u6240\u6709\u53c2\u6570\u90fd\u4f1a\u88ab\u4e00\u6b21\u6027\u7528\u4e8e\u6c42\u503c\u3002 \u5b9a\u4e49\u4e09\uff1a \u4e00\u4e9b\u51fd\u6570\u5f0f\u8bed\u8a00\u7684\u5de5\u4f5c\u539f\u7406\u662f\u5c06\u591a\u53c2\u6570\u51fd\u6570\u8bed\u6cd5\u8f6c\u5316\u4e3a\u5355\u53c2\u6570\u51fd\u6570\u96c6\u5408\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u79f0\u4e3a\u67ef\u91cc\u5316\uff0c\u5b83\u662f\u4ee5\u903b\u8f91\u5b66\u5bb6Haskell Curry\u7684\u540d\u5b57\u547d\u540d\u7684\u3002Haskell Curry\u4ece\u65e9\u671f\u6982\u5ff5\u4e2d\u53d1\u5c55\u51fa\u4e86\u8be5\u7406\u8bba\u3002\u5176\u5f62\u5f0f\u76f8\u5f53\u4e8e\u5c06z=f(x, y)\u8f6c\u6362\u6210z=f(x)(y)\u7684\u5f62\u5f0f\uff0c\u539f\u51fd\u6570\u7531\u4e24\u4e2a\u53c2\u6570\uff0c\u73b0\u5728\u53d8\u4e3a\u4e24\u4e2a\u63a5\u53d7\u5355\u53c2\u6570\u7684\u51fd\u6570\uff0c \u793a\u4f8b1\uff1a\u67ef\u91cc\u5316\u7684\u8fc7\u7a0b\u5c31\u662f\u628a\u539f\u6765\u5e26\u4e24\u4e2a\u53c2\u6570\u7684\u51fd\u6570add(x, y)\uff0c\u53d8\u6210\u4e86\u4e00\u4e2a\u5d4c\u5957\u51fd\u6570\uff0c\u5728add_currying\u51fd\u6570\u5185\uff0c\u53c8\u5b9a\u4e49\u4e86\u4e00\u4e2a_add\u51fd\u6570\uff0c\u5e76\u4e14_add\u51fd\u6570\u53c8\u5f15\u7528\u4e86\u5916\u90e8\u51fd\u6570add_currying\u7684\u53d8\u91cfx\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a\u95ed\u5305\u3002 \u95ed\u5305\uff0c\u4e00\u53e5\u8bdd\u8bf4\u5c31\u662f\u5728\u51fd\u6570\u4e2d\u518d\u5d4c\u5957\u4e00\u4e2a\u51fd\u6570\uff0c\u5e76\u4e14\u5f15\u7528\u5916\u90e8\u51fd\u6570\u7684\u53d8\u91cf\u3002 # \u666e\u901a\u5199\u6cd5 def add(x, y): return x + y print(add(1, 2)) # 3 # \u67ef\u91cc\u5316\u5199\u6cd5 def add_currying(x): def _add(y): return x + y return _add print(add_currying(1)(2)) # 3 \u793a\u4f8b2\uff0c\u901a\u8fc7\u56fa\u5b9a\u5176\u4e2d\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e0d\u53d8\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 def add2(a, b): def add1(a, b, c): return a + b + c return add1(a, 666, b) result6 = add2(12, 13) print(result6) # 691 result6 = add2(12, 555, 13) # TypeError: add2() takes 2 positional arguments but 3 were given \u793a\u4f8b3\uff0c\u901a\u8fc7functools\u63d0\u4f9b\u7684\u504f\u51fd\u6570\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 from functools import partial def add1(a, b, c): return a + b + c add3 = partial(add1, b=666) result7 = add3(a=12, c=13) print(result7) # 691 \u793a\u4f8b4\uff0c\u901a\u8fc7lambda\u8868\u8fbe\u5f0f\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 def add1(a, b, c): return a + b + c add4 = lambda x, y: add1(x, 666, y) result8 = add4(12, 13) print(result8) # 691 \u793a\u4f8b5\uff0c\u901a\u8fc7python\u7684\u88c5\u9970\u5668\u6765\u5b9e\u73b0\u67ef\u91cc\u5316 def add1(a, b, c): return a + b + c def currying_add(func): def wrapper(a, c, b=666): return func(a, b, c) return wrapper result9 = currying_add(add1)(12, 13) print(result9) # 691 \u793a\u4f8b6\uff0c\u901a\u8fc7python\u7684\u88c5\u9970\u5668\u7b26\u53f7@\u6765\u5b9e\u73b0\u67ef\u91cc\u5316 def currying_add(func): def wrapper(a, c, b=666): return func(a, b, c) return wrapper @currying_add def add5(a, b, c): return a + b + c result10 = add5(12, 13) print(result10) # 691 7. \u8fed\u4ee3\u5668\u4e0e\u751f\u6210\u5668 \u8fed\u4ee3\u5668 \u8fed\u4ee3\u662fPython\u6700\u5f3a\u5927\u7684\u529f\u80fd\u4e4b\u4e00\uff0c\u662f\u8bbf\u95ee\u96c6\u5408\u5143\u7d20\u7684\u4e00\u79cd\u65b9\u5f0f\u3002\u8fed\u4ee3\u5668\u662f\u4e00\u4e2a\u53ef\u4ee5\u8bb0\u4f4f\u904d\u5386\u7684\u4f4d\u7f6e\u7684\u5bf9\u8c61\u3002 \u8fed\u4ee3\u5668\u5bf9\u8c61\u4ece\u96c6\u5408\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u5f00\u59cb\u8bbf\u95ee\uff0c\u76f4\u5230\u6240\u6709\u7684\u5143\u7d20\u88ab\u8bbf\u95ee\u5b8c\u7ed3\u675f\u3002\u8fed\u4ee3\u5668\u53ea\u80fd\u5f80\u524d\u4e0d\u4f1a\u540e\u9000\u3002 \u8fed\u4ee3\u5668\u6709\u4e24\u4e2a\u57fa\u672c\u7684\u65b9\u6cd5\uff1aiter() \u548c next()\u3002 \u8fed\u4ee3\u5668\u793a\u4f8b\uff1a list_a = [1, 2, 3, 4] it = iter(list_a) # \u521b\u5efa\u8fed\u4ee3\u5668\u5bf9\u8c61 print(next(it)) # \u8f93\u51fa\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u4e2a\u5143\u7d20 # 1 print(next(it)) # \u8f93\u51fa\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u4e2a\u5143\u7d20 # 2 \u8fed\u4ee3\u5668\u5bf9\u8c61\u53ef\u4ee5\u4f7f\u7528\u5e38\u89c4for\u8bed\u53e5\u8fdb\u884c\u904d\u5386\u3002 list_a = [1, 2, 3, 4] it = iter(list_a) # \u521b\u5efa\u8fed\u4ee3\u5668\u5bf9\u8c61 for x in it: print(x, end=\" \") print(end=\"\\n\") # 1 2 3 4 \u751f\u6210\u5668 \u5728 Python \u4e2d\uff0c\u4f7f\u7528\u4e86 yield \u7684\u51fd\u6570\u88ab\u79f0\u4e3a\u751f\u6210\u5668\uff08generator\uff09\u3002\u8ddf\u666e\u901a\u51fd\u6570\u4e0d\u540c\u7684\u662f\uff0c\u751f\u6210\u5668\u662f\u4e00\u4e2a\u8fd4\u56de\u8fed\u4ee3\u5668\u7684\u51fd\u6570\uff0c\u53ea\u80fd\u7528\u4e8e\u8fed\u4ee3\u64cd\u4f5c\uff0c\u751f\u6210\u5668\u5c31\u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\u3002 \u5728\u8c03\u7528\u751f\u6210\u5668\u8fd0\u884c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u6b21\u9047\u5230 yield \u65f6\u51fd\u6570\u4f1a\u6682\u505c\u5e76\u4fdd\u5b58\u5f53\u524d\u6240\u6709\u7684\u8fd0\u884c\u4fe1\u606f\uff0c\u8fd4\u56de yield \u7684\u503c, \u5e76\u5728\u4e0b\u4e00\u6b21\u6267\u884c next() \u65b9\u6cd5\u65f6\u4ece\u5f53\u524d\u4f4d\u7f6e\u7ee7\u7eed\u8fd0\u884c\u3002 \u8c03\u7528\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\u5bf9\u8c61\u3002 \u793a\u4f8b, \u6590\u6ce2\u90a3\u5951\u6570\u5217\uff1a def fibonacci(n): a, b, counter = 0, 1, 0 while True: if (counter > n): return yield a a, b = b, a + b counter += 1 f = fibonacci(10) # f \u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u7531\u751f\u6210\u5668\u8fd4\u56de\u751f\u6210 print(f) # <generator object fibonacci at 0x7fbe8a7f7580> \u5b9e\u9645\u8c03\u7528\u751f\u6210\u5668\u65f6\uff0c\u4ee3\u7801\u5e76\u4e0d\u4f1a\u7acb\u5373\u6267\u884c for x in f: # \u8bf7\u6c42\u751f\u6210\u5668\u4e2d\u7684\u5143\u7d20\u65f6\uff0c\u5b83\u624d\u4f1a\u6267\u884c\u5b83\u7684\u4ee3\u7801 print(x, end=\" \") print(end=\"\\n\") # 0 1 1 2 3 5 8 13 21 34 55 \u751f\u6210\u5668\u8868\u8fbe\u5f0f\uff1a \u7528\u751f\u6210\u5668\u8868\u8fbe\u5f0f\u6765\u521b\u5efa\u751f\u6210\u5668\u66f4\u4e3a\u7b80\u5355\u3002\u751f\u6210\u5668\u8868\u8fbe\u5f0f\u4e0e\u5217\u8868\u3001\u5b57\u5178\u3001\u96c6\u5408\u7684\u63a8\u5bfc\u5f0f\u5f88\u7c7b\u4f3c\uff0c\u521b\u5efa\u4e00\u4e2a\u751f\u6210\u5668\u8868\u8fbe\u5f0f\uff0c\u53ea\u9700\u8981\u5c06\u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u4e2d\u62ec\u53f7\u66ff\u6362\u4e3a\u5c0f\u62ec\u53f7\u5373\u53ef\u3002 gen1 = (x ** 2 for x in range(100)) print(gen1) # <generator object <genexpr> at 0x7fd3f30c9580> \u4e0a\u9762\u7684\u4ee3\u7801\u4e0e\u4e0b\u9762\u7684\u751f\u6210\u5668\u662f\u7b49\u4ef7\u7684 def _make_gen(): for x in range(100): yield x ** 2 gen2 = _make_gen() print(gen2) # <generator object _make_gen at 0x7fceb69ed580> \u751f\u6210\u5668\u8868\u8fbe\u5f0f\u53ef\u4ee5\u4f5c\u4e3a\u51fd\u6570\u53c2\u6570\u7528\u4e8e\u66ff\u4ee3\u5217\u8868\u63a8\u5bfc\u5f0f\u3002\u5bf9\u6bd4\u4e0b\u97622\u4e2a\u4f8b\u5b50\u3002 # \u793a\u4f8b1 result11 = sum(x ** 2 for x in range(100)) print(result11) # 328350 gen1 = (x ** 2 for x in range(100)) result11 = sum(gen1) print(result11) # 328350 # \u793a\u4f8b2 result12 = dict((i, i ** 2) for i in range(5)) print(result12) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} gen2 = ((i, i ** 2) for i in range(5)) result12 = dict(gen2) print(result12) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} \u751f\u6210\u5668\uff1aitertools\u6a21\u5757 \u6807\u51c6\u5e93\u4e2d\u7684itertools\u6a21\u5757\u662f\u9002\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u7b97\u6cd5\u7684\u751f\u6210\u5668\u96c6\u5408\u3002 import itertools first_letter = lambda x: x[0] names = ['Alan', 'Adam', 'Wes', 'Will', 'Albert', 'Steven'] for letter, names in itertools.groupby(names, first_letter): print(letter) print(first_letter) print(letter, list(names)) # names is generator # A # <function <lambda> at 0x7fa598a7a0d0> # A ['Alan', 'Adam'] # W # <function <lambda> at 0x7fa598a7a0d0> # W ['Wes', 'Will'] # A # <function <lambda> at 0x7fa598a7a0d0> # A ['Albert'] # S # <function <lambda> at 0x7fa598a7a0d0> # S ['Steven'] 8. \u9519\u8bef\u548c\u5f02\u5e38\u5904\u7406 Python\u7528\u5f02\u5e38\u5bf9\u8c61(exception object)\u6765\u8868\u793a\u5f02\u5e38\u60c5\u51b5\u3002\u9047\u5230\u9519\u8bef\u540e\uff0c\u4f1a\u5f15\u53d1\u5f02\u5e38\u3002\u5982\u679c\u5f02\u5e38\u5bf9\u8c61\u5e76\u672a\u88ab\u5904\u7406\u6216\u6355\u6349\uff0c\u7a0b\u5e8f\u5c31\u4f1a\u7528\u6240\u8c13\u7684\u56de\u6eaf(traceback\uff0c \u4e00\u79cd\u9519\u8bef\u4fe1\u606f)\u7ec8\u6b62\u6267\u884c\u3002 \u5f02\u5e38\u548c\u8bed\u6cd5\u9519\u8bef\u662f\u6709\u533a\u522b\u7684\u3002 * \u9519\u8bef\uff1a\u662f\u6307\u4ee3\u7801\u4e0d\u7b26\u5408\u89e3\u91ca\u5668\u6216\u8005\u7f16\u8bd1\u5668\u8bed\u6cd5\u3002 * \u5f02\u5e38\uff1a\u662f\u6307\u4e0d\u5b8c\u6574\u3001\u4e0d\u5408\u6cd5\u8f93\u5165\uff0c\u6216\u8005\u8ba1\u7b97\u51fa\u73b0\u9519\u8bef\u3002 python\u91cc\u7528try...except...\u8bed\u53e5\u6765\u5904\u7406\u5f02\u5e38\u60c5\u51b5\u3002 def attempt_float(x): try: return float(x) except (TypeError, ValueError): return \"Type error, not numbers\" r1 = attempt_float('1.2256') print(r1) # 1.2256 r1 = attempt_float('friends') print(r1) # Type error, not numbers 9. \u6587\u4ef6\u4e0e\u64cd\u4f5c\u7cfb\u7edf f=open(path, 'w')\uff0c\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\u4f1a\u5728path\u6307\u5b9a\u7684\u8def\u5f84\u88ab\u521b\u5efa\uff0c\u5e76\u5728\u540c\u4e00\u8def\u5f84\u4e0b\u8986\u76d6\u540c\u540d\u6587\u4ef6\u3002\uff08\u8bf7\u5c0f\u5fc3\uff01\uff09 f=open(path, 'x')\uff0c\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\u4f1a\u5728path\u6307\u5b9a\u7684\u8def\u5f84\u88ab\u521b\u5efa\uff0c\u5982\u679c\u7ed9\u5b9a\u8def\u5f84\u4e0b\u5df2\u7ecf\u5b58\u5728\u540c\u540d\u6587\u4ef6\u5c31\u4f1a\u521b\u5efa\u5931\u8d25\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u8bfb\u53d6\u6587\u4ef6\u6bcf\u4e00\u884c\uff0c\u6587\u4ef6\u6bcf\u4e00\u884c\u4f5c\u4e3a\u5217\u8868\u4e00\u4e2a\u5143\u7d20 lines = [x.rstrip() for x in open(path)] # \u8f93\u51fa\u5217\u8868 print(lines) # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f.close() \u53e6\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u5173\u95ed\u6587\u4ef6\u7684\u65b9\u5f0f import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u4f7f\u7528with\u8bed\u53e5\u8bfb\u53d6\u6587\u4ef6\uff0c\u6587\u4ef6\u4f1a\u5728with\u4ee3\u7801\u5757\u7ed3\u675f\u540e\u81ea\u52a8\u5173\u95ed\u3002 with open(path) as f: lines = [x.rstrip() for x in open(path)] # \u8f93\u51fa\uff1a\u6587\u4ef6\u6bcf\u4e00\u884c\u4f5c\u4e3a\u5217\u8868\u4e00\u4e2a\u5143\u7d20 print(lines) \u5728\u6253\u5f00\u6587\u4ef6\u65f6\u4f7f\u7528seek\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\u8981\u5f53\u5fc3\u3002\u5982\u679c\u6587\u4ef6\u7684\u53e5\u67c4\u4f4d\u7f6e\u6070\u597d\u5728\u4e00\u4e2aUnicode\u7b26\u53f7\u7684\u5b57\u8282\u4e2d\u95f4\u65f6\uff0c\u540e\u7eed\u7684\u8bfb\u53d6\u4f1a\u5bfc\u81f4\u9519\u8bef\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u8bfb\u53d6\u6587\u4ef6\u3002 print(f.read(5)) # \u8f93\u51fa\u524d5\u4e2a\u5b57\u7b26\u3002 read\u65b9\u6cd5\u901a\u8fc7\u8bfb\u53d6\u7684\u5b57\u8282\u6570\u6765\u63a8\u8fdb\u6587\u4ef6\u53e5\u67c4\u7684\u4f4d\u7f6e\u3002 # I Thi print(f.tell()) # tell\u65b9\u6cd5\u53ef\u4ee5\u7ed9\u51fa\u53e5\u67c4\u5f53\u524d\u7684\u4f4d\u7f6e # 5 print(f.seek(6)) # seek\u65b9\u6cd5\u53ef\u4ee5\u5c06\u53e5\u67c4\u4f4d\u7f6e\u6539\u53d8\u5230\u6587\u4ef6\u4e2d\u7279\u5b9a\u7684\u5b57\u8282 # 6 print(f.read(1)) # \u4ece\u7b2c7\u4e2a\u5b57\u8282\u5f00\u59cb\uff0c\u8f93\u51fa1\u4e2a\u5b57\u8282 # k # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f.close() \u5982\u679c\u4f7f\u7528\u4e8c\u8fdb\u5236\u65b9\u5f0f\u6253\u5f00\u6587\u4ef6\uff0c\u5219\uff1a import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f2 = open(path, 'rb') # \u4e8c\u8fdb\u5236\u6a21\u5f0f # \u8bfb\u53d6\u6587\u4ef6 print(f2.read(5)) # \u7b2c\u4e00\u4e2ab\u4ee3\u8868\u4e8c\u8fdb\u5236\u683c\u5f0f # b'I Thi' print(f2.tell()) # 5 print(f2.seek(6)) # 6 print(f2.read(2)) # \u4ece\u7b2c7\u4e2a\u5b57\u8282\u5f00\u59cb\uff0c\u8f93\u51fa2\u4e2a\u5b57\u8282 # b'k ' # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f2.close() \u5c06\u672c\u6587\u5199\u5165\u6587\u4ef6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6587\u4ef6\u5bf9\u8c61\u7684write\u6216wirtelines\u65b9\u6cd5\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path1 = 'file01.txt' path2 = 'file02.txt' # file02.txt\u662f\u4e00\u4e2a\u7a7a\u6587\u4ef6 with open(path2, 'r+', encoding='utf-8') as f: f.writelines(x for x in open(path1, 'r', encoding='utf-8') if len(x) > 1) # \u628afile01.txt\u7684\u5185\u5bb9\u5199\u5165file02.txt lines = f.readlines() print(lines) 10. \u88c5\u9970\u5668 \u95ed\u5305 \u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u89e3\u91ca\uff1a \u95ed\u5305\uff08Closure\uff09 \uff0c\u53c8\u79f0\u8bcd\u6cd5\u95ed\u5305\uff08Lexical Closure\uff09\u6216\u51fd\u6570\u95ed\u5305\uff08function closures\uff09\uff0c\u662f\u5f15\u7528\u4e86\u81ea\u7531\u53d8\u91cf\u7684\u51fd\u6570\u3002\u8fd9\u4e2a\u88ab\u5f15\u7528\u7684\u81ea\u7531\u53d8\u91cf\u5c06\u548c\u8fd9\u4e2a\u51fd\u6570\u4e00\u540c\u5b58\u5728\uff0c\u5373\u4f7f\u5df2\u7ecf\u79bb\u5f00\u4e86\u521b\u9020\u5b83\u7684\u73af\u5883\u4e5f\u4e0d\u4f8b\u5916\u3002 \u95ed\u5305\u5ef6\u4f38\u4e86\u4f5c\u7528\u57df\u7684\u51fd\u6570\uff0c\u5176\u4e2d\u5305\u542b\u51fd\u6570\u5b9a\u4e49\u4f53\u4e2d\u5f15\u7528\u3001\u4f46\u662f\u4e0d\u5728\u5b9a\u4e49\u4f53\u4e2d\u5b9a\u4e49\u7684\u975e\u5168\u5c40\u53d8\u91cf\u3002\u51fd\u6570\u662f\u4e0d\u662f\u533f\u540d\u7684\u6ca1\u6709\u5173\u7cfb\uff0c\u5173\u952e\u662f\u5b83\u80fd\u8bbf\u95ee\u5b9a\u4e49\u4f53\u4e4b\u5916\u5b9a\u4e49\u7684\u975e\u5168\u5c40\u53d8\u91cf\u3002 \u4f8b\u4e00\uff0c\u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\u503c\u3002 \u4e0b\u9762\u662f\u662f\u4f20\u7edf\u7c7b\u5b9e\u73b0\u65b9\u5f0f\uff0cAvg\u7684\u5b9e\u4f8b\u662f\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u3002 class Avg(): def __init__(self): self.mylist = [] def __call__(self, newValue): self.mylist.append(newValue) total = sum(self.mylist) return total/len(self.mylist) avg = Avg() avg(10) # 10.0 avg(20) # 15.0 avg(30) # 20.0 \u4e0b\u9762\u662f\u9ad8\u9636\u51fd\u6570\u5b9e\u73b0\u65b9\u5f0f\u3002\u8c03\u7528 make_avg \u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a my_avg \u51fd\u6570\u5bf9\u8c61\u3002\u6bcf\u6b21\u8c03\u7528 my_avg \u65f6\uff0c\u5b83\u4f1a\u628a\u53c2\u6570\u6dfb\u52a0\u5230\u7cfb\u5217\u503c\u4e2d\uff0c\u7136\u540e\u8ba1\u7b97\u5f53\u524d\u5e73\u5747\u503c\u3002 def make_avg(): my_list = [] def avg(newValue): my_list.append(newValue) total = sum(my_list) return total/len(my_list) return avg my_avg = make_avg() my_avg(10) # 10.0 my_avg(20) # 15.0 my_avg(30) # 20.0 my_avg.__code__.co_varnames # ('newValue', 'total') my_avg.__code__.co_freevars # ('my_list',) my_avg.__closure__ # (<cell at 0x7fe93d347468: list object at 0x7fe93d0e2f48>,) my_avg.__closure__[0].cell_contents # [10, 20, 30] \u8fd9\u4e24\u4e2a\u793a\u4f8b\u6709\u5171\u901a\u4e4b\u5904\uff1a\u8c03\u7528 Avg() \u6216 make_avg() \u5f97\u5230\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61 avg \uff0c\u5b83\u4f1a\u66f4\u65b0\u5386\u53f2\u503c\uff0c\u7136\u540e\u8ba1\u7b97\u5f53\u524d\u5747\u503c\u3002 \u5728\u7c7b\u5b9e\u73b0\u4e2d\uff0c avg \u662f Avg \u7684\u5b9e\u4f8b\uff1b\u5728\u9ad8\u9636\u51fd\u6570\u5b9e\u73b0\u4e2d\u662f\u5185\u90e8\u51fd\u6570 avg \u3002 \u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\u4e2d\uff0c\u6211\u4eec\u90fd\u53ea\u9700\u8c03\u7528 avg(n) \uff0c\u628a n \u653e\u5165\u7cfb\u5217\u503c\u4e2d\uff0c\u7136\u540e\u91cd\u65b0\u8ba1\u7b97\u5747\u503c\u3002 \u7b2c\u4e00\u4e2a\u4f8b\u5b50\u4e2d\uff0c Avg \u7c7b\u7684\u5b9e\u4f8b avg \u5728 self.series \u5b9e\u4f8b\u5c5e\u6027\u4e2d\u5b58\u50a8\u5386\u53f2\u503c\u3002 \u7b2c\u4e8c\u4e2a\u4f8b\u5b50\u4e2d\u7684 my_list \u662f\u51fd\u6570 make_avg() \u7684\u5c40\u90e8\u53d8\u91cf\uff0c\u4e5f\u79f0\u4e3a\u8be5\u51fd\u6570\u7684 \u81ea\u7531\u53d8\u91cf\uff08free variable\uff09 \uff0c\u6307\u672a\u5728\u672c\u5730\u4f5c\u7528\u57df\u4e2d\u7ed1\u5b9a\u7684\u53d8\u91cf\u3002 avg() \u51fd\u6570\u7684\u95ed\u5305\u5ef6\u4f38\u5230\u51fd\u6570\u7684\u4f5c\u7528\u57df\u4e4b\u5916\uff0c\u5305\u542b\u4e86 make_avg() \u7684\u81ea\u7531\u53d8\u91cf my_list \u7684\u7ed1\u5b9a\u3002 \u5bf9\u4e8e\u8fd4\u56de\u7684 my_avg \u5bf9\u8c61\uff0c\u5176 __code__ \u5c5e\u6027\uff08\u8868\u793a\u7f16\u8bd1\u540e\u7684\u51fd\u6570\u5b9a\u4e49\u4f53\uff09\u4e2d\u4fdd\u5b58\u4e86\u5c40\u90e8\u53d8\u91cf\u548c\u81ea\u7531\u53d8\u91cf\u7684\u540d\u79f0\uff0c\u5373 my_avg.__code__.co_varnames \u8fd4\u56de\u4e86\u5c40\u90e8\u53d8\u91cf ('newValue', 'total') \u548c my_avg.__code__.co_freevars \u8fd4\u56de\u4e86\u81ea\u7531\u53d8\u91cf ('my_list',) \u3002 \u81ea\u7531\u53d8\u91cf my_list \u7ed1\u5b9a\u5728\u8fd4\u56de\u7684 my_avg \u7684 __closure__ \u7684\u5c5e\u6027\u4e2d\uff0c my_avg.__closure__ \u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u5bf9\u5e94\u4e86 my_avg.__code__.co_freevars \u4e2d\u7684\u4e00\u4e2a\u540d\u79f0\u3002\u8fd9\u4e9b\u5143\u7d20\u662f cell \u5bf9\u8c61\uff0c\u6709\u4e2a cell_contents \u5c5e\u6027\uff0c\u5982\uff1a my_avg.__closure__ \u8fd4\u56de (<cell at 0x7fe93d347468: list object at 0x7fe93d0e2f48>,) \uff0c\u91cc\u9762\u4fdd\u5b58\u7740\u771f\u6b63\u7684\u503c\uff0c\u5982 my_avg.__closure__[0].cell_contents \u91cc\u9762\u4fdd\u5b58\u6bcf\u6b21\u8c03\u7528\u7684\u771f\u5b9e\u503c [10, 20, 30] \u3002 \u4e0a\u9762 my_list \u662f\u4e00\u4e2a\u53ef\u53d8\u7c7b\u578b\uff0c\u5982\u679c\u7528\u4e0d\u53ef\u53d8\u7c7b\u578b\u6539\u5199\uff0c\u5e76\u5b9e\u73b0\u95ed\u5305\uff0c\u53ef\u4ee5\u4f7f\u7528 nolocal \u8fdb\u884c\u58f0\u660e\u3002\u5b83\u7684\u4f5c\u7528\u662f\u628a\u53d8\u91cf\u6807\u8bb0\u4e3a\u81ea\u7531\u53d8\u91cf\uff0c\u5373\u4f7f\u5728\u51fd\u6570\u4e2d\u4e3a\u53d8\u91cf\u8d4b\u4e88\u65b0\u503c\u4e86\uff0c\u4e5f\u4f1a\u53d8\u6210\u81ea\u7531\u53d8\u91cf\u3002\u5982\u679c\u4e3anonlocal\u58f0\u660e\u7684\u53d8\u91cf\u8d4b\u4e88\u65b0\u503c\uff0c\u95ed\u5305\u4e2d\u4fdd\u5b58\u7684\u7ed1\u5b9a\u4f1a\u66f4\u65b0\u3002 my_avg.__code__.co_freevars \u8fd4\u56de\u4e862\u4e2a\u81ea\u7531\u53d8\u91cf ('count', 'total') \uff0c\u5e76\u5728 my_avg.__closure__[0].cell_contents \u548c my_avg.__closure__[1].cell_contents \u91cc\u9762\u4fdd\u5b58\u4e86\u6700\u540e\u4e00\u6b21\u6267\u884c\u7684\u771f\u5b9e\u503c\u3002 def make_avg(): count = 0 total = 0 def avg(newValue): nonlocal count, total count += 1 total += newValue return total / count return avg my_avg = make_avg() my_avg(10) # 10.0 my_avg(20) # 15.0 my_avg(30) # 20.0 my_avg.__code__.co_varnames # ('newValue',) my_avg.__code__.co_freevars # ('count', 'total') my_avg.__closure__ # (<cell at 0x7fe93d3474c8: int object at 0x7fe93e865240>, <cell at 0x7fe93d347318: int object at 0x7fe93e865960>) my_avg.__closure__[0].cell_contents # 3 my_avg.__closure__[1].cell_contents # 60 \u4f8b\u4e8c\uff1a money \u662f\u4e00\u4e2a\u5c40\u90e8\u53d8\u91cf\uff0c\u5728 get_money \u662f\u5916\u56f4\u51fd\u6570\uff0c\u51fd\u6570\u6267\u884c\u4e4b\u540e\u5e94\u8be5\u5c31\u4e0d\u4f1a\u5b58\u5728\u4e86\u3002 \u4f46\u662f\u5d4c\u5957\u51fd\u6570 work \u5f15\u7528\u4e86 money \u8fd9\u4e2a\u81ea\u7531\u53d8\u91cf\uff0c\u5c06\u8fd9\u4e2a\u5c40\u90e8\u53d8\u91cf\u5c01\u95ed\u5728\u4e86\u5d4c\u5957\u51fd\u6570 work \u4e2d\uff0c\u8fd9\u6837\u5c31\u5f62\u6210\u4e86\u4e00\u4e2a\u95ed\u5305\u3002 closure = get_money() \u83b7\u5f97\u7684\u5c31\u662f\u4e00\u4e2a\u95ed\u5305\u3002 closure() \u8f93\u51fa\u95ed\u5305\uff0c\u5373\uff0c\u6267\u884c\u4e86 work() \uff0c\u6253\u5370\u8f93\u51fa money \u7684\u503c\u3002 \u672c\u5730\u51fd\u6570\u901a\u8fc7global\u58f0\u660e\u5bf9\u5168\u5c40\u53d8\u91cf\u8fdb\u884c\u5f15\u7528\u4fee\u6539\uff0c\u90a3\u4e48\u5bf9\u4e8e\u5185\u5d4c\u51fd\u6570 work() \u4f5c\u7528\u57df\u4e2d\u7684\u53d8\u91cf\u8fdb\u884c\u4fee\u6539\uff0c\u5c31\u8981\u4f7f\u7528 nonlocal \u8fdb\u884c\u58f0\u660e\u3002 def get_money(): money = 0 def work(): nonlocal money money += 100 print(money) return work closure = get_money() closure() # 100 closure() # 200 closure() # 300 \u4f8b\u4e09\uff1a \u51fd\u6570 maker \u4e2d\u5b9a\u4e49\u4e86\u51fd\u6570 action \uff0c action \u5f15\u7528\u4e86 maker \u5d4c\u5957\u4f5c\u7528\u57df\u5185\u7684\u53d8\u91cf k \uff0c\u5e76\u4e14\uff0c maker \u5c06\u51fd\u6570 action \u4f5c\u4e3a\u8fd4\u56de\u5bf9\u8c61\u8fdb\u884c\u8fd4\u56de\u3002 \u8fd9\u6837\uff0c\u6211\u4eec\u901a\u8fc7\u6267\u884c f = maker(2) \uff0c f \u83b7\u53d6\u4e86\u8fd4\u56de\u5bf9\u8c61 action \uff0c\u867d\u7136\u6b64\u65f6 maker \u51fd\u6570\u4ee5\u53ca\u7ed3\u675f\u9000\u51fa\u4e86\uff0c\u4f46\u5bf9\u8c61 f \u4ecd\u7136\u8bb0\u4f4f\u4e86\u51fd\u6570 maker \u5d4c\u5957\u4f5c\u7528\u57df\u5185\u7684\u53d8\u91cf k \u548c n \uff0c\u5e76\u5728\u6267\u884c f(3) \u65f6\uff0c\u5c06 x=3 \u4ee5\u53ca\u4e4b\u524d\u8bb0\u4f4f\u7684 k \u548c n \uff0c\u4e00\u5e76\u4f20\u5165 action() \uff0c\u8ba1\u7b97\u5e76\u8fd4\u56de x + n + k \u503c\u3002 make \u4e5f\u79f0\u4e3a \u5de5\u5382\u51fd\u6570 \u3002 def maker(n): k = 8 def action(x): return x + n + k return action f = maker(2) print(f(3)) # 13 print(f(4)) # 14 print(f(5)) # 15 \u7ed3\u5408\u524d\u97622\u4e2a\u4f8b\u5b50\u518d\u770b\u4e0a\u9762\u7684\u89e3\u91ca\uff0c\u95ed\u5305\u5c31\u662f\u5f15\u7528\u4e86\u81ea\u7531\u53d8\u91cf\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u4fdd\u5b58\u4e86\u6267\u884c\u7684\u4e0a\u4e0b\u6587\uff0c\u53ef\u4ee5\u8131\u79bb\u539f\u672c\u7684\u4f5c\u7528\u57df\u72ec\u7acb\u5b58\u5728\u3002 \u88c5\u9970\u5668 \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5c06\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u4f20\u7ed9\u53e6\u4e00\u4e2a\u51fd\u6570\uff0c\u51fd\u6570 my_decorator \u7684\u4f20\u5165\u53c2\u6570\u6b63\u597d\u662f\u5176\u5d4c\u5957\u51fd\u6570 myFunc \u3002 def my_decorator(nestedFunc): def myFunc(): print(\"Before executing nestedFunc()\") nestedFunc() print(\"After executing nestedFunc()\") return myFunc def nestedFunc(): print(\"Decoration - executing nestedFunc()\") nestedFunc() # Decoration - executing nestedFunc() nestedFunc = my_decorator(nestedFunc) nestedFunc() # Before executing nestedFunc() # Decoration - executing nestedFunc() # After executing nestedFunc() \u88c5\u9970\u5668\u53ea\u662f\u4e2a\u65b9\u6cd5\uff0c\u4f7f\u7528\u65f6\u7528\u4e86 @ \u8bed\u6cd5\u3002 @ \u8bed\u6cd5\u53ea\u662f\u5c06\u51fd\u6570 nestedFunc \u4f20\u5165\u88c5\u9970\u5668\u51fd\u6570 my_decorator \u3002 @my_decorator \u662f nestedFunc = my_decorator(nestedFunc) \u7684\u5feb\u6377\u8868\u8fbe\u65b9\u5f0f\uff0c @my_decorator def nestedFunc(): print(\"New added to decoration - executing nestedFunc()\") nestedFunc() # Before executing nestedFunc() # New added to decoration - executing nestedFunc() # After executing nestedFunc() print(nestedFunc.__name__) # myFunc \u4f46\u4e0a\u4f8b\u6700\u540e\u7684\u8f93\u51fa\u4e0d\u662f\u6211\u4eec\u60f3\u8981\u7684\uff0c\u6211\u4eec\u5e0c\u671b\u8f93\u51fa nestedFunc \uff0c\u4f46\u5374\u88ab myFunc \u66ff\u4ee3\u4e86\uff0c\u5b83\u91cd\u5199\u4e86\u6211\u4eec\u51fd\u6570\u7684\u540d\u5b57\u548c\u6ce8\u91ca\u6587\u6863(docstring)\u3002 \u4e0b\u9762\u4f7f\u7528 functools.wraps \u6765\u4fee\u6b63\u4e0a\u9762\u7684\u95ee\u9898\u3002 from functools import wraps def my_decorator(nestedFunc): @wraps(nestedFunc) def myFunc(): print(\"Before executing nestedFunc()\") nestedFunc() print(\"After executing nestedFunc()\") return myFunc def nestedFunc(): print(\"Decoration - executing nestedFunc()\") @my_decorator def nestedFunc(): print(\"New added to decoration - executing nestedFunc()\") nestedFunc() # Before executing nestedFunc() # New added to decoration - executing nestedFunc() # After executing nestedFunc() print(nestedFunc.__name__) # nestedFunc \u4e0b\u9762\u662f\u88c5\u9970\u5668\u7684\u84dd\u672c\u89c4\u8303\u3002 from functools import wraps def decorator_name(f): @wraps(f) def decorated(*args, **kwargs): if not can_run: return \"Function will not run\" return f(*args, **kwargs) return decorated @decorator_name def func(): return (\"Function is running\") can_run = True print(func()) # Output: Function is running can_run = False print(func()) # Output: Function will not run \u4e0b\u9762\u8fd8\u662f\u4e00\u4e2a\u88c5\u9970\u5668\u7684\u4f8b\u5b50\u3002\u628a\u4e0b\u9762\u7684\u4ee3\u7801\u6bb5\u4fdd\u5b58\u5230\u6587\u4ef6 test.py \u3002 registry = [] def register(func): print(f'running register {func}') registry.append(func) return func @register def f1(): print('running f1()') @register def f2(): print('running f2()') def f3(): print('running f3()') def main(): print('runnning main()') print(f'registry--> {registry}') f1() f2() f3() if __name__ == '__main__': main() \u6267\u884c\u4e0a\u8ff0\u4ee3\u7801\u6bb5 python3 test.py \uff0c\u5f97\u5230\u4e0b\u9762\u7684\u7ed3\u679c\u3002 running register <function f1 at 0x7f70847bec80> running register <function f2 at 0x7f70705aa9d8> runnning main() registry--> [<function f1 at 0x7f70847bec80>, <function f2 at 0x7f70705aa9d8>] running f1() running f2() running f3() register \u5728\u6a21\u5757\u4e2d\u5176\u4ed6\u51fd\u6570\u4e4b\u524d\u8fd0\u884c\uff08\u4e24\u6b21\uff09\u3002\u8c03\u7528 register \u65f6\uff0c\u4f20\u7ed9\u5b83\u7684\u53c2\u6570\u662f\u88ab\u88c5\u9970\u7684\u51fd\u6570\uff0c\u4f8b\u5982 function f1 at 0x7f70847bec80> \u3002\u52a0\u8f7d\u6a21\u5757\u540e\uff0c registry \u4e2d\u6709\u4e24\u4e2a\u88ab\u88c5\u9970\u51fd\u6570\u7684\u5f15\u7528\uff1a f1 \u548c f2 \u3002\u8fd9\u4e24\u4e2a\u51fd\u6570\uff0c\u4ee5\u53ca f3 \uff0c\u53ea\u5728 main \u660e\u786e\u8c03\u7528\u5b83\u4eec\u65f6\u624d\u6267\u884c\u3002 \u7531\u6b64\u5f97\uff0c\u51fd\u6570\u88c5\u9970\u5668\u5728\u5bfc\u5165\u6a21\u5757\u65f6\u7acb\u5373\u6267\u884c\uff0c\u800c\u88ab\u88c5\u9970\u7684\u51fd\u6570\u53ea\u5728\u660e\u786e\u8c03\u7528\u65f6\u8fd0\u884c\uff0c\u5373Python\u4e2d\u63d0\u5230\u7684 \u5bfc\u5165\u65f6 \u548c \u8fd0\u884c\u65f6 \u4e4b\u95f4\u7684\u533a\u522b\u3002 \u4e0a\u9762\u4f8b\u5b50\u4e2d\u88c5\u9970\u5668\u51fd\u6570\u4e0e\u88ab\u88c5\u9970\u7684\u51fd\u6570\u5728\u540c\u4e00\u4e2a\u6a21\u5757\u4e2d\u5b9a\u4e49\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u88c5\u9970\u5668\u901a\u5e38\u5728\u4e00\u4e2a\u6a21\u5757\u4e2d\u5b9a\u4e49\uff0c\u7136\u540e\u5e94\u7528\u5230\u5176\u4ed6\u6a21\u5757\u4e2d\u7684\u51fd\u6570\u4e0a\u3002 \u4e0a\u9762\u4f8b\u5b50\u4e2d register \u88c5\u9970\u5668\u8fd4\u56de\u7684\u51fd\u6570\u4e0e\u901a\u8fc7\u53c2\u6570\u4f20\u5165\u7684\u76f8\u540c\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5927\u591a\u6570\u88c5\u9970\u5668\u4f1a\u5728\u5185\u90e8\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\uff0c\u7136\u540e\u5c06\u5176\u8fd4\u56de\u3002","title":"\u5185\u7f6e\u51fd\u6570\u53ca\u6587\u4ef6"},{"location":"python/Foundation/ch03/#_1","text":"","title":"\u5185\u7f6e\u51fd\u6570\u53ca\u6587\u4ef6"},{"location":"python/Foundation/ch03/#1-lambda","text":"\u533f\u540d\u51fd\u6570\u662f\u4e00\u79cd\u901a\u8fc7\u5355\u4e2a\u8bed\u53e5\u751f\u6210\u51fd\u6570\u7684\u65b9\u5f0f\uff0c\u5176\u7ed3\u679c\u662f\u8fd4\u56de\u503c\u3002\u533f\u540d\u51fd\u6570\u4f7f\u7528lambda\u5173\u952e\u5b57\u5b9a\u4e49\uff0c\u8be5\u5173\u952e\u5b57\u4ec5\u8868\u8fbe\u201c\u6211\u4eec\u58f0\u660e\u4e00\u4e2a\u533f\u540d\u51fd\u6570\u201d\u7684\u610f\u601d\u3002 lambda \u51fd\u6570\u53ef\u4ee5\u63a5\u6536\u4efb\u610f\u591a\u4e2a\u53c2\u6570 (\u5305\u62ec\u53ef\u9009\u53c2\u6570) \u5e76\u4e14\u8fd4\u56de\u5355\u4e2a\u8868\u8fbe\u5f0f\u7684\u503c\u3002 lambda arg1,arg2,arg3\u2026 :<\u8868\u8fbe\u5f0f> f = lambda x, y: x * y print(f(2, 3)) # 6 f = [lambda a: a * 2, lambda b: b * 3] print(f[0](5)) # \u6267\u884cf\u5217\u8868\u7b2c\u4e00\u4e2a\u5143\u7d20 # 10 print(f[1](5)) # \u6267\u884cf\u5143\u7d20\u7b2c\u4e8c\u4e2a\u5143\u7d20 # 15 print(f[0, 1](5, 5)) # TypeError: list indices must be integers or slices, not tuple \u793a\u4f8b1\uff1a def short_func1(x): return x * 2 short_func2 = lambda x: x * 2 print(short_func1(5)) # 10 print(short_func2(5)) # 10 \u793a\u4f8b2\uff1a def apply_to_list(some_list, f): return [f(x) for x in some_list] ints = [4, 0, 1, 5, 6] result5 = apply_to_list(ints, lambda x: x * 2) print(result5) # [8, 0, 2, 10, 12] lambda: None \u51fd\u6570\u6ca1\u6709\u8f93\u5165\u53c2\u6570\uff0c\u8f93\u51fa\u662fNone\u3002 print(lambda: None) # <function <lambda> at 0x7fa5c4097670> lambda **kwargs: 1 \u8f93\u5165\u662f\u4efb\u610f\u952e\u503c\u5bf9\u53c2\u6570\uff0c\u8f93\u51fa\u662f1\u3002 print(lambda **kwargs: 1) # <function <lambda> at 0x7fa5c4097670>","title":"1. \u533f\u540d\uff08Lambda\uff09\u51fd\u6570"},{"location":"python/Foundation/ch03/#2-enumerate","text":"\u5f53\u9700\u8981\u5bf9\u6570\u636e\u5efa\u7acb\u7d22\u5f15\u65f6\uff0c\u4e00\u79cd\u6709\u6548\u7684\u6a21\u5f0f\u5c31\u662f\u4f7f\u7528enumerate\u6784\u9020\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u5e8f\u5217\u503c\uff08\u5047\u8bbe\u662f\u552f\u4e00\u7684\uff09\u6620\u5c04\u5230\u7d22\u5f15\u4f4d\u7f6e\u4e0a\u3002 seasons = ['Spring', 'Summer', 'Fall', 'Winter'] print(list(enumerate(seasons))) # [(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')] \u5bf9\u6bd4\u4e0b\u97622\u4e2a\u5faa\u73af a_list = ['foo', 'bar', 'baz'] mapping = {} for i, v in enumerate(a_list): # enumerate\u751f\u6210\u7d22\u5f15\u503ci\u548c\u5e8f\u5217\u503cv mapping[v] = i print(mapping) # {'foo': 0, 'bar': 1, 'baz': 2} i = 0 mapping = {} for v in a_list: print(i, a_list[i]) mapping[v] = i # \u53ef\u4ee5\u628ai\u548cv\u4e92\u6362 i += 1 print(mapping) # {'foo': 0, 'bar': 1, 'baz': 2} \u5229\u7528 enumerate() \u6279\u91cf\u4fee\u6539\u5217\u8868\u5185\u7684\u5143\u7d20 a_list = ['01', '02', '03'] unit_element = '1' for i, element in enumerate(a_list): a_list[i] = unit_element + element print(a_list) # ['101', '102', '103'] sorted\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u6839\u636e\u4efb\u610f\u5e8f\u5217\u4e2d\u7684\u5143\u7d20\u65b0\u5efa\u7684\u5df2\u6392\u5e8f\u5217\u8868\u3002sorted\u51fd\u6570\u63a5\u53d7\u7684\u53c2\u6570\u4e0e\u5217\u8868\u7684sort\u65b9\u6cd5\u4e00\u81f4\u3002 y = sorted([7, 1, 2, 6, 0, 3, 2]) print(y) # [0, 1, 2, 2, 3, 6, 7] \u7ed3\u679c\u5df2\u6392\u5e8f z = sorted('Hello World') print(z) # [' ', 'H', 'W', 'd', 'e', 'l', 'l', 'l', 'o', 'o', 'r'] zip\u5c06\u5217\u8868\u3001\u5143\u7ec4\u6216\u5176\u4ed6\u5e8f\u5217\u7684\u5143\u7d20\u914d\u5bf9\uff0c\u65b0\u5efa\u4e00\u4e2a\u5143\u7ec4\u6784\u6210\u7684\u5217\u8868\u3002 seq1 = ['foo', 'bar', 'baz'] seq2 = ['one', 'two', 'three'] seq3 = [False, True] zipped = zip(seq1, seq2) print(list(zipped)) # [('foo', 'one'), ('bar', 'two'), ('baz', 'three')] zipped = zip(seq1, seq2, seq3) print(list(zipped)) # [('foo', 'one', False), ('bar', 'two', True)] for i, (a, b) in enumerate(zip(seq1, seq2)): print('{0}: {1}, {2}'.format(i, a, b)) # \u65b9\u6cd51 {0}\u5217\u8868\u5143\u7d20\u7684\u7d22\u5f15, {1}\u5143\u7ec4\u4e2d\u7b2c\u4e00\u4e2a\u503c, {2}\u5143\u7ec4\u4e2d\u7b2c\u4e8c\u4e2a\u503c print(f'{i}: {a}, {b}') # \u65b9\u6cd52 # 0: foo, one # 1: bar, two # 2: baz, three \u7ed9\u5b9a\u4e00\u4e2a\u5df2\u201c\u914d\u5bf9\u201d\u7684\u5e8f\u5217\u65f6\uff0czip\u51fd\u6570\u53ef\u4ee5\u53bb\u201c\u62c6\u5206\u201d\u5e8f\u5217\u3002\u8fd9\u79cd\u65b9\u5f0f\u7684\u53e6\u4e00\u79cd\u601d\u8def\u5c31\u662f\u5c06\u884c\u7684\u5217\u8868\u8f6c\u6362\u4e3a\u5217\u7684\u5217\u8868\u3002\u53c2\u8003Python\u7684 Unpacking pitchers = [('Jack', 'Ma'), ('Tom', 'Li'), ('Jimmy', 'Zhang')] first_names, last_names = zip(*pitchers) print(first_names) # ('Jack', 'Tom', 'Jimmy') print(last_names) # ('Ma', 'Li', 'Zhang') reversed\u51fd\u6570\u5c06\u5e8f\u5217\u7684\u5143\u7d20\u5012\u5e8f\u6392\u5217 print(list(reversed(range(10)))) # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]","title":"2. \u5185\u7f6e\u5e8f\u5217\u51fd\u6570enumerate"},{"location":"python/Foundation/ch03/#3","text":"\u63a8\u5bfc\u5f0fcomprehensions\uff08\u53c8\u79f0\u89e3\u6790\u5f0f\uff09\uff0c\u662fPython\u7684\u4e00\u79cd\u7279\u6027\u3002\u4f7f\u7528\u63a8\u5bfc\u5f0f\u53ef\u4ee5\u5feb\u901f\u751f\u6210\u5217\u8868\u3001\u5143\u7ec4\u3001\u96c6\u5408\u3001\u5b57\u5178\u7c7b\u578b\u7684\u6570\u636e\u3002\u63a8\u5bfc\u5f0f\u53c8\u5206\u4e3a\u5217\u8868\u63a8\u5bfc\u5f0f\u3001\u5143\u7ec4\u63a8\u5bfc\u5f0f\u3001\u96c6\u5408\u63a8\u5bfc\u5f0f\u3001\u5b57\u5178\u63a8\u5bfc\u5f0f\u3002","title":"3. \u5217\u8868\u3001\u96c6\u5408\u548c\u5b57\u5178\u7684\u63a8\u5bfc\u5f0f"},{"location":"python/Foundation/ch03/#list-comprehension","text":"\u5217\u8868\u63a8\u5bfc\u5f0f(list comprehension)\u5141\u8bb8\u4f60\u8fc7\u6ee4\u4e00\u4e2a\u5bb9\u5668\u7684\u5143\u7d20\uff0c\u7528\u4e00\u79cd\u7b80\u660e\u7684\u8868\u8fbe\u5f0f\u8f6c\u6362\u4f20\u9012\u7ed9\u8fc7\u6ee4\u5668\u7684\u5143\u7d20\uff0c\u4ece\u800c\u751f\u6210\u4e00\u4e2a\u65b0\u7684\u5217\u8868\u3002 \u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u57fa\u672c\u5f62\u5f0f\u4e3a\uff1a[expr for val in collection if condition]\uff0c\u6761\u4ef6if-condition\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u53ef\u4ee5\u53ea\u4fdd\u7559\u8868\u8fbe\u5f0f\u3002\u5217\u8868\u63a8\u5bfc\u5f0f\u4e0e\u4e0b\u9762\u7684for\u5faa\u73af\u662f\u7b49\u4ef7\u7684\uff1a result = [] for val in collection: if condition: result.append(expr) \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a data = [] for i in range(-5, 5): if i >= -1: data.append(i**2) print(data) # [1, 0, 1, 4, 9, 16] data = [i**2 for i in range(-5, 5) if i >= -1] print(data) # [1, 0, 1, 4, 9, 16] \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u4f7f\u7528for\u53bb\u904d\u5386\u4e00\u4e2a\u53ef\u8fed\u4ee3\u7684\u5217\u8868\u3002 data = [] fruit = [ 'pomegranate', 'cherry', 'apricot', 'date', 'Apple', 'lemon', 'kiwi', 'ORANGE', 'lime', 'Watermelon', 'guava', 'papaya', 'FIG', 'pear', 'banana', 'Tamarind', 'persimmon', 'elderberry', 'peach', 'BLUEberry', 'lychee', 'grape' ] data = [x.upper() if x.startswith('p') else x.title() for x in fruit] print(data) # ['POMEGRANATE', 'Cherry', 'Apricot', 'Date', 'Apple', 'Lemon', 'Kiwi', 'Orange', 'Lime', 'Watermelon', 'Guava', 'PAPAYA', 'Fig', 'PEAR', 'Banana', 'Tamarind', 'PERSIMMON', 'Elderberry', 'PEACH', 'Blueberry', 'Lychee', 'Grape']","title":"\u5217\u8868\u63a8\u5bfc\u5f0f(list comprehension)"},{"location":"python/Foundation/ch03/#_2","text":"\u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u4ee3\u66ff2\u5c42for\u5faa\u73af\u3002 data = [] for i in range(1, 3): if i >= 0: for j in range(1, 3): data.append((i, j)) print(data) # [(1, 1), (1, 2), (2, 1), (2, 2)] data = [(i, j) for i in range(1, 3) if i >= -1 for j in range(1, 3)] print(data) # [(1, 1), (1, 2), (2, 1), (2, 2)] \u518d\u4e3e\u4e00\u4e2a\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u4f8b\u5b50\u3002 all_data = [ ['John', 'Emily', 'Michael', 'Lee', 'Steven'], ['Maria', 'Juan', 'Javier', 'Natalia', 'Pilar'], ] names_of_interest = [] for names in all_data: enough_es = [name for name in names if name.count('e') >=2] names_of_interest.extend(enough_es) print(names_of_interest) # ['Lee', 'Steven'] result = [name for names in all_data for name in names if name.count('e') >= 2] print(result) # ['Lee', 'Steven'] \u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u77e9\u9635\u6241\u5e73\u5316\u3002 \u8003\u8651\u4e0b\u9762\u8fd9\u4e2a3x4\u7684\u77e9\u9635\uff0c\u5b83\u75313\u4e2a\u957f\u5ea6\u4e3a4\u7684\u5217\u8868\u7ec4\u6210\u3002\u4e0b\u9762\u4f8b\u5b50\u5bf9\u6bd4\u4e86\u7528\u4f20\u7edffor\u5faa\u73af\u5c06\u77e9\u9635\u6241\u5e73\u5316\uff0c\u548c\u7528\u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u77e9\u9635\u6241\u5e73\u5316\u3002\u5e76\u4e14\u901a\u8fc7\u5217\u8868\u63a8\u5bfc\u5f0f\u4e2d\u7684\u5217\u8868\u63a8\u5bfc\u5f0f\u5c06\u6241\u5e73\u77e9\u9635\u8fd8\u539f\u4e3a3x4\u77e9\u9635\u3002 matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], ] flattened = [] # \u4f20\u7edffor\u5faa\u73af\u5d4c\u5957 for m in matrix: for x in m: flattened.append(x) print(flattened) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # \u5d4c\u5957\u5217\u8868\u63a8\u5bfc\u5f0f flattened = [x for m in matrix for x in m] print(flattened) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # \u5217\u8868\u63a8\u5bfc\u5f0f\u4e2d\u7684\u5217\u8868\u63a8\u5bfc\u5f0f z = [[x for x in m] for m in matrix] print(z) # [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]","title":"\u5957\u5217\u8868\u63a8\u5bfc\u5f0f"},{"location":"python/Foundation/ch03/#_3","text":"\u4e0b\u9762\u7684\u4f8b\u5b50\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6570\u5b571~5\u7684\u5143\u7ec4\u3002\u4ece\u7ed3\u679c\u53ef\u4ee5\u770b\u5230\uff0c\u5143\u7ec4\u63a8\u5bfc\u5f0f\u751f\u6210\u7684\u7ed3\u679c\u5e76\u4e0d\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u800c\u662f\u4e00\u4e2a\u751f\u6210\u5668\u5bf9\u8c61\uff0c\u9700\u8981\u901a\u8fc7tuple()\u51fd\u6570\uff0c\u5c06\u751f\u6210\u5668\u5bf9\u8c61\u8f6c\u6362\u6210\u5143\u7ec4\u3002 data = (x for x in range(5)) print(data) # <generator object <genexpr> at 0x7f87217a8e40> print(type(data)) # <class 'generator'> print(tuple(data)) # (0, 1, 2, 3, 4)","title":"\u5143\u7ec4\u63a8\u5bfc\u5f0f"},{"location":"python/Foundation/ch03/#_4","text":"\u4e0b\u9762\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u96c6\u5408\u63a8\u5bfc\u5f0f\u4f8b\u5b50\u3002 data = {x**2 for x in range(5)} print(data) # {0, 1, 4, 9, 16} print(type(data)) # <class 'set'> \u96c6\u5408\u8981\u4fdd\u8bc1\u5143\u7d20\u5fc5\u987b\u662f\u552f\u4e00\u7684\u3002 data = (1, 1, 2, 2, 3, 3, 4, 5, 6) newset = {x**2 for x in data} print(newset) # {1, 4, 36, 9, 16, 25} print(type(newset) # <class 'set'>","title":"\u96c6\u5408\u63a8\u5bfc\u5f0f"},{"location":"python/Foundation/ch03/#_5","text":"\u5b57\u5178\u63a8\u5bfc\u5f0f: dict_comp = {key-expr : value-expr for value in collection if condition} \u5b57\u5178\u63a8\u5bfc\u5f0f\u7684\u7b80\u5355\u793a\u4f8b\uff1a strings = ['a', 'as', 'bat', 'car', 'dove', 'python'] loc_mapping = {index: val for index, val in enumerate(strings)} print(loc_mapping) # {0: 'a', 1: 'as', 2: 'bat', 3: 'car', 4: 'dove', 5: 'python'} # \u4ea4\u6362\u952e\u548c\u503c loc_mapping = {index: val for val, index in enumerate(strings)} print(loc_mapping) # {'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5}","title":"\u5b57\u5178\u63a8\u5bfc\u5f0f"},{"location":"python/Foundation/ch03/#4","text":"\u5982\u679cPython\u8fbe\u5230\u51fd\u6570\u7684\u5c3e\u90e8\u65f6\u4ecd\u7136\u6ca1\u6709\u9047\u5230return\u8bed\u53e5\uff0c\u5c31\u4f1a\u81ea\u52a8\u8fd4\u56deNone\u3002 \u6bcf\u4e2a\u51fd\u6570\u90fd\u53ef\u4ee5\u6709\u4f4d\u7f6e\u53c2\u6570\u548c\u5173\u952e\u5b57\u53c2\u6570\u3002\u5173\u952e\u5b57\u53c2\u6570\u6700\u5e38\u7528\u4e8e\u6307\u5b9a\u9ed8\u8ba4\u503c\u6216\u53ef\u9009\u53c2\u6570\u3002\u5173\u952e\u5b57\u53c2\u6570\u5fc5\u987b\u8ddf\u5728\u4f4d\u7f6e\u53c2\u6570\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528\u5173\u952e\u5b57\u53c2\u6570\u5411\u4f4d\u7f6e\u53c2\u6570\u4f20\u53c2\u3002 import sys def my_function1(x, y, z=1.5): if z > 1: return z * (x + y) else: return z / (x + y) result1 = my_function1(5, 6, z=0.7) print(result1) # 0.06363636363636363 result1 = my_function1(x=5, y=6, z=0.7) print(result1) # 0.06363636363636363 result1 = my_function1(3.14, 7, 3.5) print(result1) # 35.49 result1 = my_function1(10, 20) print(result1) # 45.0","title":"4. \u51fd\u6570\u58f0\u660e"},{"location":"python/Foundation/ch03/#5","text":"\u51fd\u6570\u6709\u4e24\u79cd\u8fde\u63a5\u53d8\u91cf\u7684\u65b9\u5f0f\uff1a\u5168\u5c40\u3001\u672c\u5730\u3002 def func1(): list1 = [] # \u672c\u5730\u53d8\u91cf for i in range(5): list1.append(i) print(list1) func1() # [0, 1, 2, 3, 4] list2 = [] # \u5168\u5c40\u53d8\u91cf def func2(): global list2 # \u5168\u5c40\u53d8\u91cf for i in range(5): list2.append(i) print(list2) func2() # [0, 1, 2, 3, 4] \u6570\u636e\u6e05\u6d17\u793a\u4f8b states = [' Alabama', 'Georgia!', 'georgia', 'Georgia', 'FlOrIda', 'south carolina##', 'West virginia? '] # \u65b9\u6cd51 import re def clean_string1(strings): result2 = [] for value in strings: value = value.strip() value = re.sub('[! #? ]', '', value) value = value.title() result2.append(value) return result2 print(clean_string1((states))) # ['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'Southcarolina', 'Westvirginia'] # \u65b9\u6cd52 def remove_punctuaion(value): return re.sub('[! #? ]', '', value) clean_ops = [str.strip, remove_punctuaion, str.title] def clean_string2(strings, ops): result3 = [] for value in strings: for function in ops: value = function(value) result3.append(value) return result3 result4 = clean_string2(states, clean_ops) print(result4) # ['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'Southcarolina', 'Westvirginia'] # \u53ef\u4ee5\u5c06\u51fd\u6570\u4f5c\u4e3a\u4e00\u4e2a\u53c2\u6570\u4f20\u7ed9\u5176\u4ed6\u7684\u51fd\u6570\u3002 for x in map(remove_punctuaion, states): print(x) # Alabama # Georgia # georgia # Georgia # FlOrIda # southcarolina # Westvirginia","title":"5. \u547d\u540d\u7a7a\u95f4\u3001\u4f5c\u7528\u57df\u548c\u672c\u5730\u51fd\u6570"},{"location":"python/Foundation/ch03/#6","text":"\u67ef\u91cc\u5316\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u672f\u8bed\uff08\u4ee5\u6570\u5b66\u5bb6Haskell Curry\u547d\u540d\uff09\uff0c\u5b83\u8868\u793a\u901a\u8fc7\u90e8\u5206\u53c2\u6570\u5e94\u7528\u7684\u65b9\u5f0f\u4ece\u5df2\u6709\u7684\u51fd\u6570\u4e2d\u884d\u751f\u51fa\u65b0\u7684\u51fd\u6570\u3002\u67ef\u91cc\u5316\u662f\u4e00\u79cd\u5c06\u591a\u53c2\u6570\u51fd\u6570\u8f6c\u5316\u4e3a\u5355\u53c2\u6570\u9ad8\u9636\u51fd\u6570\u7684\u6280\u672f\uff0c\u5982\u679c\u4f60\u56fa\u5b9a\u67d0\u4e9b\u53c2\u6570\uff0c\u4f60\u5c06\u5f97\u5230\u63a5\u53d7\u4f59\u4e0b\u53c2\u6570\u7684\u4e00\u4e2a\u51fd\u6570\u3002 \u5b9a\u4e49\u4e00\uff1a \u67ef\u91cc\u5316\uff1a\u4e00\u4e2a\u51fd\u6570\u4e2d\u6709\u4e2a\u591a\u4e2a\u53c2\u6570\uff0c\u60f3\u56fa\u5b9a\u5176\u4e2d\u67d0\u4e2a\u6216\u8005\u51e0\u4e2a\u53c2\u6570\u7684\u503c\uff0c\u800c\u53ea\u63a5\u53d7\u53e6\u5916\u51e0\u4e2a\u8fd8\u672a\u56fa\u5b9a\u7684\u53c2\u6570\uff0c\u8fd9\u6837\u51fd\u6570\u6f14\u53d8\u6210\u65b0\u7684\u51fd\u6570\u3002 \u5b9a\u4e49\u4e8c\uff1a \u51fd\u6570\u67ef\u91cc\u5316\uff08currying\uff09\u53c8\u79f0\u90e8\u5206\u6c42\u503c\u3002\u4e00\u4e2a currying \u7684\u51fd\u6570\u9996\u5148\u4f1a\u63a5\u53d7\u4e00\u4e9b\u53c2\u6570\uff0c\u63a5\u53d7\u4e86\u8fd9\u4e9b\u53c2\u6570\u4e4b\u540e\uff0c\u8be5\u51fd\u6570\u5e76\u4e0d\u4f1a\u7acb\u5373\u6c42\u503c\uff0c\u800c\u662f\u7ee7\u7eed\u8fd4\u56de\u53e6\u5916\u4e00\u4e2a\u51fd\u6570\uff0c\u521a\u624d\u4f20\u5165\u7684\u53c2\u6570\u5728\u51fd\u6570\u5f62\u6210\u7684\u95ed\u5305\u4e2d\u88ab\u4fdd\u5b58\u8d77\u6765\u3002\u5f85\u5230\u51fd\u6570\u88ab\u771f\u6b63\u9700\u8981\u6c42\u503c\u7684\u65f6\u5019\uff0c\u4e4b\u524d\u4f20\u5165\u7684\u6240\u6709\u53c2\u6570\u90fd\u4f1a\u88ab\u4e00\u6b21\u6027\u7528\u4e8e\u6c42\u503c\u3002 \u5b9a\u4e49\u4e09\uff1a \u4e00\u4e9b\u51fd\u6570\u5f0f\u8bed\u8a00\u7684\u5de5\u4f5c\u539f\u7406\u662f\u5c06\u591a\u53c2\u6570\u51fd\u6570\u8bed\u6cd5\u8f6c\u5316\u4e3a\u5355\u53c2\u6570\u51fd\u6570\u96c6\u5408\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u79f0\u4e3a\u67ef\u91cc\u5316\uff0c\u5b83\u662f\u4ee5\u903b\u8f91\u5b66\u5bb6Haskell Curry\u7684\u540d\u5b57\u547d\u540d\u7684\u3002Haskell Curry\u4ece\u65e9\u671f\u6982\u5ff5\u4e2d\u53d1\u5c55\u51fa\u4e86\u8be5\u7406\u8bba\u3002\u5176\u5f62\u5f0f\u76f8\u5f53\u4e8e\u5c06z=f(x, y)\u8f6c\u6362\u6210z=f(x)(y)\u7684\u5f62\u5f0f\uff0c\u539f\u51fd\u6570\u7531\u4e24\u4e2a\u53c2\u6570\uff0c\u73b0\u5728\u53d8\u4e3a\u4e24\u4e2a\u63a5\u53d7\u5355\u53c2\u6570\u7684\u51fd\u6570\uff0c \u793a\u4f8b1\uff1a\u67ef\u91cc\u5316\u7684\u8fc7\u7a0b\u5c31\u662f\u628a\u539f\u6765\u5e26\u4e24\u4e2a\u53c2\u6570\u7684\u51fd\u6570add(x, y)\uff0c\u53d8\u6210\u4e86\u4e00\u4e2a\u5d4c\u5957\u51fd\u6570\uff0c\u5728add_currying\u51fd\u6570\u5185\uff0c\u53c8\u5b9a\u4e49\u4e86\u4e00\u4e2a_add\u51fd\u6570\uff0c\u5e76\u4e14_add\u51fd\u6570\u53c8\u5f15\u7528\u4e86\u5916\u90e8\u51fd\u6570add_currying\u7684\u53d8\u91cfx\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a\u95ed\u5305\u3002 \u95ed\u5305\uff0c\u4e00\u53e5\u8bdd\u8bf4\u5c31\u662f\u5728\u51fd\u6570\u4e2d\u518d\u5d4c\u5957\u4e00\u4e2a\u51fd\u6570\uff0c\u5e76\u4e14\u5f15\u7528\u5916\u90e8\u51fd\u6570\u7684\u53d8\u91cf\u3002 # \u666e\u901a\u5199\u6cd5 def add(x, y): return x + y print(add(1, 2)) # 3 # \u67ef\u91cc\u5316\u5199\u6cd5 def add_currying(x): def _add(y): return x + y return _add print(add_currying(1)(2)) # 3 \u793a\u4f8b2\uff0c\u901a\u8fc7\u56fa\u5b9a\u5176\u4e2d\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e0d\u53d8\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 def add2(a, b): def add1(a, b, c): return a + b + c return add1(a, 666, b) result6 = add2(12, 13) print(result6) # 691 result6 = add2(12, 555, 13) # TypeError: add2() takes 2 positional arguments but 3 were given \u793a\u4f8b3\uff0c\u901a\u8fc7functools\u63d0\u4f9b\u7684\u504f\u51fd\u6570\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 from functools import partial def add1(a, b, c): return a + b + c add3 = partial(add1, b=666) result7 = add3(a=12, c=13) print(result7) # 691 \u793a\u4f8b4\uff0c\u901a\u8fc7lambda\u8868\u8fbe\u5f0f\u6765\u5b9e\u73b0\u67ef\u91cc\u5316\u3002 def add1(a, b, c): return a + b + c add4 = lambda x, y: add1(x, 666, y) result8 = add4(12, 13) print(result8) # 691 \u793a\u4f8b5\uff0c\u901a\u8fc7python\u7684\u88c5\u9970\u5668\u6765\u5b9e\u73b0\u67ef\u91cc\u5316 def add1(a, b, c): return a + b + c def currying_add(func): def wrapper(a, c, b=666): return func(a, b, c) return wrapper result9 = currying_add(add1)(12, 13) print(result9) # 691 \u793a\u4f8b6\uff0c\u901a\u8fc7python\u7684\u88c5\u9970\u5668\u7b26\u53f7@\u6765\u5b9e\u73b0\u67ef\u91cc\u5316 def currying_add(func): def wrapper(a, c, b=666): return func(a, b, c) return wrapper @currying_add def add5(a, b, c): return a + b + c result10 = add5(12, 13) print(result10) # 691","title":"6. \u67ef\u91cc\u5316\uff1a\u90e8\u5206\u53c2\u6570\u5e94\u7528"},{"location":"python/Foundation/ch03/#7","text":"","title":"7. \u8fed\u4ee3\u5668\u4e0e\u751f\u6210\u5668"},{"location":"python/Foundation/ch03/#_6","text":"\u8fed\u4ee3\u662fPython\u6700\u5f3a\u5927\u7684\u529f\u80fd\u4e4b\u4e00\uff0c\u662f\u8bbf\u95ee\u96c6\u5408\u5143\u7d20\u7684\u4e00\u79cd\u65b9\u5f0f\u3002\u8fed\u4ee3\u5668\u662f\u4e00\u4e2a\u53ef\u4ee5\u8bb0\u4f4f\u904d\u5386\u7684\u4f4d\u7f6e\u7684\u5bf9\u8c61\u3002 \u8fed\u4ee3\u5668\u5bf9\u8c61\u4ece\u96c6\u5408\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u5f00\u59cb\u8bbf\u95ee\uff0c\u76f4\u5230\u6240\u6709\u7684\u5143\u7d20\u88ab\u8bbf\u95ee\u5b8c\u7ed3\u675f\u3002\u8fed\u4ee3\u5668\u53ea\u80fd\u5f80\u524d\u4e0d\u4f1a\u540e\u9000\u3002 \u8fed\u4ee3\u5668\u6709\u4e24\u4e2a\u57fa\u672c\u7684\u65b9\u6cd5\uff1aiter() \u548c next()\u3002 \u8fed\u4ee3\u5668\u793a\u4f8b\uff1a list_a = [1, 2, 3, 4] it = iter(list_a) # \u521b\u5efa\u8fed\u4ee3\u5668\u5bf9\u8c61 print(next(it)) # \u8f93\u51fa\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u4e2a\u5143\u7d20 # 1 print(next(it)) # \u8f93\u51fa\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u4e2a\u5143\u7d20 # 2 \u8fed\u4ee3\u5668\u5bf9\u8c61\u53ef\u4ee5\u4f7f\u7528\u5e38\u89c4for\u8bed\u53e5\u8fdb\u884c\u904d\u5386\u3002 list_a = [1, 2, 3, 4] it = iter(list_a) # \u521b\u5efa\u8fed\u4ee3\u5668\u5bf9\u8c61 for x in it: print(x, end=\" \") print(end=\"\\n\") # 1 2 3 4","title":"\u8fed\u4ee3\u5668"},{"location":"python/Foundation/ch03/#_7","text":"\u5728 Python \u4e2d\uff0c\u4f7f\u7528\u4e86 yield \u7684\u51fd\u6570\u88ab\u79f0\u4e3a\u751f\u6210\u5668\uff08generator\uff09\u3002\u8ddf\u666e\u901a\u51fd\u6570\u4e0d\u540c\u7684\u662f\uff0c\u751f\u6210\u5668\u662f\u4e00\u4e2a\u8fd4\u56de\u8fed\u4ee3\u5668\u7684\u51fd\u6570\uff0c\u53ea\u80fd\u7528\u4e8e\u8fed\u4ee3\u64cd\u4f5c\uff0c\u751f\u6210\u5668\u5c31\u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\u3002 \u5728\u8c03\u7528\u751f\u6210\u5668\u8fd0\u884c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u6b21\u9047\u5230 yield \u65f6\u51fd\u6570\u4f1a\u6682\u505c\u5e76\u4fdd\u5b58\u5f53\u524d\u6240\u6709\u7684\u8fd0\u884c\u4fe1\u606f\uff0c\u8fd4\u56de yield \u7684\u503c, \u5e76\u5728\u4e0b\u4e00\u6b21\u6267\u884c next() \u65b9\u6cd5\u65f6\u4ece\u5f53\u524d\u4f4d\u7f6e\u7ee7\u7eed\u8fd0\u884c\u3002 \u8c03\u7528\u4e00\u4e2a\u751f\u6210\u5668\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\u5bf9\u8c61\u3002 \u793a\u4f8b, \u6590\u6ce2\u90a3\u5951\u6570\u5217\uff1a def fibonacci(n): a, b, counter = 0, 1, 0 while True: if (counter > n): return yield a a, b = b, a + b counter += 1 f = fibonacci(10) # f \u662f\u4e00\u4e2a\u8fed\u4ee3\u5668\uff0c\u7531\u751f\u6210\u5668\u8fd4\u56de\u751f\u6210 print(f) # <generator object fibonacci at 0x7fbe8a7f7580> \u5b9e\u9645\u8c03\u7528\u751f\u6210\u5668\u65f6\uff0c\u4ee3\u7801\u5e76\u4e0d\u4f1a\u7acb\u5373\u6267\u884c for x in f: # \u8bf7\u6c42\u751f\u6210\u5668\u4e2d\u7684\u5143\u7d20\u65f6\uff0c\u5b83\u624d\u4f1a\u6267\u884c\u5b83\u7684\u4ee3\u7801 print(x, end=\" \") print(end=\"\\n\") # 0 1 1 2 3 5 8 13 21 34 55 \u751f\u6210\u5668\u8868\u8fbe\u5f0f\uff1a \u7528\u751f\u6210\u5668\u8868\u8fbe\u5f0f\u6765\u521b\u5efa\u751f\u6210\u5668\u66f4\u4e3a\u7b80\u5355\u3002\u751f\u6210\u5668\u8868\u8fbe\u5f0f\u4e0e\u5217\u8868\u3001\u5b57\u5178\u3001\u96c6\u5408\u7684\u63a8\u5bfc\u5f0f\u5f88\u7c7b\u4f3c\uff0c\u521b\u5efa\u4e00\u4e2a\u751f\u6210\u5668\u8868\u8fbe\u5f0f\uff0c\u53ea\u9700\u8981\u5c06\u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u4e2d\u62ec\u53f7\u66ff\u6362\u4e3a\u5c0f\u62ec\u53f7\u5373\u53ef\u3002 gen1 = (x ** 2 for x in range(100)) print(gen1) # <generator object <genexpr> at 0x7fd3f30c9580> \u4e0a\u9762\u7684\u4ee3\u7801\u4e0e\u4e0b\u9762\u7684\u751f\u6210\u5668\u662f\u7b49\u4ef7\u7684 def _make_gen(): for x in range(100): yield x ** 2 gen2 = _make_gen() print(gen2) # <generator object _make_gen at 0x7fceb69ed580> \u751f\u6210\u5668\u8868\u8fbe\u5f0f\u53ef\u4ee5\u4f5c\u4e3a\u51fd\u6570\u53c2\u6570\u7528\u4e8e\u66ff\u4ee3\u5217\u8868\u63a8\u5bfc\u5f0f\u3002\u5bf9\u6bd4\u4e0b\u97622\u4e2a\u4f8b\u5b50\u3002 # \u793a\u4f8b1 result11 = sum(x ** 2 for x in range(100)) print(result11) # 328350 gen1 = (x ** 2 for x in range(100)) result11 = sum(gen1) print(result11) # 328350 # \u793a\u4f8b2 result12 = dict((i, i ** 2) for i in range(5)) print(result12) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16} gen2 = ((i, i ** 2) for i in range(5)) result12 = dict(gen2) print(result12) # {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}","title":"\u751f\u6210\u5668"},{"location":"python/Foundation/ch03/#itertools","text":"\u6807\u51c6\u5e93\u4e2d\u7684itertools\u6a21\u5757\u662f\u9002\u7528\u4e8e\u5927\u591a\u6570\u6570\u636e\u7b97\u6cd5\u7684\u751f\u6210\u5668\u96c6\u5408\u3002 import itertools first_letter = lambda x: x[0] names = ['Alan', 'Adam', 'Wes', 'Will', 'Albert', 'Steven'] for letter, names in itertools.groupby(names, first_letter): print(letter) print(first_letter) print(letter, list(names)) # names is generator # A # <function <lambda> at 0x7fa598a7a0d0> # A ['Alan', 'Adam'] # W # <function <lambda> at 0x7fa598a7a0d0> # W ['Wes', 'Will'] # A # <function <lambda> at 0x7fa598a7a0d0> # A ['Albert'] # S # <function <lambda> at 0x7fa598a7a0d0> # S ['Steven']","title":"\u751f\u6210\u5668\uff1aitertools\u6a21\u5757"},{"location":"python/Foundation/ch03/#8","text":"Python\u7528\u5f02\u5e38\u5bf9\u8c61(exception object)\u6765\u8868\u793a\u5f02\u5e38\u60c5\u51b5\u3002\u9047\u5230\u9519\u8bef\u540e\uff0c\u4f1a\u5f15\u53d1\u5f02\u5e38\u3002\u5982\u679c\u5f02\u5e38\u5bf9\u8c61\u5e76\u672a\u88ab\u5904\u7406\u6216\u6355\u6349\uff0c\u7a0b\u5e8f\u5c31\u4f1a\u7528\u6240\u8c13\u7684\u56de\u6eaf(traceback\uff0c \u4e00\u79cd\u9519\u8bef\u4fe1\u606f)\u7ec8\u6b62\u6267\u884c\u3002 \u5f02\u5e38\u548c\u8bed\u6cd5\u9519\u8bef\u662f\u6709\u533a\u522b\u7684\u3002 * \u9519\u8bef\uff1a\u662f\u6307\u4ee3\u7801\u4e0d\u7b26\u5408\u89e3\u91ca\u5668\u6216\u8005\u7f16\u8bd1\u5668\u8bed\u6cd5\u3002 * \u5f02\u5e38\uff1a\u662f\u6307\u4e0d\u5b8c\u6574\u3001\u4e0d\u5408\u6cd5\u8f93\u5165\uff0c\u6216\u8005\u8ba1\u7b97\u51fa\u73b0\u9519\u8bef\u3002 python\u91cc\u7528try...except...\u8bed\u53e5\u6765\u5904\u7406\u5f02\u5e38\u60c5\u51b5\u3002 def attempt_float(x): try: return float(x) except (TypeError, ValueError): return \"Type error, not numbers\" r1 = attempt_float('1.2256') print(r1) # 1.2256 r1 = attempt_float('friends') print(r1) # Type error, not numbers","title":"8. \u9519\u8bef\u548c\u5f02\u5e38\u5904\u7406"},{"location":"python/Foundation/ch03/#9","text":"f=open(path, 'w')\uff0c\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\u4f1a\u5728path\u6307\u5b9a\u7684\u8def\u5f84\u88ab\u521b\u5efa\uff0c\u5e76\u5728\u540c\u4e00\u8def\u5f84\u4e0b\u8986\u76d6\u540c\u540d\u6587\u4ef6\u3002\uff08\u8bf7\u5c0f\u5fc3\uff01\uff09 f=open(path, 'x')\uff0c\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\u4f1a\u5728path\u6307\u5b9a\u7684\u8def\u5f84\u88ab\u521b\u5efa\uff0c\u5982\u679c\u7ed9\u5b9a\u8def\u5f84\u4e0b\u5df2\u7ecf\u5b58\u5728\u540c\u540d\u6587\u4ef6\u5c31\u4f1a\u521b\u5efa\u5931\u8d25\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u8bfb\u53d6\u6587\u4ef6\u6bcf\u4e00\u884c\uff0c\u6587\u4ef6\u6bcf\u4e00\u884c\u4f5c\u4e3a\u5217\u8868\u4e00\u4e2a\u5143\u7d20 lines = [x.rstrip() for x in open(path)] # \u8f93\u51fa\u5217\u8868 print(lines) # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f.close() \u53e6\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u5173\u95ed\u6587\u4ef6\u7684\u65b9\u5f0f import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u4f7f\u7528with\u8bed\u53e5\u8bfb\u53d6\u6587\u4ef6\uff0c\u6587\u4ef6\u4f1a\u5728with\u4ee3\u7801\u5757\u7ed3\u675f\u540e\u81ea\u52a8\u5173\u95ed\u3002 with open(path) as f: lines = [x.rstrip() for x in open(path)] # \u8f93\u51fa\uff1a\u6587\u4ef6\u6bcf\u4e00\u884c\u4f5c\u4e3a\u5217\u8868\u4e00\u4e2a\u5143\u7d20 print(lines) \u5728\u6253\u5f00\u6587\u4ef6\u65f6\u4f7f\u7528seek\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\u8981\u5f53\u5fc3\u3002\u5982\u679c\u6587\u4ef6\u7684\u53e5\u67c4\u4f4d\u7f6e\u6070\u597d\u5728\u4e00\u4e2aUnicode\u7b26\u53f7\u7684\u5b57\u8282\u4e2d\u95f4\u65f6\uff0c\u540e\u7eed\u7684\u8bfb\u53d6\u4f1a\u5bfc\u81f4\u9519\u8bef\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f = open(path) # \u8bfb\u53d6\u6587\u4ef6\u3002 print(f.read(5)) # \u8f93\u51fa\u524d5\u4e2a\u5b57\u7b26\u3002 read\u65b9\u6cd5\u901a\u8fc7\u8bfb\u53d6\u7684\u5b57\u8282\u6570\u6765\u63a8\u8fdb\u6587\u4ef6\u53e5\u67c4\u7684\u4f4d\u7f6e\u3002 # I Thi print(f.tell()) # tell\u65b9\u6cd5\u53ef\u4ee5\u7ed9\u51fa\u53e5\u67c4\u5f53\u524d\u7684\u4f4d\u7f6e # 5 print(f.seek(6)) # seek\u65b9\u6cd5\u53ef\u4ee5\u5c06\u53e5\u67c4\u4f4d\u7f6e\u6539\u53d8\u5230\u6587\u4ef6\u4e2d\u7279\u5b9a\u7684\u5b57\u8282 # 6 print(f.read(1)) # \u4ece\u7b2c7\u4e2a\u5b57\u8282\u5f00\u59cb\uff0c\u8f93\u51fa1\u4e2a\u5b57\u8282 # k # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f.close() \u5982\u679c\u4f7f\u7528\u4e8c\u8fdb\u5236\u65b9\u5f0f\u6253\u5f00\u6587\u4ef6\uff0c\u5219\uff1a import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path = 'file01.txt' # \u6253\u5f00\u6587\u4ef6 f2 = open(path, 'rb') # \u4e8c\u8fdb\u5236\u6a21\u5f0f # \u8bfb\u53d6\u6587\u4ef6 print(f2.read(5)) # \u7b2c\u4e00\u4e2ab\u4ee3\u8868\u4e8c\u8fdb\u5236\u683c\u5f0f # b'I Thi' print(f2.tell()) # 5 print(f2.seek(6)) # 6 print(f2.read(2)) # \u4ece\u7b2c7\u4e2a\u5b57\u8282\u5f00\u59cb\uff0c\u8f93\u51fa2\u4e2a\u5b57\u8282 # b'k ' # \u5173\u95ed\u6587\u4ef6\u4f1a\u5c06\u8d44\u6e90\u91ca\u653e\u56de\u64cd\u4f5c\u7cfb\u7edf f2.close() \u5c06\u672c\u6587\u5199\u5165\u6587\u4ef6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6587\u4ef6\u5bf9\u8c61\u7684write\u6216wirtelines\u65b9\u6cd5\u3002 import os # \u67e5\u770b\u5f53\u524d\u8def\u5f84 os.getcwd() # '/opt/myMemo' # \u66f4\u6539\u6587\u4ef6\u8bfb\u53d6\u9ed8\u8ba4\u8def\u5f84 os.chdir('/opt/myMemo/python/datasets/examples') # \u6307\u5b9a\u6587\u4ef6\u540d path1 = 'file01.txt' path2 = 'file02.txt' # file02.txt\u662f\u4e00\u4e2a\u7a7a\u6587\u4ef6 with open(path2, 'r+', encoding='utf-8') as f: f.writelines(x for x in open(path1, 'r', encoding='utf-8') if len(x) > 1) # \u628afile01.txt\u7684\u5185\u5bb9\u5199\u5165file02.txt lines = f.readlines() print(lines)","title":"9. \u6587\u4ef6\u4e0e\u64cd\u4f5c\u7cfb\u7edf"},{"location":"python/Foundation/ch03/#10","text":"","title":"10. \u88c5\u9970\u5668"},{"location":"python/Foundation/ch03/#_8","text":"\u7ef4\u57fa\u767e\u79d1\u4e2d\u7684\u89e3\u91ca\uff1a \u95ed\u5305\uff08Closure\uff09 \uff0c\u53c8\u79f0\u8bcd\u6cd5\u95ed\u5305\uff08Lexical Closure\uff09\u6216\u51fd\u6570\u95ed\u5305\uff08function closures\uff09\uff0c\u662f\u5f15\u7528\u4e86\u81ea\u7531\u53d8\u91cf\u7684\u51fd\u6570\u3002\u8fd9\u4e2a\u88ab\u5f15\u7528\u7684\u81ea\u7531\u53d8\u91cf\u5c06\u548c\u8fd9\u4e2a\u51fd\u6570\u4e00\u540c\u5b58\u5728\uff0c\u5373\u4f7f\u5df2\u7ecf\u79bb\u5f00\u4e86\u521b\u9020\u5b83\u7684\u73af\u5883\u4e5f\u4e0d\u4f8b\u5916\u3002 \u95ed\u5305\u5ef6\u4f38\u4e86\u4f5c\u7528\u57df\u7684\u51fd\u6570\uff0c\u5176\u4e2d\u5305\u542b\u51fd\u6570\u5b9a\u4e49\u4f53\u4e2d\u5f15\u7528\u3001\u4f46\u662f\u4e0d\u5728\u5b9a\u4e49\u4f53\u4e2d\u5b9a\u4e49\u7684\u975e\u5168\u5c40\u53d8\u91cf\u3002\u51fd\u6570\u662f\u4e0d\u662f\u533f\u540d\u7684\u6ca1\u6709\u5173\u7cfb\uff0c\u5173\u952e\u662f\u5b83\u80fd\u8bbf\u95ee\u5b9a\u4e49\u4f53\u4e4b\u5916\u5b9a\u4e49\u7684\u975e\u5168\u5c40\u53d8\u91cf\u3002 \u4f8b\u4e00\uff0c\u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\u503c\u3002 \u4e0b\u9762\u662f\u662f\u4f20\u7edf\u7c7b\u5b9e\u73b0\u65b9\u5f0f\uff0cAvg\u7684\u5b9e\u4f8b\u662f\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\u3002 class Avg(): def __init__(self): self.mylist = [] def __call__(self, newValue): self.mylist.append(newValue) total = sum(self.mylist) return total/len(self.mylist) avg = Avg() avg(10) # 10.0 avg(20) # 15.0 avg(30) # 20.0 \u4e0b\u9762\u662f\u9ad8\u9636\u51fd\u6570\u5b9e\u73b0\u65b9\u5f0f\u3002\u8c03\u7528 make_avg \u65f6\uff0c\u8fd4\u56de\u4e00\u4e2a my_avg \u51fd\u6570\u5bf9\u8c61\u3002\u6bcf\u6b21\u8c03\u7528 my_avg \u65f6\uff0c\u5b83\u4f1a\u628a\u53c2\u6570\u6dfb\u52a0\u5230\u7cfb\u5217\u503c\u4e2d\uff0c\u7136\u540e\u8ba1\u7b97\u5f53\u524d\u5e73\u5747\u503c\u3002 def make_avg(): my_list = [] def avg(newValue): my_list.append(newValue) total = sum(my_list) return total/len(my_list) return avg my_avg = make_avg() my_avg(10) # 10.0 my_avg(20) # 15.0 my_avg(30) # 20.0 my_avg.__code__.co_varnames # ('newValue', 'total') my_avg.__code__.co_freevars # ('my_list',) my_avg.__closure__ # (<cell at 0x7fe93d347468: list object at 0x7fe93d0e2f48>,) my_avg.__closure__[0].cell_contents # [10, 20, 30] \u8fd9\u4e24\u4e2a\u793a\u4f8b\u6709\u5171\u901a\u4e4b\u5904\uff1a\u8c03\u7528 Avg() \u6216 make_avg() \u5f97\u5230\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61 avg \uff0c\u5b83\u4f1a\u66f4\u65b0\u5386\u53f2\u503c\uff0c\u7136\u540e\u8ba1\u7b97\u5f53\u524d\u5747\u503c\u3002 \u5728\u7c7b\u5b9e\u73b0\u4e2d\uff0c avg \u662f Avg \u7684\u5b9e\u4f8b\uff1b\u5728\u9ad8\u9636\u51fd\u6570\u5b9e\u73b0\u4e2d\u662f\u5185\u90e8\u51fd\u6570 avg \u3002 \u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\u4e2d\uff0c\u6211\u4eec\u90fd\u53ea\u9700\u8c03\u7528 avg(n) \uff0c\u628a n \u653e\u5165\u7cfb\u5217\u503c\u4e2d\uff0c\u7136\u540e\u91cd\u65b0\u8ba1\u7b97\u5747\u503c\u3002 \u7b2c\u4e00\u4e2a\u4f8b\u5b50\u4e2d\uff0c Avg \u7c7b\u7684\u5b9e\u4f8b avg \u5728 self.series \u5b9e\u4f8b\u5c5e\u6027\u4e2d\u5b58\u50a8\u5386\u53f2\u503c\u3002 \u7b2c\u4e8c\u4e2a\u4f8b\u5b50\u4e2d\u7684 my_list \u662f\u51fd\u6570 make_avg() \u7684\u5c40\u90e8\u53d8\u91cf\uff0c\u4e5f\u79f0\u4e3a\u8be5\u51fd\u6570\u7684 \u81ea\u7531\u53d8\u91cf\uff08free variable\uff09 \uff0c\u6307\u672a\u5728\u672c\u5730\u4f5c\u7528\u57df\u4e2d\u7ed1\u5b9a\u7684\u53d8\u91cf\u3002 avg() \u51fd\u6570\u7684\u95ed\u5305\u5ef6\u4f38\u5230\u51fd\u6570\u7684\u4f5c\u7528\u57df\u4e4b\u5916\uff0c\u5305\u542b\u4e86 make_avg() \u7684\u81ea\u7531\u53d8\u91cf my_list \u7684\u7ed1\u5b9a\u3002 \u5bf9\u4e8e\u8fd4\u56de\u7684 my_avg \u5bf9\u8c61\uff0c\u5176 __code__ \u5c5e\u6027\uff08\u8868\u793a\u7f16\u8bd1\u540e\u7684\u51fd\u6570\u5b9a\u4e49\u4f53\uff09\u4e2d\u4fdd\u5b58\u4e86\u5c40\u90e8\u53d8\u91cf\u548c\u81ea\u7531\u53d8\u91cf\u7684\u540d\u79f0\uff0c\u5373 my_avg.__code__.co_varnames \u8fd4\u56de\u4e86\u5c40\u90e8\u53d8\u91cf ('newValue', 'total') \u548c my_avg.__code__.co_freevars \u8fd4\u56de\u4e86\u81ea\u7531\u53d8\u91cf ('my_list',) \u3002 \u81ea\u7531\u53d8\u91cf my_list \u7ed1\u5b9a\u5728\u8fd4\u56de\u7684 my_avg \u7684 __closure__ \u7684\u5c5e\u6027\u4e2d\uff0c my_avg.__closure__ \u4e2d\u7684\u5404\u4e2a\u5143\u7d20\u5bf9\u5e94\u4e86 my_avg.__code__.co_freevars \u4e2d\u7684\u4e00\u4e2a\u540d\u79f0\u3002\u8fd9\u4e9b\u5143\u7d20\u662f cell \u5bf9\u8c61\uff0c\u6709\u4e2a cell_contents \u5c5e\u6027\uff0c\u5982\uff1a my_avg.__closure__ \u8fd4\u56de (<cell at 0x7fe93d347468: list object at 0x7fe93d0e2f48>,) \uff0c\u91cc\u9762\u4fdd\u5b58\u7740\u771f\u6b63\u7684\u503c\uff0c\u5982 my_avg.__closure__[0].cell_contents \u91cc\u9762\u4fdd\u5b58\u6bcf\u6b21\u8c03\u7528\u7684\u771f\u5b9e\u503c [10, 20, 30] \u3002 \u4e0a\u9762 my_list \u662f\u4e00\u4e2a\u53ef\u53d8\u7c7b\u578b\uff0c\u5982\u679c\u7528\u4e0d\u53ef\u53d8\u7c7b\u578b\u6539\u5199\uff0c\u5e76\u5b9e\u73b0\u95ed\u5305\uff0c\u53ef\u4ee5\u4f7f\u7528 nolocal \u8fdb\u884c\u58f0\u660e\u3002\u5b83\u7684\u4f5c\u7528\u662f\u628a\u53d8\u91cf\u6807\u8bb0\u4e3a\u81ea\u7531\u53d8\u91cf\uff0c\u5373\u4f7f\u5728\u51fd\u6570\u4e2d\u4e3a\u53d8\u91cf\u8d4b\u4e88\u65b0\u503c\u4e86\uff0c\u4e5f\u4f1a\u53d8\u6210\u81ea\u7531\u53d8\u91cf\u3002\u5982\u679c\u4e3anonlocal\u58f0\u660e\u7684\u53d8\u91cf\u8d4b\u4e88\u65b0\u503c\uff0c\u95ed\u5305\u4e2d\u4fdd\u5b58\u7684\u7ed1\u5b9a\u4f1a\u66f4\u65b0\u3002 my_avg.__code__.co_freevars \u8fd4\u56de\u4e862\u4e2a\u81ea\u7531\u53d8\u91cf ('count', 'total') \uff0c\u5e76\u5728 my_avg.__closure__[0].cell_contents \u548c my_avg.__closure__[1].cell_contents \u91cc\u9762\u4fdd\u5b58\u4e86\u6700\u540e\u4e00\u6b21\u6267\u884c\u7684\u771f\u5b9e\u503c\u3002 def make_avg(): count = 0 total = 0 def avg(newValue): nonlocal count, total count += 1 total += newValue return total / count return avg my_avg = make_avg() my_avg(10) # 10.0 my_avg(20) # 15.0 my_avg(30) # 20.0 my_avg.__code__.co_varnames # ('newValue',) my_avg.__code__.co_freevars # ('count', 'total') my_avg.__closure__ # (<cell at 0x7fe93d3474c8: int object at 0x7fe93e865240>, <cell at 0x7fe93d347318: int object at 0x7fe93e865960>) my_avg.__closure__[0].cell_contents # 3 my_avg.__closure__[1].cell_contents # 60 \u4f8b\u4e8c\uff1a money \u662f\u4e00\u4e2a\u5c40\u90e8\u53d8\u91cf\uff0c\u5728 get_money \u662f\u5916\u56f4\u51fd\u6570\uff0c\u51fd\u6570\u6267\u884c\u4e4b\u540e\u5e94\u8be5\u5c31\u4e0d\u4f1a\u5b58\u5728\u4e86\u3002 \u4f46\u662f\u5d4c\u5957\u51fd\u6570 work \u5f15\u7528\u4e86 money \u8fd9\u4e2a\u81ea\u7531\u53d8\u91cf\uff0c\u5c06\u8fd9\u4e2a\u5c40\u90e8\u53d8\u91cf\u5c01\u95ed\u5728\u4e86\u5d4c\u5957\u51fd\u6570 work \u4e2d\uff0c\u8fd9\u6837\u5c31\u5f62\u6210\u4e86\u4e00\u4e2a\u95ed\u5305\u3002 closure = get_money() \u83b7\u5f97\u7684\u5c31\u662f\u4e00\u4e2a\u95ed\u5305\u3002 closure() \u8f93\u51fa\u95ed\u5305\uff0c\u5373\uff0c\u6267\u884c\u4e86 work() \uff0c\u6253\u5370\u8f93\u51fa money \u7684\u503c\u3002 \u672c\u5730\u51fd\u6570\u901a\u8fc7global\u58f0\u660e\u5bf9\u5168\u5c40\u53d8\u91cf\u8fdb\u884c\u5f15\u7528\u4fee\u6539\uff0c\u90a3\u4e48\u5bf9\u4e8e\u5185\u5d4c\u51fd\u6570 work() \u4f5c\u7528\u57df\u4e2d\u7684\u53d8\u91cf\u8fdb\u884c\u4fee\u6539\uff0c\u5c31\u8981\u4f7f\u7528 nonlocal \u8fdb\u884c\u58f0\u660e\u3002 def get_money(): money = 0 def work(): nonlocal money money += 100 print(money) return work closure = get_money() closure() # 100 closure() # 200 closure() # 300 \u4f8b\u4e09\uff1a \u51fd\u6570 maker \u4e2d\u5b9a\u4e49\u4e86\u51fd\u6570 action \uff0c action \u5f15\u7528\u4e86 maker \u5d4c\u5957\u4f5c\u7528\u57df\u5185\u7684\u53d8\u91cf k \uff0c\u5e76\u4e14\uff0c maker \u5c06\u51fd\u6570 action \u4f5c\u4e3a\u8fd4\u56de\u5bf9\u8c61\u8fdb\u884c\u8fd4\u56de\u3002 \u8fd9\u6837\uff0c\u6211\u4eec\u901a\u8fc7\u6267\u884c f = maker(2) \uff0c f \u83b7\u53d6\u4e86\u8fd4\u56de\u5bf9\u8c61 action \uff0c\u867d\u7136\u6b64\u65f6 maker \u51fd\u6570\u4ee5\u53ca\u7ed3\u675f\u9000\u51fa\u4e86\uff0c\u4f46\u5bf9\u8c61 f \u4ecd\u7136\u8bb0\u4f4f\u4e86\u51fd\u6570 maker \u5d4c\u5957\u4f5c\u7528\u57df\u5185\u7684\u53d8\u91cf k \u548c n \uff0c\u5e76\u5728\u6267\u884c f(3) \u65f6\uff0c\u5c06 x=3 \u4ee5\u53ca\u4e4b\u524d\u8bb0\u4f4f\u7684 k \u548c n \uff0c\u4e00\u5e76\u4f20\u5165 action() \uff0c\u8ba1\u7b97\u5e76\u8fd4\u56de x + n + k \u503c\u3002 make \u4e5f\u79f0\u4e3a \u5de5\u5382\u51fd\u6570 \u3002 def maker(n): k = 8 def action(x): return x + n + k return action f = maker(2) print(f(3)) # 13 print(f(4)) # 14 print(f(5)) # 15 \u7ed3\u5408\u524d\u97622\u4e2a\u4f8b\u5b50\u518d\u770b\u4e0a\u9762\u7684\u89e3\u91ca\uff0c\u95ed\u5305\u5c31\u662f\u5f15\u7528\u4e86\u81ea\u7531\u53d8\u91cf\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u4fdd\u5b58\u4e86\u6267\u884c\u7684\u4e0a\u4e0b\u6587\uff0c\u53ef\u4ee5\u8131\u79bb\u539f\u672c\u7684\u4f5c\u7528\u57df\u72ec\u7acb\u5b58\u5728\u3002","title":"\u95ed\u5305"},{"location":"python/Foundation/ch03/#_9","text":"\u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5c06\u51fd\u6570\u4f5c\u4e3a\u53c2\u6570\u4f20\u7ed9\u53e6\u4e00\u4e2a\u51fd\u6570\uff0c\u51fd\u6570 my_decorator \u7684\u4f20\u5165\u53c2\u6570\u6b63\u597d\u662f\u5176\u5d4c\u5957\u51fd\u6570 myFunc \u3002 def my_decorator(nestedFunc): def myFunc(): print(\"Before executing nestedFunc()\") nestedFunc() print(\"After executing nestedFunc()\") return myFunc def nestedFunc(): print(\"Decoration - executing nestedFunc()\") nestedFunc() # Decoration - executing nestedFunc() nestedFunc = my_decorator(nestedFunc) nestedFunc() # Before executing nestedFunc() # Decoration - executing nestedFunc() # After executing nestedFunc() \u88c5\u9970\u5668\u53ea\u662f\u4e2a\u65b9\u6cd5\uff0c\u4f7f\u7528\u65f6\u7528\u4e86 @ \u8bed\u6cd5\u3002 @ \u8bed\u6cd5\u53ea\u662f\u5c06\u51fd\u6570 nestedFunc \u4f20\u5165\u88c5\u9970\u5668\u51fd\u6570 my_decorator \u3002 @my_decorator \u662f nestedFunc = my_decorator(nestedFunc) \u7684\u5feb\u6377\u8868\u8fbe\u65b9\u5f0f\uff0c @my_decorator def nestedFunc(): print(\"New added to decoration - executing nestedFunc()\") nestedFunc() # Before executing nestedFunc() # New added to decoration - executing nestedFunc() # After executing nestedFunc() print(nestedFunc.__name__) # myFunc \u4f46\u4e0a\u4f8b\u6700\u540e\u7684\u8f93\u51fa\u4e0d\u662f\u6211\u4eec\u60f3\u8981\u7684\uff0c\u6211\u4eec\u5e0c\u671b\u8f93\u51fa nestedFunc \uff0c\u4f46\u5374\u88ab myFunc \u66ff\u4ee3\u4e86\uff0c\u5b83\u91cd\u5199\u4e86\u6211\u4eec\u51fd\u6570\u7684\u540d\u5b57\u548c\u6ce8\u91ca\u6587\u6863(docstring)\u3002 \u4e0b\u9762\u4f7f\u7528 functools.wraps \u6765\u4fee\u6b63\u4e0a\u9762\u7684\u95ee\u9898\u3002 from functools import wraps def my_decorator(nestedFunc): @wraps(nestedFunc) def myFunc(): print(\"Before executing nestedFunc()\") nestedFunc() print(\"After executing nestedFunc()\") return myFunc def nestedFunc(): print(\"Decoration - executing nestedFunc()\") @my_decorator def nestedFunc(): print(\"New added to decoration - executing nestedFunc()\") nestedFunc() # Before executing nestedFunc() # New added to decoration - executing nestedFunc() # After executing nestedFunc() print(nestedFunc.__name__) # nestedFunc \u4e0b\u9762\u662f\u88c5\u9970\u5668\u7684\u84dd\u672c\u89c4\u8303\u3002 from functools import wraps def decorator_name(f): @wraps(f) def decorated(*args, **kwargs): if not can_run: return \"Function will not run\" return f(*args, **kwargs) return decorated @decorator_name def func(): return (\"Function is running\") can_run = True print(func()) # Output: Function is running can_run = False print(func()) # Output: Function will not run \u4e0b\u9762\u8fd8\u662f\u4e00\u4e2a\u88c5\u9970\u5668\u7684\u4f8b\u5b50\u3002\u628a\u4e0b\u9762\u7684\u4ee3\u7801\u6bb5\u4fdd\u5b58\u5230\u6587\u4ef6 test.py \u3002 registry = [] def register(func): print(f'running register {func}') registry.append(func) return func @register def f1(): print('running f1()') @register def f2(): print('running f2()') def f3(): print('running f3()') def main(): print('runnning main()') print(f'registry--> {registry}') f1() f2() f3() if __name__ == '__main__': main() \u6267\u884c\u4e0a\u8ff0\u4ee3\u7801\u6bb5 python3 test.py \uff0c\u5f97\u5230\u4e0b\u9762\u7684\u7ed3\u679c\u3002 running register <function f1 at 0x7f70847bec80> running register <function f2 at 0x7f70705aa9d8> runnning main() registry--> [<function f1 at 0x7f70847bec80>, <function f2 at 0x7f70705aa9d8>] running f1() running f2() running f3() register \u5728\u6a21\u5757\u4e2d\u5176\u4ed6\u51fd\u6570\u4e4b\u524d\u8fd0\u884c\uff08\u4e24\u6b21\uff09\u3002\u8c03\u7528 register \u65f6\uff0c\u4f20\u7ed9\u5b83\u7684\u53c2\u6570\u662f\u88ab\u88c5\u9970\u7684\u51fd\u6570\uff0c\u4f8b\u5982 function f1 at 0x7f70847bec80> \u3002\u52a0\u8f7d\u6a21\u5757\u540e\uff0c registry \u4e2d\u6709\u4e24\u4e2a\u88ab\u88c5\u9970\u51fd\u6570\u7684\u5f15\u7528\uff1a f1 \u548c f2 \u3002\u8fd9\u4e24\u4e2a\u51fd\u6570\uff0c\u4ee5\u53ca f3 \uff0c\u53ea\u5728 main \u660e\u786e\u8c03\u7528\u5b83\u4eec\u65f6\u624d\u6267\u884c\u3002 \u7531\u6b64\u5f97\uff0c\u51fd\u6570\u88c5\u9970\u5668\u5728\u5bfc\u5165\u6a21\u5757\u65f6\u7acb\u5373\u6267\u884c\uff0c\u800c\u88ab\u88c5\u9970\u7684\u51fd\u6570\u53ea\u5728\u660e\u786e\u8c03\u7528\u65f6\u8fd0\u884c\uff0c\u5373Python\u4e2d\u63d0\u5230\u7684 \u5bfc\u5165\u65f6 \u548c \u8fd0\u884c\u65f6 \u4e4b\u95f4\u7684\u533a\u522b\u3002 \u4e0a\u9762\u4f8b\u5b50\u4e2d\u88c5\u9970\u5668\u51fd\u6570\u4e0e\u88ab\u88c5\u9970\u7684\u51fd\u6570\u5728\u540c\u4e00\u4e2a\u6a21\u5757\u4e2d\u5b9a\u4e49\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u88c5\u9970\u5668\u901a\u5e38\u5728\u4e00\u4e2a\u6a21\u5757\u4e2d\u5b9a\u4e49\uff0c\u7136\u540e\u5e94\u7528\u5230\u5176\u4ed6\u6a21\u5757\u4e2d\u7684\u51fd\u6570\u4e0a\u3002 \u4e0a\u9762\u4f8b\u5b50\u4e2d register \u88c5\u9970\u5668\u8fd4\u56de\u7684\u51fd\u6570\u4e0e\u901a\u8fc7\u53c2\u6570\u4f20\u5165\u7684\u76f8\u540c\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5927\u591a\u6570\u88c5\u9970\u5668\u4f1a\u5728\u5185\u90e8\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\uff0c\u7136\u540e\u5c06\u5176\u8fd4\u56de\u3002","title":"\u88c5\u9970\u5668"},{"location":"python/Foundation/ch04/","text":"Python\u7684\u9762\u5411\u5bf9\u8c61\u6982\u5ff5 \u7c7b(class)\u628a\u6570\u636e\u4e0e\u529f\u80fd\u7ed1\u5b9a\u5728\u4e00\u8d77\u3002\u521b\u5efa\u65b0\u7c7b\u5c31\u662f\u521b\u5efa\u65b0\u7684\u5bf9\u8c61\u7c7b\u578b\uff08type of object\uff09\uff0c\u4ece\u800c\u521b\u5efa\u8be5\u7c7b\u578b\u7684\u65b0\u5b9e\u4f8b\uff08instances\uff09\u3002 \u7c7b\u5b9e\u4f8b\u5177\u6709\u591a\u79cd\u4fdd\u6301\u81ea\u8eab\u72b6\u6001\u7684\u5c5e\u6027\uff08attributes\uff09\u3002 \u7c7b\u5b9e\u4f8b\u8fd8\u652f\u6301\uff08\u7531\u7c7b\u5b9a\u4e49\u7684\uff09\u4fee\u6539\u81ea\u8eab\u72b6\u6001\u7684\u65b9\u6cd5\uff08methods\uff09\u3002 Python\u7684\u7c7b\u652f\u6301\u6240\u6709\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u7684\u6807\u51c6\u7279\u6027\uff1a \u7c7b\u7ee7\u627f\uff08class inheritance\uff09\u673a\u5236\u652f\u6301\u591a\u4e2a\u57fa\u7c7b\uff08base classes\uff09\uff1b \u6d3e\u751f\u7c7b\uff08derived class\uff09\u53ef\u4ee5\u8986\u76d6\u57fa\u7c7b\u7684\u4efb\u4f55\u65b9\u6cd5\uff08methods\uff09\uff1b \u7c7b\u7684\u65b9\u6cd5\u53ef\u4ee5\u8c03\u7528\u57fa\u7c7b\u4e2d\u76f8\u540c\u540d\u79f0\u7684\u65b9\u6cd5 \u5bf9\u8c61\u53ef\u4ee5\u5305\u542b\u4efb\u610f\u6570\u91cf\u548c\u7c7b\u578b\u7684\u6570\u636e\u3002 \u7c7b\uff08class\uff09\u548c\u6a21\u5757\uff08module\uff09\u90fd\u62e5\u6709\u52a8\u6001\u7279\u6027\uff08dynamic nature\uff09\uff1a\u5728\u8fd0\u884c\u65f6\u521b\u5efa\uff0c\u521b\u5efa\u540e\u4e5f\u53ef\u4ee5\u4fee\u6539\u3002 \u540d\u79f0Names\u548c\u5bf9\u8c61Objects \u5bf9\u8c61\u4e4b\u95f4\u76f8\u4e92\u72ec\u7acb\uff0c\u591a\u4e2a\u540d\u79f0\uff08names\uff09\uff08\u5728\u591a\u4e2a\u4f5c\u7528\u57df\u5185\uff09\u53ef\u4ee5\u7ed1\u5b9a\u5230\u540c\u4e00\u4e2a\u5bf9\u8c61\u3002 \u5176\u4ed6\u8bed\u8a00\u79f0\u4e4b\u4e3a\u522b\u540d\uff08alias\uff09\u3002 \u522b\u540d\u5728\u67d0\u4e9b\u65b9\u9762\u5c31\u50cf\u6307\u9488\u3002\u4f8b\u5982\uff0c\u4f20\u9012\u5bf9\u8c61\u7684\u4ee3\u4ef7\u5f88\u5c0f\uff0c\u56e0\u4e3a\u5b9e\u73b0\u53ea\u4f20\u9012\u4e00\u4e2a\u6307\u9488\uff1b\u5982\u679c\u51fd\u6570\u4fee\u6539\u4e86\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u7684\u5bf9\u8c61\uff0c\u8c03\u7528\u8005\u5c31\u53ef\u4ee5\u770b\u5230\u66f4\u6539\u3002 \u4f5c\u7528\u57dfScopes\u548c\u547d\u540d\u7a7a\u95f4Namespaces \u547d\u540d\u7a7a\u95f4\uff08namespace\uff09 \u662f\u4e00\u4e2a\u4ece\u540d\u5b57\u5230\u5bf9\u8c61\u7684\u6620\u5c04\u3002 \u5f53\u524d\u5927\u90e8\u5206\u547d\u540d\u7a7a\u95f4\u90fd\u7531 Python \u5b57\u5178\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u51e0\u4e2a\u547d\u540d\u7a7a\u95f4\u7684\u4f8b\u5b50\uff1a \u5b58\u653e\u5185\u7f6e\u51fd\u6570\u7684\u96c6\u5408\uff08\u5305\u542b abs() \u8fd9\u6837\u7684\u51fd\u6570\uff0c\u548c\u5185\u5efa\u7684\u5f02\u5e38\u7b49\uff09\uff1b \u6a21\u5757\u4e2d\u7684\u5168\u5c40\u540d\u79f0\uff1b \u51fd\u6570\u8c03\u7528\u4e2d\u7684\u5c40\u90e8\u540d\u79f0\uff1b \u4ece\u67d0\u79cd\u610f\u4e49\u4e0a\u8bf4\uff0c \u5bf9\u8c61\u7684\u5c5e\u6027\u96c6\u5408\uff08the set of attributes of an object\uff09\u4e5f\u662f\u4e00\u79cd\u547d\u540d\u7a7a\u95f4\u7684\u5f62\u5f0f \u3002 \u5173\u4e8e\u547d\u540d\u7a7a\u95f4\u7684\u91cd\u8981\u4e00\u70b9\u662f\uff0c\u4e0d\u540c\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u540d\u79f0\u4e4b\u95f4\u7edd\u5bf9\u6ca1\u6709\u5173\u7cfb\uff1b \u4f8b\u5982\uff0c\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u5757\u4e2d\u90fd\u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a maximize \u51fd\u6570\u800c\u4e0d\u4f1a\u4ea7\u751f\u6df7\u6dc6\uff0c\u4f46\u5728\u8c03\u7528 maximize \u51fd\u6570\u65f6\u5fc5\u987b\u5fc5\u987b\u5728\u5176\u524d\u9762\u52a0\u4e0a\u6a21\u5757\u540d\u79f0\u3002 \u4efb\u4f55\u8ddf\u5728\u4e00\u4e2a\u70b9\u53f7\u4e4b\u540e\u7684\u540d\u79f0\u90fd\u79f0\u4e3a \u5c5e\u6027\uff08attribute\uff09 \u3002\u4f8b\u5982\uff0c\u5728\u8868\u8fbe\u5f0f z.real \u4e2d\uff0c real \u662f\u5bf9\u8c61 z \u7684\u4e00\u4e2a\u5c5e\u6027\u3002 \u6309\u4e25\u683c\u7684\u8bf4\u6cd5\uff0c \u5bf9\u6a21\u5757\uff08module\uff09\u4e2d\u7684\u540d\u79f0\u7684\u5f15\u7528\uff08reference\uff09\u90fd\u5c5e\u4e8e\u5c5e\u6027\u5f15\u7528\uff08attribute reference\uff09 \uff1a \u5728\u8868\u8fbe\u5f0f modname.funcname \u4e2d\uff0c modname \u662f\u4e00\u4e2a\u6a21\u5757\u5bf9\u8c61\uff08module object\uff09\u800c funcname \u662f\u5b83\u7684\u4e00\u4e2a\u5c5e\u6027\u3002 \u5728\u6b64\u60c5\u51b5\u4e0b\u5728\u6a21\u5757\u7684\u5c5e\u6027\uff08module\u2019s attribute\uff09\u548c\u6a21\u5757\u4e2d\u5b9a\u4e49\u7684\u5168\u5c40\u540d\u79f0\u4e4b\u95f4\u6b63\u597d\u5b58\u5728\u4e00\u4e2a\u76f4\u89c2\u7684\u6620\u5c04\uff1a\u5b83\u4eec\u5171\u4eab\u76f8\u540c\u7684\u547d\u540d\u7a7a\u95f4\u3002 \u4f46\u5b58\u5728\u4e00\u4e2a\u4f8b\u5916\u3002 \u6a21\u5757\u5bf9\u8c61\u6709\u4e00\u4e2a\u53ea\u8bfb\u5c5e\u6027 __dict__ \uff0c\u5b83\u8fd4\u56de\u7528\u4e8e\u5b9e\u73b0\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u7684\u5b57\u5178\uff1b __dict__ \u662f\u5c5e\u6027\u4f46\u4e0d\u662f\u5168\u5c40\u540d\u79f0\u3002 \u4f7f\u7528\u8fd9\u4e2a\u5c06\u8fdd\u53cd\u547d\u540d\u7a7a\u95f4\u5b9e\u73b0\u7684\u62bd\u8c61\uff0c\u5e94\u5f53\u4ec5\u88ab\u7528\u4e8e\u4e8b\u540e\u8c03\u8bd5\u5668\u4e4b\u7c7b\u7684\u573a\u5408\u3002 \u5c5e\u6027\uff08attribute\uff09 \u53ef\u4ee5\u662f\u53ea\u8bfb\u6216\u8005\u53ef\u5199\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5bf9\u5c5e\u6027\u8fdb\u884c\u8d4b\u503c\uff0c\u4f8b\u5982 modname.the_answer = 42 \u3002 \u5220\u9664\u5c5e\u6027\u53ef\u4ee5\u7528del\u8bed\u53e5\uff0c\u4f8b\u5982\uff0c del modname.the_answer \u5c06\u4f1a\u4ece\u540d\u4e3a modname \u7684\u5bf9\u8c61\u4e2d\u79fb\u9664 the_answer \u5c5e\u6027\u3002 \u547d\u540d\u7a7a\u95f4\u5728\u4e0d\u540c\u65f6\u523b\u88ab\u521b\u5efa\uff0c\u62e5\u6709\u4e0d\u540c\u7684\u751f\u5b58\u671f\uff08lifetimes\uff09\u3002\u5305\u542b\u5185\u7f6e\u540d\u79f0\uff08built-in names\uff09\u7684\u547d\u540d\u7a7a\u95f4\u662f\u5728Python\u89e3\u91ca\u5668\u542f\u52a8\u65f6\u521b\u5efa\u7684\uff0c\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u5220\u9664\u3002 \u6a21\u5757\u7684\u5168\u5c40\u547d\u540d\u7a7a\u95f4\uff08global namespace\uff09\u5728\u6a21\u5757\u5b9a\u4e49\u88ab\u8bfb\u5165\u65f6\u521b\u5efa\uff1b\u901a\u5e38\uff0c\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u4e5f\u4f1a\u6301\u7eed\u5230\u89e3\u91ca\u5668\u9000\u51fa\u3002 \u88ab\u89e3\u91ca\u5668\u7684\u9876\u5c42\u8c03\u7528\uff08top-level invocation\uff09\u6267\u884c\u7684\u8bed\u53e5\uff0c\u4ece\u4e00\u4e2a\u811a\u672c\u6587\u4ef6\u8bfb\u53d6\u6216\u4ea4\u4e92\u5f0f\u5730\u8bfb\u53d6\uff0c\u88ab\u8ba4\u4e3a\u662f __main__ \u6a21\u5757\u8c03\u7528\u7684\u4e00\u90e8\u5206\uff0c\u56e0\u6b64\u5b83\u4eec\u62e5\u6709\u81ea\u5df1\u7684\u5168\u5c40\u547d\u540d\u7a7a\u95f4\u3002 \u5185\u7f6e\u540d\u79f0\uff08built-in names\uff09\u5b9e\u9645\u4e0a\u4e5f\u5b58\u5728\u4e8e\u4e00\u4e2a\u6a21\u5757\u4e2d\uff0c\u8fd9\u4e2a\u6a21\u5757\u88ab\u79f0\u4f5c builtins \u3002 \u4e00\u4e2a\u51fd\u6570\u7684\u672c\u5730\u547d\u540d\u7a7a\u95f4\uff08local namespace\uff09\u5728\u8fd9\u4e2a\u51fd\u6570\u88ab\u8c03\u7528\u65f6\u521b\u5efa\uff0c\u5e76\u5728\u51fd\u6570\u8fd4\u56de\u6216\u629b\u51fa\u4e00\u4e2a\u65e0\u6cd5\u5728\u8be5\u51fd\u6570\u5185\u90e8\u5904\u7406\u7684\u9519\u8bef\u65f6\u88ab\u5220\u9664\u3002 \u6bcf\u6b21\u9012\u5f52\u8c03\u7528\uff08recursive invocations\uff09\u90fd\u4f1a\u6709\u5b83\u81ea\u5df1\u7684\u672c\u5730\u547d\u540d\u7a7a\u95f4\u3002 \u4e00\u4e2a \u4f5c\u7528\u57df\uff08scope\uff09 \u662f\u4e00\u4e2a\u547d\u540d\u7a7a\u95f4\u53ef\u76f4\u63a5\u8bbf\u95ee\uff08directly accessible\uff09\u7684Python\u7a0b\u5e8f\u7684\u4ee3\u7801\u533a\u57df\u3002 \u8fd9\u91cc\u7684 \u201c\u53ef\u76f4\u63a5\u8bbf\u95ee\u201d \u610f\u5473\u7740\u4e0d\u52a0\u4efb\u4f55\u9650\u5b9a\u7684\u540d\u79f0\u5f15\u7528\u4f1a\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u8fdb\u884c\u67e5\u627e\u3002 \u867d\u7136\u4f5c\u7528\u57df\u662f\u9759\u6001\u5730\u786e\u5b9a\u7684\uff0c\u4f46\u5b83\u4eec\u4f1a\u88ab\u52a8\u6001\u5730\u4f7f\u7528\u3002 \u5728\u4ee3\u7801\u6267\u884c\u671f\u95f4\u7684\u4efb\u4f55\u65f6\u523b\uff0c\u4f1a\u67093\u62164\u4e2a\u7684\u5d4c\u5957\u4f5c\u7528\u57df\u4f9b\u547d\u540d\u7a7a\u95f4\u76f4\u63a5\u8bbf\u95ee: \u6700\u5148\u641c\u7d22\u7684\u6700\u5185\u90e8\u4f5c\u7528\u57df\u5305\u542b\u5c40\u90e8\u540d\u79f0 \u4ece\u6700\u8fd1\u7684\u5c01\u95ed\u4f5c\u7528\u57df\u5f00\u59cb\u641c\u7d22\u7684\u4efb\u4f55\u5c01\u95ed\u51fd\u6570\u7684\u4f5c\u7528\u57df\u5305\u542b\u975e\u5c40\u90e8\u540d\u79f0\uff0c\u4e5f\u5305\u62ec\u975e\u5168\u5c40\u540d\u79f0 \u5012\u6570\u7b2c\u4e8c\u4e2a\u4f5c\u7528\u57df\u5305\u542b\u5f53\u524d\u6a21\u5757\u7684\u5168\u5c40\u540d\u79f0 \u6700\u5916\u9762\u7684\u4f5c\u7528\u57df\uff08\u6700\u540e\u641c\u7d22\uff09\u662f\u5305\u542b\u5185\u7f6e\u540d\u79f0\u7684\u547d\u540d\u7a7a\u95f4 \u5982\u679c\u4e00\u4e2a\u540d\u79f0\u88ab\u58f0\u660e\u4e3a\u5168\u5c40\u53d8\u91cf\uff0c\u5219\u6240\u6709\u5f15\u7528\u548c\u8d4b\u503c\u5c06\u76f4\u63a5\u6307\u5411\u8be5\u6a21\u5757\u5168\u5c40\u540d\u79f0\u6240\u5728\u7684\u4e2d\u95f4\u4f5c\u7528\u57df\u3002 \u5982\u679c\u8981\u91cd\u65b0\u7ed1\u5b9a\u5728\u6700\u5185\u5c42\u4f5c\u7528\u57df\u4ee5\u5916\u7684\u53d8\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528 nonlocal \u8bed\u53e5\u58f0\u660e\u4e3a\u975e\u672c\u5730\u53d8\u91cf\u3002 \u5982\u679c\u6ca1\u6709\u88ab\u58f0\u660e\u4e3a\u975e\u672c\u5730\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u5c06\u662f\u53ea\u8bfb\u7684\u3002\u7ed9\u8fd9\u6837\u7684\u53d8\u91cf\u8d4b\u65b0\u503c\u53ea\u4f1a\u5728\u6700\u5185\u5c42\u4f5c\u7528\u57df\u4e2d\u521b\u5efa\u4e00\u4e2a \u65b0\u7684 \u5c40\u90e8\u53d8\u91cf\uff0c\u800c\u540c\u540d\u7684\u5916\u90e8\u5168\u5c40\u53d8\u91cf\u5c06\u4fdd\u6301\u4e0d\u53d8\u3002 \u901a\u5e38\uff0c\u5f53\u524d\u5c40\u90e8\u4f5c\u7528\u57df\uff08local scope\uff09\u5c06\u5f15\u7528\u5f53\u524d\u51fd\u6570\u4f5c\u7528\u57df\u7684\u540d\u79f0\uff08local name\uff09\u3002 \u5728\u51fd\u6570\u4f5c\u7528\u57df\u4ee5\u5916\uff0c\u5f53\u524d\u5c40\u90e8\u4f5c\u7528\u57df\u5c06\u5f15\u7528\u4e0e\u5168\u5c40\u4f5c\u7528\u57df\u76f8\u4e00\u81f4\u7684\u547d\u540d\u7a7a\u95f4\uff1a\u6a21\u5757\u7684\u547d\u540d\u7a7a\u95f4\uff08the module\u2019s namespace\uff09\u3002 \u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff0c\u662f\u5728\u672c\u5730\u5c40\u90e8\u547d\u540d\u7a7a\u95f4\u5185\u5efa\u4e00\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\u3002 \u5728\u4e00\u4e2a\u6a21\u5757\uff08module \uff09\u5185\u5b9a\u4e49\u7684\u51fd\u6570\u7684\u4f5c\u7528\u57df\u5c31\u662f\u8be5\u6a21\u5757\u7684\u547d\u540d\u7a7a\u95f4\uff0c\u65e0\u8bba\u8be5\u51fd\u6570\u4ece\u4ec0\u4e48\u5730\u65b9\u6216\u4ee5\u4ec0\u4e48\u522b\u540d\u88ab\u8c03\u7528\u3002 \u53e6\u4e00\u65b9\u9762\uff0c\u5b9e\u9645\u7684\u540d\u79f0\u641c\u7d22\u662f\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u5b8c\u6210\u7684\u3002 \u4f46\u662f\uff0cPython\u6b63\u5728\u671d\u7740\u201c\u7f16\u8bd1\u65f6\u9759\u6001\u540d\u79f0\u89e3\u6790\u201d\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u56e0\u6b64\u4e0d\u8981\u8fc7\u4e8e\u4f9d\u8d56\u52a8\u6001\u540d\u79f0\u89e3\u6790\uff01\u4e8b\u5b9e\u4e0a\uff0c\u5c40\u90e8\u53d8\u91cf\u5df2\u7ecf\u662f\u88ab\u9759\u6001\u786e\u5b9a\u4e86\u3002 \u5982\u679c\u4e0d\u5b58\u5728\u751f\u6548\u7684 global \u6216 nonlocal \u8bed\u53e5\uff0c\u5219\u5bf9\u540d\u79f0\u7684\u8d4b\u503c\u603b\u662f\u4f1a\u8fdb\u5165\u6700\u5185\u5c42\u4f5c\u7528\u57df\u3002\u8d4b\u503c\u4e0d\u4f1a\u590d\u5236\u6570\u636e\uff0c\u662f\u5c06\u540d\u79f0\u7ed1\u5b9a\u5230\u5bf9\u8c61\u3002 \u5220\u9664\u4e5f\u662f\u5982\u6b64\uff1a\u8bed\u53e5 del x \u4f1a\u4ece\u5c40\u90e8\u4f5c\u7528\u57df\u6240\u5f15\u7528\u7684\u547d\u540d\u7a7a\u95f4\u4e2d\u79fb\u9664\u5bf9 x \u7684\u7ed1\u5b9a\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6240\u6709\u5f15\u5165\u65b0\u540d\u79f0\u7684\u64cd\u4f5c\u90fd\u662f\u4f7f\u7528\u5c40\u90e8\u4f5c\u7528\u57df\u3002\u7279\u522b\u5730\uff0c import \u8bed\u53e5\u548c\u51fd\u6570\u5b9a\u4e49\u4f1a\u5728\u5c40\u90e8\u4f5c\u7528\u57df\u4e2d\u7ed1\u5b9a\u6a21\u5757\u6216\u51fd\u6570\u540d\u79f0\u3002 global \u8bed\u53e5\u53ef\u88ab\u7528\u6765\u8868\u660e\u7279\u5b9a\u53d8\u91cf\u5b58\u5728\u4e8e\u5168\u5c40\u4f5c\u7528\u57df\uff0c\u5e76\u4e14\u5e94\u5f53\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u88ab \u91cd\u65b0 \u7ed1\u5b9a\uff1b nonlocal \u8bed\u53e5\u8868\u660e\u7279\u5b9a\u53d8\u91cf\u751f\u5b58\u4e8e\u5916\u5c42\u4f5c\u7528\u57df\u4e2d\uff0c\u5e76\u4e14\u5e94\u5f53\u5728\u5176\u6240\u5904\u7684\u5916\u5c42\u4f5c\u7528\u57df\u4e2d\u88ab \u91cd\u65b0 \u7ed1\u5b9a\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a \u5c40\u90e8\u8d4b\u503c\uff08local assignment\uff0c\u8fd9\u662f\u9ed8\u8ba4\u72b6\u6001\uff09\u4e0d\u4f1a\u6539\u53d8 scope_test \u5bf9 spam \u7684\u7ed1\u5b9a\u3002 nonlocal \u8d4b\u503c\u4f1a\u6539\u53d8 scope_test \u5bf9 spam \u7684\u7ed1\u5b9a\u3002 global \u8d4b\u503c\u4f1a\u6539\u53d8\u6a21\u5757\u5c42\u7ea7\u7684\u7ed1\u5b9a\uff0c\u5373\uff0c global spam \u91cd\u65b0\u7ed1\u5b9a\u4e86spam\u7684\u5168\u5c40\u5b9a\u4e49\uff0c\u4ece spam = \"spam out of func\" \u53d8\u6210\u4e86 spam = \"global spam\" \u3002\u5982\u679c\u6ce8\u91ca\u6389def do_global()\u8fd9\u4e00\u6bb5\u4ee3\u7801\uff0c\u5219 spam = \"spam out of func\" \u8d77\u4f5c\u7528\u3002 spam = \"spam out of func\" def scope_test(): def do_local(): spam = \"local spam\" def do_nonlocal(): nonlocal spam spam = \"nonlocal spam\" def do_global(): global spam spam = \"global spam\" spam = \"test spam\" do_local() print(\"After local assignment:\", spam) do_nonlocal() print(\"After nonlocal assignment:\", spam) do_global() print(\"After global assignment:\", spam) scope_test() print(\"In global scope:\", spam) # \u8fd0\u884c\u7ed3\u679c # scope_test() After local assignment: test spam After nonlocal assignment: nonlocal spam After global assignment: nonlocal spam # print(\"In global scope:\", spam) In global scope: global spam \u7c7bClass \u7c7b\u5b9a\u4e49 Class Definition \u7c7b\u5b9a\u4e49\u4e0e\u51fd\u6570\u5b9a\u4e49 (def \u8bed\u53e5) \u4e00\u6837\u5fc5\u987b\u88ab\u6267\u884c\u624d\u4f1a\u8d77\u4f5c\u7528\u3002 class ClassName: <statement-1> ... <statement-N> \u5728\u5b9e\u8df5\u4e2d\uff0c\u7c7b\u5b9a\u4e49\u5185\u7684\u8bed\u53e5\u901a\u5e38\u90fd\u662f\u51fd\u6570\u5b9a\u4e49\uff0c\u4f46\u4e5f\u5141\u8bb8\u6709\u5176\u4ed6\u8bed\u53e5\u3002\u5728\u7c7b\u5185\u90e8\u7684\u51fd\u6570\u5b9a\u4e49\u901a\u5e38\u5177\u6709\u4e00\u79cd\u7279\u6709\u5f62\u5f0f\u7684\u53c2\u6570\u5217\u8868\uff0c\u8fd9\u662f\u7ea6\u5b9a\u7684\u65b9\u6cd5\u89c4\u8303\uff08conventions for methods\uff09\u3002 \u7f16\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u8fdb\u5165\u4e00\u4e2a\u7c7b\u7684\u5185\u90e8\uff0c\u5c06\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\uff0c\u4e00\u4e2a\u5c40\u90e8\u4f5c\u7528\u57df\u3002\u56e0\u6b64\uff0c\u6240\u6709\u5bf9\u7c7b\u5185\u90e8\u5c40\u90e8\u53d8\u91cf\u7684\u8d4b\u503c\u90fd\u662f\u5728\u8fd9\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\u4e4b\u5185\uff0c\u5305\u62ec\u65b0\u5b9a\u4e49\u7684\u51fd\u6570\u540d\u79f0\u3002 \u5f53\u6b63\u5e38\u79bb\u5f00\u4e00\u4e2a\u7c7b\u65f6\uff0c\u7f16\u8bd1\u8fc7\u7a0b\u5c06\u521b\u5efa\u4e00\u4e2a\u7c7b\u5bf9\u8c61\uff08class object\uff09\uff0c\u5c01\u88c5\u4e86\u7c7b\u5b9a\u4e49\u6240\u521b\u5efa\u7684\u547d\u540d\u7a7a\u95f4\u91cc\u7684\u5185\u5bb9\u3002 \u6700\u521d\u7684\uff08\u5728\u8fdb\u5165\u7c7b\u5b9a\u4e49\u4e4b\u524d\u8d77\u4f5c\u7528\u7684\uff09\u5c40\u90e8\u4f5c\u7528\u57df\u5c06\u91cd\u65b0\u751f\u6548\uff0c\u7c7b\u5bf9\u8c61\uff08class object\uff09\u5c06\u5728\u8fd9\u91cc\u88ab\u7ed1\u5b9a\u5230\u7c7b\u5b9a\u4e49\u5934\u90e8\u6240\u58f0\u660e\u7684\u7c7b\u540d\u79f0 (\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\u662f ClassName )\u3002 \u7c7b\u5bf9\u8c61 Class Objects \u7c7b\u5bf9\u8c61\u652f\u6301\u4e24\u79cd\u64cd\u4f5c\uff1a\u5c5e\u6027\u5f15\u7528\uff08attribute references\uff09\u548c\u5b9e\u4f8b\u5316\uff08instantiation\uff09\u3002 \u5c5e\u6027\u5f15\u7528\uff08attribute references\uff09 \u4f7f\u7528Python\u4e2d\u5c5e\u6027\u5f15\u7528\u7684\u6807\u51c6\u8bed\u6cd5: obj.name \u3002 \u5b58\u5728\u4e8e\u7c7b\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u6240\u6709\u540d\u79f0\uff0c\u7c7b\u5bf9\u8c61\u88ab\u521b\u5efa\u65f6\u540c\u65f6\u88ab\u521b\u5efa\u4e86\uff0c\u8fd9\u4e9b\u5c31\u662f\u6709\u6548\u7684\u5c5e\u6027\u540d\u79f0\u3002\u56e0\u6b64\uff0c\u5982\u679c\u7c7b\u5b9a\u4e49\u662f\u5982\u4e0b\u6240\u793a\uff0c\u90a3\u4e48 MyClass.i \u548c MyClass.f \u5c31\u662f\u6709\u6548\u7684\u5c5e\u6027\u5f15\u7528\uff0c\u5c06\u5206\u522b\u8fd4\u56de\u4e00\u4e2a\u6574\u6570\u548c\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u3002 \u7c7b\u5c5e\u6027\u4e5f\u53ef\u4ee5\u88ab\u8d4b\u503c\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u8d4b\u503c\u6765\u66f4\u6539 MyClass.i \u7684\u503c\u3002 __doc__ \u4e5f\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5c5e\u6027\uff0c\u5c06\u8fd4\u56de\u6240\u5c5e\u7c7b\u7684\u6587\u6863\u5b57\u7b26\u4e32: \"A simple example class\"\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' print(MyClass.i) # 12345 print(MyClass.__doc__) # A simple example class MyClass.i = 10 print(MyClass.i) # 10 \u7c7b\u7684 \u5b9e\u4f8b\u5316\uff08instantiation\uff09 \u4f7f\u7528\u51fd\u6570\u8868\u793a\u6cd5\u3002 \u53ef\u4ee5\u628a\u7c7b\u5bf9\u8c61\uff08class object\uff09\u770b\u4f5c\u662f\u4e00\u4e2a\u4e0d\u5e26\u53c2\u6570\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u8fd4\u56de\u4e86\u8be5\u7c7b\u7684\u4e00\u4e2a\u65b0\u5b9e\u4f8b\u3002 \u5728\u4e0b\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c x = MyClass() \u521b\u5efa\u4e86 MyClass() \u8fd9\u4e2a\u7c7b\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5e76\u8d4b\u503c\u7ed9\u5c40\u90e8\u53d8\u91cf x \u3002 \u5b9e\u4f8b\u5316\u64cd\u4f5c\uff08\u8c03\u7528\u7c7b\u5bf9\u8c61\uff09\u4f1a\u521b\u5efa\u4e00\u4e2a\u7a7a\u5bf9\u8c61\u3002\u8bb8\u591a\u7c7b\u4f1a\u521b\u5efa\u5e26\u6709\u7279\u5b9a\u521d\u59cb\u72b6\u6001\u7684\u81ea\u5b9a\u4e49\u5b9e\u4f8b\u3002\u4e3a\u6b64\u7c7b\u5b9a\u4e49\u4e2d\u9700\u8981\u5305\u542b\u4e00\u4e2a\u540d\u4e3a __init__() \u7684\u7279\u6b8a\u65b9\u6cd5\u3002 \u5f53\u4e00\u4e2a\u7c7b\u5b9a\u4e49\u4e86 __init__() \u65b9\u6cd5\u65f6\uff0c\u7c7b\u7684\u5b9e\u4f8b\u5316\u64cd\u4f5c\u4f1a\u81ea\u52a8\u4e3a\u65b0\u521b\u5efa\u7684\u7c7b\u5b9e\u4f8b\u8c03\u7528 __init__() \u3002 \u66f4\u65b0\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u6ce8\u610f __dict__ \u4e24\u6b21\u8fd4\u56de\u7684\u4e0d\u540c\u7684\u5b57\u5178\u3002\u590d\u4e60\u4e00\u4e0b\uff0c\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u63d0\u5230\uff0c __dict__ \u662f\u5c5e\u6027\u4f46\u4e0d\u662f\u5168\u5c40\u540d\u79f0\uff0c\u8fd4\u56de\u7528\u4e8e\u5b9e\u73b0\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u7684\u5b57\u5178\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() print(x.__dict__) # {'data': []} x.i = 10 print(x.__dict__) # {'data': [], 'i': 10} __init__() \u65b9\u6cd5\u53ef\u4ee5\u6709\u989d\u5916\u7684\u53c2\u6570\u8f93\u5165\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7c7b\u5b9e\u4f8b\u5316\u7684\u53c2\u6570\u5c06\u88ab\u4f20\u9012\u7ed9 __init__() \u3002 \u5982\u4e0b\u4f8b: class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpart x = Complex(3.0, -4.5) print(x.r, x.i) # 3.0 -4.5 \u5b9e\u4f8b\u5bf9\u8c61 Instance Objects \u5bf9\u5b9e\u4f8b\u5bf9\u8c61\u552f\u4e00\u7684\u64cd\u4f5c\u662f\u5c5e\u6027\u5f15\u7528\u3002\u6709\u4e24\u79cd\u6709\u6548\u7684\u5c5e\u6027\u540d\u79f0\uff1a\u6570\u636e\u5c5e\u6027\uff08data attributes\uff09\u548c\u65b9\u6cd5\uff08methods\uff09\u3002 \u6570\u636e\u5c5e\u6027\uff08data attributes\uff09 \u7c7b\u4f3c\u4e8e\u5b9e\u4f8b\u53d8\u91cf\uff0c\u6570\u636e\u5c5e\u6027\u4e0d\u9700\u8981\u58f0\u660e\u3002\u50cf\u5c40\u90e8\u53d8\u91cf\u4e00\u6837\uff0c\u6570\u636e\u5c5e\u6027\u5c06\u5728\u7b2c\u4e00\u6b21\u88ab\u8d4b\u503c\u65f6\u4ea7\u751f\u3002 \u4f8b\u5982\uff0c\u5982\u679c x \u662f\u4e0a\u9762\u521b\u5efa\u7684 MyClass \u7684\u5b9e\u4f8b\uff0c\u5219\u4ee5\u4e0b\u4ee3\u7801\u6bb5\u5c06\u6253\u5370\u6570\u503c 16 \uff0c\u4e14\u6ca1\u6709\u7559\u4e0b\u5173\u4e8e x.counter \u7684\u75d5\u8ff9\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() x.counter = 1 while x.counter < 10: x.counter = x.counter * 2 print(x.counter) # 16 print(x.__dict__) # {'data': [], 'counter': 16} del x.counter print(x.__dict__) # {'data': []} \u53e6\u4e00\u7c7b\u5b9e\u4f8b\u5c5e\u6027\u5f15\u7528\u79f0\u4e3a \u65b9\u6cd5\uff08methods\uff09 \u3002 \u65b9\u6cd5\u662f\u96b6\u5c5e\u4e8e\u5bf9\u8c61\u7684 \u51fd\u6570 \u3002 \u5728Python\u4e2d\uff0c\u65b9\u6cd5\u8fd9\u4e2a\u672f\u8bed\u5e76\u4e0d\u662f\u7c7b\u5b9e\u4f8b\u6240\u7279\u6709\u7684\uff0c\u5176\u4ed6\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u6709\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0c\u5217\u8868\u5bf9\u8c61\uff08list objects\uff09\u5177\u6709append, insert, remove, sort\u7b49\u65b9\u6cd5\u3002 \u5728\u4ee5\u4e0b\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u65b9\u6cd5\u4e00\u8bcd\u5c06\u4e13\u6307\u7c7b\u5b9e\u4f8b\u5bf9\u8c61\u7684\u65b9\u6cd5\uff0c\u9664\u975e\u53e6\u5916\u660e\u786e\u8bf4\u660e\u3002 \u5b9e\u4f8b\u5bf9\u8c61\u7684\u6709\u6548\u65b9\u6cd5\u540d\u79f0\u4f9d\u8d56\u4e8e\u5176\u6240\u5c5e\u7684\u7c7b\u3002 \u6839\u636e\u5b9a\u4e49\uff0c\u4e00\u4e2a\u7c7b\u5b9a\u4e49\u4e2d\u6240\u5305\u542b\u7684\u6240\u6709\u51fd\u6570\u5bf9\u8c61\uff08function objects\uff09\u90fd\u79f0\u4e3a\u5c5e\u6027\u3002 \u56e0\u6b64\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c x.f \u662f\u6709\u6548\u7684\u65b9\u6cd5\u5f15\u7528\uff0c\u56e0\u4e3a MyClass.f \u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u800c x.i \u4e0d\u662f\u65b9\u6cd5\uff0c\u56e0\u4e3a MyClass.i \u4e0d\u662f\u51fd\u6570\u3002\u4f46\u662f x.f \u4e0e MyClass.f \u5e76\u4e0d\u662f\u4e00\u56de\u4e8b\uff0c x.f \u662f\u4e00\u4e2a \u65b9\u6cd5\u5bf9\u8c61 \uff0c\u800c MyClass.f \u662f\u4e00\u4e2a \u51fd\u6570\u5bf9\u8c61 \u3002\u5dee\u522b\u5728\u4e8e f() \u662f\u5426\u4e0e\u5b9e\u4f8b\u7ed1\u5b9a\uff0c\u672a\u7ed1\u5b9a\uff0c\u5c31\u662f\u51fd\u6570\uff0c\u7ed1\u5b9a\uff0c\u5c31\u662f\u65b9\u6cd5\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() print(MyClass.f(0)) # hello world print(x.f()) # hello world print(MyClass.f) # <function MyClass.f at 0x7ff9368b3488> print(x.f) # <bound method MyClass.f of <__main__.MyClass object at 0x7ff9368acbe0>> print(type(MyClass.f)) # <class 'function'> print(type(x.f)) # <class 'method'> \u8fd9\u91cc\u505a\u4e2a\u5c0f\u7ed3\uff1a \u51fd\u6570(function)\u662fPython\u4e2d\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61(callable), \u65b9\u6cd5(method)\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u51fd\u6570\u3002 \u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61\u662f\u65b9\u6cd5\u548c\u51fd\u6570\uff0c\u548c\u8fd9\u4e2a\u5bf9\u8c61\u65e0\u5173\uff0c\u4ec5\u548c\u8fd9\u4e2a\u5bf9\u8c61\u662f\u5426\u4e0e\u7c7b\u6216\u5b9e\u4f8b\u7ed1\u5b9a\u6709\u5173\uff08bound method\uff09\u3002 \u9759\u6001\u65b9\u6cd5\u6ca1\u6709\u548c\u4efb\u4f55\u7c7b\u6216\u5b9e\u4f8b\u7ed1\u5b9a\uff0c\u6240\u4ee5 \u9759\u6001\u65b9\u6cd5\u662f\u4e2a\u51fd\u6570 \u3002 \u65b9\u6cd5\u5bf9\u8c61 Method Objects \u5728 MyClass \u793a\u4f8b\u4e2d\uff0c x.f() \u662f\u4e00\u4e2a\u65b9\u6cd5\u5bf9\u8c61\uff0c\u88ab\u8c03\u7528\u540e\uff0c\u5c06\u8fd4\u56de\u5b57\u7b26\u4e32 'hello world' \u3002\u53ef\u4ee5\u7acb\u5373\u8c03\u7528\uff0c\u4e5f\u53ef\u4ee5\u4fdd\u5b58\u8d77\u6765\u4ee5\u540e\u518d\u8c03\u7528 xf = x.f \u3002 \u867d\u7136 f() \u7684\u51fd\u6570\u5b9a\u4e49\u6307\u5b9a\u4e86\u4e00\u4e2a\u53c2\u6570\uff0c\u4f46\u4e0a\u9762\u4f8b\u5b50\u4e2d\u8c03\u7528 x.f() \u65f6\u5e76\u6ca1\u6709\u5e26\u53c2\u6570\uff0c\u4e5f\u6ca1\u6709\u5f15\u53d1\u5f02\u5e38\u62a5\u9519\u3002\u539f\u56e0\u5728\u4e8e\uff0c \u65b9\u6cd5(method)\u7684\u7279\u6b8a\u4e4b\u5904\u5c31\u5728\u4e8e\u5b9e\u4f8b\u5bf9\u8c61\u4f1a\u4f5c\u4e3a\u51fd\u6570\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u88ab\u4f20\u5165\u3002 \u8c03\u7528 x.f() \u5176\u5b9e\u5c31\u76f8\u5f53\u4e8e MyClass.f(x) \u3002 \u603b\u4e4b\uff0c\u8c03\u7528\u4e00\u4e2a\u5177\u6709 n \u4e2a\u53c2\u6570\u7684\u65b9\u6cd5(method)\u5c31\u76f8\u5f53\u4e8e\u8c03\u7528\u518d\u591a\u4e00\u4e2a\u53c2\u6570\u7684\u5bf9\u5e94\u51fd\u6570\uff0c\u8fd9\u4e2a\u53c2\u6570\u503c\u4e3a\u65b9\u6cd5\u6240\u5c5e\u5b9e\u4f8b\u5bf9\u8c61\uff0c \u4f4d\u7f6e\u5728\u5176\u4ed6\u53c2\u6570\u4e4b\u524d \u3002 \u5f53\u4e00\u4e2a\u5b9e\u4f8b\u7684\u975e\u6570\u636e\u5c5e\u6027\u88ab\u5f15\u7528\u65f6\uff0c\u5c06\u641c\u7d22\u5b9e\u4f8b\u6240\u5c5e\u7684\u7c7b\u3002 \u5982\u679c\u88ab\u5f15\u7528\u7684\u5c5e\u6027\u540d\u79f0\u662f\u7c7b\u4e2d\u4e00\u4e2a\u6709\u6548\u7684\u51fd\u6570\u5bf9\u8c61\uff0c\u5219\u4f1a\u521b\u5efa\u4e00\u4e2a\u62bd\u8c61\u7684\u5bf9\u8c61\uff0c\u901a\u8fc7\u6253\u5305\uff08parking\uff0c\u5373\u6307\u5411\uff09\u5339\u914d\u5230\u7684\u5b9e\u4f8b\u5bf9\u8c61\u548c\u51fd\u6570\u5bf9\u8c61\uff0c\u8fd9\u4e2a\u62bd\u8c61\u5bf9\u8c61\u5c31\u662f\u65b9\u6cd5\u5bf9\u8c61\u3002 \u5f53\u5e26\u53c2\u6570\u8c03\u7528\u65b9\u6cd5\u5bf9\u8c61\u65f6\uff0c\u5c06\u57fa\u4e8e\u5b9e\u4f8b\u5bf9\u8c61\u548c\u53c2\u6570\u5217\u8868\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u53c2\u6570\u5217\u8868\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e2a\u65b0\u53c2\u6570\u5217\u8868\u8c03\u7528\u76f8\u5e94\u7684\u51fd\u6570\u5bf9\u8c61\u3002 \u7c7b\u548c\u5b9e\u4f8b\u53d8\u91cf Class and Instance Variables \u4e00\u822c\u6765\u8bf4\uff0c \u5b9e\u4f8b\u53d8\u91cf \u7528\u4e8e\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u552f\u4e00\u6570\u636e\uff0c\u800c \u7c7b\u53d8\u91cf \u7528\u4e8e\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u5171\u4eab\u7684\u5c5e\u6027\u548c\u65b9\u6cd5: class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance d = Dog('Fido') e = Dog('Buddy') print(d.kind) # shared by all dogs # 'canine' print(e.kind) # shared by all dogs # 'canine' print(d.name) # unique to d instance # 'Fido' print(e.name) # unique to e instance # 'Buddy' \u4e0b\u4ee3\u7801\u4e2d\u7684 tricks \u5217\u8868\u4e0d\u5e94\u8be5\u88ab\u7528\u4f5c\u7c7b\u53d8\u91cf\uff0c\u56e0\u4e3a\u6240\u6709\u7684 Dog \u5b9e\u4f8b\u5c06\u53ea\u5171\u4eab\u4e00\u4e2a\u5355\u72ec\u7684\u5217\u8868: class Dog: kind = 'canine' # class variable shared by all instances tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name # instance variable unique to each instance def add_trick(self, trick): self.tricks.append(trick) d = Dog('Fido') e = Dog('Buddy') d.add_trick('roll over') e.add_trick('play dead') print(d.tricks) # ['roll over', 'play dead'] \u6b63\u786e\u7684\u7c7b\u8bbe\u8ba1\u5e94\u8be5\u4f7f\u7528\u5b9e\u4f8b\u53d8\u91cf: class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick) d = Dog('Fido') e = Dog('Buddy') d.add_trick('roll over') e.add_trick('play dead') print(d.tricks) # ['roll over'] print(e.tricks) # ['play dead'] \u5982\u679c\u540c\u6837\u7684\u5c5e\u6027\u540d\u79f0\u540c\u65f6\u51fa\u73b0\u5728\u5b9e\u4f8b\u548c\u7c7b\u4e2d\uff0c\u5219\u5c5e\u6027\u67e5\u627e\u4f1a \u4f18\u5148\u9009\u62e9\u5b9e\u4f8b : class Warehouse: purpose = 'storage' region = 'west' w1 = Warehouse() print(w1.purpose, w1.region) # storage west w2 = Warehouse() w2.region = 'east' # Instance W2 has higher priority than class print(w2.purpose, w2.region) # storage east \u6570\u636e\u5c5e\u6027\uff08Data attributes\uff09\u53ef\u4ee5\u88ab\u65b9\u6cd5\uff08method\uff09\u4ee5\u53ca\u4e00\u4e2a\u5bf9\u8c61\u7684\u666e\u901a\u7528\u6237\uff08ordinary users\uff09\uff08\u201c\u5ba2\u6237\u7aefClient\u201d\uff09\u6240\u5f15\u7528\u3002 \u6362\u53e5\u8bdd\u8bf4\uff0c\u7c7b\u4e0d\u80fd\u7528\u4e8e\u5b9e\u73b0\u7eaf\u62bd\u8c61\u6570\u636e\u7c7b\u578b\u3002 \u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u5e38\u5e38\u88ab\u547d\u540d\u4e3a self \uff0c\u8fd9\u53ea\u662f\u4e00\u4e2a\u7ea6\u5b9a: self \u8fd9\u4e00\u540d\u79f0\u5728Python\u4e2d\u6ca1\u6709\u7279\u6b8a\u542b\u4e49\u3002 \u4f46\u662f\u9075\u5faa\u6b64\u7ea6\u5b9a\u4f1a\u4f7f\u5f97\u4ee3\u7801\u5177\u6709\u5f88\u597d\u7684\u53ef\u8bfb\u6027\u3002 \u4efb\u4f55\u4e00\u4e2a\u4f5c\u4e3a\u7c7b\u5c5e\u6027\uff08class attribute\uff09\u7684\u51fd\u6570\u5bf9\u8c61\uff08function object\uff09\u90fd\u4e3a\u8be5\u7c7b\u7684\u5b9e\u4f8b\u5b9a\u4e49\u4e86\u4e00\u4e2a\u76f8\u5e94\u65b9\u6cd5\u3002 \u51fd\u6570\u5b9a\u4e49\u7684\u6587\u672c\u5e76\u975e\u5fc5\u987b\u5305\u542b\u4e8e\u7c7b\u5b9a\u4e49\u4e4b\u5185\uff1a\u5c06\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u8d4b\u503c\u7ed9\u4e00\u4e2a\u5c40\u90e8\u53d8\u91cf\u4e5f\u662f\u53ef\u4ee5\u7684\u3002\u5982\u4e0b\u4f8b\u3002\u73b0\u5728 f , g \u548c h \u90fd\u662f\u7c7b C \u7684\u5f15\u7528\u51fd\u6570\u5bf9\u8c61\u7684\u5c5e\u6027\uff0c\u56e0\u800c\u5b83\u4eec\u5c31\u90fd\u662f\u7c7b C \u7684\u5b9e\u4f8b\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d h \u5b8c\u5168\u7b49\u540c\u4e8e g \u3002\u4f46\u8bf7\u6ce8\u610f\uff0c\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u7684\u53ef\u8bfb\u6027\u975e\u5e38\u4e0d\u597d\u3002 # Function defined outside the class def f1(self, x, y): return min(x, x + y) class C: f = f1 # Assign a function object to a local variable in the class def g(self): return 'hello world' h = g \u65b9\u6cd5\uff08methods\uff09\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 self \u53c2\u6570\u7684\u65b9\u6cd5\u5c5e\u6027\uff08method attributes\uff09\u8c03\u7528\u5176\u4ed6\u65b9\u6cd5\uff08method\uff09: class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) \u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u4e0e\u666e\u901a\u51fd\u6570\u76f8\u540c\u7684\u65b9\u5f0f\u5f15\u7528\u5168\u5c40\u540d\u79f0\u3002 \u4e0e\u65b9\u6cd5\u76f8\u5173\u8054\u7684\u5168\u5c40\u4f5c\u7528\u57df\u5c31\u662f\u5305\u542b\u5176\u5b9a\u4e49\u7684\u6a21\u5757\u3002 \uff08\u7c7b\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u4f5c\u4e3a\u5168\u5c40\u4f5c\u7528\u57df\u3002\uff09 \u867d\u7136\u6211\u4eec\u5f88\u5c11\u4f1a\u6709\u5145\u5206\u7684\u7406\u7531\u5728\u65b9\u6cd5\u4e2d\u4f7f\u7528\u5168\u5c40\u4f5c\u7528\u57df\uff0c\u4f46\u5168\u5c40\u4f5c\u7528\u57df\u5b58\u5728\u8bb8\u591a\u5408\u7406\u7684\u4f7f\u7528\u573a\u666f\uff1a\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u5bfc\u5165\u5230\u5168\u5c40\u4f5c\u7528\u57df\u7684\u51fd\u6570\u548c\u6a21\u5757\u53ef\u4ee5\u88ab\u65b9\u6cd5\u6240\u4f7f\u7528\uff0c\u5728\u5176\u4e2d\u5b9a\u4e49\u7684\u51fd\u6570\u548c\u7c7b\u4e5f\u4e00\u6837\u3002 \u901a\u5e38\uff0c\u5305\u542b\u8be5\u65b9\u6cd5\u7684\u7c7b\u672c\u8eab\u662f\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u5b9a\u4e49\u7684\u3002 \u603b\u7ed3 \u7c7b\u5b9a\u4e49\u5c0f\u7ed3 \u4e00\u4e2a\u7c7b\u5b9a\u4e49\u7c7b\u6210\u5458\u5c5e\u6027\u548c\u6210\u5458\u65b9\u6cd5\u3002 \u4e00\u4e2a\u7c7b\u53ef\u4ee5\u5b9e\u4f8b\u5316\u591a\u4e2a\u5bf9\u8c61\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5316\u5bf9\u8c61\u90fd\u662f\u72ec\u7acb\u7684\u3002 \u521b\u5efa\u7684\u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\uff0c\u4f1a\u5f15\u7528\u7236\u7c7b\u4e2d\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u5e76\u4e0d\u4f1a\u628a\u7c7b\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u590d\u5236\u7ed9\u5bf9\u8c61\uff0c\u56e0\u6b64\uff1a \u5728\u8bbf\u95ee\u5b9e\u4f8b\u5316\u5bf9\u8c61\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u65f6\uff0c\u4f1a\u5148\u53bb\u627e\u5bf9\u8c61\u81ea\u5df1\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u7136\u540e\u518d\u53bb\u5b9e\u4f8b\u5316\u8fd9\u4e2a\u5bf9\u8c61\u7684\u7c7b\u4e2d\u67e5\u627e\uff08\u5f15\u7528\uff09\u3002 \u5bf9\u8c61\u6210\u5458\u7684\u6dfb\u52a0\u548c\u4fee\u6539\uff0c\u90fd\u53ea\u4f1a\u5f71\u54cd\u5f53\u524d\u5bf9\u8c61\u81ea\u5df1\uff0c\u4e0d\u4f1a\u5f71\u54cd\u7c7b\u548c\u5176\u5b83\u5bf9\u8c61\u3002 \u5220\u9664\u5bf9\u8c61\u6210\u5458\u7684\u65f6\u5019\uff0c\u5fc5\u987b\u662f\u8be5\u5bf9\u8c61\u81ea\u5df1\u5177\u5907\u7684\u6210\u5458\u624d\u53ef\u4ee5\uff0c\u4e0d\u80fd\u5220\u9664\u7c7b\u4e2d\u5f15\u7528\u7684\u6210\u5458\u3002 \u5bf9\u7c7b\u6210\u5458\u7684\u64cd\u4f5c\uff0c\u4f1a\u5f71\u54cd\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\uff0c\u5305\u62ec\u4e4b\u524d\u521b\u5efa\u7684\u5bf9\u8c61\uff08\u5f15\u7528\uff09\u3002 \u7c7b\u6210\u5458\u64cd\u4f5c\uff08\u4e0d\u63a8\u8350\uff09\uff1a \u6210\u5458\u5c5e\u6027\uff1a \u8bbf\u95ee\uff1a ClassName.AttributeName \u4fee\u6539\uff1a ClassName.AttributeName = NewValue \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u6dfb\u52a0\uff1a ClassName.NewAttributeName = Value \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u5220\u9664\uff1a del ClassName.AttributeName \uff0c\u6ce8\u610f\uff0c\u53ea\u80fd\u5220\u9664\u7c7b\u5bf9\u8c61\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u4e0d\u518d\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u6210\u5458\u65b9\u6cd5\uff1a \u8bbf\u95ee\uff1a ClassName.MethodName() \u4fee\u6539\uff1a ClassName.MethodName = NewFunction \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002 \u6dfb\u52a0\uff1a ClassName.MethodName = Function \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002 \u5220\u9664\uff1a del ClassName.MethodName \uff0c\u6ce8\u610f\uff0c\u53ea\u80fd\u5220\u9664\u7c7b\u5bf9\u8c61\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u4e0d\u518d\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002 \u6210\u5458\u65b9\u6cd5\u4e2d\u7684self self \u53ea\u662f\u4e00\u4e2a\u5f62\u53c2\uff0c\u4e0d\u662f\u5173\u952e\u5b57\u3002 self \u5728\u65b9\u6cd5\uff08method\uff09\u4ee3\u8868\u5f53\u524d\u5bf9\u8c61\u81ea\u5df1\u3002\u524d\u9762\u63d0\u5230\u8fc7\uff0c\u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u5e38\u5e38\u88ab\u547d\u540d\u4e3a self \uff0c\u8fd9\u53ea\u662f\u4e00\u4e2a\u7ea6\u5b9a\u3002 \u53ef\u4ee5\u4f7f\u7528 self \u5728\u7c7b\u5185\u90e8\u64cd\u4f5c\u6210\u5458\uff08\u6dfb\u52a0\u3001\u4fee\u6539\u3001\u5220\u9664\u7b49\uff09\u3002 \u65b9\u6cd5\u7684\u5206\u7c7b\uff1a \u542b\u6709self\u6216\u8005\u53ef\u4ee5\u63a5\u53d7\u5bf9\u8c61\u4f5c\u4e3a\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u975e\u7ed1\u5b9a\u7c7b\u65b9\u6cd5 \uff0c\u975e\u7ed1\u5b9a\u7c7b\u7684\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528\u5bf9\u8c61\u53bb\u8bbf\u95ee\u3002 \u4e0d\u542b\u6709self\u6216\u8005\u4e0d\u80fd\u63a5\u53d7\u5bf9\u8c61\u4f5c\u4e3a\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u7ed1\u5b9a\u7c7b\u65b9\u6cd5 \uff0c\u7ed1\u5b9a\u65b9\u6cd5\u53ea\u80fd\u4f7f\u7528\u7c7b\u53bb\u8bbf\u95ee\u3002 \u9b54\u672f\u65b9\u6cd5 \u9b54\u672f\u65b9\u6cd5\uff08Magic Method\uff09\u548c\u666e\u901a\u65b9\u6cd5\u4e00\u6837\uff0c\u90fd\u662f\u7c7b\u4e2d\u5b9a\u4e49\u7684\u6210\u5458\u65b9\u6cd5\u3002 \u9b54\u672f\u65b9\u6cd5\u540d\u79f0\u524d\u540e\u5404\u67092\u4e2a\u4e0b\u5212\u7ebf\uff0c\u6bd4\u5982 __init__ \u9b54\u672f\u65b9\u6cd5\u662f\u4e0d\u9700\u8981\u624b\u52a8\u8c03\u7528\u7684\uff0c\u4f1a\u5728\u67d0\u79cd\u60c5\u51b5\u4e0b\u81ea\u52a8\u89e6\u53d1\uff08\u81ea\u52a8\u6267\u884c\uff09\u3002 \u9b54\u672f\u65b9\u6cd5\u662f\u7cfb\u7edf\u5b9a\u4e49\u597d\u7684\uff0c\u4e0d\u662f\u7528\u6237\u5b9a\u4e49\u7684\u3002 __init__ \u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e5f\u79f0\u4f5c \u6784\u9020\u65b9\u6cd5 \u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\u521b\u5efa\u540e\u81ea\u52a8\u89e6\u53d1\u3002 __init__ \u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u7528\u6765\u5728\u5bf9\u8c61\u5b9e\u4f8b\u5316\u540e\u5b8c\u6210\u5bf9\u8c61\u7684\u521d\u59cb\u5316\uff0c\u6bd4\u5982\u5c5e\u6027\u8d4b\u503c\uff0c\u65b9\u6cd5\u8c03\u7528\u7b49\u3002 __del__ \u6790\u6784\u65b9\u6cd5 \u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\u88ab\u9500\u6bc1\u65f6\u81ea\u52a8\u89e6\u53d1\u3002 __del__ \u6790\u6784\u65b9\u6cd5\u53ef\u4ee5\u5728\u9500\u6bc1\u5bf9\u8c61\u65f6\u5b8c\u6210\u4e00\u4e9b\u7279\u6b8a\u4efb\u52a1\uff0c\u5173\u95ed\u5bf9\u8c61\u6253\u5f00\u7684\u4e00\u4e9b\u8d44\u6e90\uff0c\u5982\u6587\u4ef6\u7b49\u3002 \u6ce8\u610f\uff0c\u662f\u5bf9\u8c61\u88ab\u9500\u6bc1\u65f6\u89e6\u53d1\u4e86\u6790\u6784\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f\u8fd9\u4e2a\u6790\u6784\u65b9\u6cd5\u9500\u6bc1\u4e86\u5bf9\u8c61\u3002 \u5bf9\u8c61\u9500\u6bc1\u7684\u60c5\u51b5\uff1a \u5f53\u7a0b\u5e8f\u6267\u884c\u5b8c\u6bd5\uff0c\u9500\u6bc1\u548c\u91ca\u653e\u5185\u5b58\u4e2d\u7684\u8d44\u6e90\u3002 \u4f7f\u7528 del \u5220\u9664\u65f6\u3002 \u5bf9\u8c61\u4e0d\u518d\u88ab\u4efb\u4f55\u5bf9\u8c61\u5f15\u7528\u65f6\uff0c\u4f1a\u81ea\u52a8\u9500\u6bc1\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5bf9\u6bd4 bmw = Car('BMW') \u548c Car('BMW') \u6765\u7406\u89e3 init \u548c del \u7684\u89e6\u53d1\u673a\u5236\u3002 \u7f16\u8f91\u6587\u4ef6 file1.py class Car(): brand = \"\" def __init__(self, car_brand): self.brand = car_brand print(f\"initial method called, create {self.brand} car\") def __del__(self): print(f\"delete method called, destroy {self.brand} car\") bmw = Car('BMW') vw = Car('VW') \u6267\u884c\u4e0a\u9762\u7684\u4ee3\u7801 python3 file1.py \u5f97\u5230\u5982\u4e0b\u8f93\u51fa\uff0c\u5728\u7a0b\u5e8f\u6267\u884c\u5b8c\u6bd5\u65f6\uff0c\u4f9d\u6b21\u6267\u884c __del__ \u3002 initial method called, create BMW car initial method called, create VW car delete method called, destroy BMW car delete method called, destroy VW car \u7f16\u8f91\u6587\u4ef6 file2.py class Car(): brand = \"\" def __init__(self, car_brand): self.brand = car_brand print(f\"initial method called, create {self.brand} car\") def __del__(self): print(f\"delete method called, destroy {self.brand} car\") Car('BMW') Car('VW') \u6267\u884c\u4e0a\u9762\u7684\u4ee3\u7801 python3 file2.py \u5f97\u5230\u5982\u4e0b\u8f93\u51fa\uff1a initial method called, create BMW car delete method called, destroy BMW car initial method called, create VW car delete method called, destroy VW car Python\u51fd\u6570\u5185\u7701\u5185\u7701 \u4ece\u9b54\u672f\u65b9\u6cd5\u53ef\u4ee5\u5ef6\u7533\u5230Python\u7684 \u51fd\u6570\u5185\u7701 \uff0c\u51fd\u6570\u5185\u7701\u7684\u610f\u601d\u662f\u8bf4\uff0c\u5f53\u4f60\u62ff\u5230\u4e00\u4e2a\u201c\u51fd\u6570\u5bf9\u8c61\u201d\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7ee7\u7eed\u77e5\u9053\uff0c\u5b83\u7684\u540d\u5b57\uff0c\u53c2\u6570\u5b9a\u4e49\u7b49\u4fe1\u606f\u3002\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u901a\u8fc7\u51fd\u6570\u5bf9\u8c61\u7684\u5c5e\u6027\uff08\u4e00\u4e9b\u53cc\u4e0b\u5212\u7ebf\u7684\u9b54\u6cd5\u65b9\u6cd5\uff09\u5f97\u5230\u3002\u7b80\u8a00\u4e4b\uff0c\u5185\u7701\u662f\u5728\u8fd0\u884c\u65f6\u786e\u5b9a\u5bf9\u8c61\u7c7b\u578b\u7684\u80fd\u529b\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u5217\u51fa\u4e86\u5e38\u89c4\u5bf9\u8c61\u6ca1\u6709\u800c\u51fd\u6570\u6709\u7684\u5c5e\u6027\u3002 class C: pass obj = C() def func(): pass sorted(set(dir(obj)) - set(dir(func))) # ['__weakref__'] sorted(set(dir(func)) - set(dir(obj))) # ['__annotations__', '__call__', '__closure__', '__code__', '__defaults__', '__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__'] \u4e0b\u8868\u603b\u7ed3\u4e86\u7528\u6237\u5b9a\u4e49\u7684\u51fd\u6570\u7684\u5c5e\u6027\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u6f14\u793a\u4e86\u5728\u6307\u5b9a\u957f\u5ea6\u9644\u8fd1\u622a\u65ad\u5b57\u7b26\u4e32\u7684\u51fd\u6570\uff0c\u4ee5\u53ca\u63d0\u53d6\u5173\u4e8e\u51fd\u6570\u53c2\u6570\u7684\u4fe1\u606f\u7684\u65b9\u6cd5\u3002 \u53c2\u6570\u540d\u79f0\u5728 __code__.co_varnames \u4e2d\uff0c\u4f46\u8fd9\u91cc\u9762\u4e5f\u5305\u542b\u51fd\u6570\u5b9a\u4e49\u4f53\u4e2d\u521b\u5efa\u7684\u5c40\u90e8\u53d8\u91cf\u3002\u56e0\u6b64\uff0c\u53c2\u6570\u540d\u79f0\u662f\u524d N \u4e2a\u5b57\u7b26\u4e32\uff0c N \u7684\u503c\u7531 __code__.co_argcount \u786e\u5b9a\uff0c\u4f8b\u5b50\u91cc\u9762N\u662f2\uff0c\u5373\u53c2\u6570\u540d\u79f0\u662f text \u548c max_len \uff0c\u5c40\u90e8\u53d8\u91cf\u662f end \u3001 space_before \u3001 space_after \u3002 def clip(text, max_len=80): \"\"\" Get sub-string by the first blank before or after specified position. rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1. \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip() clip('This is the string', max_len=10) # 'This is' clip.__defaults__ # (80,) clip.__code__ # <code object clip at 0x7f1e04a5c8a0, file \"<stdin>\", line 1> clip.__code__.co_varnames # ('text', 'max_len', 'end', 'space_before', 'space_after') clip.__code__.co_argcount # 2 clip.__doc__ # '\\n Get sub-string by the first blank before or after specified position.\\n rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1.\\n ' \u4e0a\u4f8b\u4e2d\uff0c\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u53ea\u80fd\u901a\u8fc7\u5b83\u4eec\u5728 __defaults__ \u5143\u7ec4\u4e2d\u7684\u4f4d\u7f6e\u786e\u5b9a\uff0c\u56e0\u6b64\u8981\u4ece\u540e\u5411\u524d\u626b\u63cf\u624d\u80fd\u628a\u53c2\u6570\u548c\u9ed8\u8ba4\u503c\u5bf9\u5e94\u8d77\u6765\uff0c\u6709\u4e9b\u4e0d\u5408\u7406\u3002\u5f15\u5165 inspect \u6a21\u5757\u540e\uff0c\u4e0a\u9762\u7684\u64cd\u4f5c\u5c31\u66f4\u5bb9\u6613\u4e86\u3002 inspect.signature \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a inspect.Signature \u5bf9\u8c61\uff0c\u5b83\u6709\u4e00\u4e2a parameters \u5c5e\u6027\uff0c\u8fd9\u662f\u4e00\u4e2a\u6709\u5e8f\u6620\u5c04\uff0c\u628a\u53c2\u6570\u540d\u548c inspect.Parameter \u5bf9\u8c61\u5bf9\u5e94\u8d77\u6765\u3002\u5404\u4e2a Parameter \u5c5e\u6027\u4e5f\u6709\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u4f8b\u5982 name \u3001 default \u548c kind \u3002 from inspect import signature sig = signature(clip) type(sig) # <class 'inspect.Signature'> print(sig) # (text, max_len=80) print(str(sig)) # (text, max_len=80) for name, param in sig.parameters.items(): print(f'{param.kind} : {name} = {param.default}') # 1 : text = <class 'inspect._empty'> # 1 : max_len = 80 \u51fd\u6570\u6ce8\u89e3 Python 3 \u63d0\u4f9b\u4e86\u4e00\u79cd\u53e5\u6cd5\uff0c\u7528\u4e8e\u4e3a\u51fd\u6570\u58f0\u660e\u4e2d\u7684\u53c2\u6570\u548c\u8fd4\u56de\u503c\u9644\u52a0\u5143\u6570\u636e\u3002\u5bf9\u4e0a\u4f8b\u6dfb\u52a0\u6ce8\u89e3\u540e\u5982\u4e0b\u6240\u793a\uff0c\u4e8c\u8005\u552f\u4e00\u7684\u533a\u522b\u5728\u7b2c\u4e00\u884c\u3002 \u51fd\u6570\u58f0\u660e\u4e2d\u7684\u5404\u4e2a\u53c2\u6570\u53ef\u4ee5\u5728:\u4e4b\u540e\u589e\u52a0\u6ce8\u89e3\u8868\u8fbe\u5f0f\u3002 \u5982\u679c\u53c2\u6570\u6709\u9ed8\u8ba4\u503c\uff0c\u6ce8\u89e3\u653e\u5728\u53c2\u6570\u540d\u548c = \u53f7\u4e4b\u95f4\u3002 \u5982\u679c\u60f3\u6ce8\u89e3\u8fd4\u56de\u503c\uff0c\u5728)\u548c\u51fd\u6570\u58f0\u660e\u672b\u5c3e\u7684 : \u4e4b\u95f4\u6dfb\u52a0 -> \u548c\u4e00\u4e2a\u8868\u8fbe\u5f0f\u3002\u90a3\u4e2a\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f\u4efb\u4f55\u7c7b\u578b\u3002 \u6ce8\u89e3\u4e2d\u6700\u5e38\u7528\u7684\u7c7b\u578b\u662f\u7c7b\uff08\u5982 str \u6216 int \uff09\u548c\u5b57\u7b26\u4e32\uff08\u5982'int > 0'\uff09\u3002\u5728\u4e0b\u4f8b\u4e2d\uff0cmax_len\u53c2\u6570\u7684\u6ce8\u89e3\u7528\u7684\u662f\u5b57\u7b26\u4e32\u3002 \u6ce8\u89e3\u4e0d\u4f1a\u505a\u4efb\u4f55\u5904\u7406\uff0c\u53ea\u662f\u5b58\u50a8\u5728\u51fd\u6570\u7684 __annotations__ \u5c5e\u6027\uff08\u4e00\u4e2a\u5b57\u5178\uff09\u4e2d\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u6ce8\u89e3\u5bf9Python\u89e3\u91ca\u5668\u6ca1\u6709\u4efb\u4f55\u610f\u4e49\u3002 \u6ce8\u89e3\u53ea\u662f\u5143\u6570\u636e \uff0c\u53ef\u4ee5\u4f9bIDE\u3001\u6846\u67b6\u548c\u88c5\u9970\u5668\u7b49\u5de5\u5177\u4f7f\u7528\u3002 return \u952e\u4fdd\u5b58\u7684\u662f\u8fd4\u56de\u503c\u6ce8\u89e3\uff0c\u5373\u4e0b\u4f8b\u4e2d\u51fd\u6570\u58f0\u660e\u91cc\u4ee5 -> \u6807\u8bb0\u7684\u90e8\u5206\u3002 def clip(text:str, max_len:'int > 0'=80) -> str: \"\"\" Get sub-string by the first blank before or after specified position. rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1. \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip() clip('This is the string', max_len=10) # 'This is' clip.__annotations__ # {'text': <class 'str'>, 'max_len': 'int > 0', 'return': <class 'str'>} signature \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a Signature \u5bf9\u8c61\uff0c\u5b83\u6709\u4e00\u4e2a return_annotation \u5c5e\u6027\u548c\u4e00\u4e2a parameters \u5c5e\u6027\uff0c\u540e\u8005\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u628a\u53c2\u6570\u540d\u6620\u5c04\u5230 Parameter \u5bf9\u8c61\u4e0a\u3002\u6bcf\u4e2a Parameter \u5bf9\u8c61\u81ea\u5df1\u4e5f\u6709 annotation \u5c5e\u6027\u3002 from inspect import signature sig = signature(clip) print(sig.return_annotation) # <class 'str'> for param in sig.parameters.values(): note = repr(param.annotation).ljust(13) print(f'{note} : {param.name} = {param.default}') # <class 'str'> : text = <class 'inspect._empty'> # 'int > 0' : max_len = 80","title":"Python\u7684\u9762\u5411\u5bf9\u8c61\u6982\u5ff5"},{"location":"python/Foundation/ch04/#python","text":"\u7c7b(class)\u628a\u6570\u636e\u4e0e\u529f\u80fd\u7ed1\u5b9a\u5728\u4e00\u8d77\u3002\u521b\u5efa\u65b0\u7c7b\u5c31\u662f\u521b\u5efa\u65b0\u7684\u5bf9\u8c61\u7c7b\u578b\uff08type of object\uff09\uff0c\u4ece\u800c\u521b\u5efa\u8be5\u7c7b\u578b\u7684\u65b0\u5b9e\u4f8b\uff08instances\uff09\u3002 \u7c7b\u5b9e\u4f8b\u5177\u6709\u591a\u79cd\u4fdd\u6301\u81ea\u8eab\u72b6\u6001\u7684\u5c5e\u6027\uff08attributes\uff09\u3002 \u7c7b\u5b9e\u4f8b\u8fd8\u652f\u6301\uff08\u7531\u7c7b\u5b9a\u4e49\u7684\uff09\u4fee\u6539\u81ea\u8eab\u72b6\u6001\u7684\u65b9\u6cd5\uff08methods\uff09\u3002 Python\u7684\u7c7b\u652f\u6301\u6240\u6709\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u7684\u6807\u51c6\u7279\u6027\uff1a \u7c7b\u7ee7\u627f\uff08class inheritance\uff09\u673a\u5236\u652f\u6301\u591a\u4e2a\u57fa\u7c7b\uff08base classes\uff09\uff1b \u6d3e\u751f\u7c7b\uff08derived class\uff09\u53ef\u4ee5\u8986\u76d6\u57fa\u7c7b\u7684\u4efb\u4f55\u65b9\u6cd5\uff08methods\uff09\uff1b \u7c7b\u7684\u65b9\u6cd5\u53ef\u4ee5\u8c03\u7528\u57fa\u7c7b\u4e2d\u76f8\u540c\u540d\u79f0\u7684\u65b9\u6cd5 \u5bf9\u8c61\u53ef\u4ee5\u5305\u542b\u4efb\u610f\u6570\u91cf\u548c\u7c7b\u578b\u7684\u6570\u636e\u3002 \u7c7b\uff08class\uff09\u548c\u6a21\u5757\uff08module\uff09\u90fd\u62e5\u6709\u52a8\u6001\u7279\u6027\uff08dynamic nature\uff09\uff1a\u5728\u8fd0\u884c\u65f6\u521b\u5efa\uff0c\u521b\u5efa\u540e\u4e5f\u53ef\u4ee5\u4fee\u6539\u3002","title":"Python\u7684\u9762\u5411\u5bf9\u8c61\u6982\u5ff5"},{"location":"python/Foundation/ch04/#namesobjects","text":"\u5bf9\u8c61\u4e4b\u95f4\u76f8\u4e92\u72ec\u7acb\uff0c\u591a\u4e2a\u540d\u79f0\uff08names\uff09\uff08\u5728\u591a\u4e2a\u4f5c\u7528\u57df\u5185\uff09\u53ef\u4ee5\u7ed1\u5b9a\u5230\u540c\u4e00\u4e2a\u5bf9\u8c61\u3002 \u5176\u4ed6\u8bed\u8a00\u79f0\u4e4b\u4e3a\u522b\u540d\uff08alias\uff09\u3002 \u522b\u540d\u5728\u67d0\u4e9b\u65b9\u9762\u5c31\u50cf\u6307\u9488\u3002\u4f8b\u5982\uff0c\u4f20\u9012\u5bf9\u8c61\u7684\u4ee3\u4ef7\u5f88\u5c0f\uff0c\u56e0\u4e3a\u5b9e\u73b0\u53ea\u4f20\u9012\u4e00\u4e2a\u6307\u9488\uff1b\u5982\u679c\u51fd\u6570\u4fee\u6539\u4e86\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u7684\u5bf9\u8c61\uff0c\u8c03\u7528\u8005\u5c31\u53ef\u4ee5\u770b\u5230\u66f4\u6539\u3002","title":"\u540d\u79f0Names\u548c\u5bf9\u8c61Objects"},{"location":"python/Foundation/ch04/#scopesnamespaces","text":"\u547d\u540d\u7a7a\u95f4\uff08namespace\uff09 \u662f\u4e00\u4e2a\u4ece\u540d\u5b57\u5230\u5bf9\u8c61\u7684\u6620\u5c04\u3002 \u5f53\u524d\u5927\u90e8\u5206\u547d\u540d\u7a7a\u95f4\u90fd\u7531 Python \u5b57\u5178\u5b9e\u73b0\u3002 \u4e0b\u9762\u662f\u51e0\u4e2a\u547d\u540d\u7a7a\u95f4\u7684\u4f8b\u5b50\uff1a \u5b58\u653e\u5185\u7f6e\u51fd\u6570\u7684\u96c6\u5408\uff08\u5305\u542b abs() \u8fd9\u6837\u7684\u51fd\u6570\uff0c\u548c\u5185\u5efa\u7684\u5f02\u5e38\u7b49\uff09\uff1b \u6a21\u5757\u4e2d\u7684\u5168\u5c40\u540d\u79f0\uff1b \u51fd\u6570\u8c03\u7528\u4e2d\u7684\u5c40\u90e8\u540d\u79f0\uff1b \u4ece\u67d0\u79cd\u610f\u4e49\u4e0a\u8bf4\uff0c \u5bf9\u8c61\u7684\u5c5e\u6027\u96c6\u5408\uff08the set of attributes of an object\uff09\u4e5f\u662f\u4e00\u79cd\u547d\u540d\u7a7a\u95f4\u7684\u5f62\u5f0f \u3002 \u5173\u4e8e\u547d\u540d\u7a7a\u95f4\u7684\u91cd\u8981\u4e00\u70b9\u662f\uff0c\u4e0d\u540c\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u540d\u79f0\u4e4b\u95f4\u7edd\u5bf9\u6ca1\u6709\u5173\u7cfb\uff1b \u4f8b\u5982\uff0c\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u6a21\u5757\u4e2d\u90fd\u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a maximize \u51fd\u6570\u800c\u4e0d\u4f1a\u4ea7\u751f\u6df7\u6dc6\uff0c\u4f46\u5728\u8c03\u7528 maximize \u51fd\u6570\u65f6\u5fc5\u987b\u5fc5\u987b\u5728\u5176\u524d\u9762\u52a0\u4e0a\u6a21\u5757\u540d\u79f0\u3002 \u4efb\u4f55\u8ddf\u5728\u4e00\u4e2a\u70b9\u53f7\u4e4b\u540e\u7684\u540d\u79f0\u90fd\u79f0\u4e3a \u5c5e\u6027\uff08attribute\uff09 \u3002\u4f8b\u5982\uff0c\u5728\u8868\u8fbe\u5f0f z.real \u4e2d\uff0c real \u662f\u5bf9\u8c61 z \u7684\u4e00\u4e2a\u5c5e\u6027\u3002 \u6309\u4e25\u683c\u7684\u8bf4\u6cd5\uff0c \u5bf9\u6a21\u5757\uff08module\uff09\u4e2d\u7684\u540d\u79f0\u7684\u5f15\u7528\uff08reference\uff09\u90fd\u5c5e\u4e8e\u5c5e\u6027\u5f15\u7528\uff08attribute reference\uff09 \uff1a \u5728\u8868\u8fbe\u5f0f modname.funcname \u4e2d\uff0c modname \u662f\u4e00\u4e2a\u6a21\u5757\u5bf9\u8c61\uff08module object\uff09\u800c funcname \u662f\u5b83\u7684\u4e00\u4e2a\u5c5e\u6027\u3002 \u5728\u6b64\u60c5\u51b5\u4e0b\u5728\u6a21\u5757\u7684\u5c5e\u6027\uff08module\u2019s attribute\uff09\u548c\u6a21\u5757\u4e2d\u5b9a\u4e49\u7684\u5168\u5c40\u540d\u79f0\u4e4b\u95f4\u6b63\u597d\u5b58\u5728\u4e00\u4e2a\u76f4\u89c2\u7684\u6620\u5c04\uff1a\u5b83\u4eec\u5171\u4eab\u76f8\u540c\u7684\u547d\u540d\u7a7a\u95f4\u3002 \u4f46\u5b58\u5728\u4e00\u4e2a\u4f8b\u5916\u3002 \u6a21\u5757\u5bf9\u8c61\u6709\u4e00\u4e2a\u53ea\u8bfb\u5c5e\u6027 __dict__ \uff0c\u5b83\u8fd4\u56de\u7528\u4e8e\u5b9e\u73b0\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u7684\u5b57\u5178\uff1b __dict__ \u662f\u5c5e\u6027\u4f46\u4e0d\u662f\u5168\u5c40\u540d\u79f0\u3002 \u4f7f\u7528\u8fd9\u4e2a\u5c06\u8fdd\u53cd\u547d\u540d\u7a7a\u95f4\u5b9e\u73b0\u7684\u62bd\u8c61\uff0c\u5e94\u5f53\u4ec5\u88ab\u7528\u4e8e\u4e8b\u540e\u8c03\u8bd5\u5668\u4e4b\u7c7b\u7684\u573a\u5408\u3002 \u5c5e\u6027\uff08attribute\uff09 \u53ef\u4ee5\u662f\u53ea\u8bfb\u6216\u8005\u53ef\u5199\u7684\uff0c\u6240\u4ee5\u53ef\u4ee5\u5bf9\u5c5e\u6027\u8fdb\u884c\u8d4b\u503c\uff0c\u4f8b\u5982 modname.the_answer = 42 \u3002 \u5220\u9664\u5c5e\u6027\u53ef\u4ee5\u7528del\u8bed\u53e5\uff0c\u4f8b\u5982\uff0c del modname.the_answer \u5c06\u4f1a\u4ece\u540d\u4e3a modname \u7684\u5bf9\u8c61\u4e2d\u79fb\u9664 the_answer \u5c5e\u6027\u3002 \u547d\u540d\u7a7a\u95f4\u5728\u4e0d\u540c\u65f6\u523b\u88ab\u521b\u5efa\uff0c\u62e5\u6709\u4e0d\u540c\u7684\u751f\u5b58\u671f\uff08lifetimes\uff09\u3002\u5305\u542b\u5185\u7f6e\u540d\u79f0\uff08built-in names\uff09\u7684\u547d\u540d\u7a7a\u95f4\u662f\u5728Python\u89e3\u91ca\u5668\u542f\u52a8\u65f6\u521b\u5efa\u7684\uff0c\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u5220\u9664\u3002 \u6a21\u5757\u7684\u5168\u5c40\u547d\u540d\u7a7a\u95f4\uff08global namespace\uff09\u5728\u6a21\u5757\u5b9a\u4e49\u88ab\u8bfb\u5165\u65f6\u521b\u5efa\uff1b\u901a\u5e38\uff0c\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u4e5f\u4f1a\u6301\u7eed\u5230\u89e3\u91ca\u5668\u9000\u51fa\u3002 \u88ab\u89e3\u91ca\u5668\u7684\u9876\u5c42\u8c03\u7528\uff08top-level invocation\uff09\u6267\u884c\u7684\u8bed\u53e5\uff0c\u4ece\u4e00\u4e2a\u811a\u672c\u6587\u4ef6\u8bfb\u53d6\u6216\u4ea4\u4e92\u5f0f\u5730\u8bfb\u53d6\uff0c\u88ab\u8ba4\u4e3a\u662f __main__ \u6a21\u5757\u8c03\u7528\u7684\u4e00\u90e8\u5206\uff0c\u56e0\u6b64\u5b83\u4eec\u62e5\u6709\u81ea\u5df1\u7684\u5168\u5c40\u547d\u540d\u7a7a\u95f4\u3002 \u5185\u7f6e\u540d\u79f0\uff08built-in names\uff09\u5b9e\u9645\u4e0a\u4e5f\u5b58\u5728\u4e8e\u4e00\u4e2a\u6a21\u5757\u4e2d\uff0c\u8fd9\u4e2a\u6a21\u5757\u88ab\u79f0\u4f5c builtins \u3002 \u4e00\u4e2a\u51fd\u6570\u7684\u672c\u5730\u547d\u540d\u7a7a\u95f4\uff08local namespace\uff09\u5728\u8fd9\u4e2a\u51fd\u6570\u88ab\u8c03\u7528\u65f6\u521b\u5efa\uff0c\u5e76\u5728\u51fd\u6570\u8fd4\u56de\u6216\u629b\u51fa\u4e00\u4e2a\u65e0\u6cd5\u5728\u8be5\u51fd\u6570\u5185\u90e8\u5904\u7406\u7684\u9519\u8bef\u65f6\u88ab\u5220\u9664\u3002 \u6bcf\u6b21\u9012\u5f52\u8c03\u7528\uff08recursive invocations\uff09\u90fd\u4f1a\u6709\u5b83\u81ea\u5df1\u7684\u672c\u5730\u547d\u540d\u7a7a\u95f4\u3002 \u4e00\u4e2a \u4f5c\u7528\u57df\uff08scope\uff09 \u662f\u4e00\u4e2a\u547d\u540d\u7a7a\u95f4\u53ef\u76f4\u63a5\u8bbf\u95ee\uff08directly accessible\uff09\u7684Python\u7a0b\u5e8f\u7684\u4ee3\u7801\u533a\u57df\u3002 \u8fd9\u91cc\u7684 \u201c\u53ef\u76f4\u63a5\u8bbf\u95ee\u201d \u610f\u5473\u7740\u4e0d\u52a0\u4efb\u4f55\u9650\u5b9a\u7684\u540d\u79f0\u5f15\u7528\u4f1a\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u8fdb\u884c\u67e5\u627e\u3002 \u867d\u7136\u4f5c\u7528\u57df\u662f\u9759\u6001\u5730\u786e\u5b9a\u7684\uff0c\u4f46\u5b83\u4eec\u4f1a\u88ab\u52a8\u6001\u5730\u4f7f\u7528\u3002 \u5728\u4ee3\u7801\u6267\u884c\u671f\u95f4\u7684\u4efb\u4f55\u65f6\u523b\uff0c\u4f1a\u67093\u62164\u4e2a\u7684\u5d4c\u5957\u4f5c\u7528\u57df\u4f9b\u547d\u540d\u7a7a\u95f4\u76f4\u63a5\u8bbf\u95ee: \u6700\u5148\u641c\u7d22\u7684\u6700\u5185\u90e8\u4f5c\u7528\u57df\u5305\u542b\u5c40\u90e8\u540d\u79f0 \u4ece\u6700\u8fd1\u7684\u5c01\u95ed\u4f5c\u7528\u57df\u5f00\u59cb\u641c\u7d22\u7684\u4efb\u4f55\u5c01\u95ed\u51fd\u6570\u7684\u4f5c\u7528\u57df\u5305\u542b\u975e\u5c40\u90e8\u540d\u79f0\uff0c\u4e5f\u5305\u62ec\u975e\u5168\u5c40\u540d\u79f0 \u5012\u6570\u7b2c\u4e8c\u4e2a\u4f5c\u7528\u57df\u5305\u542b\u5f53\u524d\u6a21\u5757\u7684\u5168\u5c40\u540d\u79f0 \u6700\u5916\u9762\u7684\u4f5c\u7528\u57df\uff08\u6700\u540e\u641c\u7d22\uff09\u662f\u5305\u542b\u5185\u7f6e\u540d\u79f0\u7684\u547d\u540d\u7a7a\u95f4 \u5982\u679c\u4e00\u4e2a\u540d\u79f0\u88ab\u58f0\u660e\u4e3a\u5168\u5c40\u53d8\u91cf\uff0c\u5219\u6240\u6709\u5f15\u7528\u548c\u8d4b\u503c\u5c06\u76f4\u63a5\u6307\u5411\u8be5\u6a21\u5757\u5168\u5c40\u540d\u79f0\u6240\u5728\u7684\u4e2d\u95f4\u4f5c\u7528\u57df\u3002 \u5982\u679c\u8981\u91cd\u65b0\u7ed1\u5b9a\u5728\u6700\u5185\u5c42\u4f5c\u7528\u57df\u4ee5\u5916\u7684\u53d8\u91cf\uff0c\u53ef\u4ee5\u4f7f\u7528 nonlocal \u8bed\u53e5\u58f0\u660e\u4e3a\u975e\u672c\u5730\u53d8\u91cf\u3002 \u5982\u679c\u6ca1\u6709\u88ab\u58f0\u660e\u4e3a\u975e\u672c\u5730\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u5c06\u662f\u53ea\u8bfb\u7684\u3002\u7ed9\u8fd9\u6837\u7684\u53d8\u91cf\u8d4b\u65b0\u503c\u53ea\u4f1a\u5728\u6700\u5185\u5c42\u4f5c\u7528\u57df\u4e2d\u521b\u5efa\u4e00\u4e2a \u65b0\u7684 \u5c40\u90e8\u53d8\u91cf\uff0c\u800c\u540c\u540d\u7684\u5916\u90e8\u5168\u5c40\u53d8\u91cf\u5c06\u4fdd\u6301\u4e0d\u53d8\u3002 \u901a\u5e38\uff0c\u5f53\u524d\u5c40\u90e8\u4f5c\u7528\u57df\uff08local scope\uff09\u5c06\u5f15\u7528\u5f53\u524d\u51fd\u6570\u4f5c\u7528\u57df\u7684\u540d\u79f0\uff08local name\uff09\u3002 \u5728\u51fd\u6570\u4f5c\u7528\u57df\u4ee5\u5916\uff0c\u5f53\u524d\u5c40\u90e8\u4f5c\u7528\u57df\u5c06\u5f15\u7528\u4e0e\u5168\u5c40\u4f5c\u7528\u57df\u76f8\u4e00\u81f4\u7684\u547d\u540d\u7a7a\u95f4\uff1a\u6a21\u5757\u7684\u547d\u540d\u7a7a\u95f4\uff08the module\u2019s namespace\uff09\u3002 \u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff0c\u662f\u5728\u672c\u5730\u5c40\u90e8\u547d\u540d\u7a7a\u95f4\u5185\u5efa\u4e00\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\u3002 \u5728\u4e00\u4e2a\u6a21\u5757\uff08module \uff09\u5185\u5b9a\u4e49\u7684\u51fd\u6570\u7684\u4f5c\u7528\u57df\u5c31\u662f\u8be5\u6a21\u5757\u7684\u547d\u540d\u7a7a\u95f4\uff0c\u65e0\u8bba\u8be5\u51fd\u6570\u4ece\u4ec0\u4e48\u5730\u65b9\u6216\u4ee5\u4ec0\u4e48\u522b\u540d\u88ab\u8c03\u7528\u3002 \u53e6\u4e00\u65b9\u9762\uff0c\u5b9e\u9645\u7684\u540d\u79f0\u641c\u7d22\u662f\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u5b8c\u6210\u7684\u3002 \u4f46\u662f\uff0cPython\u6b63\u5728\u671d\u7740\u201c\u7f16\u8bd1\u65f6\u9759\u6001\u540d\u79f0\u89e3\u6790\u201d\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u56e0\u6b64\u4e0d\u8981\u8fc7\u4e8e\u4f9d\u8d56\u52a8\u6001\u540d\u79f0\u89e3\u6790\uff01\u4e8b\u5b9e\u4e0a\uff0c\u5c40\u90e8\u53d8\u91cf\u5df2\u7ecf\u662f\u88ab\u9759\u6001\u786e\u5b9a\u4e86\u3002 \u5982\u679c\u4e0d\u5b58\u5728\u751f\u6548\u7684 global \u6216 nonlocal \u8bed\u53e5\uff0c\u5219\u5bf9\u540d\u79f0\u7684\u8d4b\u503c\u603b\u662f\u4f1a\u8fdb\u5165\u6700\u5185\u5c42\u4f5c\u7528\u57df\u3002\u8d4b\u503c\u4e0d\u4f1a\u590d\u5236\u6570\u636e\uff0c\u662f\u5c06\u540d\u79f0\u7ed1\u5b9a\u5230\u5bf9\u8c61\u3002 \u5220\u9664\u4e5f\u662f\u5982\u6b64\uff1a\u8bed\u53e5 del x \u4f1a\u4ece\u5c40\u90e8\u4f5c\u7528\u57df\u6240\u5f15\u7528\u7684\u547d\u540d\u7a7a\u95f4\u4e2d\u79fb\u9664\u5bf9 x \u7684\u7ed1\u5b9a\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6240\u6709\u5f15\u5165\u65b0\u540d\u79f0\u7684\u64cd\u4f5c\u90fd\u662f\u4f7f\u7528\u5c40\u90e8\u4f5c\u7528\u57df\u3002\u7279\u522b\u5730\uff0c import \u8bed\u53e5\u548c\u51fd\u6570\u5b9a\u4e49\u4f1a\u5728\u5c40\u90e8\u4f5c\u7528\u57df\u4e2d\u7ed1\u5b9a\u6a21\u5757\u6216\u51fd\u6570\u540d\u79f0\u3002 global \u8bed\u53e5\u53ef\u88ab\u7528\u6765\u8868\u660e\u7279\u5b9a\u53d8\u91cf\u5b58\u5728\u4e8e\u5168\u5c40\u4f5c\u7528\u57df\uff0c\u5e76\u4e14\u5e94\u5f53\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u88ab \u91cd\u65b0 \u7ed1\u5b9a\uff1b nonlocal \u8bed\u53e5\u8868\u660e\u7279\u5b9a\u53d8\u91cf\u751f\u5b58\u4e8e\u5916\u5c42\u4f5c\u7528\u57df\u4e2d\uff0c\u5e76\u4e14\u5e94\u5f53\u5728\u5176\u6240\u5904\u7684\u5916\u5c42\u4f5c\u7528\u57df\u4e2d\u88ab \u91cd\u65b0 \u7ed1\u5b9a\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff1a \u5c40\u90e8\u8d4b\u503c\uff08local assignment\uff0c\u8fd9\u662f\u9ed8\u8ba4\u72b6\u6001\uff09\u4e0d\u4f1a\u6539\u53d8 scope_test \u5bf9 spam \u7684\u7ed1\u5b9a\u3002 nonlocal \u8d4b\u503c\u4f1a\u6539\u53d8 scope_test \u5bf9 spam \u7684\u7ed1\u5b9a\u3002 global \u8d4b\u503c\u4f1a\u6539\u53d8\u6a21\u5757\u5c42\u7ea7\u7684\u7ed1\u5b9a\uff0c\u5373\uff0c global spam \u91cd\u65b0\u7ed1\u5b9a\u4e86spam\u7684\u5168\u5c40\u5b9a\u4e49\uff0c\u4ece spam = \"spam out of func\" \u53d8\u6210\u4e86 spam = \"global spam\" \u3002\u5982\u679c\u6ce8\u91ca\u6389def do_global()\u8fd9\u4e00\u6bb5\u4ee3\u7801\uff0c\u5219 spam = \"spam out of func\" \u8d77\u4f5c\u7528\u3002 spam = \"spam out of func\" def scope_test(): def do_local(): spam = \"local spam\" def do_nonlocal(): nonlocal spam spam = \"nonlocal spam\" def do_global(): global spam spam = \"global spam\" spam = \"test spam\" do_local() print(\"After local assignment:\", spam) do_nonlocal() print(\"After nonlocal assignment:\", spam) do_global() print(\"After global assignment:\", spam) scope_test() print(\"In global scope:\", spam) # \u8fd0\u884c\u7ed3\u679c # scope_test() After local assignment: test spam After nonlocal assignment: nonlocal spam After global assignment: nonlocal spam # print(\"In global scope:\", spam) In global scope: global spam","title":"\u4f5c\u7528\u57dfScopes\u548c\u547d\u540d\u7a7a\u95f4Namespaces"},{"location":"python/Foundation/ch04/#class","text":"","title":"\u7c7bClass"},{"location":"python/Foundation/ch04/#class-definition","text":"\u7c7b\u5b9a\u4e49\u4e0e\u51fd\u6570\u5b9a\u4e49 (def \u8bed\u53e5) \u4e00\u6837\u5fc5\u987b\u88ab\u6267\u884c\u624d\u4f1a\u8d77\u4f5c\u7528\u3002 class ClassName: <statement-1> ... <statement-N> \u5728\u5b9e\u8df5\u4e2d\uff0c\u7c7b\u5b9a\u4e49\u5185\u7684\u8bed\u53e5\u901a\u5e38\u90fd\u662f\u51fd\u6570\u5b9a\u4e49\uff0c\u4f46\u4e5f\u5141\u8bb8\u6709\u5176\u4ed6\u8bed\u53e5\u3002\u5728\u7c7b\u5185\u90e8\u7684\u51fd\u6570\u5b9a\u4e49\u901a\u5e38\u5177\u6709\u4e00\u79cd\u7279\u6709\u5f62\u5f0f\u7684\u53c2\u6570\u5217\u8868\uff0c\u8fd9\u662f\u7ea6\u5b9a\u7684\u65b9\u6cd5\u89c4\u8303\uff08conventions for methods\uff09\u3002 \u7f16\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u8fdb\u5165\u4e00\u4e2a\u7c7b\u7684\u5185\u90e8\uff0c\u5c06\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\uff0c\u4e00\u4e2a\u5c40\u90e8\u4f5c\u7528\u57df\u3002\u56e0\u6b64\uff0c\u6240\u6709\u5bf9\u7c7b\u5185\u90e8\u5c40\u90e8\u53d8\u91cf\u7684\u8d4b\u503c\u90fd\u662f\u5728\u8fd9\u4e2a\u65b0\u7684\u547d\u540d\u7a7a\u95f4\u4e4b\u5185\uff0c\u5305\u62ec\u65b0\u5b9a\u4e49\u7684\u51fd\u6570\u540d\u79f0\u3002 \u5f53\u6b63\u5e38\u79bb\u5f00\u4e00\u4e2a\u7c7b\u65f6\uff0c\u7f16\u8bd1\u8fc7\u7a0b\u5c06\u521b\u5efa\u4e00\u4e2a\u7c7b\u5bf9\u8c61\uff08class object\uff09\uff0c\u5c01\u88c5\u4e86\u7c7b\u5b9a\u4e49\u6240\u521b\u5efa\u7684\u547d\u540d\u7a7a\u95f4\u91cc\u7684\u5185\u5bb9\u3002 \u6700\u521d\u7684\uff08\u5728\u8fdb\u5165\u7c7b\u5b9a\u4e49\u4e4b\u524d\u8d77\u4f5c\u7528\u7684\uff09\u5c40\u90e8\u4f5c\u7528\u57df\u5c06\u91cd\u65b0\u751f\u6548\uff0c\u7c7b\u5bf9\u8c61\uff08class object\uff09\u5c06\u5728\u8fd9\u91cc\u88ab\u7ed1\u5b9a\u5230\u7c7b\u5b9a\u4e49\u5934\u90e8\u6240\u58f0\u660e\u7684\u7c7b\u540d\u79f0 (\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\u662f ClassName )\u3002","title":"\u7c7b\u5b9a\u4e49 Class Definition"},{"location":"python/Foundation/ch04/#class-objects","text":"\u7c7b\u5bf9\u8c61\u652f\u6301\u4e24\u79cd\u64cd\u4f5c\uff1a\u5c5e\u6027\u5f15\u7528\uff08attribute references\uff09\u548c\u5b9e\u4f8b\u5316\uff08instantiation\uff09\u3002 \u5c5e\u6027\u5f15\u7528\uff08attribute references\uff09 \u4f7f\u7528Python\u4e2d\u5c5e\u6027\u5f15\u7528\u7684\u6807\u51c6\u8bed\u6cd5: obj.name \u3002 \u5b58\u5728\u4e8e\u7c7b\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u6240\u6709\u540d\u79f0\uff0c\u7c7b\u5bf9\u8c61\u88ab\u521b\u5efa\u65f6\u540c\u65f6\u88ab\u521b\u5efa\u4e86\uff0c\u8fd9\u4e9b\u5c31\u662f\u6709\u6548\u7684\u5c5e\u6027\u540d\u79f0\u3002\u56e0\u6b64\uff0c\u5982\u679c\u7c7b\u5b9a\u4e49\u662f\u5982\u4e0b\u6240\u793a\uff0c\u90a3\u4e48 MyClass.i \u548c MyClass.f \u5c31\u662f\u6709\u6548\u7684\u5c5e\u6027\u5f15\u7528\uff0c\u5c06\u5206\u522b\u8fd4\u56de\u4e00\u4e2a\u6574\u6570\u548c\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u3002 \u7c7b\u5c5e\u6027\u4e5f\u53ef\u4ee5\u88ab\u8d4b\u503c\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u8d4b\u503c\u6765\u66f4\u6539 MyClass.i \u7684\u503c\u3002 __doc__ \u4e5f\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5c5e\u6027\uff0c\u5c06\u8fd4\u56de\u6240\u5c5e\u7c7b\u7684\u6587\u6863\u5b57\u7b26\u4e32: \"A simple example class\"\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' print(MyClass.i) # 12345 print(MyClass.__doc__) # A simple example class MyClass.i = 10 print(MyClass.i) # 10 \u7c7b\u7684 \u5b9e\u4f8b\u5316\uff08instantiation\uff09 \u4f7f\u7528\u51fd\u6570\u8868\u793a\u6cd5\u3002 \u53ef\u4ee5\u628a\u7c7b\u5bf9\u8c61\uff08class object\uff09\u770b\u4f5c\u662f\u4e00\u4e2a\u4e0d\u5e26\u53c2\u6570\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u8fd4\u56de\u4e86\u8be5\u7c7b\u7684\u4e00\u4e2a\u65b0\u5b9e\u4f8b\u3002 \u5728\u4e0b\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c x = MyClass() \u521b\u5efa\u4e86 MyClass() \u8fd9\u4e2a\u7c7b\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5e76\u8d4b\u503c\u7ed9\u5c40\u90e8\u53d8\u91cf x \u3002 \u5b9e\u4f8b\u5316\u64cd\u4f5c\uff08\u8c03\u7528\u7c7b\u5bf9\u8c61\uff09\u4f1a\u521b\u5efa\u4e00\u4e2a\u7a7a\u5bf9\u8c61\u3002\u8bb8\u591a\u7c7b\u4f1a\u521b\u5efa\u5e26\u6709\u7279\u5b9a\u521d\u59cb\u72b6\u6001\u7684\u81ea\u5b9a\u4e49\u5b9e\u4f8b\u3002\u4e3a\u6b64\u7c7b\u5b9a\u4e49\u4e2d\u9700\u8981\u5305\u542b\u4e00\u4e2a\u540d\u4e3a __init__() \u7684\u7279\u6b8a\u65b9\u6cd5\u3002 \u5f53\u4e00\u4e2a\u7c7b\u5b9a\u4e49\u4e86 __init__() \u65b9\u6cd5\u65f6\uff0c\u7c7b\u7684\u5b9e\u4f8b\u5316\u64cd\u4f5c\u4f1a\u81ea\u52a8\u4e3a\u65b0\u521b\u5efa\u7684\u7c7b\u5b9e\u4f8b\u8c03\u7528 __init__() \u3002 \u66f4\u65b0\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u6ce8\u610f __dict__ \u4e24\u6b21\u8fd4\u56de\u7684\u4e0d\u540c\u7684\u5b57\u5178\u3002\u590d\u4e60\u4e00\u4e0b\uff0c\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u63d0\u5230\uff0c __dict__ \u662f\u5c5e\u6027\u4f46\u4e0d\u662f\u5168\u5c40\u540d\u79f0\uff0c\u8fd4\u56de\u7528\u4e8e\u5b9e\u73b0\u6a21\u5757\u547d\u540d\u7a7a\u95f4\u7684\u5b57\u5178\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() print(x.__dict__) # {'data': []} x.i = 10 print(x.__dict__) # {'data': [], 'i': 10} __init__() \u65b9\u6cd5\u53ef\u4ee5\u6709\u989d\u5916\u7684\u53c2\u6570\u8f93\u5165\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7c7b\u5b9e\u4f8b\u5316\u7684\u53c2\u6570\u5c06\u88ab\u4f20\u9012\u7ed9 __init__() \u3002 \u5982\u4e0b\u4f8b: class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpart x = Complex(3.0, -4.5) print(x.r, x.i) # 3.0 -4.5","title":"\u7c7b\u5bf9\u8c61 Class Objects"},{"location":"python/Foundation/ch04/#instance-objects","text":"\u5bf9\u5b9e\u4f8b\u5bf9\u8c61\u552f\u4e00\u7684\u64cd\u4f5c\u662f\u5c5e\u6027\u5f15\u7528\u3002\u6709\u4e24\u79cd\u6709\u6548\u7684\u5c5e\u6027\u540d\u79f0\uff1a\u6570\u636e\u5c5e\u6027\uff08data attributes\uff09\u548c\u65b9\u6cd5\uff08methods\uff09\u3002 \u6570\u636e\u5c5e\u6027\uff08data attributes\uff09 \u7c7b\u4f3c\u4e8e\u5b9e\u4f8b\u53d8\u91cf\uff0c\u6570\u636e\u5c5e\u6027\u4e0d\u9700\u8981\u58f0\u660e\u3002\u50cf\u5c40\u90e8\u53d8\u91cf\u4e00\u6837\uff0c\u6570\u636e\u5c5e\u6027\u5c06\u5728\u7b2c\u4e00\u6b21\u88ab\u8d4b\u503c\u65f6\u4ea7\u751f\u3002 \u4f8b\u5982\uff0c\u5982\u679c x \u662f\u4e0a\u9762\u521b\u5efa\u7684 MyClass \u7684\u5b9e\u4f8b\uff0c\u5219\u4ee5\u4e0b\u4ee3\u7801\u6bb5\u5c06\u6253\u5370\u6570\u503c 16 \uff0c\u4e14\u6ca1\u6709\u7559\u4e0b\u5173\u4e8e x.counter \u7684\u75d5\u8ff9\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() x.counter = 1 while x.counter < 10: x.counter = x.counter * 2 print(x.counter) # 16 print(x.__dict__) # {'data': [], 'counter': 16} del x.counter print(x.__dict__) # {'data': []} \u53e6\u4e00\u7c7b\u5b9e\u4f8b\u5c5e\u6027\u5f15\u7528\u79f0\u4e3a \u65b9\u6cd5\uff08methods\uff09 \u3002 \u65b9\u6cd5\u662f\u96b6\u5c5e\u4e8e\u5bf9\u8c61\u7684 \u51fd\u6570 \u3002 \u5728Python\u4e2d\uff0c\u65b9\u6cd5\u8fd9\u4e2a\u672f\u8bed\u5e76\u4e0d\u662f\u7c7b\u5b9e\u4f8b\u6240\u7279\u6709\u7684\uff0c\u5176\u4ed6\u5bf9\u8c61\u4e5f\u53ef\u4ee5\u6709\u65b9\u6cd5\u3002 \u4f8b\u5982\uff0c\u5217\u8868\u5bf9\u8c61\uff08list objects\uff09\u5177\u6709append, insert, remove, sort\u7b49\u65b9\u6cd5\u3002 \u5728\u4ee5\u4e0b\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u65b9\u6cd5\u4e00\u8bcd\u5c06\u4e13\u6307\u7c7b\u5b9e\u4f8b\u5bf9\u8c61\u7684\u65b9\u6cd5\uff0c\u9664\u975e\u53e6\u5916\u660e\u786e\u8bf4\u660e\u3002 \u5b9e\u4f8b\u5bf9\u8c61\u7684\u6709\u6548\u65b9\u6cd5\u540d\u79f0\u4f9d\u8d56\u4e8e\u5176\u6240\u5c5e\u7684\u7c7b\u3002 \u6839\u636e\u5b9a\u4e49\uff0c\u4e00\u4e2a\u7c7b\u5b9a\u4e49\u4e2d\u6240\u5305\u542b\u7684\u6240\u6709\u51fd\u6570\u5bf9\u8c61\uff08function objects\uff09\u90fd\u79f0\u4e3a\u5c5e\u6027\u3002 \u56e0\u6b64\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c x.f \u662f\u6709\u6548\u7684\u65b9\u6cd5\u5f15\u7528\uff0c\u56e0\u4e3a MyClass.f \u662f\u4e00\u4e2a\u51fd\u6570\uff0c\u800c x.i \u4e0d\u662f\u65b9\u6cd5\uff0c\u56e0\u4e3a MyClass.i \u4e0d\u662f\u51fd\u6570\u3002\u4f46\u662f x.f \u4e0e MyClass.f \u5e76\u4e0d\u662f\u4e00\u56de\u4e8b\uff0c x.f \u662f\u4e00\u4e2a \u65b9\u6cd5\u5bf9\u8c61 \uff0c\u800c MyClass.f \u662f\u4e00\u4e2a \u51fd\u6570\u5bf9\u8c61 \u3002\u5dee\u522b\u5728\u4e8e f() \u662f\u5426\u4e0e\u5b9e\u4f8b\u7ed1\u5b9a\uff0c\u672a\u7ed1\u5b9a\uff0c\u5c31\u662f\u51fd\u6570\uff0c\u7ed1\u5b9a\uff0c\u5c31\u662f\u65b9\u6cd5\u3002 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' def __init__(self): self.data = [] x = MyClass() print(MyClass.f(0)) # hello world print(x.f()) # hello world print(MyClass.f) # <function MyClass.f at 0x7ff9368b3488> print(x.f) # <bound method MyClass.f of <__main__.MyClass object at 0x7ff9368acbe0>> print(type(MyClass.f)) # <class 'function'> print(type(x.f)) # <class 'method'> \u8fd9\u91cc\u505a\u4e2a\u5c0f\u7ed3\uff1a \u51fd\u6570(function)\u662fPython\u4e2d\u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61(callable), \u65b9\u6cd5(method)\u662f\u4e00\u79cd\u7279\u6b8a\u7684\u51fd\u6570\u3002 \u4e00\u4e2a\u53ef\u8c03\u7528\u5bf9\u8c61\u662f\u65b9\u6cd5\u548c\u51fd\u6570\uff0c\u548c\u8fd9\u4e2a\u5bf9\u8c61\u65e0\u5173\uff0c\u4ec5\u548c\u8fd9\u4e2a\u5bf9\u8c61\u662f\u5426\u4e0e\u7c7b\u6216\u5b9e\u4f8b\u7ed1\u5b9a\u6709\u5173\uff08bound method\uff09\u3002 \u9759\u6001\u65b9\u6cd5\u6ca1\u6709\u548c\u4efb\u4f55\u7c7b\u6216\u5b9e\u4f8b\u7ed1\u5b9a\uff0c\u6240\u4ee5 \u9759\u6001\u65b9\u6cd5\u662f\u4e2a\u51fd\u6570 \u3002","title":"\u5b9e\u4f8b\u5bf9\u8c61 Instance Objects"},{"location":"python/Foundation/ch04/#method-objects","text":"\u5728 MyClass \u793a\u4f8b\u4e2d\uff0c x.f() \u662f\u4e00\u4e2a\u65b9\u6cd5\u5bf9\u8c61\uff0c\u88ab\u8c03\u7528\u540e\uff0c\u5c06\u8fd4\u56de\u5b57\u7b26\u4e32 'hello world' \u3002\u53ef\u4ee5\u7acb\u5373\u8c03\u7528\uff0c\u4e5f\u53ef\u4ee5\u4fdd\u5b58\u8d77\u6765\u4ee5\u540e\u518d\u8c03\u7528 xf = x.f \u3002 \u867d\u7136 f() \u7684\u51fd\u6570\u5b9a\u4e49\u6307\u5b9a\u4e86\u4e00\u4e2a\u53c2\u6570\uff0c\u4f46\u4e0a\u9762\u4f8b\u5b50\u4e2d\u8c03\u7528 x.f() \u65f6\u5e76\u6ca1\u6709\u5e26\u53c2\u6570\uff0c\u4e5f\u6ca1\u6709\u5f15\u53d1\u5f02\u5e38\u62a5\u9519\u3002\u539f\u56e0\u5728\u4e8e\uff0c \u65b9\u6cd5(method)\u7684\u7279\u6b8a\u4e4b\u5904\u5c31\u5728\u4e8e\u5b9e\u4f8b\u5bf9\u8c61\u4f1a\u4f5c\u4e3a\u51fd\u6570\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u88ab\u4f20\u5165\u3002 \u8c03\u7528 x.f() \u5176\u5b9e\u5c31\u76f8\u5f53\u4e8e MyClass.f(x) \u3002 \u603b\u4e4b\uff0c\u8c03\u7528\u4e00\u4e2a\u5177\u6709 n \u4e2a\u53c2\u6570\u7684\u65b9\u6cd5(method)\u5c31\u76f8\u5f53\u4e8e\u8c03\u7528\u518d\u591a\u4e00\u4e2a\u53c2\u6570\u7684\u5bf9\u5e94\u51fd\u6570\uff0c\u8fd9\u4e2a\u53c2\u6570\u503c\u4e3a\u65b9\u6cd5\u6240\u5c5e\u5b9e\u4f8b\u5bf9\u8c61\uff0c \u4f4d\u7f6e\u5728\u5176\u4ed6\u53c2\u6570\u4e4b\u524d \u3002 \u5f53\u4e00\u4e2a\u5b9e\u4f8b\u7684\u975e\u6570\u636e\u5c5e\u6027\u88ab\u5f15\u7528\u65f6\uff0c\u5c06\u641c\u7d22\u5b9e\u4f8b\u6240\u5c5e\u7684\u7c7b\u3002 \u5982\u679c\u88ab\u5f15\u7528\u7684\u5c5e\u6027\u540d\u79f0\u662f\u7c7b\u4e2d\u4e00\u4e2a\u6709\u6548\u7684\u51fd\u6570\u5bf9\u8c61\uff0c\u5219\u4f1a\u521b\u5efa\u4e00\u4e2a\u62bd\u8c61\u7684\u5bf9\u8c61\uff0c\u901a\u8fc7\u6253\u5305\uff08parking\uff0c\u5373\u6307\u5411\uff09\u5339\u914d\u5230\u7684\u5b9e\u4f8b\u5bf9\u8c61\u548c\u51fd\u6570\u5bf9\u8c61\uff0c\u8fd9\u4e2a\u62bd\u8c61\u5bf9\u8c61\u5c31\u662f\u65b9\u6cd5\u5bf9\u8c61\u3002 \u5f53\u5e26\u53c2\u6570\u8c03\u7528\u65b9\u6cd5\u5bf9\u8c61\u65f6\uff0c\u5c06\u57fa\u4e8e\u5b9e\u4f8b\u5bf9\u8c61\u548c\u53c2\u6570\u5217\u8868\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u53c2\u6570\u5217\u8868\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e2a\u65b0\u53c2\u6570\u5217\u8868\u8c03\u7528\u76f8\u5e94\u7684\u51fd\u6570\u5bf9\u8c61\u3002","title":"\u65b9\u6cd5\u5bf9\u8c61 Method Objects"},{"location":"python/Foundation/ch04/#class-and-instance-variables","text":"\u4e00\u822c\u6765\u8bf4\uff0c \u5b9e\u4f8b\u53d8\u91cf \u7528\u4e8e\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u552f\u4e00\u6570\u636e\uff0c\u800c \u7c7b\u53d8\u91cf \u7528\u4e8e\u7c7b\u7684\u6240\u6709\u5b9e\u4f8b\u5171\u4eab\u7684\u5c5e\u6027\u548c\u65b9\u6cd5: class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance d = Dog('Fido') e = Dog('Buddy') print(d.kind) # shared by all dogs # 'canine' print(e.kind) # shared by all dogs # 'canine' print(d.name) # unique to d instance # 'Fido' print(e.name) # unique to e instance # 'Buddy' \u4e0b\u4ee3\u7801\u4e2d\u7684 tricks \u5217\u8868\u4e0d\u5e94\u8be5\u88ab\u7528\u4f5c\u7c7b\u53d8\u91cf\uff0c\u56e0\u4e3a\u6240\u6709\u7684 Dog \u5b9e\u4f8b\u5c06\u53ea\u5171\u4eab\u4e00\u4e2a\u5355\u72ec\u7684\u5217\u8868: class Dog: kind = 'canine' # class variable shared by all instances tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name # instance variable unique to each instance def add_trick(self, trick): self.tricks.append(trick) d = Dog('Fido') e = Dog('Buddy') d.add_trick('roll over') e.add_trick('play dead') print(d.tricks) # ['roll over', 'play dead'] \u6b63\u786e\u7684\u7c7b\u8bbe\u8ba1\u5e94\u8be5\u4f7f\u7528\u5b9e\u4f8b\u53d8\u91cf: class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick) d = Dog('Fido') e = Dog('Buddy') d.add_trick('roll over') e.add_trick('play dead') print(d.tricks) # ['roll over'] print(e.tricks) # ['play dead'] \u5982\u679c\u540c\u6837\u7684\u5c5e\u6027\u540d\u79f0\u540c\u65f6\u51fa\u73b0\u5728\u5b9e\u4f8b\u548c\u7c7b\u4e2d\uff0c\u5219\u5c5e\u6027\u67e5\u627e\u4f1a \u4f18\u5148\u9009\u62e9\u5b9e\u4f8b : class Warehouse: purpose = 'storage' region = 'west' w1 = Warehouse() print(w1.purpose, w1.region) # storage west w2 = Warehouse() w2.region = 'east' # Instance W2 has higher priority than class print(w2.purpose, w2.region) # storage east \u6570\u636e\u5c5e\u6027\uff08Data attributes\uff09\u53ef\u4ee5\u88ab\u65b9\u6cd5\uff08method\uff09\u4ee5\u53ca\u4e00\u4e2a\u5bf9\u8c61\u7684\u666e\u901a\u7528\u6237\uff08ordinary users\uff09\uff08\u201c\u5ba2\u6237\u7aefClient\u201d\uff09\u6240\u5f15\u7528\u3002 \u6362\u53e5\u8bdd\u8bf4\uff0c\u7c7b\u4e0d\u80fd\u7528\u4e8e\u5b9e\u73b0\u7eaf\u62bd\u8c61\u6570\u636e\u7c7b\u578b\u3002 \u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u5e38\u5e38\u88ab\u547d\u540d\u4e3a self \uff0c\u8fd9\u53ea\u662f\u4e00\u4e2a\u7ea6\u5b9a: self \u8fd9\u4e00\u540d\u79f0\u5728Python\u4e2d\u6ca1\u6709\u7279\u6b8a\u542b\u4e49\u3002 \u4f46\u662f\u9075\u5faa\u6b64\u7ea6\u5b9a\u4f1a\u4f7f\u5f97\u4ee3\u7801\u5177\u6709\u5f88\u597d\u7684\u53ef\u8bfb\u6027\u3002 \u4efb\u4f55\u4e00\u4e2a\u4f5c\u4e3a\u7c7b\u5c5e\u6027\uff08class attribute\uff09\u7684\u51fd\u6570\u5bf9\u8c61\uff08function object\uff09\u90fd\u4e3a\u8be5\u7c7b\u7684\u5b9e\u4f8b\u5b9a\u4e49\u4e86\u4e00\u4e2a\u76f8\u5e94\u65b9\u6cd5\u3002 \u51fd\u6570\u5b9a\u4e49\u7684\u6587\u672c\u5e76\u975e\u5fc5\u987b\u5305\u542b\u4e8e\u7c7b\u5b9a\u4e49\u4e4b\u5185\uff1a\u5c06\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u8d4b\u503c\u7ed9\u4e00\u4e2a\u5c40\u90e8\u53d8\u91cf\u4e5f\u662f\u53ef\u4ee5\u7684\u3002\u5982\u4e0b\u4f8b\u3002\u73b0\u5728 f , g \u548c h \u90fd\u662f\u7c7b C \u7684\u5f15\u7528\u51fd\u6570\u5bf9\u8c61\u7684\u5c5e\u6027\uff0c\u56e0\u800c\u5b83\u4eec\u5c31\u90fd\u662f\u7c7b C \u7684\u5b9e\u4f8b\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d h \u5b8c\u5168\u7b49\u540c\u4e8e g \u3002\u4f46\u8bf7\u6ce8\u610f\uff0c\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u7684\u53ef\u8bfb\u6027\u975e\u5e38\u4e0d\u597d\u3002 # Function defined outside the class def f1(self, x, y): return min(x, x + y) class C: f = f1 # Assign a function object to a local variable in the class def g(self): return 'hello world' h = g \u65b9\u6cd5\uff08methods\uff09\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 self \u53c2\u6570\u7684\u65b9\u6cd5\u5c5e\u6027\uff08method attributes\uff09\u8c03\u7528\u5176\u4ed6\u65b9\u6cd5\uff08method\uff09: class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) \u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u4e0e\u666e\u901a\u51fd\u6570\u76f8\u540c\u7684\u65b9\u5f0f\u5f15\u7528\u5168\u5c40\u540d\u79f0\u3002 \u4e0e\u65b9\u6cd5\u76f8\u5173\u8054\u7684\u5168\u5c40\u4f5c\u7528\u57df\u5c31\u662f\u5305\u542b\u5176\u5b9a\u4e49\u7684\u6a21\u5757\u3002 \uff08\u7c7b\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u4f5c\u4e3a\u5168\u5c40\u4f5c\u7528\u57df\u3002\uff09 \u867d\u7136\u6211\u4eec\u5f88\u5c11\u4f1a\u6709\u5145\u5206\u7684\u7406\u7531\u5728\u65b9\u6cd5\u4e2d\u4f7f\u7528\u5168\u5c40\u4f5c\u7528\u57df\uff0c\u4f46\u5168\u5c40\u4f5c\u7528\u57df\u5b58\u5728\u8bb8\u591a\u5408\u7406\u7684\u4f7f\u7528\u573a\u666f\uff1a\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u5bfc\u5165\u5230\u5168\u5c40\u4f5c\u7528\u57df\u7684\u51fd\u6570\u548c\u6a21\u5757\u53ef\u4ee5\u88ab\u65b9\u6cd5\u6240\u4f7f\u7528\uff0c\u5728\u5176\u4e2d\u5b9a\u4e49\u7684\u51fd\u6570\u548c\u7c7b\u4e5f\u4e00\u6837\u3002 \u901a\u5e38\uff0c\u5305\u542b\u8be5\u65b9\u6cd5\u7684\u7c7b\u672c\u8eab\u662f\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u5b9a\u4e49\u7684\u3002","title":"\u7c7b\u548c\u5b9e\u4f8b\u53d8\u91cf Class and Instance Variables"},{"location":"python/Foundation/ch04/#_1","text":"","title":"\u603b\u7ed3"},{"location":"python/Foundation/ch04/#_2","text":"\u4e00\u4e2a\u7c7b\u5b9a\u4e49\u7c7b\u6210\u5458\u5c5e\u6027\u548c\u6210\u5458\u65b9\u6cd5\u3002 \u4e00\u4e2a\u7c7b\u53ef\u4ee5\u5b9e\u4f8b\u5316\u591a\u4e2a\u5bf9\u8c61\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5316\u5bf9\u8c61\u90fd\u662f\u72ec\u7acb\u7684\u3002 \u521b\u5efa\u7684\u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\uff0c\u4f1a\u5f15\u7528\u7236\u7c7b\u4e2d\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u5e76\u4e0d\u4f1a\u628a\u7c7b\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u590d\u5236\u7ed9\u5bf9\u8c61\uff0c\u56e0\u6b64\uff1a \u5728\u8bbf\u95ee\u5b9e\u4f8b\u5316\u5bf9\u8c61\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u65f6\uff0c\u4f1a\u5148\u53bb\u627e\u5bf9\u8c61\u81ea\u5df1\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\uff0c\u7136\u540e\u518d\u53bb\u5b9e\u4f8b\u5316\u8fd9\u4e2a\u5bf9\u8c61\u7684\u7c7b\u4e2d\u67e5\u627e\uff08\u5f15\u7528\uff09\u3002 \u5bf9\u8c61\u6210\u5458\u7684\u6dfb\u52a0\u548c\u4fee\u6539\uff0c\u90fd\u53ea\u4f1a\u5f71\u54cd\u5f53\u524d\u5bf9\u8c61\u81ea\u5df1\uff0c\u4e0d\u4f1a\u5f71\u54cd\u7c7b\u548c\u5176\u5b83\u5bf9\u8c61\u3002 \u5220\u9664\u5bf9\u8c61\u6210\u5458\u7684\u65f6\u5019\uff0c\u5fc5\u987b\u662f\u8be5\u5bf9\u8c61\u81ea\u5df1\u5177\u5907\u7684\u6210\u5458\u624d\u53ef\u4ee5\uff0c\u4e0d\u80fd\u5220\u9664\u7c7b\u4e2d\u5f15\u7528\u7684\u6210\u5458\u3002 \u5bf9\u7c7b\u6210\u5458\u7684\u64cd\u4f5c\uff0c\u4f1a\u5f71\u54cd\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\uff0c\u5305\u62ec\u4e4b\u524d\u521b\u5efa\u7684\u5bf9\u8c61\uff08\u5f15\u7528\uff09\u3002","title":"\u7c7b\u5b9a\u4e49\u5c0f\u7ed3"},{"location":"python/Foundation/ch04/#_3","text":"\u6210\u5458\u5c5e\u6027\uff1a \u8bbf\u95ee\uff1a ClassName.AttributeName \u4fee\u6539\uff1a ClassName.AttributeName = NewValue \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u6dfb\u52a0\uff1a ClassName.NewAttributeName = Value \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u5220\u9664\uff1a del ClassName.AttributeName \uff0c\u6ce8\u610f\uff0c\u53ea\u80fd\u5220\u9664\u7c7b\u5bf9\u8c61\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u4e0d\u518d\u5177\u6709\u8fd9\u4e2a\u5c5e\u6027\u3002 \u6210\u5458\u65b9\u6cd5\uff1a \u8bbf\u95ee\uff1a ClassName.MethodName() \u4fee\u6539\uff1a ClassName.MethodName = NewFunction \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002 \u6dfb\u52a0\uff1a ClassName.MethodName = Function \uff0c\u7b49\u4e8e\u7ed9\u8fd9\u4e2a\u7c7b\u5bf9\u8c61\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002 \u5220\u9664\uff1a del ClassName.MethodName \uff0c\u6ce8\u610f\uff0c\u53ea\u80fd\u5220\u9664\u7c7b\u5bf9\u8c61\u81ea\u5df1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd9\u4e2a\u7c7b\u521b\u5efa\u7684\u5bf9\u8c61\u90fd\u4e0d\u518d\u5177\u6709\u8fd9\u4e2a\u65b9\u6cd5\u3002","title":"\u7c7b\u6210\u5458\u64cd\u4f5c\uff08\u4e0d\u63a8\u8350\uff09\uff1a"},{"location":"python/Foundation/ch04/#self","text":"self \u53ea\u662f\u4e00\u4e2a\u5f62\u53c2\uff0c\u4e0d\u662f\u5173\u952e\u5b57\u3002 self \u5728\u65b9\u6cd5\uff08method\uff09\u4ee3\u8868\u5f53\u524d\u5bf9\u8c61\u81ea\u5df1\u3002\u524d\u9762\u63d0\u5230\u8fc7\uff0c\u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u5e38\u5e38\u88ab\u547d\u540d\u4e3a self \uff0c\u8fd9\u53ea\u662f\u4e00\u4e2a\u7ea6\u5b9a\u3002 \u53ef\u4ee5\u4f7f\u7528 self \u5728\u7c7b\u5185\u90e8\u64cd\u4f5c\u6210\u5458\uff08\u6dfb\u52a0\u3001\u4fee\u6539\u3001\u5220\u9664\u7b49\uff09\u3002 \u65b9\u6cd5\u7684\u5206\u7c7b\uff1a \u542b\u6709self\u6216\u8005\u53ef\u4ee5\u63a5\u53d7\u5bf9\u8c61\u4f5c\u4e3a\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u975e\u7ed1\u5b9a\u7c7b\u65b9\u6cd5 \uff0c\u975e\u7ed1\u5b9a\u7c7b\u7684\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528\u5bf9\u8c61\u53bb\u8bbf\u95ee\u3002 \u4e0d\u542b\u6709self\u6216\u8005\u4e0d\u80fd\u63a5\u53d7\u5bf9\u8c61\u4f5c\u4e3a\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u7ed1\u5b9a\u7c7b\u65b9\u6cd5 \uff0c\u7ed1\u5b9a\u65b9\u6cd5\u53ea\u80fd\u4f7f\u7528\u7c7b\u53bb\u8bbf\u95ee\u3002","title":"\u6210\u5458\u65b9\u6cd5\u4e2d\u7684self"},{"location":"python/Foundation/ch04/#_4","text":"\u9b54\u672f\u65b9\u6cd5\uff08Magic Method\uff09\u548c\u666e\u901a\u65b9\u6cd5\u4e00\u6837\uff0c\u90fd\u662f\u7c7b\u4e2d\u5b9a\u4e49\u7684\u6210\u5458\u65b9\u6cd5\u3002 \u9b54\u672f\u65b9\u6cd5\u540d\u79f0\u524d\u540e\u5404\u67092\u4e2a\u4e0b\u5212\u7ebf\uff0c\u6bd4\u5982 __init__ \u9b54\u672f\u65b9\u6cd5\u662f\u4e0d\u9700\u8981\u624b\u52a8\u8c03\u7528\u7684\uff0c\u4f1a\u5728\u67d0\u79cd\u60c5\u51b5\u4e0b\u81ea\u52a8\u89e6\u53d1\uff08\u81ea\u52a8\u6267\u884c\uff09\u3002 \u9b54\u672f\u65b9\u6cd5\u662f\u7cfb\u7edf\u5b9a\u4e49\u597d\u7684\uff0c\u4e0d\u662f\u7528\u6237\u5b9a\u4e49\u7684\u3002","title":"\u9b54\u672f\u65b9\u6cd5"},{"location":"python/Foundation/ch04/#__init__","text":"\u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\u521b\u5efa\u540e\u81ea\u52a8\u89e6\u53d1\u3002 __init__ \u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u7528\u6765\u5728\u5bf9\u8c61\u5b9e\u4f8b\u5316\u540e\u5b8c\u6210\u5bf9\u8c61\u7684\u521d\u59cb\u5316\uff0c\u6bd4\u5982\u5c5e\u6027\u8d4b\u503c\uff0c\u65b9\u6cd5\u8c03\u7528\u7b49\u3002","title":"__init__\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4e5f\u79f0\u4f5c\u6784\u9020\u65b9\u6cd5"},{"location":"python/Foundation/ch04/#__del__","text":"\u7c7b\u5b9e\u4f8b\u5316\u5bf9\u8c61\u88ab\u9500\u6bc1\u65f6\u81ea\u52a8\u89e6\u53d1\u3002 __del__ \u6790\u6784\u65b9\u6cd5\u53ef\u4ee5\u5728\u9500\u6bc1\u5bf9\u8c61\u65f6\u5b8c\u6210\u4e00\u4e9b\u7279\u6b8a\u4efb\u52a1\uff0c\u5173\u95ed\u5bf9\u8c61\u6253\u5f00\u7684\u4e00\u4e9b\u8d44\u6e90\uff0c\u5982\u6587\u4ef6\u7b49\u3002 \u6ce8\u610f\uff0c\u662f\u5bf9\u8c61\u88ab\u9500\u6bc1\u65f6\u89e6\u53d1\u4e86\u6790\u6784\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f\u8fd9\u4e2a\u6790\u6784\u65b9\u6cd5\u9500\u6bc1\u4e86\u5bf9\u8c61\u3002 \u5bf9\u8c61\u9500\u6bc1\u7684\u60c5\u51b5\uff1a \u5f53\u7a0b\u5e8f\u6267\u884c\u5b8c\u6bd5\uff0c\u9500\u6bc1\u548c\u91ca\u653e\u5185\u5b58\u4e2d\u7684\u8d44\u6e90\u3002 \u4f7f\u7528 del \u5220\u9664\u65f6\u3002 \u5bf9\u8c61\u4e0d\u518d\u88ab\u4efb\u4f55\u5bf9\u8c61\u5f15\u7528\u65f6\uff0c\u4f1a\u81ea\u52a8\u9500\u6bc1\u3002 \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\uff0c\u5bf9\u6bd4 bmw = Car('BMW') \u548c Car('BMW') \u6765\u7406\u89e3 init \u548c del \u7684\u89e6\u53d1\u673a\u5236\u3002 \u7f16\u8f91\u6587\u4ef6 file1.py class Car(): brand = \"\" def __init__(self, car_brand): self.brand = car_brand print(f\"initial method called, create {self.brand} car\") def __del__(self): print(f\"delete method called, destroy {self.brand} car\") bmw = Car('BMW') vw = Car('VW') \u6267\u884c\u4e0a\u9762\u7684\u4ee3\u7801 python3 file1.py \u5f97\u5230\u5982\u4e0b\u8f93\u51fa\uff0c\u5728\u7a0b\u5e8f\u6267\u884c\u5b8c\u6bd5\u65f6\uff0c\u4f9d\u6b21\u6267\u884c __del__ \u3002 initial method called, create BMW car initial method called, create VW car delete method called, destroy BMW car delete method called, destroy VW car \u7f16\u8f91\u6587\u4ef6 file2.py class Car(): brand = \"\" def __init__(self, car_brand): self.brand = car_brand print(f\"initial method called, create {self.brand} car\") def __del__(self): print(f\"delete method called, destroy {self.brand} car\") Car('BMW') Car('VW') \u6267\u884c\u4e0a\u9762\u7684\u4ee3\u7801 python3 file2.py \u5f97\u5230\u5982\u4e0b\u8f93\u51fa\uff1a initial method called, create BMW car delete method called, destroy BMW car initial method called, create VW car delete method called, destroy VW car","title":"__del__\u6790\u6784\u65b9\u6cd5"},{"location":"python/Foundation/ch04/#python_1","text":"\u4ece\u9b54\u672f\u65b9\u6cd5\u53ef\u4ee5\u5ef6\u7533\u5230Python\u7684 \u51fd\u6570\u5185\u7701 \uff0c\u51fd\u6570\u5185\u7701\u7684\u610f\u601d\u662f\u8bf4\uff0c\u5f53\u4f60\u62ff\u5230\u4e00\u4e2a\u201c\u51fd\u6570\u5bf9\u8c61\u201d\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7ee7\u7eed\u77e5\u9053\uff0c\u5b83\u7684\u540d\u5b57\uff0c\u53c2\u6570\u5b9a\u4e49\u7b49\u4fe1\u606f\u3002\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u901a\u8fc7\u51fd\u6570\u5bf9\u8c61\u7684\u5c5e\u6027\uff08\u4e00\u4e9b\u53cc\u4e0b\u5212\u7ebf\u7684\u9b54\u6cd5\u65b9\u6cd5\uff09\u5f97\u5230\u3002\u7b80\u8a00\u4e4b\uff0c\u5185\u7701\u662f\u5728\u8fd0\u884c\u65f6\u786e\u5b9a\u5bf9\u8c61\u7c7b\u578b\u7684\u80fd\u529b\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u5217\u51fa\u4e86\u5e38\u89c4\u5bf9\u8c61\u6ca1\u6709\u800c\u51fd\u6570\u6709\u7684\u5c5e\u6027\u3002 class C: pass obj = C() def func(): pass sorted(set(dir(obj)) - set(dir(func))) # ['__weakref__'] sorted(set(dir(func)) - set(dir(obj))) # ['__annotations__', '__call__', '__closure__', '__code__', '__defaults__', '__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__'] \u4e0b\u8868\u603b\u7ed3\u4e86\u7528\u6237\u5b9a\u4e49\u7684\u51fd\u6570\u7684\u5c5e\u6027\u3002 \u4e0b\u9762\u7684\u4f8b\u5b50\u662f\u6f14\u793a\u4e86\u5728\u6307\u5b9a\u957f\u5ea6\u9644\u8fd1\u622a\u65ad\u5b57\u7b26\u4e32\u7684\u51fd\u6570\uff0c\u4ee5\u53ca\u63d0\u53d6\u5173\u4e8e\u51fd\u6570\u53c2\u6570\u7684\u4fe1\u606f\u7684\u65b9\u6cd5\u3002 \u53c2\u6570\u540d\u79f0\u5728 __code__.co_varnames \u4e2d\uff0c\u4f46\u8fd9\u91cc\u9762\u4e5f\u5305\u542b\u51fd\u6570\u5b9a\u4e49\u4f53\u4e2d\u521b\u5efa\u7684\u5c40\u90e8\u53d8\u91cf\u3002\u56e0\u6b64\uff0c\u53c2\u6570\u540d\u79f0\u662f\u524d N \u4e2a\u5b57\u7b26\u4e32\uff0c N \u7684\u503c\u7531 __code__.co_argcount \u786e\u5b9a\uff0c\u4f8b\u5b50\u91cc\u9762N\u662f2\uff0c\u5373\u53c2\u6570\u540d\u79f0\u662f text \u548c max_len \uff0c\u5c40\u90e8\u53d8\u91cf\u662f end \u3001 space_before \u3001 space_after \u3002 def clip(text, max_len=80): \"\"\" Get sub-string by the first blank before or after specified position. rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1. \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip() clip('This is the string', max_len=10) # 'This is' clip.__defaults__ # (80,) clip.__code__ # <code object clip at 0x7f1e04a5c8a0, file \"<stdin>\", line 1> clip.__code__.co_varnames # ('text', 'max_len', 'end', 'space_before', 'space_after') clip.__code__.co_argcount # 2 clip.__doc__ # '\\n Get sub-string by the first blank before or after specified position.\\n rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1.\\n ' \u4e0a\u4f8b\u4e2d\uff0c\u53c2\u6570\u7684\u9ed8\u8ba4\u503c\u53ea\u80fd\u901a\u8fc7\u5b83\u4eec\u5728 __defaults__ \u5143\u7ec4\u4e2d\u7684\u4f4d\u7f6e\u786e\u5b9a\uff0c\u56e0\u6b64\u8981\u4ece\u540e\u5411\u524d\u626b\u63cf\u624d\u80fd\u628a\u53c2\u6570\u548c\u9ed8\u8ba4\u503c\u5bf9\u5e94\u8d77\u6765\uff0c\u6709\u4e9b\u4e0d\u5408\u7406\u3002\u5f15\u5165 inspect \u6a21\u5757\u540e\uff0c\u4e0a\u9762\u7684\u64cd\u4f5c\u5c31\u66f4\u5bb9\u6613\u4e86\u3002 inspect.signature \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a inspect.Signature \u5bf9\u8c61\uff0c\u5b83\u6709\u4e00\u4e2a parameters \u5c5e\u6027\uff0c\u8fd9\u662f\u4e00\u4e2a\u6709\u5e8f\u6620\u5c04\uff0c\u628a\u53c2\u6570\u540d\u548c inspect.Parameter \u5bf9\u8c61\u5bf9\u5e94\u8d77\u6765\u3002\u5404\u4e2a Parameter \u5c5e\u6027\u4e5f\u6709\u81ea\u5df1\u7684\u5c5e\u6027\uff0c\u4f8b\u5982 name \u3001 default \u548c kind \u3002 from inspect import signature sig = signature(clip) type(sig) # <class 'inspect.Signature'> print(sig) # (text, max_len=80) print(str(sig)) # (text, max_len=80) for name, param in sig.parameters.items(): print(f'{param.kind} : {name} = {param.default}') # 1 : text = <class 'inspect._empty'> # 1 : max_len = 80 \u51fd\u6570\u6ce8\u89e3 Python 3 \u63d0\u4f9b\u4e86\u4e00\u79cd\u53e5\u6cd5\uff0c\u7528\u4e8e\u4e3a\u51fd\u6570\u58f0\u660e\u4e2d\u7684\u53c2\u6570\u548c\u8fd4\u56de\u503c\u9644\u52a0\u5143\u6570\u636e\u3002\u5bf9\u4e0a\u4f8b\u6dfb\u52a0\u6ce8\u89e3\u540e\u5982\u4e0b\u6240\u793a\uff0c\u4e8c\u8005\u552f\u4e00\u7684\u533a\u522b\u5728\u7b2c\u4e00\u884c\u3002 \u51fd\u6570\u58f0\u660e\u4e2d\u7684\u5404\u4e2a\u53c2\u6570\u53ef\u4ee5\u5728:\u4e4b\u540e\u589e\u52a0\u6ce8\u89e3\u8868\u8fbe\u5f0f\u3002 \u5982\u679c\u53c2\u6570\u6709\u9ed8\u8ba4\u503c\uff0c\u6ce8\u89e3\u653e\u5728\u53c2\u6570\u540d\u548c = \u53f7\u4e4b\u95f4\u3002 \u5982\u679c\u60f3\u6ce8\u89e3\u8fd4\u56de\u503c\uff0c\u5728)\u548c\u51fd\u6570\u58f0\u660e\u672b\u5c3e\u7684 : \u4e4b\u95f4\u6dfb\u52a0 -> \u548c\u4e00\u4e2a\u8868\u8fbe\u5f0f\u3002\u90a3\u4e2a\u8868\u8fbe\u5f0f\u53ef\u4ee5\u662f\u4efb\u4f55\u7c7b\u578b\u3002 \u6ce8\u89e3\u4e2d\u6700\u5e38\u7528\u7684\u7c7b\u578b\u662f\u7c7b\uff08\u5982 str \u6216 int \uff09\u548c\u5b57\u7b26\u4e32\uff08\u5982'int > 0'\uff09\u3002\u5728\u4e0b\u4f8b\u4e2d\uff0cmax_len\u53c2\u6570\u7684\u6ce8\u89e3\u7528\u7684\u662f\u5b57\u7b26\u4e32\u3002 \u6ce8\u89e3\u4e0d\u4f1a\u505a\u4efb\u4f55\u5904\u7406\uff0c\u53ea\u662f\u5b58\u50a8\u5728\u51fd\u6570\u7684 __annotations__ \u5c5e\u6027\uff08\u4e00\u4e2a\u5b57\u5178\uff09\u4e2d\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u6ce8\u89e3\u5bf9Python\u89e3\u91ca\u5668\u6ca1\u6709\u4efb\u4f55\u610f\u4e49\u3002 \u6ce8\u89e3\u53ea\u662f\u5143\u6570\u636e \uff0c\u53ef\u4ee5\u4f9bIDE\u3001\u6846\u67b6\u548c\u88c5\u9970\u5668\u7b49\u5de5\u5177\u4f7f\u7528\u3002 return \u952e\u4fdd\u5b58\u7684\u662f\u8fd4\u56de\u503c\u6ce8\u89e3\uff0c\u5373\u4e0b\u4f8b\u4e2d\u51fd\u6570\u58f0\u660e\u91cc\u4ee5 -> \u6807\u8bb0\u7684\u90e8\u5206\u3002 def clip(text:str, max_len:'int > 0'=80) -> str: \"\"\" Get sub-string by the first blank before or after specified position. rfind() \u8fd4\u56de\u5b57\u7b26\u4e32\u6700\u540e\u4e00\u6b21\u51fa\u73b0\u7684\u4f4d\u7f6e\uff0c\u5982\u679c\u6ca1\u6709\u5339\u914d\u9879\u5219\u8fd4\u56de -1. \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip() clip('This is the string', max_len=10) # 'This is' clip.__annotations__ # {'text': <class 'str'>, 'max_len': 'int > 0', 'return': <class 'str'>} signature \u51fd\u6570\u8fd4\u56de\u4e00\u4e2a Signature \u5bf9\u8c61\uff0c\u5b83\u6709\u4e00\u4e2a return_annotation \u5c5e\u6027\u548c\u4e00\u4e2a parameters \u5c5e\u6027\uff0c\u540e\u8005\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u628a\u53c2\u6570\u540d\u6620\u5c04\u5230 Parameter \u5bf9\u8c61\u4e0a\u3002\u6bcf\u4e2a Parameter \u5bf9\u8c61\u81ea\u5df1\u4e5f\u6709 annotation \u5c5e\u6027\u3002 from inspect import signature sig = signature(clip) print(sig.return_annotation) # <class 'str'> for param in sig.parameters.values(): note = repr(param.annotation).ljust(13) print(f'{note} : {param.name} = {param.default}') # <class 'str'> : text = <class 'inspect._empty'> # 'int > 0' : max_len = 80","title":"Python\u51fd\u6570\u5185\u7701\u5185\u7701"},{"location":"python/Foundation/ch05/","text":"\u9762\u5411\u5bf9\u8c61\u4e09\u5927\u7279\u6027 \u4e09\u5927\u7279\u6027\uff1a \u5c01\u88c5 \u7ee7\u627f \u591a\u6001 \u5c01\u88c5 Encapsulation \u5c01\u88c5\u662f\u4f7f\u7528\u7279\u6b8a\u7684\u8bed\u6cd5\uff0c\u5bf9\u6210\u5458\u5c5e\u6027\u548c\u6210\u5458\u65b9\u6cd5\u8fdb\u884c\u5305\u88c5\uff0c\u9650\u5236\u4e00\u4e9b\u8bbf\u95ee\u548c\u64cd\u4f5c\uff0c\u8fbe\u5230\u4fdd\u62a4\u548c\u9690\u85cf\u7684\u76ee\u7684\u3002 \u5c01\u88c5\u673a\u5236\u4fdd\u8bc1\u4e86\u7c7b\u5185\u90e8\u6570\u636e\u7ed3\u6784\u7684\u5b8c\u6574\u6027\uff0c\u56e0\u4e3a\u4f7f\u7528\u7c7b\u7684\u7528\u6237\u65e0\u6cd5\u76f4\u63a5\u770b\u5230\u7c7b\u4e2d\u7684\u6570\u636e\u7ed3\u6784\uff0c\u53ea\u80fd\u4f7f\u7528\u7c7b\u5141\u8bb8\u516c\u5f00\u7684\u6570\u636e\uff0c\u5f88\u597d\u5730\u907f\u514d\u4e86\u5916\u90e8\u5bf9\u5185\u90e8\u6570\u636e\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u7a0b\u5e8f\u7684\u53ef\u7ef4\u62a4\u6027\u3002 \u5bf9\u4e00\u4e2a\u7c7b\u5b9e\u73b0\u826f\u597d\u7684\u5c01\u88c5\uff0c\u7528\u6237\u53ea\u80fd\u501f\u52a9\u66b4\u9732\u51fa\u6765\u7684\u7c7b\u65b9\u6cd5\u6765\u8bbf\u95ee\u6570\u636e\uff0c\u53ef\u4ee5\u5728\u8fd9\u4e9b\u66b4\u9732\u7684\u65b9\u6cd5\u4e2d\u52a0\u5165\u9002\u5f53\u7684\u63a7\u5236\u903b\u8f91\uff0c\u5373\u53ef\u63a7\u5236\u7528\u6237\u5bf9\u7c7b\u4e2d\u5c5e\u6027\u6216\u65b9\u6cd5\u7684\u64cd\u4f5c\u3002 \u5bf9\u7c7b\u8fdb\u884c\u826f\u597d\u7684\u5c01\u88c5\uff0c\u4e3b\u8981\u662f\u5185\u90e8\u4f7f\u7528\u5c01\u88c5\u7684\u6210\u5458\uff0c\u4e5f\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u590d\u7528\u6027\u3002 \u7c7b\u6210\u5458\u5c01\u88c5\u7684\u7ea7\u522b\uff1a \u516c\u6709\u7684\uff08public\uff09 \u4fdd\u62a4\u7684\uff08protected\uff09\uff0c\u5728Python\u4e2d\u5e76\u6ca1\u6709\u5b9e\u73b0protected\u5c01\u88c5\uff0c\u5c5e\u4e8e\u5f00\u53d1\u8005\u7684\u7ea6\u5b9a\u4fd7\u6210\u3002 \u79c1\u6709\u7684\uff08private\uff09\uff0c\u5728Python\u4e2dprivate\u5c01\u88c5\u662f\u901a\u8fc7\u6539\u540d\u7b56\u7565\u6765\u5b9e\u73b0\u7684\uff0c\u5e76\u4e0d\u662f\u771f\u6b63\u7684\u79c1\u6709\u5316\u3002 \u8bbf\u95ee\u9650\u5236 \u5171\u6709\u7684public \u53d7\u4fdd\u62a4\u7684protected \u79c1\u6709\u7684private \u5728\u7c7b\u7684\u5185\u90e8 OK OK OK \u5728\u7c7b\u7684\u5916\u90e8 OK No (Python\u4e2d\u53ef\u4ee5) No \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u3002(\u53c2\u8003 \u79c1\u6709\u53d8\u91cfPrivate Variables ) name \u662f\u5171\u6709\u5c5e\u6027\uff0c\u53ef\u4ee5\u5728\u5916\u90e8\u8c03\u7528tom.name\u3002 _age \u662f\u53d7\u4fdd\u62a4\u7684\u5c5e\u6027\uff0c\u7406\u8bba\u4e0a\u5728\u5916\u90e8\u662f\u4e0d\u53ef\u8c03\u7528\u7684\uff0c\u4f46\u5728Python\u4e2d\u662f\u53ef\u4ee5\u8c03\u7528\u7684 tom._age \u3002 __phone \u662f\u79c1\u6709\u5c5e\u6027\uff0c\u5728\u5916\u90e8\u662f\u4e0d\u53ef\u8c03\u7528\u7684\uff0c tom.__get_phone() \u62a5\u9519\u201c\u5c5e\u6027\u4e0d\u5b58\u5728\u201d\u3002 \u5bf9\u5e94\u65b9\u6cd5\u4e5f\u662f\u7c7b\u4f3c\u3002 \u5728\u7c7b\u7684\u5185\u90e8\u5bf9\u53d7\u4fdd\u62a4\u5bf9\u8c61\u548c\u79c1\u6709\u5bf9\u8c61\u6ca1\u6709\u8bbf\u95ee\u9650\u5236\u3002 _get_age \u53ef\u4ee5\u8c03\u7528\u79c1\u6709\u5c5e\u6027 __phone \u3002 class Person(): name = 'name' # public _age = 0 # protected __phone = 'phone' # private def __init__(self, n, a, p): self.name = n self._age = a self.__phone = p def get_name(self): print(f'My name is {self.name}') def _get_age(self): print(f'My age is {self._age}') print(f'My age is {self.__phone}') def __get_phone(self): print(f'My phone is {self.__phone}') tom = Person('Tom', 18, 12345678) tom.name # 'Tom' tom._age # 18 tom.__phone # AttributeError: 'Person' object has no attribute '__phone' tom.get_name() # My name is Tom tom._get_age() # My age is 18 # My age is 12345678 tom.__get_phone() # AttributeError: 'Person' object has no attribute '__get_phone' \u7ee7\u627f Inheritance \u5728\u4e0d\u6307\u5b9a\u7ee7\u627f\u7684\u7236\u7c7b\u65f6\uff0c\u6240\u6709\u7c7b\u90fd\u7ee7\u627fobject\u7c7b\uff08\u7cfb\u7edf\u63d0\u4f9b\uff09\u3002 \u88ab\u5176\u5b83\u7c7b\u7ee7\u627f\u7684\u7c7b\uff0c\u79f0\u4e3a\u7236\u7c7b\uff0c\u6216\u8005\u57fa\u7c7b\uff0c\u6216\u8005\u8d85\u7c7b\u3002 \u7ee7\u627f\u5176\u5b83\u7c7b\u7684\u7c7b\uff0c\u79f0\u4e3a\u5b50\u7c7b\uff0c\u6216\u8005\u6d3e\u751f\u7c7b\uff08derived class\uff09\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5c31\u62e5\u6709\u4e86\u7236\u7c7b\u4e2d\u7684\u6240\u6709\u6210\u5458\uff08\u9664\u4e86\u79c1\u6709\u6210\u5458\uff09\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5e76\u4e0d\u4f1a\u628a\u7236\u7c7b\u7684\u6210\u5458\u590d\u5236\u7ed9\u5b50\u7c7b\uff0c\u800c\u662f\u5f15\u7528\u3002 \u5b50\u7c7b\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u7236\u7c7b\u7684\u65b9\u6cd5 super().BaseClassName \u3002\u5982\u679c\u7236\u7c7b\u65b9\u6cd5\u6709\u53c2\u6570\u8981\u6c42\uff0c\u5b50\u7c7b\u8c03\u7528\u65f6\u4e5f\u6709\u53c2\u6570\u8981\u6c42\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u53ef\u4ee5\u91cd\u65b0\u5b9a\u4e49\u7236\u7c7b\u4e2d\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u91cd\u5199\uff08Override\uff09 \u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5b9a\u4e49\u7236\u7c7b\u4e2d\u6ca1\u6709\u7684\u65b9\u6cd5\uff0c\u88ab\u79f0\u4e3a\u5bf9\u7236\u7c7b\u7684\u6269\u5c55\u3002 \u4e00\u4e2a\u7236\u7c7b\u53ef\u4ee5\u88ab\u591a\u4e2a\u5b50\u7c7b\u7ee7\u627f\u3002 \u6d3e\u751f\u7c7b\uff08derived class\uff09 \u5b9a\u4e49\u7684\u8bed\u6cd5\u5982\u4e0b\u6240\u793a: class BaseClassName(): <statement-1> . . . <statement-N> class DerivedClassName(BaseClassName): <statement-1> . . . <statement-N> \u540d\u79f0 BaseClassName \u5fc5\u987b\u5b9a\u4e49\u4e8e\u5305\u542b\u6d3e\u751f\u7c7b\u5b9a\u4e49\u7684\u4f5c\u7528\u57df\u4e2d\u3002 \u4e5f\u5141\u8bb8\u7528\u5176\u4ed6\u4efb\u610f\u8868\u8fbe\u5f0f\u4ee3\u66ff\u57fa\u7c7b\u540d\u79f0\u6240\u5728\u7684\u4f4d\u7f6e\uff0c\u4f8b\u5982\uff0c\u5f53\u57fa\u7c7b\u5b9a\u4e49\u5728\u53e6\u4e00\u4e2a\u6a21\u5757\u4e2d\u7684\u65f6\u5019: class DerivedClassName(modname.BaseClassName): \u6d3e\u751f\u7c7b\u5b9a\u4e49\u7684\u6267\u884c\u8fc7\u7a0b\u4e0e\u57fa\u7c7b\u76f8\u540c\u3002 \u5f53\u6784\u9020\u7c7b\u5bf9\u8c61\u65f6\uff0c\u57fa\u7c7b\u4f1a\u88ab\u8bb0\u4f4f\u3002 \u6b64\u4fe1\u606f\u5c06\u88ab\u7528\u6765\u89e3\u6790\u5c5e\u6027\u5f15\u7528\uff1a\u5982\u679c\u8bf7\u6c42\u7684\u5c5e\u6027\u5728\u7c7b\u4e2d\u627e\u4e0d\u5230\uff0c\u641c\u7d22\u5c06\u8f6c\u5f80\u57fa\u7c7b\u4e2d\u8fdb\u884c\u67e5\u627e\u3002 \u5982\u679c\u57fa\u7c7b\u672c\u8eab\u4e5f\u6d3e\u751f\u81ea\u5176\u4ed6\u67d0\u4e2a\u7c7b\uff0c\u5219\u6b64\u89c4\u5219\u5c06\u88ab\u9012\u5f52\u5730\uff08recursively\uff09\u5e94\u7528\u3002 \u6d3e\u751f\u7c7b\u7684\u5b9e\u4f8b\u5316\u6ca1\u6709\u4efb\u4f55\u7279\u6b8a\u4e4b\u5904: DerivedClassName() \u4f1a\u521b\u5efa\u8be5\u7c7b\u7684\u4e00\u4e2a \u65b0\u5b9e\u4f8b \u3002 \u65b9\u6cd5\u5f15\u7528\u5c06\u6309\u4ee5\u4e0b\u65b9\u5f0f\u89e3\u6790\uff1a\u641c\u7d22\u76f8\u5e94\u7684\u7c7b\u5c5e\u6027\uff0c\u5982\u6709\u5fc5\u8981\u5c06\u6309\u57fa\u7c7b\u7ee7\u627f\u94fe\u9010\u6b65\u5411\u4e0b\u67e5\u627e\uff0c\u5982\u679c\u4ea7\u751f\u4e86\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u5219\u65b9\u6cd5\u5f15\u7528\u5c31\u751f\u6548\u3002 \u6d3e\u751f\u7c7b\u53ef\u80fd\u4f1a\u91cd\u5199\uff08override\uff09\u5176\u57fa\u7c7b\u7684\u65b9\u6cd5\u3002 \u56e0\u4e3a\u65b9\u6cd5\u5728\u8c03\u7528\u540c\u4e00\u5bf9\u8c61\u7684\u5176\u4ed6\u65b9\u6cd5\u65f6\u6ca1\u6709\u7279\u6b8a\u6743\u9650\uff0c\u6240\u4ee5\u8c03\u7528\u540c\u4e00\u57fa\u7c7b\u4e2d\u5b9a\u4e49\u7684\u53e6\u4e00\u65b9\u6cd5\u7684\u57fa\u7c7b\u65b9\u6cd5\u6700\u7ec8\u53ef\u80fd\u4f1a\u8c03\u7528\u8986\u76d6\u5b83\u7684\u6d3e\u751f\u7c7b\u7684\u65b9\u6cd5\u3002 \u5728\u6d3e\u751f\u7c7b\u4e2d\u7684\u91cd\u8f7d\u65b9\u6cd5\uff08overriding method\uff09\u5b9e\u9645\u4e0a\u53ef\u80fd\u60f3\u8981\u6269\u5c55\u800c\u975e\u7b80\u5355\u5730\u66ff\u6362\u540c\u540d\u7684\u57fa\u7c7b\u65b9\u6cd5\u3002 \u6709\u4e00\u79cd\u65b9\u5f0f\u53ef\u4ee5\u7b80\u5355\u5730\u76f4\u63a5\u8c03\u7528\u57fa\u7c7b\u65b9\u6cd5\uff1a\u5373\u8c03\u7528 BaseClassName.methodname(self, arguments) \u3002 \u8bf7\u6ce8\u610f\uff0c\u4ec5\u5f53\u6b64\u57fa\u7c7b\u53ef\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u4ee5 BaseClassName \u7684\u540d\u79f0\u88ab\u8bbf\u95ee\u65f6\u65b9\u53ef\u4f7f\u7528\u6b64\u65b9\u5f0f\u3002 Python\u6709\u4e24\u4e2a\u5185\u7f6e\u51fd\u6570\u53ef\u88ab\u7528\u4e8e\u7ee7\u627f\u673a\u5236\uff1a \u4f7f\u7528 isinstance() \u6765\u68c0\u67e5\u4e00\u4e2a\u5b9e\u4f8b\u7684\u7c7b\u578b: isinstance(obj, int) \u4ec5\u4f1a\u5728 obj.__class__ \u4e3a int \u6216\u67d0\u4e2a\u6d3e\u751f\u81ea int \u7684\u7c7b\u65f6\u4e3a True \u3002 \u4f7f\u7528 issubclass() \u6765\u68c0\u67e5\u7c7b\u7684\u7ee7\u627f\u5173\u7cfb: issubclass(bool, int) \u4e3a True \uff0c\u56e0\u4e3a bool \u662f int \u7684\u5b50\u7c7b\u3002 \u4f46\u662f\uff0c issubclass(float, int) \u4e3a False \uff0c\u56e0\u4e3a float \u4e0d\u662f int \u7684\u5b50\u7c7b\u3002 \u591a\u91cd\u7ee7\u627f Multiple Inheritance \u5355\u7ee7\u627f\uff08single-inheritance\uff09\uff1a\u4e00\u4e2a\u7c7b\u53ea\u80fd\u7ee7\u627f\u4e00\u4e2a\u7236\u7c7b\u65b9\u5f0f\u3002 class DerivedClassName(BaseClassName): <statement-1> . . . <statement-N> \u591a\u7ee7\u627f\uff08Multiple Inheritance\uff09\uff1a\u4e00\u4e2a\u7c7b\u53bb\u7ee7\u627f\u591a\u4e2a\u7c7b\u7684\u65b9\u5f0f\u3002\u5b9a\u4e49\u8bed\u53e5\u5982\u4e0b\u6240\u793a class DerivedClassName(Base1, Base2, Base3): <statement-1> . . . <statement-N> \u5728\u6700\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u641c\u7d22\u4ece\u7236\u7c7b\u6240\u7ee7\u627f\u5c5e\u6027\u7684\u64cd\u4f5c\u662f\u6df1\u5ea6\u4f18\u5148\uff08depth-first\uff09\u3001\u4ece\u5de6\u81f3\u53f3\uff08left-to-right\uff09\u7684\uff0c\u5f53\u5c42\u6b21\u7ed3\u6784\u4e2d\u5b58\u5728\u91cd\u53e0\u65f6\u4e0d\u4f1a\u5728\u540c\u4e00\u4e2a\u7c7b\u4e2d\u641c\u7d22\u4e24\u6b21\u3002 \u56e0\u6b64\uff0c\u5982\u679c\u67d0\u4e00\u5c5e\u6027\u5728 DerivedClassName \u4e2d\u672a\u627e\u5230\uff0c\u5219\u4f1a\u5230 Base1 \u4e2d\u641c\u7d22\u5b83\uff0c\u7136\u540e\uff08\u9012\u5f52\u5730\uff09\u5230 Base1 \u7684\u57fa\u7c7b\u4e2d\u641c\u7d22\uff0c\u5982\u679c\u5728\u90a3\u91cc\u672a\u627e\u5230\uff0c\u518d\u5230 Base2 \u4e2d\u641c\u7d22\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002 \u771f\u5b9e\u60c5\u51b5\u66f4\u590d\u6742\uff1b\u65b9\u6cd5\u89e3\u6790\u987a\u5e8f\u4f1a\u52a8\u6001\u6539\u53d8\u4ee5\u652f\u6301\u5bf9 super() \u7684\u534f\u540c\u8c03\u7528\u3002 \u8fd9\u79cd\u65b9\u5f0f\u5728\u67d0\u4e9b\u5176\u4ed6\u591a\u91cd\u7ee7\u627f\u578b\u8bed\u8a00\u4e2d\u88ab\u79f0\u4e3a \u540e\u7eed\u65b9\u6cd5\u8c03\u7528\uff08call-next-method\uff09 \uff0c\u5b83\u6bd4 \u5355\u7ee7\u627f\uff08single-inheritance\uff09 \u8bed\u8a00\u4e2d\u7684 uper \u8c03\u7528\u66f4\u5f3a\u5927\u3002 \u52a8\u6001\u6539\u53d8\u987a\u5e8f\u662f\u6709\u5fc5\u8981\u7684\uff0c\u56e0\u4e3a\u6240\u6709\u591a\u91cd\u7ee7\u627f\u7684\u60c5\u51b5\u90fd\u4f1a\u663e\u793a\u51fa\u4e00\u4e2a\u6216\u66f4\u591a\u7684\u83f1\u5f62\u5173\u8054\uff08diamond relationships\uff09\uff08\u5373\u81f3\u5c11\u6709\u4e00\u4e2a\u7236\u7c7b\u53ef\u901a\u8fc7\u591a\u6761\u8def\u5f84\u88ab\u6700\u5e95\u5c42\u7c7b\u6240\u8bbf\u95ee\uff09\u3002 \u4f8b\u5982\uff0c\u6240\u6709\u7c7b\u90fd\u662f\u7ee7\u627f\u81ea object \uff0c\u56e0\u6b64\u4efb\u4f55\u591a\u91cd\u7ee7\u627f\u7684\u60c5\u51b5\u90fd\u63d0\u4f9b\u4e86\u4e00\u6761\u4ee5\u4e0a\u7684\u8def\u5f84\u53ef\u4ee5\u901a\u5411 object \u3002 \u4e3a\u4e86\u786e\u4fdd\u57fa\u7c7b\u4e0d\u4f1a\u88ab\u8bbf\u95ee\u4e00\u6b21\u4ee5\u4e0a\uff0c\u52a8\u6001\u7b97\u6cd5\u4f1a\u7528\u4e00\u79cd\u7279\u6b8a\u65b9\u5f0f\u5c06\u641c\u7d22\u987a\u5e8f\u7ebf\u6027\u5316\uff0c \u4fdd\u7559\u6bcf\u4e2a\u7c7b\u6240\u6307\u5b9a\u7684\u4ece\u5de6\u81f3\u53f3\u7684\u987a\u5e8f\uff0c\u53ea\u8c03\u7528\u6bcf\u4e2a\u7236\u7c7b\u4e00\u6b21\uff0c\u5e76\u4e14\u4fdd\u6301\u5355\u8c03\uff08monotonic\uff09\uff08\u5373\u4e00\u4e2a\u7c7b\u53ef\u4ee5\u88ab\u5b50\u7c7b\u5316\u800c\u4e0d\u5f71\u54cd\u5176\u7236\u7c7b\u7684\u4f18\u5148\u987a\u5e8f\uff09\u3002 \u603b\u800c\u8a00\u4e4b\uff0c\u8fd9\u4e9b\u7279\u6027\u4f7f\u5f97\u8bbe\u8ba1\u5177\u6709\u591a\u91cd\u7ee7\u627f\u7684\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u7c7b\u6210\u4e3a\u53ef\u80fd\u3002 \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5b9a\u4e49\u4e863\u4e2a\u7c7b\u548c\u7ee7\u627f\u5173\u7cfb\u3002 class F(): def drink(self): print(\"Drink Beer\") class M(): def drink(self): print(\"Drink Red Wine\") class C(F, M): def drink(self): print(\"Drink Water\") \u6267\u884c\u7ed3\u679c\u662f c = C() c.drink() # Drink Water \u65b9\u6cd51\uff1a\u6309\u7167mro\u8fdb\u884c\u7ee7\u627f\u67e5\u627e\u3002 \u5982\u679c\u628a C \u7c7b\u6539\u5199\u4e3a\u5982\u4e0b\uff0c\u53ef\u4ee5\u8c03\u7528\u7236\u7c7b\uff0c\u53c2\u7167 C \u7c7b\u7684mro\u8fdb\u884c\uff0c mro \u91cc\u9762\u7c7b F \u7684\u4e0a\u4e00\u7ea7\u662f\u7c7b M \uff0c\u6240\u4ee5\u7c7b F \u4e2d\u7684 super() \u5c31\u662f\u6307\u7c7b M \u3002 class C(F, M): def drink(self): super().drink() print(\"Drink Water\") c = C() c.drink() # Drink Beer # Drink Water C.mro() # [<class '__main__.C'>, <class '__main__.F'>, <class '__main__.M'>, <class 'object'>] \u65b9\u6cd52\uff1a\u201c\u6307\u540d\u9053\u59d3\u201d\u8c03\u7528\u3002\u5982\u679c\u628a C \u7c7b\u6539\u5199\u4e3a\u5982\u4e0b\uff0c\u53ef\u4ee5\u8c03\u7528 M \u7c7b\u3002 class C(F, M): def drink(self): M.drink(self) print(\"Drink Water\") c = C() c.drink() # Drink Red Wine # Drink Water \u83f1\u5f62\u7ee7\u627f\u548c\u7ee7\u627f\u5173\u7cfb\u68c0\u6d4b \u83f1\u5f62\u7ee7\u627f\u7684\u63cf\u8ff0\u662f\uff0c\u7c7b A \u4f5c\u4e3a\u57fa\u7c7b\uff08\u8fd9\u91cc\u57fa\u7c7b\u662f\u6307\u975e object \u7c7b\uff09\uff0c\u7c7b B \u548c\u7c7b C \u540c\u65f6\u7ee7\u627f\u7c7b A \uff0c\u7136\u540e\u7c7b D \u53c8\u7ee7\u627f\u7c7b B \u548c\u7c7b C \uff0c\u5982\u4e0b\u56fe\uff0c\u770b\u8d77\u6765\u50cf\u4e2a\u94bb\u77f3\u7684\u5f62\u72b6\u3002 A / \\ B C \\ / D \u5728\u8fd9\u79cd\u7ed3\u6784\u4e2d\uff0c\u5728\u8c03\u7528\u987a\u5e8f\u4e0a\u5c31\u4f1a\u51fa\u73b0\u7591\u60d1\uff0c\u8c03\u7528\u987a\u5e8f\u7a76\u7adf\u662f\u4ee5\u4e0b\u54ea\u4e00\u79cd\u987a\u5e8f\u5462\uff1f D->B->A->C\uff08\u6df1\u5ea6\u4f18\u5148\uff09 D->B->C->A\uff08\u5e7f\u5ea6\u4f18\u5148\uff09 \u770b\u4e0b\u9762\u4ee3\u7801\uff0c\u5728Python3\u4e2d\uff0c \u83f1\u5f62 \u7684\u591a\u7ee7\u627f\u5173\u7cfb\u662f\u6309\u7167D->B->C->A \u5e7f\u5ea6\u4f18\u5148 \u7684\u641c\u7d22\u65b9\u5f0f\u3002 class A(): pass class B(A): def test(self): print(\"init B.test()\") class C(A): def test(self): print(\"init C.test()\") class D(B, C): pass d = D() d.test() # init B.test() D.mro() # [<class '__main__.D'>, <class '__main__.B'>, <class '__main__.C'>, <class '__main__.A'>, <class 'object'>] \u5bf9\u4e8e\u4e0b\u9762\u8fd9\u79cd \u975e\u83f1\u5f62 \u7684\u591a\u7ee7\u627f\u5173\u7cfb\uff0c\u67e5\u627e\u987a\u5e8f\u662fA->B->E->C->F->D \u6df1\u5ea6\u4f18\u5148 \u7684\u641c\u7d22\u65b9\u5f0f\u3002 E F | | B(E) C(F) D | | | \\ | / \\ | / A(B,C,D) \u4ee3\u7801\u5b9e\u73b0\uff1a class D(): def test(self): print(\"init D.test()\") class F(): def test(self): print(\"init F.test()\") class C(F): pass class E(): pass class B(E): pass class A(B, C, D): pass a = A() a.test() # init F.test() A.mro() # [<class '__main__.A'>, <class '__main__.B'>, <class '__main__.E'>, <class '__main__.C'>, <class '__main__.F'>, <class '__main__.D'>, <class 'object'>] \u603b\u7ed3\uff1a \u7ee7\u627f\u7ed3\u6784\u8981\u5c3d\u91cf\u7b80\u5355\uff0c\u4e0d\u8981\u8fc7\u4e8e\u590d\u6742\u3002 \u63a8\u8350\u4f7f\u7528minxins\u673a\u5236\uff0c\u5728\u591a\u7ee7\u627f\u80cc\u666f\u4e0b\uff0c\u6ee1\u8db3\u7ee7\u627f\u7684\u4ec0\u4e48\u662f\u4ec0\u4e48\u7684\u5173\u7cfb\uff08is-a\uff09 \u591a\u7ee7\u627f\u5173\u7cfb\u7684minxins\u673a\u5236 \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5982\u679c\u5728 Vehicle \u7c7b\u4e2d\u5b9a\u4e49\u4e86 fly \u7684\u65b9\u6cd5\uff0c\u4f1a\u5bfc\u81f4 Car(Vehicle) \u7684\u7ee7\u627f\u5173\u7cfb\u51fa\u73b0\u77db\u76fe\uff0c\u6c7d\u8f66\u5e76\u4e0d\u4f1a\u98de\uff0c\u4f46\u6309\u7167\u4e0a\u8ff0\u7ee7\u627f\u5173\u7cfb\uff0c\u6c7d\u8f66\u4e5f\u80fd\u98de\u4e86\u3002 \u4f46\u662f\u5982\u679c\u6c11\u822a\u98de\u673a\u548c\u76f4\u5347\u673a\u90fd\u5404\u81ea\u5199\u81ea\u5df1\u7684\u98de\u884cfly\u65b9\u6cd5\uff0c\u53c8\u8fdd\u80cc\u4e86\u4ee3\u7801\u5c3d\u53ef\u80fd\u91cd\u7528\u7684\u539f\u5219\u3002 class Vehicle: # \u4ea4\u901a\u5de5\u5177 def fly(self): ''' \u98de\u884c\u529f\u80fd\u76f8\u5e94\u7684\u4ee3\u7801 ''' print(\"I am flying\") # \u6c11\u822a\u98de\u673a class CivilAircraft(Vehicle): pass # \u76f4\u5347\u98de\u673a class Helicopter(Vehicle): pass # \u6c7d\u8f66 class Car(Vehicle): pass Python\u4e2d\u6ca1\u6709\u7c7b\u4f3cJava\u63a5\u53e3interface\u7684\u529f\u80fd\uff0c\u4f46\u63d0\u4f9b\u4e86Mixins\u673a\u5236\u3002 Python\u5bf9\u4e8e Mixin \u7c7b\u7684\u547d\u540d\u65b9\u5f0f\u4e00\u822c\u4ee5 Mixin , able , ible \u4e3a\u540e\u7f00\u3002 Mixin \u7c7b\u5fc5\u987b\u529f\u80fd\u5355\u4e00\uff0c\u5982\u679c\u6709\u591a\u4e2a\u529f\u80fd\uff0c\u90a3\u5c31\u5199\u591a\u4e2aMixin\u7c7b\u3002 \u4e00\u4e2a\u7c7b\u53ef\u4ee5\u7ee7\u627f\u591a\u4e2a Mixin \u7c7b\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u9075\u5faa\u7ee7\u627f\u7684\u201cis-a\u201d\u539f\u5219\uff0c\u53ea\u80fd\u7ee7\u627f\u4e00\u4e2a\u6807\u8bc6\u5176\u5f52\u5c5e\u542b\u4e49\u7684\u7236\u7c7b Mixin \u7c7b\u4e0d\u4f9d\u8d56\u4e8e\u5b50\u7c7b\u7684\u5b9e\u73b0\u3002 \u5b50\u7c7b\u5373\u4fbf\u6ca1\u6709\u7ee7\u627f\u8fd9\u4e2a Mixin \u7c7b\u7c7b\uff0c\u4e5f\u7167\u6837\u53ef\u4ee5\u5de5\u4f5c\uff0c\u5c31\u662f\u7f3a\u5c11\u4e86\u67d0\u4e2a\u529f\u80fd\u3002 \u6211\u4eec\u5b9a\u4e49\u7684 Mixin \u7c7b\u8d8a\u591a\uff0c\u5b50\u7c7b\u7684\u4ee3\u7801\u53ef\u8bfb\u6027\u5c31\u4f1a\u8d8a\u5dee\u3002 # \u4ea4\u901a\u5de5\u5177 class Vehicle: pass # \u4e3a\u5f53\u524d\u7c7b\u6df7\u5165\u4e00\u4e9b\u529f\u80fd\uff0c\u4e0d\u662f\u4e00\u4e2a\u5355\u7eaf\u7684\u7c7b class FlyableMixin: def fly(self): ''' \u98de\u884c\u529f\u80fd\u76f8\u5e94\u7684\u4ee3\u7801 ''' print(\"I am flying\") # \u6c11\u822a\u98de\u673a class CivilAircraft(FlyableMixin, Vehicle): pass # \u76f4\u5347\u98de\u673a class Helicopter(FlyableMixin, Vehicle): pass # \u6c7d\u8f66 class Car(Vehicle): pass \u7ec4\u5408\uff08Class Combination\uff09 \u5728\u4e00\u4e2a\u7c7b\u4e2d\u4ee5\u53e6\u4e00\u4e2a\u7c7b\u7684\u5bf9\u8c61\u4f5c\u4e3a\u6570\u636e\u5c5e\u6027\uff0c\u79f0\u4e3a\u7c7b\u7684 \u7ec4\u5408 \u3002\u7ec4\u5408\u4e0e\u7ee7\u627f\u90fd\u662f\u7528\u6765\u89e3\u51b3\u4ee3\u7801\u7684\u91cd\u7528\u6027\u95ee\u9898\u3002 \u7ee7\u627f\u4f53\u73b0\u201c\u662f\u201d\u7684\u5173\u7cfb\uff0c\u5f53\u7c7b\u4e4b\u95f4\u6709\u5f88\u591a\u76f8\u540c\u4e4b\u5904\uff0c\u7528\u7ee7\u627f\u3002 \u7ec4\u5408\u4f53\u73b0\u201c\u6709\u201d\u7684\u5173\u7cfb\uff0c\u5f53\u7c7b\u4e4b\u95f4\u6709\u663e\u8457\u4e0d\u540c\uff0c\u4e00\u4e2a\u7c7b\u662f\u53e6\u4e00\u4e2a\u7c7b\u7684\u5c5e\u6027\u662f\uff0c\u7528\u7ec4\u5408\u3002 \u4e0b\u4f8b\u662f\u8ba1\u7b97\u5706\u73af\u7684\u9762\u79ef\u548c\u5468\u957f\uff0c\u5706\u73af\u662f\u7531\u4e24\u4e2a\u5706\u7ec4\u6210\u7684\uff0c\u5706\u73af\u7684\u9762\u79ef\u662f\u5916\u9762\u5706\u7684\u9762\u79ef\u51cf\u53bb\u5185\u90e8\u5706\u7684\u9762\u79ef\u3002\u5706\u73af\u7684\u5468\u957f\u662f\u5185\u90e8\u5706\u7684\u5468\u957f\u52a0\u4e0a\u5916\u90e8\u5706\u7684\u5468\u957f\u3002 \u8fd9\u4e2a\u4f8b\u5b50\u6f14\u793a\u4e86\u7c7b ring \u91cc\u9762\u7684\u5c5e\u6027 circle1 \u548c circle2 \u6b63\u662f\u53e6\u4e00\u4e2a\u7c7b Circle \u3002 from math import pi class Circle(): def __init__(self, r): self.r = r def area(self): return pi * self.r * self.r def perimeter(self): return 2 * pi * self.r class Ring(): def __init__(self, r1, r2): self.circle1 = Circle(r1) self.circle2 = Circle(r2) def area(self): return abs(self.circle1.area() - self.circle2.area()) def permiter(self): return self.circle1.perimeter() + self.circle2.perimeter() ring = Ring(5, 8) print(ring.area()) # 122.52211349000193 print(ring.permiter()) # 81.68140899333463 \u4e0b\u9762\u7684\u4f8b\u5b50\u6f14\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f20\u53c2\u7684\u65b9\u5f0f\u8fdb\u884c\u7c7b\u7684\u7ec4\u5408\u3002 class Birthday(): def __init__(self, year, month, day): self.year = year self.month = month self.day = day class Course(): def __init__(self, course_name, course_period): self.course_name = course_name self.course_period = course_period class Professor(): def __init__(self, name, gender, birth, course): self.name = name self.gender = gender self.birth = birth self.course = course def teach(self): print(f\"Professor name: {self.name}; Gender: {self.gender}; Birthday: {self.birth.year}-{self.birth.month}{self.birth.day}, Course name: {self.course.course_name} and period: {self.course.course_period}\") prof = Professor('Tom', 'Male', Birthday(1985, 5, 5), Course('Chinese', '2022/3/1 ~ 2022/6/30')) prof.teach() # Professor name: Tom; Gender: Male; Birthday: 1985-55, Course name: Chinese and period: 2022/3/1 ~ 2022/6/30 \u591a\u6001 Polymorphism \u591a\u6001\u610f\u5473\u7740\u76f8\u540c\u7684\u51fd\u6570\u540d\u7528\u4e8e\u4e0d\u540c\u7684\u60c5\u5f62\u3002 \u5982\u4e0b\u4f8b\uff0c len() \u88ab\u7528\u4e8e\u4e0d\u540c\u7684\u60c5\u5f62\u3002 # len() being used for a string print(len(\"geeks\")) # 5 # len() being used for a list print(len([10, 20, 30])) # 3 \u7c7b\u65b9\u6cd5\u7684\u591a\u6001\u6027 \u4e0b\u9762\u7684\u4ee3\u7801\u5c55\u793a\u4e86 Python \u5982\u4f55\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u7c7b\u7c7b\u578b\u3002 \u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u904d\u5386\u5bf9\u8c61\u5143\u7ec4\u7684 for \u5faa\u73af\u3002 \u7136\u540e\u8c03\u7528\u65b9\u6cd5\u800c\u4e0d\u7528\u5173\u5fc3\u6bcf\u4e2a\u5bf9\u8c61\u662f\u54ea\u4e2a\u7c7b\u7c7b\u578b\u3002 \u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u65b9\u6cd5\u5b9e\u9645\u4e0a\u5b58\u5728\u4e8e\u6bcf\u4e2a\u7c7b\u4e2d\u3002 class India(): def capital(self): print(\"New Delhi is the capital of India.\") def language(self): print(\"Hindi is the most widely spoken language of India.\") def type(self): print(\"India is a developing country.\") class USA(): def capital(self): print(\"Washington, D.C. is the capital of USA.\") def language(self): print(\"English is the primary language of USA.\") def type(self): print(\"USA is a developed country.\") obj_ind = India() obj_usa = USA() for country in (obj_ind, obj_usa): country.capital() country.language() country.type() # New Delhi is the capital of India. # Hindi is the most widely spoken language of India. # India is a developing country. # Washington, D.C. is the capital of USA. # English is the primary language of USA. # USA is a developed country. \u7ee7\u627f\u7684\u591a\u6001\u6027 \u5728 Python \u4e2d\uff0c\u591a\u6001\u5141\u8bb8\u6211\u4eec\u5728\u5b50\u7c7b\u4e2d\u5b9a\u4e49\u4e0e\u7236\u7c7b\u4e2d\u7684\u65b9\u6cd5\u540c\u540d\u7684\u65b9\u6cd5\u3002 \u5728\u7ee7\u627f\u4e2d\uff0c\u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u7684\u65b9\u6cd5\u3002 \u4f46\u662f\uff0c\u53ef\u4ee5\u4fee\u6539\u4ece\u7236\u7c7b\u7ee7\u627f\u7684\u5b50\u7c7b\u4e2d\u7684\u65b9\u6cd5\u3002 \u8fd9\u5728\u4ece\u7236\u7c7b\u7ee7\u627f\u7684\u65b9\u6cd5\u4e0d\u592a\u9002\u5408\u5b50\u7c7b\u7684\u60c5\u51b5\u4e0b\u7279\u522b\u6709\u7528\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5728\u5b50\u7c7b\u4e2d\u91cd\u65b0\u5b9e\u73b0\u8be5\u65b9\u6cd5\u3002 \u8fd9\u79cd\u5728\u5b50\u7c7b\u4e2d\u91cd\u65b0\u5b9e\u73b0\u65b9\u6cd5\u7684\u8fc7\u7a0b\u79f0\u4e3a \u65b9\u6cd5\u8986\u76d6\uff08Method Overriding\uff09 \u3002 class Bird: def intro(self): print(\"There are many types of birds.\") def flight(self): print(\"Most of the birds can fly but some cannot.\") class sparrow(Bird): def flight(self): print(\"Sparrows can fly.\") class ostrich(Bird): def flight(self): print(\"Ostriches cannot fly.\") obj_bird = Bird() obj_spr = sparrow() obj_ost = ostrich() obj_bird.intro() # There are many types of birds. obj_bird.flight() # Most of the birds can fly but some cannot. obj_spr.intro() # There are many types of birds. obj_spr.flight() # Sparrows can fly. obj_ost.intro() # There are many types of birds. obj_ost.flight() # Ostriches cannot fly. \u51fd\u6570\u548c\u5bf9\u8c61\u7684\u591a\u6001\u6027 \u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u53ef\u4ee5\u63a5\u53d7\u4efb\u4f55\u5bf9\u8c61\u7684\u51fd\u6570\uff0c\u5141\u8bb8\u591a\u6001\u6027\u3002 \u5728\u4e0b\u9762\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a func() \u7684\u51fd\u6570\uff0c\u4f20\u5165\u53c2\u6570\u662f obj \u7684\u5bf9\u8c61\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u8c03\u7528\u4e09\u4e2a\u65b9\u6cd5\uff0c\u5373 capital() \u3001 language() \u548c type() \uff0c\u6bcf\u4e2a\u65b9\u6cd5\u90fd\u5b9a\u4e49\u5728 India \u548c USA \u4e24\u4e2a\u7c7b\u4e2d\u3002 \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u76f8\u540c\u7684 func() \u51fd\u6570\u8c03\u7528\u5b83\u4eec\u7684\u52a8\u4f5c\uff1a class India(): def capital(self): print(\"New Delhi is the capital of India.\") def language(self): print(\"Hindi is the most widely spoken language of India.\") def type(self): print(\"India is a developing country.\") class USA(): def capital(self): print(\"Washington, D.C. is the capital of USA.\") def language(self): print(\"English is the primary language of USA.\") def type(self): print(\"USA is a developed country.\") def func(obj): obj.capital() obj.language() obj.type() obj_ind = India() obj_usa = USA() func(obj_ind) # New Delhi is the capital of India. # Hindi is the most widely spoken language of India. # India is a developing country. func(obj_usa) # Washington, D.C. is the capital of USA. # English is the primary language of USA. # USA is a developed country. \u9e2d\u5b50\u7c7b\u578b\uff08Ducking Typing\uff09\u548c\u767d\u9e45\u7c7b\u578b\uff08Goose Typing\uff09 \u5728Python\u4e2d\u5b9e\u73b0\u591a\u6001\u4e3b\u8981\u6709\u4e24\u79cd\u673a\u5236\uff1a\u767d\u9e45\u7c7b\u578b\u548c\u9e2d\u5b50\u7c7b\u578b\u3002\u767d\u9e45\u7c7b\u578b\u548c\u9e2d\u5b50\u7c7b\u578b\u4e0d\u4ec5\u662f\u4e24\u79cd\u673a\u5236\uff0c\u4e5f\u662f\u4e24\u79cd\u4e0d\u540c\u7684\u7f16\u7a0b\u98ce\u683c\u3002 \u4e0b\u9762\u662f\u4e00\u4e2a\u6253\u5370\u5546\u54c1\u4ef7\u683c\u7684\u4f8b\u5b50\uff0c\u5206\u522b\u7528\u9e2d\u5b50\u7c7b\u578b\u548c\u767d\u9e45\u7c7b\u578b\u5b9e\u73b0\u3002 \u9e2d\u5b50\u7c7b\u578b \u5728\u9e2d\u5b50\u7c7b\u578b\u7684\u5b9e\u73b0\u4e2d\uff0c\u6211\u4eec\u53ea\u9700\u8981\u4fdd\u8bc1\u8c03\u7528 price \u65b9\u6cd5\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u6709 price \u65b9\u6cd5\u5373\u53ef\u3002 class Food: def price(self): print(\"{} price:$4\".format(__class__.__name__)) class Clothes: def price(self): print(\"{} price:$5\".format(__class__.__name__)) class Coffee: def price(self): print(\"{} price:$6\".format(__class__.__name__)) if __name__ == '__main__': goods = [Food(), Clothes(), Coffee()] for good in goods: good.price() # Food price:$4 # Clothes price:$5 # Coffee price:$6 \u767d\u9e45\u7c7b\u578b \u5728\u767d\u9e45\u7c7b\u578b\u4e2d\uff0c\u76f4\u63a5\u8ba9\u6240\u6709\u5bf9\u8c61\u7684\u7c7b\u7ee7\u627f\u7236\u7c7b Good \u4e2d\u7684\u62bd\u8c61\u65b9\u6cd5 price \u3002Python\u4e2d\u7684\u767d\u9e45\u7c7b\u578b\u673a\u5236\u5c31\u662f\u5f3a\u7c7b\u578b\u8bed\u8a00\u4e2d\u5b9e\u73b0\u591a\u6001\u7684\u6807\u51c6\u6a21\u5f0f\uff0c\u5373\u901a\u8fc7\u8c03\u53d6\u7236\u7c7b\u7684\u865a\u51fd\u6570\u6216\u8005\u7ee7\u627f\u7684\u51fd\u6570\u6765\u5b8c\u6210\u4e0d\u540c\u7684\u884c\u4e3a\u3002 import abc class Good(abc.ABC): @abc.abstractmethod def price(self): pass class Food(Good): def price(self): print(\"{} price:$4\".format(__class__.__name__)) class Clothes(Good): def price(self): print(\"{} price:$5\".format(__class__.__name__)) if __name__ == '__main__': goods = [Food(), Clothes(), Coffee()] for good in goods: good.price() # Food price:$4 # Clothes price:$5 # Coffee price:$6 \u7c7b\u65b9\u6cd5\uff08Class method\uff09\u548c\u9759\u6001\u65b9\u6cd5\uff08Static Method\uff09 \u7c7b\u65b9\u6cd5\uff08Class method\uff09\u4e5f\u53eb\u7ed1\u5b9a\u65b9\u6cd5\uff0c\u5fc5\u987b\u628a\u7c7b\u4f5c\u4e3a\u4f20\u5165\u53c2\u6570\uff0c\u4f7f\u7528 cls \u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u4f20\u5165\u53c2\u6570\uff0c\u800c\u9759\u6001\u65b9\u6cd5\uff08Static Method\uff09\uff0c\u4e5f\u53eb\u975e\u7ed1\u5b9a\u65b9\u6cd5\uff0c\u4e0d\u9700\u8981\u7279\u5b9a\u7684\u53c2\u6570\u3002 \u7c7b\u65b9\u6cd5\u662f\u7ed1\u5b9a\u5230\u7c7b\u7684\uff0c\u4e0d\u662f\u7ed1\u5b9a\u5230\u7c7b\u5bf9\u8c61\uff0c\u6240\u4ee5\u7c7b\u65b9\u6cd5\u53ef\u4ee5\u8bbf\u95ee\u6216\u4fee\u6539\u7c7b\uff0c\u5e76\u5bf9\u6240\u6709\u7c7b\u5b9e\u4f8b\u751f\u6548\u3002 \u9759\u6001\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u6216\u4fee\u6539\u7c7b\uff0c\u56e0\u4e3a\u9759\u6001\u65b9\u6cd5\u662f\u4e0d\u77e5\u9053\u7c7b\u672c\u8eab\u7684\uff0c\u9759\u6001\u65b9\u6cd5\u662f\u5c5e\u4e8e\u5de5\u5177\u7c7b\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4f20\u5165\u7684\u53c2\u6570\u5b8c\u6210\u7279\u5b9a\u7684\u529f\u80fd\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u666e\u901a\u51fd\u6570\u800c\u5df2\u3002 Python\u4e2d\u4f7f\u7528 @classmethod \u88c5\u9970\u5668\uff08decorator\uff09\u6765\u521b\u5efa\u4e00\u4e2a\u7c7b\u65b9\u6cd5\uff0c\u7528@staticmethod\u88c5\u9970\u5668\u6765\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u65b9\u6cd5\u3002 \u8bed\u6cd5\u683c\u5f0f\uff1a @classmethod def fun(cls, arg1, arg2, ...): \u5176\u4e2d\uff1a fun: \u9700\u8981\u8f6c\u6362\u6210\u7c7b\u65b9\u6cd5\u7684\u51fd\u6570 returns: \u51fd\u6570\u7684\u7c7b\u65b9\u6cd5 classmethod() \u65b9\u6cd5\u7ed1\u5b9a\u5230\u7c7b\u800c\u4e0d\u662f\u5bf9\u8c61\u3002\u7c7b\u65b9\u6cd5\u53ef\u4ee5\u88ab\u7c7b\u548c\u5bf9\u8c61\u8c03\u7528\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u7c7b\u6216\u5bf9\u8c61\u8fdb\u884c\u8c03\u7528\u3002 \u4f8b1\uff1a\u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684 classmethod \u3002 \u521b\u5efa\u4e00\u4e2a\u7c7b Training \uff0c\u6709\u7c7b\u53d8\u91cf course \u548c\u65b9\u6cd5 purchase \u3002 \u6211\u4eec\u901a\u8fc7\u628a\u51fd\u6570 Training.purchase \u4f20\u7ed9 classmethod() \uff0c\u628a\u8be5\u65b9\u6cd5\u8f6c\u6210\u7c7b\u65b9\u6cd5\uff0c\u7136\u540e\u76f4\u63a5\u8c03\u7528\u5b83\uff0c\u800c\u65e0\u9700\u5148\u521b\u5efa\u5bf9\u8c61\u3002 \u53ef\u4ee5\u770b\u51fa\u8f6c\u6362\u524d\u540e Training.purchase \u7684\u7c7b\u578b\u53d8\u5316\u3002 class Training: course = 'Python for Data Analysis' def purchase(obj): print(\"Puchase course : \", obj.course) type(Training.purchase) # <class 'function'> Training.purchase = classmethod(Training.purchase) Training.purchase() # Puchase course : Python for Data Analysis type(Training.purchase) # <class 'method'> \u4f8b2\uff1a\u4f7f\u7528\u88c5\u9970\u5668 @classmethod \u521b\u5efa\u5de5\u5382\u7c7b\u3002 class Training: def __init__(self, course): self.course = course @classmethod def purchase(cls, course): return cls(course) def display(self): print('Purchase course: ', self.course) training = Training(\"Python for Data Analysis\") training.display() # Purchase course: Python for Data Analysis \u4f8b3\uff1a\u901a\u8fc7 staticmethod() \u548c classmethod() \u6765\u68c0\u67e5\u4e00\u4e2aperson\u662f\u5426\u662fadult\u3002 person1\u662f\u901a\u8fc7\u59d3\u540d\u548c\u5e74\u9f84\u521b\u5efa\u7684\u5b9e\u4f8b\u3002person2\u662f\u901a\u8fc7\u59d3\u540d\u548c\u5e74\u4efd\u521b\u5efa\u7684\u5b9e\u4f8b\u3002 from datetime import date class Person: def __init__(self, name, age): self.name = name self.age = age @classmethod def fromBirthYear(cls, name, year): return cls(name, date.today().year - year) @staticmethod def isAdult(age): return age > 18 person1 = Person('mayank', 21) person2 = Person.fromBirthYear('mayank', 1996) print(person1.age) # 21 print(person2.age) # 26 print(Person.isAdult(22)) # True \u5c0f\u7ed3\uff1a \u82e5\u7c7b\u4e2d\u9700\u8981\u4e00\u4e2a\u529f\u80fd\uff0c\u8be5\u529f\u80fd\u7684\u5b9e\u73b0\u4ee3\u7801\u4e2d\u9700\u8981\u5f15\u7528\u5bf9\u8c61\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u5bf9\u8c61\u65b9\u6cd5\uff1b\u9700\u8981\u5f15\u7528\u7c7b\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u7c7b\u65b9\u6cd5\uff1b\u65e0\u9700\u5f15\u7528\u7c7b\u6216\u5bf9\u8c61\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u9759\u6001\u65b9\u6cd5\u3002 \u7334\u5b50\u8865\u4e01\uff08monkey patch\uff09 \u7334\u5b50\u8865\u4e01\u662f\u52a8\u6001\u4e3a\u5df2\u7ecf\u521b\u5efa\u51fa\u7684\u5bf9\u8c61\u589e\u52a0\u65b0\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u6210\u5458\u7684\u4e00\u79cd\u673a\u5236\uff0c\u4e5f\u5c31\u662f\u52a8\u6001\u6253\u8865\u4e01\u3002 \u5b9e\u4f8b\u5316\u5bf9\u8c61\u7684\u7334\u5b50\u8865\u4e01\u3002 class Test: def __init__(self): self.a = 1 def func1(self, x, y): print(x + y) # \u6b63\u5e38\u5b9e\u4f8b\u5316 test = Test() test.func1(1, 1) # 2 # \u4fee\u6539\u5b9e\u4f8b test.func1 = lambda x, y : print(x + 2 * y) test.func1(1, 1) # 3 # \u901a\u8fc7\u4fee\u6539\u5b9e\u4f8b\uff0c\u8bbf\u95ee\u5185\u90e8\u6210\u5458\u53d8\u91cf\u3002 test.func1 = lambda x, y : print(x + 2 * y + self.a) test.func1(1, 1) # NameError: name 'self' is not defined test.func1 = lambda self, x, y : print(x + 2 * y + self.a) test.func1(test, 1, 1) # 4 \u7c7b\u5bf9\u8c61\u7684\u7334\u5b50\u8865\u4e01\u3002 class Test: def __init__(self): self.a = 1 def func1(self, x, y): print(x + y) # \u4fee\u6539\u7c7b\u6210\u5458\uff0c\u5b9e\u4f8b\u5316\u540e\u7684\u7ed3\u679c\u5df2\u4fee\u6539\u3002 Test.func1 = lambda self, x, y : print(x + 2 * y) test = Test() test.func1(1, 1) # 3 # \u4fee\u6539\u7c7b\u6210\u5458\uff0c\u5e76\u8bbf\u95ee\u6210\u5458\u53d8\u91cf\uff0c\u5b9e\u4f8b\u5316\u540e\u7684\u7ed3\u679c\u5df2\u4fee\u6539\u3002 Test.func1 = lambda self, x, y : print(x + 2 * y + self.a) test = Test() test.func1(1, 1) # 4 # \u589e\u52a0\u7c7b\u6210\u5458\u3002 Test.func2 = lambda self, p, q: print(p + 3 * q + self.a) test = Test() test.func1(1, 1) # 4 test.func2(1, 3) # 11 \u79c1\u6709\u53d8\u91cf Private Variables \u90a3\u79cd\u4ec5\u9650\u4ece\u4e00\u4e2a\u5bf9\u8c61\u5185\u90e8\u8bbf\u95ee\u7684\u201c\u79c1\u6709\u201d\u5b9e\u4f8b\u53d8\u91cf\uff08\u201cPrivate\u201d instance variables\uff09\u5728 Python \u4e2d\u5e76\u4e0d\u5b58\u5728\u3002 \u4f46\u662f\uff0c\u5927\u591a\u6570 Python \u4ee3\u7801\u90fd\u9075\u5faa\u8fd9\u6837\u4e00\u4e2a\u7ea6\u5b9a\uff1a\u5e26\u6709 \u4e00\u4e2a\u524d\u7f00\u4e0b\u5212\u7ebf \u7684\u540d\u79f0 (\u4f8b\u5982 _spam ) \u5e94\u8be5\u88ab\u5f53\u4f5c\u662f API \u7684\u975e\u516c\u6709\uff08non-public\uff09\u90e8\u5206 (\u65e0\u8bba\u5b83\u662f\u51fd\u6570\u3001\u65b9\u6cd5\u6216\u662f\u6570\u636e\u6210\u5458)\u3002 \u8fd9\u5e94\u5f53\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5b9e\u73b0\u7ec6\u8282\uff0c\u53ef\u80fd\u4e0d\u7ecf\u901a\u77e5\u5373\u52a0\u4ee5\u6539\u53d8\u3002 \u7531\u4e8e\u5b58\u5728\u5bf9\u4e8e\u7c7b\u79c1\u6709\u6210\u5458\uff08class-private members\uff09\u7684\u6709\u6548\u4f7f\u7528\u573a\u666f\uff08\u4f8b\u5982\u907f\u514d\u540d\u79f0\u4e0e\u5b50\u7c7b\u6240\u5b9a\u4e49\u7684\u540d\u79f0\u76f8\u51b2\u7a81\uff09\uff0c\u56e0\u6b64\u5b58\u5728\u5bf9\u6b64\u79cd\u673a\u5236\u7684\u6709\u9650\u652f\u6301\uff0c\u79f0\u4e3a \u540d\u79f0\u6539\u5199\uff08name mangling\uff09 \u3002 \u4efb\u4f55\u5f62\u5f0f\u4e3a __spam \u7684\u6807\u8bc6\u7b26\uff08\u81f3\u5c11\u5e26\u6709 \u4e24\u4e2a\u524d\u7f00\u4e0b\u5212\u7ebf \uff0c\u81f3\u591a\u4e00\u4e2a\u540e\u7f00\u4e0b\u5212\u7ebf\uff09\u7684\u6587\u672c\u5c06\u88ab\u66ff\u6362\u4e3a _classname__spam \uff0c\u5176\u4e2d classname \u4e3a\u53bb\u9664\u4e86\u524d\u7f00\u4e0b\u5212\u7ebf\u7684\u5f53\u524d\u7c7b\u540d\u79f0\u3002 \u8fd9\u79cd\u6539\u5199\u4e0d\u8003\u8651\u6807\u8bc6\u7b26\u7684\u53e5\u6cd5\u4f4d\u7f6e\uff0c\u53ea\u8981\u5b83\u51fa\u73b0\u5728\u7c7b\u5b9a\u4e49\u5185\u90e8\u5c31\u4f1a\u8fdb\u884c\u3002 \u540d\u79f0\u6539\u5199\uff08Name mangling\uff09\u6709\u52a9\u4e8e\u8ba9\u5b50\u7c7b\u91cd\u8f7d\u65b9\u6cd5\uff08\uff09override methods\u800c\u4e0d\u7834\u574f\u7c7b\u5185\u65b9\u6cd5\uff08intraclass method\uff09\u8c03\u7528\u3002\u4f8b\u5982: class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() method class MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) \u4e0a\u9762\u7684\u793a\u4f8b\u5373\u4f7f\u5728 MappingSubclass \u5f15\u5165\u4e86\u4e00\u4e2a __update \u6807\u8bc6\u7b26\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u51fa\u9519\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5728 Mapping \u7c7b\u4e2d\u88ab\u66ff\u6362\u4e3a _Mapping__update \u800c\u5728 MappingSubclass \u7c7b\u4e2d\u88ab\u66ff\u6362\u4e3a _MappingSubclass__update \u3002 \u8bf7\u6ce8\u610f\uff0c\u6539\u5199\u89c4\u5219\uff08mangling rules\uff09\u7684\u8bbe\u8ba1\u4e3b\u8981\u662f\u4e3a\u4e86\u907f\u514d\u610f\u5916\u51b2\u7a81\uff1b\u8bbf\u95ee\u6216\u4fee\u6539\u79c1\u6709\u53d8\u91cf\u4ecd\u7136\u662f\u53ef\u80fd\u7684\u3002\u8fd9\u5728\u7279\u6b8a\u60c5\u51b5\u4e0b\u751a\u81f3\u4f1a\u5f88\u6709\u7528\uff0c\u4f8b\u5982\u5728\u8c03\u8bd5\u5668\uff08debugger\uff09\u4e2d\u3002 \u8bf7\u6ce8\u610f\u4f20\u9012\u7ed9 exec() \u6216 eval() \u7684\u4ee3\u7801\u4e0d\u4f1a\u628a\u53d1\u8d77\u8c03\u7528\u7c7b\u7684\u7c7b\u540d\u89c6\u4f5c\u5f53\u524d\u7c7b\uff1b\u8fd9\u7c7b\u4f3c\u4e8e global \u8bed\u53e5\u7684\u6548\u679c\uff0c\u56e0\u6b64\u8fd9\u79cd\u6548\u679c\u4ec5\u9650\u4e8e\u540c\u65f6\u7ecf\u8fc7\u5b57\u8282\u7801\u7f16\u8bd1\u7684\u4ee3\u7801\u3002 \u540c\u6837\u7684\u9650\u5236\u4e5f\u9002\u7528\u4e8e getattr() , setattr() \u548c delattr() \uff0c\u4ee5\u53ca\u5bf9\u4e8e __dict__ \u7684\u76f4\u63a5\u5f15\u7528\u3002 \u53cd\u5c04(reflection) \u53cd\u5c04(reflection)\u662f\u52a8\u6001\u8bed\u8a00\u7684\u4e00\u4e2a\u7279\u6027\u3002 \u53cd\u5c04\u673a\u5236 \u6307\u7684\u662f\u5728\u7a0b\u5e8f\u7684\u8fd0\u884c\u72b6\u6001\u4e2d\uff0c\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u7c7b\uff0c\u90fd\u53ef\u4ee5\u77e5\u9053\u8fd9\u4e2a\u7c7b\u7684\u6240\u6709\u5c5e\u6027\u548c\u65b9\u6cd5\uff1b\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u90fd\u80fd\u591f\u8c03\u7528\u4ed6\u7684\u4efb\u610f\u65b9\u6cd5\u548c\u5c5e\u6027\u3002\u8fd9\u79cd\u52a8\u6001\u83b7\u53d6\u7a0b\u5e8f\u4fe1\u606f\u4ee5\u53ca\u52a8\u6001\u8c03\u7528\u5bf9\u8c61\u7684\u529f\u80fd\u79f0\u4e3a\u53cd\u5c04\u673a\u5236\u3002 \u901a\u8fc7\u4e0b\u9762\u4f8b\u5b50\u53ef\u77e5\uff0c\u901a\u8fc7 dir(person) \u83b7\u53d6\u4efb\u610f\u4e00\u4e2a\u7c7b\u6216\u8005\u5bf9\u8c61\u7684\u5c5e\u6027\u5217\u8868\u3002\u901a\u8fc7\u5185\u7f6e\u51fd\u6570 hasattr \u3001 getattr \u3001 setattr \u3001 delattr \u64cd\u4f5c\u7c7b\u548c\u5bf9\u8c61\u3002 class Person: def __init__(self, name, age, gender): self.name = name self.age = age self.gender = gender person = Person('Tom', 21, 'Male') print(dir(person)) # ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'age', 'gender', 'name'] # hasattr(object,'name') # \u6309\u5b57\u7b26\u4e32'name'\u5224\u65ad\u6709\u65e0\u5c5e\u6027person.name hasattr(person, 'name') # True # getattr(object, 'name', default=None) # \u7b49\u540c\u4e8eperson.name,\u4e0d\u5b58\u5728\u8be5\u5c5e\u6027\u5219\u8fd4\u56de\u9ed8\u8ba4\u503cNone getattr(person, 'name', None) # 'Tom' # setattr(x, 'y', v) # \u7b49\u540c\u4e8eperson.age = 18 setattr(person, 'age', 18) print(person.age) # 18 # delattr(x, 'y') # \u7b49\u540c\u4e8edel person.age delattr(person, 'age') print(person.age) # AttributeError: 'Person' object has no attribute 'age' \u4e0b\u9762\u662f\u4e00\u4e2a\u5b9e\u9645\u5e94\u7528\u7684\u4f8b\u5b50\u3002 class FtpServer(): def server_run(self): while True: inp = input('Input your command >>:').strip() cmd, file = inp.split() if hasattr(self, cmd): func = getattr(self, cmd) func(file) def get(self, file): print(f'Downloading {file}...') def put(self, file): print(f'Uploading {file}...') ftp_server = FtpServer() ftp_server.server_run() # Input your command >>:get a.ext # Downloading a.ext... # Input your command >>:put a.txt # Uploading a.txt... \u8fed\u4ee3\u5668 Iterators \u5728Python\u4e2d\uff0c\u5927\u591a\u6570\u5bb9\u5668\u5bf9\u8c61\uff08container object\uff09\u90fd\u53ef\u4ee5\u4f7f\u7528 for \u8bed\u53e5: for element in [1, 2, 3]: print(element) for element in (1, 2, 3): print(element) for key in {'one': 1, 'two': 2}: print(key) for char in \"123\": print(char) for line in open(\"myfile.txt\"): print(line, end='') for \u8bed\u53e5\u4f1a\u5728\u5bb9\u5668\u5bf9\u8c61\u4e0a\u8c03\u7528 iter()\u3002 \u8be5\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u5b9a\u4e49\u4e86 __next__() \u65b9\u6cd5\u7684\u8fed\u4ee3\u5668\u5bf9\u8c61\uff0c\u6b64\u65b9\u6cd5\u5c06\u9010\u4e00\u8bbf\u95ee\u5bb9\u5668\u4e2d\u7684\u5143\u7d20\u3002 \u5f53\u5143\u7d20\u7528\u5c3d\u65f6\uff0c __next__() \u5c06\u5f15\u53d1 StopIteration \u5f02\u5e38\u6765\u901a\u77e5\u7ec8\u6b62 for \u5faa\u73af\u3002 \u53ef\u4ee5\u4f7f\u7528 next() \u5185\u7f6e\u51fd\u6570\u6765\u8c03\u7528 __next__() \u65b9\u6cd5\uff1b\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u521a\u521a\u63cf\u8ff0\u7684\u5177\u4f53\u8fd0\u884c\u65b9\u5f0f: >>> s = 'abc' >>> it = iter(s) >>> it <str_iterator object at 0x10c90e650> >>> next(it) 'a' >>> next(it) 'b' >>> next(it) 'c' >>> next(it) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> next(it) StopIteration \u5728\u4e86\u89e3\u4e86\u8fed\u4ee3\u5668\u534f\u8bae\uff08iterator protocol\uff09\u7684\u673a\u5236\u540e\uff0c\u7ed9\u7c7b\u6dfb\u52a0\u8fed\u4ee3\u5668\u5c31\u5f88\u5bb9\u6613\u4e86\u3002 \u5b9a\u4e49\u4e00\u4e2a __iter__() \u65b9\u6cd5\u6765\u8fd4\u56de\u4e00\u4e2a\u5e26\u6709 __next__() \u65b9\u6cd5\u7684\u5bf9\u8c61\u3002 \u5982\u679c\u7c7b\u5df2\u5b9a\u4e49\u4e86 __next__() \uff0c\u5219 __iter__() \u53ef\u4ee5\u7b80\u5355\u5730\u8fd4\u56de self : class Reverse: \"\"\"Iterator for looping over a sequence backwards.\"\"\" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] rev = Reverse('spam') print(iter(rev)) for char in rev: print(char) # m # a # p # s \u751f\u6210\u5668 Generators \u751f\u6210\u5668\uff08Generators\uff09 \u662f\u4e00\u4e2a\u7528\u4e8e\u521b\u5efa\u8fed\u4ee3\u5668\u7684\u7b80\u5355\u800c\u5f3a\u5927\u7684\u5de5\u5177\u3002 \u5b83\u4eec\u7684\u5199\u6cd5\u7c7b\u4f3c\u4e8e\u6807\u51c6\u7684\u51fd\u6570\uff0c\u4f46\u5f53\u5b83\u4eec\u8981\u8fd4\u56de\u6570\u636e\u65f6\u4f1a\u4f7f\u7528 yield \u8bed\u53e5\u3002 \u6bcf\u6b21\u5728\u751f\u6210\u5668\u4e0a\u8c03\u7528 next() \u65f6\uff0c\u5b83\u4f1a\u4ece\u4e0a\u6b21\u79bb\u5f00\u7684\u4f4d\u7f6e\u6062\u590d\u6267\u884c\uff08\u5b83\u4f1a\u8bb0\u4f4f\u4e0a\u6b21\u6267\u884c\u8bed\u53e5\u65f6\u7684\u6240\u6709\u6570\u636e\u503c\uff09\u3002 \u4e00\u4e2a\u521b\u5efa\u751f\u6210\u5668\u7684\u793a\u4f8b\u5982\u4e0b\uff08\u6539\u5199\u4e0a\u9762\u8fed\u4ee3\u5668\u4e2d\u6240\u4e3e\u7684\u4f8b\u5b50\uff09: def reverse(data): for index in range(len(data) - 1, -1, -1): yield data[index] for char in reverse('golf'): print(char) # f # l # o # g \u53ef\u4ee5\u7528\u751f\u6210\u5668\u6765\u5b8c\u6210\u7684\u64cd\u4f5c\u540c\u6837\u53ef\u4ee5\u7528\u524d\u9762\u6240\u63cf\u8ff0\u7684\u57fa\u4e8e\u7c7b\u7684\u8fed\u4ee3\u5668\u6765\u5b8c\u6210\u3002\u4f46\u751f\u6210\u5668\u7684\u5199\u6cd5\u66f4\u4e3a\u7d27\u51d1\uff0c\u56e0\u4e3a\u5b83\u4f1a\u81ea\u52a8\u521b\u5efa __iter__() \u548c __next__() \u65b9\u6cd5\u3002 \u53e6\u4e00\u4e2a\u5173\u952e\u7279\u6027\u5728\u4e8e\u5c40\u90e8\u53d8\u91cf\u548c\u6267\u884c\u72b6\u6001\u4f1a\u5728\u6bcf\u6b21\u8c03\u7528\u4e4b\u95f4\u81ea\u52a8\u4fdd\u5b58\u3002 \u8fd9\u4f7f\u5f97\u8be5\u51fd\u6570\u76f8\u6bd4\u4f7f\u7528 self.index \u548c self.data \u8fd9\u79cd\u5b9e\u4f8b\u53d8\u91cf\u7684\u65b9\u5f0f\u66f4\u6613\u7f16\u5199\u4e14\u66f4\u4e3a\u6e05\u6670\u3002 \u9664\u4e86\u4f1a\u81ea\u52a8\u521b\u5efa\u65b9\u6cd5\u548c\u4fdd\u5b58\u7a0b\u5e8f\u72b6\u6001\uff0c\u5f53\u751f\u6210\u5668\u7ec8\u7ed3\u65f6\uff0c\u5b83\u4eec\u8fd8\u4f1a\u81ea\u52a8\u5f15\u53d1 StopIteration \u3002 \u751f\u6210\u5668\u8868\u8fbe\u5f0f Generator Expressions \u67d0\u4e9b\u7b80\u5355\u7684\u751f\u6210\u5668\u53ef\u4ee5\u5199\u6210\u7b80\u6d01\u7684\u8868\u8fbe\u5f0f\u4ee3\u7801\uff0c\u6240\u7528\u8bed\u6cd5\u7c7b\u4f3c\u5217\u8868\u63a8\u5bfc\u5f0f\uff0c\u4f46\u5916\u5c42\u4e3a\u5706\u62ec\u53f7\u800c\u975e\u65b9\u62ec\u53f7\u3002 \u8fd9\u79cd\u8868\u8fbe\u5f0f\u88ab\u8bbe\u8ba1\u7528\u4e8e\u751f\u6210\u5668\u5c06\u7acb\u5373\u88ab\u5916\u5c42\u51fd\u6570\u6240\u4f7f\u7528\u7684\u60c5\u51b5\u3002 \u751f\u6210\u5668\u8868\u8fbe\u5f0f\u76f8\u6bd4\u5b8c\u6574\u7684\u751f\u6210\u5668\u66f4\u7d27\u51d1\u4f46\u8f83\u4e0d\u7075\u6d3b\uff0c\u76f8\u6bd4\u7b49\u6548\u7684\u5217\u8868\u63a8\u5bfc\u5f0f\u5219\u66f4\u4e3a\u8282\u7701\u5185\u5b58\u3002 \u793a\u4f8b: >>> sum(i * i for i in range(10)) # sum of squares 285 >>> xvec = [10, 20, 30] >>> yvec = [7, 5, 3] >>> sum(x * y for x, y in zip(xvec, yvec)) # dot product 260 >>> unique_words = set(word for line in page for word in line.split()) >>> valedictorian = max((student.gpa, student.name) for student in graduates) >>> data = 'golf' >>> list(data[i] for i in range(len(data)-1, -1, -1)) ['f', 'l', 'o', 'g'] \u5143\u7c7b\uff08metaclass\uff09 \u6240\u6709\u7684\u5bf9\u8c61\u90fd\u662f\u5b9e\u4f8b\u5316\u6216\u8005\u8bf4\u8c03\u7528\u7c7b\u800c\u5f97\u5230\u7684\uff08\u8c03\u7528\u7c7b\u7684\u8fc7\u7a0b\u79f0\u4e3a\u7c7b\u7684\u5b9e\u4f8b\u5316\u3002 class StandfordProfessor(object): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') \u4e0a\u4f8b\u4e2d\uff0c\u5bf9\u8c61 professor \u662f\u8c03\u7528\u7c7b StandfordProfessor \u5f97\u5230\u7684\u3002\u7c7b StandfordProfessor \u672c\u8d28\u4e5f\u662f\u4e00\u4e2a\u5bf9\u8c61\uff0c \u4e0b\u9762\u53ef\u4ee5\u9a8c\u8bc1\uff0c StandfordProfessor \u662f\u8c03\u7528\u4e86\u5185\u7f6e\u7684\u7c7b type \u5f97\u5230\u7684\u3002\u8fd9\u4e2a type \u79f0\u4e3a\u5143\u7c7b\u3002 print(type(StandfordProfessor)) # <class 'type'> \u5982\u679c\u4e00\u4e2a\u7c7b\u6ca1\u6709\u58f0\u660e\u81ea\u5df1\u7684\u5143\u7c7b\uff0c\u9ed8\u8ba4\u5b83\u7684\u5143\u7c7b\u5c31\u662f type \uff0c\u9664\u4e86\u4f7f\u7528\u5185\u7f6e\u5143\u7c7b type \uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f type \u6765\u81ea\u5b9a\u4e49\u5143\u7c7b\uff0c\u7136\u540e\u4f7f\u7528 metaclass \u5173\u952e\u5b57\u53c2\u6570\u4e3a\u4e00\u4e2a\u7c7b\u7684\u6307\u5b9a\u5143\u7c7b\u3002 \u53ea\u6709\u7ee7\u627f\u4e86type\u7c7b\u624d\u80fd\u79f0\u4e4b\u4e3a\u4e00\u4e2a\u5143\u7c7b\uff0c\u5426\u5219\u5c31\u662f\u4e00\u4e2a\u666e\u901a\u7684\u81ea\u5b9a\u4e49\u7c7b\u3002 class Mymeta(type): pass class StandfordProfessor(object, metaclass=Mymeta): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') \u4e0b\u9762\u8fdb\u884c\u81ea\u5b9a\u4e49\u5143\u7c7b\uff0c\u63a7\u5236\u7c7b StandfordProfessor \u7684\u8c03\u7528\u3002 \u8981\u60f3\u8ba9 professor \u8fd9\u4e2a\u5bf9\u8c61\u53d8\u6210\u4e00\u4e2a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\uff0c\u9700\u8981\u5728\u8be5\u5bf9\u8c61\u7684\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u65b9\u6cd5 __call__ \uff0c\u8be5\u65b9\u6cd5\u4f1a\u5728\u8c03\u7528\u5bf9\u8c61\u65f6\u81ea\u52a8\u89e6\u53d1\u3002\u8c03\u7528 professor \u7684\u8fd4\u56de\u503c\u5c31\u662f __call__ \u65b9\u6cd5\u7684\u8fd4\u56de\u503c\u3002 class Mymeta(type): def __call__(self, *args, **kwargs): print(self) # \u7c7b\u540d print(args) # \u8f93\u5165\u53c2\u6570 print(kwargs) # \u8f93\u5165\u53c2\u6570 return 10086 class StandfordProfessor(object, metaclass=Mymeta): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') # <class '__main__.StandfordProfessor'> # ('Tom', 'Male') # {} \u7c7b\u7684\u4ea7\u751f\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u5143\u7c7b\u7684\u8c03\u7528\u8fc7\u7a0b,\u5373 StandfordProfessor = Mymeta('StandfordProfessor', (object), {...}) \uff0c\u8c03\u7528 Mymeta \u4f1a\u5148\u4ea7\u751f\u4e00\u4e2a\u7a7a\u5bf9\u8c61 StandfordProfessor \uff0c\u7136\u540e\u8fde\u540c\u8c03\u7528 Mymeta \u62ec\u53f7\u5185\u7684\u53c2\u6570\u4e00\u540c\u4f20\u7ed9 Mymeta \u4e0b\u7684 __init__ \u65b9\u6cd5\uff0c\u5b8c\u6210\u521d\u59cb\u5316\u3002\u6211\u4eec\u53ef\u4ee5\u57fa\u4e8e\u4e0a\u4f8b\u505a\u5982\u4e0b\u6539\u5199\u3002 class Mymeta(type): def __init__(self, class_name, class_bases, class_dic): super(Mymeta, self).__init__(class_name, class_bases, class_dic) if class_name.islower(): raise TypeError(f'Please follow Camel-Case to change class name {class_name}') if '__doc__' not in class_dic or len(class_dic['__doc__'].strip(' \\n')) == 0: raise TypeError('Please add documentation in class {class_name}, which is mandatory.') class StandfordProfessor(object, metaclass=Mymeta): \"\"\" Documentation of class StanfordTeacher \"\"\" university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') professor.display() # Professor Tom says welcome to Standford! print(professor.__dict__) # {'name': 'Tom', 'gender': 'Male'} StandfordProfessor.mro() # [<class '__main__.StandfordProfessor'>, <class 'object'>]","title":"\u9762\u5411\u5bf9\u8c61\u4e09\u5927\u7279\u6027"},{"location":"python/Foundation/ch05/#_1","text":"\u4e09\u5927\u7279\u6027\uff1a \u5c01\u88c5 \u7ee7\u627f \u591a\u6001","title":"\u9762\u5411\u5bf9\u8c61\u4e09\u5927\u7279\u6027"},{"location":"python/Foundation/ch05/#encapsulation","text":"\u5c01\u88c5\u662f\u4f7f\u7528\u7279\u6b8a\u7684\u8bed\u6cd5\uff0c\u5bf9\u6210\u5458\u5c5e\u6027\u548c\u6210\u5458\u65b9\u6cd5\u8fdb\u884c\u5305\u88c5\uff0c\u9650\u5236\u4e00\u4e9b\u8bbf\u95ee\u548c\u64cd\u4f5c\uff0c\u8fbe\u5230\u4fdd\u62a4\u548c\u9690\u85cf\u7684\u76ee\u7684\u3002 \u5c01\u88c5\u673a\u5236\u4fdd\u8bc1\u4e86\u7c7b\u5185\u90e8\u6570\u636e\u7ed3\u6784\u7684\u5b8c\u6574\u6027\uff0c\u56e0\u4e3a\u4f7f\u7528\u7c7b\u7684\u7528\u6237\u65e0\u6cd5\u76f4\u63a5\u770b\u5230\u7c7b\u4e2d\u7684\u6570\u636e\u7ed3\u6784\uff0c\u53ea\u80fd\u4f7f\u7528\u7c7b\u5141\u8bb8\u516c\u5f00\u7684\u6570\u636e\uff0c\u5f88\u597d\u5730\u907f\u514d\u4e86\u5916\u90e8\u5bf9\u5185\u90e8\u6570\u636e\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u7a0b\u5e8f\u7684\u53ef\u7ef4\u62a4\u6027\u3002 \u5bf9\u4e00\u4e2a\u7c7b\u5b9e\u73b0\u826f\u597d\u7684\u5c01\u88c5\uff0c\u7528\u6237\u53ea\u80fd\u501f\u52a9\u66b4\u9732\u51fa\u6765\u7684\u7c7b\u65b9\u6cd5\u6765\u8bbf\u95ee\u6570\u636e\uff0c\u53ef\u4ee5\u5728\u8fd9\u4e9b\u66b4\u9732\u7684\u65b9\u6cd5\u4e2d\u52a0\u5165\u9002\u5f53\u7684\u63a7\u5236\u903b\u8f91\uff0c\u5373\u53ef\u63a7\u5236\u7528\u6237\u5bf9\u7c7b\u4e2d\u5c5e\u6027\u6216\u65b9\u6cd5\u7684\u64cd\u4f5c\u3002 \u5bf9\u7c7b\u8fdb\u884c\u826f\u597d\u7684\u5c01\u88c5\uff0c\u4e3b\u8981\u662f\u5185\u90e8\u4f7f\u7528\u5c01\u88c5\u7684\u6210\u5458\uff0c\u4e5f\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u590d\u7528\u6027\u3002 \u7c7b\u6210\u5458\u5c01\u88c5\u7684\u7ea7\u522b\uff1a \u516c\u6709\u7684\uff08public\uff09 \u4fdd\u62a4\u7684\uff08protected\uff09\uff0c\u5728Python\u4e2d\u5e76\u6ca1\u6709\u5b9e\u73b0protected\u5c01\u88c5\uff0c\u5c5e\u4e8e\u5f00\u53d1\u8005\u7684\u7ea6\u5b9a\u4fd7\u6210\u3002 \u79c1\u6709\u7684\uff08private\uff09\uff0c\u5728Python\u4e2dprivate\u5c01\u88c5\u662f\u901a\u8fc7\u6539\u540d\u7b56\u7565\u6765\u5b9e\u73b0\u7684\uff0c\u5e76\u4e0d\u662f\u771f\u6b63\u7684\u79c1\u6709\u5316\u3002 \u8bbf\u95ee\u9650\u5236 \u5171\u6709\u7684public \u53d7\u4fdd\u62a4\u7684protected \u79c1\u6709\u7684private \u5728\u7c7b\u7684\u5185\u90e8 OK OK OK \u5728\u7c7b\u7684\u5916\u90e8 OK No (Python\u4e2d\u53ef\u4ee5) No \u770b\u4e0b\u9762\u7684\u4f8b\u5b50\u3002(\u53c2\u8003 \u79c1\u6709\u53d8\u91cfPrivate Variables ) name \u662f\u5171\u6709\u5c5e\u6027\uff0c\u53ef\u4ee5\u5728\u5916\u90e8\u8c03\u7528tom.name\u3002 _age \u662f\u53d7\u4fdd\u62a4\u7684\u5c5e\u6027\uff0c\u7406\u8bba\u4e0a\u5728\u5916\u90e8\u662f\u4e0d\u53ef\u8c03\u7528\u7684\uff0c\u4f46\u5728Python\u4e2d\u662f\u53ef\u4ee5\u8c03\u7528\u7684 tom._age \u3002 __phone \u662f\u79c1\u6709\u5c5e\u6027\uff0c\u5728\u5916\u90e8\u662f\u4e0d\u53ef\u8c03\u7528\u7684\uff0c tom.__get_phone() \u62a5\u9519\u201c\u5c5e\u6027\u4e0d\u5b58\u5728\u201d\u3002 \u5bf9\u5e94\u65b9\u6cd5\u4e5f\u662f\u7c7b\u4f3c\u3002 \u5728\u7c7b\u7684\u5185\u90e8\u5bf9\u53d7\u4fdd\u62a4\u5bf9\u8c61\u548c\u79c1\u6709\u5bf9\u8c61\u6ca1\u6709\u8bbf\u95ee\u9650\u5236\u3002 _get_age \u53ef\u4ee5\u8c03\u7528\u79c1\u6709\u5c5e\u6027 __phone \u3002 class Person(): name = 'name' # public _age = 0 # protected __phone = 'phone' # private def __init__(self, n, a, p): self.name = n self._age = a self.__phone = p def get_name(self): print(f'My name is {self.name}') def _get_age(self): print(f'My age is {self._age}') print(f'My age is {self.__phone}') def __get_phone(self): print(f'My phone is {self.__phone}') tom = Person('Tom', 18, 12345678) tom.name # 'Tom' tom._age # 18 tom.__phone # AttributeError: 'Person' object has no attribute '__phone' tom.get_name() # My name is Tom tom._get_age() # My age is 18 # My age is 12345678 tom.__get_phone() # AttributeError: 'Person' object has no attribute '__get_phone'","title":"\u5c01\u88c5 Encapsulation"},{"location":"python/Foundation/ch05/#inheritance","text":"\u5728\u4e0d\u6307\u5b9a\u7ee7\u627f\u7684\u7236\u7c7b\u65f6\uff0c\u6240\u6709\u7c7b\u90fd\u7ee7\u627fobject\u7c7b\uff08\u7cfb\u7edf\u63d0\u4f9b\uff09\u3002 \u88ab\u5176\u5b83\u7c7b\u7ee7\u627f\u7684\u7c7b\uff0c\u79f0\u4e3a\u7236\u7c7b\uff0c\u6216\u8005\u57fa\u7c7b\uff0c\u6216\u8005\u8d85\u7c7b\u3002 \u7ee7\u627f\u5176\u5b83\u7c7b\u7684\u7c7b\uff0c\u79f0\u4e3a\u5b50\u7c7b\uff0c\u6216\u8005\u6d3e\u751f\u7c7b\uff08derived class\uff09\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5c31\u62e5\u6709\u4e86\u7236\u7c7b\u4e2d\u7684\u6240\u6709\u6210\u5458\uff08\u9664\u4e86\u79c1\u6709\u6210\u5458\uff09\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5e76\u4e0d\u4f1a\u628a\u7236\u7c7b\u7684\u6210\u5458\u590d\u5236\u7ed9\u5b50\u7c7b\uff0c\u800c\u662f\u5f15\u7528\u3002 \u5b50\u7c7b\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u7236\u7c7b\u7684\u65b9\u6cd5 super().BaseClassName \u3002\u5982\u679c\u7236\u7c7b\u65b9\u6cd5\u6709\u53c2\u6570\u8981\u6c42\uff0c\u5b50\u7c7b\u8c03\u7528\u65f6\u4e5f\u6709\u53c2\u6570\u8981\u6c42\u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u53ef\u4ee5\u91cd\u65b0\u5b9a\u4e49\u7236\u7c7b\u4e2d\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a \u91cd\u5199\uff08Override\uff09 \u3002 \u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u540e\uff0c\u5b9a\u4e49\u7236\u7c7b\u4e2d\u6ca1\u6709\u7684\u65b9\u6cd5\uff0c\u88ab\u79f0\u4e3a\u5bf9\u7236\u7c7b\u7684\u6269\u5c55\u3002 \u4e00\u4e2a\u7236\u7c7b\u53ef\u4ee5\u88ab\u591a\u4e2a\u5b50\u7c7b\u7ee7\u627f\u3002 \u6d3e\u751f\u7c7b\uff08derived class\uff09 \u5b9a\u4e49\u7684\u8bed\u6cd5\u5982\u4e0b\u6240\u793a: class BaseClassName(): <statement-1> . . . <statement-N> class DerivedClassName(BaseClassName): <statement-1> . . . <statement-N> \u540d\u79f0 BaseClassName \u5fc5\u987b\u5b9a\u4e49\u4e8e\u5305\u542b\u6d3e\u751f\u7c7b\u5b9a\u4e49\u7684\u4f5c\u7528\u57df\u4e2d\u3002 \u4e5f\u5141\u8bb8\u7528\u5176\u4ed6\u4efb\u610f\u8868\u8fbe\u5f0f\u4ee3\u66ff\u57fa\u7c7b\u540d\u79f0\u6240\u5728\u7684\u4f4d\u7f6e\uff0c\u4f8b\u5982\uff0c\u5f53\u57fa\u7c7b\u5b9a\u4e49\u5728\u53e6\u4e00\u4e2a\u6a21\u5757\u4e2d\u7684\u65f6\u5019: class DerivedClassName(modname.BaseClassName): \u6d3e\u751f\u7c7b\u5b9a\u4e49\u7684\u6267\u884c\u8fc7\u7a0b\u4e0e\u57fa\u7c7b\u76f8\u540c\u3002 \u5f53\u6784\u9020\u7c7b\u5bf9\u8c61\u65f6\uff0c\u57fa\u7c7b\u4f1a\u88ab\u8bb0\u4f4f\u3002 \u6b64\u4fe1\u606f\u5c06\u88ab\u7528\u6765\u89e3\u6790\u5c5e\u6027\u5f15\u7528\uff1a\u5982\u679c\u8bf7\u6c42\u7684\u5c5e\u6027\u5728\u7c7b\u4e2d\u627e\u4e0d\u5230\uff0c\u641c\u7d22\u5c06\u8f6c\u5f80\u57fa\u7c7b\u4e2d\u8fdb\u884c\u67e5\u627e\u3002 \u5982\u679c\u57fa\u7c7b\u672c\u8eab\u4e5f\u6d3e\u751f\u81ea\u5176\u4ed6\u67d0\u4e2a\u7c7b\uff0c\u5219\u6b64\u89c4\u5219\u5c06\u88ab\u9012\u5f52\u5730\uff08recursively\uff09\u5e94\u7528\u3002 \u6d3e\u751f\u7c7b\u7684\u5b9e\u4f8b\u5316\u6ca1\u6709\u4efb\u4f55\u7279\u6b8a\u4e4b\u5904: DerivedClassName() \u4f1a\u521b\u5efa\u8be5\u7c7b\u7684\u4e00\u4e2a \u65b0\u5b9e\u4f8b \u3002 \u65b9\u6cd5\u5f15\u7528\u5c06\u6309\u4ee5\u4e0b\u65b9\u5f0f\u89e3\u6790\uff1a\u641c\u7d22\u76f8\u5e94\u7684\u7c7b\u5c5e\u6027\uff0c\u5982\u6709\u5fc5\u8981\u5c06\u6309\u57fa\u7c7b\u7ee7\u627f\u94fe\u9010\u6b65\u5411\u4e0b\u67e5\u627e\uff0c\u5982\u679c\u4ea7\u751f\u4e86\u4e00\u4e2a\u51fd\u6570\u5bf9\u8c61\u5219\u65b9\u6cd5\u5f15\u7528\u5c31\u751f\u6548\u3002 \u6d3e\u751f\u7c7b\u53ef\u80fd\u4f1a\u91cd\u5199\uff08override\uff09\u5176\u57fa\u7c7b\u7684\u65b9\u6cd5\u3002 \u56e0\u4e3a\u65b9\u6cd5\u5728\u8c03\u7528\u540c\u4e00\u5bf9\u8c61\u7684\u5176\u4ed6\u65b9\u6cd5\u65f6\u6ca1\u6709\u7279\u6b8a\u6743\u9650\uff0c\u6240\u4ee5\u8c03\u7528\u540c\u4e00\u57fa\u7c7b\u4e2d\u5b9a\u4e49\u7684\u53e6\u4e00\u65b9\u6cd5\u7684\u57fa\u7c7b\u65b9\u6cd5\u6700\u7ec8\u53ef\u80fd\u4f1a\u8c03\u7528\u8986\u76d6\u5b83\u7684\u6d3e\u751f\u7c7b\u7684\u65b9\u6cd5\u3002 \u5728\u6d3e\u751f\u7c7b\u4e2d\u7684\u91cd\u8f7d\u65b9\u6cd5\uff08overriding method\uff09\u5b9e\u9645\u4e0a\u53ef\u80fd\u60f3\u8981\u6269\u5c55\u800c\u975e\u7b80\u5355\u5730\u66ff\u6362\u540c\u540d\u7684\u57fa\u7c7b\u65b9\u6cd5\u3002 \u6709\u4e00\u79cd\u65b9\u5f0f\u53ef\u4ee5\u7b80\u5355\u5730\u76f4\u63a5\u8c03\u7528\u57fa\u7c7b\u65b9\u6cd5\uff1a\u5373\u8c03\u7528 BaseClassName.methodname(self, arguments) \u3002 \u8bf7\u6ce8\u610f\uff0c\u4ec5\u5f53\u6b64\u57fa\u7c7b\u53ef\u5728\u5168\u5c40\u4f5c\u7528\u57df\u4e2d\u4ee5 BaseClassName \u7684\u540d\u79f0\u88ab\u8bbf\u95ee\u65f6\u65b9\u53ef\u4f7f\u7528\u6b64\u65b9\u5f0f\u3002 Python\u6709\u4e24\u4e2a\u5185\u7f6e\u51fd\u6570\u53ef\u88ab\u7528\u4e8e\u7ee7\u627f\u673a\u5236\uff1a \u4f7f\u7528 isinstance() \u6765\u68c0\u67e5\u4e00\u4e2a\u5b9e\u4f8b\u7684\u7c7b\u578b: isinstance(obj, int) \u4ec5\u4f1a\u5728 obj.__class__ \u4e3a int \u6216\u67d0\u4e2a\u6d3e\u751f\u81ea int \u7684\u7c7b\u65f6\u4e3a True \u3002 \u4f7f\u7528 issubclass() \u6765\u68c0\u67e5\u7c7b\u7684\u7ee7\u627f\u5173\u7cfb: issubclass(bool, int) \u4e3a True \uff0c\u56e0\u4e3a bool \u662f int \u7684\u5b50\u7c7b\u3002 \u4f46\u662f\uff0c issubclass(float, int) \u4e3a False \uff0c\u56e0\u4e3a float \u4e0d\u662f int \u7684\u5b50\u7c7b\u3002","title":"\u7ee7\u627f Inheritance"},{"location":"python/Foundation/ch05/#multiple-inheritance","text":"\u5355\u7ee7\u627f\uff08single-inheritance\uff09\uff1a\u4e00\u4e2a\u7c7b\u53ea\u80fd\u7ee7\u627f\u4e00\u4e2a\u7236\u7c7b\u65b9\u5f0f\u3002 class DerivedClassName(BaseClassName): <statement-1> . . . <statement-N> \u591a\u7ee7\u627f\uff08Multiple Inheritance\uff09\uff1a\u4e00\u4e2a\u7c7b\u53bb\u7ee7\u627f\u591a\u4e2a\u7c7b\u7684\u65b9\u5f0f\u3002\u5b9a\u4e49\u8bed\u53e5\u5982\u4e0b\u6240\u793a class DerivedClassName(Base1, Base2, Base3): <statement-1> . . . <statement-N> \u5728\u6700\u7b80\u5355\u7684\u60c5\u51b5\u4e0b\uff0c\u641c\u7d22\u4ece\u7236\u7c7b\u6240\u7ee7\u627f\u5c5e\u6027\u7684\u64cd\u4f5c\u662f\u6df1\u5ea6\u4f18\u5148\uff08depth-first\uff09\u3001\u4ece\u5de6\u81f3\u53f3\uff08left-to-right\uff09\u7684\uff0c\u5f53\u5c42\u6b21\u7ed3\u6784\u4e2d\u5b58\u5728\u91cd\u53e0\u65f6\u4e0d\u4f1a\u5728\u540c\u4e00\u4e2a\u7c7b\u4e2d\u641c\u7d22\u4e24\u6b21\u3002 \u56e0\u6b64\uff0c\u5982\u679c\u67d0\u4e00\u5c5e\u6027\u5728 DerivedClassName \u4e2d\u672a\u627e\u5230\uff0c\u5219\u4f1a\u5230 Base1 \u4e2d\u641c\u7d22\u5b83\uff0c\u7136\u540e\uff08\u9012\u5f52\u5730\uff09\u5230 Base1 \u7684\u57fa\u7c7b\u4e2d\u641c\u7d22\uff0c\u5982\u679c\u5728\u90a3\u91cc\u672a\u627e\u5230\uff0c\u518d\u5230 Base2 \u4e2d\u641c\u7d22\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002 \u771f\u5b9e\u60c5\u51b5\u66f4\u590d\u6742\uff1b\u65b9\u6cd5\u89e3\u6790\u987a\u5e8f\u4f1a\u52a8\u6001\u6539\u53d8\u4ee5\u652f\u6301\u5bf9 super() \u7684\u534f\u540c\u8c03\u7528\u3002 \u8fd9\u79cd\u65b9\u5f0f\u5728\u67d0\u4e9b\u5176\u4ed6\u591a\u91cd\u7ee7\u627f\u578b\u8bed\u8a00\u4e2d\u88ab\u79f0\u4e3a \u540e\u7eed\u65b9\u6cd5\u8c03\u7528\uff08call-next-method\uff09 \uff0c\u5b83\u6bd4 \u5355\u7ee7\u627f\uff08single-inheritance\uff09 \u8bed\u8a00\u4e2d\u7684 uper \u8c03\u7528\u66f4\u5f3a\u5927\u3002 \u52a8\u6001\u6539\u53d8\u987a\u5e8f\u662f\u6709\u5fc5\u8981\u7684\uff0c\u56e0\u4e3a\u6240\u6709\u591a\u91cd\u7ee7\u627f\u7684\u60c5\u51b5\u90fd\u4f1a\u663e\u793a\u51fa\u4e00\u4e2a\u6216\u66f4\u591a\u7684\u83f1\u5f62\u5173\u8054\uff08diamond relationships\uff09\uff08\u5373\u81f3\u5c11\u6709\u4e00\u4e2a\u7236\u7c7b\u53ef\u901a\u8fc7\u591a\u6761\u8def\u5f84\u88ab\u6700\u5e95\u5c42\u7c7b\u6240\u8bbf\u95ee\uff09\u3002 \u4f8b\u5982\uff0c\u6240\u6709\u7c7b\u90fd\u662f\u7ee7\u627f\u81ea object \uff0c\u56e0\u6b64\u4efb\u4f55\u591a\u91cd\u7ee7\u627f\u7684\u60c5\u51b5\u90fd\u63d0\u4f9b\u4e86\u4e00\u6761\u4ee5\u4e0a\u7684\u8def\u5f84\u53ef\u4ee5\u901a\u5411 object \u3002 \u4e3a\u4e86\u786e\u4fdd\u57fa\u7c7b\u4e0d\u4f1a\u88ab\u8bbf\u95ee\u4e00\u6b21\u4ee5\u4e0a\uff0c\u52a8\u6001\u7b97\u6cd5\u4f1a\u7528\u4e00\u79cd\u7279\u6b8a\u65b9\u5f0f\u5c06\u641c\u7d22\u987a\u5e8f\u7ebf\u6027\u5316\uff0c \u4fdd\u7559\u6bcf\u4e2a\u7c7b\u6240\u6307\u5b9a\u7684\u4ece\u5de6\u81f3\u53f3\u7684\u987a\u5e8f\uff0c\u53ea\u8c03\u7528\u6bcf\u4e2a\u7236\u7c7b\u4e00\u6b21\uff0c\u5e76\u4e14\u4fdd\u6301\u5355\u8c03\uff08monotonic\uff09\uff08\u5373\u4e00\u4e2a\u7c7b\u53ef\u4ee5\u88ab\u5b50\u7c7b\u5316\u800c\u4e0d\u5f71\u54cd\u5176\u7236\u7c7b\u7684\u4f18\u5148\u987a\u5e8f\uff09\u3002 \u603b\u800c\u8a00\u4e4b\uff0c\u8fd9\u4e9b\u7279\u6027\u4f7f\u5f97\u8bbe\u8ba1\u5177\u6709\u591a\u91cd\u7ee7\u627f\u7684\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u7c7b\u6210\u4e3a\u53ef\u80fd\u3002 \u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5b9a\u4e49\u4e863\u4e2a\u7c7b\u548c\u7ee7\u627f\u5173\u7cfb\u3002 class F(): def drink(self): print(\"Drink Beer\") class M(): def drink(self): print(\"Drink Red Wine\") class C(F, M): def drink(self): print(\"Drink Water\") \u6267\u884c\u7ed3\u679c\u662f c = C() c.drink() # Drink Water \u65b9\u6cd51\uff1a\u6309\u7167mro\u8fdb\u884c\u7ee7\u627f\u67e5\u627e\u3002 \u5982\u679c\u628a C \u7c7b\u6539\u5199\u4e3a\u5982\u4e0b\uff0c\u53ef\u4ee5\u8c03\u7528\u7236\u7c7b\uff0c\u53c2\u7167 C \u7c7b\u7684mro\u8fdb\u884c\uff0c mro \u91cc\u9762\u7c7b F \u7684\u4e0a\u4e00\u7ea7\u662f\u7c7b M \uff0c\u6240\u4ee5\u7c7b F \u4e2d\u7684 super() \u5c31\u662f\u6307\u7c7b M \u3002 class C(F, M): def drink(self): super().drink() print(\"Drink Water\") c = C() c.drink() # Drink Beer # Drink Water C.mro() # [<class '__main__.C'>, <class '__main__.F'>, <class '__main__.M'>, <class 'object'>] \u65b9\u6cd52\uff1a\u201c\u6307\u540d\u9053\u59d3\u201d\u8c03\u7528\u3002\u5982\u679c\u628a C \u7c7b\u6539\u5199\u4e3a\u5982\u4e0b\uff0c\u53ef\u4ee5\u8c03\u7528 M \u7c7b\u3002 class C(F, M): def drink(self): M.drink(self) print(\"Drink Water\") c = C() c.drink() # Drink Red Wine # Drink Water","title":"\u591a\u91cd\u7ee7\u627f Multiple Inheritance"},{"location":"python/Foundation/ch05/#_2","text":"\u83f1\u5f62\u7ee7\u627f\u7684\u63cf\u8ff0\u662f\uff0c\u7c7b A \u4f5c\u4e3a\u57fa\u7c7b\uff08\u8fd9\u91cc\u57fa\u7c7b\u662f\u6307\u975e object \u7c7b\uff09\uff0c\u7c7b B \u548c\u7c7b C \u540c\u65f6\u7ee7\u627f\u7c7b A \uff0c\u7136\u540e\u7c7b D \u53c8\u7ee7\u627f\u7c7b B \u548c\u7c7b C \uff0c\u5982\u4e0b\u56fe\uff0c\u770b\u8d77\u6765\u50cf\u4e2a\u94bb\u77f3\u7684\u5f62\u72b6\u3002 A / \\ B C \\ / D \u5728\u8fd9\u79cd\u7ed3\u6784\u4e2d\uff0c\u5728\u8c03\u7528\u987a\u5e8f\u4e0a\u5c31\u4f1a\u51fa\u73b0\u7591\u60d1\uff0c\u8c03\u7528\u987a\u5e8f\u7a76\u7adf\u662f\u4ee5\u4e0b\u54ea\u4e00\u79cd\u987a\u5e8f\u5462\uff1f D->B->A->C\uff08\u6df1\u5ea6\u4f18\u5148\uff09 D->B->C->A\uff08\u5e7f\u5ea6\u4f18\u5148\uff09 \u770b\u4e0b\u9762\u4ee3\u7801\uff0c\u5728Python3\u4e2d\uff0c \u83f1\u5f62 \u7684\u591a\u7ee7\u627f\u5173\u7cfb\u662f\u6309\u7167D->B->C->A \u5e7f\u5ea6\u4f18\u5148 \u7684\u641c\u7d22\u65b9\u5f0f\u3002 class A(): pass class B(A): def test(self): print(\"init B.test()\") class C(A): def test(self): print(\"init C.test()\") class D(B, C): pass d = D() d.test() # init B.test() D.mro() # [<class '__main__.D'>, <class '__main__.B'>, <class '__main__.C'>, <class '__main__.A'>, <class 'object'>] \u5bf9\u4e8e\u4e0b\u9762\u8fd9\u79cd \u975e\u83f1\u5f62 \u7684\u591a\u7ee7\u627f\u5173\u7cfb\uff0c\u67e5\u627e\u987a\u5e8f\u662fA->B->E->C->F->D \u6df1\u5ea6\u4f18\u5148 \u7684\u641c\u7d22\u65b9\u5f0f\u3002 E F | | B(E) C(F) D | | | \\ | / \\ | / A(B,C,D) \u4ee3\u7801\u5b9e\u73b0\uff1a class D(): def test(self): print(\"init D.test()\") class F(): def test(self): print(\"init F.test()\") class C(F): pass class E(): pass class B(E): pass class A(B, C, D): pass a = A() a.test() # init F.test() A.mro() # [<class '__main__.A'>, <class '__main__.B'>, <class '__main__.E'>, <class '__main__.C'>, <class '__main__.F'>, <class '__main__.D'>, <class 'object'>] \u603b\u7ed3\uff1a \u7ee7\u627f\u7ed3\u6784\u8981\u5c3d\u91cf\u7b80\u5355\uff0c\u4e0d\u8981\u8fc7\u4e8e\u590d\u6742\u3002 \u63a8\u8350\u4f7f\u7528minxins\u673a\u5236\uff0c\u5728\u591a\u7ee7\u627f\u80cc\u666f\u4e0b\uff0c\u6ee1\u8db3\u7ee7\u627f\u7684\u4ec0\u4e48\u662f\u4ec0\u4e48\u7684\u5173\u7cfb\uff08is-a\uff09","title":"\u83f1\u5f62\u7ee7\u627f\u548c\u7ee7\u627f\u5173\u7cfb\u68c0\u6d4b"},{"location":"python/Foundation/ch05/#minxins","text":"\u770b\u4e0b\u9762\u4f8b\u5b50\uff0c\u5982\u679c\u5728 Vehicle \u7c7b\u4e2d\u5b9a\u4e49\u4e86 fly \u7684\u65b9\u6cd5\uff0c\u4f1a\u5bfc\u81f4 Car(Vehicle) \u7684\u7ee7\u627f\u5173\u7cfb\u51fa\u73b0\u77db\u76fe\uff0c\u6c7d\u8f66\u5e76\u4e0d\u4f1a\u98de\uff0c\u4f46\u6309\u7167\u4e0a\u8ff0\u7ee7\u627f\u5173\u7cfb\uff0c\u6c7d\u8f66\u4e5f\u80fd\u98de\u4e86\u3002 \u4f46\u662f\u5982\u679c\u6c11\u822a\u98de\u673a\u548c\u76f4\u5347\u673a\u90fd\u5404\u81ea\u5199\u81ea\u5df1\u7684\u98de\u884cfly\u65b9\u6cd5\uff0c\u53c8\u8fdd\u80cc\u4e86\u4ee3\u7801\u5c3d\u53ef\u80fd\u91cd\u7528\u7684\u539f\u5219\u3002 class Vehicle: # \u4ea4\u901a\u5de5\u5177 def fly(self): ''' \u98de\u884c\u529f\u80fd\u76f8\u5e94\u7684\u4ee3\u7801 ''' print(\"I am flying\") # \u6c11\u822a\u98de\u673a class CivilAircraft(Vehicle): pass # \u76f4\u5347\u98de\u673a class Helicopter(Vehicle): pass # \u6c7d\u8f66 class Car(Vehicle): pass Python\u4e2d\u6ca1\u6709\u7c7b\u4f3cJava\u63a5\u53e3interface\u7684\u529f\u80fd\uff0c\u4f46\u63d0\u4f9b\u4e86Mixins\u673a\u5236\u3002 Python\u5bf9\u4e8e Mixin \u7c7b\u7684\u547d\u540d\u65b9\u5f0f\u4e00\u822c\u4ee5 Mixin , able , ible \u4e3a\u540e\u7f00\u3002 Mixin \u7c7b\u5fc5\u987b\u529f\u80fd\u5355\u4e00\uff0c\u5982\u679c\u6709\u591a\u4e2a\u529f\u80fd\uff0c\u90a3\u5c31\u5199\u591a\u4e2aMixin\u7c7b\u3002 \u4e00\u4e2a\u7c7b\u53ef\u4ee5\u7ee7\u627f\u591a\u4e2a Mixin \u7c7b\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u9075\u5faa\u7ee7\u627f\u7684\u201cis-a\u201d\u539f\u5219\uff0c\u53ea\u80fd\u7ee7\u627f\u4e00\u4e2a\u6807\u8bc6\u5176\u5f52\u5c5e\u542b\u4e49\u7684\u7236\u7c7b Mixin \u7c7b\u4e0d\u4f9d\u8d56\u4e8e\u5b50\u7c7b\u7684\u5b9e\u73b0\u3002 \u5b50\u7c7b\u5373\u4fbf\u6ca1\u6709\u7ee7\u627f\u8fd9\u4e2a Mixin \u7c7b\u7c7b\uff0c\u4e5f\u7167\u6837\u53ef\u4ee5\u5de5\u4f5c\uff0c\u5c31\u662f\u7f3a\u5c11\u4e86\u67d0\u4e2a\u529f\u80fd\u3002 \u6211\u4eec\u5b9a\u4e49\u7684 Mixin \u7c7b\u8d8a\u591a\uff0c\u5b50\u7c7b\u7684\u4ee3\u7801\u53ef\u8bfb\u6027\u5c31\u4f1a\u8d8a\u5dee\u3002 # \u4ea4\u901a\u5de5\u5177 class Vehicle: pass # \u4e3a\u5f53\u524d\u7c7b\u6df7\u5165\u4e00\u4e9b\u529f\u80fd\uff0c\u4e0d\u662f\u4e00\u4e2a\u5355\u7eaf\u7684\u7c7b class FlyableMixin: def fly(self): ''' \u98de\u884c\u529f\u80fd\u76f8\u5e94\u7684\u4ee3\u7801 ''' print(\"I am flying\") # \u6c11\u822a\u98de\u673a class CivilAircraft(FlyableMixin, Vehicle): pass # \u76f4\u5347\u98de\u673a class Helicopter(FlyableMixin, Vehicle): pass # \u6c7d\u8f66 class Car(Vehicle): pass","title":"\u591a\u7ee7\u627f\u5173\u7cfb\u7684minxins\u673a\u5236"},{"location":"python/Foundation/ch05/#class-combination","text":"\u5728\u4e00\u4e2a\u7c7b\u4e2d\u4ee5\u53e6\u4e00\u4e2a\u7c7b\u7684\u5bf9\u8c61\u4f5c\u4e3a\u6570\u636e\u5c5e\u6027\uff0c\u79f0\u4e3a\u7c7b\u7684 \u7ec4\u5408 \u3002\u7ec4\u5408\u4e0e\u7ee7\u627f\u90fd\u662f\u7528\u6765\u89e3\u51b3\u4ee3\u7801\u7684\u91cd\u7528\u6027\u95ee\u9898\u3002 \u7ee7\u627f\u4f53\u73b0\u201c\u662f\u201d\u7684\u5173\u7cfb\uff0c\u5f53\u7c7b\u4e4b\u95f4\u6709\u5f88\u591a\u76f8\u540c\u4e4b\u5904\uff0c\u7528\u7ee7\u627f\u3002 \u7ec4\u5408\u4f53\u73b0\u201c\u6709\u201d\u7684\u5173\u7cfb\uff0c\u5f53\u7c7b\u4e4b\u95f4\u6709\u663e\u8457\u4e0d\u540c\uff0c\u4e00\u4e2a\u7c7b\u662f\u53e6\u4e00\u4e2a\u7c7b\u7684\u5c5e\u6027\u662f\uff0c\u7528\u7ec4\u5408\u3002 \u4e0b\u4f8b\u662f\u8ba1\u7b97\u5706\u73af\u7684\u9762\u79ef\u548c\u5468\u957f\uff0c\u5706\u73af\u662f\u7531\u4e24\u4e2a\u5706\u7ec4\u6210\u7684\uff0c\u5706\u73af\u7684\u9762\u79ef\u662f\u5916\u9762\u5706\u7684\u9762\u79ef\u51cf\u53bb\u5185\u90e8\u5706\u7684\u9762\u79ef\u3002\u5706\u73af\u7684\u5468\u957f\u662f\u5185\u90e8\u5706\u7684\u5468\u957f\u52a0\u4e0a\u5916\u90e8\u5706\u7684\u5468\u957f\u3002 \u8fd9\u4e2a\u4f8b\u5b50\u6f14\u793a\u4e86\u7c7b ring \u91cc\u9762\u7684\u5c5e\u6027 circle1 \u548c circle2 \u6b63\u662f\u53e6\u4e00\u4e2a\u7c7b Circle \u3002 from math import pi class Circle(): def __init__(self, r): self.r = r def area(self): return pi * self.r * self.r def perimeter(self): return 2 * pi * self.r class Ring(): def __init__(self, r1, r2): self.circle1 = Circle(r1) self.circle2 = Circle(r2) def area(self): return abs(self.circle1.area() - self.circle2.area()) def permiter(self): return self.circle1.perimeter() + self.circle2.perimeter() ring = Ring(5, 8) print(ring.area()) # 122.52211349000193 print(ring.permiter()) # 81.68140899333463 \u4e0b\u9762\u7684\u4f8b\u5b50\u6f14\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f20\u53c2\u7684\u65b9\u5f0f\u8fdb\u884c\u7c7b\u7684\u7ec4\u5408\u3002 class Birthday(): def __init__(self, year, month, day): self.year = year self.month = month self.day = day class Course(): def __init__(self, course_name, course_period): self.course_name = course_name self.course_period = course_period class Professor(): def __init__(self, name, gender, birth, course): self.name = name self.gender = gender self.birth = birth self.course = course def teach(self): print(f\"Professor name: {self.name}; Gender: {self.gender}; Birthday: {self.birth.year}-{self.birth.month}{self.birth.day}, Course name: {self.course.course_name} and period: {self.course.course_period}\") prof = Professor('Tom', 'Male', Birthday(1985, 5, 5), Course('Chinese', '2022/3/1 ~ 2022/6/30')) prof.teach() # Professor name: Tom; Gender: Male; Birthday: 1985-55, Course name: Chinese and period: 2022/3/1 ~ 2022/6/30","title":"\u7ec4\u5408\uff08Class Combination\uff09"},{"location":"python/Foundation/ch05/#polymorphism","text":"\u591a\u6001\u610f\u5473\u7740\u76f8\u540c\u7684\u51fd\u6570\u540d\u7528\u4e8e\u4e0d\u540c\u7684\u60c5\u5f62\u3002 \u5982\u4e0b\u4f8b\uff0c len() \u88ab\u7528\u4e8e\u4e0d\u540c\u7684\u60c5\u5f62\u3002 # len() being used for a string print(len(\"geeks\")) # 5 # len() being used for a list print(len([10, 20, 30])) # 3","title":"\u591a\u6001 Polymorphism"},{"location":"python/Foundation/ch05/#_3","text":"\u4e0b\u9762\u7684\u4ee3\u7801\u5c55\u793a\u4e86 Python \u5982\u4f55\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u7c7b\u7c7b\u578b\u3002 \u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u904d\u5386\u5bf9\u8c61\u5143\u7ec4\u7684 for \u5faa\u73af\u3002 \u7136\u540e\u8c03\u7528\u65b9\u6cd5\u800c\u4e0d\u7528\u5173\u5fc3\u6bcf\u4e2a\u5bf9\u8c61\u662f\u54ea\u4e2a\u7c7b\u7c7b\u578b\u3002 \u6211\u4eec\u5047\u8bbe\u8fd9\u4e9b\u65b9\u6cd5\u5b9e\u9645\u4e0a\u5b58\u5728\u4e8e\u6bcf\u4e2a\u7c7b\u4e2d\u3002 class India(): def capital(self): print(\"New Delhi is the capital of India.\") def language(self): print(\"Hindi is the most widely spoken language of India.\") def type(self): print(\"India is a developing country.\") class USA(): def capital(self): print(\"Washington, D.C. is the capital of USA.\") def language(self): print(\"English is the primary language of USA.\") def type(self): print(\"USA is a developed country.\") obj_ind = India() obj_usa = USA() for country in (obj_ind, obj_usa): country.capital() country.language() country.type() # New Delhi is the capital of India. # Hindi is the most widely spoken language of India. # India is a developing country. # Washington, D.C. is the capital of USA. # English is the primary language of USA. # USA is a developed country.","title":"\u7c7b\u65b9\u6cd5\u7684\u591a\u6001\u6027"},{"location":"python/Foundation/ch05/#_4","text":"\u5728 Python \u4e2d\uff0c\u591a\u6001\u5141\u8bb8\u6211\u4eec\u5728\u5b50\u7c7b\u4e2d\u5b9a\u4e49\u4e0e\u7236\u7c7b\u4e2d\u7684\u65b9\u6cd5\u540c\u540d\u7684\u65b9\u6cd5\u3002 \u5728\u7ee7\u627f\u4e2d\uff0c\u5b50\u7c7b\u7ee7\u627f\u7236\u7c7b\u7684\u65b9\u6cd5\u3002 \u4f46\u662f\uff0c\u53ef\u4ee5\u4fee\u6539\u4ece\u7236\u7c7b\u7ee7\u627f\u7684\u5b50\u7c7b\u4e2d\u7684\u65b9\u6cd5\u3002 \u8fd9\u5728\u4ece\u7236\u7c7b\u7ee7\u627f\u7684\u65b9\u6cd5\u4e0d\u592a\u9002\u5408\u5b50\u7c7b\u7684\u60c5\u51b5\u4e0b\u7279\u522b\u6709\u7528\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5728\u5b50\u7c7b\u4e2d\u91cd\u65b0\u5b9e\u73b0\u8be5\u65b9\u6cd5\u3002 \u8fd9\u79cd\u5728\u5b50\u7c7b\u4e2d\u91cd\u65b0\u5b9e\u73b0\u65b9\u6cd5\u7684\u8fc7\u7a0b\u79f0\u4e3a \u65b9\u6cd5\u8986\u76d6\uff08Method Overriding\uff09 \u3002 class Bird: def intro(self): print(\"There are many types of birds.\") def flight(self): print(\"Most of the birds can fly but some cannot.\") class sparrow(Bird): def flight(self): print(\"Sparrows can fly.\") class ostrich(Bird): def flight(self): print(\"Ostriches cannot fly.\") obj_bird = Bird() obj_spr = sparrow() obj_ost = ostrich() obj_bird.intro() # There are many types of birds. obj_bird.flight() # Most of the birds can fly but some cannot. obj_spr.intro() # There are many types of birds. obj_spr.flight() # Sparrows can fly. obj_ost.intro() # There are many types of birds. obj_ost.flight() # Ostriches cannot fly.","title":"\u7ee7\u627f\u7684\u591a\u6001\u6027"},{"location":"python/Foundation/ch05/#_5","text":"\u6211\u4eec\u4e5f\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u53ef\u4ee5\u63a5\u53d7\u4efb\u4f55\u5bf9\u8c61\u7684\u51fd\u6570\uff0c\u5141\u8bb8\u591a\u6001\u6027\u3002 \u5728\u4e0b\u9762\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a func() \u7684\u51fd\u6570\uff0c\u4f20\u5165\u53c2\u6570\u662f obj \u7684\u5bf9\u8c61\u3002 \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u8c03\u7528\u4e09\u4e2a\u65b9\u6cd5\uff0c\u5373 capital() \u3001 language() \u548c type() \uff0c\u6bcf\u4e2a\u65b9\u6cd5\u90fd\u5b9a\u4e49\u5728 India \u548c USA \u4e24\u4e2a\u7c7b\u4e2d\u3002 \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u76f8\u540c\u7684 func() \u51fd\u6570\u8c03\u7528\u5b83\u4eec\u7684\u52a8\u4f5c\uff1a class India(): def capital(self): print(\"New Delhi is the capital of India.\") def language(self): print(\"Hindi is the most widely spoken language of India.\") def type(self): print(\"India is a developing country.\") class USA(): def capital(self): print(\"Washington, D.C. is the capital of USA.\") def language(self): print(\"English is the primary language of USA.\") def type(self): print(\"USA is a developed country.\") def func(obj): obj.capital() obj.language() obj.type() obj_ind = India() obj_usa = USA() func(obj_ind) # New Delhi is the capital of India. # Hindi is the most widely spoken language of India. # India is a developing country. func(obj_usa) # Washington, D.C. is the capital of USA. # English is the primary language of USA. # USA is a developed country.","title":"\u51fd\u6570\u548c\u5bf9\u8c61\u7684\u591a\u6001\u6027"},{"location":"python/Foundation/ch05/#ducking-typinggoose-typing","text":"\u5728Python\u4e2d\u5b9e\u73b0\u591a\u6001\u4e3b\u8981\u6709\u4e24\u79cd\u673a\u5236\uff1a\u767d\u9e45\u7c7b\u578b\u548c\u9e2d\u5b50\u7c7b\u578b\u3002\u767d\u9e45\u7c7b\u578b\u548c\u9e2d\u5b50\u7c7b\u578b\u4e0d\u4ec5\u662f\u4e24\u79cd\u673a\u5236\uff0c\u4e5f\u662f\u4e24\u79cd\u4e0d\u540c\u7684\u7f16\u7a0b\u98ce\u683c\u3002 \u4e0b\u9762\u662f\u4e00\u4e2a\u6253\u5370\u5546\u54c1\u4ef7\u683c\u7684\u4f8b\u5b50\uff0c\u5206\u522b\u7528\u9e2d\u5b50\u7c7b\u578b\u548c\u767d\u9e45\u7c7b\u578b\u5b9e\u73b0\u3002 \u9e2d\u5b50\u7c7b\u578b \u5728\u9e2d\u5b50\u7c7b\u578b\u7684\u5b9e\u73b0\u4e2d\uff0c\u6211\u4eec\u53ea\u9700\u8981\u4fdd\u8bc1\u8c03\u7528 price \u65b9\u6cd5\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u6709 price \u65b9\u6cd5\u5373\u53ef\u3002 class Food: def price(self): print(\"{} price:$4\".format(__class__.__name__)) class Clothes: def price(self): print(\"{} price:$5\".format(__class__.__name__)) class Coffee: def price(self): print(\"{} price:$6\".format(__class__.__name__)) if __name__ == '__main__': goods = [Food(), Clothes(), Coffee()] for good in goods: good.price() # Food price:$4 # Clothes price:$5 # Coffee price:$6 \u767d\u9e45\u7c7b\u578b \u5728\u767d\u9e45\u7c7b\u578b\u4e2d\uff0c\u76f4\u63a5\u8ba9\u6240\u6709\u5bf9\u8c61\u7684\u7c7b\u7ee7\u627f\u7236\u7c7b Good \u4e2d\u7684\u62bd\u8c61\u65b9\u6cd5 price \u3002Python\u4e2d\u7684\u767d\u9e45\u7c7b\u578b\u673a\u5236\u5c31\u662f\u5f3a\u7c7b\u578b\u8bed\u8a00\u4e2d\u5b9e\u73b0\u591a\u6001\u7684\u6807\u51c6\u6a21\u5f0f\uff0c\u5373\u901a\u8fc7\u8c03\u53d6\u7236\u7c7b\u7684\u865a\u51fd\u6570\u6216\u8005\u7ee7\u627f\u7684\u51fd\u6570\u6765\u5b8c\u6210\u4e0d\u540c\u7684\u884c\u4e3a\u3002 import abc class Good(abc.ABC): @abc.abstractmethod def price(self): pass class Food(Good): def price(self): print(\"{} price:$4\".format(__class__.__name__)) class Clothes(Good): def price(self): print(\"{} price:$5\".format(__class__.__name__)) if __name__ == '__main__': goods = [Food(), Clothes(), Coffee()] for good in goods: good.price() # Food price:$4 # Clothes price:$5 # Coffee price:$6","title":"\u9e2d\u5b50\u7c7b\u578b\uff08Ducking Typing\uff09\u548c\u767d\u9e45\u7c7b\u578b\uff08Goose Typing\uff09"},{"location":"python/Foundation/ch05/#class-methodstatic-method","text":"\u7c7b\u65b9\u6cd5\uff08Class method\uff09\u4e5f\u53eb\u7ed1\u5b9a\u65b9\u6cd5\uff0c\u5fc5\u987b\u628a\u7c7b\u4f5c\u4e3a\u4f20\u5165\u53c2\u6570\uff0c\u4f7f\u7528 cls \u4f5c\u4e3a\u7b2c\u4e00\u4e2a\u4f20\u5165\u53c2\u6570\uff0c\u800c\u9759\u6001\u65b9\u6cd5\uff08Static Method\uff09\uff0c\u4e5f\u53eb\u975e\u7ed1\u5b9a\u65b9\u6cd5\uff0c\u4e0d\u9700\u8981\u7279\u5b9a\u7684\u53c2\u6570\u3002 \u7c7b\u65b9\u6cd5\u662f\u7ed1\u5b9a\u5230\u7c7b\u7684\uff0c\u4e0d\u662f\u7ed1\u5b9a\u5230\u7c7b\u5bf9\u8c61\uff0c\u6240\u4ee5\u7c7b\u65b9\u6cd5\u53ef\u4ee5\u8bbf\u95ee\u6216\u4fee\u6539\u7c7b\uff0c\u5e76\u5bf9\u6240\u6709\u7c7b\u5b9e\u4f8b\u751f\u6548\u3002 \u9759\u6001\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u6216\u4fee\u6539\u7c7b\uff0c\u56e0\u4e3a\u9759\u6001\u65b9\u6cd5\u662f\u4e0d\u77e5\u9053\u7c7b\u672c\u8eab\u7684\uff0c\u9759\u6001\u65b9\u6cd5\u662f\u5c5e\u4e8e\u5de5\u5177\u7c7b\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4f20\u5165\u7684\u53c2\u6570\u5b8c\u6210\u7279\u5b9a\u7684\u529f\u80fd\uff0c\u5176\u5b9e\u5c31\u662f\u4e00\u4e2a\u666e\u901a\u51fd\u6570\u800c\u5df2\u3002 Python\u4e2d\u4f7f\u7528 @classmethod \u88c5\u9970\u5668\uff08decorator\uff09\u6765\u521b\u5efa\u4e00\u4e2a\u7c7b\u65b9\u6cd5\uff0c\u7528@staticmethod\u88c5\u9970\u5668\u6765\u521b\u5efa\u4e00\u4e2a\u9759\u6001\u65b9\u6cd5\u3002 \u8bed\u6cd5\u683c\u5f0f\uff1a @classmethod def fun(cls, arg1, arg2, ...): \u5176\u4e2d\uff1a fun: \u9700\u8981\u8f6c\u6362\u6210\u7c7b\u65b9\u6cd5\u7684\u51fd\u6570 returns: \u51fd\u6570\u7684\u7c7b\u65b9\u6cd5 classmethod() \u65b9\u6cd5\u7ed1\u5b9a\u5230\u7c7b\u800c\u4e0d\u662f\u5bf9\u8c61\u3002\u7c7b\u65b9\u6cd5\u53ef\u4ee5\u88ab\u7c7b\u548c\u5bf9\u8c61\u8c03\u7528\u3002\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u7c7b\u6216\u5bf9\u8c61\u8fdb\u884c\u8c03\u7528\u3002 \u4f8b1\uff1a\u521b\u5efa\u4e00\u4e2a\u7b80\u5355\u7684 classmethod \u3002 \u521b\u5efa\u4e00\u4e2a\u7c7b Training \uff0c\u6709\u7c7b\u53d8\u91cf course \u548c\u65b9\u6cd5 purchase \u3002 \u6211\u4eec\u901a\u8fc7\u628a\u51fd\u6570 Training.purchase \u4f20\u7ed9 classmethod() \uff0c\u628a\u8be5\u65b9\u6cd5\u8f6c\u6210\u7c7b\u65b9\u6cd5\uff0c\u7136\u540e\u76f4\u63a5\u8c03\u7528\u5b83\uff0c\u800c\u65e0\u9700\u5148\u521b\u5efa\u5bf9\u8c61\u3002 \u53ef\u4ee5\u770b\u51fa\u8f6c\u6362\u524d\u540e Training.purchase \u7684\u7c7b\u578b\u53d8\u5316\u3002 class Training: course = 'Python for Data Analysis' def purchase(obj): print(\"Puchase course : \", obj.course) type(Training.purchase) # <class 'function'> Training.purchase = classmethod(Training.purchase) Training.purchase() # Puchase course : Python for Data Analysis type(Training.purchase) # <class 'method'> \u4f8b2\uff1a\u4f7f\u7528\u88c5\u9970\u5668 @classmethod \u521b\u5efa\u5de5\u5382\u7c7b\u3002 class Training: def __init__(self, course): self.course = course @classmethod def purchase(cls, course): return cls(course) def display(self): print('Purchase course: ', self.course) training = Training(\"Python for Data Analysis\") training.display() # Purchase course: Python for Data Analysis \u4f8b3\uff1a\u901a\u8fc7 staticmethod() \u548c classmethod() \u6765\u68c0\u67e5\u4e00\u4e2aperson\u662f\u5426\u662fadult\u3002 person1\u662f\u901a\u8fc7\u59d3\u540d\u548c\u5e74\u9f84\u521b\u5efa\u7684\u5b9e\u4f8b\u3002person2\u662f\u901a\u8fc7\u59d3\u540d\u548c\u5e74\u4efd\u521b\u5efa\u7684\u5b9e\u4f8b\u3002 from datetime import date class Person: def __init__(self, name, age): self.name = name self.age = age @classmethod def fromBirthYear(cls, name, year): return cls(name, date.today().year - year) @staticmethod def isAdult(age): return age > 18 person1 = Person('mayank', 21) person2 = Person.fromBirthYear('mayank', 1996) print(person1.age) # 21 print(person2.age) # 26 print(Person.isAdult(22)) # True \u5c0f\u7ed3\uff1a \u82e5\u7c7b\u4e2d\u9700\u8981\u4e00\u4e2a\u529f\u80fd\uff0c\u8be5\u529f\u80fd\u7684\u5b9e\u73b0\u4ee3\u7801\u4e2d\u9700\u8981\u5f15\u7528\u5bf9\u8c61\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u5bf9\u8c61\u65b9\u6cd5\uff1b\u9700\u8981\u5f15\u7528\u7c7b\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u7c7b\u65b9\u6cd5\uff1b\u65e0\u9700\u5f15\u7528\u7c7b\u6216\u5bf9\u8c61\uff0c\u5219\u5c06\u5176\u5b9a\u4e49\u6210\u9759\u6001\u65b9\u6cd5\u3002","title":"\u7c7b\u65b9\u6cd5\uff08Class method\uff09\u548c\u9759\u6001\u65b9\u6cd5\uff08Static Method\uff09"},{"location":"python/Foundation/ch05/#monkey-patch","text":"\u7334\u5b50\u8865\u4e01\u662f\u52a8\u6001\u4e3a\u5df2\u7ecf\u521b\u5efa\u51fa\u7684\u5bf9\u8c61\u589e\u52a0\u65b0\u7684\u65b9\u6cd5\u548c\u5c5e\u6027\u6210\u5458\u7684\u4e00\u79cd\u673a\u5236\uff0c\u4e5f\u5c31\u662f\u52a8\u6001\u6253\u8865\u4e01\u3002 \u5b9e\u4f8b\u5316\u5bf9\u8c61\u7684\u7334\u5b50\u8865\u4e01\u3002 class Test: def __init__(self): self.a = 1 def func1(self, x, y): print(x + y) # \u6b63\u5e38\u5b9e\u4f8b\u5316 test = Test() test.func1(1, 1) # 2 # \u4fee\u6539\u5b9e\u4f8b test.func1 = lambda x, y : print(x + 2 * y) test.func1(1, 1) # 3 # \u901a\u8fc7\u4fee\u6539\u5b9e\u4f8b\uff0c\u8bbf\u95ee\u5185\u90e8\u6210\u5458\u53d8\u91cf\u3002 test.func1 = lambda x, y : print(x + 2 * y + self.a) test.func1(1, 1) # NameError: name 'self' is not defined test.func1 = lambda self, x, y : print(x + 2 * y + self.a) test.func1(test, 1, 1) # 4 \u7c7b\u5bf9\u8c61\u7684\u7334\u5b50\u8865\u4e01\u3002 class Test: def __init__(self): self.a = 1 def func1(self, x, y): print(x + y) # \u4fee\u6539\u7c7b\u6210\u5458\uff0c\u5b9e\u4f8b\u5316\u540e\u7684\u7ed3\u679c\u5df2\u4fee\u6539\u3002 Test.func1 = lambda self, x, y : print(x + 2 * y) test = Test() test.func1(1, 1) # 3 # \u4fee\u6539\u7c7b\u6210\u5458\uff0c\u5e76\u8bbf\u95ee\u6210\u5458\u53d8\u91cf\uff0c\u5b9e\u4f8b\u5316\u540e\u7684\u7ed3\u679c\u5df2\u4fee\u6539\u3002 Test.func1 = lambda self, x, y : print(x + 2 * y + self.a) test = Test() test.func1(1, 1) # 4 # \u589e\u52a0\u7c7b\u6210\u5458\u3002 Test.func2 = lambda self, p, q: print(p + 3 * q + self.a) test = Test() test.func1(1, 1) # 4 test.func2(1, 3) # 11","title":"\u7334\u5b50\u8865\u4e01\uff08monkey patch\uff09"},{"location":"python/Foundation/ch05/#private-variables","text":"\u90a3\u79cd\u4ec5\u9650\u4ece\u4e00\u4e2a\u5bf9\u8c61\u5185\u90e8\u8bbf\u95ee\u7684\u201c\u79c1\u6709\u201d\u5b9e\u4f8b\u53d8\u91cf\uff08\u201cPrivate\u201d instance variables\uff09\u5728 Python \u4e2d\u5e76\u4e0d\u5b58\u5728\u3002 \u4f46\u662f\uff0c\u5927\u591a\u6570 Python \u4ee3\u7801\u90fd\u9075\u5faa\u8fd9\u6837\u4e00\u4e2a\u7ea6\u5b9a\uff1a\u5e26\u6709 \u4e00\u4e2a\u524d\u7f00\u4e0b\u5212\u7ebf \u7684\u540d\u79f0 (\u4f8b\u5982 _spam ) \u5e94\u8be5\u88ab\u5f53\u4f5c\u662f API \u7684\u975e\u516c\u6709\uff08non-public\uff09\u90e8\u5206 (\u65e0\u8bba\u5b83\u662f\u51fd\u6570\u3001\u65b9\u6cd5\u6216\u662f\u6570\u636e\u6210\u5458)\u3002 \u8fd9\u5e94\u5f53\u88ab\u89c6\u4e3a\u4e00\u4e2a\u5b9e\u73b0\u7ec6\u8282\uff0c\u53ef\u80fd\u4e0d\u7ecf\u901a\u77e5\u5373\u52a0\u4ee5\u6539\u53d8\u3002 \u7531\u4e8e\u5b58\u5728\u5bf9\u4e8e\u7c7b\u79c1\u6709\u6210\u5458\uff08class-private members\uff09\u7684\u6709\u6548\u4f7f\u7528\u573a\u666f\uff08\u4f8b\u5982\u907f\u514d\u540d\u79f0\u4e0e\u5b50\u7c7b\u6240\u5b9a\u4e49\u7684\u540d\u79f0\u76f8\u51b2\u7a81\uff09\uff0c\u56e0\u6b64\u5b58\u5728\u5bf9\u6b64\u79cd\u673a\u5236\u7684\u6709\u9650\u652f\u6301\uff0c\u79f0\u4e3a \u540d\u79f0\u6539\u5199\uff08name mangling\uff09 \u3002 \u4efb\u4f55\u5f62\u5f0f\u4e3a __spam \u7684\u6807\u8bc6\u7b26\uff08\u81f3\u5c11\u5e26\u6709 \u4e24\u4e2a\u524d\u7f00\u4e0b\u5212\u7ebf \uff0c\u81f3\u591a\u4e00\u4e2a\u540e\u7f00\u4e0b\u5212\u7ebf\uff09\u7684\u6587\u672c\u5c06\u88ab\u66ff\u6362\u4e3a _classname__spam \uff0c\u5176\u4e2d classname \u4e3a\u53bb\u9664\u4e86\u524d\u7f00\u4e0b\u5212\u7ebf\u7684\u5f53\u524d\u7c7b\u540d\u79f0\u3002 \u8fd9\u79cd\u6539\u5199\u4e0d\u8003\u8651\u6807\u8bc6\u7b26\u7684\u53e5\u6cd5\u4f4d\u7f6e\uff0c\u53ea\u8981\u5b83\u51fa\u73b0\u5728\u7c7b\u5b9a\u4e49\u5185\u90e8\u5c31\u4f1a\u8fdb\u884c\u3002 \u540d\u79f0\u6539\u5199\uff08Name mangling\uff09\u6709\u52a9\u4e8e\u8ba9\u5b50\u7c7b\u91cd\u8f7d\u65b9\u6cd5\uff08\uff09override methods\u800c\u4e0d\u7834\u574f\u7c7b\u5185\u65b9\u6cd5\uff08intraclass method\uff09\u8c03\u7528\u3002\u4f8b\u5982: class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() method class MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) \u4e0a\u9762\u7684\u793a\u4f8b\u5373\u4f7f\u5728 MappingSubclass \u5f15\u5165\u4e86\u4e00\u4e2a __update \u6807\u8bc6\u7b26\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u51fa\u9519\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5728 Mapping \u7c7b\u4e2d\u88ab\u66ff\u6362\u4e3a _Mapping__update \u800c\u5728 MappingSubclass \u7c7b\u4e2d\u88ab\u66ff\u6362\u4e3a _MappingSubclass__update \u3002 \u8bf7\u6ce8\u610f\uff0c\u6539\u5199\u89c4\u5219\uff08mangling rules\uff09\u7684\u8bbe\u8ba1\u4e3b\u8981\u662f\u4e3a\u4e86\u907f\u514d\u610f\u5916\u51b2\u7a81\uff1b\u8bbf\u95ee\u6216\u4fee\u6539\u79c1\u6709\u53d8\u91cf\u4ecd\u7136\u662f\u53ef\u80fd\u7684\u3002\u8fd9\u5728\u7279\u6b8a\u60c5\u51b5\u4e0b\u751a\u81f3\u4f1a\u5f88\u6709\u7528\uff0c\u4f8b\u5982\u5728\u8c03\u8bd5\u5668\uff08debugger\uff09\u4e2d\u3002 \u8bf7\u6ce8\u610f\u4f20\u9012\u7ed9 exec() \u6216 eval() \u7684\u4ee3\u7801\u4e0d\u4f1a\u628a\u53d1\u8d77\u8c03\u7528\u7c7b\u7684\u7c7b\u540d\u89c6\u4f5c\u5f53\u524d\u7c7b\uff1b\u8fd9\u7c7b\u4f3c\u4e8e global \u8bed\u53e5\u7684\u6548\u679c\uff0c\u56e0\u6b64\u8fd9\u79cd\u6548\u679c\u4ec5\u9650\u4e8e\u540c\u65f6\u7ecf\u8fc7\u5b57\u8282\u7801\u7f16\u8bd1\u7684\u4ee3\u7801\u3002 \u540c\u6837\u7684\u9650\u5236\u4e5f\u9002\u7528\u4e8e getattr() , setattr() \u548c delattr() \uff0c\u4ee5\u53ca\u5bf9\u4e8e __dict__ \u7684\u76f4\u63a5\u5f15\u7528\u3002","title":"\u79c1\u6709\u53d8\u91cf Private Variables"},{"location":"python/Foundation/ch05/#reflection","text":"\u53cd\u5c04(reflection)\u662f\u52a8\u6001\u8bed\u8a00\u7684\u4e00\u4e2a\u7279\u6027\u3002 \u53cd\u5c04\u673a\u5236 \u6307\u7684\u662f\u5728\u7a0b\u5e8f\u7684\u8fd0\u884c\u72b6\u6001\u4e2d\uff0c\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u7c7b\uff0c\u90fd\u53ef\u4ee5\u77e5\u9053\u8fd9\u4e2a\u7c7b\u7684\u6240\u6709\u5c5e\u6027\u548c\u65b9\u6cd5\uff1b\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u90fd\u80fd\u591f\u8c03\u7528\u4ed6\u7684\u4efb\u610f\u65b9\u6cd5\u548c\u5c5e\u6027\u3002\u8fd9\u79cd\u52a8\u6001\u83b7\u53d6\u7a0b\u5e8f\u4fe1\u606f\u4ee5\u53ca\u52a8\u6001\u8c03\u7528\u5bf9\u8c61\u7684\u529f\u80fd\u79f0\u4e3a\u53cd\u5c04\u673a\u5236\u3002 \u901a\u8fc7\u4e0b\u9762\u4f8b\u5b50\u53ef\u77e5\uff0c\u901a\u8fc7 dir(person) \u83b7\u53d6\u4efb\u610f\u4e00\u4e2a\u7c7b\u6216\u8005\u5bf9\u8c61\u7684\u5c5e\u6027\u5217\u8868\u3002\u901a\u8fc7\u5185\u7f6e\u51fd\u6570 hasattr \u3001 getattr \u3001 setattr \u3001 delattr \u64cd\u4f5c\u7c7b\u548c\u5bf9\u8c61\u3002 class Person: def __init__(self, name, age, gender): self.name = name self.age = age self.gender = gender person = Person('Tom', 21, 'Male') print(dir(person)) # ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'age', 'gender', 'name'] # hasattr(object,'name') # \u6309\u5b57\u7b26\u4e32'name'\u5224\u65ad\u6709\u65e0\u5c5e\u6027person.name hasattr(person, 'name') # True # getattr(object, 'name', default=None) # \u7b49\u540c\u4e8eperson.name,\u4e0d\u5b58\u5728\u8be5\u5c5e\u6027\u5219\u8fd4\u56de\u9ed8\u8ba4\u503cNone getattr(person, 'name', None) # 'Tom' # setattr(x, 'y', v) # \u7b49\u540c\u4e8eperson.age = 18 setattr(person, 'age', 18) print(person.age) # 18 # delattr(x, 'y') # \u7b49\u540c\u4e8edel person.age delattr(person, 'age') print(person.age) # AttributeError: 'Person' object has no attribute 'age' \u4e0b\u9762\u662f\u4e00\u4e2a\u5b9e\u9645\u5e94\u7528\u7684\u4f8b\u5b50\u3002 class FtpServer(): def server_run(self): while True: inp = input('Input your command >>:').strip() cmd, file = inp.split() if hasattr(self, cmd): func = getattr(self, cmd) func(file) def get(self, file): print(f'Downloading {file}...') def put(self, file): print(f'Uploading {file}...') ftp_server = FtpServer() ftp_server.server_run() # Input your command >>:get a.ext # Downloading a.ext... # Input your command >>:put a.txt # Uploading a.txt...","title":"\u53cd\u5c04(reflection)"},{"location":"python/Foundation/ch05/#iterators","text":"\u5728Python\u4e2d\uff0c\u5927\u591a\u6570\u5bb9\u5668\u5bf9\u8c61\uff08container object\uff09\u90fd\u53ef\u4ee5\u4f7f\u7528 for \u8bed\u53e5: for element in [1, 2, 3]: print(element) for element in (1, 2, 3): print(element) for key in {'one': 1, 'two': 2}: print(key) for char in \"123\": print(char) for line in open(\"myfile.txt\"): print(line, end='') for \u8bed\u53e5\u4f1a\u5728\u5bb9\u5668\u5bf9\u8c61\u4e0a\u8c03\u7528 iter()\u3002 \u8be5\u51fd\u6570\u8fd4\u56de\u4e00\u4e2a\u5b9a\u4e49\u4e86 __next__() \u65b9\u6cd5\u7684\u8fed\u4ee3\u5668\u5bf9\u8c61\uff0c\u6b64\u65b9\u6cd5\u5c06\u9010\u4e00\u8bbf\u95ee\u5bb9\u5668\u4e2d\u7684\u5143\u7d20\u3002 \u5f53\u5143\u7d20\u7528\u5c3d\u65f6\uff0c __next__() \u5c06\u5f15\u53d1 StopIteration \u5f02\u5e38\u6765\u901a\u77e5\u7ec8\u6b62 for \u5faa\u73af\u3002 \u53ef\u4ee5\u4f7f\u7528 next() \u5185\u7f6e\u51fd\u6570\u6765\u8c03\u7528 __next__() \u65b9\u6cd5\uff1b\u4e0b\u9762\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u521a\u521a\u63cf\u8ff0\u7684\u5177\u4f53\u8fd0\u884c\u65b9\u5f0f: >>> s = 'abc' >>> it = iter(s) >>> it <str_iterator object at 0x10c90e650> >>> next(it) 'a' >>> next(it) 'b' >>> next(it) 'c' >>> next(it) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> next(it) StopIteration \u5728\u4e86\u89e3\u4e86\u8fed\u4ee3\u5668\u534f\u8bae\uff08iterator protocol\uff09\u7684\u673a\u5236\u540e\uff0c\u7ed9\u7c7b\u6dfb\u52a0\u8fed\u4ee3\u5668\u5c31\u5f88\u5bb9\u6613\u4e86\u3002 \u5b9a\u4e49\u4e00\u4e2a __iter__() \u65b9\u6cd5\u6765\u8fd4\u56de\u4e00\u4e2a\u5e26\u6709 __next__() \u65b9\u6cd5\u7684\u5bf9\u8c61\u3002 \u5982\u679c\u7c7b\u5df2\u5b9a\u4e49\u4e86 __next__() \uff0c\u5219 __iter__() \u53ef\u4ee5\u7b80\u5355\u5730\u8fd4\u56de self : class Reverse: \"\"\"Iterator for looping over a sequence backwards.\"\"\" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] rev = Reverse('spam') print(iter(rev)) for char in rev: print(char) # m # a # p # s","title":"\u8fed\u4ee3\u5668 Iterators"},{"location":"python/Foundation/ch05/#generators","text":"\u751f\u6210\u5668\uff08Generators\uff09 \u662f\u4e00\u4e2a\u7528\u4e8e\u521b\u5efa\u8fed\u4ee3\u5668\u7684\u7b80\u5355\u800c\u5f3a\u5927\u7684\u5de5\u5177\u3002 \u5b83\u4eec\u7684\u5199\u6cd5\u7c7b\u4f3c\u4e8e\u6807\u51c6\u7684\u51fd\u6570\uff0c\u4f46\u5f53\u5b83\u4eec\u8981\u8fd4\u56de\u6570\u636e\u65f6\u4f1a\u4f7f\u7528 yield \u8bed\u53e5\u3002 \u6bcf\u6b21\u5728\u751f\u6210\u5668\u4e0a\u8c03\u7528 next() \u65f6\uff0c\u5b83\u4f1a\u4ece\u4e0a\u6b21\u79bb\u5f00\u7684\u4f4d\u7f6e\u6062\u590d\u6267\u884c\uff08\u5b83\u4f1a\u8bb0\u4f4f\u4e0a\u6b21\u6267\u884c\u8bed\u53e5\u65f6\u7684\u6240\u6709\u6570\u636e\u503c\uff09\u3002 \u4e00\u4e2a\u521b\u5efa\u751f\u6210\u5668\u7684\u793a\u4f8b\u5982\u4e0b\uff08\u6539\u5199\u4e0a\u9762\u8fed\u4ee3\u5668\u4e2d\u6240\u4e3e\u7684\u4f8b\u5b50\uff09: def reverse(data): for index in range(len(data) - 1, -1, -1): yield data[index] for char in reverse('golf'): print(char) # f # l # o # g \u53ef\u4ee5\u7528\u751f\u6210\u5668\u6765\u5b8c\u6210\u7684\u64cd\u4f5c\u540c\u6837\u53ef\u4ee5\u7528\u524d\u9762\u6240\u63cf\u8ff0\u7684\u57fa\u4e8e\u7c7b\u7684\u8fed\u4ee3\u5668\u6765\u5b8c\u6210\u3002\u4f46\u751f\u6210\u5668\u7684\u5199\u6cd5\u66f4\u4e3a\u7d27\u51d1\uff0c\u56e0\u4e3a\u5b83\u4f1a\u81ea\u52a8\u521b\u5efa __iter__() \u548c __next__() \u65b9\u6cd5\u3002 \u53e6\u4e00\u4e2a\u5173\u952e\u7279\u6027\u5728\u4e8e\u5c40\u90e8\u53d8\u91cf\u548c\u6267\u884c\u72b6\u6001\u4f1a\u5728\u6bcf\u6b21\u8c03\u7528\u4e4b\u95f4\u81ea\u52a8\u4fdd\u5b58\u3002 \u8fd9\u4f7f\u5f97\u8be5\u51fd\u6570\u76f8\u6bd4\u4f7f\u7528 self.index \u548c self.data \u8fd9\u79cd\u5b9e\u4f8b\u53d8\u91cf\u7684\u65b9\u5f0f\u66f4\u6613\u7f16\u5199\u4e14\u66f4\u4e3a\u6e05\u6670\u3002 \u9664\u4e86\u4f1a\u81ea\u52a8\u521b\u5efa\u65b9\u6cd5\u548c\u4fdd\u5b58\u7a0b\u5e8f\u72b6\u6001\uff0c\u5f53\u751f\u6210\u5668\u7ec8\u7ed3\u65f6\uff0c\u5b83\u4eec\u8fd8\u4f1a\u81ea\u52a8\u5f15\u53d1 StopIteration \u3002","title":"\u751f\u6210\u5668 Generators"},{"location":"python/Foundation/ch05/#generator-expressions","text":"\u67d0\u4e9b\u7b80\u5355\u7684\u751f\u6210\u5668\u53ef\u4ee5\u5199\u6210\u7b80\u6d01\u7684\u8868\u8fbe\u5f0f\u4ee3\u7801\uff0c\u6240\u7528\u8bed\u6cd5\u7c7b\u4f3c\u5217\u8868\u63a8\u5bfc\u5f0f\uff0c\u4f46\u5916\u5c42\u4e3a\u5706\u62ec\u53f7\u800c\u975e\u65b9\u62ec\u53f7\u3002 \u8fd9\u79cd\u8868\u8fbe\u5f0f\u88ab\u8bbe\u8ba1\u7528\u4e8e\u751f\u6210\u5668\u5c06\u7acb\u5373\u88ab\u5916\u5c42\u51fd\u6570\u6240\u4f7f\u7528\u7684\u60c5\u51b5\u3002 \u751f\u6210\u5668\u8868\u8fbe\u5f0f\u76f8\u6bd4\u5b8c\u6574\u7684\u751f\u6210\u5668\u66f4\u7d27\u51d1\u4f46\u8f83\u4e0d\u7075\u6d3b\uff0c\u76f8\u6bd4\u7b49\u6548\u7684\u5217\u8868\u63a8\u5bfc\u5f0f\u5219\u66f4\u4e3a\u8282\u7701\u5185\u5b58\u3002 \u793a\u4f8b: >>> sum(i * i for i in range(10)) # sum of squares 285 >>> xvec = [10, 20, 30] >>> yvec = [7, 5, 3] >>> sum(x * y for x, y in zip(xvec, yvec)) # dot product 260 >>> unique_words = set(word for line in page for word in line.split()) >>> valedictorian = max((student.gpa, student.name) for student in graduates) >>> data = 'golf' >>> list(data[i] for i in range(len(data)-1, -1, -1)) ['f', 'l', 'o', 'g']","title":"\u751f\u6210\u5668\u8868\u8fbe\u5f0f Generator Expressions"},{"location":"python/Foundation/ch05/#metaclass","text":"\u6240\u6709\u7684\u5bf9\u8c61\u90fd\u662f\u5b9e\u4f8b\u5316\u6216\u8005\u8bf4\u8c03\u7528\u7c7b\u800c\u5f97\u5230\u7684\uff08\u8c03\u7528\u7c7b\u7684\u8fc7\u7a0b\u79f0\u4e3a\u7c7b\u7684\u5b9e\u4f8b\u5316\u3002 class StandfordProfessor(object): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') \u4e0a\u4f8b\u4e2d\uff0c\u5bf9\u8c61 professor \u662f\u8c03\u7528\u7c7b StandfordProfessor \u5f97\u5230\u7684\u3002\u7c7b StandfordProfessor \u672c\u8d28\u4e5f\u662f\u4e00\u4e2a\u5bf9\u8c61\uff0c \u4e0b\u9762\u53ef\u4ee5\u9a8c\u8bc1\uff0c StandfordProfessor \u662f\u8c03\u7528\u4e86\u5185\u7f6e\u7684\u7c7b type \u5f97\u5230\u7684\u3002\u8fd9\u4e2a type \u79f0\u4e3a\u5143\u7c7b\u3002 print(type(StandfordProfessor)) # <class 'type'> \u5982\u679c\u4e00\u4e2a\u7c7b\u6ca1\u6709\u58f0\u660e\u81ea\u5df1\u7684\u5143\u7c7b\uff0c\u9ed8\u8ba4\u5b83\u7684\u5143\u7c7b\u5c31\u662f type \uff0c\u9664\u4e86\u4f7f\u7528\u5185\u7f6e\u5143\u7c7b type \uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f type \u6765\u81ea\u5b9a\u4e49\u5143\u7c7b\uff0c\u7136\u540e\u4f7f\u7528 metaclass \u5173\u952e\u5b57\u53c2\u6570\u4e3a\u4e00\u4e2a\u7c7b\u7684\u6307\u5b9a\u5143\u7c7b\u3002 \u53ea\u6709\u7ee7\u627f\u4e86type\u7c7b\u624d\u80fd\u79f0\u4e4b\u4e3a\u4e00\u4e2a\u5143\u7c7b\uff0c\u5426\u5219\u5c31\u662f\u4e00\u4e2a\u666e\u901a\u7684\u81ea\u5b9a\u4e49\u7c7b\u3002 class Mymeta(type): pass class StandfordProfessor(object, metaclass=Mymeta): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') \u4e0b\u9762\u8fdb\u884c\u81ea\u5b9a\u4e49\u5143\u7c7b\uff0c\u63a7\u5236\u7c7b StandfordProfessor \u7684\u8c03\u7528\u3002 \u8981\u60f3\u8ba9 professor \u8fd9\u4e2a\u5bf9\u8c61\u53d8\u6210\u4e00\u4e2a\u53ef\u8c03\u7528\u7684\u5bf9\u8c61\uff0c\u9700\u8981\u5728\u8be5\u5bf9\u8c61\u7684\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u65b9\u6cd5 __call__ \uff0c\u8be5\u65b9\u6cd5\u4f1a\u5728\u8c03\u7528\u5bf9\u8c61\u65f6\u81ea\u52a8\u89e6\u53d1\u3002\u8c03\u7528 professor \u7684\u8fd4\u56de\u503c\u5c31\u662f __call__ \u65b9\u6cd5\u7684\u8fd4\u56de\u503c\u3002 class Mymeta(type): def __call__(self, *args, **kwargs): print(self) # \u7c7b\u540d print(args) # \u8f93\u5165\u53c2\u6570 print(kwargs) # \u8f93\u5165\u53c2\u6570 return 10086 class StandfordProfessor(object, metaclass=Mymeta): university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') # <class '__main__.StandfordProfessor'> # ('Tom', 'Male') # {} \u7c7b\u7684\u4ea7\u751f\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u5143\u7c7b\u7684\u8c03\u7528\u8fc7\u7a0b,\u5373 StandfordProfessor = Mymeta('StandfordProfessor', (object), {...}) \uff0c\u8c03\u7528 Mymeta \u4f1a\u5148\u4ea7\u751f\u4e00\u4e2a\u7a7a\u5bf9\u8c61 StandfordProfessor \uff0c\u7136\u540e\u8fde\u540c\u8c03\u7528 Mymeta \u62ec\u53f7\u5185\u7684\u53c2\u6570\u4e00\u540c\u4f20\u7ed9 Mymeta \u4e0b\u7684 __init__ \u65b9\u6cd5\uff0c\u5b8c\u6210\u521d\u59cb\u5316\u3002\u6211\u4eec\u53ef\u4ee5\u57fa\u4e8e\u4e0a\u4f8b\u505a\u5982\u4e0b\u6539\u5199\u3002 class Mymeta(type): def __init__(self, class_name, class_bases, class_dic): super(Mymeta, self).__init__(class_name, class_bases, class_dic) if class_name.islower(): raise TypeError(f'Please follow Camel-Case to change class name {class_name}') if '__doc__' not in class_dic or len(class_dic['__doc__'].strip(' \\n')) == 0: raise TypeError('Please add documentation in class {class_name}, which is mandatory.') class StandfordProfessor(object, metaclass=Mymeta): \"\"\" Documentation of class StanfordTeacher \"\"\" university = 'Standford' def __init__(self, name, gender): self.name = name self.gender = gender def display(self): print(f'Professor {self.name} says welcome to {self.university}!') professor = StandfordProfessor('Tom', 'Male') professor.display() # Professor Tom says welcome to Standford! print(professor.__dict__) # {'name': 'Tom', 'gender': 'Male'} StandfordProfessor.mro() # [<class '__main__.StandfordProfessor'>, <class 'object'>]","title":"\u5143\u7c7b\uff08metaclass\uff09"},{"location":"python/Foundation/ch06/","text":"","title":"Ch06"},{"location":"python/Foundation/python_foundation_index/","text":"\u76ee\u5f55 \u5b89\u88c5 \u8bed\u8a00\u57fa\u7840 Python\u6570\u636e\u7c7b\u578b\uff086\u4e2a\uff09 \u6570\u503c\u578b\uff08number\uff09 \u5b57\u7b26\u578b\uff08string\uff09 \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09 \u5143\u7ec4\uff08tuple\uff09 \u5185\u5b58\u89c6\u56fe\uff08memoryview\uff09 \u52a8\u6001\u5f15\u7528\u3001\u5f3a\u7c7b\u578b \u4e8c\u5143\u8fd0\u7b97\u7b26\u548c\u6bd4\u8f83\u8fd0\u7b97 \u6807\u91cf\u7c7b\u578b \u4e09\u5143\u8868\u8fbe\u5f0f \u6253\u5305Packing\u548c\u62c6\u5305Unpacking \u89e3\u5305Unpacking \u6253\u5305Packing \u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26 \u901a\u8fc7 For-Loops \u89e3\u5305 \u7528 * \u548c ** \u5b9a\u4e49\u51fd\u6570 \u4f7f\u7528 * \u548c ** \u8c03\u7528\u51fd\u6570 \u51fd\u6570\u53ca\u6587\u4ef6 \u533f\u540d\uff08Lambda\uff09\u51fd\u6570 \u5185\u7f6e\u5e8f\u5217\u51fd\u6570enumerate \u5217\u8868\u3001\u96c6\u5408\u548c\u5b57\u5178\u7684\u63a8\u5bfc\u5f0f \u51fd\u6570\u58f0\u660e \u547d\u540d\u7a7a\u95f4\u3001\u4f5c\u7528\u57df\u548c\u672c\u5730\u51fd\u6570 \u67ef\u91cc\u5316\uff1a\u90e8\u5206\u53c2\u6570\u5e94\u7528 \u8fed\u4ee3\u5668\u4e0e\u751f\u6210\u5668 \u8fed\u4ee3\u5668 \u751f\u6210\u5668 \u751f\u6210\u5668 itertools \u9519\u8bef\u548c\u5f02\u5e38\u5904\u7406 \u6587\u4ef6\u4e0e\u64cd\u4f5c\u7cfb\u7edf \u88c5\u9970\u5668 \u95ed\u5305 \u88c5\u9970\u5668 \u9762\u5411\u5bf9\u8c61\u6982\u5ff5 \u540d\u79f0Names\u548c\u5bf9\u8c61Objects \u4f5c\u7528\u57dfScopes\u548c\u547d\u540d\u7a7a\u95f4Namespace \u7c7bClass \u7c7b\u5b9a\u4e49 Class Definition \u7c7b\u5bf9\u8c61 Class Objects \u5b9e\u4f8b\u5bf9\u8c61 Instance Objects \u65b9\u6cd5\u5bf9\u8c61 Method Objects \u7c7b\u548c\u5b9e\u4f8b\u53d8\u91cf Class and Instance Variables \u603b\u7ed3 \u7c7b\u5b9a\u4e49\u5c0f\u7ed3 \u7c7b\u6210\u5458\u64cd\u4f5c\uff08\u4e0d\u63a8\u8350\uff09\uff1a \u6210\u5458\u65b9\u6cd5\u4e2d\u7684self \u9b54\u672f\u65b9\u6cd5 __init__\u521d\u59cb\u5316\u65b9\u6cd5 __del__\u6790\u6784\u65b9\u6cd5 \u9762\u5411\u5bf9\u8c61\u4e09\u5927\u7279\u6027 \u5c01\u88c5 Encapsulation \u7ee7\u627f Inheritance \u591a\u91cd\u7ee7\u627f Multiple Inheritance \u83f1\u5f62\u7ee7\u627f \u7ee7\u627f\u5173\u7cfb\u68c0\u6d4b \u591a\u6001 Polymorphism \u7c7b\u65b9\u6cd5\u7684\u591a\u6001\u6027 \u7ee7\u627f\u7684\u591a\u6001\u6027 \u51fd\u6570\u548c\u5bf9\u8c61\u7684\u591a\u6001\u6027 \u9e2d\u5b50\u7c7b\u578b(Ducking Typing) \u79c1\u6709\u53d8\u91cf Private Variables \u8fed\u4ee3\u5668 Iterators \u751f\u6210\u5668 Generators \u751f\u6210\u5668\u8868\u8fbe\u5f0f Generator Expressions","title":"\u76ee\u5f55"},{"location":"python/Foundation/python_foundation_index/#_1","text":"","title":"\u76ee\u5f55"},{"location":"python/Foundation/python_foundation_index/#_2","text":"","title":"\u5b89\u88c5"},{"location":"python/Foundation/python_foundation_index/#_3","text":"Python\u6570\u636e\u7c7b\u578b\uff086\u4e2a\uff09 \u6570\u503c\u578b\uff08number\uff09 \u5b57\u7b26\u578b\uff08string\uff09 \u5217\u8868\uff08list\uff09 \u5b57\u5178\uff08dictionary\uff09 \u96c6\u5408\uff08set\uff09 \u5143\u7ec4\uff08tuple\uff09 \u5185\u5b58\u89c6\u56fe\uff08memoryview\uff09 \u52a8\u6001\u5f15\u7528\u3001\u5f3a\u7c7b\u578b \u4e8c\u5143\u8fd0\u7b97\u7b26\u548c\u6bd4\u8f83\u8fd0\u7b97 \u6807\u91cf\u7c7b\u578b \u4e09\u5143\u8868\u8fbe\u5f0f","title":"\u8bed\u8a00\u57fa\u7840"},{"location":"python/Foundation/python_foundation_index/#packingunpacking","text":"\u89e3\u5305Unpacking \u6253\u5305Packing \u4f7f\u7528 * \u548c ** \u8fd0\u7b97\u7b26 \u901a\u8fc7 For-Loops \u89e3\u5305 \u7528 * \u548c ** \u5b9a\u4e49\u51fd\u6570 \u4f7f\u7528 * \u548c ** \u8c03\u7528\u51fd\u6570","title":"\u6253\u5305Packing\u548c\u62c6\u5305Unpacking"},{"location":"python/Foundation/python_foundation_index/#_4","text":"\u533f\u540d\uff08Lambda\uff09\u51fd\u6570 \u5185\u7f6e\u5e8f\u5217\u51fd\u6570enumerate \u5217\u8868\u3001\u96c6\u5408\u548c\u5b57\u5178\u7684\u63a8\u5bfc\u5f0f \u51fd\u6570\u58f0\u660e \u547d\u540d\u7a7a\u95f4\u3001\u4f5c\u7528\u57df\u548c\u672c\u5730\u51fd\u6570 \u67ef\u91cc\u5316\uff1a\u90e8\u5206\u53c2\u6570\u5e94\u7528 \u8fed\u4ee3\u5668\u4e0e\u751f\u6210\u5668 \u8fed\u4ee3\u5668 \u751f\u6210\u5668 \u751f\u6210\u5668 itertools \u9519\u8bef\u548c\u5f02\u5e38\u5904\u7406 \u6587\u4ef6\u4e0e\u64cd\u4f5c\u7cfb\u7edf \u88c5\u9970\u5668 \u95ed\u5305 \u88c5\u9970\u5668","title":"\u51fd\u6570\u53ca\u6587\u4ef6"},{"location":"python/Foundation/python_foundation_index/#_5","text":"\u540d\u79f0Names\u548c\u5bf9\u8c61Objects \u4f5c\u7528\u57dfScopes\u548c\u547d\u540d\u7a7a\u95f4Namespace \u7c7bClass \u7c7b\u5b9a\u4e49 Class Definition \u7c7b\u5bf9\u8c61 Class Objects \u5b9e\u4f8b\u5bf9\u8c61 Instance Objects \u65b9\u6cd5\u5bf9\u8c61 Method Objects \u7c7b\u548c\u5b9e\u4f8b\u53d8\u91cf Class and Instance Variables \u603b\u7ed3 \u7c7b\u5b9a\u4e49\u5c0f\u7ed3 \u7c7b\u6210\u5458\u64cd\u4f5c\uff08\u4e0d\u63a8\u8350\uff09\uff1a \u6210\u5458\u65b9\u6cd5\u4e2d\u7684self \u9b54\u672f\u65b9\u6cd5 __init__\u521d\u59cb\u5316\u65b9\u6cd5 __del__\u6790\u6784\u65b9\u6cd5","title":"\u9762\u5411\u5bf9\u8c61\u6982\u5ff5"},{"location":"python/Foundation/python_foundation_index/#_6","text":"\u5c01\u88c5 Encapsulation \u7ee7\u627f Inheritance \u591a\u91cd\u7ee7\u627f Multiple Inheritance \u83f1\u5f62\u7ee7\u627f \u7ee7\u627f\u5173\u7cfb\u68c0\u6d4b \u591a\u6001 Polymorphism \u7c7b\u65b9\u6cd5\u7684\u591a\u6001\u6027 \u7ee7\u627f\u7684\u591a\u6001\u6027 \u51fd\u6570\u548c\u5bf9\u8c61\u7684\u591a\u6001\u6027 \u9e2d\u5b50\u7c7b\u578b(Ducking Typing) \u79c1\u6709\u53d8\u91cf Private Variables \u8fed\u4ee3\u5668 Iterators \u751f\u6210\u5668 Generators \u751f\u6210\u5668\u8868\u8fbe\u5f0f Generator Expressions","title":"\u9762\u5411\u5bf9\u8c61\u4e09\u5927\u7279\u6027"}]}