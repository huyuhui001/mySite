<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=https://huyuhui001.github.io/mySite/k8s/foundamentals/casestudy-calico/ rel=canonical><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.3.0, mkdocs-material-7.3.6"><title>Calico Installation - MEMO</title><link rel=stylesheet href=../../../assets/stylesheets/main.a57b2b03.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.3f5d1f46.min.css><meta name=theme-color content=#009485><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style><link rel=stylesheet href=../../../extra.css></head> <body dir=ltr data-md-color-scheme data-md-color-primary=teal data-md-color-accent=green> <script>function __prefix(e){return new URL("../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#case-study-install-calico class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title=MEMO class="md-header__button md-logo" aria-label=MEMO data-md-component=logo> <img src=../../../assets/logo.jpg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> MEMO </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Calico Installation </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/huyuhui001/mySite title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> huyuhui001/mySite </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../installation/single-local/ class="md-tabs__link md-tabs__link--active"> Kubernetes </a> </li> <li class=md-tabs__item> <a href=../../../linux/Administration/linux_admin/ class=md-tabs__link> Linux </a> </li> <li class=md-tabs__item> <a href=../../../python/Foundation/python_foundation_index/ class=md-tabs__link> Python </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=MEMO class="md-nav__button md-logo" aria-label=MEMO data-md-component=logo> <img src=../../../assets/logo.jpg alt=logo> </a> MEMO </label> <div class=md-nav__source> <a href=https://github.com/huyuhui001/mySite title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> huyuhui001/mySite </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1 type=checkbox id=__nav_1 checked> <label class=md-nav__link for=__nav_1> Kubernetes <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Kubernetes data-md-level=1> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Kubernetes </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_1 type=checkbox id=__nav_1_1> <label class=md-nav__link for=__nav_1_1> Installation <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Installation data-md-level=2> <label class=md-nav__title for=__nav_1_1> <span class="md-nav__icon md-icon"></span> Installation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../installation/single-local/ class=md-nav__link> Single Node Installation </a> </li> <li class=md-nav__item> <a href=../../installation/multiple-local/ class=md-nav__link> Multiple Nodes Installation </a> </li> <li class=md-nav__item> <a href=../../installation/aliyun-ubuntu/ class=md-nav__link> Installation on Aliyun ECS </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_2 type=checkbox id=__nav_1_2> <label class=md-nav__link for=__nav_1_2> Docker <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Docker data-md-level=2> <label class=md-nav__title for=__nav_1_2> <span class="md-nav__icon md-icon"></span> Docker </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../docker/ class=md-nav__link> Fundamentals </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_3 type=checkbox id=__nav_1_3> <label class=md-nav__link for=__nav_1_3> Foundamentals <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Foundamentals data-md-level=2> <label class=md-nav__title for=__nav_1_3> <span class="md-nav__icon md-icon"></span> Foundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../memo/ class=md-nav__link> Memo </a> </li> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../basics/ class=md-nav__link> kubectl basics </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_4 type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4> Core Kubernetes <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Core Kubernetes" data-md-level=2> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Core Kubernetes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../pod/ class=md-nav__link> Pod </a> </li> <li class=md-nav__item> <a href=../deployment/ class=md-nav__link> Deployment </a> </li> <li class=md-nav__item> <a href=../service/ class=md-nav__link> Service </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_5 type=checkbox id=__nav_1_5> <label class=md-nav__link for=__nav_1_5> Application Modelling <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Application Modelling" data-md-level=2> <label class=md-nav__title for=__nav_1_5> <span class="md-nav__icon md-icon"></span> Application Modelling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../namespace/ class=md-nav__link> Namespace </a> </li> <li class=md-nav__item> <a href=../statefulset/ class=md-nav__link> StatefulSet </a> </li> <li class=md-nav__item> <a href=../daemonset/ class=md-nav__link> DaemonSet </a> </li> <li class=md-nav__item> <a href=../job/ class=md-nav__link> Job and Cronjob </a> </li> <li class=md-nav__item> <a href=../configuration/ class=md-nav__link> Configuration </a> </li> <li class=md-nav__item> <a href=../secrets/ class=md-nav__link> Secrets </a> </li> <li class=md-nav__item> <a href=../persistence/ class=md-nav__link> Persistence </a> </li> <li class=md-nav__item> <a href=../rbac/ class=md-nav__link> Role Based Access Control (RBAC) </a> </li> <li class=md-nav__item> <a href=../ingress/ class=md-nav__link> Ingress </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_6 type=checkbox id=__nav_1_6> <label class=md-nav__link for=__nav_1_6> Advanced Kubernetes <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Advanced Kubernetes" data-md-level=2> <label class=md-nav__title for=__nav_1_6> <span class="md-nav__icon md-icon"></span> Advanced Kubernetes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../scheduling/ class=md-nav__link> Scheduling </a> </li> <li class=md-nav__item> <a href=../hpa/ class=md-nav__link> Horizontal Pod Autoscaling </a> </li> <li class=md-nav__item> <a href=../policy/ class=md-nav__link> Policy </a> </li> <li class=md-nav__item> <a href=../networkpolicy/ class=md-nav__link> Network Policy </a> </li> <li class=md-nav__item> <a href=../clustermgt/ class=md-nav__link> Cluster Management </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_7 type=checkbox id=__nav_1_7> <label class=md-nav__link for=__nav_1_7> Operating Kubernetes <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Operating Kubernetes" data-md-level=2> <label class=md-nav__title for=__nav_1_7> <span class="md-nav__icon md-icon"></span> Operating Kubernetes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../troubleshooting/ class=md-nav__link> Troubleshooting </a> </li> <li class=md-nav__item> <a href=../healthcheck/ class=md-nav__link> Health Check </a> </li> <li class=md-nav__item> <a href=../helming/ class=md-nav__link> Helming </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_1_8 type=checkbox id=__nav_1_8 checked> <label class=md-nav__link for=__nav_1_8> Case Study <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Case Study" data-md-level=2> <label class=md-nav__title for=__nav_1_8> <span class="md-nav__icon md-icon"></span> Case Study </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../casestudy-operation-resources/ class=md-nav__link> Operations on Resources </a> </li> <li class=md-nav__item> <a href=../casestudy-health-check/ class=md-nav__link> Health Check </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Calico Installation <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Calico Installation </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#the-calico-datastore class=md-nav__link> The Calico Datastore </a> </li> <li class=md-nav__item> <a href=#configure-ip-pools class=md-nav__link> Configure IP Pools </a> </li> <li class=md-nav__item> <a href=#install-cni-plugin class=md-nav__link> Install CNI plugin </a> </li> <li class=md-nav__item> <a href=#install-typha class=md-nav__link> Install Typha </a> </li> <li class=md-nav__item> <a href=#install-caliconode class=md-nav__link> Install calico/node </a> </li> <li class=md-nav__item> <a href=#test-networking class=md-nav__link> Test networking </a> <nav class=md-nav aria-label="Test networking"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pod-to-pod-pings class=md-nav__link> Pod to pod pings </a> </li> <li class=md-nav__item> <a href=#check-routes class=md-nav__link> Check routes </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2> Linux <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Linux data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Linux </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../linux/Administration/linux_admin/ class=md-nav__link> SUSE Linux Administration </a> </li> <li class=md-nav__item> <a href=../../../linux/SES/linux_ses/ class=md-nav__link> SUSE Enterprise Storage Foundation </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> Python <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Python data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Python </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../python/Foundation/python_foundation_index/ class=md-nav__link> Python Foundamentals </a> </li> <li class=md-nav__item> <a href=../../../python/DataAnalysis/python_data_analysis_index/ class=md-nav__link> Data Analysis </a> </li> <li class=md-nav__item> <a href=../../../python/Demo/python_demo_index/ class=md-nav__link> Demos </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#the-calico-datastore class=md-nav__link> The Calico Datastore </a> </li> <li class=md-nav__item> <a href=#configure-ip-pools class=md-nav__link> Configure IP Pools </a> </li> <li class=md-nav__item> <a href=#install-cni-plugin class=md-nav__link> Install CNI plugin </a> </li> <li class=md-nav__item> <a href=#install-typha class=md-nav__link> Install Typha </a> </li> <li class=md-nav__item> <a href=#install-caliconode class=md-nav__link> Install calico/node </a> </li> <li class=md-nav__item> <a href=#test-networking class=md-nav__link> Test networking </a> <nav class=md-nav aria-label="Test networking"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pod-to-pod-pings class=md-nav__link> Pod to pod pings </a> </li> <li class=md-nav__item> <a href=#check-routes class=md-nav__link> Check routes </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/huyuhui001/mySite/edit/main/docs/k8s/foundamentals/casestudy-calico.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=case-study-install-calico>Case Study: Install Calico<a class=headerlink href=#case-study-install-calico title="Permanent link"> ¶</a></h1> <div class="admonition scenario"> <p class=admonition-title>Scenario</p> <p>Install Calico</p> <ul> <li>Calico Datastore</li> <li>Configure IP Pools</li> <li>Install CNI plugin</li> <li>Install Typha</li> <li>Install calico/node</li> <li>Test networking</li> </ul> </div> <h2 id=the-calico-datastore>The Calico Datastore<a class=headerlink href=#the-calico-datastore title="Permanent link"> ¶</a></h2> <p>In order to use Kubernetes as the Calico datastore, we need to define the custom resources Calico uses.</p> <p>Download and examine the list of Calico custom resource definitions, and open it in a file editor. <div class=highlight><pre><span></span><code><span class=go>wget https://projectcalico.docs.tigera.io/manifests/crds.yaml</span>
</code></pre></div></p> <p>Create the custom resource definitions in Kubernetes. <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f crds.yaml</span>
</code></pre></div></p> <p>Install <code>calicoctl</code>. To interact directly with the Calico datastore, use the <code>calicoctl</code> client tool.</p> <p>Download the calicoctl binary to a Linux host with access to Kubernetes. The latest release of calicoctl can be found in the <a href=https://github.com/projectcalico/calico/releases>git page</a> and replace below <code>v3.23.2</code> by actual release number. <div class=highlight><pre><span></span><code><span class=go>wget https://github.com/projectcalico/calico/releases/download/v3.23.3/calicoctl-linux-amd64</span>
<span class=go>chmod +x calicoctl-linux-amd64</span>
<span class=go>sudo cp calicoctl-linux-amd64 /usr/local/bin/calicoctl</span>
</code></pre></div></p> <p>Configure calicoctl to access Kubernetes <div class=highlight><pre><span></span><code><span class=go>echo &quot;export KUBECONFIG=/root/.kube/config&quot; &gt;&gt; ~/.bashrc</span>
<span class=go>echo &quot;export DATASTORE_TYPE=kubernetes&quot; &gt;&gt; ~/.bashrc</span>

<span class=go>echo $KUBECONFIG</span>
<span class=go>echo $DATASTORE_TYPE</span>
</code></pre></div></p> <p>Verify <code>calicoctl</code> can reach the datastore by running： <div class=highlight><pre><span></span><code><span class=go>calicoctl get nodes -o wide</span>
</code></pre></div> Output similar to below: <div class=highlight><pre><span></span><code>NAME     ASN   IPV4   IPV6   
cka001                       
cka002                       
cka003  
</code></pre></div></p> <p>Nodes are backed by the Kubernetes node object, so we should see names that match <code>kubectl get nodes</code>. <div class=highlight><pre><span></span><code><span class=go>kubectl get nodes -o wide</span>
</code></pre></div> <div class=highlight><pre><span></span><code>NAME     STATUS     ROLES                  AGE   VERSION   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
cka001   NotReady   control-plane,master   23m   v1.24.0   Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.5.9
cka002   NotReady   &lt;none&gt;                 22m   v1.24.0   Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.5.9
cka003   NotReady   &lt;none&gt;                 21m   v1.24.0   Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.5.9
</code></pre></div></p> <h2 id=configure-ip-pools>Configure IP Pools<a class=headerlink href=#configure-ip-pools title="Permanent link"> ¶</a></h2> <p>A workload is a container or VM that Calico handles the virtual networking for. In Kubernetes, workloads are pods. A workload endpoint is the virtual network interface a workload uses to connect to the Calico network.</p> <p>IP pools are ranges of IP addresses that Calico uses for workload endpoints.</p> <p>Get current IP pools in the cluster. So far, it's empty after fresh installation. <div class=highlight><pre><span></span><code><span class=go>calicoctl get ippools</span>
</code></pre></div> <div class=highlight><pre><span></span><code>NAME   CIDR   SELECTOR 
</code></pre></div></p> <p>The Pod CIDR is <code>10.244.0.0/16</code> we specified via <code>kubeadm init</code>.</p> <p>Let's create two IP pools for use in the cluster. Each pool can not have any overlaps.</p> <ul> <li>ipv4-ippool-1: <code>10.244.0.0/18</code></li> <li>ipv4-ippool-2: <code>10.244.192.0/19</code></li> </ul> <p><div class=highlight><pre><span></span><code><span class=go>calicoctl apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: projectcalico.org/v3</span>
<span class=go>kind: IPPool</span>
<span class=go>metadata:</span>
<span class=go>  name: ipv4-ippool-1</span>
<span class=go>spec:</span>
<span class=go>  cidr: 10.244.0.0/18</span>
<span class=go>  ipipMode: Never</span>
<span class=go>  natOutgoing: true</span>
<span class=go>  disabled: false</span>
<span class=go>  nodeSelector: all()</span>
<span class=go>EOF</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>calicoctl apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: projectcalico.org/v3</span>
<span class=go>kind: IPPool</span>
<span class=go>metadata:</span>
<span class=go>  name: ipv4-ippool-2</span>
<span class=go>spec:</span>
<span class=go>  cidr: 10.244.192.0/19</span>
<span class=go>  ipipMode: Never</span>
<span class=go>  natOutgoing: true</span>
<span class=go>  disabled: true</span>
<span class=go>  nodeSelector: all()</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>IP pool now looks like below. <div class=highlight><pre><span></span><code><span class=go>calicoctl get ippools -o wide</span>
</code></pre></div> <div class=highlight><pre><span></span><code>NAME            CIDR              NAT    IPIPMODE   VXLANMODE   DISABLED   DISABLEBGPEXPORT   SELECTOR   
ipv4-ippool-1   10.244.0.0/18     true   Never      Never       false      false              all()      
ipv4-ippool-2   10.244.192.0/19   true   Never      Never       true       false              all()     
</code></pre></div></p> <h2 id=install-cni-plugin>Install CNI plugin<a class=headerlink href=#install-cni-plugin title="Permanent link"> ¶</a></h2> <ul> <li>Provision Kubernetes user account for the plugin.</li> </ul> <p>Kubernetes uses the Container Network Interface (CNI) to interact with networking providers like Calico. The Calico binary that presents this API to Kubernetes is called the CNI plugin and must be installed on every node in the Kubernetes cluster.</p> <p>The CNI plugin interacts with the Kubernetes API server while creating pods, both to obtain additional information and to update the datastore with information about the pod.</p> <p>On the Kubernetes <em>master</em> node, create a key for the CNI plugin to authenticate with and certificate signing request.</p> <p>Change to directory <code>/etc/kubernetes/pki/</code>. <div class=highlight><pre><span></span><code><span class=go>cd /etc/kubernetes/pki/</span>
</code></pre></div> <div class=highlight><pre><span></span><code>openssl req -newkey rsa:4096 \
  -keyout cni.key \
  -nodes \
  -out cni.csr \
  -subj &quot;/CN=calico-cni&quot;
</code></pre></div></p> <p>We will sign this certificate using the main Kubernetes CA. <div class=highlight><pre><span></span><code><span class=go>sudo openssl x509 -req -in cni.csr \</span>
<span class=go>  -CA /etc/kubernetes/pki/ca.crt \</span>
<span class=go>  -CAkey /etc/kubernetes/pki/ca.key \</span>
<span class=go>  -CAcreateserial \</span>
<span class=go>  -out cni.crt \</span>
<span class=go>  -days 3650</span>
</code></pre></div> Output looks like below. User is <code>calico-cni</code>. <div class=highlight><pre><span></span><code>Signature ok
subject=CN = calico-cni
Getting CA Private Key
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>sudo chown $(id -u):$(id -g) cni.crt</span>
</code></pre></div></p> <p>Next, we create a kubeconfig file for the CNI plugin to use to access Kubernetes. Copy this <code>cni.kubeconfig</code> file to every node in the cluster.</p> <p>Stay in directory <code>/etc/kubernetes/pki/</code>. <div class=highlight><pre><span></span><code><span class=go>APISERVER=$(kubectl config view -o jsonpath=&#39;{.clusters[0].cluster.server}&#39;)</span>

<span class=go>echo $APISERVER</span>

<span class=go>kubectl config set-cluster kubernetes \</span>
<span class=go>  --certificate-authority=/etc/kubernetes/pki/ca.crt \</span>
<span class=go>  --embed-certs=true \</span>
<span class=go>  --server=$APISERVER \</span>
<span class=go>  --kubeconfig=cni.kubeconfig</span>

<span class=go>kubectl config set-credentials calico-cni \</span>
<span class=go>  --client-certificate=cni.crt \</span>
<span class=go>  --client-key=cni.key \</span>
<span class=go>  --embed-certs=true \</span>
<span class=go>  --kubeconfig=cni.kubeconfig</span>

<span class=go>kubectl config set-context cni@kubernetes \</span>
<span class=go>  --cluster=kubernetes \</span>
<span class=go>  --user=calico-cni \</span>
<span class=go>  --kubeconfig=cni.kubeconfig</span>

<span class=go>kubectl config use-context cni@kubernetes --kubeconfig=cni.kubeconfig</span>
</code></pre></div></p> <p>The context for CNI looks like below. <div class=highlight><pre><span></span><code><span class=go>kubectl config get-contexts --kubeconfig=cni.kubeconfig</span>
</code></pre></div> <div class=highlight><pre><span></span><code>CURRENT   NAME             CLUSTER      AUTHINFO     NAMESPACE
*         cni@kubernetes   kubernetes   calico-cni 
</code></pre></div></p> <ul> <li>Provision RBAC</li> </ul> <p>Change to home directory <div class=highlight><pre><span></span><code><span class=go>cd ~</span>
</code></pre></div></p> <p>Define a cluster role the CNI plugin will use to access Kubernetes.</p> <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>kind: ClusterRole</span>
<span class=go>apiVersion: rbac.authorization.k8s.io/v1</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-cni</span>
<span class=go>rules:</span>
<span class=gp>  # </span>The CNI plugin needs to get pods, nodes, and namespaces.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods</span>
<span class=go>      - nodes</span>
<span class=go>      - namespaces</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=gp>  # </span>The CNI plugin patches pods/status.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods/status</span>
<span class=go>    verbs:</span>
<span class=go>      - patch</span>
<span class=gp> # </span>These permissions are required <span class=k>for</span> Calico CNI to perform IPAM allocations.
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - blockaffinities</span>
<span class=go>      - ipamblocks</span>
<span class=go>      - ipamhandles</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>      - create</span>
<span class=go>      - update</span>
<span class=go>      - delete</span>
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - ipamconfigs</span>
<span class=go>      - clusterinformations</span>
<span class=go>      - ippools</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>EOF</span>
</code></pre></div> <p>Bind the cluster role to the <code>calico-cni</code> account. <div class=highlight><pre><span></span><code><span class=go>kubectl create clusterrolebinding calico-cni --clusterrole=calico-cni --user=calico-cni</span>
</code></pre></div></p> <ul> <li>Install the plugin</li> </ul> <p>Do these steps on <strong>each node</strong> in your cluster.</p> <p>Installation on <code>cka001</code>.</p> <p>Run these commands as <strong>root</strong>. <div class=highlight><pre><span></span><code><span class=go>sudo su</span>
</code></pre></div></p> <p>Install the CNI plugin Binaries. Get right release in the link <code>https://github.com/projectcalico/cni-plugin/releases</code>, and link <code>https://github.com/containernetworking/plugins/releases</code>. <div class=highlight><pre><span></span><code><span class=go>mkdir -p /opt/cni/bin</span>

<span class=go>curl -L -o /opt/cni/bin/calico https://github.com/projectcalico/cni-plugin/releases/download/v3.20.5/calico-amd64</span>
<span class=go>chmod 755 /opt/cni/bin/calico</span>

<span class=go>curl -L -o /opt/cni/bin/calico-ipam https://github.com/projectcalico/cni-plugin/releases/download/v3.20.5/calico-ipam-amd64</span>
<span class=go>chmod 755 /opt/cni/bin/calico-ipam</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>wget https://github.com/containernetworking/plugins/releases/download/v1.1.1/cni-plugins-linux-amd64-v1.1.1.tgz</span>
<span class=go>tar xvf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin</span>
</code></pre></div></p> <p>Create the config directory <div class=highlight><pre><span></span><code><span class=go>mkdir -p /etc/cni/net.d/</span>
</code></pre></div></p> <p>Copy the kubeconfig from the previous section <div class=highlight><pre><span></span><code><span class=go>cp /etc/kubernetes/pki/cni.kubeconfig /etc/cni/net.d/calico-kubeconfig</span>

<span class=go>chmod 600 /etc/cni/net.d/calico-kubeconfig</span>
</code></pre></div></p> <p>Write the CNI configuration <div class=highlight><pre><span></span><code><span class=go>cat &gt; /etc/cni/net.d/10-calico.conflist &lt;&lt;EOF</span>
<span class=go>{</span>
<span class=go>  &quot;name&quot;: &quot;k8s-pod-network&quot;,</span>
<span class=go>  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span>
<span class=go>  &quot;plugins&quot;: [</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;calico&quot;,</span>
<span class=go>      &quot;log_level&quot;: &quot;info&quot;,</span>
<span class=go>      &quot;datastore_type&quot;: &quot;kubernetes&quot;,</span>
<span class=go>      &quot;mtu&quot;: 1500,</span>
<span class=go>      &quot;ipam&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;calico-ipam&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;policy&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;k8s&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;kubernetes&quot;: {</span>
<span class=go>          &quot;kubeconfig&quot;: &quot;/etc/cni/net.d/calico-kubeconfig&quot;</span>
<span class=go>      }</span>
<span class=go>    },</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;portmap&quot;,</span>
<span class=go>      &quot;snat&quot;: true,</span>
<span class=go>      &quot;capabilities&quot;: {&quot;portMappings&quot;: true}</span>
<span class=go>    }</span>
<span class=go>  ]</span>
<span class=go>}</span>
<span class=go>EOF</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>cp /etc/cni/net.d/calico-kubeconfig ~</span>
</code></pre></div></p> <p>Exit from su and go back to the logged in user. <div class=highlight><pre><span></span><code><span class=go>exit</span>
</code></pre></div></p> <p>Installation on <code>cka002</code>.</p> <p><div class=highlight><pre><span></span><code><span class=go>sftp -i cka-key-pair.pem cka002</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>put calico-amd64</span>
<span class=go>put calicoctl-linux-amd64</span>
<span class=go>put calico-ipam-amd64</span>
<span class=go>put calico-kubeconfig</span>
<span class=go>put cni-plugins-linux-amd64-v1.1.1.tgz</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>ssh -i cka-key-pair.pem cka002</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>mkdir -p /opt/cni/bin</span>

<span class=go>cp calico-amd64 /opt/cni/bin/calico</span>
<span class=go>cp calico-ipam-amd64 /opt/cni/bin/calico-ipam</span>

<span class=go>tar xvf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin</span>

<span class=go>mkdir -p /etc/cni/net.d/</span>

<span class=go>cp calico-kubeconfig /etc/cni/net.d/calico-kubeconfig</span>

<span class=go>chmod 600 /etc/cni/net.d/calico-kubeconfig</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>cat &gt; /etc/cni/net.d/10-calico.conflist &lt;&lt;EOF</span>
<span class=go>{</span>
<span class=go>  &quot;name&quot;: &quot;k8s-pod-network&quot;,</span>
<span class=go>  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span>
<span class=go>  &quot;plugins&quot;: [</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;calico&quot;,</span>
<span class=go>      &quot;log_level&quot;: &quot;info&quot;,</span>
<span class=go>      &quot;datastore_type&quot;: &quot;kubernetes&quot;,</span>
<span class=go>      &quot;mtu&quot;: 1500,</span>
<span class=go>      &quot;ipam&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;calico-ipam&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;policy&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;k8s&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;kubernetes&quot;: {</span>
<span class=go>          &quot;kubeconfig&quot;: &quot;/etc/cni/net.d/calico-kubeconfig&quot;</span>
<span class=go>      }</span>
<span class=go>    },</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;portmap&quot;,</span>
<span class=go>      &quot;snat&quot;: true,</span>
<span class=go>      &quot;capabilities&quot;: {&quot;portMappings&quot;: true}</span>
<span class=go>    }</span>
<span class=go>  ]</span>
<span class=go>}</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Back to <code>cka001</code>. <div class=highlight><pre><span></span><code><span class=go>exit</span>
</code></pre></div></p> <p>Installation on <code>cka003</code>.</p> <p><div class=highlight><pre><span></span><code><span class=go>sftp -i cka-key-pair.pem cka003</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>put calico-amd64</span>
<span class=go>put calicoctl-linux-amd64</span>
<span class=go>put calico-ipam-amd64</span>
<span class=go>put calico-kubeconfig</span>
<span class=go>put cni-plugins-linux-amd64-v1.1.1.tgz</span>
</code></pre></div></p> <p><div class=highlight><pre><span></span><code><span class=go>ssh -i cka-key-pair.pem cka003</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>mkdir -p /opt/cni/bin</span>

<span class=go>cp calico-amd64 /opt/cni/bin/calico</span>
<span class=go>cp calico-ipam-amd64 /opt/cni/bin/calico-ipam</span>

<span class=go>tar xvf cni-plugins-linux-amd64-v1.1.1.tgz -C /opt/cni/bin</span>

<span class=go>mkdir -p /etc/cni/net.d/</span>

<span class=go>cp calico-kubeconfig /etc/cni/net.d/calico-kubeconfig</span>

<span class=go>chmod 600 /etc/cni/net.d/calico-kubeconfig</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>cat &gt; /etc/cni/net.d/10-calico.conflist &lt;&lt;EOF</span>
<span class=go>{</span>
<span class=go>  &quot;name&quot;: &quot;k8s-pod-network&quot;,</span>
<span class=go>  &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span>
<span class=go>  &quot;plugins&quot;: [</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;calico&quot;,</span>
<span class=go>      &quot;log_level&quot;: &quot;info&quot;,</span>
<span class=go>      &quot;datastore_type&quot;: &quot;kubernetes&quot;,</span>
<span class=go>      &quot;mtu&quot;: 1500,</span>
<span class=go>      &quot;ipam&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;calico-ipam&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;policy&quot;: {</span>
<span class=go>          &quot;type&quot;: &quot;k8s&quot;</span>
<span class=go>      },</span>
<span class=go>      &quot;kubernetes&quot;: {</span>
<span class=go>          &quot;kubeconfig&quot;: &quot;/etc/cni/net.d/calico-kubeconfig&quot;</span>
<span class=go>      }</span>
<span class=go>    },</span>
<span class=go>    {</span>
<span class=go>      &quot;type&quot;: &quot;portmap&quot;,</span>
<span class=go>      &quot;snat&quot;: true,</span>
<span class=go>      &quot;capabilities&quot;: {&quot;portMappings&quot;: true}</span>
<span class=go>    }</span>
<span class=go>  ]</span>
<span class=go>}</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Back to <code>cka001</code>. <div class=highlight><pre><span></span><code><span class=go>exit</span>
</code></pre></div></p> <p>Stay in home directory in node <code>cka001</code>.</p> <p>At this point Kubernetes nodes will become Ready because Kubernetes has a networking provider and configuration installed. <div class=highlight><pre><span></span><code><span class=go>kubectl get nodes</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>NAME     STATUS   ROLES                  AGE     VERSION
cka001   Ready    control-plane,master   4h50m   v1.24.0
cka002   Ready    &lt;none&gt;                 4h49m   v1.24.0
cka003   Ready    &lt;none&gt;                 4h49m   v1.24.0
</code></pre></div></p> <h2 id=install-typha>Install Typha<a class=headerlink href=#install-typha title="Permanent link"> ¶</a></h2> <p>Typha sits between the Kubernetes API server and per-node daemons like Felix and confd (running in calico/node). It watches the Kubernetes resources and Calico custom resources used by these daemons, and whenever a resource changes it fans out the update to the daemons. This reduces the number of watches the Kubernetes API server needs to serve and improves scalability of the cluster.</p> <ul> <li>Provision Certificates</li> </ul> <p>We will use mutually authenticated TLS to ensure that calico/node and Typha communicate securely. We generate a certificate authority (CA) and use it to sign a certificate for Typha.</p> <p>Change to directory <code>/etc/kubernetes/pki/</code>. <div class=highlight><pre><span></span><code><span class=go>cd /etc/kubernetes/pki/</span>
</code></pre></div></p> <p>Create the CA certificate and key <div class=highlight><pre><span></span><code><span class=go>openssl req -x509 -newkey rsa:4096 \</span>
<span class=go>  -keyout typhaca.key \</span>
<span class=go>  -nodes \</span>
<span class=go>  -out typhaca.crt \</span>
<span class=go>  -subj &quot;/CN=Calico Typha CA&quot; \</span>
<span class=go>  -days 365</span>
</code></pre></div></p> <p>Store the CA certificate in a ConfigMap that Typha &amp; calico/node will access. <div class=highlight><pre><span></span><code><span class=go>kubectl create configmap -n kube-system calico-typha-ca --from-file=typhaca.crt</span>
</code></pre></div></p> <p>Create the Typha key and certificate signing request (CSR). <div class=highlight><pre><span></span><code><span class=go>openssl req -newkey rsa:4096 \</span>
<span class=go>  -keyout typha.key \</span>
<span class=go>  -nodes \</span>
<span class=go>  -out typha.csr \</span>
<span class=go>  -subj &quot;/CN=calico-typha&quot;</span>
</code></pre></div></p> <p>The certificate presents the Common Name (CN) as <code>calico-typha</code>. <code>calico/node</code> will be configured to verify this name.</p> <p>Sign the Typha certificate with the CA. <div class=highlight><pre><span></span><code><span class=go>openssl x509 -req -in typha.csr \</span>
<span class=go>  -CA typhaca.crt \</span>
<span class=go>  -CAkey typhaca.key \</span>
<span class=go>  -CAcreateserial \</span>
<span class=go>  -out typha.crt \</span>
<span class=go>  -days 365</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Signature ok
subject=CN = calico-typha
Getting CA Private Key
</code></pre></div></p> <p>Store the Typha key and certificate in a secret that Typha will access <div class=highlight><pre><span></span><code><span class=go>kubectl create secret generic -n kube-system calico-typha-certs --from-file=typha.key --from-file=typha.crt</span>
</code></pre></div></p> <ul> <li>Provision RBAC</li> </ul> <p>Change to home directory. <div class=highlight><pre><span></span><code><span class=go>cd ~</span>
</code></pre></div></p> <p>Create a ServiceAccount that will be used to run Typha. <div class=highlight><pre><span></span><code><span class=go>kubectl create serviceaccount -n kube-system calico-typha</span>
</code></pre></div></p> <p>Define a cluster role for Typha with permission to watch Calico datastore objects. <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>kind: ClusterRole</span>
<span class=go>apiVersion: rbac.authorization.k8s.io/v1</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-typha</span>
<span class=go>rules:</span>
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods</span>
<span class=go>      - namespaces</span>
<span class=go>      - serviceaccounts</span>
<span class=go>      - endpoints</span>
<span class=go>      - services</span>
<span class=go>      - nodes</span>
<span class=go>    verbs:</span>
<span class=gp>      # </span>Used to discover service IPs <span class=k>for</span> advertisement.
<span class=go>      - watch</span>
<span class=go>      - list</span>
<span class=go>  - apiGroups: [&quot;networking.k8s.io&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - networkpolicies</span>
<span class=go>    verbs:</span>
<span class=go>      - watch</span>
<span class=go>      - list</span>
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - globalfelixconfigs</span>
<span class=go>      - felixconfigurations</span>
<span class=go>      - bgppeers</span>
<span class=go>      - globalbgpconfigs</span>
<span class=go>      - bgpconfigurations</span>
<span class=go>      - ippools</span>
<span class=go>      - ipamblocks</span>
<span class=go>      - globalnetworkpolicies</span>
<span class=go>      - globalnetworksets</span>
<span class=go>      - networkpolicies</span>
<span class=go>      - clusterinformations</span>
<span class=go>      - hostendpoints</span>
<span class=go>      - blockaffinities</span>
<span class=go>      - networksets</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>      - watch</span>
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=gp>      #</span>- ippools
<span class=gp>      #</span>- felixconfigurations
<span class=go>      - clusterinformations</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - create</span>
<span class=go>      - update</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Bind the cluster role to the calico-typha ServiceAccount. <div class=highlight><pre><span></span><code><span class=go>kubectl create clusterrolebinding calico-typha --clusterrole=calico-typha --serviceaccount=kube-system:calico-typha</span>
</code></pre></div></p> <ul> <li>Install Deployment</li> </ul> <p>Since Typha is required by <code>calico/node</code>, and <code>calico/node</code> establishes the pod network, we run Typha as a host networked pod to avoid a chicken-and-egg problem. We run 3 replicas of Typha so that even during a rolling update, a single failure does not make Typha unavailable. <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: apps/v1</span>
<span class=go>kind: Deployment</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-typha</span>
<span class=go>  namespace: kube-system</span>
<span class=go>  labels:</span>
<span class=go>    k8s-app: calico-typha</span>
<span class=go>spec:</span>
<span class=go>  replicas: 3</span>
<span class=go>  revisionHistoryLimit: 2</span>
<span class=go>  selector:</span>
<span class=go>    matchLabels:</span>
<span class=go>      k8s-app: calico-typha</span>
<span class=go>  template:</span>
<span class=go>    metadata:</span>
<span class=go>      labels:</span>
<span class=go>        k8s-app: calico-typha</span>
<span class=go>      annotations:</span>
<span class=go>        cluster-autoscaler.kubernetes.io/safe-to-evict: &#39;true&#39;</span>
<span class=go>    spec:</span>
<span class=go>      hostNetwork: true</span>
<span class=go>      tolerations:</span>
<span class=gp>        # </span>Mark the pod as a critical add-on <span class=k>for</span> rescheduling.
<span class=go>        - key: CriticalAddonsOnly</span>
<span class=go>          operator: Exists</span>
<span class=go>      serviceAccountName: calico-typha</span>
<span class=go>      priorityClassName: system-cluster-critical</span>
<span class=go>      containers:</span>
<span class=go>      - image: calico/typha:v3.8.0</span>
<span class=go>        name: calico-typha</span>
<span class=go>        ports:</span>
<span class=go>        - containerPort: 5473</span>
<span class=go>          name: calico-typha</span>
<span class=go>          protocol: TCP</span>
<span class=go>        env:</span>
<span class=gp>          # </span>Disable logging to file and syslog since those don<span class=err>&#39;</span>t make sense <span class=k>in</span> Kubernetes.
<span class=go>          - name: TYPHA_LOGFILEPATH</span>
<span class=go>            value: &quot;none&quot;</span>
<span class=go>          - name: TYPHA_LOGSEVERITYSYS</span>
<span class=go>            value: &quot;none&quot;</span>
<span class=gp>          # </span>Monitor the Kubernetes API to find the number of running instances and rebalance
<span class=gp>          # </span>connections.
<span class=go>          - name: TYPHA_CONNECTIONREBALANCINGMODE</span>
<span class=go>            value: &quot;kubernetes&quot;</span>
<span class=go>          - name: TYPHA_DATASTORETYPE</span>
<span class=go>            value: &quot;kubernetes&quot;</span>
<span class=go>          - name: TYPHA_HEALTHENABLED</span>
<span class=go>            value: &quot;true&quot;</span>
<span class=gp>          # </span>Location of the CA bundle Typha uses to authenticate calico/node<span class=p>;</span> volume mount
<span class=go>          - name: TYPHA_CAFILE</span>
<span class=go>            value: /calico-typha-ca/typhaca.crt</span>
<span class=gp>          # </span>Common name on the calico/node certificate
<span class=go>          - name: TYPHA_CLIENTCN</span>
<span class=go>            value: calico-node</span>
<span class=gp>          # </span>Location of the server certificate <span class=k>for</span> Typha<span class=p>;</span> volume mount
<span class=go>          - name: TYPHA_SERVERCERTFILE</span>
<span class=go>            value: /calico-typha-certs/typha.crt</span>
<span class=gp>          # </span>Location of the server certificate key <span class=k>for</span> Typha<span class=p>;</span> volume mount
<span class=go>          - name: TYPHA_SERVERKEYFILE</span>
<span class=go>            value: /calico-typha-certs/typha.key</span>
<span class=go>        livenessProbe:</span>
<span class=go>          httpGet:</span>
<span class=go>            path: /liveness</span>
<span class=go>            port: 9098</span>
<span class=go>            host: localhost</span>
<span class=go>          periodSeconds: 30</span>
<span class=go>          initialDelaySeconds: 30</span>
<span class=go>        readinessProbe:</span>
<span class=go>          httpGet:</span>
<span class=go>            path: /readiness</span>
<span class=go>            port: 9098</span>
<span class=go>            host: localhost</span>
<span class=go>          periodSeconds: 10</span>
<span class=go>        volumeMounts:</span>
<span class=go>        - name: calico-typha-ca</span>
<span class=go>          mountPath: &quot;/calico-typha-ca&quot;</span>
<span class=go>          readOnly: true</span>
<span class=go>        - name: calico-typha-certs</span>
<span class=go>          mountPath: &quot;/calico-typha-certs&quot;</span>
<span class=go>          readOnly: true</span>
<span class=go>      volumes:</span>
<span class=go>      - name: calico-typha-ca</span>
<span class=go>        configMap:</span>
<span class=go>          name: calico-typha-ca</span>
<span class=go>      - name: calico-typha-certs</span>
<span class=go>        secret:</span>
<span class=go>          secretName: calico-typha-certs</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>We set <code>TYPHA_CLIENTCN</code> to calico-node which is the common name we will use on the certificate <code>calico/node</code> will use late.</p> <p>Verify Typha is up an running with three instances <div class=highlight><pre><span></span><code><span class=go>kubectl get pods -l k8s-app=calico-typha -n kube-system</span>
</code></pre></div> Result looks like below. <div class=highlight><pre><span></span><code>NAME                           READY   STATUS    RESTARTS   AGE
calico-typha-5b8669646-b2xnq   1/1     Running   0          20s
calico-typha-5b8669646-q5glk   0/1     Pending   0          20s
calico-typha-5b8669646-rvv86   1/1     Running   0          20s
</code></pre></div></p> <p>Here is an error message received: <div class=highlight><pre><span></span><code>0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate, 2 node(s) didn&#39;t have free ports for the requested pod ports.
</code></pre></div></p> <ul> <li>Install Service</li> </ul> <p><code>calico/node</code> uses a Kubernetes Service to get load-balanced access to Typha. <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: v1</span>
<span class=go>kind: Service</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-typha</span>
<span class=go>  namespace: kube-system</span>
<span class=go>  labels:</span>
<span class=go>    k8s-app: calico-typha</span>
<span class=go>spec:</span>
<span class=go>  ports:</span>
<span class=go>    - port: 5473</span>
<span class=go>      protocol: TCP</span>
<span class=go>      targetPort: calico-typha</span>
<span class=go>      name: calico-typha</span>
<span class=go>  selector:</span>
<span class=go>    k8s-app: calico-typha</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Validate that Typha is using TLS. <div class=highlight><pre><span></span><code><span class=go>TYPHA_CLUSTERIP=$(kubectl get svc -n kube-system calico-typha -o jsonpath=&#39;{.spec.clusterIP}&#39;)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=go>curl https://$TYPHA_CLUSTERIP:5473 -v --cacert /etc/kubernetes/pki/typhaca.crt</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>*   Trying 11.244.91.165:5473...
* TCP_NODELAY set
* Connected to 11.244.91.165 (11.244.91.165) port 5473 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/kubernetes/pki/typhaca.crt
  CApath: /etc/ssl/certs
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS alert, bad certificate (554):
* error:14094412:SSL routines:ssl3_read_bytes:sslv3 alert bad certificate
* Closing connection 0
curl: (35) error:14094412:SSL routines:ssl3_read_bytes:sslv3 alert bad certificate
</code></pre></div></p> <p>This demonstrates that Typha is presenting its TLS certificate and rejecting our connection because we do not present a certificate. We will later deploy calico/node with a certificate Typha will accept.</p> <h2 id=install-caliconode>Install calico/node<a class=headerlink href=#install-caliconode title="Permanent link"> ¶</a></h2> <p><code>calico/node</code> runs three daemons:</p> <ul> <li>Felix, the Calico per-node daemon</li> <li>BIRD, a daemon that speaks the BGP protocol to distribute routing information to other nodes</li> <li> <p>confd, a daemon that watches the Calico datastore for config changes and updates BIRD’s config files</p> </li> <li> <p>Provision Certificates</p> </li> </ul> <p>Change to directory <code>/etc/kubernetes/pki/</code>. <div class=highlight><pre><span></span><code><span class=go>cd /etc/kubernetes/pki/</span>
</code></pre></div></p> <p>Create the key <code>calico/node</code> will use to authenticate with Typha and the certificate signing request (CSR) <div class=highlight><pre><span></span><code><span class=go>openssl req -newkey rsa:4096 \</span>
<span class=go>  -keyout calico-node.key \</span>
<span class=go>  -nodes \</span>
<span class=go>  -out calico-node.csr \</span>
<span class=go>  -subj &quot;/CN=calico-node&quot;</span>
</code></pre></div></p> <p>The certificate presents the Common Name (CN) as <code>calico-node</code>, which is what we configured Typha to accept in the last lab.</p> <p>Sign the Felix certificate with the CA we created earlier. <div class=highlight><pre><span></span><code><span class=go>openssl x509 -req -in calico-node.csr \</span>
<span class=go>  -CA typhaca.crt \</span>
<span class=go>  -CAkey typhaca.key \</span>
<span class=go>  -CAcreateserial \</span>
<span class=go>  -out calico-node.crt \</span>
<span class=go>  -days 365</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Signature ok
subject=CN = calico-node
Getting CA Private Key
</code></pre></div></p> <p>Store the key and certificate in a Secret that calico/node will access. <div class=highlight><pre><span></span><code><span class=go>kubectl create secret generic -n kube-system calico-node-certs --from-file=calico-node.key --from-file=calico-node.crt</span>
</code></pre></div></p> <ul> <li>Provision RBAC</li> </ul> <p>Change to home directory. <div class=highlight><pre><span></span><code><span class=go>cd ~</span>
</code></pre></div></p> <p>Create the ServiceAccount that calico/node will run as. <div class=highlight><pre><span></span><code><span class=go>kubectl create serviceaccount -n kube-system calico-node</span>
</code></pre></div></p> <p>Provision a cluster role with permissions to read and modify Calico datastore objects <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>kind: ClusterRole</span>
<span class=go>apiVersion: rbac.authorization.k8s.io/v1</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-node</span>
<span class=go>rules:</span>
<span class=gp>  # </span>The CNI plugin needs to get pods, nodes, and namespaces.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods</span>
<span class=go>      - nodes</span>
<span class=go>      - namespaces</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=gp>  # </span>EndpointSlices are used <span class=k>for</span> Service-based network policy rule
<span class=gp>  # </span>enforcement.
<span class=go>  - apiGroups: [&quot;discovery.k8s.io&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - endpointslices</span>
<span class=go>    verbs:</span>
<span class=go>      - watch</span>
<span class=go>      - list</span>
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - endpoints</span>
<span class=go>      - services</span>
<span class=go>    verbs:</span>
<span class=gp>      # </span>Used to discover service IPs <span class=k>for</span> advertisement.
<span class=go>      - watch</span>
<span class=go>      - list</span>
<span class=gp>      # </span>Used to discover Typhas.
<span class=go>      - get</span>
<span class=gp>  # </span>Pod CIDR auto-detection on kubeadm needs access to config maps.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - configmaps</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - nodes/status</span>
<span class=go>    verbs:</span>
<span class=gp>      # </span>Needed <span class=k>for</span> clearing NodeNetworkUnavailable flag.
<span class=go>      - patch</span>
<span class=gp>      # </span>Calico stores some configuration information <span class=k>in</span> node annotations.
<span class=go>      - update</span>
<span class=gp>  # </span>Watch <span class=k>for</span> changes to Kubernetes NetworkPolicies.
<span class=go>  - apiGroups: [&quot;networking.k8s.io&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - networkpolicies</span>
<span class=go>    verbs:</span>
<span class=go>      - watch</span>
<span class=go>      - list</span>
<span class=gp>  # </span>Used by Calico <span class=k>for</span> policy information.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods</span>
<span class=go>      - namespaces</span>
<span class=go>      - serviceaccounts</span>
<span class=go>    verbs:</span>
<span class=go>      - list</span>
<span class=go>      - watch</span>
<span class=gp>  # </span>The CNI plugin patches pods/status.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - pods/status</span>
<span class=go>    verbs:</span>
<span class=go>      - patch</span>
<span class=gp>  # </span>Used <span class=k>for</span> creating service account tokens to be used by the CNI plugin
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - serviceaccounts/token</span>
<span class=go>    resourceNames:</span>
<span class=go>      - calico-node</span>
<span class=go>    verbs:</span>
<span class=go>      - create</span>
<span class=gp>  # </span>Calico monitors various CRDs <span class=k>for</span> config.
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - globalfelixconfigs</span>
<span class=go>      - felixconfigurations</span>
<span class=go>      - bgppeers</span>
<span class=go>      - globalbgpconfigs</span>
<span class=go>      - bgpconfigurations</span>
<span class=go>      - ippools</span>
<span class=go>      - ipamblocks</span>
<span class=go>      - globalnetworkpolicies</span>
<span class=go>      - globalnetworksets</span>
<span class=go>      - networkpolicies</span>
<span class=go>      - networksets</span>
<span class=go>      - clusterinformations</span>
<span class=go>      - hostendpoints</span>
<span class=go>      - blockaffinities</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>      - watch</span>
<span class=gp>  # </span>Calico must create and update some CRDs on startup.
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - ippools</span>
<span class=go>      - felixconfigurations</span>
<span class=go>      - clusterinformations</span>
<span class=go>    verbs:</span>
<span class=go>      - create</span>
<span class=go>      - update</span>
<span class=gp>  # </span>Calico stores some configuration information on the node.
<span class=go>  - apiGroups: [&quot;&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - nodes</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>      - watch</span>
<span class=gp>  # </span>These permissions are required <span class=k>for</span> Calico CNI to perform IPAM allocations.
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - blockaffinities</span>
<span class=go>      - ipamblocks</span>
<span class=go>      - ipamhandles</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=go>      - list</span>
<span class=go>      - create</span>
<span class=go>      - update</span>
<span class=go>      - delete</span>
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - ipamconfigs</span>
<span class=go>    verbs:</span>
<span class=go>      - get</span>
<span class=gp>  # </span>Block affinities must also be watchable by confd <span class=k>for</span> route aggregation.
<span class=go>  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span>
<span class=go>    resources:</span>
<span class=go>      - blockaffinities</span>
<span class=go>    verbs:</span>
<span class=go>      - watch</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Bind the cluster role to the calico-node ServiceAccount <div class=highlight><pre><span></span><code><span class=go>kubectl create clusterrolebinding calico-node --clusterrole=calico-node --serviceaccount=kube-system:calico-node</span>
</code></pre></div></p> <ul> <li>Install daemon set</li> </ul> <p>Change to home directory. <div class=highlight><pre><span></span><code><span class=go>cd ~</span>
</code></pre></div></p> <p><code>calico/node</code> runs as a daemon set so that it is installed on every node in the cluster.</p> <p>Change <code>image: calico/node:v3.20.0</code> to right version. </p> <p>Create the daemon set <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>kind: DaemonSet</span>
<span class=go>apiVersion: apps/v1</span>
<span class=go>metadata:</span>
<span class=go>  name: calico-node</span>
<span class=go>  namespace: kube-system</span>
<span class=go>  labels:</span>
<span class=go>    k8s-app: calico-node</span>
<span class=go>spec:</span>
<span class=go>  selector:</span>
<span class=go>    matchLabels:</span>
<span class=go>      k8s-app: calico-node</span>
<span class=go>  updateStrategy:</span>
<span class=go>    type: RollingUpdate</span>
<span class=go>    rollingUpdate:</span>
<span class=go>      maxUnavailable: 1</span>
<span class=go>  template:</span>
<span class=go>    metadata:</span>
<span class=go>      labels:</span>
<span class=go>        k8s-app: calico-node</span>
<span class=go>    spec:</span>
<span class=go>      nodeSelector:</span>
<span class=go>        kubernetes.io/os: linux</span>
<span class=go>      hostNetwork: true</span>
<span class=go>      tolerations:</span>
<span class=gp>        # </span>Make sure calico-node gets scheduled on all nodes.
<span class=go>        - effect: NoSchedule</span>
<span class=go>          operator: Exists</span>
<span class=gp>        # </span>Mark the pod as a critical add-on <span class=k>for</span> rescheduling.
<span class=go>        - key: CriticalAddonsOnly</span>
<span class=go>          operator: Exists</span>
<span class=go>        - effect: NoExecute</span>
<span class=go>          operator: Exists</span>
<span class=go>      serviceAccountName: calico-node</span>
<span class=gp>      # </span>Minimize downtime during a rolling upgrade or deletion<span class=p>;</span> tell Kubernetes to <span class=k>do</span> a <span class=s2>&quot;force</span>
<span class=gp>      # </span><span class=s2>deletion&quot;</span>: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
<span class=go>      terminationGracePeriodSeconds: 0</span>
<span class=go>      priorityClassName: system-node-critical</span>
<span class=go>      containers:</span>
<span class=gp>        # </span>Runs calico-node container on each Kubernetes node.  This
<span class=gp>        # </span>container programs network policy and routes on each
<span class=gp>        # </span>host.
<span class=go>        - name: calico-node</span>
<span class=go>          image: calico/node:v3.20.0</span>
<span class=go>          env:</span>
<span class=gp>            # </span>Use Kubernetes API as the backing datastore.
<span class=go>            - name: DATASTORE_TYPE</span>
<span class=go>              value: &quot;kubernetes&quot;</span>
<span class=go>            - name: FELIX_TYPHAK8SSERVICENAME</span>
<span class=go>              value: calico-typha</span>
<span class=gp>            # </span>Wait <span class=k>for</span> the datastore.
<span class=go>            - name: WAIT_FOR_DATASTORE</span>
<span class=go>              value: &quot;true&quot;</span>
<span class=gp>            # </span>Set based on the k8s node name.
<span class=go>            - name: NODENAME</span>
<span class=go>              valueFrom:</span>
<span class=go>                fieldRef:</span>
<span class=go>                  fieldPath: spec.nodeName</span>
<span class=gp>            # </span>Choose the backend to use.
<span class=go>            - name: CALICO_NETWORKING_BACKEND</span>
<span class=go>              value: bird</span>
<span class=gp>            # </span>Cluster <span class=nb>type</span> to identify the deployment <span class=nb>type</span>
<span class=go>            - name: CLUSTER_TYPE</span>
<span class=go>              value: &quot;k8s,bgp&quot;</span>
<span class=gp>            # </span>Auto-detect the BGP IP address.
<span class=go>            - name: IP</span>
<span class=go>              value: &quot;autodetect&quot;</span>
<span class=gp>            # </span>Disable file logging so kubectl logs works.
<span class=go>            - name: CALICO_DISABLE_FILE_LOGGING</span>
<span class=go>              value: &quot;true&quot;</span>
<span class=gp>            # </span>Set Felix endpoint to host default action to ACCEPT.
<span class=go>            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION</span>
<span class=go>              value: &quot;ACCEPT&quot;</span>
<span class=gp>            # </span>Disable IPv6 on Kubernetes.
<span class=go>            - name: FELIX_IPV6SUPPORT</span>
<span class=go>              value: &quot;false&quot;</span>
<span class=gp>            # </span>Set Felix logging to <span class=s2>&quot;info&quot;</span>
<span class=go>            - name: FELIX_LOGSEVERITYSCREEN</span>
<span class=go>              value: &quot;info&quot;</span>
<span class=go>            - name: FELIX_HEALTHENABLED</span>
<span class=go>              value: &quot;true&quot;</span>
<span class=gp>            # </span>Location of the CA bundle Felix uses to authenticate Typha<span class=p>;</span> volume mount
<span class=go>            - name: FELIX_TYPHACAFILE</span>
<span class=go>              value: /calico-typha-ca/typhaca.crt</span>
<span class=gp>            # </span>Common name on the Typha certificate<span class=p>;</span> used to verify we are talking to an authentic typha
<span class=go>            - name: FELIX_TYPHACN</span>
<span class=go>              value: calico-typha</span>
<span class=gp>            # </span>Location of the client certificate <span class=k>for</span> connecting to Typha<span class=p>;</span> volume mount
<span class=go>            - name: FELIX_TYPHACERTFILE</span>
<span class=go>              value: /calico-node-certs/calico-node.crt</span>
<span class=gp>            # </span>Location of the client certificate key <span class=k>for</span> connecting to Typha<span class=p>;</span> volume mount
<span class=go>            - name: FELIX_TYPHAKEYFILE</span>
<span class=go>              value: /calico-node-certs/calico-node.key</span>
<span class=go>          securityContext:</span>
<span class=go>            privileged: true</span>
<span class=go>          resources:</span>
<span class=go>            requests:</span>
<span class=go>              cpu: 250m</span>
<span class=go>          lifecycle:</span>
<span class=go>            preStop:</span>
<span class=go>              exec:</span>
<span class=go>                command:</span>
<span class=go>                - /bin/calico-node</span>
<span class=go>                - -shutdown</span>
<span class=go>          livenessProbe:</span>
<span class=go>            httpGet:</span>
<span class=go>              path: /liveness</span>
<span class=go>              port: 9099</span>
<span class=go>              host: localhost</span>
<span class=go>            periodSeconds: 10</span>
<span class=go>            initialDelaySeconds: 10</span>
<span class=go>            failureThreshold: 6</span>
<span class=go>          readinessProbe:</span>
<span class=go>            exec:</span>
<span class=go>              command:</span>
<span class=go>              - /bin/calico-node</span>
<span class=go>              - -bird-ready</span>
<span class=go>              - -felix-ready</span>
<span class=go>            periodSeconds: 10</span>
<span class=go>          volumeMounts:</span>
<span class=go>            - mountPath: /lib/modules</span>
<span class=go>              name: lib-modules</span>
<span class=go>              readOnly: true</span>
<span class=go>            - mountPath: /run/xtables.lock</span>
<span class=go>              name: xtables-lock</span>
<span class=go>              readOnly: false</span>
<span class=go>            - mountPath: /var/run/calico</span>
<span class=go>              name: var-run-calico</span>
<span class=go>              readOnly: false</span>
<span class=go>            - mountPath: /var/lib/calico</span>
<span class=go>              name: var-lib-calico</span>
<span class=go>              readOnly: false</span>
<span class=go>            - mountPath: /var/run/nodeagent</span>
<span class=go>              name: policysync</span>
<span class=go>            - mountPath: &quot;/calico-typha-ca&quot;</span>
<span class=go>              name: calico-typha-ca</span>
<span class=go>              readOnly: true</span>
<span class=go>            - mountPath: /calico-node-certs</span>
<span class=go>              name: calico-node-certs</span>
<span class=go>              readOnly: true</span>
<span class=go>      volumes:</span>
<span class=gp>        # </span>Used by calico-node.
<span class=go>        - name: lib-modules</span>
<span class=go>          hostPath:</span>
<span class=go>            path: /lib/modules</span>
<span class=go>        - name: var-run-calico</span>
<span class=go>          hostPath:</span>
<span class=go>            path: /var/run/calico</span>
<span class=go>        - name: var-lib-calico</span>
<span class=go>          hostPath:</span>
<span class=go>            path: /var/lib/calico</span>
<span class=go>        - name: xtables-lock</span>
<span class=go>          hostPath:</span>
<span class=go>            path: /run/xtables.lock</span>
<span class=go>            type: FileOrCreate</span>
<span class=gp>        # </span>Used to create per-pod Unix Domain Sockets
<span class=go>        - name: policysync</span>
<span class=go>          hostPath:</span>
<span class=go>            type: DirectoryOrCreate</span>
<span class=go>            path: /var/run/nodeagent</span>
<span class=go>        - name: calico-typha-ca</span>
<span class=go>          configMap:</span>
<span class=go>            name: calico-typha-ca</span>
<span class=go>        - name: calico-node-certs</span>
<span class=go>          secret:</span>
<span class=go>            secretName: calico-node-certs</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Verify that calico/node is running on each node in your cluster, and goes to Running within a few minutes. <div class=highlight><pre><span></span><code><span class=go>kubectl get pod -l k8s-app=calico-node -n kube-system</span>
</code></pre></div> Result looks like below. <div class=highlight><pre><span></span><code>NAME                READY   STATUS    RESTARTS   AGE
calico-node-4c4sp   1/1     Running   0          40s
calico-node-j2z6v   1/1     Running   0          40s
calico-node-vgm9n   1/1     Running   0          40s
</code></pre></div></p> <h2 id=test-networking>Test networking<a class=headerlink href=#test-networking title="Permanent link"> ¶</a></h2> <h3 id=pod-to-pod-pings>Pod to pod pings<a class=headerlink href=#pod-to-pod-pings title="Permanent link"> ¶</a></h3> <p>Create three busybox instances <div class=highlight><pre><span></span><code><span class=go>kubectl create deployment pingtest --image=busybox --replicas=3 -- sleep infinity</span>
</code></pre></div></p> <p>Check their IP addresses <div class=highlight><pre><span></span><code><span class=go>kubectl get pods --selector=app=pingtest --output=wide</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>NAME                        READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES
pingtest-585b76c894-chwjq   1/1     Running   0          7s    10.244.31.1    cka002   &lt;none&gt;           &lt;none&gt;
pingtest-585b76c894-s2tbs   1/1     Running   0          7s    10.244.31.0    cka002   &lt;none&gt;           &lt;none&gt;
pingtest-585b76c894-vm9wn   1/1     Running   0          7s    10.244.28.64   cka003   &lt;none&gt;           &lt;none&gt;
</code></pre></div></p> <p>Note the IP addresses of the second two pods, then exec into the first one. From inside the pod, ping the other two pod IP addresses. For example: <div class=highlight><pre><span></span><code><span class=go>kubectl exec -ti pingtest-585b76c894-chwjq -- sh</span>
<span class=go>/ # ping 10.244.31.1 -c 4</span>
<span class=go>4 packets transmitted, 4 packets received, 0% packet loss</span>

<span class=go>/ # ping 10.244.31.0 -c 4</span>
<span class=go>4 packets transmitted, 4 packets received, 0% packet loss</span>

<span class=go>/ # ping 10.244.28.64 -c 4</span>
<span class=go>4 packets transmitted, 0 packets received, 100% packet loss</span>
</code></pre></div></p> <h3 id=check-routes>Check routes<a class=headerlink href=#check-routes title="Permanent link"> ¶</a></h3> <p>From one of the nodes, verify that routes exist to each of the pingtest pods’ IP addresses. For example <div class=highlight><pre><span></span><code><span class=go>ip route get 10.244.31.1</span>
<span class=go>ip route get 10.244.31.0</span>
<span class=go>ip route get 10.244.28.64</span>
</code></pre></div> In the result, the <code>via &lt;cka001_ip&gt;</code>(it's control-plane) in this example indicates the next-hop for this pod IP, which matches the IP address of the node the pod is scheduled on, as expected. IPAM allocations from different pools.</p> <p>Recall that we created two IP pools, but left one disabled. <div class=highlight><pre><span></span><code><span class=go>calicoctl get ippools -o wide</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>NAME            CIDR              NAT    IPIPMODE   VXLANMODE   DISABLED   DISABLEBGPEXPORT   SELECTOR   
ipv4-ippool-1   10.244.0.0/18     true   Never      Never       false      false              all()      
ipv4-ippool-2   10.244.192.0/19   true   Never      Never       true       false              all()   
</code></pre></div></p> <p>Enable the second pool. <div class=highlight><pre><span></span><code><span class=go>calicoctl --allow-version-mismatch apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: projectcalico.org/v3</span>
<span class=go>kind: IPPool</span>
<span class=go>metadata:</span>
<span class=go>  name: ipv4-ippool-2</span>
<span class=go>spec:</span>
<span class=go>  cidr: 10.244.192.0/19</span>
<span class=go>  ipipMode: Never</span>
<span class=go>  natOutgoing: true</span>
<span class=go>  disabled: false</span>
<span class=go>  nodeSelector: all()</span>
<span class=go>EOF</span>
</code></pre></div></p> <p><div class=highlight><pre><span></span><code><span class=go>calicoctl get ippools -o wide</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>NAME            CIDR              NAT    IPIPMODE   VXLANMODE   DISABLED   DISABLEBGPEXPORT   SELECTOR   
ipv4-ippool-1   10.244.0.0/18     true   Never      Never       false      false              all()      
ipv4-ippool-2   10.244.192.0/19   true   Never      Never       false      false              all()      
</code></pre></div></p> <p>Create a pod, explicitly requesting an address from pool2 <div class=highlight><pre><span></span><code><span class=go>kubectl apply -f - &lt;&lt;EOF</span>
<span class=go>apiVersion: v1</span>
<span class=go>kind: Pod</span>
<span class=go>metadata:</span>
<span class=go>  name: pingtest-ippool-2</span>
<span class=go>  annotations:</span>
<span class=go>    cni.projectcalico.org/ipv4pools: &quot;[\&quot;ipv4-ippool-2\&quot;]&quot;</span>
<span class=go>spec:</span>
<span class=go>  containers:</span>
<span class=go>  - args:</span>
<span class=go>    - sleep</span>
<span class=go>    - infinity</span>
<span class=go>    image: busybox</span>
<span class=go>    imagePullPolicy: Always</span>
<span class=go>    name: pingtest</span>
<span class=go>EOF</span>
</code></pre></div></p> <p>Verify it has an IP address from pool2 <div class=highlight><pre><span></span><code><span class=go>kubectl get pod pingtest-ippool-2 -o wide</span>
</code></pre></div> Result <div class=highlight><pre><span></span><code>NAME                READY   STATUS    RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES
pingtest-ippool-2   1/1     Running   0          18s   10.244.203.192   cka003   &lt;none&gt;           &lt;none&gt;
</code></pre></div></p> <p>Let's attach to the Pod <code>pingtest-585b76c894-chwjq</code> again. <div class=highlight><pre><span></span><code><span class=go>kubectl exec -ti pingtest-585b76c894-chwjq -- sh</span>
<span class=go>/ # 10.244.203.192 -c 4</span>
<span class=go>4 packets transmitted, 0 packets received, 100% packet loss</span>
</code></pre></div></p> <p>!! Mark here. it's failed. Need further check why the route does not work.</p> <p>Clean up <div class=highlight><pre><span></span><code><span class=go>kubectl delete deployments.apps pingtest</span>
<span class=go>kubectl delete pod pingtest-ippool-2</span>
</code></pre></div></p> <div class="admonition reference"> <p class=admonition-title>Reference</p> <p><a href=https://projectcalico.docs.tigera.io/getting-started/kubernetes/hardway/ >End-to-end Calico installation</a></p> </div> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> Back to top </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../casestudy-health-check/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Health Check" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Health Check </div> </div> </a> <a href=../../../linux/Administration/linux_admin/ class="md-footer__link md-footer__link--next" aria-label="Next: SUSE Linux Administration" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> SUSE Linux Administration </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.top"], "search": "../../../assets/javascripts/workers/search.fcfe8b6d.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.b1047164.min.js></script> </body> </html>